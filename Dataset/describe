when downloading many files (1000+), motrix crashes easily.
**desktop (please complete the following information):** - os: [e.g
macos, windows, linux] - version [e.g
10.14.2, win 10]
os linux ur otrix elease
the downloaded view display the unfinished download task.
a running nacos cluster, if you want to expand a node at this time, you will find that the raft protocol of the naming module of the original cluster cannot recognize the newly added node, resulting in the naming module not working properly
the configuration file server.port parameter is invalid
, , ublic , namespace
from #3858, nacos should be able to access a specified ip or domain as its' ip
but for my research, the feature has been invalid in newest version because of checking ip only
detail see `inetutils.ipautorefresh` so i think change the condition as `isip` or `isdomain`.
some times a service shown in nacos, has instances not health more then one,
new instance can't registed on the nacos regist center
if delete the service form nacos,new instance registed success
diskcache.write()->concurrentdiskutil.writefilecontent() he json string is truncated when writing chinese characters aramter content lenth is 4315,content.getbytes(charsetname) lenth is 4331
![image](
in `responsehandler` like `stringresponsehandler`, if the server return `gzip` content_encoding, it will not try to decompress content but read content directly.
it may caused the content is not right or garbled text
i think other `responsehandler` has the same problem.
.3.1 .3.2 nacos.config.max-retry pringboot
nacos: 1.3.2
spring cloud alibaba: 2.2.1
spring cloud dubbo:2.2.1
acos rivider
service is not found when groupname is blank
if groupname is blank, when request /v1/ns/catalog/service
if distrofilter.dofilter,it will set groupname as 'default_group', but real servicename's groupname is blank,such as '@@service' ![image](
![image](
all persistent service information could not be saved to a file because the wrong file was removed
repeat input when using sogou input method to set configuration
logging in with the wrong username or password will cause jackson serialization results to fail, because the response header contains null key,and after catching this exception, the username and password will be printed,i think that is dangerous.
revert chunk isn't work in content comparison page.
when update raft group info should update leader info to avoid occur not leader exeception
description:
![image]( phenomenon:
![image](
the title of the prompt box that appears when accessing the restricted namespace is incorrect
![image](
the persist instance register to server,but the cache in server will not create
branch: in the newest develop branch
when the persist instance register to server, raftcore will publish the new data.
in the com.alibaba.nacos.naming.consistency.persistent.raft.raftstore#write,the cache file created and then deleted
1 **nacos-client**
`naming` `namespace` ublic : `com.alibaba.nacos.client.naming.utils.initutils#initnamespacefornaming`
`config` `namespace` "", : `com.alibaba.nacos.client.utils.paramutil#parsenamespace` 2 ** **
`public` `permissions` `resource` `:*:*` `07ba088a-4782-468e-80cc-ee758beab327:*:*` 3 **com.alibaba.nacos.core.auth.authfilter **
`config` `resource` `:default_group:config/service-gateway`
`naming` `resource` `public:default_group:naming/service-gateway`
ava.util.regex.pattern#matches , naming
a = ":*:*";
b = "public:default_group:naming/service-gateway"; // naming
c = ":default_group:config/service-gateway"; // config pattern.matches(a, b); false
pattern.matches(a, c); true
nacos ublic 03
controllermethodscache.getmethod() will mismatch when the request's path is same,but the param is not same.
@getmapping
com.alibaba.nacos.config.server.controller.configcontroller#searchconfig @getmapping(params = "search=accurate")
com.alibaba.nacos.config.server.controller.configcontroller#getconfig @getmapping(params = "search=blur")
com.alibaba.nacos.config.server.controller.configcontroller#fuzzysearchconfig controllermethodscache.getmethod() can't match correctly in (com.alibaba.nacos.core.auth.authfilter, com.alibaba.nacos.naming.web.distrofilter)
version:0.26.8
pc key key cp lose_wait lient/control.go common.verify_eer .close() ps tcp ommon.verify_eer cp ridge.go .close()
// lag
func (s *bridge) verifyerror(c *conn.conn) { c.write([]byte(common.verify_eer)) c.close() c.close()
rm inux_arm64_server .26.8
ubuntu20.04 npc .26.8
ubuntu18.04 npc .26.7
<img width="704" alt=" 020-07-24 00 16 01" src=" ">
crash on startup: npclient`github.com/klauspost/cpuid.getprocfeatures:
-> <+0>: mrs x0, id_aa64pfr0_el1 //thread 6: exc_bad_instruction (code=1, subcode= ) <+4>: str x0, [sp, # ] <+8>: ret <+12>: .long ; unknown opcode
linux indows
after install, open app is crash **version**
v0.26.8 **device**
mi note 3 **rom**
miui 11.0.4
erver key
ps (1.1.1.1) ttps (
ocks5
![snip20200513_1](
#/install
install from source.
`v0.23.1` `v0.26.6`
- 1 389 ps 390 2p ps ocker
- 1 indows pc eb
- 1 ac pc eb 2p 1
ps
appname = nps
#boot mode(dev|pro)
runmode = dev #http(s) proxy port, no startup if empty
http_proxy_ip=0.0.0.0
http_proxy_port=8001
https_proxy_port=8002 ##bridge
bridge_type=tcp
bridge_port=3389
bridge_ip=0.0.0.0 #p2p
p2p_ip=48.65.88.**
p2p_port=3390 #web
web_host=nps.****.com
web_username=admin
web_password=*********
web_port = 81 # ...
eb
./npc -server=nps.****.com:3389 -vkey=ii5r6f1u3fk37odt -type=tcp
$ ./npc -server=nps.****.com:3389 -vkey=ii5r6f1u3fk37odt -type=tcp
2020/04/19 14:46:15.856 [i] [npc.go:229] the version of client is 0.26.6, the core version of client is 0.26.0
2020/04/19 14:46:15.979 [i] [client.go:67] successful connection with server nps.****.com:3389
eb 92.168.1.88:80
./npc -server=nps.****.com:3389 -vkey=ii5r6f1u3fk37odt -type=tcp -password=3818b56dab01 -local_type=secret
ac
./npc -server=nps.****.com:3389 -vkey=ii5r6f1u3fk37odt -type=tcp -password=3818b56dab01 -local_type=secret
2020/04/19 15:37:45.390 [i] [npc.go:229] the version of client is 0.26.6, the core version of client is 0.26.0
2020/04/19 15:37:45.390 [i] [local.go:115] successful start-up of local tcp monitoring, port 2000
2020/04/19 15:37:45.541 [i] [client.go:67] successful connection with server nps.****.com:3389
url
ac `curl `
curl: (52) empty reply from server
ac
2020/04/19 15:40:35.698 [d] [local.go:117] new secret connection
2020/04/19 15:40:41.757 [w] [client.go:208] connect to 192.168.1.88:80 error dial tcp 192.168.1.88:80: i/o timeout
trl+c ac pc eb
ac pc
ac eb
eb `192.168.1.1:80`
ac url 127.0.0.1:2000 6
(v0.23.1) ug 7
pc.conf
server_addr=nps.****.com:3389
conn_type=tcp
vkey=ii5r6f1u3fk37odt
auto_reconnection=true
compress=true [secret_web]
mode=secret
password=3818b56dab02
target_addr=192.168.1.88:80
``` mac pc.conf
server_addr=nps.****.com:3389
conn_type=tcp
vkey=ii5r6f1u3fk37odt
auto_reconnection=true
compress=true # ecret_web
# eb_secret
# the server returned an error, which port or host may have been occupied or not allowed to open
[secret_web]
local_port=2000
password=3818b56dab02
pc
win10
client connects to server but gives me eof error
udp dp
ean ede x64
ridge 7100 imeout win7 in10 tcp
`http` `gitea` `git push`
![image](
feb 06 19:55:56 v2ray nps[26245]: 2020/02/06 19:55:56.137 [d] [http.go:223] http request, method get, host git.kekxv.com, url /caesar/t, remote address 127.0.0.1:45476, target 127.0.0.1:80
feb 06 19:55:58 v2ray nps[26245]: 2020/02/06 19:55:58.009 [d] [http.go:223] http request, method get, host git.kekxv.com, url /user/avatar/caesar/-1, remote address 127.0.0.1:45478, target 127.0.0.1:80
feb 06 19:56:00 v2ray nps[26245]: 2020/02/06 19:56:00.043 [d] [http.go:223] http request, method get, host git.kekxv.com, url /javascript/jstools/blame/branch/master/model/jsflowchart/index.html, remote a
feb 06 19:56:01 v2ray nps[26245]: 2020/02/06 19:56:01.073 [d] [http.go:223] http request, method get, host git.kekxv.com, url /manifest.json, remote address 127.0.0.1:45484, target 127.0.0.1:80
feb 06 19:57:38 v2ray nps[26245]: 2020/02/06 19:57:38.057 [d] [http.go:223] http request, method get, host git.kekxv.com, url /caesar/jstools/commits/branch/master/pwa, remote address 127.0.0.1:45564, tar
feb 06 19:57:38 v2ray nps[26245]: 2020/02/06 19:57:38.971 [d] [http.go:223] http request, method get, host git.kekxv.com, url /javascript/jstools/commits/branch/master/pwa, remote address 127.0.0.1:45566,
feb 06 19:59:07 v2ray nps[26245]: 2020/02/06 19:59:07.957 [d] [http.go:223] http request, method get, host git.kekxv.com, url /caesar/jstools/src/branch/master/model/indexdb/readme.md, remote address 127.
feb 06 19:59:09 v2ray nps[26245]: 2020/02/06 19:59:09.493 [d] [http.go:223] http request, method get, host git.kekxv.com, url /javascript/jstools/src/branch/master/model/indexdb/readme.md, remote address feb 06 20:00:07 v2ray nps[26245]: 2020/02/06 20:00:07.105 [d] [http.go:223] http request, method get, host git.kekxv.com, url /caesar/learnwebgl/blame/commit/67c6cdf0e125135249e27101096c05d9713455f5/readm
feb 06 20:04:16 v2ray nps[26245]: 2020/02/06 20:04:16.234 [d] [http.go:223] http request, method get, host git.kekxv.com, url /explore/organizations, remote address 127.0.0.1:45818, target 127.0.0.1:80
lines 1-18/18 (end)
docker ps , cpu
ps xxxx/xx/xx xx:xx:xx reload fail
dns forward will result query error,
;; warning: id mismatch: expected id 40089, got 5635
;; warning: query response not set
nps a b
both server and client sides report error as below: ```
[w] [mux.go:42] mux:unknown conn type, only [w] [mux.go:448] bad file descriptor
[w] [mux.go:448] bad file descriptor
[w] [mux.go:448] bad file descriptor
nps install
dd success son
key linux_amd64 0.25.1
debian 10 no such file or directory
2019/12/07 00:10:50 copy file ::/home/github/conf/tasks.json to /etc/nps/conf/tasks.json
2019/12/07 00:10:50 executable files have been copied to /usr/bin/nps
2019/12/07 00:10:50 write systemd service err open /usr/lib/systemd/system/nps.service: no such file or directory
2019/12/07 00:10:50 install ok!
2019/12/07 00:10:50 static files and configuration files in the current directory will be useless
2019/12/07 00:10:50 the new configuration file is located in /etc/nps you can edit them
2019/12/07 00:10:50 you can start with:
sudo systemctl enable|disable|start|stop|restart|status nps
nps test|start|stop|restart|status
0.25 ; ttp ttps ttps_just_proxy rue ttps ost ttp ost
web http basic auth , web , ; http basic auth <img width="819" alt="screen shot 2019-11-30 at 11 04 29 am" src=" "> <img width="450" alt="screen shot 2019-11-30 at 10 48 27 am" src=" ">
a clear and concise description of what the bug is.
ws lbert
downloading to /home/yihuazhou/.hanlp/embeddings/albert_base_zh.tar.gz 97.69%, 37.0 mb/37.9 mb, 92 kb/s, eta 10 s failed to load
see traceback below:
================================error log begins================================
traceback (most recent call last): file "/home/yihuazhou/miniconda3/lib/python3.8/site-packages/hanlp/utils/io_util.py", line 201, in download urlretrieve(url, tmp_path, reporthook) file "/home/yihuazhou/miniconda3/lib/python3.8/urllib/request.py", line 286, in urlretrieve raise contenttooshorterror(
urllib.error.contenttooshorterror: <urlopen error retrieval incomplete: got only 38807364 out of 39731739 bytes> during handling of the above exception, another exception occurred: traceback (most recent call last): file "/home/yihuazhou/miniconda3/lib/python3.8/site-packages/hanlp/utils/component_util.py", line 48, in load_from_meta_file obj.load(save_dir, **load_kwargs) file "/home/yihuazhou/miniconda3/lib/python3.8/site-packages/hanlp/common/component.py", line 244, in load self.build(**merge_dict(self.config, training=false, logger=logger, **kwargs, overwrite=true, inplace=true)) file "/home/yihuazhou/miniconda3/lib/python3.8/site-packages/hanlp/common/component.py", line 254, in build self.model = self.build_model(**merge_dict(self.config, training=kwargs.get(\'training\', none), file "/home/yihuazhou/miniconda3/lib/python3.8/site-packages/hanlp/components/taggers/transformers/transformer_tagger.py", line 34, in build_model model, tokenizer = build_transformer(transformer, max_seq_length, len(self.transform.tag_vocab), tagging=true) file "/home/yihuazhou/miniconda3/lib/python3.8/site-packages/hanlp/layers/transformers/loader.py", line 39, in build_transformer bert_dir = get_resource(model_url) file "/home/yihuazhou/miniconda3/lib/python3.8/site-packages/hanlp/utils/io_util.py", line 340, in get_resource path = download(url=path, save_path=realpath) file "/home/yihuazhou/miniconda3/lib/python3.8/site-packages/hanlp/utils/io_util.py", line 214, in download installed_version, latest_version, latest_version_str = check_outdated()
valueerror: not enough values to unpack (expected 3, got 2)
=================================error log ends=================================
when reporting an issue, make sure to paste the full error log above.
a clear and concise description of what the bug is.
"hanlp-doc-zh/hanlp-doc-zh/tests/train/zh/train_msra_ner_albert.py"
demo
ead index
f2 `serializabledict` mplement `__getstate__` method, emantic analysis ickle
tests/train/zh/cws/train_msr_cws_bert.py
typeerror: `generator` yielded an element that did not match the expected structure
the expected structure was ((tf.int32, tf.int32, tf.int32), tf.int32), but the yielded element was ([\'"\', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \',\', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \',\', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \', \' \'], [\'s\', \'b\', \'e\', \'s\', \'s\', \'b\', \'e\', \'s\', \'s\', \'s\', \'b\', \'m\', \'e\', \'s\', \'s\', \'s\', \'s\', \'s\', \'s\', \'b\', \'e\', \'s\', \'s\', \'b\', \'m\', \'m\', \'e\', \'s\', \'b\', \'m\', \'e\', \'s\', \'s\', \'b\', \'e\', \'s\', \'b\', \'m\', \'m\', \'e\', \'s\', \'s\', \'s\', \'s\', \'b\', \'e\', \'s\', \'s\']).
`hanlp.pretrained.dep.ctb7_biaffine_dep_zh`
okenizer agger "token/tag" `hanlp_get_tokens` unction append ipline ag pu /10 oop op
disable pu `tracemalloc` `transform\\txt.py`
anlp\\common\\structure.py erializable , oad son, oad_json ,
( ave son ickle ,)
load son oad_pickle oad_json
( oad_pickle , ) ,
a clear and concise description of what the bug is
hartabel ao hartable.txt =
nableprobability(boolean enable) rue alse onfigprobabilityenabled if (configprobabilityenabled) mathutility.normalizeexp(predictionscores);
````java @override public iclassifier enableprobability(boolean enable) { return this; }
````java @override public iclassifier enableprobability(boolean enable) { configprobabilityenabled = enable; return this; }
hanlp 2.0.0a33 pipeline output_key son **sentences tokens art_of_speech_tags amed_entities yntactic_dependencies emantic_dependencies**
conllword json
pipeline syntactic_parser json dump .
2.0.0-alpha.25 ctb5_pos_rnn
i am trying to run ner with hanlp, but it is giving me an error
i am running the following comman in google colab with gpu recognizer = hanlp.load(hanlp.pretrained.ner.conll03_ner_bert_base_uncased_en)
**modulenotfounderror: no module named 'regex'**
was created with hanlp-2.0.0, but you are running 2.0.0-alpha.12
the init container does work well with containers beause of the use of busybox wget.
currently when setting the `max-age` cookie value, it's possible for a valid value to not be set as expected, as well as an invalid value from raising a hard error
in both cases the values are replaced by a `0` `max-age`.
running sanic behind a proxy and trying to generate an url using `request.url_for` throws a keyerror
this used to work but now sanic suddenly requires a server_name in order to do this
i get the following trace: ```
traceback (most recent call last): file "/usr/local/lib/python3.7/site-packages/sanic/app.py", line 942, in handle_request response = await response file "/app/tsauth/views/activate.py", line 41, in init_activate request=request) file "/usr/local/lib/python3.7/site-packages/mako/template.py", line 476, in render return runtime._render(self, self.callable_, args, data) file "/usr/local/lib/python3.7/site-packages/mako/runtime.py", line 883, in _render **_kwargs_for_callable(callable_, data) file "/usr/local/lib/python3.7/site-packages/mako/runtime.py", line 920, in _render_context _exec_template(inherit, lclcontext, args=args, kwargs=kwargs) file "/usr/local/lib/python3.7/site-packages/mako/runtime.py", line 947, in _exec_template callable_(context, *args, **kwargs) file "transaction_mako", line 60, in render_body file "/usr/local/lib/python3.7/site-packages/sanic/request.py", line 522, in url_for if "//" in self.app.config.server_name: file "/usr/local/lib/python3.7/site-packages/sanic/config.py", line 54, in __getattr__ raise attributeerror("config has no \'{}\'".format(ke.args[0]))
attributeerror: config has no 'server_name'
[2019-10-23 12:38:09 +0000] - (sanic.access)[info][<redacted>:33328]: get <redacted> 500 144
10/23/2019 12:38:09 pm error exception occurred while handling uri: '<redacted>'
traceback (most recent call last): file "/usr/local/lib/python3.7/site-packages/sanic/config.py", line 52, in __getattr__ return self[attr]
keyerror: 'server_name'
using pipenv to install sanic and uvicorn fails because sanic requires websockets >= 6.0, <7.0, and uvicorn requires websockets ==7.* you can install this with `pipenv install --skip-lock`, but locking the packages will produce an error
$> pipenv graph
sanic==19.6.2 - aiofiles [required: >=0.3.0, installed: 0.4.0] - httptools [required: >=0.0.10, installed: 0.0.13] - multidict [required: >=4.0,<5.0, installed: 4.5.2] - requests-async [required: ==0.5.0, installed: 0.5.0] - httpcore [required: ==0.3.*, installed: 0.3.0] - certifi [required: any, installed: 2019.6.16] - chardet [required: ==3.*, installed: 3.0.4] - h11 [required: ==0.8.*, installed: 0.8.1] - h2 [required: ==3.*, installed: 3.1.0] - hpack [required: >=2.3,<4, installed: 3.0.0] - hyperframe [required: >=5.2.0,<6, installed: 5.2.0] - idna [required: ==2.*, installed: 2.8] - rfc3986 [required: ==1.*, installed: 1.3.2] - requests [required: ==2.*, installed: 2.22.0] - certifi [required: >=2017.4.17, installed: 2019.6.16] - chardet [required: >=3.0.2,<3.1.0, installed: 3.0.4] - idna [required: >=2.5,<2.9, installed: 2.8] - urllib3 [required: >=1.21.1,<1.26,!=1.25.1,!=1.25.0, installed: 1.25.3] - ujson [required: >=1.35, installed: 1.35] - uvloop [required: >=0.5.3, installed: 0.12.2] - websockets [required: >=6.0,<7.0, installed: 6.0]
uvicorn==0.8.3 - click [required: ==7.*, installed: 7.0] - h11 [required: ==0.8.*, installed: 0.8.1] - httptools [required: ==0.0.13, installed: 0.0.13] - uvloop [required: ==0.12.*, installed: 0.12.2] - websockets [required: ==7.*, installed: 6.0]
in the debug mode, if you do not change your source code to trigger auto reload, the stop signals(sigterm, sigint) send to the main process will not work properly to stop the worker sub-process
as the following code, run it and stop(ctrl-c), the ``on_shutdown`` method will not be called
from sanic import sanic app = sanic(__name__) @app.listener('after_server_stop')
def on_shutdown(app, loop): print('i am done!') app.run(debug=true)
``` i think the problem maybe caused by the following code in ``reloader_helpers.py``: ```
def watchdog(sleep_interval): mtimes = {} worker_process = restart_with_reloader() signal.signal( signal.sigterm, lambda *args: kill_program_completly(worker_process) ) signal.signal( signal.sigint, lambda *args: kill_program_completly(worker_process) )
``` because of creating worker_process before register signal hander(``kill_program_completly``), the woker_process still use the default signal handler and do not kill sub-process woker
the following snippet is a immature solution, just for reference: ```
def kill_program_completly(proc): if not proc: kill_process_children(os.getpid()) os._exit(0) proc = proc.pop() kill_process_children(proc.pid) proc.terminate() os._exit(0) def watchdog(sleep_interval): mtimes = {} worker_process = [] signal.signal( signal.sigterm, lambda *args: kill_program_completly(worker_process) ) signal.signal( signal.sigint, lambda *args: kill_program_completly(worker_process) ) worker_process.append(restart_with_reloader()) while true: for filename in _iter_module_files(): try: mtime = os.stat(filename).st_mtime except oserror: continue old_time = mtimes.get(filename) if old_time is none: mtimes[filename] = mtime continue elif mtime > old_time: wp = worker_process.pop() kill_process_children(wp.pid) wp.terminate() worker_process.append(restart_with_reloader()) mtimes[filename] = mtime break sleep(sleep_interval) ```
say we have a route with the trailing slash and `strict_slashes=true`:
`@app.route('/endpoint/', strict_slashes=true)`
this way, `url_for()` will always trim the trailing slash, returning a non-working url.
logger did not work at current master commit (
when using a blueprint with multiple workers on windows, sanic fails on startup due to a failure to pickle the route: > exception has occurred: _pickle.picklingerror
can't pickle <class 'sanic.blueprints.route'>: attribute lookup route on sanic.blueprints failed
when in debug mode, the auto reload functionality seems to break debuggers such as pycharm.
the default port for a sanic app is 8000, which by http standards is a custom port
this port can also be set during calls to `app.run()`
when using `app.url_for('handler.name', _external=true)`, the resultant url does **not** contain the port without manual intervention
this line is the final step before the application returns the url
the url is build using `urlunparse` which takes a `tuple` of values as would be producted by [urlparse]( #urllib.parse.urlparse)
the snippet below shows that only the first 6 arguments are provided, which does not include the port (unless included as part of `netloc`).
#l695 in order to get port, the value of `app.confg.server_name` **must** be set to the hostname and port
app.config.server_name = '{}:{}'.format(host, port)
app.run(host=host, port=port)
thus, the default behavior for creating the url is incorrect as it requires manual attribute setting for every single application.
when using geo based and marker based ar in the same scene only either one of them work
problem seems to be the camera entity or i am missing something
when `<a-entity camera/>` is used as advised on arjs docs for multiple marker support, geo based elements are not displayed
`<a-entity camera gps-camera rotation-reader/>` does not work either
when `<a-camera gps-camera rotation-reader/>` is used as advised on geoarjs docs, then barcode or pattern marker is **found** but the overlaying a-element **can't be seen** (i was able to see it at some weird lucky angles, maybe the problem is due to camera being moved?)
acts as same when `<a-camera camera gps-camera rotation-reader/>` is used or when 2 different camera elements used as `<a-camera camera gps-camera rotation-reader/><a-entity camera/>`
when viewing a web page using ar.js on ios safari, if you press the home button, wait 1-2 seconds and open safari back
it seems to trigger a weird resize event and video feed get's thinner while black borders appear on the sides
it doesn't effect the animations or anything just aesthetically looking very bad
the problem does not exist on android, and the thickness of borders seems to differ from iphone to iphone based on resolution
confirmed the problem in iphone x (in which borders seem to be very thin, and iphone xr has no borders) and iphone 8 (almost 10% of the screen is covered.) tried it with basic samples, and was able to reproduce the problem both on three.js and aframe examples.
aframe demo, the cube have incorrect scaling or size
i need to resize the browser windows to fix it(i.e
if you go to inspector view(i.e
video 2), you will see the cube have correct size and scaling
i guess this issue is related to canvas or canvas size.
im not quite sure if this is intended behaviour or a bug, but a lot of resize events are getting fired once ar.js has loaded (ca
20 per second)
i cannot ungroup a certain group.
on [draw.io]( it is not possible anymore to export diagrams as pdf
when selecting the pdf export via _file_ --> _export as_ --> _pdf..._ the usual configuration popup shows up
regardless of the entered settings there , when clicking on the "export" button, a new browser page opens showing only the message "error!".
this error seems to occur always and indepently of the drawn diagram
even a blank diagram or a diagram with just a simple box and text result in this error.
this feature has proven to be extremly useful when writing latex papers, so i would be very happy if this could be fixed somehow.
to reproduce: 1
create new diagram
create a rectangle and remove fill
create a text 4
place text under rectangle
select text with alt+click ===
now the element cannot be moved with mouse (although reacts on arrow keys)
text cannot be edited
~ side panel shows the element, but clicking 'to frong' on arrange tab has no effect, the text remains under rectangle (on more complex diagrams, seems to work on simple one as this test )
when exporting .pdf, any page exports totally blank.
exporting diagram to .vsdx causes orientation of edge labels to switch direction.
entering the mermaid syntax for a state diagram, for example as shown below, does nothing.
statediagram s1 --> s2
when i authorize the github, the window doesn\'t closes automatically and comes back to draw.io "_this window will be closed automatically_." stays always
also, it looks like authorization is incomplete
when i close this window manually and come back, the authorize window persists
when i close the authorize dialog, it displays _access denied_.
the tangential handles are not working.
exporting the example diagram in this issue to pdf results in the edge label on page 2 not being visible on the resulting pdf.
if i use the url parameters gitlab=, gitlab-id= and mode=gitlab the redirect-uri is build the wrong way
i discovered this whith my personal gitlab installation, but the bug can be reproduced with gitlab.com
when exporting a diagram to vsdx, only the active layer is exported.
cookies.get() return undefined in reactjs
// src/converter.mjs
export default { read: function (value) { return value.replace(/%3b/g, ';') }, write: function (value) { return string(value).replace(/;/g, '%3b') }
```js src/api.mjs function get (key) { if (typeof document === 'undefined' || (arguments.length && !key)) { return } // to prevent the for loop in the first place assign an empty array // in case there are no cookies at all
var cookies = document.cookie ? document.cookie.split('; ') : [] var jar = {} for (var i = 0; i < cookies.length; i++) { var parts = cookies[i].split('=') var value = parts.slice(1).join('=') var foundkey = defaultconverter.read(parts[0]).replace(/%3d/g, '=') jar[foundkey] = converter.read(value, foundkey) // why does this read function have only one argument, and here two are passed in? if (key === foundkey) { break } } return key ? jar[key] : jar }
this was working earlier and suddenly didn't, and perhaps i did something to change it but..
i wouldn't begin to know what
this is a react project, created through `razzle`
the only js-cookie related code is in an imported component at the top of every page
here's the code: ```js
import react from "react";
import { usedispatch } from 'react-redux';
import { unwrapresult } from '@reduxjs/toolkit';
import cookies from 'js-cookie';
import { checktoken } from \'../store/user\'; import { usehistory } from "react-router-dom"; const checkauth = () => { const dispatch = usedispatch(); const history = usehistory(); const token = cookies.get(\'token\'); console.log(cookies.get()); console.log("token", token); if(token) { dispatch(checktoken(token)) .then(unwrapresult) .then(res => { console.log(res); }) .catch((err) => { console.log(err); history.push(\'/\'); }) } return (<></>);
} export default checkauth;
``` the output i get from this:
{}__proto__: object
token undefined
cookies either aren't being saved or aren't being retrieved by `get`.
setting an expire date in safari doesn't seem to work while it works under chrome
when putting 365 days, the expire date shown in the console in safari is always +7 days while in chrome it shows the right date
e.g: cookies.set('name', 'value', { expires: 365 }) i am using safari on macos catalina - safari version 13.1.1 (15609.2.9.1.2) i am testing this on a wordpress website using mamp in localhost:8888
a clear and concise description of what the bug is.
after creating a cookie and reloading the page, the cookie deletes (disappears)
but, when i reload for the second time, it shows up again!
it's not an appropriate behavior due i need the cookie to handle some stuff on my application.
the creation and getting the cookie is just the same as doc.
a clear and concise description of what the bug is.
a clear and concise description of what the bug is
encodeuri(\' \') // "%e6%b5%8b%e8%af%95%e4%ba%86"
but in encode function we use decodeuricomponent to decode, its not perfect .why not add the compatibility scheme, like this.
s.replace(/(%[0-9a-za-z]%{2})+/g, decodeuricomponent); or
s.replace(/(%[0-9a-z]%{2})+/g, decodeuricomponent) || s.replace(/(%[0-9a-z]%{2})+/g, decodeuri); ```
i am getting `urierror: malformed uri sequence` error thrown when using this package
it seems as though it's happening when any set cookie is invalid, even cookies that i'm not interacting with at all (e.g
a 3rd party cookie)
i'm using the latest version of this package (2.2.1)
i have an issue where im getting a warning message on my browser (see attached image below)
i'm using js-cookies on the frontend and not using expressjs to set my cookies
i'm wondering how can you set `samesite` attribute in js-cookies? maybe this will fix my warning
i'm not using the cookie for validation its just a storage for my jwt because i'm using `bearer token` schema for the validation though and i'm not sure if im just going to ignore this warning message.
setting the cookie expiry for more than 7 days does not work in the brave browser
set both ```expires: 10``` and ```samesite: 'strict' ``` at the same time seems lost ```strict``` in safari.
it is not a problem of this library per se since manually setting the cookie in safari would also destroy ```strict```.
a clear and concise description of what the bug is.
i am not sure if this is a bug
it may just be a mistake
but you call `write` function with two parameters
this function is return only first converted value
if this is not mistake - can someone explain to me why this is done? #l19 p.s
many thanks for lib :smile_cat:
cookie name with slash `/` character is escaped to `%2f`
`user/123=foo` becomes `user%2f123=foo` i believe the forward slash character is allowed in the cookie key
it's unclear why you're passing `key` here as the converter expects a single parameter:
`value = converter.write(value, key)` and on the next line:
#l21 perhaps it would be better to have:
`key = converter.write(key)`
js-cookie can't se the cookie expire date to more than 7 days using the following format
cookie.set('key','value',{expires:10})
`cookies.set(key, value)` works
`cookies.set(key, value, attributesobj)` doesn't work (no cookie is set, and no error is logged/thrown)
the problem also happens when setting default values via `cookies.defaults = {attributesobj}`
`cookies(key,value,option)` does not work .
but , `cookies.set(key,value,option)` it's worked in `2.2.0` i use `cookies(key,value,option)` it's work
i want to know which version of the update .
it is not possible to set this cookie `document.cookie = "foo=bar; samesite=lax"` even though secure attribute is added `document.cookie = "foo=bar; samesite=lax; secure"` which is required since future chrome v80
now in chrome v78 it is not working - cookie is rejected at all
firefox sets cookie ok
in chrome is possible to set via javascript only samesite=none
i think it is not possible to fix but it should be mention in doc that is not reliable in all browsers including top used chrome.
if you provide *localhost* as the domain in cookies.set, it will fail for internet explorer 11.
documentation about json, which is here is missing in readme at github.
update callback of children of a timeline, should only be fired when the children is running, but it will keep called untile the timeline was finished.
when using steps easing, the first step always takes less time to finish, compare to every other steps.
all date and datetime fields are not being displayed
underlying database is aws athena
data is retrieved from database correctly, evident by casting the date field to string using date_format()
however, any field with data type = date / datetime is not displayed / render on screen.
using .animate on a nativeview with iterations, doesn't repeat the event as stated in the documentation
neither does `number.positive_infinity`
![screenshot 2020-09-12 at 21 21 45](
we get the following exception in our app after the state in a controller changes a `docklayout` if hidden by an `ngif` and a `stacklayout` is shown as the `ngif`becomes true
that mechanism has been working for weeks now, i'm confused it occurs now.
it happens with android only
system.err: an uncaught exception occurred on "main" thread.
system.err: calling js method onselectedpositionchange failed
system.err: typeerror: right-hand side of 'instanceof' is not an object
system.err: system.err: stacktrace:
system.err: (file: node_modules/@nativescript/core/ui/layouts/flexbox-layout/flexbox-layout.android.js:14:0)
system.err: at applyallnativesetters(file: node_modules/@nativescript/core/ui/core/properties/properties.js:1065:0)
system.err: at initnativeview(file: node_modules/@nativescript/core/ui/core/properties/properties.js:992:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.onresumenativeupdates(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:647:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase._resumenativeupdates(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:278:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.onloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:232:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view/view.js.view.onloaded(file: node_modules/@nativescript/core/ui/core/view/view.android.js:249:0)
system.err: at (file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:75)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:310:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.callloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.loadview(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:456:0)
system.err: at (file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:234:0)
system.err: at push.../node_modules/@nativescript/core/ui/layouts/layout-base-common.js.layoutbasecommon.eachchildview(file: node_modules/@nativescript/core/ui/layouts/layout-base-common.js:125:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view/view-common.js.viewcommon.eachchild(file: node_modules/@nativescript/core/ui/core/view/view-common.js:925:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.onloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:233:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view/view.js.view.onloaded(file: node_modules/@nativescript/core/ui/core/view/view.android.js:249:0)
system.err: at (file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:75)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:310:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.callloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.loadview(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:456:0)
system.err: at (file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:234:0)
system.err: at push.../node_modules/@nativescript/core/ui/layouts/layout-base-common.js.layoutbasecommon.eachchildview(file: node_modules/@nativescript/core/ui/layouts/layout-base-common.js:125:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view/view-common.js.viewcommon.eachchild(file: node_modules/@nativescript/core/ui/core/view/view-common.js:925:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.onloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:233:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view/view.js.view.onloaded(file: node_modules/@nativescript/core/ui/core/view/view.android.js:249:0)
system.err: at (file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:75)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:310:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.callloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.loadview(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:456:0)
system.err: at (file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:234:0)
system.err: at push.../node_modules/@nativescript/core/ui/layouts/layout-base-common.js.layoutbasecommon.eachchildview(file: node_modules/@nativescript/core/ui/layouts/layout-base-common.js:125:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view/view-common.js.viewcommon.eachchild(file: node_modules/@nativescript/core/ui/core/view/view-common.js:925:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.onloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:233:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view/view.js.view.onloaded(file: node_modules/@nativescript/core/ui/core/view/view.android.js:249:0)
system.err: at (file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:75)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:310:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.callloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.loadview(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:456:0)
system.err: at (file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:234:0)
system.err: at push.../node_modules/@nativescript/core/ui/layouts/layout-base-common.js.layoutbasecommon.eachchildview(file: node_modules/@nativescript/core/ui/layouts/layout-base-common.js:125:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view/view-common.js.viewcommon.eachchild(file: node_modules/@nativescript/core/ui/core/view/view-common.js:925:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.onloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:233:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view/view.js.view.onloaded(file: node_modules/@nativescript/core/ui/core/view/view.android.js:249:0)
system.err: at (file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:75)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:310:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.callloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.loadview(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:456:0)
system.err: at (file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:234:0)
system.err: at push.../node_modules/@nativescript/core/ui/content-view/content-view.js.contentview.eachchildview(file: node_modules/@nativescript/core/ui/content-view/content-view.js:70:0)
system.err: at push.../node_modules/@nativescript/core/ui/page/page-common.js.pagebase.eachchildview(file: node_modules/@nativescript/core/ui/page/page-common.js:126:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view/view-common.js.viewcommon.eachchild(file: node_modules/@nativescript/core/ui/core/view/view-common.js:925:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.onloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:233:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view/view.js.view.onloaded(file: node_modules/@nativescript/core/ui/core/view/view.android.js:249:0)
system.err: at push.../node_modules/@nativescript/core/ui/page/page.js.page.onloaded(file: node_modules/@nativescript/core/ui/page/page.android.js:43:0)
system.err: at (file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:75)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:310:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.callloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.loadview(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:456:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase._addviewcore(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:451:0)
system.err: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase._addview(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:437:0)
system.err: at push.../node_modules/@nativescript/core/ui/frame/frame.js.fragmentcallbacksimplementation.oncreateview(file: node_modules/@nativescript/core/ui/frame/frame.android.js:700:0)
system.err: at push.../node_modules/@nativescript/core/ui/frame/fragment.js.fragmentclass.oncreateview(file: node_modules/@nativescript/core/ui/frame/fragment.android.js:29:0)
system.err: at push.../node_modules/@nativescript/core/ui/bottom-navigation/bottom-navigation.js.bottomnavigation.commitcurrenttransaction(file: node_modules/@nativescript/core/ui/bottom-navigation/bottom-navigation.android.js:360:0)
system.err: at push.../node_modules/@nativescript/core/ui/bottom-navigation/bottom-navigation.js.bottomnavigation.changetab(file: node_modules/@nativescript/core/ui/bottom-navigation/bottom-navigation.android.js:374:0)
system.err: at bottomnavigationbarimplementation.onselectedpositionchange(file: node_modules/@nativescript/core/ui/bottom-navigation/bottom-navigation.android.js:118:0)
system.err: at com.tns.runtime.calljsmethodnative(native method)
system.err: at com.tns.runtime.dispatchcalljsmethodnative(runtime.java:1286)
system.err: at com.tns.runtime.calljsmethodimpl(runtime.java:1173)
system.err: at com.tns.runtime.calljsmethod(runtime.java:1160)
system.err: at com.tns.runtime.calljsmethod(runtime.java:1138)
system.err: at com.tns.runtime.calljsmethod(runtime.java:1134)
system.err: at com.tns.gen.org.nativescript.widgets.bottomnavigationbar_vendor_105222_32_bottomnavigationbarimplementation.onselectedpositionchange(bottomnavigationbar_vendor_105222_32_bottomnavigationbarimplementation.java:39)
system.err: at org.nativescript.widgets.bottomnavigationbar.setselectedposition(bottomnavigationbar.java:289)
system.err: at org.nativescript.widgets.bottomnavigationbar$tabclicklistener.onclick(bottomnavigationbar.java:302)
system.err: at android.view.view.performclick(view.java:7259)
system.err: at android.view.view.performclickinternal(view.java:7236)
system.err: at android.view.view.access$3600(view.java:801)
system.err: at android.view.view$performclick.run(view.java:27892)
system.err: at android.os.handler.handlecallback(handler.java:883)
system.err: at android.os.handler.dispatchmessage(handler.java:100)
system.err: at android.os.looper.loop(looper.java:214)
system.err: at android.app.activitythread.main(activitythread.java:7356)
system.err: at java.lang.reflect.method.invoke(native method)
system.err: at com.android.internal.os.runtimeinit$methodandargscaller.run(runtimeinit.java:492)
system.err: at com.android.internal.os.zygoteinit.main(zygoteinit.java:930)
js: error: *** nativescripterror *** : error: calling js method onselectedpositionchange failed
js: typeerror: right-hand side of 'instanceof' is not an object
js: error: *** stacktrace *** : (file: node_modules/@nativescript/core/ui/layouts/flexbox-layout/flexbox-layout.android.js:14:0)
js: at applyallnativesetters(file: node_modules/@nativescript/core/ui/core/properties/properties.js:1065:0)
js: at initnativeview(file: node_modules/@nativescript/core/ui/core/properties/properties.js:992:0)
js: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.onresumenativeupdates(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:647:0)
js: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase._resumenativeupdates(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:278:0)
js: at push.../node_modules/@nativescript/core/ui/core/view-base/view-base.js.viewbase.onloaded(file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:232:0)
js: at push.../node_modules/@nativescript/core/ui/core/view/view.js.view.onloaded(file: node_modules/@nativescript/core/ui/core/view/view.android.js:249:0)
js: at (file: node_modules/@nativescript/core/ui/core/view-base/view-base.js:317:75)
js: at push.../node_modules/@nativesc...
js: error: *** nativescripterror *** : com.tns.nativescriptexception: calling js method onselectedpositionchange failed
js: typeerror: right-hand side of 'instanceof' is not an object
interesting thing is that the view where this occurs does not use the flexlayout *at all*.
if you enter (focus) a text field, the ios variant will reload the text defined in the property
this is different behavior to the android version where this does not happen
basically i am using both `text` and `formattedtext` property of the text view
by pressing a button i am using the user input from `text` and adding some formatting to it
this works fine on android
on ios since both properties are set, every time the text view is focused, the text from `formattedtext` is reloaded thus clearing the user input if the button was not pressed
i don't see the point why this is implemented like this on ios and i think it can be removed to match the behavior of android
see #l33
`connectivitymanager.getactivenetworkinfo()` ( #getactivenetworkinfo()) and `networkinfo` ( were deprecated in api level 29, and we use it in:
if you put `ispassthroughparentenabled="true"` on a `flexboxlayout`, the app will crash with the following exception: <details> ```
calling js method oncreateview failed
typeerror: this.nativeviewprotected.setpassthroughparent is not a function stacktrace:
layoutbase.<computed>(
at applyallnativesetters(
at initnativeview(
at viewbase.onresumenativeupdates(
at viewbase._resumenativeupdates(
at viewbase.onloaded(
at view.onloaded(
at (
at viewbase.callfunctionwithsuper(
at viewbase.callloaded(
at viewbase.loadview(
at (
at layoutbasecommon.eachchildview(
at viewcommon.eachchild(
at viewbase.onloaded(
at view.onloaded(
at (
at viewbase.callfunctionwithsuper(
at viewbase.callloaded(
at viewbase.loadview(
at (
at contentview.eachchildview(
at pagebase.eachchildview(
at viewcommon.eachchild(
at viewbase.onloaded(
at view.onloaded(
at page.onloaded(
at (
at viewbase.callfunctionwithsuper(
at viewbase.callloaded(
at viewbase.loadview(
at viewbase._addviewcore(
at viewbase._addview(
at fragmentcallbacksimplementation.oncreateview(
at fragmentclass.oncreateview(
at com.tns.runtime.calljsmethodnative(native method)
at com.tns.runtime.dispatchcalljsmethodnative(runtime.java:1286)
at com.tns.runtime.calljsmethodimpl(runtime.java:1173)
at com.tns.runtime.calljsmethod(runtime.java:1160)
at com.tns.runtime.calljsmethod(runtime.java:1138)
at com.tns.runtime.calljsmethod(runtime.java:1134)
at com.tns.fragmentclass.oncreateview(fragmentclass.java:54)
at androidx.fragment.app.fragment.performcreateview(fragment.java:2439)
at androidx.fragment.app.fragmentmanagerimpl.movetostate(fragmentmanager.java:1460)
at androidx.fragment.app.fragmentmanagerimpl.movefragmenttoexpectedstate(fragmentmanager.java:1784)
at androidx.fragment.app.fragmentmanagerimpl.movetostate(fragmentmanager.java:1852)
at androidx.fragment.app.backstackrecord.executeops(backstackrecord.java:802)
at androidx.fragment.app.fragmentmanagerimpl.executeops(fragmentmanager.java:2625)
at androidx.fragment.app.fragmentmanagerimpl.executeopstogether(fragmentmanager.java:2411)
at androidx.fragment.app.fragmentmanagerimpl.removeredundantoperationsandexecute(fragmentmanager.java:2366)
at androidx.fragment.app.fragmentmanagerimpl.execpendingactions(fragmentmanager.java:2273)
at androidx.fragment.app.fragmentmanagerimpl$1.run(fragmentmanager.java:733)
at android.os.handler.handlecallback(handler.java:789)
at android.os.handler.dispatchmessage(handler.java:98)
at android.os.looper.loop(looper.java:164)
at android.app.activitythread.main(activitythread.java:6944)
at java.lang.reflect.method.invoke(native method)
at com.android.internal.os.zygote$methodandargscaller.run(zygote.java:327)
at com.android.internal.os.zygoteinit.main(zygoteinit.java:1374)
</details> additionally, it appears that button taps propagate to parent containers
if you run the playground ( from the documentation (added here), at least on android, a single tap of the button will trigger the onwraplayouttapped function
if i'm reading [this]( correctly, this does not appear to be the intended behavior (`so if you tap on our button, you will notice that no event will be propagated to its parents`)
note that there's an issue [here]( but it was auto closed and not responded to
i was hoping to find out if this is a bug or if it is now intended behavior (i posted there as well as the slack channel but did not get a response).
a picture is worth a thousand words: so we start the app with one background color
clicking the button swaps between the two other colors
so pink initial, green and purple swapping
![peek 2020-04-22 00-22]( the issue is that when you navigate away from a `tabview`, `tabs`, `frame` or `bottomnavigation` and then return, css is no longer changing the backgroundcolor
this exact same code pattern is in all four of them; i'll explain the issue using bottomnavigation code..
it is a bit weird; but stepping through the code you can see why this is happen and understand what is occurring: the code here (bottom-navigation): #l100-l107 saves the backgroundcolor during the ondestroy
so that this code here:
#l383-l388 can reset the original color
however, this creates the side effect of messing up the ability for css to change the `backgroundcolor` after this point
the reason why is in properties.ts on line 889:
const csspropertydescriptor = descriptor(cssvalue, 2, false, false, false); // notice the "2"
const stylepropertydescriptor = descriptor(stylevalue, 3, true, true, true); // notice the "3"
a `cssvalue` = 2 & a `stylevalue` = 3 so when you set a value via css you run the routine with a propertysource of 2
when you set the value via direct setter (i.e
style) you get the propertysource of 3
that code does checks/assignment is here:
#l844-l847 because the control is being recreated; it runs the: `this.backgroundcolor = this._originalbackground;`
which is setting the color back correctly, but also sets the `computedsource` to 3.
so, now, when it goes to apply the css; the css is always propertysource = 2
so, any changes in the `css:background-color` will now fail to apply since the `_originalbackground` promoted the `computedsource` to 3.
i built an android app bundle (.aab) and installed it on my phone
that was when i noticed that half of my pages were blank for no reason
the reason for this was that in some pages i had a "$parents[\'bottomnavigation\']" reference in order to use certain properties from my root binding context, so i checked command parameters and problem was gone when i removed \'--env.uglify\'.
'visibility' attribute binding does not work if trying to perform a binding expression using an observable parent or child.
- open a modalview on ios with `fullscreen: false` option
- from that modal, use `utils.openfile` to open any local file
- file is opened in the main ui (in the background as a non-fullscreen is opened) instead of the foreground ..
- so the openfile content is not visible and can only be seen after dismissing the modalview ..
in textfield, editable is set to false
i am trying to toggle between secure and not secure
but unfortunately, text is hidden and not visible even if secure is set to false.
launching a dialog from `@nativescript/core/ui/dialogs` pulls the colour from `button`, but constructs one globally without attaching it to any context, so any extra styles are not applied appropriately
this includes component-local .css definitions for `button`, but more importantly (for my use case), the `app.css` `.ns-dark button` definition doesn't get used when the user is in dark mode
keep in mind that the `button` that is used for style extraction is only ever constructed once, too, which would disable the ability to switch back and forth between dark and light even if the style were properly composed at instantiation.
when changing a css class of **tabstrip** programmatically the changes are not applied or only partially applied
the issue is present for both android and ios but has different behavior.
radsidedrawer creates a white stripe glitch on the right side when hiding in dark mode on ios
on android: some icons align the whole label to the right like `float: right`;
on both platforms: some icons are not visible
if using animations for translate or rotate anywhere, it's possible that your ios views will become pixellated at some point in time and remain that way
this is due to these all these changes in the base `view.ios.ts`:
#diff-c254ad08e8de54e61bc7d63b02b743ff a view that should look like this:
![img_e1c8fa8c3db9-1]( will eventually end up looking like this and never recover (sometimes even an app reboot will not restore - basically the changes mentioned introduce a bug in way ios transforms are applied):
<img width="416" alt="screen shot 2020-02-19 at 12 17 15 pm" src=" "> reverting that changeset mentioned in `view.ios.ts` make everything work perfect again and never degrade.
according to according to the htmlview should support new properties like color, link-color and font-size.
we want to try out the new features added to the htmlview, so we try to style it in css like this: ```
.html-view { font-size: 16; color: #808080; link-color: #ff44ff;
``` while it works correctly on android, it only works partially on ios 12 (correct font-size and correct darkgrey text-color but it shows just the default blue link-color) and it does not work at all on ios 13, as all the text is just black (only the font-size is set correctly)
see the result in the screenshot below: <img width="1485" alt="bildschirmfoto 2020-02-22 um 15 30 36" src=" "> when trying to set those properties in xml like this:
<htmlview html="{{ myhtml }}" color="#808080" linkcolor="#ff44ff" fontsize="16"/> on android and ios 12, the color is set correctly to the darkgrey tone, but the font-size and the link-color are not set correctly
on ios 13 none of the properties are set correctly
the text and the link is black and it has the default font-size
<img width="1491" alt="bildschirmfoto 2020-02-22 um 15 25 33" src=" ">
we're using sentry to track errors in our app and a recent update to their packages adds an event listener for `readystatechange`.
nativescript implementation of `xmlhttprequest` throw an error "event not supported: readystatechange" on every request we make.
#l179-l187 even though the event is emitted by `xmlhttprequest`:
#l158
#l172
when using tabs to navigate to a page that has a listview by tapping on the tab (as opposed to using a gesture, or swipe), navigation occurs but you cannot subsequently navigate to other tabs by tapping.
css (`color` and `background-color`) are not applied for **tabstripitem** elements of **tabs**
reproducible on ios only
works as expected on android.
works as expected with **bottomnavigation**
app crashes when using `tabs` with `swipeenabled="false"`
when accessing tabstripitem we can't change the title value on ios (works as expected on android)
```javascript tabs.tabstrip.items[0].title = "item 1"; tabs.tabstrip.items[1].title = "item 22"; tabs.tabstrip.items[2].title = "item 333";
previously if a mail-to link had `%0a` in it, it would have added a new line in the body of the email,
but that is no longer working
when setting a `selectedindex` on the `tabs` tag as per [ it is only respected by the `tabcontentitem` and not the `tabstrip` and `tabstripitem` - these default to the first item
also, when returning to the page containing the `tabs` using goback, the `tabcontentitem` is correct, but again the `tabstripitem` is not set - this would appear to be related.
when having an action dialog with both title and message set, the message is not displayed.
**bug:** a **color** set (via css) on a **label** inside a **tabstripitem** is not applied.
it will be applied for **:active** state.
it will be applied if the **tabstrip** has a **backgroundcolor** set explicitly
- uses[ this demo app]( (template with tab navigation)
- deploy on an ios device and observe [these styles]( #l3-l20) notice that the red color is not applied for the tabstripitem label (but at the same time, the green color is applied for the **:active** state).
when the hint of keyboard is english, everything works fine
but if i put some persian words, then i get two issues
first, the pointer within the `textfield` gets lost
second, the view doesn't scroll and stays behind the keyboard
i attach a video for a demonstration.
in ios 13, a button's text gets truncated in the middle when using a formattedstring with fontawesome
this also happens if the text is short and if there is enough space to show the whole text.
for us, it is only reproducable on ios 13 simulator (we have no ios 13 physical device, but we cannot reproduce it on our iphone 6 with ios 12 and the ios 12 simulator)
![bildschirmfoto 2020-01-23 um 15 32 34]( in addition, yo can see on ios 13 simulator, that the bottom part of the button's text is cutt off a bit
there is no padding or anything else that could cause this issue.
![bildschirmfoto 2020-01-23 um 15 42 14]( compared to the correct look on ios 12:
![bildschirmfoto 2020-01-23 um 15 44 27](
list picker shows "?" values for some time after going back from the background (ios)
navigation to another page from a `bottomnavigation` and back again breaks the content of the current tab.
listview can no longer be scrolled, items cannot be tapped etc.
textfield with keyboardtype="integer" crashes the application.
in the app i am building i require a textfield to be positioned quite low in a stacklayout
the result is that on my android device the soft keyboard tries to open but closes before fully doing so
see [this]( video.
when there's a css class for active tabstripitem and there's no default css class for the tabstripitem after selecting the tab the class is applied and when the tab is changed it does not return to the previos state
this happens only on android, but not on ios.
using textfield or textview, i\'d like the keyboard to have a word suggestion above the keys, but all autocorrect="true" does is put a red line under misspelt words
i see in the code there is an autocomplete property, but the fields seem unresponsive to this too
the text input form in raddataform does provide word suggestions.
using custom tan strip with scrollable content is causing the last portion of the content to be hidden behind the tab strip
possible related to
using an image tag, with a full url to an external site, with `usecache` causes an app crash
there is no error generated without looking into the adb logcat
either true or false causes the error
the color of font icon in action bar is not changing after initial rendering of a page.
while setting a margin in percentage (%), the label on the screen disappears when the device is rotated from portrait to landscape & vice versa **(android only)**.
if you apply a border to a flexboxlayout it will cover the content within it
when using the dark theme introduced in android 10, background and border colors are different than what they are supposed to be.
as you can see, i can navigate from page 2 to page 1, but when navigating from page 1 to the homepage, an exception is raised.
this does not happen in version 2.5.2 of this plugin
i think there was something wrong with the bottomnavigation element of nativescript
changes in elements tab doesn't apply after livesync
the bug is a runtime error on android os.
it only occurs if the navigation is performed within a frame of a tabviewitem using the animation-type "slide".
if the animation is disabled or performed outside of a tabview the error does not ossur.
after a navigation to the page containing the listview (with slide animation) the app must be put to background and activated again.
a tap on the first list entry "destroys" the layout (using listviews itemtemplates).
a second tap crashes the app: ```
system.err: an uncaught exception occurred on "main" thread.
system.err: calling js method onitemclick failed
system.err: typeerror: cannot read property 'get' of undefined
system.err:
system.err: stacktrace:
system.err: itemclicklistenerimpl.onitemclick(
system.err: at com.tns.runtime.calljsmethodnative(native method)
system.err: at com.tns.runtime.dispatchcalljsmethodnative(runtime.java:1209)
system.err: at com.tns.runtime.calljsmethodimpl(runtime.java:1096)
system.err: at com.tns.runtime.calljsmethod(runtime.java:1083)
system.err: at com.tns.runtime.calljsmethod(runtime.java:1063)
system.err: at com.tns.runtime.calljsmethod(runtime.java:1055)
system.err: at com.tns.gen.java.lang.object_vendor_31981_32_itemclicklistenerimpl.onitemclick(object_vendor_31981_32_itemclicklistenerimpl.java:26)
system.err: at android.widget.adapterview.performitemclick(adapterview.java:318)
system.err: at android.widget.abslistview.performitemclick(abslistview.java:1159)
system.err: at android.widget.abslistview$performclick.run(abslistview.java:3136)
system.err: at android.widget.abslistview$3.run(abslistview.java:4052)
system.err: at android.os.handler.handlecallback(handler.java:873)
system.err: at android.os.handler.dispatchmessage(handler.java:99)
system.err: at android.os.looper.loop(looper.java:193)
system.err: at android.app.activitythread.main(activitythread.java:6669)
system.err: at java.lang.reflect.method.invoke(native method)
system.err: at com.android.internal.os.runtimeinit$methodandargscaller.run(runtimeinit.java:493)
system.err: at com.android.internal.os.zygoteinit.main(zygoteinit.java:858)
using tab navigation inside a sidedrawer navigation with nested page-router-outlets breaks the ability to interact (e.g
tap the nav button to open sidedrawer again) with the actionbar inside the tabview after using routerextensions back()
this applies only to android
ios works fine
using core modules version 6.1.2 works fine for both platforms
it seems not to be directly associated to the sidedrawer since you cannot tap any button in the actionbar after routing back.
ios only, android worked fine app crashes with the following error on a rotate: > js error typeerror: undefined is not an object (evaluating 'this.columns[measurespec.getcolumnindex()].children') adding some logging before that line indicates that during the rotation; the
`measurespec.getcolumnindex()` = `nan` which is why this fails.
the following page navigation is not working
it works once...you can see i'm toggling the flip - but second and subsequently - not working
if i comment out the transition - then the navigation takes place
``` let page_def = { modulename: "test-page", animated: true, clearhistory: true, transition: { name: bswitch2list ? "flipright" : "flipleft", duration: 350, curve: "easeout" } }; framemodule.frame.topmost().navigate( page_def );
i just recently upgraded to 6.2.0
i was able to make the android build work but ios build in sidekick is producing some fatal errors that makes the app crash on load
package.json:
````{ "nativescript": { "id": "xxxxxxxxxx", "tns-ios": { "version": "6.2.0" }, "tns-android": { "version": "6.2.0" } }, "description": "nativescript application", "license": "see license in <your-license-filename>", "repository": "<fill-your-repository-here>", "scripts": { "lint": "tslint \\"src/**/*.ts\\"" }, "dependencies": { "@angular/animations": "8.0.0", "@angular/common": "8.0.0", "@angular/compiler": "8.0.0", "@angular/core": "8.0.0", "@angular/forms": "8.0.0", "@angular/http": "8.0.0-beta.10", "@angular/platform-browser": "8.0.0", "@angular/platform-browser-dynamic": "8.0.0", "@angular/router": "8.0.0", "@nstudio/nativescript-loading-indicator": "^1.0.0", "nativescript-angular": "8.0.2", "nativescript-checkbox": "^3.0.3", "nativescript-datetimepicker": "^1.2.0", "nativescript-masked-text-field": "^4.0.1", "nativescript-platform-css-free": "^1.6.16", "nativescript-theme-core": "~1.0.4", "reflect-metadata": "~0.1.10", "rxjs": "~6.3.0", "tns-core-modules": "~6.2.0", "zone.js": "0.9.1" }, "devdependencies": { "@angular/compiler-cli": "8.0.0", "@nativescript/schematics": "^0.5.2", "@ngtools/webpack": "8.0.0", "codelyzer": "~4.5.0", "nativescript-dev-webpack": "~1.3.0", "tns-platform-declarations": "6.0.1", "tslint": "~5.11.0", "typescript": "3.4.5", "node-sass": "4.12.0" }, "readme": "nativescript application"
````initializing connection
removing all cached process handles
sending handshake request attempt #1 to server
creating connection to com.apple.runningboard
handshake succeeded
identity resolved as application<xxxxxx>
fbsworkspace connecting to endpoint : <private>
fbsworkspace registering source: <private>
fbsworkspace connected to endpoint : <private>
added observer for process assertions expiration warning: <_rbsexpirationwarningassertion: ; identifier: com.apple.runningboardservices.processexpirationwarningforhandle; reason: observation; valid: yes>
retrieving resting unlock: 0
fbsworkspace already connected to endpoint : <private>
registering for test daemon availability notify post.
notify_get_state check indicated test daemon not ready.
console error [native code]: error typeerror: undefined is not an object (evaluating \'tns_core_modules_application__webpack_imported_module_3__["android"].on\')
console error [native code]: error context {
"nodeflags": 33669121,
"rootnodeflags": 33554433,
"nodematchedqueries": 0,
"flags": 0,
"nodeindex": 0,
"parent": null,
"renderparent": null,
"bindingindex": 0,
"outputindex": 0,
"checkindex": 0,
"flags": 33554433,
"childflags": 114688,
"directchildflags": 114688,
"childmatchedqueries": 0,
"matchedqueries": {},
"matchedqueryids": 0,
"references": {},
"ngcontentindex": null,
"childcount": 1,
"bindings": [],
"bindingflags": 0,
"outputs": [],
"element": {
"name": "ns-app",
"attrs": [],
"template": null,
"componentprovider": {
"nodeindex": 1,
"parent": "[circular]",
"renderparent": "[circul<\\m-b\\m^@\\m-&>
console log angular is running in the development mode
call enableprodmode() to enable the production mode.
***** fatal javascript exception - application has been terminated
native stack trace:
1 nativescript::reportfatalerrorbeforeshutdown(jsc::execstate*, jsc::exception*, bool)
2 nativescript::fficallback<nativescript::objcmethodcallback>::fficlosurecallback(ffi_cif*, void*, void**, void*)
3 ffi_closure_sysv_inner
4 .ldo_closure
5 <redacted>
6 <redacted>
7 <redacted>
8 <redacted>
9 <redacted>
10 <redacted>
11 <redacted>
12 <redacted>
13 <redacted>
14 <redacted>
15 <redacted>
16 <redacted>
17 <redacted>
18 cfrunlooprunspecific
19 gseventrunmodal
20 uiapplicationmain
21 ffi_call_sysv
22 ffi_call_int
23 ffi_call
24 nativescript::functionwrapper::call(jsc::execstate*)
25 llint_entry
26 llint_entry
27 llint_entry
28 llint_entry
29 llint_entry
30 llint_entry
31 llint_entry
javascript stack trace:
traitcollectiondidchange(
at uiapplicationmain([native code])
at _start(
at run(
at bootstrapnativescriptapp(
at bootstrapapp(
at bootstrapmodule(
at ./main.ts(
at __webpack_require__(
at checkdeferredmodules(
at webpackjsonpcallback(
at anonymous(
at evaluate([native code])
at moduleevaluation([native code])
at promisereactionjob([native code])
javascript error:
js error typeerror: this.traitcollection.hasdifferentcolorappearancecomparedtotraitcollection is not a function
(in 'this.traitcollection.hasdifferentcolorappearancecomparedtotraitcollection(previoustraitcollection)', 'this.traitcollection.hasdifferentcolorappearancecomparedtotraitcollection' is undefined)
*** javascript call stack:
0 uiapplicationmain@[native code]
1 _start@
2 run@
3 bootstrapnativescriptapp@
4 bootstrapapp@
5 bootstrapmodule@
6 ./main.ts@
7 __webpack_require__@
8 checkdeferredmodules@
9 webpackjsonpcallback@
10 anonymous@
11 evaluate@[native code]
12 moduleevaluation@:1:11
13 promisereactionjob@:1:11
*** terminating app due to uncaught exception 'nativescript encountered a fatal error: typeerror: this.traitcollection.hasdifferentcolorappearancecomparedtotraitcollection is not a function
(in 'this.traitcollection.hasdifferentcolorappearancecomparedtotraitcollection(previoustraitcollection)', 'this.traitcollection.hasdifferentcolorappearancecomparedtotraitcollection' is undefined)
traitcollectiondidchange(
at uiapplicationmain([native code])
at _start(
at run(
at bootstrapnativescriptapp(
at bootstrapapp(
at bootstrapmodule(
at ./main.ts(
at __webpack_require__(
at checkdeferredmodules(
at webpackjsonpcallback(
at anonymous(
at evaluate([native code])
at moduleeva<\\m-b\\m^@\\m-&>
nativescript caught signal 6.
native stack:
1 sig_handler(int)
2 <redacted>
3 pthread_kill
4 abort
5 __cxa_bad_cast
6 <redacted>
7 <redacted>
8 <redacted>
9 __cxa_get_exception_ptr
10 <redacted>
11 <redacted>
12 nativescript::reportfatalerrorbeforeshutdown(jsc::execstate*, jsc::exception*, bool)
13 nativescript::fficallback<nativescript::objcmethodcallback>::fficlosurecallback(ffi_cif*, void*, void**, void*)
14 ffi_closure_sysv_inner
15 .ldo_closure
16 <redacted>
17 <redacted>
18 <redacted>
19 <redacted>
20 <redacted>
21 <redacted>
22 <redacted>
23 <redacted>
24 <redacted>
25 <redacted>
26 <redacted>
27 <redacted>
28 <redacted>
29 cfrunlooprunspecific
30 gseventrunmodal
31 uiapplicationmain
uiapplicationmain([native code])
at _start(
at run(
at bootstrapnativescriptapp(
at bootstrapapp(
at bootstrapmodule(
at ./main.ts(
at __webpack_require__(
at checkdeferredmodules(
at webpackjsonpcallback(
at anonymous(
at evaluate([native code])
at moduleevaluation
at promisereactionjob
background color and border are not applying to elements with height longer than 2048 (device 1) and 2730 (device 2) and 3075 (device 3)
i've also tested this on android 9 and it works fine.
i have been stuck at this issue for a while now and i'm starting to think it's a bug in nativescript implementation
so any feedback would be appreciated
so i have this page which seems pretty standard
it has an actionbar at the top, scrollable content in the form of messages and then at the bottom a sticky input with a button
what i would like to achieve is the following behaviour present in many other apps: when i click in the textview the focus goes on the whole area (the whole formgroup)
when i start typing, the view would remains focused (currently removing the scrollview #pagescrollview or disabling scroll will make the page jump as soon as you start typing)
scrolling should be only available in the messages so you should never be able to hide the formgroup ```
<scrollview #pagescrollview> <gridlayout rows="*, auto, auto" class="page-conversation" width="100%" height="100%"> <scrollview orientation="vertical" #messagesscrollview > <stacklayout class="messages"> <stacklayout orientation="vertical" *ngfor="let message of messages" class="message" [ngclass]="{ \'message--received\': message.reply, \'message--sent\': !message.reply }" > <label class="message-content" textwrap="true" [text]="message[\'content\']"></label> <label class="message-timestamp" [text]="message[\'timestamp\'] | date:\'dd.mm.yy, hh:mm\'"></label> </stacklayout> </stacklayout> </scrollview> <gridlayout rows="auto, 50" columns="*, *, *, auto" row="1" class="compose" > <stacklayout row="0" rowspan="1" col="0" colspan="4" [formgroup]="form"> <textview hint="enter message" #newmessage formcontrolname="newmessage" [text]="" required (focus)="onfocus($event)" (blur)="onblur($event)" [autocorrect]="false" class="textarea" autocapitalizationtype="none" ></textview> </stacklayout> <stacklayout row="1" col="0" class="option"> <label text="test"></label> </stacklayout> <stacklayout row="1" col="1" class="option"> <label text="test"></label> </stacklayout> <stacklayout row="1" col="2" class="option"> <label text="test"></label> </stacklayout> <stacklayout row="1" col="3" class="option"> <button #composearea text="send msg" class="send-button" ></button> </stacklayout> </gridlayout> </gridlayout>
</scrollview>
``` so i think the main point of concern here would be the behaviour of scrollview and/or textview.
if an angular project has dependency to "nativescript-dev-webpack": "^1.0.0", the build will fail because of a wrong version check throwing : **building @nativescript/core for angular requires nativescript-dev-webpack with version at least 1.3.0
please upgrade: npm i nativescript-dev-webpack --save-dev.**
when setting a class on the `actionbar` or a `gridlayout` inside of it, css inheritance doesn't work.
1) create an app with framemodule.topmost() onactivityresumed
2) suspend app
3) go to settings -> display -> advanced -> font size -> change the font size
4) resume app, app display blank page, press home button, app crashed error log: an uncaught exception occurred on "main" thread.
unable to stop activity calling js method onstop failed
typeerror: cannot read property 'backstack' of undefined
setting any border or border-radius to buttons (probably other elements) will remove their ripple effect on android.
when use tabs and minimised the app (open some other app) the highlighter(the line under the icon and tab text) of the selected tab is changed
it seems like the first tab was the selected one
note: the content of the tab is not changed, only the highlighter.
on ios the images within the tabstrip are not vertically centered within a bottomnavigation
on android they are perfectly centered
here is a screenshot from two running iphone simulators, where you should be able to see the issue
![image](
nested `css-calc` and `css-variables` with fallback value give incorrect result.
label formattedtext doesnt work under repeater
same works using listview (sample project but it doesnt work when used with repeater.
shorthandproperty instances can't be listened for changes
i am working on the nativescript mapbox plugin
my fork is here: the crash can be replicated using the included demo-angular app and e2e test
since upgrading nativescript to ns 6+, i am experiencing a random crash when navigating away from a page containing a map and removing the map container when running with "markingmode":"none"
i do not know if the map plugin code is causing the instability as i have not been able to reproduce this problem navigating away from other pages, but the crash happens after the navigation has completed and the map view and object have been destroyed leading me to believe that maybe this is not my bug
the map object is quite large so when doing lateral navigation ideally i want to destroy the mapbox view
i do this by wrapping the mapbox tag in container with an *ngif
before navigating away the *ngif condition is set to false and i wait for the mapbox ondestroy to return before proceeding with the navigation (thinking maybe there's a race condition somewhere.) after a random number of navigations between the map page and the test-crash page in the demo-angular app, it will crash on #l86
when navigating /to/ the test-crash page with the error: ```
jni detected error in application: can't call android.graphics.drawable.drawable android.graphics.drawable.colordrawable$colorstate.newdrawable(android.content.res.resources) on null object
``` cacheddrawable in this case is not null on the javascript side so i suspect a markingmode: "none" issue
adding a line of code to the javascript:
if ( cacheddrawable == null ) { console.log( "background.android.js - cacheddrawable is null ---------------" );
} else { console.log( "background.android.js - cacheddrawable is:", cacheddrawable );
causes a crash on the second console.log with the error can't call tostring() on null object.
we want to define platform-sepecific css styles like this:
.ns-android page { background-color: lightgray;
} .ns-ios page { background-color: greenyellow;
} .ns-android .switch[checked=true] { color: #589948; background-color: #589948;
} .ns-android .switch[checked=false] { background-color: #333333;
} .ns-android .my-button { background-color: #fcfdf7; color: #589948;
} .ns-ios .switch[checked=true] { color: #f07800; background-color: rgba(240, 120, 0, 0.3);
} .ns-ios .my-button { background-color: #fafbfb; color: #f07800;
``` those styles are correctly applied for elements that are placed in a normal page, but they are totally missing in a modal-page for both android and ios.
(i have not tested .ns-portrait, .ns-tablet etc as we only need the platform classes at the moment)
![nsstyleissue]( also, in the beginning of the gif you can see a strange effect for the switch component on android: when clicking the switch, it is colored blue for a short time, which is the default accent-color
this effect does not occur for normal styles (without .ns-android).
when a textfield is focused the app is freezing - happening on ios 13 emulator (iphone 11 max pro).
the application crashes runtime when `tns test` command is executed for newly created code shared application.
in our app we need to load data, that should be visualized in tabs and we want to use the new tabs component for that
**issue 1**: when trying to create the tabstripitems and the tabcontentitems dynamically, the tabstrip is not visible afterwards
you are only able to swipe through the tabs
when you navigate forwards to another page and then navigate back to the page, then suddenly you also see the tabstrip on the top
**issue 2** after navigating back you see the tabstrip, but it has not the complete style.
it has the correct backgroundcolor, the selected tab has the correct highlight-color, but all tabs do not have the correct text-color and font-size and the selected tab does not have the correct text-color (the styles have been successfully tested on a static tabs-component)
tabstrip { background-color: #f1f1eb; highlight-color: #d69a46;
tabstripitem label { color: #3c3c3c; font-size: 18;
tabstripitem:active label { color: #00718e;
tabstripitem image { color: #3c3c3c;
tabstripitem:active image { color: #00718e;
``` see the behaviour:
![tabsdynamicissue](
when defining the tabs this way:
<tabstrip> <tabstripitem> <label text="tabs 1"></label> </tabstripitem> <tabstripitem> <label text="tabs 2"></label> </tabstripitem> <tabstripitem> <label text="tabs 3"></label> </tabstripitem>
</tabstrip>
i see an error message in log: > js: error: failed to apply property [color] with value [#00caab] to tabstripitem(55)@ns-ui-widgets-category/tabs/usage/usage-page.xml:13:13;
error: undefined is not a valid file or resource.
> js: at object.fromfileorresource (
> js: at tabs.push.../node_modules/tns-core-modules/ui/tabs/tabs.js.tabs.geticon (
> js: at tabs.push.../node_modules/tns-core-modules/ui/tabs/tabs.js.tabs.settabbariconcolor (
> js: at object.callback (
> js: at style.push.../node_modules/tns-core-modules/data/observable/observable.js.observable.notify (
> js: at style.<anonymous> (
navigating to a page that contains `bottomnavigation` (or `tabs`) + having [nativescript-advanced-webview]( as a **dependency** (not even explicitly used/initialized) is crashing the app with: ```
system.err: an uncaught exception occurred on "main" thread.
system.err: the specified child already has a parent
you must call removeview() on the child's parent first.
system.err:
system.err: stacktrace:
system.err: java.lang.illegalstateexception: the specified child already has a parent
you must call removeview() on the child's parent first.
system.err: at android.view.viewgroup.addviewinner(viewgroup.java:5034)
system.err: at android.view.viewgroup.addview(viewgroup.java:4865)
system.err: at android.view.viewgroup.addview(viewgroup.java:4805)
system.err: at android.view.viewgroup.addview(viewgroup.java:4778)
system.err: at androidx.fragment.app.fragmentmanagerimpl.movetostate(fragmentmanagerimpl.java:887)
system.err: at androidx.fragment.app.fragmentmanagerimpl.movefragmenttoexpectedstate(fragmentmanagerimpl.java:1238)
system.err: at androidx.fragment.app.fragmentmanagerimpl.movetostate(fragmentmanagerimpl.java:1303)
system.err: at androidx.fragment.app.fragmentmanagerimpl.dispatchstatechange(fragmentmanagerimpl.java:2656)
system.err: at androidx.fragment.app.fragmentmanagerimpl.dispatchactivitycreated(fragmentmanagerimpl.java:2610)
system.err: at androidx.fragment.app.fragment.performactivitycreated(fragment.java:2619)
system.err: at androidx.fragment.app.fragmentmanagerimpl.movetostate(fragmentmanagerimpl.java:904)
system.err: at androidx.fragment.app.fragmentmanagerimpl.movefragmenttoexpectedstate(fragmentmanagerimpl.java:1238)
system.err: at androidx.fragment.app.fragmentmanagerimpl.movetostate(fragmentmanagerimpl.java:1303)
system.err: at androidx.fragment.app.backstackrecord.executeops(backstackrecord.java:439)
system.err: at androidx.fragment.app.fragmentmanagerimpl.executeops(fragmentmanagerimpl.java:2076)
system.err: at androidx.fragment.app.fragmentmanagerimpl.executeopstogether(fragmentmanagerimpl.java:1866)
system.err: at androidx.fragment.app.fragmentmanagerimpl.removeredundantoperationsandexecute(fragmentmanagerimpl.java:1821)
system.err: at androidx.fragment.app.fragmentmanagerimpl.execpendingactions(fragmentmanagerimpl.java:1727)
system.err: at androidx.fragment.app.fragmentmanagerimpl$2.run(fragmentmanagerimpl.java:150)
system.err: at android.os.handler.handlecallback(handler.java:873)
system.err: at android.os.handler.dispatchmessage(handler.java:99)
system.err: at android.os.looper.loop(looper.java:193)
system.err: at android.app.activitythread.main(activitythread.java:6669)
system.err: at java.lang.reflect.method.invoke(native method)
system.err: at com.android.internal.os.runtimeinit$methodandargscaller.run(runtimeinit.java:493)
system.err: at com.android.internal.os.zygoteinit.main(zygoteinit.java:858)
the `resetonfinish` boolean argument of `play` in the `animation` class only works if the animation has an `iterations` count greater then _1_.
when you rotate from portrait to landscape mode the styling of tabs/selection is completely messed up
in the example below the second tab becomes unstyled when the rectangles that were previously styling the tabs are moved and split the first tab:
![screenshot 2019-09-25 at 0 42 29](
the listpicker is working on ios but not on android, when i try to load a page with a listpicker on it i get the error: ```terminal
system.err: an uncaught exception occurred on "main" thread.
system.err: calling js method oncreateview failed
system.err: typeerror: this.nativeview.gettextcolor is not a function
system.err: system.err: stacktrace:
system.err: push.../node_modules/tns-core-modules/ui/list-picker/list-picker.js.listpicker.<computed>(
system.err: at applyallnativesetters(
system.err: at initnativeview(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.onresumenativeupdates(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase._resumenativeupdates(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.onloaded(
system.err: at push.../node_modules/tns-core-modules/ui/core/view/view.js.view.onloaded(
system.err: at (
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callloaded(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.loadview(
system.err: at (
system.err: at push.../node_modules/tns-core-modules/ui/layouts/layout-base-common.js.layoutbasecommon.eachchildview(
system.err: at push.../node_modules/tns-core-modules/ui/core/view/view-common.js.viewcommon.eachchild(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.onloaded(
system.err: at push.../node_modules/tns-core-modules/ui/core/view/view.js.view.onloaded(
system.err: at (
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callloaded(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.loadview(
system.err: at (
system.err: at push.../node_modules/tns-core-modules/ui/layouts/layout-base-common.js.layoutbasecommon.eachchildview(
system.err: at push.../node_modules/tns-core-modules/ui/core/view/view-common.js.viewcommon.eachchild(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.onloaded(
system.err: at push.../node_modules/tns-core-modules/ui/core/view/view.js.view.onloaded(
system.err: at (
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callloaded(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.loadview(
system.err: at (
system.err: at push.../node_modules/tns-core-modules/ui/layouts/layout-base-common.js.layoutbasecommon.eachchildview(
system.err: at push.../node_modules/tns-core-modules/ui/core/view/view-common.js.viewcommon.eachchild(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.onloaded(
system.err: at push.../node_modules/tns-core-modules/ui/core/view/view.js.view.onloaded(
system.err: at (
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callloaded(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.loadview(
system.err: at (
system.err: at push.../node_modules/tns-core-modules/ui/content-view/content-view.js.contentview.eachchildview(
system.err: at push.../node_modules/tns-core-modules/ui/page/page-common.js.pagebase.eachchildview(
system.err: at push.../node_modules/tns-core-modules/ui/core/view/view-common.js.viewcommon.eachchild(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.onloaded(
system.err: at push.../node_modules/tns-core-modules/ui/core/view/view.js.view.onloaded(
system.err: at push.../node_modules/tns-core-modules/ui/page/page.js.page.onloaded(
system.err: at (
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callloaded(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.loadview(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase._addviewcore(
system.err: at push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase._addview(
system.err: at push.../node_modules/tns-core-modules/ui/frame/frame.js.fragmentcallbacksimplementation.oncreateview(
system.err: at push.../node_modules/tns-core-modules/ui/frame/fragment.js.fragmentclass.oncreateview(
system.err: at com.tns.runtime.calljsmethodnative(native method)
system.err: at com.tns.runtime.dispatchcalljsmethodnative(runtime.java:1209)
system.err: at com.tns.runtime.calljsmethodimpl(runtime.java:1096)
system.err: at com.tns.runtime.calljsmethod(runtime.java:1083)
system.err: at com.tns.runtime.calljsmethod(runtime.java:1063)
system.err: at com.tns.runtime.calljsmethod(runtime.java:1055)
system.err: at com.tns.fragmentclass.oncreateview(fragmentclass.java:53)
system.err: at androidx.fragment.app.fragment.performcreateview(fragment.java:2595)
system.err: at androidx.fragment.app.fragmentmanagerimpl.movetostate(fragmentmanagerimpl.java:881)
system.err: at androidx.fragment.app.fragmentmanagerimpl.movefragmenttoexpectedstate(fragmentmanagerimpl.java:1238)
system.err: at androidx.fragment.app.fragmentmanagerimpl.movetostate(fragmentmanagerimpl.java:1303)
system.err: at androidx.fragment.app.backstackrecord.executeops(backstackrecord.java:439)
system.err: at androidx.fragment.app.fragmentmanagerimpl.executeops(fragmentmanagerimpl.java:2076)
system.err: at androidx.fragment.app.fragmentmanagerimpl.executeopstogether(fragmentmanagerimpl.java:1866)
system.err: at androidx.fragment.app.fragmentmanagerimpl.removeredundantoperationsandexecute(fragmentmanagerimpl.java:1821)
system.err: at androidx.fragment.app.fragmentmanagerimpl.execpendingactions(fragmentmanagerimpl.java:1727)
system.err: at androidx.fragment.app.fragmentmanagerimpl$2.run(fragmentmanagerimpl.java:150)
system.err: at android.os.handler.handlecallback(handler.java:883)
system.err: at android.os.handler.dispatchmessage(handler.java:100)
system.err: at android.os.looper.loop(looper.java:214)
system.err: at android.app.activitythread.main(activitythread.java:7343)
system.err: at java.lang.reflect.method.invoke(native method)
system.err: at com.android.internal.os.runtimeinit$methodandargscaller.run(runtimeinit.java:492)
system.err: at com.android.internal.os.zygoteinit.main(zygoteinit.java:933)
``` searching in the code of this repository the problem appears to happen in the file `tns-core-modules/ui/list-picker/list-picker.android.ts` line 175.
modal page not working and causing the app to crash after suspend/resume
reproducible on nativescript core and nativescript angular.
in our real app we want to show circular avatar-images of our users within a listview and if the user has no image, we want to show a placeholder image while using a fontawesome icon as the source of the image
[ here are the problems: **problem 1**
when using stretch="aspectfill", the image fontawesome icon gets blurred and does not fill the whole image, as you can see a border around the icon
`<image stretch="aspectfill" src="{{ imageurl ? imageurl : \'font://&#xf2bd;\' }}" classname="profileimage profileimage-list fa-solid"/>` ```
.profileimage { background-position: center; background-repeat: no-repeat; background-size: cover; border-radius: 50%; vertical-align: center; background-color: darkcyan; color: aliceblue;
} .profileimage-list { width: 50; height: 50;
you can see the effect in the large image in the top left and in the images within the list in the screenshot below
**problem 2:**
according to the docs, one should set stretch to none and set a fontsize to the image
`<image stretch="none" src="font://&#xf2bd;"classname="profileimage profileimage-large-custom fa-solid"/>` ```
.profileimage-large-custom { width: 100; height: 100; font-size: 30;
``` this way, the icon has no blurred effect (as expected), but it is not possible to center and stretch the icon within the image component, as the results looks different on all test devices
(see the top right image in the screenshot)
so on some devices, the icon is too large and does not fit into the image component, and on other devices, the icon is too small and is not centered within the image component
**result:**
![image2](
it appears that apple has updated the `uisegmentedcontrol` component
take a look at the screenshots below to see the difference between ios 12 & 13 in the same app
they have removed `tintcolor` and added `selectedsegmenttintcolor` property
tested the new property localy and it works, but breaks on ios12 and earlier
earlier versions handled the selected items text color automatically (i believe it was transparent, so that it gets the color of the background)
but now it is the same as the rest of the items as it just applies the `color` property value
would be great if we could get it to behave as it did before, with the selected-item text color beeing transparent
<stacklayout class="fkz-blue-bg"> <segmentedbar selectedbackgroundcolor="white" color="white" selectedindex="0"> <segmentedbaritem title="raspored" /> <segmentedbaritem title="rezultati" /> <segmentedbaritem title="tabela" /> </segmentedbar>
</stacklayout>
``` **ios 12.2**
![segmentbar_ios_12]( **ios 13.0**
![segmentbar_ios_13](
`no view controller managing visible view` error upon changing selected index in tabs component.
when having a proxyviewcontainer as first child of tabcontentitem, the app crashes
this is very important for angular
see playground.
`<tabs selectedindex="1">` does not apply.
when tapping on the tab strip tabs one by one, they get stuck at the second.
when tapping on the tab strip tabs one by one, they get stuck at the second.
if an android button is not stretched and has short text, there seems to be some min-width set that can't be seen or removed from css or element properties.
as `hmr` is enabled by default in ns 6.0 , when i make a change in my code and close the app and reopen it, the changes are gone
also, from that point on, i can't see the result of changes in the phone.
if you set border-width, border-radius, background-image or clip-path, the button ripple is gone, and can be got back by removing them later
however, if the css is added on the fly, the ripple is not restored
something like this: ```css
button { border-radius: 1; background-color: #ccc;
then add this css later:
.something button { border-radius: 0;
sharing internet connection on ios breaks the layouts on resume.
when i'm canceling animate function with width and height parameters, app crash on only android platform
error is "android.view.view.getlayoutparams() on a null object reference"
if i set a scale parameter, it works properly.
bottomnavigation and tabs components do not respect tabstrip.iosiconrenderingmode property value but use `uiimagerenderingmode.alwaysoriginal` instead.
tabstripitem title gets clipped when both iconsource and title are specified.
animate seems to be hard coded to a count of 2 no matter what iteration i set it to in the demo below
be it infinite, 1, 3 100 etc
**issue with animate css showing element only rotating 2 times when it should be infinite.**
if i change the keyframes to something like this then the animation is infinite but after 2 loops it reverses?!
@keyframes rotateme { 0% { transform: rotate(0); } 50% { transform: rotate(180deg); } 100% { transform: rotate(360deg); }
``` **preferred outcome using the animate method.**
since all changes to platform classes in #7606 are done through cssclasses property, they are not reflected in classname property, thus changing classname will overwrite them.
most of the time when i use the auto-import in vscode the import is a total mess and does not represent the actual path
this on a newly started project with ns 6.0 and using long import paths.
multiple taps on a button which changes `tabs`' *selectedindex* causes glitches.
the runtime error i am seeing is as follows: 1
on the android version of the application, i start on a page, and do an unanimated transition to a second page
from the second page, i do an animated transition to a third page
from the third page, i call frame.goback() to go back to the first page
once on the first page again, you cannot navigate anywhere and the navigatedto event for the first page and navigatedfrom event from the third page are not called
very specific, i know
i have a specific reason for using an unanimated transition from one page to the next in my app as well.
similar to [this]( issue but calling the close callback still works
the issue is that the modal's content is not changed accordingly to the changes and is not closed.
when you change the `selectedindex` programatically the tab actually changes but the styles are not applied, so visually the old tab remains selected and the new one looks like unselected
works as expected on android.
if a module name ends in `.page` (i'm guessing `.<anything>`) you'll not be able to use it, at least not as a frame's `defaultpage`
please see this [playground example](
uinavigationbar can't be modified in `actionbar.loadedevent` event handler.
this is a rather strange bug
if you have a `textfield` on the 2+ tab, and you have the `textfield.edtable` property bound to some value and the `autocapitalizationtype` is set to `sentences` (the default one), the text field never gets enabled.
in android, after an app is suspended and its activities are destroyed by the os, upon resuming and trying to navigate the app crashes with an error of type `cannot read property 'goback' of undefined`
this happens when such kinds of calls are present in the code:
frame.topmost().goback();
tab with nested frame is not completely selected.
`setviewcontrollersdirectionanimatedcompletion` method does not call its completion callback.
on ios when nesting tabs inside bottomnavigation the layout is wrong
the content of the tabs tab doesn't get to the bottom of the screen
see the light blue background in the following image:
![screenshot 2019-07-22 at 10 24 44](
i have two built versions with {n} 6.0 and {n} 5.4.3, on the older built, the (tap) events works as expected and without any lags, but on the newer built, i can feel a lag of about 1 second or less before it executes the function assigned to the event
any body else having the same experience or there is something wrong with my {n} 6.0 built? <bountysource-plugin> ---
want to back this issue? **[post a bounty on it!]( we accept bounties via [bountysource](
</bountysource-plugin>
on ios when `tabs` are wrapped in any layout, the tab strip isn't laid out correctly.
app crashes when selecting tab with no relevant content item when there are more tabstripitems than tabcontentitems.
the actionbar will crash when we try to setup icon-font for the actionitem with the following error:
system.err: error: java.lang.illegalargumentexception: width and height must be > 0
system.err: android.graphics.bitmap.createbitmap(bitmap.java:1033)
system.err: android.graphics.bitmap.createbitmap(bitmap.java:1000)
system.err: android.graphics.bitmap.createbitmap(bitmap.java:950)
system.err: android.graphics.bitmap.createbitmap(bitmap.java:911)
system.err: com.tns.runtime.calljsmethodnative(native method)
system.err: com.tns.runtime.dispatchcalljsmethodnative(runtime.java:1242)
system.err: com.tns.runtime.calljsmethodimpl(runtime.java:1122)
system.err: com.tns.runtime.calljsmethod(runtime.java:1109)
system.err: com.tns.runtime.calljsmethod(runtime.java:1089)
system.err: com.tns.runtime.calljsmethod(runtime.java:1081)
system.err: com.tns.fragmentclass.oncreateview(fragmentclass.java:53)
system.err: androidx.fragment.app.fragment.performcreateview(fragment.java:2439)
system.err: androidx.fragment.app.fragmentmanagerimpl.movetostate(fragmentmanager.java:1460)
system.err: androidx.fragment.app.fragmentmanagerimpl.movefragmenttoexpectedstate(fragmentmanager.java:1784)
system.err: androidx.fragment.app.fragmentmanagerimpl.movetostate(fragmentmanager.java:1852)
system.err: androidx.fragment.app.backstackrecord.executeops(backstackrecord.java:802)
system.err: androidx.fragment.app.fragmentmanagerimpl.executeops(fragmentmanager.java:2625)
system.err: androidx.fragment.app.fragmentmanagerimpl.executeopstogether(fragmentmanager.java:2411)
system.err: androidx.fragment.app.fragmentmanagerimpl.removeredundantoperationsandexecute(fragmentmanager.java:2366)
system.err: androidx.fragment.app.fragmentmanagerimpl.execpendingactions(fragmentmanager.java:2273)
system.err: androidx.fragment.app.fragmentmanagerimpl$1.run(fragmentmanager.java:733)
system.err: android.os.handler.handlecallback(handler.java:873)
system.err: android.os.handler.dispatchmessage(handler.java:99)
system.err: android.os.looper.loop(looper.java:201)
system.err: android.app.activitythread.main(activitythread.java:6806)
system.err: java.lang.reflect.method.invoke(native method)
system.err: com.android.internal.os.runtimeinit$methodandargscaller.run(runtimeinit.java:547)
system.err: com.android.internal.os.zygoteinit.main(zygoteinit.java:873)
system.err: system.err: stacktrace:
system.err: frame: function:'push.../node_modules/tns-core-modules/image-source/image-source.js.imagesource.loadfromfonticoncode', file:'
system.err: frame: function:'fromfonticoncode', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/action-bar/action-bar.js.actionbar._addactionitems', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/action-bar/action-bar.js.actionbar.update', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/action-bar/action-bar.js.actionbar.onloaded', file:'
system.err: frame: function:'', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callloaded', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.loadview', file:'
system.err: frame: function:'', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/page/page-common.js.pagebase.eachchildview', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/core/view/view-common.js.viewcommon.eachchild', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.onloaded', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/core/view/view.js.view.onloaded', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/page/page.js.page.onloaded', file:'
system.err: frame: function:'', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callfunctionwithsuper', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.callloaded', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase.loadview', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase._addviewcore', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/core/view-base/view-base.js.viewbase._addview', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/frame/frame.js.fragmentcallbacksimplementation.oncreateview', file:'
system.err: frame: function:'push.../node_modules/tns-core-modules/ui/frame/fragment.js.fragmentclass.oncreateview', file:'
system.err: at com.tns.runtime.calljsmethodnative(native method)
system.err: at com.tns.runtime.dispatchcalljsmethodnative(runtime.java:1242)
system.err: at com.tns.runtime.calljsmethodimpl(runtime.java:1122)
system.err: at com.tns.runtime.calljsmethod(runtime.java:1109)
system.err: at com.tns.runtime.calljsmethod(runtime.java:1089)
system.err: at com.tns.runtime.calljsmethod(runtime.java:1081)
system.err: at com.tns.fragmentclass.oncreateview(fragmentclass.java:53)
system.err: at androidx.fragment.app.fragment.performcreateview(fragment.java:2439)
system.err: at androidx.fragment.app.fragmentmanagerimpl.movetostate(fragmentmanager.java:1460)
system.err: at androidx.fragment.app.fragmentmanagerimpl.movefragmenttoexpectedstate(fragmentmanager.java:1784)
system.err: at androidx.fragment.app.fragmentmanagerimpl.movetostate(fragmentmanager.java:1852)
system.err: at androidx.fragment.app.backstackrecord.executeops(backstackrecord.java:802)
system.err: at androidx.fragment.app.fragmentmanagerimpl.executeops(fragmentmanager.java:2625)
system.err: at androidx.fragment.app.fragmentmanagerimpl.executeopstogether(fragmentmanager.java:2411)
system.err: at androidx.fragment.app.fragmentmanagerimpl.removeredundantoperationsandexecute(fragmentmanager.java:2366)
system.err: at androidx.fragment.app.fragmentmanagerimpl.execpendingactions(fragmentmanager.java:2273)
system.err: at androidx.fragment.app.fragmentmanagerimpl$1.run(fragmentmanager.java:733)
system.err: at android.os.handler.handlecallback(handler.java:873)
system.err: at android.os.handler.dispatchmessage(handler.java:99)
system.err: at android.os.looper.loop(looper.java:201)
system.err: at android.app.activitythread.main(activitythread.java:6806)
system.err: at java.lang.reflect.method.invoke(native method)
system.err: at com.android.internal.os.runtimeinit$methodandargscaller.run(runtimeinit.java:547)
system.err: at com.android.internal.os.zygoteinit.main(zygoteinit.java:873)
system.err: caused by: java.lang.illegalargumentexception: width and height must be > 0
system.err: at android.graphics.bitmap.createbitmap(bitmap.java:1033)
system.err: at android.graphics.bitmap.createbitmap(bitmap.java:1000)
system.err: at android.graphics.bitmap.createbitmap(bitmap.java:950)
system.err: at android.graphics.bitmap.createbitmap(bitmap.java:911)
system.err: ..
the app will crash even if we setup the width and height inline or via css on actionbar and actionitem
this error is reproducable only on android
**sample** ```xml
<page.actionbar> <actionbar width="48" height="48"> <actionbar.actionitems> <actionitem icon="font://&#xf359;" width="48" height="48" class="font-awesome font-size color" ios.position="left" tap="navigateback"/> <actionitem icon="font://&#xf141;" width="48" height="48" class="font-awesome font-size color" ios.position="right"/> </actionbar.actionitems> </actionbar> </page.actionbar>
label { background-color: orangered; color: white; margin:8; padding: 16;
actionbar{ width: 48; height: 48;
/* >> action-bar-icon-fonts-css */
.font-awesome { font-family: "font awesome 5 free", "fa-regular-400";
/* << action-bar-icon-fonts-css */
.font-size { font-size: 48; width: 48; height: 48;
} .color { color: blue;
``` <bountysource-plugin> ---
want to back this issue? **[post a bounty on it!]( we accept bounties via [bountysource](
</bountysource-plugin>
wrong tabstripitem selected.
cannot change text color for selected tabstripitem applied via "active" pseudoselector.
font icon does not update to active state for selected tabstripitem when "active" pseudoselector is specified.
after scanning qr code in playground in device logs is printed error for loading `app.css` but actually it is loaded and changes are applied.
tabcontentitem background color is not applied.
tabstripitem color value not applied on element's text.
the tabstripitem selected / highlight indicator is not visible in case tabstripitem background color is set.
app crashes in a scenario with frame -> bottom navigation -> frame (nested fragments) after you navigate forward from the root level frame and try to go back
note the error occurs only if navigation is performed with animated=false (no transition).
bottomnavigation component renders empty space at the bottom (where tabstrip would be) when no tabstrip is defined.
swiping a content item of `tabs` crashes the application on ios.
the parent expression shows [object object] when the project is ran with --env.uglify flag
for example following code snippet in the label doesn\'t work as expected: `<span text="{{$parents[\'listview\']._people, $parents[\'listview\']._people.length }}" />`
setting `iconsource` on `tabstripitem` does not work for ios.
tap on a `tabstripitem` does not change to its `tabcontentitem` on ios.
navigating back on `ios` via the default _swipe back navigation_ removes all `actionbar` styles to the default `ios` style
and if the _swipe back navigation_ event is started but not completed the styles remain changed
**to reproduce / sample project**
see [playground](
when you call observablearray.splice(), the event it emits fails to account for replaced items
this means it accounts only for removals/inserts, but any replace returns an added count of 0
when a button's css class is changed at runtime, it does not respect the class' color property
when applying a background to a label with a formatted string, the background is re-applied in the inner `<span>`s
this is a problem when we have a semi-transparent background, as you can see here: ![span background bug](
custom components extending span are not rendered in formattedstring.
the value of the property will not be updated correctly when we used nested objects
dialogs like `alert` and `prompt` not showing on the 2nd modal opened by the first modal
but when i try to show the alert from the first modal it works as expected.
the app will crash when a new value in the listpicker is selected
this happens when an observablearray with key-value pairs are used for the component's source.
the listpicker will not update the ui when a new item in the listpicker's source array is added.
setting minminute, minhour, maxminute and maxhour, has no effect on spinners, all values can be selected
setting minminute, minhour, maxminute and maxhour
hour spinner is locked either on current hour or value set by property "hour"
minute spinner is limited by min and max values.
component builder does not support codefile / cssfile / import with bundle workflow -- discovered in xml declaration tests here:
livesync tests do not pass when using bundle workflow (with hmr) -- they can only pass with `--no-hmr` flag
[code-only custom components]( #code-only-custom-component) do not work with bundle workflow
note: seems the issue is typescript only -- works with js.
introduction of the webpack only workflow (uselegacyworkflow=false) breaks the established development workflow in nativescript core team where we link a local copy of tns-core-modules in test projects and use it to run/debug test scenarios on mac osx (assuming behavior is the same on windows and linux as well).
the code below doesn't change the color of the status bar on android on navigating back to the page using `routerextensions#backtopreviouspage()` or native android back navigation
constructor( private page: page
) {} ngoninit() { this.page.on('navigatingto', () => { this.page.androidstatusbarbackground = new color('orange'); }); }
on ios, the content placed outside the frame disappears after you open and close a modal.
the nativescript theme provides some nice helper classes for margin and padding
i wanted to apply a margin-top of 5 to my button
i've used `m-t-5` which simply did not work on my button
when i've checked, we've already specified `margin: 0` for our button (`.btn`) class
so first i thought it might be a problem of the the order the classes are applied but i could move them around without any success
for some reason i came up with a solution by adding `m-0` to the button as well which does not make any sense for me but it works.
the overlay underneath dialogs causes colors to be wrong for the segmentedbar (and tabview icons) - see screenshots
note the gray color for selected segment, but this is orange when a system dialog appears.
setting view.androidelevation property should not require explicitly setting view.androiddynamicelevationoffset property (it should use its respective default value instead).
when the "double space to insert a period" shortcut in enabled, the textfield model is not being updated after the period is inserted.
master detail template crashes on ios simulator < 11 when scrolling the application.
actionbar background color animation doesn't work on ios, neither with css animation nor with js (`view.animate()`)
the same code works on android.
in the past month we've tracked 20+ crashes with this error:
typeerror: undefined is not an object (evaluating 'measurespec.setcolumn')
when the keyboard is up, the safe area is showing above the keyboard, which doesn't make sense because there is a safe area below the keyboard
the bug is visible in the next image: ![safearea_and_keyboard](
when using html to describe items, segmentedbar doesn't show any of the tabs and a runtime error is logged in console (ios only):
_typeerror: undefined is not an object (evaluating \'parent.ios.settitleforsegmentatindex\')_ `<segmentedbar selectedindex="selectedindex"> <segmentedbaritem title="a"></segmentedbaritem> <segmentedbaritem title="b"></segmentedbaritem> </segmentedbar>`
when tapping on a `textfield` with `isuserinteractionenabled` set to `false` tap event is fired only on android (bug) but not in ios (as expected).
when using `text-transform: capitalize` on label/text/button/etc
ui elements, the behaviour on ios and android inconsistent and wrong on android
on android, the source string is split on " " (space) to get an array of words, then each word gets lower-cased(!), then the first character of each word gets upper-cased
on ios, a platform native function is used which which uses a different/hidden implementation.
we are trying to set the font-size of the titles within tabview using the _tabtextfontsize_ property
<tabview tabtextfontsize="18"> </tabview>
``` it is working as expected when navigating forwards to the page where the tabview is located.
but when you are in another page and navigate **back** to the tabview-page, the font-size is not set correctly anymore
![nstabfontissue](
as shown in the screenshot, flexbox works on android as expected, on ios not
on android, everthing looks like expected:
(notice the heck at the end of the line, it not shrinked and completely readable) on ios, though, it doesn :
different layouts fall behind the tabbar with the actionbar hidden
(page.actionbarhidden)
i have a feeling the change that was made with: has to do something with it.
changing padding of a label on ios at runtime does not apply.
$parents['listview'] or $parents['repeater'] dont work as expected when used in conditional expression.
on ios, when you apply a border radius to an element with one border color, the border radius is applied
if you try to apply multiple border colors to the element, the border radius is not applied.
i am specifically trying to do apply a border-radius on a flexbox layout but i have also tried other ns layouts.
on ios if a nativescript app is opened during a phone call the layout is distorted by the addition of the call status bar at the top
this appears to only occur if the app is not running and is then opened during a phone call.
i have a `textfield` with `editable` set to `false`
however if i tap quickly on the field **while the app is resuming**, i can change the text.
i was running the emulator (ios, ipad) for approximately a day and half (ie, starting the emulator and not stopping it for a day and half; the computer was periodically asleep during the time, but the emulator was not shut down.)
at that point, it started having faulty router navigation
specifically, (i) a navigation button would stop working and (ii) the emulator would navigate away from a certain page immediately upon going back to that page (even though navigation had not been ordered)
navigation on the app is done with router, navigation extras, and active router
it is very unlikely this is a code error, because i have run the same code multiple times on different emulators (and on my device), without seeing this behavior
i closed the emulator
on running it again, the behavior has stopped (and navigation is working properly)
so it seems likely to me that the navigation "glitch" was specific to the emulator, and probably a result of the emulator running for so long
a breakdown in the emulator after running it for so long is not a significant concern
however, it would be helpful to know whether others have seen buggy behavior in an emulator open for a long time, as it would help me confirm whether or not there is some hidden code problem, a bug in router with nativescript, or an issue with the ios back button.
i've created a gridlayout container which has a min-height, so it can grow vertically if the text content is too long
elements in its cells should take the available space automatically
this does not happen
only if i use fixed height instead of min-height it works as expected
verticalalignment = 'stretch' has no effect.
listview separatorcolor="transparent" doesn\'t delete separator on android (pixel 2xl) but works fine on ios (iphone x)
when rotating on an ios device (tested on ios version 11.4.1 and 12.1) after scrolling down the page until the top components are off-screen, items stack up
the playground link below is using transparent colors to show the overlap but that and margins aren't necessary
when using a linear-gradient on page on ios (works on android) is making the v-template (or the list view ?)in it invisible, but listener still work.
trying to move element in a circular path using css keyframes by applying:
`@keyframes orbit{
from { transform: rotate(0deg) translate(-50px) rotate(0deg); } to{ transform: rotate(360deg) translate(-50px) rotate(-360deg); }
results the element to stay in the same position.
i have figured out to achieve this i have to specify the rotation angle in every 6.25% and it doesn't move in an exact circular path.
this is code runs well on browser, do i miss something with nativescript or is it a bug that would be fixed?
simple test app that has an icon on the bottom left
press it and navigate to another page
press back and press the icon again to repeat
page is frozen
this is on ios
i've narrowed the problem down to the navigation code (file main-view-model.ts)
if the `transition` property is commented out - it works
if that property is activated, then on navigating back to the main page, the whole page is frozen - subsequent clicks never occur.
flexshrink= doesn seems to work on ios.
i've installed cleaned nativescript project and tried to change barstyle with this code.
var navigationbar = frame.topmost().ios.controller.navigationbar;
navigationbar.barstyle = 1;
it works, when my app-root.xml looks like this
<frame defaultpage="home/home-page" id="my-frame-id"></frame>
as soon as i put it in the grid layout, barstyle breaks and is not changing text color, only background color
but i need to change actual text.
on ios, when creating an element dynamically and applying animation on it, the border radius property does not work
on android works as expected.
our users should be able to use the "next" option of the keyboard to get to the next textfield while being able to scroll the page when keyboard is open.
problem: this does not work on our physical devices, it only works on android emulator
we tested on the following devices: motorola moto x play, moto z play, google nexus 4
we already added **android:windowsoftinputmode="statehidden|adjustresize"** to our androidmanifest.xml.
and we added **returnkeytype="next"** to our textfields
we also tried setting focus on the next textfield manually: ```
<textfield ..
returnkeytype="next" returnpress="onreturnkeypressed"/>
exports.onreturnkeypressed = function(args) { var tf = args.object; var tfnext = null; if(tf.id === "tf1") { tfnext = page.getviewbyid("tf2"); } else if(tf.id === "tf2") { tfnext = page.getviewbyid("tf3"); } if(tfnext) { tfnext.focus(); } else { tf.dismisssoftinput(); }
``` but that did not change anything
using adjustpan instead of adjustresize for android:windowsoftinputmode would fix this for that certain form, but it has other disadvantages, so we do not want to use that.
i'm trying to create a component using flexboxlayout with a fixed sized rectangle to the left and a variant size label to the right with the textwrap property enabled, so if the right label text increase its length there will be a line break but that makes the left rectangle to be narrowed
the template layout is like follows: ```xml
<stacklayout width="80%" id="synchpointsavailable"> <label id="countwith" text="{{\'membership.buy-gift-view.you-count-with\' | l}}"></label> <flexboxlayout backgroundcolor="blue" width="100%" flexdirection="row" alignitems="center"> <absolutelayout backgroundcolor="green" id="synchpointscontainer"> <flexboxlayout id="synchpointscircle" alignitems="center" justifycontent="center"> <label id="synchpoints" [text]="synchpoints | humanformat"></label> </flexboxlayout> <stacklayout id="bubble1"> </stacklayout> <stacklayout id="bubble2"> </stacklayout> </absolutelayout> <label id="synchpointslabel" flexgrow="1" text="{{\'membership.buy-gift-view.synch-points\' | l}}" textwrap="true"></label> </flexboxlayout> </stacklayout>
and the scss file that style it is: ```scss
#synchpointsavailable { #countwith { font-size: 18; color: $accent-color; text-transform: uppercase; } #synchpointslabel { margin-left: 15; font-size: 20; color: $dark-primary-color; text-transform: uppercase; } #synchpointscontainer { width: $pointscontainersize; height: $pointscontainersize; #synchpointscircle { width: 100%; height: 100%; border-radius: 150; border-width: 3; border-color: $dark-primary-color; #synchpoints { text-align: center; color: $accent-color; } } #bubble1, #bubble2 { width: $bubblesize; height: $bubblesize; border-radius: 100; background-color: $dark-primary-color; } #bubble1 { top: 3; left: 3; } #bubble2 { top: $pointscontainersize - $bubblesize - 3; left: $pointscontainersize - $bubblesize - 3; } #synchpoints { font-size: 40; } }
this gives me the following result: ![image]( but if i increase the size of the `#synchpointslabel` from 20 to a higher value (for example 24) that makes a line break but also (and what i don't expect) cut off the width of the green rectangle: ![image]( is like the overflow of the label text (that makes the textwrap happen) is substracted in the left rectangle
i discover that if i use a fixed width in the label that do not happen but this must be unnecessary a solution
if a layout element within a `scrollview` is made to appear with `visibility`, and its area after appearing is not in view, it will jump to the top of the layout element containing the `scrollview` and mess up the entire screen
[archive.zip]( <bountysource-plugin> ---
want to back this issue? **[post a bounty on it!]( we accept bounties via [bountysource](
</bountysource-plugin>
on **iphone x** family (the ones with the notch) having a `scrollview` as direct child of nested `radsidedrawer` `maincontent` breaks the layout
the first element in the `scrollview` is offset from the top incorrectly.
nested frames (i.e
fragments) disappear when their parent is animated
related to but the problem is not specific to tabview and is more general
caused by -- arcane issue that google somehow marked as obsolete & won't fix.
tap events are being propagated to parent objects, even when ispassthroughparentenabled = false;
when doing a scale animation on a stacklayout with an embedded label, the text in the label is out of alignment
also the border-radius for the stacklayout is not working any more
this happens for all curves (linear, easein, easeout, easeinout) expect for spring curve
doing the animation with spring curve shows everything correct
issue appears on preview on ios device
on android device both views are correct displayed, but the animation after load is not performed, the stacklayout just appears but do not animate.
the `background-image` size and position seems to be calculated with the wrong scale
i am adding a background image to a `<button>` with the relevant scss: ```
button.social-login { // (...) height: 50; background-size: 32 32; background-position: 20 8; background-repeat: no-repeat; &.fb { background-color: #167dc3; background-image: url('res://facebookicon'); } &.google { background-color: #eb4e41; background-image: url('res://googleicon'); margin-bottom: 50; }
``` see the next image:
<img width="1204" alt="ns-bg-img-error" src=" "> this image shows 3 devices:
- android nexus 9 (xxhdpi)
- android nexus 5x (xxxhdpi)
- iphone 6 the icon is rendered as expected on ios
on android, it seems to be calculating with real pixels instead of dpis
i know this because the xxhdpi is sligtly bigger than the xxxhdpi.
when navigate through the example master->detail->master the labels in the action bar are multiplied
i try to set a timeout for our http requests in our nativescript app, but the [timeout]( #timeout) property has no effect for me while testing.
having a flexboxlayout with flexdirection="row" doesn\'t work well with a child having verticalalignment="center" on android
on ios the child is centered vertically, while on android it is top aligned
<flexboxlayout flexdirection="row" backgroundcolor="red" > <label text="test" verticalalignment="center" backgroundcolor="blue" />
</flexboxlayout>
to be able to hide the keyboard after tapping on any other space than a textfield i added a tap action on the parent element of a listview, this behavior works if the listview doesn't use itemtap action on the html
if i place another tap in the viewlist with itemtap the itemtap behavior gets overwritten so it stops working
on ios the problem is solved using iqkeyboardmanager plugin but apparently on android this is not supported
i also made this work adding a tap over another area other than the listview, so the issue here is that in android ns is unable to determine the tap action inside the empty space of a listview which also has itemtap action declared and an item.
prisma `1.34.7` breaks services with a service secret.
as the title said, the generated types file automatically import interface `model` from `prisma-client-lib/types.d.ts`
this will lead to a same-name-overlapping with a user-defined type
<img width="676" alt=" 2019-08-23 34 29" src=" "> a simple workaround is rename `model` but has to do this every time after re-generate the types.
mutations with custom check constraints don't work.
as i describe, i clone new but it very slow
i have this model
type user { id: id! @id createdat: datetime! @createdat updatedat: datetime! @updatedat handle: string! @unique name: string tweets: [tweet!]!
} type tweet { id: id! @id createdat: datetime! @createdat text: string! owner: user! location: location!
} type location { id: id! @id latitude: float! longitude: float!
when i run export data then import data into new database relation between **tweet->location is null.**
![image]( but when i modify something like this
type user { id: id! @id createdat: datetime! @createdat updatedat: datetime! @updatedat handle: string! @unique name: string tweets: [tweet!]!
} type tweet { id: id! @id createdat: datetime! @createdat text: string! owner: user! location: location! @relation(name: "tweethaslocation", link: table)
} type location { id: id! @id latitude: float! longitude: float!
this working
can anyone explain to me
what happen is going on here.
say thanks.
impossible to update several elements in batch - graphql types: a parent (`project`) and its child (`asset`)
type project { id: id! @id dataset: [asset!]
} type asset { id: id! @id project: project property: string
``` - resolver to update two assets belonging to the same project in batch:
assetid1 := "id-01234"
assetid2 := "id-56789"
r.prisma.updateproject(prisma.projectupdateparams{ where: prisma.projectwhereuniqueinput{id: &project.id}, data: prisma.projectupdateinput{ dataset: &prisma.assetupdatemanywithoutprojectinput{ updatemany: [ prisma.assetupdatemanywithwherenestedinput{ where: prisma.assetscalarwhereinput{id: &assetid1}, data: prisma.assetupdatemanydatainput{ property: "something", }, }, prisma.assetupdatemanywithwherenestedinput{ where: prisma.assetscalarwhereinput{id: &assetid2}, data: prisma.assetupdatemanydatainput{ property: "something else", }, }, ], }, },
}).exec(ctx)
``` - only the last asset in the list gets updated
using graphql alias in subscriptions causes an exception `java.util.nosuchelementexception: jserror.get.`
when using npx to login, init and deploy (i should have installed it though, i know) it uses the version 1.32.0-beta for the server, and when using the cli after installing it globally, it says this: warning: your prisma server and prisma cli are currently out of sync
they should be on the same minor version
prisma cli version: prisma/1.34.3 (darwin-x64) node-v8.11.3
prisma server version: 1.32.0-beta for further information, please read:
deletemany or operator on subresource gives `these should not be hit`, other tries of usage positional filtering doesn't works.
more specifically on the batchpayloadpromise interface, looking at count
export type long = string; export interface batchpayloadpromise extends promise<batchpayload>, fragmentable { count: () => promise<long>;
``` when doing a
await prisma.update*(...).count()
it will return a string by type definition (long = string)
but at runtime it is a number.
often seeing a unique constraint violation error when batching data using `prisma.upsert()`
after much testing it appears to be an issue with prisma client
type user { id: id! @id(strategy: none) ...
``` output of client with debug: true
{ error: a unique constraint would be violated on user
details: field name = id at batchedgraphqlclient.<anonymous> (/users/joshhopkins/projects/test/node_modules/http-link-dataloader/dist/src/batchedgraphqlclient.js:77:35) at step (/users/joshhopkins/projects/test/node_modules/http-link-dataloader/dist/src/batchedgraphqlclient.js:40:23) at object.next (/users/joshhopkins/projects/test/node_modules/http-link-dataloader/dist/src/batchedgraphqlclient.js:21:53) at fulfilled (/users/joshhopkins/projects/test/node_modules/http-link-dataloader/dist/src/batchedgraphqlclient.js:12:58) at processticksandrejections (internal/process/next_tick.js:81:5) result: { data: null, errors: [ [object] ], status: 200 } }
after a few hours of frustrating debugging i found the issue i was stumbling on
there is namely a difference in the `prisma deploy` and the generated prisma client (`prisma generate`) which both use the `enpoint` from the `prisma.yml` file
i am running a local prisma server (via docker) and when i tried to run `prisma deploy` it would always pull up the login page in my browser in stead of connecting to the local running prisma server
i found that when the `endpoint` is set to an ip adres (from docker) it doesn't work but when setting it to ` ` (1234 being the port of your prisma server) it works correctly
then the other side of the coin is when you set the `endpoint` like mentioned above using localhost the client that gets generated also has (at the bottom of the file) the `endpoint: `
when you try to run anything in the playground you will see that you get the `request to failed` error
in order to solve it you basically you need to change the `localhost` to the ip address that was causing the error in the `prisma deploy` command
`endpoint: http:/172.18.0.1:1234`) > **how confusing is that?!**
there is a big with `marked<=0.6.2` that has been documented [elsewhere]( and is present here: ```
project@0.0.3
prisma@1.34.1 prisma-cli-engine@1.34.1 marked@0.5.2
bug? expected? i get an error when i use the same embedded type in one type.
prisma server has an internal queuesize of concurrent request it could be processing
when this limit is hit (with high enough qps and slower queries), prisma server starts to reject new queries that it receives
once the load is reduced, prisma server should "recover" and start accepting queries again
my hypothesis is that prisma server is not able to recover once it hits the `queuesize` limit once.
i have a querie that is running well on pgadmin connecting to the same database that the prisma server is connected on pgadmin the querie returns values but when i try to run it with execute raw it does not work here is the error ```
{"key":"error/unhandled","requestid":"local:cjxzjajdf00030741cjy4qfe6","clientid":"database$dev","payload":{"exception":"scala.matcherror: 0 years 0 mons 0 days 0 hours 43 mins 47.996 secs (of class org.postgresql.util.pginterval)","query":"mutation ($_v0_query: string!) {\ executeraw(query: $_v0_query)\ }\ ","variables":"{\\"_v0_query\\":\\"select u.name, count(t.id) as total, sum(t.end - t.start) as avg_time from database$dev.\\\\\\"user\\\\\\" u left outer join database$dev.\\\\\\"_usertasks\\\\\\" ut on ut.\\\\\\"b\\\\\\" = u.id left outer join database$dev.\\\\\\"task\\\\\\" t on (ut.\\\\\\"a\\\\\\" = t.id ) group by u.name;\\"}","code":"0","stack_trace":"com.prisma.api.connector.jdbc.database.miscqueries.untypedvaluetojson(miscqueries.scala:67)\\\ com.prisma.api.connector.jdbc.database.miscqueries.$anonfun$executeraw$2(miscqueries.scala:51)\\\ com.prisma.api.connector.jdbc.database.miscqueries.$anonfun$executeraw$2$adapted(miscqueries.scala:48)\\\ scala.collection.traversablelike.$anonfun$map$1(traversablelike.scala:233)\\\ scala.collection.immutable.range.foreach(range.scala:155)\\\ scala.collection.traversablelike.map(traversablelike.scala:233)\\\ scala.collection.traversablelike.map$(traversablelike.scala:226)\\\ scala.collection.abstracttraversable.map(traversable.scala:104)\\\ com.prisma.api.connector.jdbc.database.miscqueries.$anonfun$executeraw$1(miscqueries.scala:48)\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)\\\ slick.dbio.synchronousdatabaseaction$$anon$9.run(dbioaction.scala:515)\\\ slick.dbio.synchronousdatabaseaction$$anon$9.run(dbioaction.scala:513)\\\ slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275)\\\ slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275)\\\ java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)\\\ java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)\\\ java.lang.thread.run(thread.java:748)","message":"0 years 0 mons 0 days 0 hours 43 mins 47.996 secs (of class org.postgresql.util.pginterval)"}} ```
go-client can not query connection:
error: field 'edges' of type 'useredge' must have a sub selection
when migrating to data model 1.1 from data model 1.0, the introspect method creates type definitions in the newly generated .prisma file for relational tables created on scalar [string] arrays from the data model 1.0.
prisma is throwing an error when enum is used with no migrate flag.
sometimes the following error is produced in playground as well as while running my nodejs app which interacts with a postgres database present on heroku under hobby plan.
its not possible to run updatemanyfunnels when part of `data:{}` is a connect to another `type`.
its possible to run this exact mutation when `updatemanyfunnelthemes` is replaced by `updatefunneltheme` and the appropriate `where:{}` is added.
struct generated with datamodel in snake case names will not decode
i trying to migrate my database from `heroku(server version- 1.11)` to `digital ocean(server version 1.34)`.
i did `pg_restore` and did `introspection`
the `datamodel.prisma` hence created is significantly different from my original `datamodel.prisma` for example: the `relations` are missing in each `type`
below are type college and its related type in the old `datamodel.prisma` ```
type college @model { id: id! @unique name: string shortname: string uniquename: string @unique website: string studentcalls: [collegecalls!]! @relation(name: "collegecallcollege")
type collegecalls @model { id: id! @unique college: college @relation(name: "collegecallcollege") student: user @relation(name: "collegecallstudent") year: year @relation(name: "collegecallyear") converted: boolean joined: boolean
``` relevant part from new `datamodel.prisma` after introspection ```
type college { id: id! @id createdat: datetime! @createdat name: string shortname: string uniquename: string @unique updatedat: datetime! @updatedat website: string
type collegecall @db(name: "collegecalls") { id: id! @id converted: boolean createdat: datetime! @createdat joined: boolean updatedat: datetime! @updatedat
type collegecallcollege @db(name: "_collegecallcollege") { id: id! @id a: string! @db(name: "a") b: string! @db(name: "b")
the scalar fields are fine
but how do i make the relations work?
i am getting an internal server error on deploying the following datamodel with prisma on a docker container
i saw on another issue that the bug seemed to origin from a problem of relation names so i renamed them all to be sure but it didn't solve it.
installed prisma cli using yarn pnp does not work.
when i try to import data into prisma using the .zip file obtained through `prisma export`, when it comes to updating relations it throws a series of erros that look like the one below `"failure inserting into relationtable question with ids stringidgcvalue(cjuzc7s4u03lm0869k0uk9tt2) and stringidgcvalue(cjkjgybxv002t0957fcwyh93k)
cause: deadlock detected\ detail: process 76 waits for sharelock on transaction 2676; blocked by process 75.\ process 75 waits for sharelock on transaction 2681; blocked by process 76.\ hint: see server log for query details.\ where: while updating tuple (192,3) in relation \\"question\\"",`
i have tried prisma deploy in this my database name tvd@demo has been created but table user is not created , it will throw error : ! 'econnrefused': request to failed, reason: connect econnrefused 192.168.99.100:4466 error::
ps c:\\users\\dhrumit\\desktop\\mysql-node\\helloworld> prisma deploy
creating stage demo for service tvd
deploying service `tvd` to stage `demo` to server `default` ! ! 'econnrefused': request to failed, reason: connect econnrefused 192.168.99.100:4466 get in touch if you need help:
to get more detailed output, run $ export debug="*"
trying to load a `datamodel.prisma` of 46kb in our case throws an `e2big` error
i am trying to prisma deploy , but it shows me : creating stage default for service default !
error : invalid token docker.compose.yml: ```
version: '3'
services: prisma: image: prismagraphql/prisma:1.28.3 restart: always network_mode: "host" ports: - "4466:4466" environment: prisma_config: | port: 4466 # uncomment the next line and provide the env var prisma_management_api_secret=my-secret to activate cluster security managementapisecret: thisismysupersecrettext databases: default: connector: mysql host: 192.168.56.1 port: 3306 user: root password: tfs5unmqgrzdltth migrations: true
``` prisma.yml: ````
endpoint:
datamodel: datamodel.prisma
secret: thisismysupersecrettext
```` error: ```
ps c:\\users\\dhrumit\\desktop\\mysql-node\\helloworld> prisma deploy
creating stage default for service default ! error: invalid token { "data": { "addproject": null }, "errors": [ { "locations": [ { "line": 2, "column": 9 } ], "path": [ "addproject" ], "code": 3015, "message": "invalid token", "requestid": "local:cjwg4segg00020744ebssna52" } ], "status": 200
if a type in the datamodel doesn't have the `createdat` nor `updatedat`, the generated schema exposes both in the [type]orderbyinput
and when you want to orderby `createdat_asc` for instance, it throws:
error: variable \'$orderby\' expected value of type \'userorderbyinput\' but got: "createdat_asc"
reason: enum value 'createdat_asc' is undefined in enum type 'userorderbyinput'
known values are: id_asc, id_desc, name_asc, name_desc
(line 1, column 34):
query ($where: userwhereinput, $orderby: userorderbyinput) {
i can't upgrade my private hosted server via the prisma console
i get a success message saying that the upgrade will be scheduled and run in 10 minutes but the upgrade never goes through
i have been waiting several days
anyone else have these issues? trying to upgrade from 1.24 to 1.33.
prisma server throws sqlsyntaxerrorexception on "create" mutations for types with integer id and (one or more) *relations* to other types *only*.
i'm seeing the following warning in the prisma log, and it repeats almost every minute
i've tried deploying mysql and postgres on a local machine as well as through prisma cloud ( with postgres hosted on heroku and i'm seeing the same repeating warning:
[telemetry] warning: telemetry call failed with javax.net.ssl.sslhandshakeexception: general sslengine problem
introspection crashes while intespecting a mysql database.
declaring many to many (n:m) relationships no longer work
`prisma deploy` intermittently completes successfully but no tables are created or it fails with the following error: > the migration failed and has not been performed
this is very likely not a transient issue.
> org.postgresql.util.psqlexception: error: column "gameid" referenced in foreign key constraint does not exist
when using `prisma introspect` in an existing `mysql` database after that step when i do `prisma deploy` the `graphql schema` of the server is not being updated.
naming a type `subscription` breaks ts client.
when setting up mysql through the init cli command, it creates a file with schema in the docker-compose file
however the composed docker container then throws an error saying that "schema" is only usable with postgresql, and "database" should be used for the key instead
so changing the key "schema" to "database" fixed the issue for me.
also when trying to connect to the docker service with prisma deploy, it will throw the error: `no cluster could be found for workspace \'*\' and cluster \'default\'` the docker-compose.yml file created through the cli init command, should have "database" as the key instead of "schema" when mysql is selected as the database type.
calling prisma init on existing database generates an error: "typeerror: cannot read property \'type\' of undefined"
i have a similar issue reported in issue #4252
i'm not reporting there because it is already closed
the returned error is: `not implemented: com.prisma.shared.models.typeidentifier$float$@71f30eeebsonint32{value=5042}` i've installed the prisma server in the aws fargate, following this tutorial: #deploying-a-prisma-server-to-fargate
prisma server version: 1.32.0
mongo-db version: 3.4.3 the problem is that even in some fields marked as float in the datamodel and double in db, the error is happening
### follow below the datamodel
type position { _id: id! @id ..
mtmnotional: float @db(name: "mtmnotional") ...
in the `package.json` file for `prisma-db-introspection` ( the value of the key `url` of `repository` is wrong so we can't access to the repository by clicking the link of the npm website (
i have set up a type with a self-relation (see below), with the aim to create a nested folder structure where the top item has no parent, but you can create sub-folders by providing the parent folder id ```graphql
type folder { id: id! @id name: string! parent: folder @relation(name: "folderrelation", link: inline)
`@linktable` directive was renamed to `@relationtable`
prisma cli is still generating `@linktable` when introspecting a database
![image](
cli does not throw error when deploying a field with the decorator `@id(strategy: sequence)` without a `@sequence` decorator attached.
i have a data model with the following types: ```
type event { id: id! rsvps [rsvp!]!
} type rsvp { id: id! user: user!
} type user { id: id!
``` prisma generates a query for me along with input types, so i can write: ``` events(where:{ rsvps_every: { user: { id:"abcd" } }
}) { id rsvps { id user { id } }
``` i would expect this to return a list of events that have *at least one* rsvp, where the rsvp has a user with an id matching "abcd" however, when sending this query, we something like: ```
"events": [ { "id": "1", "rsvps": [] }, { "id": "2", "rsvps": [ { "id": "4", "user": { "id": "abcd" } } ] }
``` even though an empty list of rsvps cannot match the requirement that `rsvps_every` has a user id equal to "abcd", it is returned with the query
is this expected behavior? or a bug? where can i find the documentation for the *whereinput and its expected behavior when applied to various queries?
not sure if it's a bug but also don't understand why it's happening
i've got prisma connected to my mongodb but when i make any mutations, a new database is being created in mongodb called `default_default` and data is being added there instead of the database i specified when going through the setup here here is my docker-compose.yml ```
version: '3'
services: prisma: image: prismagraphql/prisma:1.23 restart: always ports: - "4466:4466" environment: prisma_config: | port: 4466 # uncomment the next line and provide the env var prisma_management_api_secret=my-secret to activate cluster security # managementapisecret: my-secret databases: default: connector: mongo uri: \'mongodb://host.docker.internal:27017/name-of-db\'
prisma export fails as soon as the database fails to give a timely response once.
when the client composes a query on multiple unique fields, prisma generates an or query based on the passed arguments
this currently results in a single matching node being returned when the passed arguments do not match the actual outcome
i cannot filter parent by `id` in a `where` filter (see `allsubcategories`).
the prisma data models generated by `prisma introspect`are inconsistent across different projects migrated the v1.1 datamodel
everything went fine at first
this was for our main project
we are starting to build smaller projects around it
and when i tried doing `prisma introspect` in another project i received a different result
and the introspection is against the exact same configuration as in the main project and against the exact same docker container running mysql
main project:
![image]( side project:
![image]( these two commands are run exactly after each other and generate the same result when run multiple times
the important part is the difference in models generated
it also seems like relations are not caught correctly
a 1-1 relation will show up as a many to many...
i want to change my field type by 'prisma deploy --force' the previous data model definition is as follows ```
type user { id: id! @unique name: string age: int store: float is_man: boolean command: json code: string @unique
and the next data model is
type user { id: id! @unique name: string age: int store: float is_man: boolean command: json code: int @unique
i change the type of 'code' from string to integer.this will prompt a warning under normal circumstances,so i use 'prisma deploy --force' to force it.(there is currently no data in the database) then,the console told me the change was done ```
deploying service `default` to stage `default` to server `local` 100ms warnings: code ! you already have nodes for this model
this change may result in data loss
ignoring warnings because you provided --force
changes: user (type) ~ updated field `code` applying changes 1.1s your prisma graphql database endpoint is live: http: ws: ws://localhost:4466 update available 1.28.0 1.32.2 run npm i -g prisma to update ``` but in my database,i can see the status of this migration is "rollback_success"(in schema "graphcool" and table "migration"),the entire sql is shown below
insert into `migration` (`projectid`, `revision`, `schema`, `functions`, `status`, `applied`, `rolledback`, `steps`, `errors`, `startedat`, `finishedat`, `datamodel`)
values (\'default@default\', 61, \'{\\"models\\":[{\\"name\\":\\"user\\",\\"stableidentifier\\":\\"cjv24gkte005jn5026dbrtkjj\\",\\"isembedded\\":false,\\"fields\\":[{\\"name\\":\\"id\\",\\"typeidentifier\\":\\"graphqlid\\",\\"isrequired\\":true,\\"islist\\":false,\\"isunique\\":true,\\"ishidden\\":false,\\"isreadonly\\":false,\\"isautogenerated\\":false},{\\"name\\":\\"name\\",\\"typeidentifier\\":\\"string\\",\\"isrequired\\":false,\\"islist\\":false,\\"isunique\\":false,\\"ishidden\\":false,\\"isreadonly\\":false,\\"isautogenerated\\":false},{\\"name\\":\\"age\\",\\"typeidentifier\\":\\"int\\",\\"isrequired\\":false,\\"islist\\":false,\\"isunique\\":false,\\"ishidden\\":false,\\"isreadonly\\":false,\\"isautogenerated\\":false},{\\"name\\":\\"store\\",\\"typeidentifier\\":\\"float\\",\\"isrequired\\":false,\\"islist\\":false,\\"isunique\\":false,\\"ishidden\\":false,\\"isreadonly\\":false,\\"isautogenerated\\":false},{\\"name\\":\\"is_man\\",\\"typeidentifier\\":\\"boolean\\",\\"isrequired\\":false,\\"islist\\":false,\\"isunique\\":false,\\"ishidden\\":false,\\"isreadonly\\":false,\\"isautogenerated\\":false},{\\"name\\":\\"command\\",\\"typeidentifier\\":\\"json\\",\\"isrequired\\":false,\\"islist\\":false,\\"isunique\\":false,\\"ishidden\\":false,\\"isreadonly\\":false,\\"isautogenerated\\":false},{\\"name\\":\\"code\\",\\"typeidentifier\\":\\"int\\",\\"isrequired\\":false,\\"islist\\":false,\\"isunique\\":true,\\"ishidden\\":false,\\"isreadonly\\":false,\\"isautogenerated\\":false},{\\"name\\":\\"updatedat\\",\\"typeidentifier\\":\\"datetime\\",\\"isrequired\\":true,\\"islist\\":false,\\"isunique\\":false,\\"ishidden\\":true,\\"isreadonly\\":true,\\"isautogenerated\\":false},{\\"name\\":\\"createdat\\",\\"typeidentifier\\":\\"datetime\\",\\"isrequired\\":true,\\"islist\\":false,\\"isunique\\":false,\\"ishidden\\":true,\\"isreadonly\\":true,\\"isautogenerated\\":false}]}],\\"relations\\":[],\\"enums\\":[]}\', \'[]\', \'rollback_success\', 0, 0, \'[{\\"model\\":\\"user\\",\\"newmodel\\":\\"user\\",\\"name\\":\\"code\\",\\"newname\\":null,\\"discriminator\\":\\"updatefield\\"},{\\"name\\":\\"user\\",\\"newname\\":\\"user\\",\\"discriminator\\":\\"updatemodel\\"}]\', \'[\\"java.sql.sqlsyntaxerrorexception: (conn=26) duplicate key name \\\'code_unique\\\'\\\ \\\\tat org.mariadb.jdbc.internal.util.exceptions.exceptionmapper.get(exceptionmapper.java:163)\\\ \\\\tat org.mariadb.jdbc.internal.util.exceptions.exceptionmapper.getexception(exceptionmapper.java:106)\\\ \\\\tat org.mariadb.jdbc.mariadbstatement.executeexceptionepilogue(mariadbstatement.java:235)\\\ \\\\tat org.mariadb.jdbc.mariadbpreparedstatementclient.executeinternal(mariadbpreparedstatementclient.java:224)\\\ \\\\tat org.mariadb.jdbc.mariadbpreparedstatementclient.execute(mariadbpreparedstatementclient.java:159)\\\ \\\\tat com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44)\\\ \\\\tat com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java)\\\ \\\\tat slick.jdbc.statementinvoker.results(statementinvoker.scala:38)\\\ \\\\tat slick.jdbc.statementinvoker.iteratorto(statementinvoker.scala:21)\\\ \\\\tat slick.jdbc.invoker.first(invoker.scala:30)\\\ \\\\tat slick.jdbc.invoker.first$(invoker.scala:29)\\\ \\\\tat slick.jdbc.statementinvoker.first(statementinvoker.scala:15)\\\ \\\\tat slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:52)\\\ \\\\tat slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:51)\\\ \\\\tat slick.dbio.dbioaction$$anon$4.$anonfun$run$3(dbioaction.scala:239)\\\ \\\\tat scala.collection.iterator.foreach(iterator.scala:937)\\\ \\\\tat scala.collection.iterator.foreach$(iterator.scala:937)\\\ \\\\tat scala.collection.abstractiterator.foreach(iterator.scala:1425)\\\ \\\\tat scala.collection.iterablelike.foreach(iterablelike.scala:70)\\\ \\\\tat scala.collection.iterablelike.foreach$(iterablelike.scala:69)\\\ \\\\tat scala.collection.abstractiterable.foreach(iterable.scala:54)\\\ \\\\tat slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:239)\\\ \\\\tat slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:237)\\\ \\\\tat slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275)\\\ \\\\tat slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275)\\\ \\\\tat java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)\\\ \\\\tat java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)\\\ \\\\tat java.lang.thread.run(thread.java:748)\\\ caused by: java.sql.sqlexception: duplicate key name \\\'code_unique\\\'\\\ query is: alter table `default@default`.`user` add unique index `code_unique`(`code` asc)\\\ \\\\tat org.mariadb.jdbc.internal.util.logquerytool.exceptionwithquery(logquerytool.java:146)\\\ \\\\tat org.mariadb.jdbc.internal.protocol.abstractqueryprotocol.executequery(abstractqueryprotocol.java:217)\\\ \\\\tat org.mariadb.jdbc.mariadbpreparedstatementclient.executeinternal(mariadbpreparedstatementclient.java:218)\\\ \\\\t..
24 more\\\ \\"]\', \'2019-05-07 14:11:59\', \'2019-05-07 14:11:59\', \'type user {\ id: id! @unique\ name: string\ age: int\ store: float\ is_man: boolean\ command: json\ code: int @unique\ }\ \ \');
``` in prisma console( can see the type of "code" is string in the doc if i do some mutations like "createuser"
mutation{ createuser(data:{ name:"aaa" code:"this is a code" }){ id name }
``` the console will show following error
{ "data": null, "errors": [ { "message": "whoops
looks like an internal server error
search your server logs for request id: local:cjvdeh0hj004z0c02hnjk37tb", "path": [ "createuser" ], "locations": [ { "line": 2, "column": 3 } ], "requestid": "local:cjvdeh0hj004z0c02hnjk37tb" } ]
``` i spent some time reading the source code and found something beyond understanding
on line 135 of class createcolumninterpreter (package com.prisma.deploy.connector.jdbc.database)
case (_, true, _, true) => vector(updatecolumn, adduniqueconstraint)
in function "updatecolumnactions", on the basis of "type changes, after unique",prisma will update column and add unique constraint
my question is what if the old field already has a unique index(in my previous data model, the "code" field is unique),this code will definitely case "duplicate key name error" if the field name has not changed
i think the line 135 should be ```scala
case (false, true, _, true) => vector(updatecolumn, adduniqueconstraint)
``` also,there is a problem with the rollback strategy, which leads to inconsistent model definition.
the model definition rollback succeeded at the database record level, but the actual database did not roll back.
when saving a datetime field using prisma client and mongodb, the field is not saved/returned.
prisma cli is parsing regular local private urls as cloud workspace urls with the following error if you are logged in
when you are logged out it is just asking you to login:
- logged in
![image]( - logged out
![image](
we are currently facing the issue with a redeploy error throwing `"post", "field": null, "description": "you are creating a required field but there are already nodes present that would violate that constraint.` eventhough the only existing entry has all those fields filled out.
given the following: ```sql
create table public.teams ( id integer not null, scope text[] default '{}'::text[] not null,
``` the introspection algorithm will report the default as `{}` which would be an object in js/ts.
using an enum array with the directive `@scalarlist(strategy: relation)` doesn't provide a way to query based on the content of the array.
when making a query with nested `where` argument i got an empty array with prisma.
i have defined a simple data model containing `@embedded` types like this: ```
type user{ id: id! @id name: string! posts: [post]
} type post @embedded { id: id! @id text: string! comments: [comment]
} type comment @embedded{ id: id! @id text: string
``` when trying to retrieve the data using the prisma client like `prisma.users()`, only the scalar types and not the embedded types are returned.
using the uuid type for the id field in datamodel.prisma causes an error when compiling the go client.
prisma-client/prisma.go:281:6: undefined: uuid
it seems the issue is there is no scalar mapping for the uuid type
should there be a mapping from uuid to 'string', similar to the mapping for the id type? if so, it looks like this mapping is also missing from the typescript generator.
// cli/packages/prisma-client-lib/src/codegen/generators/go-client.ts
scalarmapping = { int: 'int32', string: 'string', id: 'string', float: 'float64', boolean: 'bool', datetime: 'string', json: 'map[string]interface{}', long: 'int64',
when input [json] in datamodel
the generated prisma-schema.ts does not as expected
i have the following two models: ```
type blog { id: id! @id title: string! score: int! labels: [label!]! @relation(name: "bloglabels", link: inline)
type label { id: id! @id text: string! @unique
when i tried to using pagination, sorting and filtering on `labels`, the returned results are not ordered as expected
there is something weird that happens when i do the query using a filter on a relation similar to the aggregation count bug #4422
the bug occured with mongo connector
i tried it using mysql connector and it worked fine
**to reproduce**
create the two models above.
create a label
mutation { createlabel(data: { text: "x" }) { text }
create three blogs with the label `x` & three different scores in ascending order (`blog_1`: `10`, `blog_2`: `20`, `blog_3`: `30`)
mutation { createblog(data: { title: "blog_1", score: 10, labels: { connect: { text: "x" } } }) { title }
do the query below
query { blogs(first: 2, orderby: score_desc) { title score }
the output will be (as expected)
{ "data": { "blogs": [ { "title": "blog_3", "score": 30 }, { "title": "blog_2", "score": 20 } ] }
do the query below
query { blogs(first: 2, orderby: score_desc, where:{ labels_some: { text: "x" } }) { title score }
the output will be (not expected)
{ "data": { "blogs": [ { "title": "blog_1", "score": 10 }, { "title": "blog_2", "score": 20 } ] }
getting error on prisma generate with datamodel v1.1 i had posted this to [forum three days ago]( and it's still not resolved
it's most probably related to empty many-to-many table generation
error trace: ``` customerwishlistsrelation (relation) + created an inline relation between `customer` and `customerwishlist` in the column `customer` of table `customerwishlist` applying changes 4.1s
generating schema 61ms ! ';' expected
(185:8) ! 183 | export type postsproductsrelationorderbyinput = ! 184 | ! > 185 | export type wishlistedproductsrelationorderbyinput = ! ! | ^ ! 186 | ! 187 | export type mutationtype = 'created' | ! 188 | 'updated' | get in touch if you need help:
to get more detailed output, run $ export debug="*" your prisma endpoint is live:
mutations and queries return empty `@scalarlist` if parent type uses integer `@id`.
this is the first time i'm using the aggregations api, i believe i am doing everything correctly, yet getting 0 back even though i should expect to see 1
the correct list of nodes is coming back though
this is my query: ```
query funnels { funnelsconnection(where:{ shop:{ id:"5c86a90f24aa9a0008d42d21" } archived:false }) { aggregate { count } edges { node { id } } }
``` this is the response: ```
{ "data": { "funnelsconnection": { "aggregate": { "count": 0 }, "edges": [ { "node": { "id": "5ca64a68a7b11b0009cf5687" } } ] } }
```` clearly `count` should be `1` but is coming back as `0`
not entirely sure if i'm not using the api correctly or if this is a real bug
note: even when i remove the `archived: false` flag, it still returns `0` even though there would be more than 1 node returned in that case
i only experience this issue when querying with an association.
i tried to create a type using the new datamodel v1.1: ```gql
type atomicrefnumber { id: int! @id(strategy: sequence) @sequence(name: "atomicrefnumber", initialvalue: 10000, allocationsize: 1)
``` <details>
<summary>this part is fixed already fixed</summary> note that the id field needs to be called `id`
if it's called `value` instead, the generated prisma schema would look like this: ```gql
createatomicrefnumber(data: atomicrefnumbercreateinput!): atomicrefnumber!
input atomicrefnumbercreateinput { value: int!
``` this doesn\'t look correct because the id is supposed to be generated automatically in a sequence but the "create" mutation is asking for the id
changing the id field name form `value` to `id` generates the schema as expected
</details> the generated create mutation looks like this: ```gql
createatomicrefnumber: atomicrefnumber!
``` however, when trying to perform this mutation by using either `prisma-binding` or graphql playground: ```gql
mutation { createatomicrefnumber { id }
``` => `whoops
looks like an internal server error
search your server logs for request id: us1:cjumv2n334dmk0b12fony61sx"` i\'m using the demo servers (us) so i can\'t see the logs
seems like a bug but perhaps i'm doing something wrong.
when running `prisma deploy`, the deploy process handles an error as soon as it is executed, when trying to get the projects list
this causes the deploy process to take at least 60 seconds longer than it should
the prisma-endpoint, prisma-secret and prisma-management-api-secret are correctly set, and the deploy process proceeds to finish successfully after 80+ seconds
the error `com.prisma.deploy.schema.authfailure: no 'authorization' header provided` is shown in the logs, when trying to run the `{ listprojects { name } }` query.
there should be a possibility to filter for relation based if relation exist or not
its possible to filter items with non existing relations like this: ```
prisma.organizations({ where: { consultancy : null } })
but its not possible to invert this filter e.g
filter only one where relation is set.
that`s really limiting..
[root@centos-73-64-minimal prisma]# prisma deploy environment fetcherror: request to failed, reason: connect econnrefused 127.0.0.1:4466 datamodel.prisma seems to be created correctly, does prisma support existing mysql databases yet ? i saw that this was a problem like 1 year ago, but i suppose you made it support importing from existing database since datamodel.prisma is generated and it seem that prisma init worked
seems that the docker image created with docker-compose up -d keeps restaring it-self.
i can never attach to it because it keeps restarting
error in docker-compose logs is
`prisma_1 | exception in thread "main" java.lang.runtimeexception: unable to load prisma config: com.prisma.config.invalidconfiguration: only postgres connectors specify a schema
if they do they also need to specify a database
other connectors only specify a database.
prisma_1 | at scala.sys.package$.error(package.scala:26)` if i remove the `schema` from docker-compose.yml i get another error `prisma_1 | exception in thread "main" java.lang.runtimeexception: there is not passive mysql deploy connector yet! | at scala.sys.package$.error(package.scala:26)` docker-compose.yml file with schema: ```
version: '3'
services: prisma: image: prismagraphql/prisma:1.32-alpha restart: always ports: - "4466:4466" environment: prisma_config: | port: 4466 # uncomment the next line and provide the env var prisma_management_api_secret=my-secret to activate cluster security # managementapisecret: my-secret databases: default: connector: mysql host: 176.9.44.11 user: dbusername schema: dbpassword password: \'pass\' rawaccess: true port: \'3306\' migrations: false
``` **notice mysql server is on different server** but when i run prisma init prisma the setup wizard connects to the mysql server and retrives the correct databases and i choose an existing one
[root@central ~]# mysql --version
mysql ver 14.14 distrib 5.5.45, for linux (x86_64) using readline 5.1
invalid json in json field not handled properly
`prisma init` workflow with existing mongo yields an incorrect docker file with a field called `schema` but it should be named database.
mongodb asks for schema name even if it is provided in the connection string.
running `prisma deploy` does not actually update the service, although the logging indicates that it has performed changes successfully
specifically, i'm deploying changes in my data model to an existing service
i've applied these changes locally to a prisma instance running in docker with no issue, and to my dev server (hosted in aws)
when deploying to my production server (a clone of the dev server, also in aws), the deployment _appears_ to run successfully, but then the server has not actually been updated (verified via the admin console as well as looking at the schema in playground)
there are no error messages displayed during the deployment, and each subsequent try to deploy acts as though it's running the same deployment again (as if it'd never been tried before)
even prisma cloud shows all my attempts to deploy in the deployment log, with all of the changes that should have run, as if they actually happened.
deploying a prisma service from a different folder via a cli command like `prisma deploy -p ../prisma/prisma.yml -e ../.env` will not load the env-file specified by the -e flag.
mysql does not support uuid but allows us to use that as a type on non id fields but the deployment always rolls back
docker container continuously restarting after `prisma init` using mongodb existing database.
prisma_1 | exception in thread "main" java.lang.runtimeexception: unable to load prisma config: com.prisma.config.invalidconfiguration: expected host to be non-empty
prisma_1 | at scala.sys.package$.error(package.scala:26)
prisma_1 | at com.prisma.config.configloader$.load(configloader.scala:40)
prisma_1 | at com.prisma.local.prismalocaldependencies.<init>(prismalocaldependencies.scala:48)
prisma_1 | at com.prisma.local.prismalocalmain$.delayedendpoint$com$prisma$local$prismalocalmain$1(prismalocalmain.scala:13)
prisma_1 | at com.prisma.local.prismalocalmain$delayedinit$body.apply(prismalocalmain.scala:8)
prisma_1 | at scala.function0.apply$mcv$sp(function0.scala:34)
prisma_1 | at scala.function0.apply$mcv$sp$(function0.scala:34)
prisma_1 | at scala.runtime.abstractfunction0.apply$mcv$sp(abstractfunction0.scala:12)
prisma_1 | at scala.app.$anonfun$main$1$adapted(app.scala:76)
prisma_1 | at scala.collection.immutable.list.foreach(list.scala:388)
prisma_1 | at scala.app.main(app.scala:76)
prisma_1 | at scala.app.main$(app.scala:74)
prisma_1 | at com.prisma.local.prismalocalmain$.main(prismalocalmain.scala:8)
prisma_1 | at com.prisma.local.prismalocalmain.main(prismalocalmain.scala)
the available operations don't execute in the specified order.
i use the go prisma client to determine with an example query like:
``` data, err := prismaclient.todos(&prismaclient.todosparams{ where: &prismaclient.todoswhereinput{ namein: []string{}, }, }).exec(ctx)
``` everything works correct if the array passed into namein is not empty
once its empty, it returns all objects
from my understanding prisma should return 0 objects if the in-query is empty.
i have introspected a django postgresql database with prisma and the datamodel.prisma file that has been generated cannot be deployed because all the relation fields are not specifying a @relation directive
this is the error that i get ![screen shot 2019-04-05 at 9 31 28 am]( i'm using prisma@1.30
if i have a model user and try to fetch one that does not exist, with this method: `user: (where: userwhereuniqueinput) => userpromise` typescript does not warn me that the user might be null: ```ts
const user = await prisma.user({ id: '123' }); // null
user.name // typescript does not warn me about this.
``` the generated type should be something like:
`user: (where: userwhereuniqueinput) => userpromise | promise<null>`
the init flow for existing mongodb never asks if the database is empty and always tries to introspect
it is causing the following error:
![screenshot 2019-04-03 at 7 29 12 pm](
while using `prisma introspect` on a `mysql` database faced a few problems with the `schema`
1- a few table rows are duplicated for no reason since the db schema doesn't have them duplicated, thinking that the problem might be related because of the # of relation an specific table has.
2- while executing `prisma deploy` returns a couple errors because the db schema is currently using `id` as `int` instead of the `id or uuid` type.
3- `boolean` type rows are giving us problems because our db schema uses integers instead of `true|false`.
4- the schema generated in `datamodel.prisma` has a lot of `postgres` directive like `@pgtable` and `@pgcolumn`
`prisma init` asks for schema name when working with existing postgres with data but does not print it in the `docker-compose.yml` file.
after run `prisma deploy` successfully, i can access admin ui on prisma server, but i cannot access admin ui panel locally through docker-compose.
shortly after running the prisma server it has memory leak / runaway cpu usage
it allocates up 2gigs or ram and runs at 100% cpu and is completely unresponsive
log output is below
currently running prisma server version 1.11.1 in production without issues
this error happens when attempting to upgrade to latest version 1.29.1, a similar problem also occurred when trying to upgrade to 1.14.2 a while back and kept the current version waiting for a bug fix but situation has not yet improved
i know there is not a lot of details, so hoping to get some clues to help track this one down
a [info] {} - started
a [info] {} - started
a [info] {} - close initiated..
a [info] {} - closed
a [info] obtaining exclusive agent lock..
a [info] initializing workers..
a [info] obtaining exclusive agent lock..
a [info] successfully started 1 workers
a [info] deployment worker initialization complete
a server running on :4466 a [info] {} - started
a \x1b[31m[subscriptionsessionactor] received unknown message: com.prisma.subscriptions.protocol.subscriptionprotocolv07$requests$gqlconnectionterminate$@e43b78c\x1b[0m a \x1b[31m[subscriptionsessionactor] received unknown message: com.prisma.subscriptions.protocol.subscriptionprotocolv07$requests$gqlconnectionterminate$@e43b78c\x1b[0m a \x1b[31m[subscriptionsessionactor] received unknown message: com.prisma.subscriptions.protocol.subscriptionprotocolv07$requests$gqlconnectionterminate$@e43b78c\x1b[0m a \x1b[31m[subscriptionsessionactor] received unknown message: com.prisma.subscriptions.protocol.subscriptionprotocolv07$requests$gqlconnectionterminate$@e43b78c\x1b[0m a \x1b[31m[subscriptionsessionactor] received unknown message: com.prisma.subscriptions.protocol.subscriptionprotocolv07$requests$gqlconnectionterminate$@e43b78c\x1b[0m a \x1b[31m[subscriptionsessionactor] received unknown message: com.prisma.subscriptions.protocol.subscriptionprotocolv07$requests$gqlconnectionterminate$@e43b78c\x1b[0m a \x1b[31m[subscriptionsessionactor] received unknown message: com.prisma.subscriptions.protocol.subscriptionprotocolv07$requests$gqlconnectionterminate$@e43b78c\x1b[0m a \x1b[31m[subscriptionsessionactor] received unknown message: com.prisma.subscriptions.protocol.subscriptionprotocolv07$requests$gqlconnectionterminate$@e43b78c\x1b[0m a \x1b[31m[subscriptionsessionactor] received unknown message: com.prisma.subscriptions.protocol.subscriptionprotocolv07$requests$gqlconnectionterminate$@e43b78c\x1b[0m a \x1b[31m[subscriptionsessionactor] received unknown message: com.prisma.subscriptions.protocol.subscriptionprotocolv07$requests$gqlconnectionterminate$@e43b78c\x1b[0m a \x1b[31m[subscriptionsessionactor] received unknown message: com.prisma.subscriptions.protocol.subscriptionprotocolv07$requests$gqlconnectionterminate$@e43b78c\x1b[0m a uncaught error from thread [single-server-akka.actor.default-dispatcher-23]: gc overhead limit exceeded, shutting down jvm since 'akka.jvm-exit-on-fatal-error' is enabled for actorsystem[single-server] a java.lang.outofmemoryerror: gc overhead limit exceeded a at scala.collection.immutable.hashmap$hashtriemap.updated0(hashmap.scala:363) a at scala.collection.immutable.hashmap.$plus(hashmap.scala:61) a at scala.collection.immutable.hashmap.$plus(hashmap.scala:35) a at scala.collection.mutable.mapbuilder.$plus$eq(mapbuilder.scala:29) a at scala.collection.mutable.mapbuilder.$plus$eq(mapbuilder.scala:25) a at scala.collection.traversableonce.$anonfun$tomap$1(traversableonce.scala:316) ``` docker-compose.yml
prisma: image: prismagraphql/prisma:1.29.1 container_name: prisma restart: ${restart_mode} ports: - 4466:4466 environment: prisma_config: | port: 4466 # uncomment the next line and provide the env var prisma_management_api_secret=my-secret to activate cluster security # managementapisecret: my-secret databases: default: connector: mysql active: true host: db port: 3306 user: root password: prisma managementschema: graphcool networks: - local_prisma db: image: mysql:5.7 container_name: db restart: ${restart_mode} environment: mysql_user: root mysql_root_password: prisma volumes: - ./data/db:/var/lib/mysql networks: - local_prisma
``` prisma.yml
# to disable authentication:
# disableauth: true
secret: ${env:prisma_secret} # the file path pointing to your data model
datamodel: datamodel.graphql # seed your service with initial data based on seed.graphql
seed: import: seed.graphql endpoint: ${env:prisma_endpoint} hooks: post-deploy: - echo "deployment finished" - npx graphql get-schema --project database - npx graphql prepare
import of a previous export does not work properly with the following message:
failure inserting into relationtable _codetoobj with ids stringidgcvalue(cjtflw2ilq6qp08799l21x89r) and stringidgcvalue(cjtfly6jxroq50879hp2avno8)
cause: duplicate key value violates unique constraint \\"_codetoobj_ab_unique\\"\ detail: key (\\"a\\", \\"b\\")=(cjtflw2biq6ni08798alm3tyl, cjtflwoqeqlnj0879ijz8xb29) already exists.
prisma cli is parsing regular local private urls as cloud workspace urls and deploy to any server other than localhost is broken right now with the following error if you are logged in
when you are logged out it is just asking you to login: ```
error: no cluster could be found for workspace '*' and cluster 'default' 1 # specifies the http endpoint of your prisma api
{ "data": { "generateclustertoken": null }, "errors": [ { "message": "no cluster could be found for workspace \'*\' and cluster \'default\'", "locations": [ { "line": 3, "column": 9 } ], "path": [ "generateclustertoken" ], "code": 222 } ], "status": 200
``` this is regression is introduced by the following commit: #diff-6fed8e800217d7823362a8550f1047a2r50
i'm getting an error when i try to follow the [getting started]( tutorial with my existing postgres database.
if you use last stable version or any beta 1.29 version, it doesn't work with a timestampz field
i had 1.26 prisma server version until this morning, and with this version works perfectly.
i tried to update prisma version from 1.26 to 1.27 or 1.28.
but if i updated it, database connection was refused.
i tried to make a repro environment but oddly i couldn't repro on docker-compose structure
that's only my local k8s structure.
if i downgrade prisma version to 1.26 or below, database connection become normal.
so i guess some kinda prisma updating has relation to this..
could anyone give me any solutions? - prisma config
databases: default: connector: postgres migrations: true host: postgres port: 5432 user: prisma password: prisma rawaccess: true
``` - deployment of prisma(k8s)
apiversion: extensions/v1beta1
kind: deployment
metadata: name: prisma namespace: prisma
spec: replicas: 1 strategy: {} template: spec: containers: - env: - name: prisma_config valuefrom: secretkeyref: name: prisma-config key: prisma_config image: prismagraphql/prisma:1.28 # or 1.27 name: prisma ports: - containerport: 4466 resources: {} restartpolicy: always
when a prisma client is used to fetch a type with two relation fields on different types but the promise is not immediately consumed
the generated query incorrectly nests the relation types within each other.
prisma client promise can only be consumed once which is uncommon (maybe even breaks the spec) for promises as even asynchronous promises can be consumed multiple times and once the result it available, it is immediately resolved.
deploy fails, it attempts to connecto to `postgres` database, even though i have specified an alternative database name `orqidund`.
when installing prisma via homebrew the post-deploy hook `prisma generate` fails because of a missing module.
cannot connect to a mongodb source in version 1.28 but downgrading to 1.26.5 works
one of our users seems to have identified an edge case when renaming an enum field and afterwards changing it from accepting multiple values (list) to a non-list
causing a `ava.util.nosuchelementexception: key not found:` error.
i am using mongodb with prisma
i have two types `post` and `user` and i just want to model the relationship between the two types so that one `user` can have many `post` and a `post` can only have one `user`
i create these types and when trying to query auser's posts i get back `null`.
i have this datamodel: ```graphql
type post { id: id! @unique createdat: datetime! updatedat: datetime! title: string! published: boolean! @default(value: "false") author: user comments: [comment!]!
} type user { id: id! @unique name: string email: string! @unique role: role! @default(value: "user") posts: [post!]! comments: [comment!]!
} type comment { id: id! @unique createdat: datetime! text: string! post: post! writtenby: user!
} enum role { user admin
``` for one `post` record, i have a related `comment` where there `text` is `"great work!"`
when querying that record with a relational filter for comments that uses the `text_ends_wit: "!"` filter i get an empty array: ```js
const result = await prisma .post({ id: "cjsviilj60g8y0b43bme3x8ib" }) .comments({ where: { text_ends_with: "!" } })
// result = []
``` if i remove the filter, it returns the comment: ```js
const result = await prisma .post({ id: "cjsviilj60g8y0b43bme3x8ib" }) .comments() // result:
// [ { id: 'cjsviilj90g900b434xinrr03',
// createdat: '2019-03-05t08:29:35.483z',
// text: 'great work!' } ]
we are losing nested arrays in an object.
query { [any query node] { id ..
``` returns (where "vehicle" is the node)
2019-02-24t18:50:26.183701+00:00 app[web.1]: org.postgresql.util.psqlexception: error: relation "d5jb4orrv4h617.vehicle" does not exist
2019-02-24t18:50:26.183728+00:00 app[web.1]: position: 26
2019-02-24t18:50:26.183824+00:00 app[web.1]: at org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433)
2019-02-24t18:50:26.183895+00:00 app[web.1]: at org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178)
2019-02-24t18:50:26.183966+00:00 app[web.1]: at org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306)
2019-02-24t18:50:26.184050+00:00 app[web.1]: at org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441)
2019-02-24t18:50:26.184113+00:00 app[web.1]: at org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365)
2019-02-24t18:50:26.184178+00:00 app[web.1]: at org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155)
2019-02-24t18:50:26.184258+00:00 app[web.1]: at org.postgresql.jdbc.pgpreparedstatement.executequery(pgpreparedstatement.java:118)
2019-02-24t18:50:26.184323+00:00 app[web.1]: at com.zaxxer.hikari.pool.proxypreparedstatement.executequery(proxypreparedstatement.java:52)
2019-02-24t18:50:26.184392+00:00 app[web.1]: at com.zaxxer.hikari.pool.hikariproxypreparedstatement.executequery(hikariproxypreparedstatement.java)
2019-02-24t18:50:26.184463+00:00 app[web.1]: at com.prisma.connector.shared.jdbc.sharedslickextensions.$anonfun$querytodbio$1(sharedslickextensions.scala:17)
2019-02-24t18:50:26.184528+00:00 app[web.1]: at com.prisma.connector.shared.jdbc.sharedslickextensions.$anonfun$jooqtodbio$1(sharedslickextensions.scala:56)
2019-02-24t18:50:26.184599+00:00 app[web.1]: at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)
2019-02-24t18:50:26.184662+00:00 app[web.1]: at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)
2019-02-24t18:50:26.184724+00:00 app[web.1]: at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275)
2019-02-24t18:50:26.184790+00:00 app[web.1]: at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275)
2019-02-24t18:50:26.184850+00:00 app[web.1]: at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)
2019-02-24t18:50:26.184911+00:00 app[web.1]: at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)
2019-02-24t18:50:26.184974+00:00 app[web.1]: at java.lang.thread.run(thread.java:748)
2019-02-24t18:50:26.195753+00:00 app[web.1]: {"key":"error/unhandled","requestid":"local:cjsj9qb3900060841gyzn55im","clientid":"wk_v2_server$dev","payload":{"exception":"org.postgresql.util.psqlexception: error: relation \\"d5jb4orrv4h617.vehicle\\" does not exist\ position: 26","query":"{\ vehicles {\ id\ }\ }\ ","variables":"{}","code":"0","stack_trace":"org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433)\\\ org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178)\\\ org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306)\\\ org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441)\\\ org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365)\\\ org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155)\\\ org.postgresql.jdbc.pgpreparedstatement.executequery(pgpreparedstatement.java:118)\\\ com.zaxxer.hikari.pool.proxypreparedstatement.executequery(proxypreparedstatement.java:52)\\\ com.zaxxer.hikari.pool.hikariproxypreparedstatement.executequery(hikariproxypreparedstatement.java)\\\ com.prisma.connector.shared.jdbc.sharedslickextensions.$anonfun$querytodbio$1(sharedslickextensions.scala:17)\\\ com.prisma.connector.shared.jdbc.sharedslickextensions.$anonfun$jooqtodbio$1(sharedslickextensions.scala:56)\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)\\\ slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275)\\\ slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275)\\\ java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)\\\ java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)\\\ java.lang.thread.run(thread.java:748)","message":"error: relation \\"d5jb4orrv4h617.vehicle\\" does not exist\ position: 26"}}
when i try to query a connection type query with version 1.27 and use the 'before' or 'after' argument, prisma throws an internal server error
when downgrading prisma server to 1.26.4 it works correctly.
i am encountering an issue i am having a little trouble pinpointing
after updating to 1.27.0 i started having the issue described below
i tried to upgrade to the 1.28.0-beta and still encountered the same issue
i tried to roll back to 1.26.4 and i now have the issue below on that version
**docker file**
version: '3'
services: prisma: image: prismagraphql/prisma:1.28-beta restart: always ports: - "4466:4466" environment: prisma_config: | port: 4466 databases: default: connector: postgres host: removed port: 5432 database: removed schema: public user: removed password: removed migrations: true
``` **prisma.yml**
endpoint:
datamodel: - schemas/system.prisma - schemas/user.prisma
secret: removed
hooks: post-deploy: - prisma generate
generate: - generator: typescript-client output: ../src/generated/prisma-client/
``` **console log of docker container**
recreating removed ..
attaching to removed
prisma_1 | no log level set, defaulting to info.
prisma_1 | [info] obtaining exclusive agent lock...
prisma_1 | [info] initializing workers...
prisma_1 | [info] successfully started 1 workers.
prisma_1 | server running on :4466
prisma_1 | [info] obtaining exclusive agent lock..
successful.
prisma_1 | [info] deployment worker initialization complete.
prisma_1 | [warning] management authentication is disabled
enable it in your prisma config to secure your server.
prisma_1 | [debug] initializing deployment worker for default$default
prisma_1 | [debug] scheduling deployment for project default$default
prisma_1 | encountered exception while applying migration
rolling back
org.postgresql.util.psqlexception: error: relation "public.releasenote" does not exist
prisma_1 | org.postgresql.util.psqlexception: error: relation "public.releasenote" does not exist
prisma_1 | at org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433)
prisma_1 | at org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178)
prisma_1 | at org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306)
prisma_1 | at org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441)
prisma_1 | at org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365)
prisma_1 | at org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155)
prisma_1 | at org.postgresql.jdbc.pgpreparedstatement.execute(pgpreparedstatement.java:144)
prisma_1 | at slick.jdbc.statementinvoker.results(statementinvoker.scala:38)
prisma_1 | at slick.jdbc.statementinvoker.iteratorto(statementinvoker.scala:21)
prisma_1 | at slick.jdbc.invoker.first(invoker.scala:30)
prisma_1 | at slick.jdbc.invoker.first$(invoker.scala:29)
prisma_1 | at slick.jdbc.statementinvoker.first(statementinvoker.scala:15)
prisma_1 | at slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:52)
prisma_1 | at slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:51)
prisma_1 | at slick.dbio.dbioaction$$anon$4.$anonfun$run$3(dbioaction.scala:239)
prisma_1 | at scala.collection.iterator.foreach(iterator.scala:937)
prisma_1 | at scala.collection.iterator.foreach$(iterator.scala:937)
prisma_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1425)
prisma_1 | at scala.collection.iterablelike.foreach(iterablelike.scala:70)
prisma_1 | at scala.collection.iterablelike.foreach$(iterablelike.scala:69)
prisma_1 | at scala.collection.abstractiterable.foreach(iterable.scala:54)
prisma_1 | at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:239)
prisma_1 | at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:237)
prisma_1 | at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275)
prisma_1 | at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275)
prisma_1 | at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)
prisma_1 | at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)
prisma_1 | at java.lang.thread.run(thread.java:748)
prisma_1 | [debug] applied migration for project default$default
prisma_1 | [debug] scheduling deployment for project default$default
prisma_1 | encountered exception while applying migration
rolling back
org.postgresql.util.psqlexception: error: relation "public.releasenote" does not exist
prisma_1 | org.postgresql.util.psqlexception: error: relation "public.releasenote" does not exist
prisma_1 | at org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433)
prisma_1 | at org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178)
prisma_1 | at org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306)
prisma_1 | at org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441)
prisma_1 | at org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365)
prisma_1 | at org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155)
prisma_1 | at org.postgresql.jdbc.pgpreparedstatement.execute(pgpreparedstatement.java:144)
prisma_1 | at slick.jdbc.statementinvoker.results(statementinvoker.scala:38)
prisma_1 | at slick.jdbc.statementinvoker.iteratorto(statementinvoker.scala:21)
prisma_1 | at slick.jdbc.invoker.first(invoker.scala:30)
prisma_1 | at slick.jdbc.invoker.first$(invoker.scala:29)
prisma_1 | at slick.jdbc.statementinvoker.first(statementinvoker.scala:15)
prisma_1 | at slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:52)
prisma_1 | at slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:51)
prisma_1 | at slick.dbio.dbioaction$$anon$4.$anonfun$run$3(dbioaction.scala:239)
prisma_1 | at scala.collection.iterator.foreach(iterator.scala:937)
prisma_1 | at scala.collection.iterator.foreach$(iterator.scala:937)
prisma_1 | at scala.collection.abstractiterator.foreach(iterator.scala:1425)
prisma_1 | at scala.collection.iterablelike.foreach(iterablelike.scala:70)
prisma_1 | at scala.collection.iterablelike.foreach$(iterablelike.scala:69)
prisma_1 | at scala.collection.abstractiterable.foreach(iterable.scala:54)
prisma_1 | at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:239)
prisma_1 | at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:237)
prisma_1 | at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275)
prisma_1 | at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275)
prisma_1 | at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)
prisma_1 | at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)
prisma_1 | at java.lang.thread.run(thread.java:748)
prisma_1 | [debug] applied migration for project default$default
``` **prisma deploy output**
> "c:\\program files (x86)\\yarn\\bin\\yarn.cmd" run prisma:deploy
yarn run v1.13.0
$ cd prisma && prisma deploy deploying service `default` to stage `default` to server `local`..
10.2s changes: releasenote (type) + created field `updatedat` of type `datetime!` + created field `createdat` of type `datetime!` user (type) + created field `updatedat` of type `datetime!` + created field `createdat` of type `datetime!` userprofessional (type) + created field `updatedat` of type `datetime!` + created field `createdat` of type `datetime!` userprofessionalspecialties (type) + created field `updatedat` of type `datetime!` + created field `createdat` of type `datetime!` userprofessionallanguages (type) + created field `updatedat` of type `datetime!` + created field `createdat` of type `datetime!` userprofessionaleducation (type) + created field `updatedat` of type `datetime!` + created field `createdat` of type `datetime!` userprofessionalemployment (type) + created field `updatedat` of type `datetime!` + created field `createdat` of type `datetime!` userprofessionalotherexp (type) + created field `updatedat` of type `datetime!` + created field `createdat` of type `datetime!` userprofessionalcustomer (type) + created field `updatedat` of type `datetime!` + created field `createdat` of type `datetime!` userpaymentinformation (type) + created field `updatedat` of type `datetime!` + created field `createdat` of type `datetime!` applying changes..
applying changes..
12.2s post-deploy: running prisma generate..
generating schema..
saving prisma client (typescript) at c:\\users\\itgfr\\webstormprojects\ emoved\\src\\generated\\prisma-client\\ running prisma generate..
your prisma graphql database endpoint is live: http: ws: ws://localhost:4466 done in 29.50s
process finished with exit code 0 at 02:35:48.
execution time: 29,832 ms.
on execution of `prisma deploy`, the cli responds with `error: token is issued in the future (iat).`
i have introspected a django postgresql database with prisma and the datamodel.prisma file that has been generated cannot be deployed because all the @relation names have been generated with underscores _ which makes them invalid
shouldn\'t the introspect command generate valid @relation names? any workaround for this? ![code]( <img width="1343" alt="screen shot 2019-02-21 at 5 58 55 pm" src=" ">
if we cancel prisma init workflow using ctrl+c, a directory is still created, which should not be the case
duplicate variable name for `$where` when querying an array field that references a type.
error: graphql error: graphql: there can be only one variable named 'where'
(line 1, column 12):
query call($where: userwhereinput, $where: callwhereuniqueinput!) { ^ (line 1, column 36):
query call($where: userwhereinput, $where: callwhereuniqueinput!) { ^
after successful existing database setup and running `docker-compose up -d`, the logs on the container generated show the following error a couple of times: ```
exception in thread "main" org.postgresql.util.psqlexception: error: no schema has been selected to create in position: 35 at org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433) at org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178) at org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306) at org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441) at org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365) at org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155) at org.postgresql.jdbc.pgpreparedstatement.execute(pgpreparedstatement.java:144) at com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44) at com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java) at slick.jdbc.statementinvoker.results(statementinvoker.scala:38) at slick.jdbc.statementinvoker.iteratorto(statementinvoker.scala:21) at slick.jdbc.invoker.first(invoker.scala:30) at slick.jdbc.invoker.first$(invoker.scala:29) at slick.jdbc.statementinvoker.first(statementinvoker.scala:15) at slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:52) at slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:51) at slick.dbio.dbioaction$$anon$4.$anonfun$run$3(dbioaction.scala:239) at scala.collection.iterator.foreach(iterator.scala:929) at scala.collection.iterator.foreach$(iterator.scala:929) at scala.collection.abstractiterator.foreach(iterator.scala:1417) at scala.collection.iterablelike.foreach(iterablelike.scala:71) at scala.collection.iterablelike.foreach$(iterablelike.scala:70) at scala.collection.abstractiterable.foreach(iterable.scala:54) at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:239) at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:237) at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275) at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
`prisma import --data export.zip` fails to correctly insert list of strings on most entities even though the data is provided in the `.zip` file on all entities
below you will find a `prisma.zip` which holds the schema / `prisma.yaml` as well as the `export.zip` of the project
[prisma.zip](
[export.zip](
when using `prisma init`, i select `use ssl? (y/n)` with `y` and it is ignored (does not add `ssl: true` to the dockerfile).
prisma cli doesn't resolve an object which is in a relation with another one.
the prisma server always creating new mongodb database when i deploy my service, it is not using the existing database.
naming a type in the database schema with a starting lowercase letter results in an "internal server error" message from the prisma cli when running `prisma deploy` with a cryptic `java.util.nosuchelementexception` error in the server logs if any implicit relations exist in the schema
lack of a clear error message resulted in hours of investigation/debugging.
the `prisma introspect` with and without `-i` option doesn't work
i started my prisma project two weeks ago, and it was working as expected on 1.25.x version, now in 1.26.3 not.
using create as an array for embedded type is throwing an error when they are included in the selection set of the mutation
strangely the data is correctly inserted in the database
this also happens when we try to query them
here is the log for the error: ```json
{"key":"error/unhandled","requestid":"local:cjrng6fmu004r0802xuj5bd3y","clientid":"default_default","payload":{"exception":"java.util.nosuchelementexception: key not found: url","query":"mutation {\ createmealplan(data: {subtotal: 123, tax: 123, total: 1234, isarchived: false, isdelivered: false, mealplanuser: {create: {firstname: \\"pantharshit\\", lastname: \\"asdf\\", email: \\"asdf\\", mobilenumber: \\"asdf\\", avatar: \\"ads\\"}}, menuitem: {create: {name: \\"asd\\", description: \\"asd\\", noningredients: {create: [{name: \\"asd\\", amount: \\"asd\\"}]}, image: {create: [{name: \\"adsw\\", url: \\"asd\\"}]}}}, paymentmethod: {create: {paymenttype: \\"asd\\", amountpaid: \\"asd\\", transactionid: \\"asd\\"}}}) {\ id\ menuitem {\ image {\ name\ url\ }\ }\ }\ }\ ","variables":"{}","code":"0","stack_trace":"scala.collection.immutable.map$map1.apply(map.scala:108)\\\ com.prisma.api.schema.objecttypebuilder.maptooutputresolve(objecttypebuilder.scala:214)\\\ com.prisma.api.schema.objecttypebuilder.$anonfun$mapclientfield$1(objecttypebuilder.scala:109)\\\ sangria.execution.resolver.resolvefield(resolver.scala:1024)\\\ sangria.execution.resolver.$anonfun$collectactionspar$1(resolver.scala:445)\\\ scala.collection.traversableonce.$anonfun$foldleft$1(traversableonce.scala:157)\\\ scala.collection.traversableonce.$anonfun$foldleft$1$adapted(traversableonce.scala:157)\\\ scala.collection.iterator.foreach(iterator.scala:929)\\\ scala.collection.iterator.foreach$(iterator.scala:929)\\\ scala.collection.abstractiterator.foreach(iterator.scala:1417)\\\ scala.collection.iterablelike.foreach(iterablelike.scala:71)\\\ scala.collection.iterablelike.foreach$(iterablelike.scala:70)\\\ scala.collection.abstractiterable.foreach(iterable.scala:54)\\\ scala.collection.traversableonce.foldleft(traversableonce.scala:157)\\\ scala.collection.traversableonce.foldleft$(traversableonce.scala:155)\\\ scala.collection.abstracttraversable.foldleft(traversable.scala:104)\\\ sangria.execution.resolver.collectactionspar(resolver.scala:439)\\\ sangria.execution.resolver.resolvevalue(resolver.scala:899)\\\ sangria.execution.resolver.$anonfun$resolvevalue$1(resolver.scala:820)\\\ scala.collection.traversablelike.$anonfun$map$1(traversablelike.scala:234)\\\ scala.collection.iterator.foreach(iterator.scala:929)\\\ scala.collection.iterator.foreach$(iterator.scala:929)\\\ scala.collection.abstractiterator.foreach(iterator.scala:1417)\\\ scala.collection.iterablelike.foreach(iterablelike.scala:71)\\\ scala.collection.iterablelike.foreach$(iterablelike.scala:70)\\\ scala.collection.abstractiterable.foreach(iterable.scala:54)\\\ scala.collection.traversablelike.map(traversablelike.scala:234)\\\ scala.collection.traversablelike.map$(traversablelike.scala:227)\\\ scala.collection.abstracttraversable.map(traversable.scala:104)\\\ sangria.execution.resolver.resolvevalue(resolver.scala:819)\\\ sangria.execution.resolver.resolvevalue(resolver.scala:807)\\\ sangria.execution.resolver.$anonfun$resolveactionspar$4(resolver.scala:518)\\\ scala.collection.traversablelike.$anonfun$map$1(traversablelike.scala:234)\\\ scala.collection.iterator.foreach(iterator.scala:929)\\\ scala.collection.iterator.foreach$(iterator.scala:929)\\\ scala.collection.abstractiterator.foreach(iterator.scala:1417)\\\ scala.collection.iterablelike.foreach(iterablelike.scala:71)\\\ scala.collection.iterablelike.foreach$(iterablelike.scala:70)\\\ scala.collection.abstractiterable.foreach(iterable.scala:54)\\\ scala.collection.traversablelike.map(traversablelike.scala:234)\\\ scala.collection.traversablelike.map$(traversablelike.scala:227)\\\ scala.collection.abstracttraversable.map(traversable.scala:104)\\\ sangria.execution.resolver.resolveactionspar(resolver.scala:512)\\\ sangria.execution.resolver.resolvevalue(resolver.scala:901)\\\ sangria.execution.resolver.resolvevalue(resolver.scala:807)\\\ sangria.execution.resolver.$anonfun$resolveactionspar$13(resolver.scala:609)\\\ scala.concurrent.future.$anonfun$flatmap$1(future.scala:302)\\\ scala.concurrent.impl.promise.$anonfun$transformwith$1(promise.scala:37)\\\ scala.concurrent.impl.callbackrunnable.run(promise.scala:60)\\\ akka.dispatch.batchingexecutor$abstractbatch.processbatch(batchingexecutor.scala:55)\\\ akka.dispatch.batchingexecutor$blockablebatch.$anonfun$run$1(batchingexecutor.scala:91)\\\ scala.runtime.java8.jfunction0$mcv$sp.apply(jfunction0$mcv$sp.java:12)\\\ scala.concurrent.blockcontext$.withblockcontext(blockcontext.scala:81)\\\ akka.dispatch.batchingexecutor$blockablebatch.run(batchingexecutor.scala:91)\\\ akka.dispatch.taskinvocation.run(abstractdispatcher.scala:40)\\\ akka.dispatch.forkjoinexecutorconfigurator$akkaforkjointask.exec(forkjoinexecutorconfigurator.scala:43)\\\ akka.dispatch.forkjoin.forkjointask.doexec(forkjointask.java:260)\\\ akka.dispatch.forkjoin.forkjoinpool$workqueue.runtask(forkjoinpool.java:1339)\\\ akka.dispatch.forkjoin.forkjoinpool.runworker(forkjoinpool.java:1979)\\\ akka.dispatch.forkjoin.forkjoinworkerthread.run(forkjoinworkerthread.java:107)","message":"key not found: url"}}
currently, if you use embedded types with typescript typings, the typings for that embedded type gets generated as `<t= fragmentablearray<s>>() => t`
if you wanna call this promise it throws an error, cause the embedded type isnt a function
example datamodel: ```
type user { firstname: string! lastname: string! email: string! @unique password: string isadmin: boolean @default(value: false) id: id! @id
} enum userpermission { read write delete
} type areaaccess @embedded { userid: id! @db(name: "user") permission: userpermission!
} type area { name: string! id: id! @id updatedat: datetime createdat: datetime accesses: [areaaccess!]!
``` generated area interface: ```
export interface area { name: string id: id_output updatedat?: datetimeoutput createdat?: datetimeoutput accesses?: <t = fragmentablearray<areaaccess>>() => t
the prisma demo servers are throwing an error when we migrate an `int` field to a `float` and try to insert data in it.
i have an issue where i try to create and connect an object (`company`) to its associated `user`, but the actual insert in the db function attempts to insert a blank `store` which is owned by a `company`
my datamodel.prisma looks like this: ```
type account @pgtable(name: "account") { id: int! @id @unique email: string! @unique username: string! @unique stores: [store!]! companies: [company!]!
} type company @pgtable(name: "company") { id: int! @id @unique name: string stores: [store!]! user: account @pgrelation(column: "userid")
} type store @pgtable(name: "store") { id: int! @id @unique storeid: string! company: company @pgrelation(column: "companyid") user: account @pgrelation(column: "userid")
``` each user can have multiple companies, and each company can have multiple stores
to simplify querying, i also associate the stores with the user
this datamodel was created with `prisma intropect`
the issue is when i try to create a new company (`user.sub` is the user's id): ```
createcompany: (parent, args, ctx: context) => { const user = getuser(ctx); return ctx.prisma.createcompany({ ...args.company, // includes 'name' user: { connect: { id: user.sub } }, // error occurs when this is added });
``` if i try to associate the user's id with the company, then the `createcompany` try's to also create an empty `store`
this fails, because i have contraints on my db which disallow a blank store (`name`)
if however, i leave the connect property out, then the company is created with no issues (except it is not associated to a user - not wanted)
here is the error i recieve in my docker contaier: ```
{"key":"error/unhandled","requestid":"local:cjrk2gfs400440747axvo9c1v","clientid":"default$default","payload":{"exception":"org.postgresql.util.psqlexception: error: null value in column \\"storeid\\" violates not-null constraint\ detail: failing row contains (8, null, null, null, null, null, null, null, t, null, null, null, null, null, 10, 1).","query":"mutation ($data: companycreateinput!) {\ createcompany(data: $data) {\ id\ name\ }\ }\ ","variables":"{\\"data\\":{\\"name\\":\\"company1\\",\\"user\\":{\\"connect\\":{\\"id\\":1}}}}","code":"0","stack_trace":"org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433)\\\ org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178)\\\ org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306)\\\ org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441)\\\ org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365)\\\ org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155)\\\ org.postgresql.jdbc.pgpreparedstatement.execute(pgpreparedstatement.java:144)\\\ com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44)\\\ com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java)\\\ com.prisma.connector.shared.jdbc.sharedslickextensions.$anonfun$inserttodbio$1(sharedslickextensions.scala:43)\\\ com.prisma.connector.shared.jdbc.sharedslickextensions.$anonfun$inserttodbio$1$adapted(sharedslickextensions.scala:43)\\\ com.prisma.connector.shared.jdbc.sharedslickextensions.$anonfun$jooqtodbio$1(sharedslickextensions.scala:62)\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)\\\ slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275)\\\ slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275)\\\ java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)\\\ java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)\\\ java.lang.thread.run(thread.java:748)","message":"error: null value in column \\"storeid\\" violates not-null constraint\ detail: failing row contains (8, null, null, null, null, null, null, null, t, null, null, null, null, null, 10, 1)."}}
[bugsnag - local / testing] error report: com.bugsnag.report@341ab027
at com.prisma.connector.shared.jdbc.sharedslickextensions.$anonfun$inserttodbio$1$adapted(sharedslickextensions.scala:43)
at com.prisma.connector.shared.jdbc.sharedslickextensions.$anonfun$jooqtodbio$1(sharedslickextensions.scala:62)
at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)
at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)
at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275)
at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275)
at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)
at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)
at java.lang.thread.run(thread.java:748)
org.postgresql.util.psqlexception: error: null value in column "storeid" violates not-null constraint detail: failing row contains (8, null, null, null, null, null, null, null, t, null, null, null, null, null, 10, 1).
at org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433)
at org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178)
at org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306)
at org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441)
at org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365)
at org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155)
at org.postgresql.jdbc.pgpreparedstatement.execute(pgpreparedstatement.java:144)
at com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44)
at com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java)
at com.prisma.connector.shared.jdbc.sharedslickextensions.$anonfun$inserttodbio$1(sharedslickextensions.scala:43)
at com.prisma.connector.shared.jdbc.sharedslickextensions.$anonfun$inserttodbio$1$adapted(sharedslickextensions.scala:43)
at com.prisma.connector.shared.jdbc.sharedslickextensions.$anonfun$jooqtodbio$1(sharedslickextensions.scala:62)
at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)
at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)
at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275)
at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275)
at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)
at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)
at java.lang.thread.run(thread.java:748)
i have a one to many relationship set up for user permissions to users
when i query the users for their permissions it works fine however when i query user permissions for the users it returns null.
npm package points to ` `
when using the prisma generated graphql schema and go client with graph-gophers, i receive the error message
```the error in question is "panic: field "where": field "idin": []string is not a pointer``` here is my datamodel.prisma
type user { id: id! @unique email: string! @unique password: string! displayname: string! createdat: datetime! updatedat: datetime! needstoresetpassword: boolean @default(value: false) spaces: [space!] courses: [course!]
} type space { id: id! @unique name: string! @unique description: string! inviteonly: boolean @default(value: false) users: [user!]
the go client contains the following for spacewhereinput: ```go
type spacewhereinput struct { id *string `json:"id,omitempty"` idnot *string `json:"id_not,omitempty"` idin []string `json:"id_in,omitempty"` idnotin []string `json:"id_not_in,omitempty"` ..
usersnone *userwhereinput `json:"users_none,omitempty"` and []spacewhereinput `json:"and,omitempty"` or []spacewhereinput `json:"or,omitempty"` not []spacewhereinput `json:"not,omitempty"`
the generated graphql files has following user definition
type user { id: id! email: string! password: string! displayname: string! createdat: datetime! updatedat: datetime! needstoresetpassword: boolean spaces(where: spacewhereinput, orderby: spaceorderbyinput, skip: int, after: string, before: string, first: int, last: int): [space!] courses(where: coursewhereinput, orderby: courseorderbyinput, skip: int, after: string, before: string, first: int, last: int): [course!]
the error appears when implementing a resolver for the users field, specifically in the where input of the resolver i was able to resolve the issue by changing the go client code to the following
type spacewhereinput struct { id *string `json:"id,omitempty"` idnot *string `json:"id_not,omitempty"` idin *[]string `json:"id_in,omitempty"` idnotin *[]string `json:"id_not_in,omitempty"` ..
usersnone *userwhereinput `json:"users_none,omitempty"` and *[]spacewhereinput `json:"and,omitempty"` or *[]spacewhereinput `json:"or,omitempty"` not *[]spacewhereinput `json:"not,omitempty"`
``` however, since this is generated code, this is not the correct way to solve this issue, so i've elected to not use the generated graphql schemas
is there a reason the arrays are not pointers?
subscription with or not working
on renaming a type with mysql connector using the `@rename` directive, a table is generated incorrectly in the migrations table.
all method chaining with prisma client now produce a bug
gives an error:
`project not found: 'project$stage%7d'`
a second-degree relation onto embedded documents only works if the relation is stored as an array on the object also retaining the embedded document
querying the related document fails with an exception on the graphql `whoops
looks like an internal server error
search your server logs for request id: local:cjr4nehzg00 ` the prisma stacktrace tells: `java.util.nosuchelementexception: key not found: street` see the two schemas below.
cannot deploy to prisma cluster hosted in prisma cloud
connection to database error: "no primary found in replicaset or invalid replica set name"
`prisma generate` will throw an error if there are no other fields than id in the datamodel
type test{ id: id! @unique
``` generating a client from this datamodel will result in an error:
```sh typeerror: cannot read property 'type' of undefined at typescriptgenerator.renderfieldtype (c:\\users\\scott\\appdata\ oaming\ pm\ ode_modules\\prisma\ ode_modules\\prisma-client-lib\\src\\codegen\\typescript-client.ts:607:13) at typescriptgenerator.renderinputfieldtypehelper (c:\\users\\scott\\appdata\ oaming\ pm\ ode_modules\\prisma\ ode_modules\\prisma-client-lib\\src\\codegen\\typescript-client.ts:430:17) at typescriptgenerator.renderargs (c:\\users\\scott\\appdata\ oaming\ pm\ ode_modules\\prisma\ ode_modules\\prisma-client-lib\\src\\codegen\\typescript-client.ts:402:53) at c:\\users\\scott\\appdata\ oaming\ pm\ ode_modules\\prisma\ ode_modules\\prisma-client-lib\\src\\codegen\\typescript-client.ts:454:44 at array.map (<anonymous>) at typescriptgenerator.rendermainmethodfields (c:\\users\\scott\\appdata\ oaming\ pm\ ode_modules\\prisma\ ode_modules\\prisma-client-lib\\src\\codegen\\typescript-client.ts:452:8) at typescriptgenerator.rendermutations (c:\\users\\scott\\appdata\ oaming\ pm\ ode_modules\\prisma\ ode_modules\\prisma-client-lib\\src\\codegen\\typescript-client.ts:312:17) at typescriptgenerator.render (c:\\users\\scott\\appdata\ oaming\ pm\ ode_modules\\prisma\ ode_modules\\prisma-client-lib\\src\\codegen\\typescript-client.ts:179:28) at genereatecommand.<anonymous> (c:\\users\\scott\\appdata\ oaming\ pm\ ode_modules\\prisma\ ode_modules\\prisma-cli-core\\src\\commands\\generate\\generate.ts:181:28)
``` it is mainly caused by #l607
there should be check for nullability there.
prisma cli outputs wrong information when performing migrations with mongodb
with the following datamodel: ```graphql
type user { sessions: [session!]! @relation(name: "usertosessions", ondelete: cascade) ...
} type session { user: user! @relation(name: "usertosessions") ...
``` why is "sessions" field on type "user" nullable in the resulting prisma api?
type user {
sessions(...): [session!]
``` i've checked multiple cases, this effect always persists in one-to-many relations
the one-to-many relation field is always nullable, regardless of whether it is marked as nullable or non-nullable in the datamodel
thanks in advance!
introspection doesn't work when using `prisma init` with an existing postgresql db
prisma deploy demo server gives `network error: unexpected token < in json at position 0`
i am seeing this bug again in the (al)most recent version of prisma (1.23.2)
getting an internal server error when attempting to connect a node which already exists.
all the deployments on the prisma cloud and my local docker instances of prisma have stopped working.
when using uuid instead of id, disconnect silently fails to disconnect and remove the relationship between entities
i believe it's a feature to silently fail, but it should be able to remove ids which exist.
querying fields with `id_contains`, `id_ends_with`, `id_starts_with`, `id_not_contains`, `id_not_ends_with`, `id_not_starts_with` is not working as expected
given an id `5c2eb7d56344590009c22341`, this query returns an empty array
{ users(where: {id_ends_with: "c22341" }) { id }
``` it is only happening with id, the rest of the fields are returning the expected results.
in the prisma client, when using `null` as the criteria in a `where` filter, corresponding records aren't fetched.
i have followed the documentation to setup the prisma binding for graphql mongodb for go
there is a line missing from the generated prisma-client/prisma.go
when i try a subscription in the playground, i get the following `{ "error": "could not connect to websocket endpoint wss://my-heroku-instance.herokuapp.com/server-prisma-heroku/dev
please check if the endpoint url is correct."
}` my queries and mutations are working fine at the same endpoint.
what could be the issue for subscriptions?
the error `error: the provided database doesn't contain any collection
please either provide another database or choose "no" for "does your database contain existing data?"` will pop out even though i selected `no` as the option
creating two users via [this mutation]( (that uses [this schema]( ```
mutation { user1: createuser ( data: { firstname: "alice", lastname: "jones", email: "alice@example.com", hash: "xxxx", posts: { create: [ {headline: "a" topic: discussion}, {headline: "b" topic: help}, {headline: "c" topic: discussion}, {headline: "d" topic: help} ] }, } ) { id } user2: createuser ( data: { firstname: "bob", lastname: "smith", email: "bob@example.com", hash: "yyyy", posts: { create: [ {headline: "x" topic: discussion}, {headline: "y" topic: help}, {headline: "z" topic: discussion}, ] }, } ) { id }
``` note that in the schema, the `email` field of `user` is unique but in the mutation query, the email fields for the two users are unique
also, this error does not occur if we delete the second `createuser`.
i am getting an **`internal server error` on deploying this very simple datamodel with prisma demo cloud (no docker)**
i have zeroed-down bug to this piece of sdl reproduction
i assumed that it could be due to downtime with prisma cloud itself, and then tried to connect to my aws rds instance with docker in local setting
this was also giving me a deployment error, where docker logs say: `java.util.nosuchelementexception: none.get`
see this issue in full detail, that i asked in the forum [here](
`@relation` name args value is generated against the shape [a-z][a-za-z0-9]* after prisma introspect
it shows the error during deploy after introspect.
golang client generates float32 for float type, but [graphql.org]( #scalar-types) defines float as double-precision, so the correct is float64
can't set to null a nullable field using golang client
i'm following the tutorial on howtographql
when i `prisma deploy` i get the following error message in chromium (70.0.3538.77) : `failed to load resource: net::err_timed_out` followed by : `cannot read property 'setpublishablekey' of undefined`
in billinginformationhoc.tsx, line 12
in firefox (63.0.3) : `network error: json.parse: unexpected character at line 1 column 1 of the json data`
i used prisma init to create a basic docker-compose file and basic settings
docker-compose up fails
scripts seem to be out of sync
**postgres_1 | 2018-12-16 19:33:49.954 utc [1] fatal: database files are incompatible with server**
**postgres_1 | 2018-12-16 19:33:49.954 utc [1] detail: the data directory was initialized by postgresql version 10, which is not compatible with this version 11.1 (debian 11.1-1.pgdg90+1).** this documentation could be out of date or perhaps someone didn't create a tag for latest?
when there is a reference column to type uuid is set to null (on purpose), a null pointer exception is throws from prisma
cannot query multiple records with relational fields in the `where` condition
i'm trying to create a prisma service using my newly created sql prisma server but everytime i run `prisma deploy` it gives me this error (i connected to my self hosted gcp sql server)
sdl in different order will cause different behavior
i have a model like
type posts @pgtable(name: "posts") { id: int! @unique ..
member: members @pgrelation(column: "member_id") ...
} type members @pgtable(name: "members") { id: int! @unique ..
posts: [posts!]! ...
``` it is a bidirectional direct 1-n relation
when members is above
{ members(where: {id: xxx}) { posts { id } }
will use another table post_comments as relation table
and give wrong result.
even specify @relation(name: xxx)
select "alias"."id", "relationtable"."post_id" as "__relatedmodel__", "relationtable"."member_id" as "__parentmodel__"
from "public"."posts" as "alias"
join "public"."post_comments" as "relationtable" on "alias"."id" = "relationtable"."post_id"
where "relationtable"."member_id" in ($1)
order by "relationtable"."post_id" asc;
``` but if posts is above it work fine.
select "alias"."id", "relationtable"."id" as "__relatedmodel__", "relationtable"."member_id" as "__parentmodel__"
from "public"."posts" as "alias"
join "public"."posts" as "relationtable" on "alias"."id" = "relationtable"."id"
where "relationtable"."member_id" in ($1)
order by "relationtable"."id" asc
prisma deploys different datamodel, then specified inside `datamodel.graphql`.
`prisma generate` throws an error if part of secret and endpoint came from a variable
hello ! i've been using the mongodb connector and started with the example of posts and author.
i can't get author from post(s) `cannot return null for non-nullable type author`
more than two consecutive uppercase characters in type name breaks the logic used to create the "auxiliary types".
flow type checking always fails with prisma client
flow complains about unused imports and about `process.env['prisma_endpoint']` usage.
when prodiving the `prisma_management_api_secret` env var to the cli, it should use that value and not override it with a value based on the logged in account
subscriptions provide null instead of values and generate an error in the prisma.io playground as well as typescript client
i have using nestjs framerwork so resolver is created according to nestjs and i assume one user is added with "user@example.com"
i have a graphql server using prisma inside the context object
when i try to use a `connection` query in the playground i receive the following message: `field must have a sub selection` **for example:** i have the following resolver ```
const productsconnection = async (parent, args, context) => { return await context.prisma.productsconnection({ ...args, });
``` when i call this resolver inside the playground, i receive this error: ```
query productsconnection { productsconnection { edges { cursor } }
``` ![image]( datamodel is very simple:
type product { id: id! @unique imageurl: string! title: string! price: float!
the bug is described [here](
exception in thread "main" java.lang.runtimeexception: unable to load prisma config: java.lang.runtimeexception: please provide a valid mongo connection uri
at scala.sys.package$.error(package.scala:27) at com.prisma.config.configloader$.load(configloader.scala:40) at com.prisma.local.prismalocaldependencies.<init>(prismalocaldependencies.scala:37) at com.prisma.local.prismalocalmain$.delayedendpoint$com$prisma$local$prismalocalmain$1(prismalocalmain.scala:11) at com.prisma.local.prismalocalmain$delayedinit$body.apply(prismalocalmain.scala:8) at scala.function0.apply$mcv$sp(function0.scala:34) at scala.function0.apply$mcv$sp$(function0.scala:34) at scala.runtime.abstractfunction0.apply$mcv$sp(abstractfunction0.scala:12) at scala.app.$anonfun$main$1$adapted(app.scala:76) at scala.collection.immutable.list.foreach(list.scala:389) at scala.app.main(app.scala:76) at scala.app.main$(app.scala:74) at com.prisma.local.prismalocalmain$.main(prismalocalmain.scala:8) at com.prisma.local.prismalocalmain.main(prismalocalmain.scala)
golang client does not recognize any field besides `id` for single queries
when using in high load scenario and during unit tests with live database prisma is throwing cryptic error when inserting a new field into database: ```
java.lang.classcastexception: com.prisma.api.mutations.noreturnvalue cannot be cast to com.prisma.api.mutations.returnvalue at com.prisma.api.mutations.create.$anonfun$getreturnvalue$3(create.scala:53) at scala.util.success.$anonfun$map$1(try.scala:251) at scala.util.success.map(try.scala:209)
{"key":"error/unhandled","requestid":"local:api:cjophypj70f580a77vjzk267y","clientid":"test@default","payload":{"exception":"java.lang.classcastexception: com.prisma.api.mutations.noreturnvalue cannot be cast to com.prisma.api.mutations.returnvalue","query":"mutation ($_v0_data: bpmntaskinstancecreateinput!) {\ createbpmntaskinstance(data: $_v0_data) {\ id\ datefinished\ datestarted\ duration\ performerid\ processinstanceid\ data\ status\ taskid\ }\ }\ ","variables":"{\\"_v0_data\\":{\\"datestarted\\":\\"2018-11-20t08:48:41.126z\\",\\"processinstanceid\\":\\"cjophyph60f540a77dwyigb19\\",\\"data\\":\\"{}\\",\\"status\\":\\"started\\",\\"taskid\\":\\"task_17t05yl\\"}}","code":"0","stack_trace":"com.prisma.api.mutations.create.$anonfun$getreturnvalue$3(create.scala:53)\\\ scala.util.success.$anonfun$map$1(try.scala:251)\\\ scala.util.success.map(try.scala:209)\\\ scala.concurrent.future.$anonfun$map$1(future.scala:287)\\\ scala.concurrent.impl.promise.liftedtree1$1(promise.scala:29)\\\ scala.concurrent.impl.promise.$anonfun$transform$1(promise.scala:29)\\\ scala.concurrent.impl.callbackrunnable.run(promise.scala:60)\\\ scala.concurrent.impl.executioncontextimpl$adaptedforkjointask.exec(executioncontextimpl.scala:140)\\\ java.util.concurrent.forkjointask.doexec(forkjointask.java:289)\\\ java.util.concurrent.forkjoinpool$workqueue.pollandexecall(forkjoinpool.java:1021)\\\ java.util.concurrent.forkjoinpool$workqueue.execlocaltasks(forkjoinpool.java:1046)\\\ java.util.concurrent.forkjoinpool$workqueue.runtask(forkjoinpool.java:1058)\\\ java.util.concurrent.forkjoinpool.runworker(forkjoinpool.java:1692)\\\ java.util.concurrent.forkjoinworkerthread.run(forkjoinworkerthread.java:157)","message":"com.prisma.api.mutations.noreturnvalue cannot be cast to com.prisma.api.mutations.returnvalue"}}
``` would you have any idea when this error originates?
running prisma import is failing on my data when uploading the lists
uploading lists
[ "no such column :max"
``` running `docker-compose logs -f --tail="10" prisma` shows the last activity was a node.
yet when i use mysql workbench i can see that some tables that contain list values have rows
.import/state.json
```{"nodes":50,"lists":1,"relations":0}```
the cli is notably slow to do anything, taking > 1s to start logging the first output.
the function argument signature for `prisma-client-lib/makeprismaclientclass` appears to be incorrect
the module declaration is as follows: ```ts
import { model } from './types';
export declare function makeprismaclientclass<t>({ typedefs, endpoint, secret, models, }: { typedefs: string; endpoint: string; secret?: string; models: model[];
``` the relevant portion of my generated `prisma-client/index.ts` is: ```ts
/** * type defs */ export const prisma = makeprismaclientclass<clientconstructor<prisma>>({ typedefs, endpoint: ` `
export const prisma = new prisma();
``` the generated error from `tsc` is: ```
src/prisma-client/index.ts:1359:72 - error ts2345: argument of type '{ typedefs: string; endpoint: string; }' is not assignable to parameter of type '{ typedefs: string; endpoint: string; secret?: string; models: model[]; }'
property 'models' is missing in type '{ typedefs: string; endpoint: string; }'.
``` unless i'm missing something, it appears that `models` should also be marked as optional - eg ```ts
models?: model[]
it seems that prisma is quite resource hungry
i've just deployed a prisma server to heroku, and i'm being flooded with r14 errors, with memory usage being around 600mb
i believe prisma runs on java, which might explain the high ram usage, but is there any way of reducing this? it effectively means that one needs a quite large container instance to run it, starting, for example, at a whopping $50 on heroku for a machine that can actually handle prisma without resorting to memory swapping.
flowtypes for prisma.$exists are uppercase, but should be lowercase.
this is what my datamodel looks like: ```graphql
type post { id: id! @unique createdat: datetime! updatedat: datetime! title: string! published: boolean! @default(value: "false") author: user comments: [comment!]!
} type user { id: id! @unique name: string email: string! @unique role: role! @default(value: "user") posts: [post!]! comments: [comment!]!
} type comment { id: id! @unique createdat: datetime! text: string! post: post! writtenby: user!
} enum role { user admin
``` whenever i'm fetching users, e.g
using the following code: ```go
email := "alice@prisma.io"
user, err := client.user(prisma.userwhereuniqueinput{ email: &email,
}).exec(ctx)
``` the `role` enum is not part of the result: ```go
&prisma.user{id:"cjofizq76ykpl09116fdakz9t", name:(*string)( ), email:"alice@prisma.io"}
i want to do the go-equivalent of this relational filter operation: ```ts
// fetch all comments of a particular post // that start with "great"
const comments: comment[] = await prisma .post({ id: "cjnymovvds3hy0a51xtxyhyh2" }) .comments({ where: { text_starts_with: "great" } });
``` the following code compiles but throws an error: ```go
"cjoem7agzqyuq0911h5j42pcl"
filter := "great"
comments, err := client.post(prisma.postwhereuniqueinput{ id: &id,
}).comments(&prisma.commentsparamsexec{ where: &prisma.commentwhereinput{ textstartswith: &filter, },
}).exec(ctx) if err != nil { panic(err)
fmt.printf("%#v\ ", comments)
``` i don't understand why i need to pass the params for filtering the commtens as `commentsparamsexec` and not just as `commentsparams`
when trying to adjust `commentsparamsexec` to `commentsparams` i get a compiler error: ```
src/script.go:32:3: cannot use "go-code-snippets/generated/prisma-client".commentsparams literal (type *"go-code-snippets/generated/prisma-client".commentsparams) as type *"go-code-snippets/generated/prisma-client".commentsparamsexec in argument to client.post("go-code-snippets/generated/prisma-client".postwhereuniqueinput literal).comments
the generated typescript types are not correct for select-unique queries
they always assume a return value, even though the result could be null.
it appears that the issue described in #1981 is still present in prism 1.20.1, or else i've no clue what i'm doing
when i provide a type without a scalar value, but with relations to other types, something is not being generated properly, resulting in an empty type
adding a scalar to the type does resolve the issue, but this seems a bit backwards.
can not initialize with prisma via homebrew
i want to get an array (multiple) items from my relation
go client only generates single return.
this mutation query fails flowtype checking but works perfectly fine: ```js return prisma.createchangelogentry({ title: data.title, changelog: { connect: { id: data.changelogid, }, }, creator: { connect: { id: viewerid, }, }, });
``` here's the flow error: ```
cannot call `prisma.createchangelogentry` with object literal bound to `data` because: - object literal [1] is incompatible with undefined [2] in property `changelog.connect`
- in property `id` of property `creator.connect`: - either undefined [3] is incompatible with string [4]
- or undefined [3] is incompatible with number [5]
- object literal [6] is incompatible with undefined [7] in property `creator.connect`
api/src/resolvers/mutation/createchangelogentry.js:16:38 v 16| return prisma.createchangelogentry({ 17| title: data.title, 18| changelog: { 19| connect: { 20| id: data.changelogid, 21| }, 22| }, 23| creator: { 24| connect: { 25| id: viewerid, 26| }, 27| }, 28| }); ^ references: api/src/resolvers/mutation/createchangelogentry.js:19:16 v 19| connect: { 20| id: data.changelogid, 21| }, ^ [1] api/database/client/index.js:1005:13 1005| connect?: changelogwhereuniqueinput; ^^^^^^^^^^^^^^^^^^^^^^^^^ [2] api/src/index.js:17:14 17| viewerid?: string, ^^^^^^ [3] api/database/client/index.js:1880:24 1880| export type id_input = string | number; ^^^^^^ [4] api/database/client/index.js:1880:33 1880| export type id_input = string | number; ^^^^^^ [5] api/src/resolvers/mutation/createchangelogentry.js:24:16 v 24| connect: { 25| id: viewerid, 26| }, ^ [6] api/database/client/index.js:738:13 738| connect?: userwhereuniqueinput; ^^^^^^^^^^^^^^^^^^^^ [7]
error message received from query: "whoops
looks like an internal server error
search your server logs for request id: local:api:{id}"
when generating the scheme with the prism client in version 1.20, add this line "node: (args: {id: id_output}) => nodepromise;" with which you have compilation problems, if i erase everything is fine.
related to this
in the js based schema generator, the pluralization should match the pluralization strategy implemented by
prisma cloud should create a new server
on mysql all seems to work well, but when i try to delete from a table that contains array elements, i receive following error: ```
org.postgresql.util.psqlexception: error: update or delete on table "processresource" violates foreign key constraint "processresource_readroles_nodeid_fkey" on table "processresource_readroles" detail: key (id)=(cjnz6smz300320a23u4nr6gqr) is still referenced from table "processresource_readroles".
fluent api of ts client breaks in latest beta
* using the mysql connector
* prisma 1.19
* no `rawaccess` set in `docker-compose.yml` execute this: ```
mutation { executeraw(query: "select * from `default@default`.`user`")
``` returns this error: `error: syntax error at or near \\"`\\"\ position: 15",`
*1.19.1 introduced a breaking change for the updatemany*
i use the javascript generated client but there is a clash between the mutations defined in the generated client and the prisma exposed schema.
the go client supports enums in every way for writing queries, including inserting data
however, it does not return them from the database!
```typescript
const foo = await db.user({id: doesnotexist});
// foo is typed as a user, but is actually null!
i really think there is a big problem with prisma client and subscription:
first problem, i notice there is actually no way to return directly the full subscription payload like
type postsubscriptionpayload { mutation: mutationtype! node: post updatedfields: [string!] previousvalues: postpreviousvalues
from a subscription like
type subscription { posts: postsubscriptionpayload
and the resolver ```
posts: { subscribe: async (parent, args, ctx) => { return ctx.prisma.$subscribe.post() }, resolve: payload => { console.log(payload) // { mutation: 'create', updatedfields: null } return payload } }
in the `resolve` function i get only mutation and updatedfields fields, whatever is the event that trigger the subscription (create, update or delete)
second problem, and this is a big one because it concerns the delete subscription directly
we can't get back the previous value of the deleted node at all!
type subscription { deletedpost: postpreviousvalues! // i tested with post! too, same error
i get `null` note that i console log the payload in the `resolve` function of each subscription resolver like
``` deletedpost: { subscribe: async (parent, args, ctx) => { return ctx.prisma.$subscribe.post({ mutation_in: ['deleted'] }).previousvalues() }, resolve: payload => { console.log(payload) // null return payload } }
so i'm pretty sure the problem comes from prisma client :zany_face: ```
- generator: javascript-client output: ../src/generated/prisma-client/
- generator: graphql-schema output: ../src/generated/
$ brew install prisma
==> installing prisma from prisma/prisma
==> downloading
######################################################################## 100.0%
error: an exception occurred within a child process: checksummismatcherror: sha256 mismatch
expected: 0f1e867eea6d09727bc763ba66680ad4c2d075ed618a5f54b9bdddcee7fbd991
actual: 2517026215d5410cec07c0fe82ac11d60c2c201503f238ea16c7b48d7b7dcd84
prisma generate uses `prisma-generate-schema` internally to create a schema for a given datamodel without a live endpoint
this js based schema generator is not working correctly for this specific datamodel file:- ```graphql
type user { id: id! @unique licenses: [license!]!
} type license { id: id! @unique user: user!
-bash: /usr/local/bin/prisma: permission denied
currently, the automatic `prisma generate` workflow for `prisma init` is broken for `prisma init <folder-name>`.
<img width="858" alt="screen shot 2018-10-16 at 6 24 28 pm" src=" ">
when executing a nested mutation from graphql playground, i get it in the log of the docker container:
error: null value in column "id_menu" violates not-null constraint
prisma client swallows errors returned for initial subscription requests.
i made below datamodel file.
type user { id: id! @unique email: string! @unique name: string! writtenposts: [post!]! @relation(name: "userwrittenposts") writtencomments: [comment!]! @relation(name: "userwrittencomments") likedposts: [post!]! @relation(name: "userlikedposts") groups: [group!]! @relation(name: "userbelonggroups") madegroups: [group!]! @relation(name: "madegroups") following: [user!]! @relation(name: "followers") followers: [user!]! @relation(name: "followers") createdat: datetime! updatedat: datetime!
} type post { id: id! @unique author: user! @relation @relation(name: "userwrittenposts") content: string! comments: [comment!]! @relation(name: "postcomments") likes: [user!]! @relation(name: "userlikedposts") createdat: datetime! updatedat: datetime!
} type comment { id: id! @unique user: user! @relation(name: "userwrittencomments") post: post! @relation(name: "postcomments") content: string! createdat: datetime! updatedat: datetime!
} type group { id: id! @unique name: string! @unique description: string master: user! @relation(name: "madegroups") member: [user!]! @relation(name: "userbelonggroups") createdat: datetime! updatedat: datetime!
and after `prisma generate`, i got this error
![image](
i found the data of subscription events is not exactly how it's declared on the generated graphql bindings
since #3278 my autocomplete is acting weird.
with the 1.17.1 the code generated on this [repo]( branch master autocompletes without any issue
however with the prisma-1.19.0-alpha21 cli installed and the[ corresponding branch]( my autocomplete is broken but the server works fine (mutation, queries, etc).
there is currently no way to run raw graphql request using prisma client
this seems to be a missing feature, and also a problem in the documentation, for which i created a separate issue [here](
`prisma generate` for the `flow` client adds a `documentnode` type without importing it from `'graphql'`
current implementation of environment interpolation in prisma client [relies on tagged template literals]( #l208-l219) which only works for javascript
this is currently a bug in go client and would be a bug in all languages where we interpolate variables like this.
i have an issue with paging not working correctly
i have a datamodel like
type user { id: id! @unique numfollowers: int! @default(value: "0")
my post-deploy looks like this:
hooks: post-deploy: - echo "deployment finished" - graphql get-schema --project database - graphql codegen
``` this is what i see in the terminal:
![screen shot 2018-10-05 at 16 26 28]( the issue is, that it is always succesful
for instance `graphql get-schema --project database` was returning an exception, but prisma deploy not breaking on this exception
but continuing and showing green check marks.
the new prisma client maintains an [internal data structure that has the name 'types']( #l40)
it appears as if each of the root query types from prisma is also added to the client as properties
this can cause naming collisions
if one were to have a model in their `datamodel.graphql` with the name `type` then prismas root query would have a field on it named `types` ```graphql
type type @model { id: id! @unique
generates a schema with:
```graphql type query { types(where: typewhereinput, orderby: typeorderbyinput, skip: int, after: string, before: string, first: int, last: int): [type]!
``` the naming collision occurs [here]( #l311) and the original `client.types` is overridden.
when running `prisma init` using git bash on windows 10 the arrow indicator doesn move when pressing up or down arrow keys
also the active selection is not shown in a blue color like is shown when running from command prompt.
the "get started" page at prisma docs shows me 1.18(beta) version of the page(in fact,
but the version selector at the top left shows 1.17(latest)
![image](
i am currently unable to successfully run prisma init on a clean/new mysql database running on my localhost
initially i thought this might be a duplicate of #2516, but its seems possibly this is different?
when using the prisma cli in the new container environment, signing in fails with error code 3
this happens because the login flow requires the cli to open a browser window, which is not available in the container environment
to work around the issue, you can manually copy the login url, but because the cli returns an error, it is not longer listening for the successful login.
stuck on "applying changes"
client has a `$fragment` selection api for creating a custom selection set
however, this is not available for arrays
type todo { id: id! @unique text: string! done: boolean!
as of version `1.17.1` the command `prisma generate` does fail if the `prisma.yml` endpoint holds a template literal such as `${env:core_revision}`, an example config can be found below
endpoint: {env:core_prisma_host}:4466/service/v${env:core_revision}
datamodel: - model/category.graphql
generate: - generator: typescript-client output: ./client'
go client exists cause panic
`prisma-generate-schema` currently has a dependency on `prisma-cli@1.0.7`: #l26
it should be changed to `prisma@1.17`, or removed entirely.
i am trying to import exported data from the server and i am getting may errors of `failure inserting relayrow with id: spbk0000004
cause: .sqlintegrityconstraintviolationexception: (conn=30124) duplicate entry 'spbk0002502' for key 'primary'`
i am sure that the data is correct, or at least i cannot find two rows with the same id.
for the datamodel
type user { id: id! @unique optionaldetailswithoutconnection: optionaldetailswithoutconnection
} type optionaldetailswithoutconnection{ text: string!
getting validation error ![screenshot 8](
for this datamodel ```
type todo { id: id! @unique text: string! done: boolean! user: user!
} type user { id: id! @unique name: string!
``` the generated type for a to-one relation should have `userwhereuniqueinput` as the input argument type
type todo implements node { id: id! text: string! done: boolean! user(where: userwhereinput): user!
connecting prisma to a local mysql docker container on a different port than `3306` crashes prisma.
when running the command `prisma init --endpoint ` as per the docs i get the following error: ```
error: file or directory '/**/cli/node_modules/prisma-cli-core/dist/commands/init/boilerplate/datamodel.prisma' was not included into executable at compilation stage
please recompile adding it as asset or script
at error_enoent (pkg/prelude/bootstrap.js:422:17) at findnativeaddonforstat (pkg/prelude/bootstrap.js:884:32) at statfromsnapshot (pkg/prelude/bootstrap.js:909:25) at object.fs.lstatsync (pkg/prelude/bootstrap.js:950:12) at /snapshot/cli/node_modules/graceful-fs/polyfills.js:297:22 at getstats (/snapshot/cli/node_modules/fs-extra/lib/copy-sync/copy-sync.js:46:14) at startcopy (/snapshot/cli/node_modules/fs-extra/lib/copy-sync/copy-sync.js:41:10) at object.copysync (/snapshot/cli/node_modules/fs-extra/lib/copy-sync/copy-sync.js:36:10) at init.<anonymous> (/snapshot/cli/node_modules/prisma-cli-core/src/commands/init/index.ts:62:10) at step (/snapshot/cli/node_modules/prisma-cli-core/dist/commands/init/index.js:42:23) at object.f [as next] (/snapshot/cli/node_modules/prisma-cli-core/dist/commands/init/index.js:23:53) at __awaiter (/snapshot/cli/node_modules/prisma-cli-core/dist/commands/init/index.js:17:71) at new promise (<anonymous>) at __awaiter (/snapshot/cli/node_modules/prisma-cli-core/dist/commands/init/index.js:13:12) at init.runinit (/snapshot/cli/node_modules/prisma-cli-core/dist/commands/init/index.js:85:16) at init.<anonymous> (/snapshot/cli/node_modules/prisma-cli-core/src/commands/init/index.ts:38:16) at step (/snapshot/cli/node_modules/prisma-cli-core/dist/commands/init/index.js:42:23) at object.f [as next] (/snapshot/cli/node_modules/prisma-cli-core/dist/commands/init/index.js:23:53) at __awaiter (/snapshot/cli/node_modules/prisma-cli-core/dist/commands/init/index.js:17:71) at new promise (<anonymous>) at __awaiter (/snapshot/cli/node_modules/prisma-cli-core/dist/commands/init/index.js:13:12) at init.run (/snapshot/cli/node_modules/prisma-cli-core/dist/commands/init/index.js:60:16) at function.<anonymous> (/snapshot/cli/node_modules/prisma-cli-engine/src/command.ts:67:17) at step (/snapshot/cli/node_modules/prisma-cli-engine/dist/command.js:32:23) at object.f [as next] (/snapshot/cli/node_modules/prisma-cli-engine/dist/command.js:13:53) at fulfilled (/snapshot/cli/node_modules/prisma-cli-engine/dist/command.js:4:58)
exiting with code: 1
when prisma seed is used with an invalid configuration, it fails silently.
skip and first does not return accurate results from related sub selections
instead of filtering the results the entire collection is returned
orderby works fine
first, skip do not work
when filtering the type directly filtering works fine, just not with a nested query
**from datamodel.prisma**
type user { id: id! @unique username: string! @unique email: string! @unique password: string! logs: [log!]! @relation(name:"userlogs", ondelete: cascade) sets: [set!]! @relation(name:"usersets", ondelete: cascade)
} type log { id: id! @unique created_at: datetime! sets: [set!]! @relation(name: "setsonlog", ondelete: cascade) user: user! @relation(name:"userlogs", ondelete: set_null)
} type set { id: id! @unique created_at: datetime! movement: movement! reps: int! weight: float! unit: string! user: user! @relation(name:"usersets", ondelete: set_null) log: log! @relation(name: "setsonlog", ondelete: set_null)
prisma client 1.17 create mutation generates 2 records
can't `updatemanyxxxx` fields null to post types it only work with basic type
the 'first' modifier is not working correctly in nested (one-to-many) nodes using postgresql.
combining `where.first` + `where.orderby` in create mutation = internal server error looks like #2786 (but this one is now solved)
when using the `prisma.$exists` method, `prisma-client-lib` throws an error.
env var used in endpoint (prisma.yml) breaks generated/index.ts
the order of declaration in the data model changes how the `updateone` input type looks
if, for a type `a`, the first occurring field referencing `a` is required, the input type `aupdateone` will have no disconnect field
if the first occurring field that references `a` is nullable, the `aupdateone` input type will have a disconnect field
this is inconsistent behavior.
running prisma cli command like "prisma deploy", always return "0" as exit code
![image](
prisma executes bad query for the input below.
cannot run mutation when using multiple `connect` on relationships `pgrelation` in one table.
when a nested node calls multiple arguments, prisma errors.
when importing (or exporting?) a database, some array relationships are lost
(see the example data model at the end)
i'm not sure if i'm only getting a partial database export or it's only performing a partial import or if it's certain relationships in the data model.
i'm filtering the records based on a multi-depth where clause (it goes down 4/5 levels)
interestingly, it does not throw an error if i provide an id midway down (the 2 queries are described below).
if the relation name is set to the name of an existing automatically-generated relation, prisma will generate a crud schema with incorrect relations types.
prisma can be tricked into creating an empty input type, which cannot be parsed correctly by some tools.
when applying a `id_contains` filter in a `where` clause, the server throws an exception
why would someone want to do this? when using the search functionality in the data browser on the generated query contains this construct.
running `prisma playground` opens the playground in the browser when electron app is installed.
querying with skip param doesn't work.
looks like an internal server error
search your server logs
after following the tutorial for installing the prisma server on digital ocean via docker-machine`prisma deploy` fails with `error: authentication token is invalid: token can't be decoded: invalid signature for this token or wrong algorithm.` when trying to redeploy to existing service
it also only seems to happen when logged in to prisma cloud via the cli and `config.yml` contains the cloud key
if i run `prisma logout` and make sure `config.yml` is reset to `clusters: {}` i don't get the error anymore...
querying nested nodes results in error > org.postgresql.util.psqlexception: error: missing from-clause entry for table "session_taskgroup_task_alias"
error when cascading delete is performed for a lot of related nodes
> \x1b[36mprisma_1 |\x1b[0m org.postgresql.util.psqlexception: an i/o error occurred while sending to the backend
> caused by: java.io.ioexception: tried to send an out-of-range integer as a 2-byte value: 32768
the docker images cannot be run on openshift, or at least not under the defaults
this might count as a feature, i'm not sure.
since i am in mainland china, i could not access prisma's servcie unless i use a proxy
but when i run command `prisma login`, it reports an error
when changing an optional field to required, and the field has uppercase letters, it crashes (at least on postgres).
i'm running prisma in ecs using the fargate template.
the server is crashing every 15 mins with varying log messages that seem to indicate that all networking functionality has been lost.
different logs messages seem to indicate that network connections are broken and the server becomes unresponsive
eventually, the load balancer will remove the server and restart it.
the period of the crash seems to vary with traffic
higher traffic equals more frequent crashes
lower traffic equals less frequent.
i've only been able to verify this with postgres, but when i require an enum field type to be non-nullable, i get an error but when i remove the exclamation mark (allowing the field to be null), the error goes away when running `prisma deploy`.
the prisma container exits and provides the following error message ```
exception in thread "main" org.postgresql.util.psqlexception: error: syntax error at or near "not" position: 18 at org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433) at org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178) at org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306) at org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441) at org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365) at org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155) at org.postgresql.jdbc.pgpreparedstatement.execute(pgpreparedstatement.java:144) at com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44) at com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java) at slick.jdbc.statementinvoker.results(statementinvoker.scala:38) at slick.jdbc.statementinvoker.iteratorto(statementinvoker.scala:21) at slick.jdbc.invoker.first(invoker.scala:30) at slick.jdbc.invoker.first$(invoker.scala:29) at slick.jdbc.statementinvoker.first(statementinvoker.scala:15) at slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:52) at slick.jdbc.streaminginvokeraction$headaction.run(streaminginvokeraction.scala:51) at slick.dbio.dbioaction$$anon$4.$anonfun$run$3(dbioaction.scala:239) at scala.collection.iterator.foreach(iterator.scala:929) at scala.collection.iterator.foreach$(iterator.scala:929) at scala.collection.abstractiterator.foreach(iterator.scala:1417) at scala.collection.iterablelike.foreach(iterablelike.scala:71) at scala.collection.iterablelike.foreach$(iterablelike.scala:70) at scala.collection.abstractiterable.foreach(iterable.scala:54) at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:239) at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:237) at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275) at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
org.postgresql.util.psqlexception: error: relation "cloudsecret" does not exist position: 22
on frontend i get an error `cannot read property 'task' of undefined` in the subscription
i didn't get it before, i guess it started to behave like that after i upgraded dependencies or added new subscriptions for another type (same error - `cannot read property 'user' of undefined`)
i tried to downgrade dependencies, revert commits both on frontend and backend - it didn't help
here is an example of subscription and i think the error is here because somehow `subscription` is `undefined`: ```js
const taskcreated = { subscribe: (_, args, context, info) => { return context.prisma.subscription.task({ where: { mutation_in: ['created'] } }, info); },
subscription schema: ```
subscription orderitem{ orderitem{ mutation node{ id updatedat status } updatedfields previousvalues{ id updatedat status } }
when connecting to an existing postgres database with data, the cli writes wrong prisma version into generated docker compose file
if i see it correctly, it increments the correct version by one
today the latest released prisma version is 1.13, but it writes `image: prismagraphql/prisma:1.14`.
the uuid field type creates columns to store binary uuids with the type `char()`, which is not binary-safe as it depends on the encoding of the connection and database.
running a query with deeply nested relational filters resutls in the internal server error: "unknown column \'role_alias.id\' in \'in/all/any subquery\'."
aggregation across nodes ignores pagination.
after creating a server on prisma cloud using heroku (currently only available option), the server itself is created successfully, however i am unable to deploy to it (more to come):
<img width="1118" alt="screen shot 2018-08-08 at 6 09 57 pm" src=" "> at this point, i have my `prisma_endpoint` (the one on heroku) so i go ahead and create another env file: .env.prod
prisma_endpoint={censored}
prisma_secret={censored}
prisma_management_api_secret={censored}
app_secret={censored}
``` now, when i run `prisma deploy -e .env.prod`
i get the following:
error: authentication token is invalid: token can't be decoded: invalid signature for this token or wrong algorithm
{ "data": { "addproject": null }, "errors": [ { "locations": [ { "line": 2, "column": 9 } ], "path": [ "addproject" ], "code": 3015, "message": "authentication token is invalid: token can\'t be decoded: invalid signature for this token or wrong algorithm.", "requestid": "local:management:cj..." } ], "status": 200
} ``` i feel like i am missing a step here
could someone point me in the right direction?
connecting already connected nodes breaks on `1.12.x` and `1.14-beta-1` and throws an internal server error: ```
duplicate entry 'cjkcvd9ek04730911qyfujpdg-cjkcug77n041c091103snc7yx' for key 'ab_unique'
pagination (`after` and `before`) doesn't work for id field type `uuid`.
issue #2615 states that uuids are supported as ids
however, the [current documentation (1.13)]( #scalar-types) doesn't list uuid scalar field types anymore.
i followed the steps in the [prisma docs]( on authentication using `secret` and `prisma token`
once the `token` is generated and sent via the header to the server, however, it appears that i have unlimited access to the server even if i remove the `authorization: bearer __token__` from the header, and even if i open an incognito browser tab or use a different browser (i accessing the server client-side via `window.fetch`).
deploying a relation to an unknown type throws an internal server error.
when running a "deletemanyx" mutation against a table with a large number of records, an error is returned with a message of > whoops
looks like an internal server error
search your server logs for request id: local:api:cjkcx8x7rvcxy0871suxurkfr looking at the prisma logs, i found the following: ```
[bugsnag - local / testing] error report: com.bugsnag.report@54935f02
org.postgresql.util.psqlexception: an i/o error occurred while sending to the backend
at org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:333) at org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441) at org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365) at org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155) at org.postgresql.jdbc.pgpreparedstatement.execute(pgpreparedstatement.java:144) at com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44) at com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java) at com.prisma.api.connector.jdbc.database.builderbase.$anonfun$deletetodbio$1(builderbase.scala:70) at com.prisma.api.connector.jdbc.database.builderbase.$anonfun$deletetodbio$1$adapted(builderbase.scala:70) at com.prisma.api.connector.jdbc.database.builderbase.$anonfun$jooqtodbio$1(builderbase.scala:87) at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70) at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69) at slick.dbio.dbioaction$$anon$4.$anonfun$run$3(dbioaction.scala:239) at scala.collection.iterator.foreach(iterator.scala:929) at scala.collection.iterator.foreach$(iterator.scala:929) at scala.collection.abstractiterator.foreach(iterator.scala:1417) at scala.collection.iterablelike.foreach(iterablelike.scala:71) at scala.collection.iterablelike.foreach$(iterablelike.scala:70) at scala.collection.abstractiterable.foreach(iterable.scala:54) at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:239) at slick.dbio.dbioaction$$anon$4.run(dbioaction.scala:237) at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:275) at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:275) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748) caused by: java.io.ioexception: tried to send an out-of-range integer as a 2-byte value: 44446 at org.postgresql.core.pgstream.sendinteger2(pgstream.java:224) at org.postgresql.core.v3.queryexecutorimpl.sendparse(queryexecutorimpl.java:1440) at org.postgresql.core.v3.queryexecutorimpl.sendonequery(queryexecutorimpl.java:1762) at org.postgresql.core.v3.queryexecutorimpl.sendquery(queryexecutorimpl.java:1326) at org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:298) ..
when subscribed to `deleted` events, `previousvalues` -> `id` returns the string `cuidgcvalue(...)`
(`...` represents the actual id)
when `schema: public` option is provided in docker-compose.yml, prisma successfully executes queries on tables in `public` schema of existing postgresql database
but during mutations, prisma looks for the table in `default$default` schema and then postgresql throws the following error since the table exists in `public` schema and not `default$default` schema.
prisma_1 | org.postgresql.util.psqlexception: error: relation "default$default.manager_keyword" does not exist
getting the error:
"could not connect to cluster prisma-us1 with host
did you provide the right port?" this error shows on the console when i run `yarn start`
my prisma services work for months until jul 29
it started showing the error on jul 29
i tried starting the service again on jul 30 and it's gone
but, it happens again today morning (jul 31).
if the `prisma introspect` command is run against a schema with a view that has a space in its name, the generated `datamodel.graphql` has a type with a space in it
that datamodel is incorrect.
when i run docker-compose up -d and then run docker ps, container id 3da435f9b9af continues to restart based on this output *restarting (0) 33 seconds ago*
not sure why it keeps restarting
a very simple subscription in a brand new project initialized with `prisma init` does not fire.
i'm implementing a following feature using many-to-many self-relation,
let's say x is following y and z
when i disconnect x/y, x/z got disconnected to
subscriptions to types containing recursive relationships stopped firing after upgrading to 1.12.0
this works fine under 1.11.1.
currently, my user schema is ```
type user { stripe: [stripecard!]! @relation(name: "stripecard", ondelete: cascade)
} type stripe { user: user! @relation(name: "stripecard", ondelete: set_null)
i am trying to change it to:
type user { stripe: [stripecard!]! @relation(name: "stripecard", ondelete: cascade) orders: [order!]! @relation(name: "order", ondelete: cascade)
} type stripe { user: user! @relation(name: "stripecard", ondelete: set_null) order: [order!]! @relation(name: "purchasecard", ondelete: set_null)
} type order { id: id! @unique charge_id: string! amount: int! date: int! currency: string! card_id: stripecard! @relation(name: "purchasecard", ondelete: set_null) customer: user! @relation(name: "order", ondelete: set_null)
``` it is lagging on prisma deploy "applying changes." i\'ve tried going back to it\'s initial state but it is still stalling.
trying to delete a record registered with an uuid return a internal database error
i've been able to introspect my database and manually tweak my schema and deployment is find however when running queries i get the following error: ```
db_1 | error: relation "default$default.property_types" does not exist at character 15
db_1 | statement: select *
db_1 | from "default$default"."property_types" as "alias"
db_1 | where (
db_1 | 1 = 1
db_1 | and 1 = 1
db_1 | order by "alias"."id" asc
messy log display every 30s seconds.
`[metrics] no prisma cloud secret is set
metrics collection is disabled.`
<img width="803" alt="screen shot 2018-07-19 at 09 41 17" src=" ">
using the first: 1 or last: 1 in a query returns more than 1 result
while running `prisma deploy` from a database generated via prisma introspection, i get
deploying service `default` to stage `default` to server `local` ! error: syntax error while parsing graphql query
invalid input "uuid_generate_v4(", expected value or argument (line 2, column 35): id: id! @unique @default(value: uuid_generate_v4())
i have two graphql-yoga based servers running in two different machines behind a load balancer, both of them connected to prisma running in a 3rd machine
both graphql servers subscribe to a created mutation for a type called message, but sometimes the subscription is not sent to one of the server
all servers are running on amazon ec2 instance and the prisma server is connected to an amazon mysql rds
i am running the latest version (1.11) docker image of prisma.
i am getting this error when attempting to run a mutation with the following model: datamodel.graphql
``` graphql
type category @pgtable(name: "category") { id: id! @unique createdat: datetime! description: string name: string! @unique updatedat: datetime! tags: [tag!]!
} type tag @pgtable(name: "tag") { id: id! @unique category: category @pgrelation(column: "category_id") createdat: datetime! description: string name: string! @unique updatedat: datetime!
``` when running this mutation: ``` graphql
mutation { createtag(data:{ name: "sometag", category:{ connect:{ name:"missing" } }}){ id name }
``` i get the following error: ``` json {"key":"error/unhandled","requestid":"local:api:cjjhb9vak006r08795veioykf","clientid":"default$default","payload":{"exception":"org.postgresql.util.psqlexception: error: cached plan must not change result type","query":"mutation {\ createtag(data: {name: \\"sometag\\", category: {connect: {name: \\"missing\\"}}}) {\ id\ name\ }\ }\ ","variables":"{}","code":"0","stack_trace":"org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433)\\\ org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178)\\\ org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306)\\\ org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441)\\\ org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365)\\\ org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155)\\\ org.postgresql.jdbc.pgpreparedstatement.execute(pgpreparedstatement.java:144)\\\ com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44)\\\ com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java)\\\ com.prisma.api.connector.postgresql.database.postgresapidatabasemutationbuilder.$anonfun$createdataitem$1(postgresapidatabasemutationbuilder.scala:50)\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)\\\ slick.dbio.dbioaction$$anon$1.$anonfun$run$1(dbioaction.scala:187)\\\ scala.collection.iterator.foreach(iterator.scala:929)\\\ scala.collection.iterator.foreach$(iterator.scala:929)\\\ scala.collection.abstractiterator.foreach(iterator.scala:1417)\\\ scala.collection.iterablelike.foreach(iterablelike.scala:71)\\\ scala.collection.iterablelike.foreach$(iterablelike.scala:70)\\\ scala.collection.abstractiterable.foreach(iterable.scala:54)\\\ slick.dbio.dbioaction$$anon$1.run(dbioaction.scala:187)\\\ slick.dbio.dbioaction$$anon$1.run(dbioaction.scala:184)\\\ slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:240)\\\ slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:240)\\\ java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)\\\ java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)\\\ java.lang.thread.run(thread.java:748)","message":"error: cached plan must not change result type"}}
running `prisma playground --port 1234` opens the playground electron app, if installed.
i have a copy of my mysql db deployed on aws aurora.
when i am doing a query, asking for the first x of a table (where x>max number of lines for this query), the query never ends, therefore it times out
for example, my mission with id "cjcgea18taaze0124ff7j25zs" has 236 images linked to it.
by querying the first 235 images, i have the result in less than a second, the executed query is the following : ```
{ images(first:235 where: { mission: { id: "cjcgea18taaze0124ff7j25zs" } }) { id }
which executes on aurora :
from `sterblue@dev`.`image` as `top_level_alias`
where (((exists (select * from `sterblue@dev`.`missionexecution` as `missionexecution_top_level_alias` inner join `sterblue@dev`.`_missionimages` on `missionexecution_top_level_alias`.`id` = `sterblue@dev`.`_missionimages`.`b` where `sterblue@dev`.`_missionimages`.`a` = `top_level_alias`.`id` and (((`missionexecution_top_level_alias`.`id` = 'cjcgea18taaze0124ff7j25zs'))) ))))
order by `top_level_alias`.`id` asc
limit 0, 236
``` **but** if i ask for 236 lines : ```
{ images(first:236 where: { mission: { id: "cjcgea18taaze0124ff7j25zs" } }) { id }
from `sterblue@dev`.`image` as `top_level_alias`
where (((exists (select * from `sterblue@dev`.`missionexecution` as `missionexecution_top_level_alias` inner join `sterblue@dev`.`_missionimages` on `missionexecution_top_level_alias`.`id` = `sterblue@dev`.`_missionimages`.`b` where `sterblue@dev`.`_missionimages`.`a` = `top_level_alias`.`id` and (((`missionexecution_top_level_alias`.`id` = 'cjcgea18taaze0124ff7j25zs'))) ))))
order by `top_level_alias`.`id` asc
limit 0, 237
it will never end on my aurora db (or will time out way before as it takes ages)
on a regular mysql db, the 236 lines are fetched correctly (in ~10 seconds), but some time seems to be wasted anyway as iterating over all the possible joins is quite long, and is required as we specifically asked for more line than available
but at least it ends
running the following sql query give me the expected result in a fraction of second : ```
select i.id
from `sterblue@dev`.`image` i, `sterblue@dev`.`missionexecution` me, `sterblue@dev`.`_missionimages` mi
where mi.a = i.id and mi.b = me.id and me.id = 'cjcgea18taaze0124ff7j25zs'
limit 0, 237
``` as my knowledge of database performance (index, ...) is limited, i am interested in knowing why you are using this kind of queries, instead of a simple one like the one above
i would like to know if this issue comes from the use of aurora, and how it is possible to fix it.
when passing the `headers` via the `yaml` configuration file, none of them are being sent to the webhook.
when using prisma server on heroku (or custom server on aws), some commands including `prisma seed`, `prisma seed` do not work and throw the following error
error: workspace * does not exist { "data": { "generateclustertoken": null }, "errors": [ { "message": "workspace * does not exist", "locations": [ { "line": 3, "column": 9 } ], "path": [ "generateclustertoken" ], "code": 222 } ], "status": 200
`prisma deploy -n` currently comments out the `endpoint` property and appends the new endpoint in the now commented out line, which should be adjusted as well.
an export of an older prisma version might contain values for scalar lists that reference a non existent node id.
it is currently not possible to deploy a service generated by `prisma init` to the demo cluster.
when a database type is defined with only relation fields, an associated `previousvalues` helper type is created with no fields
this causes an error during the `graphql get-schema --project database` command.
when prisma.yml does not contain an endpoint
command `prisma deploy` tried to append the endpoint to `prisma.yml` by asking the user for it
however, if we do not specify the service and stage, the generated url should have defaults.
for a specific datamodel, an unexpected type `_magicalbackrelation_accommodationoptiontofamily_every` exists in the datamodel.
with a project locally, set up with a self hosted database after i do `docker-compose up -d` i start getting max connection errors
inconsistently, could succeed `prisma deploy` but still not working.
server cannot be reached and error message in playground after a successful deploy on a demo server
`{ "error": "response not successful: received status code 500"
__ i am unable to get a basic one-to-one relationship query working using postgres.
this relationship is using `integer` as the id type and the query built is trying to compare `integer` to `character varying` causing errors when requesting any relationship
<summary><b>docker-compose.yml</b> - <i>the docker configration</i></summary> ```yaml
version: '3'
services: prisma: image: prismagraphql/prisma:1.11-beta restart: always ports: - "4466:4466" environment: prisma_config: | port: 4466 # uncomment the next line and provide the env var prisma_management_api_secret=my-secret to activate cluster security # managementapisecret: my-secret databases: default: connector: postgres host: $db_host port: \'5432\' database: $db_name schema: public user: $db_user password: $db_pass migrations: false ssl: true
</details> <details>
<summary><b>create.sql</b> - <i>ddl for the database</i></summary> ```sql
create table location ( id integer not null, description text, address character varying not null, city character varying, state character varying, postal_code character varying, country character varying, primary key(id) ) ;
create table account ( id integer not null, name character varying not null, location_id integer not null, parent_id integer, master_id integer, primary key(id), constraint account_parent_id_fkey foreign key(parent_id) references "account"("id"), constraint account_master_id_fkey foreign key(master_id) references "account"("id"), constraint account_location_id_fkey foreign key(location_id) references "location"("id"), unique(name) ) ;
</details> #### the `datamodel.graphql` ```graphql
type account @pgtable(name: "account") { id: id! @unique name: string! master: account @relation(name: "accountmaster") @pgrelation(column: "master_id") parent: account @relation(name: "accountparent") @pgrelation(column: "parent_id") location: location! @relation(name: "accountlocation") @pgrelation(column: "location_id")
} type location @pgtable(name: "location") { id: id! @unique description: string address: string! city: string state: string postal_code: string country: string
``` #### the simple query i'm running ```graphql
query { accounts { id name location { id address } }
``` #### the response i was given ```json
{ "data": { "accounts": [ null, null, null, ] }, "errors": [ { "message": "whoops
looks like an internal server error
search your server logs for request id: local:api:cjim0bm3o006z0a48sgjgx800", "path": [ "accounts", 0, "location" ], "locations": [ { "line": 5, "column": 5 } ], "requestid": "local:api:cjim0bm3o006z0a48sgjgx800" }, { "message": "whoops
looks like an internal server error
search your server logs for request id: local:api:cjim0bm3o006z0a48sgjgx800", "path": [ "accounts", 1, "location" ], "locations": [ { "line": 5, "column": 5 } ], "requestid": "local:api:cjim0bm3o006z0a48sgjgx800" }, { "message": "whoops
looks like an internal server error
search your server logs for request id: local:api:cjim0bm3o006z0a48sgjgx800", "path": [ "accounts", 2, "location" ], "locations": [ { "line": 5, "column": 5 } ], "requestid": "local:api:cjim0bm3o006z0a48sgjgx800" } ]
``` #### the error ```
org.postgresql.util.psqlexception: error: operator does not exist: integer = character varying hint: no operator matches the given name and argument type(s)
you might need to add explicit type casts
position: 296 at org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433) at org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178) at org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306) at org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441) at org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365) at org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155) at org.postgresql.jdbc.pgpreparedstatement.executequery(pgpreparedstatement.java:118) at com.zaxxer.hikari.pool.proxypreparedstatement.executequery(proxypreparedstatement.java:52) at com.zaxxer.hikari.pool.hikariproxypreparedstatement.executequery(hikariproxypreparedstatement.java) at com.prisma.api.connector.postgresql.database.postgresapidatabasequerybuilder.$anonfun$batchselectallfromrelatedmodel$1(postgresapidatabasequerybuilder.scala:104) at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70) at slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69) at slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:240) at slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:240) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
{"key":"error/unhandled","requestid":"local:api:cjim02712006x0a48n9wf8a4z","clientid":"default$default","payload":{"exception":"org.postgresql.util.psqlexception: error: operator does not exist: integer = character varying\ hint: no operator matches the given name and argument type(s)
you might need to add explicit type casts.\ position: 296","query":"{\ accounts {\ id\ name\ location {\ id\ address\ }\ }\ }\ ","variables":"{}","code":"0","stack_trace":"org.postgresql.core.v3.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.java:2433)\\\ org.postgresql.core.v3.queryexecutorimpl.processresults(queryexecutorimpl.java:2178)\\\ org.postgresql.core.v3.queryexecutorimpl.execute(queryexecutorimpl.java:306)\\\ org.postgresql.jdbc.pgstatement.executeinternal(pgstatement.java:441)\\\ org.postgresql.jdbc.pgstatement.execute(pgstatement.java:365)\\\ org.postgresql.jdbc.pgpreparedstatement.executewithflags(pgpreparedstatement.java:155)\\\ org.postgresql.jdbc.pgpreparedstatement.executequery(pgpreparedstatement.java:118)\\\ com.zaxxer.hikari.pool.proxypreparedstatement.executequery(proxypreparedstatement.java:52)\\\ com.zaxxer.hikari.pool.hikariproxypreparedstatement.executequery(hikariproxypreparedstatement.java)\\\ com.prisma.api.connector.postgresql.database.postgresapidatabasequerybuilder.$anonfun$batchselectallfromrelatedmodel$1(postgresapidatabasequerybuilder.scala:104)\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:70)\\\ slick.jdbc.simplejdbcaction.run(streaminginvokeraction.scala:69)\\\ slick.basic.basicbackend$databasedef$$anon$2.liftedtree1$1(basicbackend.scala:240)\\\ slick.basic.basicbackend$databasedef$$anon$2.run(basicbackend.scala:240)\\\ java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)\\\ java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)\\\ java.lang.thread.run(thread.java:748)","message":"error: operator does not exist: integer = character varying\ hint: no operator matches the given name and argument type(s)
you might need to add explicit type casts.\ position: 296"}}
[bugsnag - local / testing] error report: com.bugsnag.report@69bb712d
``` ## note:
**i am able to get this to work** by using `character varying` as the type for all of my `id` columns in the database
unfortunately i need to use `integer` or `serial` for the database
i'm pretty new to graphql in general so there might be a better way to represent the data in the `datamodel.graphql`
currently, i'm just following the examples provided by the prisma documentation
the pluralization library that prisma uses has a set of "uncountable" words
this means that the plural form is the same as the singular form
example: "news" will result in "news" after the pluralization
this results in the main entrypoint for single and multiple queries (i guess other parts of the schema are affected as well) to get the same name, which leads to a failed deployment
this is the place in the pluralization lib: #l133 ```
uncountable(new string[] { // 2
handle words that do not inflect in the plural (such as fish, travois, chassis, nationalities ending // endings "fish", "ois", "sheep", "deer", "pox", "itis", // words "bison", "flounder", "pliers", "bream", "gallows", "proceedings", "breeches", "graffiti", "rabies", "britches", "headquarters", "salmon", "carp", "herpes", "scissors", "chassis", "high-jinks", "sea-bass", "clippers", "homework", "series", "cod", "innings", "shears", "contretemps", "jackanapes", "species", "corps", "mackerel", "swine", "debris", "measles", "trout", "diabetes", "mews", "tuna", "djinn", "mumps", "whiting", "eland", "news", "wildebeest", "elk", "pincers", "sugar" });
``` most of these words, like "britches" will probably never have the honor of ending up as a graphql type, except "news" of course
this wasn\'t an issue in graphcool before, because of the "all..." prefix.
following this [tutorial]( for connecting an existing empty postgres db
`prisma deploy` fails with the following error: `error: variable '$name' expected value of type 'string!' but value is undefined
reason: expected non-null value, found null
(line 1, column 27):`
error seen while upgrading prima
i'm currently preparing to update my react version to v17 for a react-bootstrap-based application.
in the process, i find that dropdown won't open on the same page when launching a modal.
when you click on `<overlaytrigger>button here</overlaytrigger>` it opens a popover, but an error appears in a console: "popper: css "margin" styles cannot be used to apply padding between the popper and its reference element or boundary
to replicate margin, use the `offset` modifier, as well as the `padding` option in the `preventoverflow` and `flip` modifiers."
rendering only a dropdown menu is not possible, because it always gets 'opacity: 0'
when using onslideend on the `<carousel>` component in internet explorer 11, the onslideend method passed through the props is not called.
the modal is currently setting the container to have the attribute of `aria-hidden=true`, but this is not allowed since there are focusable elements inside it
"stateless" function components is an incorrect way to describe function components, so we should omit that terminology from our docs.
when importing react-bootstrap returns the error module not found: can't resolve 'react-bootstrap' in the version 1.0.0-beta.13
in the version 1.0.0-beta.12 everything works well
the "react overlays" doc page, which is quite short, includes a hyperlink which looks like it should take the reader to somewhere they can find out more info, but instead it\'s just a link to the same page the reader is already looking at.
after upgrading from 1.0.0-beta.10 to 1.0.0-beta.11 (or later), the role attribute is no longer specified for the `nav` element generated by the `tabs` component
it was set in 1.0.0-beta.10 and earlier
this is an accessibility issue and is flagged by many accessibility testing tools, like [axe](
can not set id attribute to listgroupitem
currently (since about a year) the coverage of the tests won't be stored in the coverage folder
the istanbul report (html based) e.g
can be opened, there are also no src/* files shown
that's why codecov is not working currently.
first, thank you for making this wonderful library
it seems that event handlers don't have types in 1.0.0-beta.8
when i create a `<button>` with an `onclick` handler like `event => ...`, and my typescript project has `strict` enabled, vs code shows me an error, `parameter 'event' implicitly has an 'any' type.ts(7006)`.
sidebar scroll is not working properly
`dndprovider.d.ts` imports react differently than all other type files
`import react from \'react\'` is not valid unless `"allowsyntheticdefaultimports": true` is set in the tsconfig.json
all other type files import react correctly `import * as react from 'react'`
**file location**
react-dnd/lib/common/dndprovider.d.ts
when you use drag handle and drag preview while coding for drag component, drag preview does not shows up while dragging
it seems like we are dragging drag handle only.
after updating to v9.4.0 we found that when mounting components using the `dragsource` decorator, it would sometimes attempt to setup the `html5backend` again, thus triggering the error `uncaught error: cannot have two html5 backends at the same time` (as `this.window.__isreactdndbackendsetup` was not `false`)
the dnd context provider is declared in the root of the page (and thus is above the components that are unmounted and mounted in the tree)
i suspect that either the teardown isn't triggering when it should, or the setup is triggering when it shouldn't, thus triggering this error
also, it should be noted that having multiple dragsources (such as items in a list), doesn't trigger this when they're rendered together
it's only when the list is replaced with another list that this bug is triggered
**expected behaviour**
we expect that unmounting and mounting two components that use `react-dnd` to correctly update the `this.window.__isreactdndbackendsetup` global variable without throwing an error.
running the umd builds of react-dnd and react-dnd-html5-backend (both v
9.4.0) in ie 11 gives a syntax error.
latest cjs packages seem to be broken (9.3.3)
using 9.2.1 works
see codesandbox or the log below: ```
[ error ] ./node_modules/react-dnd-cjs/lib/common/dndcontext.js
module not found: can't resolve 'dnd-core' in '/mnt/c/dev/foobar/app/node_modules/react-dnd-cjs/lib/common'
{ error: cannot find module 'dnd-core' at function.module._resolvefilename (internal/modules/cjs/loader.js:636:15)
if connectdragpreview is directly inside of connectdroptarget, it works bad
but the old version 7.7.0 works well.
`connectdroptarget(connectdragpreview(/*...*/))` otherwise if i wrap a dom node(eg
`<span>`) with connectdragpreview, it works well again:
`connectdroptarget(<span>{connectdragpreview(/*...*/)}</span>)` maybe it's my fault, look forward your reviewing.
file transpiled to
```javascript
import { unsubscribe } from 'redux';
export var handlerrole; (function (handlerrole) { handlerrole["source"] = "source"; handlerrole["target"] = "target";
})(handlerrole || (handlerrole = {}));
redux do not have unsubscribe export (it just typescript interface) and as result build fails
i guess it may be relate to thank you for your assist.
since using the new `dndprovider` i get an **cannot have two html5 backends at the same time.** error after re-rendering the component where `dndprovider` is set.
according to the documentation the `dndprovider` should be at the very top of the application but only one re-render will break the whole app
also when using the react-router it's not the best idea to always place it at the top
**to reproduce** 1
place the `dndprovider` in a component
cause a re-render e.g
with usestate
application will break
while dragging an element, the mouse cursor changes to indicate that the dragged element cannot be dropped if the dragged element is either dragged over (1) an drop target which returns `false` from `candrop()` or (2) a non-drop target
i found this working for chrome and firefox but not for edge and internet explorer
edge and internet explorer only show the indicator when hovering a border
**to reproduce** 1
go to the [single-target example](
compare the behavior in this regard of chrome and edge
hello, banging my head around this problem for half of the day already
any help very appreciated monitor.isdragging() throws error
![image]( my dragsource looks like that ```
const resizehandler = dragsource( "resize_type", { begindrag: ({id}) => ({id}), enddrag: (props, monitor) => { console.log(props, monitor.getdifferencefrominitialoffset().x); }, }, (connectdnd, monitor) => ({ connectdragsource: connectdnd.dragsource(), isdragging: monitor.isdragging(), // fatal here }),
)(({isdragging, connectdragsource}: {isdragging: boolean, connectdragsource: function}) => ( connectdragsource( <div classname={styles.resizehandler} style={{ background: isdragging ? `blue` : null, }} />, )
``` and at the moment of calling monitor.isdragging() everything fails as it doesn't have sourceid (equals to null)
context is created by using dragdropcontext(backend) and for backend is used some extended version of
i'm not sure if this bug belongs here so this is more of a question whether this behavior could be solved with this lib or not.
i took the simple sortable example and added `contenteditable` to the card's `div`
after that it became both draggable and editable in chrome, only editable but not draggable in firefox and only draggable but not editable in safari
**to reproduce**
- here's a code sandbox that reproduces the problem.
upgrading from v3 to v4 is producing errors and crashing my app saying that i can't have more than 1 dnd backend
**to reproduce** working on finding the steps but i think the problems comes from me making the component the provider is part of only render conditionally
what i think happens is that the dnd provider is getting mounted more than once, which i didn't have a problem with prior.
receive the following error when `optimization.minimize` = `true` in webpack 4
disabling minification seems to work around the issue: > uncaught error: cannot call enddrag while not dragging **to reproduce**
when full path of .app has a space, install scripts can't copy proxy_helper and ssl-local then shadowsock won't work
this is _possibly_ related to #1433 and #1110, and peripherally to #105
if `jq`'s input file is the same as its output file (via a pipe), `jq` will emit nothing, or perhaps even make a partial write (more below)
i have only noticed this on write operations though it is possible a filter could produce this as well.
segfault with jq on osx when using select(...test).
the exact same jq command works on linux.
stderr doesn't print its input as a raw string but as an escaped json string.
following the documentation `|= empty` is supposed to delete the element
but when multiple elements are set to empty it does not work properly.
when using jq to open an empty file, and a query of printing a particular key (which can't exist, because the file is empty), the return status is success (0)
but it clearly didn't succeed in querying the key, because it didn't exist.
when you define a function but want value semantics for arguments, you could use the shorthand: def function($arg): ...; which is equivalent to: def function(arg): arg as $arg | ...; #definingfunctions this poses a problem if the value-argument name happens to share the name of a function that's in scope, the local argument is used
can be confusing (see repro)
instead, some sort of name mangling should be performed so it's equivalent to something along the lines of: def function(_function1_arg_): _function1_arg_ as $arg | ...; # mangled: _[function name][function arity]_[arg name]_
`jq` meddles with numeric data type.
jq built for mips by using gcc+uclibc toolchain segfaults on any input.
relatively long input used with -r will cause jq to put 0a in a strange place.
downloaded jq-solaris11-64 from any command with this binary is throwing error:
-ksh: ./jq: ./jq: cannot execute [invalid argument]
i am getting an error in compiling using "compile-ios.sh".
jq does not print the timezone correctly expanding the %z in the time format for strftime/strflocaltime when it comes to dst.
in msys2 nightly builds `halt_error` prints "jq: error:" before any output
can "jq: error:" be removed from output? the 1.6 release build from the official msys2 package repo doesn\'t print "jq: error:", and niether do the linux builds.
the value of `input_filename` is not documented when input is read from stdin or when option `-n` is used
when read from stdin, it turns out the value is not `null` but a string.
i assume this is because javascript defines all numbers as floats (doubles? long doubles?) and that's what you're using to represent numbers internally, even if they lex as integers..
but i'm having a situation where `tonumber` is morphing a stream i'm filtering (my twitter archive & the ids are huge).
jq-1.6 behaves differently (and as i read the manual, incorrectly) when running map_values with a filter which includes an alternate `//`.
with run-tests, the following test asserts
```path(.[] | select(.,3))
``` ```testing 'path(.[] | select(.,3))' at line number 1
*** expected [1], but got [0] for test at line number 3: path(.[] | select(.,3))
jq: src/execute.c:295: stack_restore: assertion `path_len == 0' failed
program received signal sigabrt, aborted.
in raise () from /lib64/libc.so.6
#0 in raise () from /lib64/libc.so.6
#1 in abort () from /lib64/libc.so.6
#2 in __assert_fail_base.cold.0 () from /lib64/libc.so.6
#3 in __assert_fail () from /lib64/libc.so.6
#4 in stack_restore (jq=jq@entry= ) at src/execute.c:295
#5 in jq_reset (jq=jq@entry= ) at src/execute.c:305
#6 in jq_teardown (jq=<optimized out>) at src/execute.c:1059
#7 in run_jq_tests (lib_dirs=..., verbose=verbose@entry=0, testdata=testdata@entry= ) at src/jq_test.c:181
#8 in jq_testsuite (libdirs=..., verbose=0, argc=1, argv= ) at src/jq_test.c:22
#9 in main (argc=3, argv= ) at src/main.c:528
``` it *does not fail* outside of run-tests, e.g
with `echo '[1,2,3]' | jq 'path(.[] | select(.,3))'`
assertion in strftime builtin.
cant use "module" as key name
i cannot tell which command in in my piped unix command emitted the error.
error is not properly raised when checking an assigned variable from the output of a previous try-catch block.
failed test on appveyor don't trigger a 'fail' on the test run.
formatting output with '@sh' (or @text of course) changes the behavior of '--exit-status/-e'
i wouldn't expect formatting to change a 'true/false' state.
on jq 1.6, using the `-a` (ascii-output) and `-r` (raw) options conflict
this problem doesn't happen on jq 1.5
when piping output from azure-cli (az) to jq it fails with a parse error
if i manually select the text and pipe it into jq by way of the 'echo' command, it works fine.
i have a bug in my jq code (which i report to myself using jq's error() statement)
but when i start trying to isolate the problem the error report changes
caution: this is *not* a "jq bug" (in the sense of a hard error) this is "jq inconsistent behavior"
specifically, when processing what should be the same string, in one case i get jq: error (at <stdin>:1): expected ';' at position 2546 got '}' but in a different case (reading the string directly from file rather than creating it using gsub()), i get jq: error (at <stdin>:1): expected ';' at position 1082 got '' (and a string of other error() reports
i am not expecting that bugs in my jq code be solved here
i just want some hints about how i can isolate the problem
(that said, i am suspecting a jq bug at the root of this inconsistency, which is why i am reporting it here
and, if i am right about that [sadly, i often am wrong], it would be good if that issue could be resolved within jq.)
download jq-linux64
when dst applies to the input time, the return value of `fromtime` is an hour later than expected.
with a reactive expression like `(a ?? b) || c`, the parentheses are stripped and it renders in the output as `a ?? b || c`, which some later parser stage (in the bundler i think) does not like
this might actually be a problem with some dependency of svelte that deals with js parsing, but i'm not sure, so filing here first.
values in a destructured promise result become undefined after a re-render
<script> let test = 0; $: promise = promise.resolve({ data: 1 });
</script> {#await promise then { data }} {#if data} <button on:click={() => (test = 1)}>test</button> {:else}data is {data}{/if}
``` for some reason, having promise defined in a reactive statement was necessary here to reproduce the bug
in my project, i was calling a function in the `{#await}` block and passing it a store value.
when a style start with :global() and contain ~, it is detected as unused css and it won't be in the compiled component.
in modern javascript, `import.meta.xxx` is valid syntax
it parses inside a `<script>`, but not inside markup.
trying to build a svelte accordion component, which takes advantage of the `open` html attribute on the `<details>` element
during compile time, the css selector `details[open]>summary` gets thrown away because it is not being used in the dom
however, the design pattern for this code is such that on page load, the open attribute likely is not present, and will be applied once the user starts to interact with the accordion.
when using object destructuring assignment to extract 2 stores out of an object, like this:
```javascript
({ store1, store2,
} = context);
``` , then only whichever store is assigned to a variable _first_ (in this case `store1`) can be used
the other one is undefined when you (auto)subscribe to it (`$store2`).
svelte does not warn when there is an unused selector of the form `element > *` inside `<style>` tags
e.g.: ```css
article > * { font-size: 36px;
if `svelte:component` is used inside a `:catch` block, updating the class on a surrounding wrapper element causes error/`svelte:component` to disappear.
if a reactive declaration is an assignment, svelte automatically replaces `$:` with `let` in ssr mode if the variable on the left hand side hasn't been declared
it does this even if the left hand side is a member expression: ```svelte
<script> $: user = {}; $: user.name = 'world';
</script> <h1>hello {user.name}!</h1>
const app = create_ssr_component(($$result, $$props, $$bindings, $$slots) => { let user = {}; let user.name = "world"; return `<h1>hello ${escape(user.name)}!</h1>`;
if you reassign $$props to another variable and use it with the spread operator on two or more inputs, typing into one clears the value from the other.
only the displayed value is cleared, any bound variables retain the correct value.
using a spread property and also binding to an array value on the spread object causes an infinite update cycle
this only seems to happen if the bound value is an array or an object
<script> import component2 from './component2.svelte'; let values = [{ x: 5, y: [6] }];
</script>
the modifications that have been made to `$capture_state` a while ago make it break when the user's code contains babel macros
that is, an `import` that is then transformed by some tooling and the import binding (variable) is removed from code
we've had someone report that [with babel macros]( #issuecomment-592767853) and, more recently, [with tailwind macros]( (also a babel macro)
for example, in this user code, the `tw` binding gets removed from the code by babel: ```svelte
<script> import tw from "twin.macro"; // <= removed const bigtext = tw`text-xl`; // <= transformed into: const bigtext = { "fontsize": "1.25rem" };
``` but the compiler has seen it and it is added to `$capture_state`: ```js $$self.$capture_state = () => ({ tw, bigtext, });
``` since the variable `tw` doesn't exist, it crashes at runtime.
after upgrading svelte in our project we noticed an issue with `bind:this` behaviour inside `{#each}`.
this works with previous versions but it's broken starting from 3.23.1 i've made a simple example that reproduces this bug.
there's a useful pattern you can use while destructuring in normal js, which is that within the destructure you can reference previously-extracted properties
[live example]( #0=n4igzglgngpgziaxabvaowiyfszjaogasaxlkeaghagmb7nymbveaxwvw10qicseqdbk2j4hcygajakglytg0tdemjjarkmsa3ab00+8vmx0yfscqdum+ackbqdvrns9btonqx8uwghmaclnzk1oasm1kedgywgpichoehgawraamdlyoeewcphxqoaeaekzmhjyaxvyga) ```js
const o = { one : 1 }; // here's where the exciting stuff happens
// v-----------v
const { one, two = one + 1 } = o; console.log(one, two);
``` i wanted to use (abuse?) this functionality to avoid having to create an entire array or modify an array that i was passed, because allocating a whole array for something that can be easily calculated on a per-element basis while iterating didn't seem worth it.
store value is not up-to-date if using a `$` subscription inside a subscription function.
the below code snippet results in two different results depending on if you use `npm run dev` or do a build with `npm run build` and then for example `npm run start`
with the dev server everything is fine
when using the result of the build "style: " is missing
the code snippet:
<span> style: <a href=" " target="_blank">bootstrap</a>.
``` the comment is needed because of an issue with prettier in the svelte vs code extension by the way
it formats the "." on the next line, which results in an unwanted whitespace after the link.
compiler fails with "can\'t access property 0" on a simple component.
an a11y warning "element should have child content" is shown when an element has `contenteditable="true"` and `bind:textcontent={somevariable}`.
i have implemented my own store with a proxy implementation, so that i don't have to call `store.set(...) ` or `store.update(...)`
this works perfectly fine if the store is used in a component without auto-subscription of the store
but as soon as the store is used in a component which auto-subscribes the store, the app crashes and doesn't even show the page
just a console error `cannot read property 'foo' of undefined`
even though the implementation is exactly the same.
sorry for the mouthful of a title
showing is often easier than telling: if the initial value is empty, typing into the contenteditable div causes the value to be prepended with the previous value after each keystroke (instead of replaced)
eg typing "hello" nets a value of: hellohellohellhelheh this does not happen if a) the initial value of the field is non-empty or b) after you complete that initial input, you select all the garbage text, delete it, and re-enter new text.
the `autofocus` html attribute is not working with curly braces javascript expression
when i add a row to a table, even when the table has `transition:` set, it just pops in ignoring the transition
oddly, it works on removing the row.
i am not sure what is the expected behavior when updating reactive declared variable, but here are the inconsistencies that i have found
first of all, here is what i meant by updating reactive declared variable ```html
<script> let a = 1; $: b = a * 2; function update() { b = 42; }
a: {a} b: {b}
<button on:click={update}>update b</button>
<input bind:value={a} />
[repl]( the intended behavior for the code snippet above is to
- reactively update `b` when `a` changes
- allows `b` temporarily go "out-of-sync" of `a` when calling `update`, setting `b` to `42` - in this case, `b` is not always `a * 2`
- however, if `a` changes again, `b` will be updated back to `a * 2`, instead of staying at `42` i used the word **"intended" behavior**, because that is the behavior im looking for, but i may not be expressing it correctly in svelte
it may not be the **expected behavior** of the code
in the example above, the repl behaves as intended, however, it will break if all of the following conditions are met: **condition 1: any of the dependencies of the reactive declarations is mutated, reassigned, or exported**
in this case
- if `a` is exported (changing the example to `export let a = 1`, or
- if `a` is mutated / reassigned, eg: `<input bind:value={a} />` or having `function foo() { a = 5 };` **condition 2: the dependencies of the reactive declarations that is mutated, reassigned or exported is not a primitive**
this is because of the behavior of `$$invalidate`, svelte uses [safe_not_equal]( #l37-l39) to decide whether the updated value is the same as the current value during `$$invalidate`
comparing objects with `safe_not_equal` will always return `true`, because svelte allows user to mutate the object / array directly, therefore should always `$$invalidate` them.
- try changing the example to `a = { v: 1 }` and `$: b = a.v * 2` **condition 3: using `bind:` or `value = value` when updating the reactive declared variable**
this is kind of the edge case that wasn't handled properly in #l154 - try changing the example to `function update() { b = 42; b = b; }` or adding `<input bind:value={b} />` the behavior of the bug was introduced in
the intention of the issue #2444 was to propagate the changes of the reactive declared variables back to its dependencies
in the context of this example, would meant, updating `b` should update `a` as well
updating `a` will update `b` back again in the reactive declaration
it works if you always want `b` to be the value deriving from `a`
however in the example above, we want the value of `b` to be temporarily out of sync of `a`
i dont know what is the expected behavior of the svelte should be, but having inconsistencies when all the "subtle" conditions were met is unfriendly
it requires the user to have much deeper understanding of the nuances of the language
**related issues that are symptom to this inconsistencies:**
- - the base case of the 1st 2 examples is that condition 1 & 3 has met, the author reported the behavior of condition 2, changing the dependencies from primitives to object
- - base case: condition 2 & 3 has met, author reported the behavior of condition 1
- - base case: condition 2 & 3 has met, author reported inconsistency behavior when meeting the condition 1
css like this causes the svelte compiler to crash:
<style> .codemirror-container.flex :global {padding:0}
the current component is not being cleared at the end of the flush call
this means that lifecycle callbacks, like onmount, ondestroy, etc
are made available outside of svelte code, with unpredictable effects (effectively operating on a random component, possibly one that is already destroyed)
this looks like a simple oversight
it looks like a call to `set_current_component(null)` is missing after this loop:
#l43-l48
this is half bug, half proposal
the current implementation of derived stores doesn't provide a way to use the store's existing value in the new value (a-la `.update`)
you can see in the repl my workaround for this is to use `get(storename)` which..
sort of works
the issue is that you get a console error which pertains to whatever the error you previously encountered was, which is written every time the store updates.
(open my repl link below
this will be way easier to follow)
when using an if,elseif,else statement where the first `if` uses a function, the second `if` uses a reactive value and the `else` block contains a component, the first `if` will always be evaluated as false
* if the first `if`is changed to anything other than a function call it works as expected
* if the second `if` is changed to anything other than a reactive value it works as expected
* if the content in the `else` block does not contain a component, it works as expected
an `{#each}` with a fully-static body doesn't ever render anything.
when doing `import anchor from './anchor.svelte` and use it, it'll break the app and showing `component is undefined`
after changing name to anything else it works.
the elizabot tutorial and example do not work.
name collision between expression name and property name in destructed object disables bind to work on that property
{#each a as { a }} <input bind:value={a} />
when trying to modify the item of an array from inside an each block, not only the modification won't be reflected, but also the underlying array won't respond to reactive commands anymore.
when using the `animate:` directive, dom nodes are measured immediately before updates are applied to them
but if an update to a parent element already happened, this can result in them being in the wrong place at the time of being measured.
the compiler option `preservecomments: true` does nothing.
i am using transition:slide in order to slide in a div element after the user presses the button with the arrow pointing down
with chrome and firefox on windows it looks perfect, however on safari (ipados) the inner contents overlap with the button during the transition
or to be more precise, the inner elements of #lookupareacontent do not follow the behavior of #lookupareacontent itself.
when store get updated, i found component with transition directive won't update
it only happens when: * `store.update()` inside promise `then()` block, if i move `store.update()` call to outside, it works as expected.
* transition directive was added in component.
when svelte sees an element with an orphaned `}` character it interprets the bracket as an attribute
`<h1 }>text</h1>`
causes this to be generated in the create function:
`attr(h1, "}", "");` and causes the runtime error
`failed to execute 'setattribute' on 'element': '}' is not a valid attribute name.` repl:
as i was trying to put together a demonstration for a different bug, the repl seems to have entered a state where not only can it not compile the demonstration, it also cannot react to any changes in the code, and cannot save any new versions (attempting to save gets a window.alert box saying "r is null")
i can load the version i somehow managed to save already, but this just puts the repl back in the same state.
the title is a hell of a mouthful.
i'm still not certain i've actually pinpointed the odd behavior, but this is as close as i could get.
to elaborate on the title, if an `<input>` element with `type="number"` triggers a reactive statement via a bound variable, changing the bound variable in the reactive statement will not perform any updates to places which rely on that variable
that means, in the following example the reactive statement will trigger when `mynum` changes (due to the `console.log`)
however, if it was triggered by typing in the `<input>` element, renders using `mynum` will be unaffected
if other variables are changed, those will work fine, but ones with `mynum` will be ignored
triggering the reactive statement some other way (like having a button increment `mynum`) will result in `mynum` changing to 500.
<script> let mynum = 0; $: { console.log(mynum); mynum = 500; }
</script> <input type="number" bind:value={mynum} />
<button on:click={() => mynum++}>change num</button>
as an aside, @pngwn found a fix (not for the bug, but to get this repl working)
using `tick` before `mynum = 500` allows an update cycle and it should work as it does with `type="text"`:
if you open [this repl]( and click on "3", the console shows the following error: ```
message: "uncaught (in promise): cannot read property \'p\' of undefined"
stack: typeerror: cannot read property 'p' of undefined
at object.update [as p] (eval at handle_message (about:srcdoc:13:8), <anonymous>:496:17)
at object.update [as p] (eval at handle_message (about:srcdoc:13:8), <anonymous>:563:26)
at update (eval at handle_message (about:srcdoc:13:8), <anonymous>:161:40)
at flush (eval at handle_message (about:srcdoc:13:8), <anonymous>:130:17)
``` not sure, if i am doing something wrong here
i wasn't able to debug this properly.
at least, i didn't find a similar bug report
thanks for any hints.
when an anonymous function is created without being assigned, just as a single statement, it crashes the compiler
() => {}; // like this
function() {}; // or that
``` this issue appeared in 3.18.2.
as of 3.20.0, the compiler is now throwing an exception when compiling certain slot usages.
imported objects don't work in reactive statements if there's an assignment to the object.
the range element with a bound value 0 is omitted from server side rendering
this leads to the range input jumping(from default location) after client side js takes over
this issue seems to stem from 0 being a falsy value in javascript.
when passing 2 named slots to a component, you get an error message in the console, although everything is correct.
components containing a raw `{@html}` tag at the top level are hydrated incorrectly - the existing html is not removed.
the svelte title is replaced by `500` and i have this error on the console: ```
syntaxerror: missing formal parameter
the dev mode validation check for `{#each}` blocks breaks with strings.
using `<input type='checkbox' bind:group={foo} value='...'>` where multiple checkboxes have the same value produces wonky behavior.
seems if we try to increase some object property with increment operator before the operand svelte produces undefined value in ctx
interesting that this would work fine if we use increment operator as postfix or if the value is not an object.
this works:
<script> let value = ['hello', 'world'];
</script> <select multiple {value}> <option>hello</option> <option>world</option>
``` adding any type of spread, even an empty object ` {...{}}`, causes the value not to be set:
<script> let value = ['hello', 'world'];
</script> <select multiple {value} {...{}}> <option>hello</option> <option>world</option>
i am updating a large svelte codebase from 3.12.1 to 3.18.1, and received a parsing error for the following line that previously worked fine: ```
export let value = getcontext('value') || (v) => v;
``` if i replace the arrow function with something like `function myfunction(v) { return v}` the error goes away.
in [this app]( via [this so question]( a keyed each block is updated when *any* variable is reassigned, rather than only when the dependencies of the block are
the `update_keyed_each(...)` call isn't being wrapped in an `if (dirty & ...)` block, as it should.
the pattern described above worked fine in svelte `3.10.0` and earlier, but with `3.10.1` and later, an error is thrown on every `input`-event: ```
uncaught referenceerror: $props is not defined at htmlinputelement.oninput
``` the value binding seems to work regardless, though.
the site uses the github api to fetch user information (and gists, when requesting a repl app that hasn't yet been migrated to the db)
right now, it authenticates using the `client_id` and `client_secret` query parameters
i got an email this morning saying that this has been [deprecated]( #authenticating-using-query-parameters) in favour of [basic authentication]( #via-oauth-and-personal-access-tokens).
the title is a bit of a mouthful so i think a simple example explains it better: ```
<script> let name = \'world\'; function* foo() { yield {name: "h", value: 123} yield {name: \'x\', value: 333} } let things = {}
</script> <h1>things! {new date()}</h1> {#each [...foo()] as f,i} <input bind:this={things[f.name]} value={f.value}> {/each} <pre> this was bound: {json.stringify(things, undefined, 2)}
when in script section there is **inline comment** and right after it **block comment** we can expect error.
when starting from ssr generated html with `hydratable: true`, hydration will remove the `<title>` element along with the other appropriate `<head>` elements, but will not add it back.
the `derived` implementation doesn't handle rxjs observables like other autosubscription stuff does.
once, capture, passive options are not working for the svelte:body element
**observation** `<svelte:window on:keydown|passive={handlekeydown}>`
generates `listen(window, "keydown", /*handlekeydown*/ ctx[2], { passive: true }),` *while* `<svelte:body on:keydown|passive={handlekeydown}/>`
`document.body.addeventlistener("keydown", /*handlekeydown*/ ctx[2]);` instead of using the listen method.
i was using in component the following code: ``` def grid = import(/* webpackchunkname: "mychunk" */ \'mymodule);
``` this code lazy-load a javascript module, and tells webpack to use a specific name for the generated chunk
it worked in svelte 3.12, however svelte 3.17 removes the comment when generating javascript.
if a component contains a javascript statement "await (expression)", then svelte removes the parenthesis in the generated javascript
however, the execution order is not the same (at least in chrome) : "await a || b" is executed as "(await a) || b" the bug is probably a regression between 3.12 and 3.17.1
`if` directive doesn't work as expected if context_overflow (this.context.length > 31)
things that internally use `get_current_component()` should probably fail when they are called from an `onmount` callback.
at my team we spread classes into multiple lines when there are more than two classes to make it more readable
this breaks svelte
<div class=" foo "
</div> <style> .foo { background: red; }
when new lines and tabs are used in attributes, then run through ssr, they end up written into the html, eg
`<div class="\ one\ two\ "></div>`
this breaks the class name and can cause a fouc with sapper, and would completely break rendering of html-only static-generated pages.
in chrome, using `bind:offsetheight` on a component that immediately changes size does not trigger a change in the `offsetheight` variable: this does not seem to happen in firefox or safari, but it does happen in chrome.
a reactive assignment that looks like `$: document.title = whatever;` doesn't work, because the compiler (unhelpfully, in this case) auto-declares `document` for us, and - since that is now undefined - the assignment `document.title = whatever;` is a runtime error.
if there is a two-way binding to `arr[0]`, this is reflected in the template, but not in `$: console.log(arr);`.
if a radio input group is setup with a filter, the radio button doesn't show as selected upon filtering, unless a keyed `{#each}` is used
see repl for example: ![image](
when destructuring a store, the whole store object is returned if the property does not exist: `$: ({shouldbeundefined} = $store);` it works if used with an existing property, i.e.: `$: ({existingproperty, shouldbeundefined} = $store);`
i have an action that requires knowledge about parentnode of an element
a simplified version looks like this: ```html
<script> function onmountaction(node) { console.log(!!node.parentelement); } </script> <h1 use:onmountaction>hello!</h1>
`create_default_slot` is generated with newer assigned `current` variable.
in rare instances, flip animations are skipped (in browsers other than safari)
i'm making a sliding puzzle
i have a fixed start position
as shown in the attached gif, when i click 2 followed by 3, the sliding animation is skipped for the second click (i.e
the 3-piece teleports to its end position)
if i slide the pieces back (by clicking 3 and then 2) and repeat the process, everything works
![dec-21-2019 11-48-31]( the bug appears with some opening sequences, but not others
e.g.: if you click 4 and then 1, the bug appears, but not 5 and then 3
the bug appears in firefox and chrome, but not safari.
infinite loop when props is updated inside a invalidation trigger in svelte:component
click handler throws an exception if handler function is stored as a variable **and** that variable is set somewhere in the `<script>` section
we found this while attempting to fix #4087 via pr #4088.
since #3945, autosubscribing to a store within the template no longer causes the store to be marked as `referenced: true` in the `vars` response from the compiler.
in a very specific scenario (see repl), elements get marked non-intersecting by `intersectionobserver`, even when they're visible on the screen.
if we update state while transition, #if statement inside transition element doesn't work with slots properly
when using a _bare_ import in a component script (also with script in _module_ context as in thsi example) there are no [specifiers on the node at this line]( #l160) which causes this error: `typeerror: cannot read property 'type' of undefined`
having an `{#if}` inside of an `{#await}` using a resolved object from `{:then}` fails.
using many vars throws under certain conditions the error: reduce of empty array with no initial value
[the bind this example]( #bind-this) doesn't work in [3.16.0]( (it does in [3.15.0](
in `{await}` ..
`{:then}` blocks, not specifying a name for the resolving value will cause an error which is hard to trace back to the issue
it only happens when the block contains another block(?).
this did not happen in 3.15.0
(plugin svelte) error: not implemented empty
an incorrect(?) warning is thrown when exporting a variable that is exclusively used in a "$dereferenced" manner
this warning was not given in 3.15.0.
what the title says
see #3912 and #4008 for why this is a problem.
the whitespace between `foo` and `bar` is removed: ```svelte
<svg> <text> <tspan>foo</tspan> {"bar"} </text>
if a variable is exported from a module context and a variable with the same name is declared in a `<script>` element, the export is omitted from the module
<script context="module"> export const x = 1;
</script> <script> const x = 2;
``` **to reproduce** svelte repl:
the simple css minification that the compiler once performed on component styles seems to have largely stopped working.
when an each block follows a slot that uses a let directive that hides a variable of the same name in the parent then the each block incorrectly references the value from inside the slot.
in dev mode, when a component exports a named function with the `function` keyword, then a warning "created without expected prop xxx" is issued in the browser console
example: ~~~html
<script> export function propornot() {}
the content of an #each block that is only dependent on the number of items in the array being iterated doesn't update when the array length increases.
bug was introduced in 3.6.0 (works in 5.4.0)
when creating an async method on an object, the compiled output does not have the `async` keyword
new in 3.13.0.
when giving a prop a default value of an object that uses a keyword as both key, and value (i.e `{true : true}`) the svelte compiler outputs invalid javascript, `{true}`.
`<datalist>` gets rendered oddly since it renders both the option's value and the inner text of the option element
(this is a browser thing which seems pretty terrible but nothing can be done about that)
it appears that [attribute.ts#80]( #l80) is treating `<datalist>` `<option>` elements the same as for `<select>` and is **requiring** that a `value` attribute be present on it
this kind of limits the usability since you cannot have separate label/value for datalist options and the value cannot be a complex object.
when bundling in development mode the check for unknown props utilizes the array.prototype.includes method which isn't supported on ie 11
this causes a break on ie11
upon updating to 3.13.0 i'm now seeing the following error, which seems to be related to transitions and slots (possibly)
using an <i {...props}> results in an error.
svelte generates code that hydrates the children of `<img>` elements and other void elements, even though there can't be any by definition.
the component name "block" seems to throwing the svelte compiler off
<script> import block from "./block.svelte" </script> <block>my block</block>
results in the error:
identifier 'block' has already been declared (note that you need plugins to import files that are not javascript)
but simply changing the component name `import blocky from "./block.svelte" //path is the same` works
also, using the `block` component more than once get's rid of the error
`<svelte:window bind:scrolly={$y}/> doesn't update the `y` store.
`<input type=file bind:files>` works
`<input bind:files type=file>` doesn't
via [stack overflow](
if you download a repl with an external dependency, that dependency is conveniently added to the project
unfortunately, the required dependency `sirv-cli` is also overwritten, causing `npm run dev` to fail.
i'm trying to set variables via function passed using context
when function is invoked inside lifecycle function (e.g
`ondestroy`), components depending on those variables are not updated.
spread properties on `<input>` tags can have an unexpected behavior on readonly attributes
if a tag has `readonly={false}` along with a spread, then the readonly attribute is included in the tag as `readonly="false"`
this results in a readonly input.
there is an `outer` component with a slot, which defaults to `inner` component
`inner` component consisting of an input field bound to a store writable object.
if we now pass something to the slot, e.g the `inner` component surrounded by a div, input binding will break and log an "cannot read property \'value\' of undefined" error.
an exception is thrown from somewhere inside code-red when compiling a component that contains an import of both a default and named export.
can't render a component with a svg tag `<text />`.
when a prop (whose value is a store) changes, svelte does not unsubscribe from the old store and subscribe to the new store
this seems related to #2014 and #2435, which were previously fixed.
via
easier to show than tell:
components with an out:[transition] and a store subscription don't get destroyed if the store is updated while out:[transition] is in progress.
i'll try set `list` and `form` with spread operator:
let [type, form, list] = ['text', 'myid', 'listid'];
let props = {type, form, list};
``` it works in regular case:
<input type={type} form={form} list={list}>
``` but fails with spread operator:
<input {...props}>
when using an input (`type="radio"` or `type="checkbox"`) with `bind:group` in combination with spread properties, it sets the bound variable to undefined when clicked.
stores subscriptions inside nested components are not updated as expected when the store instance is replaced.
compound operators don't work in reactive statements, i suspect this has to do with the fact that there are no variables the assignment depends on
so it is not run when the value of the left hand side of the operator changes.
when trying to render a child component svelte will think that a destructured variable is undefined when another `export ...` statement comes after the destructuring.
for ```svelte
{:else} {#if bar()} <baz/> {/if}
``` or alternatively ```svelte
{:else if bar()} <baz/>
``` svelte generates code like `if ((show_if == null) || ) show_if = !!(bar())`.
using `bind:this` and a writable store together doesn't provide expected behavior.
you can see the exact same weird parsing behavior in the example below
with ssr, this code: ~~~html
<script> $: x = {}
~~~ compiles to this: ~~~js
$x = get_store_value(x); let x = {}
~~~ `x` is used before it is declared, and so it crashes
(it does not work with an actual store either.)
if a store is created with a function as a second argument, that function is called when the subscriber count goes from zero to one
in theory, the function returned from *that* function is called when the subscriber count goes from one to zero
it doesn't.
the initial rendering of the undefined value results in an empty input
assigning a bound input value to `undefined` makes the input display the text `undefined`
not sure if this is a bug, but it the behaviour feels inconsistent.
trying to compare two numbers inline in html code blocks causes incorrect code to be generated, resulting in incorrect results
`{1 === 1}` shows as false.
svelte gets terribly confused if you name a variable `ctx`.
some style rules aren't being applied when there is a dynamic class between the root node and target node of the selector.
on if the device is small enough the nav bar turns into a dropdown menu
on android devices, tapping the menu opens it
on ios, tapping it immediately clicks the currently visible link, which means you don't go anywhere.
a component with no props that could change will nevertheless get update code generated
the [media element binding]( #media_element_bindings) for setting `bind:currenttime={time}` is unreliable when setting single times
for example a list of video position index markers
clicking on an index, which sets the **currenttime**, doesn't always set the video position
where as if i set **currenttime** via the dom method then it does work every time.
when trying to fill in various attributes of an svg element using the spread operator i get a read-only error
this seems like it might be related to the closed issue of
if i explicitly set the attributes from an object, the svg element renders just fine
failing script: a similar script that works:
using the spread operator in a #each loop in variable deconstruction and use the spread props feature along side other explicit props, makes the explicit props not reactive.
if assign value to `toggle` in the condition, toggle classes happens only once.
if a component exports a property using an alias such as `export { alias as name }`, then binding to that property will fail.
{#if "eva".startswith(\'e\')} eee
{:else} rrr
{/if} will throw an error
reactive declarations that depend on values that are initialised from bindings are incorrect during `onmount`.
the keyed #each is constantly updated even if it has no changed dependencies.
this doesn't work: ```svelte
{#each $items as item, index} <input bind:value={item.text}>
in safari (12.1.2), when adding an `<input>` control with manual two-way binding - by using an 'on:input' handler for instance - changing the contents of the `<input>` control at any point other than the end of the word causes the cursor to jump to the end of the control
this does not happen in chrome (76.0.3809.100) or firefox (68.0.2)
i have not been able to test edge yet.
compiler throw an error when using a iife as the key in {#each}
svelte version: 3.7.1
svelte generates code that updates style properties when nothing could change.
`class:name={ true }` in combination with spread arguments is deleted on spread arguments update
a transition deep within some components makes both the true and false parts of an if/else render on the page.
`svelte.preprocess` is not accepting asynchronous preprocessors when using typescript
if an increment operator is used in a json declaration, the compiler throws an error which is not very helpful
let eid = 1;
let employees = [ {id: eid++, name: 'xxx'}, ]
when a prop is declared and its default value contain assignment, the compiler will throw up.
if a bound prop is immediately updated as the result of state propagating upward, that update does not propagate downward.
i was playing around with trying to repro a bug i'm seeing in ssr mode and happened to notice something weird in the output
not critical, mind you, but still probably worth fixing?
repl does not allow user to update repl on mobile, it keeps deleting the typed character.
changes in $$props no longer causes a slot to re-render even if the slot has properties that derive from $$props.
value passed to an event handler is not reactively updated under some conditions
in an example below, a statement variable passed to an event handler is not updated depending on how the statements array is updated
{#each statements as statement} <li> {#if false} nothing {:else} <span on:click="{ e => clicked(statement)}"> click </span> {/if} </li>
then, `statements[0].slug = 'one-updated';` does update statement value, but `statements[0] = { id: 1, slug: 'one-updated'}` doesn't
interesting, that removing if/else part or adding stub like { statement.id ? '' : ''} resolves the issue.
it seems a value from a " let:" on a component with slots doesn\'t trigger an update when used as a prop on a slot..
<withcolourpicker let:colour> <slot titlecolour={colour} /> </withcolourpicker>
changes that "withcolourpicker" makes to "colour" aren\'t causing the slot to rerender with new titlecolour.
when portions of markup are turned into html, attributes with interpolated literals (insofar as that's not an oxymoron) contain unwanted commas
`data-foo={bar}` should, like other attribute settings, remove the attribute when setting it to a value of `null` or `undefined`
the optimization (used unless `legacy` is enabled) of instead assigning to the `dataset` object prevents this.
i have a component that uses an input type image and it has an alt message also
but the svelte compiler is constantly warning that it needs an alt message.
attempting to write the following:
<p>{@html foo}<br>bar</p>
``` will fail with (under firefox):
nomodificationallowederror: modifications are not allowed for this document
``` however, adding whitespace after the `}` makes the error disappear, such as a newline or just a space:
<p>{@html foo} <br>bar</p>
`requestanimationframe` is called by `spring` and `tweened` (via `loop`) when components are rendered server-side
this makes it impossible to do this sort of thing..
<script> import { spring } from 'svelte/motion'; export let on; const x = spring(on ? 100 : 0); $: x.set(on ? 100 : 0);
``` ...because it errors during rendering (since `requestanimationframe` is immediately called)
this was fixed in #2856 but apparently undone in #2994 @mrkishi, @conduitry, just want to check this wasn't intentional before i update [this]( #l7)?
a component with slotted contents will fail to render if it has a `let:` directive but the corresponding `<slot>` has no properties.
a component can have a property like `<foo x-y-z={42}/>`, and it will ordinarily be quoted by the compiler: ```js
var foo = new foo({ props: { "x-y-z": 42 } });
``` in ssr mode, we get this instead: ```js
return `${validate_component(foo, 'foo').$$render($$result, { x-y-z: 42 }, {}, {})}`;
``` this is somewhat contrived (you can only access that property via `$$props['x-y-z']`), but it's a situation i've managed to encounter, and it's easily fixed.
reassigning an observable-as-store variable results in an error `$$unsubscribe_namehere is not a function`
it appears that currently observables can be used only in certain undocumented restricted ways, perhaps only as long as such variables are never reassigned?
inline expressions are re-evaluated when setting spread props on a component.
reactive declarations that refer to `$$props` should fire whenever any prop changes
currently, this only holds true if the declaration doesn't reference anything else
if you have an element a with a transition:slide, and puts another element b with transition:slide inside it, the last child of element a isn't included in the transition
instead it just pops up at the end of the transition
this broke with version v3.6.4, as it worked fine up until v3.6.3.
snap install fail on deepin v20 system
when live update is enabled, upon adding a key, i get a redundant message: `key was added
do you want to reload keys in selected database?`
after upgrading from redis-desktop-manager-2020.3.231 to redis-desktop-manager-2020.4.237 the file rdm.exe is missing
i needed to start the uninstall process separately to remove all files from the folder "c:\\program files\ edisdesktopmanager"
then install the 2020.4 version
now all is file
i think the uninstall process from the installation process is not removing all files
this happens to me also in the previews upgrade
when looking at memory usage for namespaces that expand multiple levels (such as `foo:bar:abc`) it is not possible to analyse the memory of lower levels without first clicking reload namespace if it has been analysed while collapsed.
there is an error message in the log panel right after rdm starts up.
3 empty (no name) levels of folders when key starts with :, the namespace separator
using the rdm redis console only returns connected
and no values or anything returned back.
load python absolute path an only use python3.7
dyld error message: library not loaded: /usr/local/opt/python@3.7/frameworks/python.framework/versions/3.7/python referenced from: /applications/redis desktop manager.app/contents/macos/redis desktop manager reason: image not found
it is extremely slow performance when select view value as json
for instance value with more than 100 kb, it takes several minutes to proceed, blocking all the application
my pc overall performance is good same time, so it is only a soft issue
- os: windows
rdm loaded from the microsoft store and installed will not run
msvcrt runtimes probably not installed via the installer.
after i clickd the rdm.exe ,nothing happend
when i open the console and type some commands, it seems there are something wrong and nonsense output.
besides, some commands can't get the results correctly.
when displaying data from a stream using xadd the values do not show correctly
rdm version 2020.2.225 for windows downloaded and installed on windows server 2019
after launching it an error is shown: "library vcruntime140_1.dll cannot be found"
after copying the vcruntime140.dll to vcruntime140_1.dll other library-internal errors are shown.
copy to clipboard copies the entire html source of the value editor instead of just the actual value.
when "localhost" is used as a host, creating a new connection, which seems to happen on every ui operation, is very slow (about 2 seconds)
not sure if it's specific to localhost or using a domain name in general instead of an ip address but after a bit of debugging i tried setting the host to 127.0.0.1 instead which resolved the issue.
i have been using redis desktop manager for a while now and we recently started using tls on our redis configurations and i haven't been able to use the tool to connect to our redis-server setup (locally running) since
i have updated the configuration to use tls, i use the same parameters than one of my colleagues running on linux which is able to connect to the server
when i look at the logs in rdm, there is the following line: `sslhandshake failed: -9824`, i googled a bit about this issue and it seems to be related to self-signed certificates on mac osx, but i haven't been able to find more data, it might be something else
i have updated to the last version available (2020.1.89), and tried to disable the "strict mode" but i still can\'t connect
have i missed a configuration somewhere ? or is it an issue ? thanks!
installed the application from snap
sudo snap install redis-desktop-manager
[sudo] password for mythio: snap "redis-desktop-manager" is already installed, see \'snap help refresh\'
the redis desktop manager do not open at all.
rdm could not load value in redis cluster.
the redis destop manager downloaded from the win10 store cannot resize and drag windows.
my rdm gui look bigger than usual, so that i cant find the button to proceed the delete action
delete namespace button does not delete affected keys
native formatters aren't available in macos app store version
in the log :
``` formatters: cannot import module: formatters (traceback (most recent call last):
file rc:/python//formatters/_init_.py , line 3, in <module>
from .msgpack import msgpackformatter
file rc:/python//formatters/msgpack.py , line 31
error = f'first object from the stream is shown, '\\ syntaxerror: invalid syntax
rormatters: function not found: ormatters.get_formatters_list (traceback (most recent call last}:
file "<string>", line 1, in <module>
nameerror: name ormatters is not defined
when launching on linux, the gui is unresponsive
doesn't register clicks or keys.
window changes to transparent when moving window to other desktop on macos 10.15
i am using the snap version of redisdesktopmanager on a linux (ubuntu 18.04) laptop with high resolution screen (100 % scaling in display settings)
all dialogs in redisdesktopmanager span to a size much bigger that the display itself so the buttons a the bottom of the dialogs are unreachable.
the latest version of the mac doesn't have a full screen downloaded it from the apple store
the key values are not being displayed
unable to get the connection window working on the windows 10
building on windows seems to complete successfully, but the binary produced still won't run
first, the needed `dll`s are not included in the build directory (for example: `python37.dll`, `qt5core.dll`, `qt5gui.dll`, etc.), and after copying those in, the program still won't run
opening it in the qt creator debugger gives the following error: ```
20:46:50: starting c:\\users\\user\\source\ edisdesktopmanager\\bin\\windows\ elease\ dm.exe ...
app font: "open sans" 11
detected locale: "en_us"
qqmlapplicationengine failed to load component
qrc:///app.qml:3 module "qtquick.controls" version 2.13 is not installed cannot update palette
root object is not loaded.
rendering backend: "software"
``` are there just some steps missing in the instructions or is something else wrong?
zset list scroll so slow , maybe the update ui problem **platform**
php serialized values not showing in version 2020
in version 0.8.8 displayed correctly
when saving a string key in json format and the view set to json the editor somehow removes spaces before and after curly braces
when setting the view to "plain text" it works okay but is of course less convenient.
i created a container with redis 5.0.7 and tried to connect using rdm and always crashes the application, forcing it to leave
i thought it would be in the docker settings or something, but in the terminal i can carry out the commands and the connection without problems
an error occurs during compilation
no-return-in-nonvoid-function src/app/models/key-models/rowcache.h:83 compilation was carried out for different systems, with new libraries, and older
windows,vs2019,qt5.14,not compile.
i need to persist key , use button `ttl` and set new ttl -1, after then , key expired.
edis desktop manager 2019.4 , , , edis, : disconnect on error : connection error : the proxy type is invalid for operation i use redis desktop manager 2019.4 in the company's internal network
since the company's internal network requires a proxy to access the external network, i cannot access redis with the proxy turned on, and the error is: disconnect on error: connection error: the proxy type is invalid for operation
while set and read key form aws redis cluster tool crash
means just close.
trying to read a large cached entry (3141 laravel* models) with rdm, but it segfaults.
i'm caching a costly database query using redis, and trying to view the entry within rdm
unfortunately it crashes with segfault(core dumped) on the terminal
_*laravel is a php framework._
build failed
/usr/local/cellar/python/3.7.5/frameworks/python.framework/versions/3.7/include/python3.7m/object.h:448: error: expected member name or ';' after declaration specifiers pytype_slot *slots; /* terminated by slot==0
*/ ~~~~~~~~~~~ ^
crash when viewing the value.
clone source and follow the build instructions to build from source.
and there is no ./configure under src directiory
users need to reselect ssh private keys all the time due to app store sandboxing
new snap package does not work with json values correctly
i need to login every time i start the application
i am using redis desktop manager 2019.3.20 and every time i try to connect to redis server via ssh, i got the following error: connection: disconnect on error: ssh connection error(authentication error): unable to extract public key from private key file: unable to open private key file **environment:** - os & version: [os x]
ui is so big !
after having updated to 2019.3 i got a popup asking me for credentials.
when i enter them i got the following message reported below i'm under proxy so maybe it's due to that, but i don't know where to set it up.
on mac os 10.15, the rdm has crashed when i open it
on 2019.2 after runnin rdm on osx it asks me to login with a rdm account...
why is this?? further, if i logged in with a github account am i expected to log in how?
i'm unable to run rdm on macos
the crash reporter opens, but then fails to upload crash report due to gateway error.
on macos x latest, following the build instructions
i\'m blocked at the qt build complaining "\'python.h\' file not found"
just open the redisdesktopmanager, but only show "new upload available" popup
can't see the window
already download again, still the case
open the program and an error message appear.
using redis desktop manager v.0.8.8.384 attempting to connect to an old redis server it looks like it gets caught in a loop and then crashes; when attempting to send the crash report it gives this error: ```
---------------------------
server error
---------------------------
error transferring - server replied: request entity too large
---------------------------
ok ---------------------------
view a lot keys causing redis can not working for other programs.
app crash when manually adding row in zset
this behavior is reproduced if one or two app windows are open
after connecting to the redis cache server
expand the tree node to see that the duplicate keys are shown
when i try to expand a group of nested keys that have a large number of keys the app crashes
it was working fine in previous version.
choose "view as" to "hex table" and then change to "json",the data will be chaos.
try to install last version from snapcraft and cant run
i tryed to remove old version and install but it also failed to run.
scroll bar on left side window where we display the list of keys doesn't work.
subscribe channel on console window
receive very long messages (in my case, over 5~6,000 column)
can not drag received text block, and can not copy to clipboard
and horizontal scrollbar not working.
so, can not do anything
every time i start rdm it is blank..
the connections i entered last time are gone and i have to enter all the tedious settings again
rdm should be remembering the connections i have made already
`0!` evaluates to `0`
this causes incorrect results and inability to divide by `0!`.
i press alt + space to pull up wox and type in a file or folder name, nothing shows up
tried different files and folders.
wox 1.4.1196 .3
this happens only during debugging (normally exception is catched).
even though i think it make sense to fix it.
environment variable get failed with wox launch
when i launch the obs from wox
it can't get the environment variable for the plugin
the code is here
#l200
when i turn on my laptop and launch wox, it show me a *microsoft .net framework* error, and it tells me it requested clipboard operation did not succeed.
notice: i installed the *clipboard history* plugin.
when invoking wox multiple times, the index of which result is selected is not reset.
wox places a result that directly matches the query sequence lower than one that has the letters spread out.
1) when trying to use the command shell prompt with the win+r substitution (instead of alt+space, then typing in an angle bracket), it will not always focus on the search bar, so you have to manually click on it in order to execute commands.
2) sometimes, even with the replace win+r combo enabled, you will catch a moment when wox opens the default "run" window, it probably also correlates with the alt+tab key combination the following occurs randomly and doesn\'t have a particular logical branch of steps you could reproduce, these are just the major facts i assume took the role in causing the bug
alt + p c:/programme
alt + d c:/download
lt + d, open current directory c:/download
alt + p open current directory :/download c:/programme
no responding at all when clicking the wox icon or press "alt+space"
icons are blurry on hidpi display except wox and uwp icons
it seems that this bug was introduced on v1.3.881
**not occurs on v1.3.792** and older.
when i close up my laptop and launch it on, my wox will only show me a line, not the input box.
maybe the width of the input box become 1px.
the indexing for wox or everything seems to be using some algorithm that gives uselessly bad results
as it is i see this tool as a complete waste of time for me.
wox just doesn't work from time to time
the cursor is invisible in the system dark theme.
whenever i update wox, installation removes my custom theme files from appdata/local
when i open wox after the update i get error msg "theme alfred not exist, fallback to default theme"
so every time after the update i have add theme files manually.
startup item is wrong: wox.infrastructure.dll
i have to set right path to wox.exe
when launch wox, quite often that would show a big "|" in the screen, without responding any key as wox is in front
i have to restart wox to get rid of it.
the app crashes whenever i attempt to press on an action keyword on the extensions tab of the settings page
no workaround any and all action keywords being changed cause a crash
when the terminal width is less than the width of the auto-completed command, the cursor gets misaligned
### reproduce
sorry for the vague description, i tried to convey the idea the best i can but this one is very difficult to explain
please take a look at this gif:
![autocomplete-bug]( if i disable the autocomplete plugin, the problem goes away
can someone help, please? thanks.
the zsh-autosuggestions is misbehaving
every-time i start writing a command starting with letter `a` , **the shell suggestion adds some gap between the third and second letter.**
for example:
- when if try to write `awk -v` it outputs me this : ![image](
- when trying to start ark from cli, the output is : ![image](
whenever force_float is set, the coloring of the suggestion set with `zsh_autosuggest_highlight_style` is ignored and instead the default coloring is used.
under **cygwin x86_64/x86**
after upgrading zsh from `5.5.1` to `5.8.1` , and enabling `zsh_autosuggest_strategy=(completion)`,
i'm getting the following error after typing commands that trigger suggestions ( ie :`ls<space>` )
zpty:23: can't open pseudo terminal: bad file descriptor
_zsh_autosuggest_strategy_completion:zpty:24: no such pty command: zsh_autosuggest_completion_pty
happens with either `export zsh_autosuggest_use_async=1` or `unset zsh_autosuggest_use_async` reverting back to zsh v5.5.1 fixes the issue.
i use zsh with vi mode enabled (bindkey -v)
when i'm on the command line with an active suggestion and i enter vicmd mode, i want to clear and disable suggestions, but i can't seem to get it to work correctly
i'm pretty new to zsh so it's likely i'm misunderstanding how this is supposed to work.
when i get a suggestion and accept it via right arrow key, the color remains as the autocomplete style, instead of changing back to default.
after installing zsh-autosuggestions on `oh-my-zsh`, after reloading zsh i always get: ```
/home/raul/.oh-my-zsh/custom/plugins/zsh-autosuggestions/zsh-autosuggestions.plugin.zsh:source:1: no such file or directory: /home/raul/.oh-my-zsh/custom/plugins/zsh-autosuggestions/zsh-autosuggestions.zsh^m
when i type
```ssh test```
then press tab i do not get all suggestion for that, but he prompt will be extended to
ssh test.otherstuff.com
the cursor is right at the first ```.```
when i then press tab again the suggestion include everything that is fitting kind of the pattern
```test*.otherstuff.com```
so all the configs in my ssh configs are basically skipped from the suggestions
zprof detail ```
num calls time self name
----------------------------------------------------------------------------------- 1) 194 26.20 0.14 39.05% 26.20 0.14 39.05% _zsh_autosuggest_bind_widget 2) 1 48.39 48.39 72.12% 22.19 22.19 33.07% _zsh_autosuggest_bind_widgets 3) 8 7.94 0.99 11.83% 4.65 0.58 6.93% _zsh_highlight 4) 1 3.15 3.15 4.69% 3.15 3.15 4.69% _z_precmd 5) 2 1.77 0.89 2.64% 1.18 0.59 1.77% _zsh_highlight_main_highlighter_highlight_list 6) 8 9.68 1.21 14.42% 1.12 0.14 1.66% _zsh_highlight_call_widget 7) 5 8.38 1.68 12.49% 1.01 0.20 1.51% _zsh_autosuggest_widget_modify 8) 1 0.83 0.83 1.23% 0.83 0.83 1.23% _zsh_autosuggest_strategy_history 9) 6 7.26 1.21 10.82% 0.79 0.13 1.18% _zsh_autosuggest_invoke_original_widget
10) 2 2.94 1.47 4.38% 0.58 0.29 0.87% _zsh_highlight_highlighter_main_paint
11) 5 7.08 1.42 10.55% 0.53 0.11 0.79% _zsh_autosuggest_modify
12) 2 0.52 0.26 0.77% 0.52 0.26 0.77% title
13) 2 0.38 0.19 0.57% 0.38 0.19 0.57% _zsh_highlight_main_calculate_fallback
14) 5 0.36 0.07 0.53% 0.36 0.07 0.53% url-quote-magic
15) 5 8.67 1.73 12.92% 0.29 0.06 0.43% _zsh_autosuggest_bound_1_self-insert
16) 4 0.24 0.06 0.35% 0.24 0.06 0.35% _zsh_highlight_main__type
17) 1 2.09 2.09 3.11% 0.23 0.23 0.34% _zsh_autosuggest_widget_clear
18) 5 4.98 1.00 7.42% 0.22 0.04 0.32% _zsh_highlight_widget_orig-s0.0000050000-r19059-self-insert
19) 6 0.21 0.04 0.32% 0.21 0.04 0.32% _zsh_autosuggest_highlight_apply
20) 6 0.20 0.03 0.30% 0.20 0.03 0.30% _zsh_autosuggest_highlight_reset
21) 2 0.20 0.10 0.30% 0.20 0.10 0.30% _zsh_highlight_add_highlight
22) 1 0.20 0.20 0.29% 0.20 0.20 0.29% _zsh_highlight_main__precmd_hook
23) 4 0.24 0.06 0.36% 0.16 0.04 0.24% _zsh_highlight_highlighter_main_predicate
24) 2 0.16 0.08 0.24% 0.16 0.08 0.24% _zsh_highlight_main_highlighter__try_expand_parameter
25) 1 0.36 0.36 0.53% 0.15 0.15 0.22% omz_termsupport_preexec
26) 1 0.15 0.15 0.22% 0.15 0.15 0.22% _zle_line_finish
27) 1 0.11 0.11 0.17% 0.11 0.11 0.17% _zle_line_init
28) 1 48.50 48.50 72.28% 0.11 0.11 0.17% _zsh_autosuggest_start
29) 4 0.10 0.03 0.16% 0.10 0.03 0.16% (anon)
30) 1 0.41 0.41 0.61% 0.10 0.10 0.15% omz_termsupport_precmd
31) 1 2.19 2.19 3.26% 0.10 0.10 0.15% _zsh_autosuggest_bound_1_accept-line
32) 2 0.09 0.04 0.13% 0.09 0.04 0.13% _zsh_highlight_main_add_region_highlight
33) 1 1.49 1.49 2.22% 0.09 0.09 0.13% _zsh_highlight_widget_orig-s0.0000050000-r19059-accept-line
34) 3 0.08 0.03 0.12% 0.08 0.03 0.12% _zsh_highlight_buffer_modified
35) 1 0.90 0.90 1.35% 0.08 0.08 0.11% _zsh_autosuggest_fetch_suggestion
36) 2 0.07 0.04 0.11% 0.07 0.04 0.11% _zsh_highlight_main_highlighter_expand_path
37) 1 0.98 0.98 1.45% 0.05 0.05 0.07% _zsh_autosuggest_fetch
38) 1 1.73 1.73 2.57% 0.05 0.05 0.07% _zsh_autosuggest_clear
39) 1 0.83 0.83 1.24% 0.05 0.05 0.07% _zsh_highlight_widget_orig-s0.0000050000-r19059-zle-line-init
40) 1 2.77 2.77 4.13% 0.04 0.04 0.07% _zsh_highlight_widget_orig-s0.0000050000-r19059-zle-line-finish
41) 1 0.03 0.03 0.05% 0.03 0.03 0.05% _zsh_highlight_preexec_hook
42) 2 0.03 0.02 0.04% 0.03 0.02 0.04% _zsh_highlight_main__is_redirection
43) 1 0.02 0.02 0.03% 0.02 0.02 0.03% _zsh_autosuggest_suggest
i'm using the powerlevel10k theme and antigen for loading plugins:
antigen bundle zsh-users/zsh-autosuggestions
``` i noticed that my prompt get slower with zsh-autosuggestions (i.e
just hit return in the terminal has a noticeable lag).
so i benchmarked this with and got this:
without zsh-autosuggestions: ~60 ms per prompt
(average over 3 runs)
with zsh-autosuggestions: ~267 ms per prompt
(average over 3 runs) so clearly, this adds a significant lag
i also profiled my prompt using the instructions at and found out that especially `_zsh_autosuggest_bind_widgets` is taking up a lot of time.
after running the `source .zshrc` command, the color of the auto prompt is displayed incorrectly and is not grayed out.
i added `forward-char` to `zsh_autosuggest_partial_accept_widgets`, but when i press right arrow, it accepts the whole line, instead of just one character.
after i installed `zsh-autosuggestions` and do `export term=xterm-256color`, git highlighting become weired, the color of first line is different from the others: ![git-st]( ![git-lg]( when in `git lg`, if i scroll up and down, the red of first line could become normal.
if i do `git status` one more time, the color could become normal, too
if i disable any one of `zsh-autosuggestions` and `export term=xterm-256color`, the git highlighting become normal
so i think `zsh-autosuggestions` is the problem.
does anybody know why?
if a suggestion is present, using the completion widgets `_most_recent_file`, `_history-complete-newer` and `_history-complete-older` does not clear the suggestion, even when the widgets are present in `zsh_autosuggest_clear_widgets`.
when pressing `esc` and then immediately pressing `l` (vi-forward-char) to finish the completion after a command, the "space" will be removed in-between command and argument.
if an autosuggest is present, and you use c-y to yank (paste), the autosuggest is not cleared
suggestions not cleared after enter
if execute a command that begins with space and pasting text thereafter, previous command is appended to that text.
when sharing the history file between multiple terminal sessions, zsh-autosuggestions doesn't refresh the history if terminal1 types: `vim test`, terminal2 doesn't suggest `vim test`
but if i type `history` in terminal2 the autosuggestion works correct afterwards.
the highlight style seems to change after sourcing `.zshrc`
if i create a new terminal window, the color style is as expected: ![image]( but if i source my `.zshrc` file, it goes to a bold white highlight style which is not what i want (the below screenshot is at the same point as the one above, as is auto-completing the file path)
![image]( echoing out the variable gives the expected result ```
$ echo $zsh_autosuggest_highlight_style
setting suggestion strategy to `completion` or `(completion)` doesn't show tab completions as suggestions.
when pasting a path or other text, the suggestion is not updated in the background
that means, that after pasting a text and pressing the right arrow to go to the end of inserted text, the previous suggestion is inserted
an example of this is shown in the screencast below.
when i try to type something like `
./.env` my terminal becomes practically unresponsive
everything else is reasonably fast
here's video proof:
i've noticed that using the completion feature of zsh-autosuggestions under cygwin, makes the prompt completly unresponsive
i'm aware of the slowness of cygwin's fork(), and using the history strategy, there's a small lag when typing , but after adding the completion option, the prompt will stop responding to any character typed.
only solution i've found is to close the current shell and open a new one.
when using [zsh-syntax-highlighting]( with zsh-autosuggestions the `zsh_autosuggest_highlight_style` doesn't get applied
however when using [trapd00r's fork]( it works just fine.
i'm a long time zsh-autosuggestions user, but i'm seeing this error pop up in my shell interactively now: ```
_zsh_autosuggest_highlight_apply:3: postdisplay: parameter not set
when installing `zsh-autosuggestions` for `oh-my-zsh` on **raspberry pi 3b raspbian (jessie)**, it fails to understand the `{zshcustom:-` part in the install script, and so fails to correctly install the plugin.
there are conflicted between `zsh-users/zsh-syntax-highlighting` and `zsh-users/zsh-autosuggestions`
with both plugins activated, if one continuously uses `zsh_autosuggest_partial_accept_widgets`, the last word of the suggestion will be duplicated.
using `vi-forward-char` in _either_ `viins` or `vicmd` to accept a suggestion will trigger a bell after successfully entering the suggestion.
i load this plugin in the background, after `precmd` hook.
this plugin runs `_zsh_autosuggest_start` after `precmd`.
so, first prompt will be without autosuggestions.
`install.md` lists the [zsh-autosuggestions obs repository]( as a way to install it in ubuntu
however, the release key expired on the 14th of october: ```
$ apt-key adv --list-key 767b5f350f20116f executing: /tmp/apt-key-gpghome.jkwbdodop0/gpg.1.sh --list-key 767b5f350f20116f
pub rsa2048 2017-08-05 [sc] [expired: 2019-10-14] 4919522e6859a90747c6d97a767b5f350f20116f
uid [ expired] shells:zsh-users obs project <shells:zsh-users@build.opensuse.org>
``` i'm not sure if github is the correct place to raise this bug, but i hope that if it isn't, someone can tell where is the right place.
zsh only autocompletes one character when used with st terminal emulator.
cannot change highlight color
ynamictopic opic > 10
stack mqparallel aiting mqmessageutils::buildmessagedata() emplate.waitforresult() analkafkaproducer end emplate.waitforresult() aiting
analkafkaproducer qmessageutils xecutor 6
opic opic ubmit 8 qmessageutils::buildmessagedata() ubmit essage opic emplate.waitforresult()
###
dmin nstance pring.xml
canalrabbitmqconsumer disconnect() channel.close(); connect.close(); ###
``` public void disconnect() { if (channel != null) { // channel try { channel.close(); } catch (ioexception | timeoutexception e) { throw new canalclientexception("stop channel error", e); } } if (connect != null) { try { connect.close(); } catch (ioexception e) { throw new canalclientexception("stop connect error", e); } } }
when finish binlog dump mode ,back to normal, dumperrorcount never be clean , then go into binlog dump mode again, but position is not belong binlog file in oss , endless retrying ...
canal
o.s.beans.generictypeawarepropertydescriptor - invalid javabean property 'connectioncharset' being accessed! ambiguous write methods found next to actually used [public void com.alibaba.otter.canal.parse.inbound.mysql.abstractmysqleventparser.setconnectioncharset(java.lang.string)]: [public void com.alibaba.otter.canal.parse.inbound.mysql.abstractmysqleventparser.setconnectioncharset(java.nio.charset.charset)]
com.alibaba.otter.canal.rocketmq.canalrocketmqproducer#sendmessage public messagequeue select(list<messagequeue> mqs, message msg, object arg) { if (partition > mqs.size()) { return mqs.get(partition % mqs.size()); } else { return mqs.get(partition); } } partition == mqs.size() rrayindexoutofboundsexception ```
canalrocketmqproducer xecutortemplate uildmessagedata orker oker uildmessagedata
2019-11-04 14:07:32.088 [multistagecoprocessor-other-canal_instance_wst_kcbzz-0] warn c.a.otter.canal.parse.inbound.mysql.tsdb.memorytablemeta - parse faield : create database `wst_kcbzz` character set 'utf8mb4' collate 'utf8mb4_bin'
com.alibaba.fastsql.sql.parser.parserexception: syntax error, error in :'character set 'utf8mb4' collate 'utf8mb4', expect null, actual null, pos 51, line 1, column 43, token literal_chars utf8mb4 at com.alibaba.fastsql.sql.parser.sqlparser.printerror(sqlparser.java:430) ~[fastsql-2.0.0_preview_973.jar:2.0.0_preview_973] at com.alibaba.fastsql.sql.parser.sqlparser.accept(sqlparser.java:438) ~[fastsql-2.0.0_preview_973.jar:2.0.0_preview_973] at com.alibaba.fastsql.sql.dialect.mysql.parser.mysqlstatementparser.parsecreatedatabase(mysqlstatementparser.java:7756) ~[fastsql-2.0.0_preview_973.jar:2.0.0_preview_973] at com.alibaba.fastsql.sql.dialect.mysql.parser.mysqlstatementparser.parsecreate(mysqlstatementparser.java:307) ~[fastsql-2.0.0_preview_973.jar:2.0.0_preview_973] at com.alibaba.fastsql.sql.parser.sqlstatementparser.parsestatementlist(sqlstatementparser.java:231) ~[fastsql-2.0.0_preview_973.jar:2.0.0_preview_973] at com.alibaba.fastsql.sql.sqlutils.parsestatements(sqlutils.java:536) ~[fastsql-2.0.0_preview_973.jar:2.0.0_preview_973] at com.alibaba.fastsql.sql.repository.schemarepository.console(schemarepository.java:439) ~[fastsql-2.0.0_preview_973.jar:2.0.0_preview_973] at com.alibaba.otter.canal.parse.inbound.mysql.tsdb.memorytablemeta.apply(memorytablemeta.java:83) ~[canal.parse-1.1.4.jar:na] at com.alibaba.otter.canal.parse.inbound.mysql.tsdb.databasetablemeta.apply(databasetablemeta.java:156) [canal.parse-1.1.4.jar:na] at com.alibaba.otter.canal.parse.inbound.mysql.dbsync.tablemetacache.apply(tablemetacache.java:238) [canal.parse-1.1.4.jar:na] at com.alibaba.otter.canal.parse.inbound.mysql.dbsync.logeventconvert.parsequeryevent(logeventconvert.java:273) [canal.parse-1.1.4.jar:na] at com.alibaba.otter.canal.parse.inbound.mysql.dbsync.logeventconvert.parse(logeventconvert.java:118) [canal.parse-1.1.4.jar:na] at com.alibaba.otter.canal.parse.inbound.mysql.mysqlmultistagecoprocessor$simpleparserstage.onevent(mysqlmultistagecoprocessor.java:292) [canal.parse-1.1.4.jar:na] at com.alibaba.otter.canal.parse.inbound.mysql.mysqlmultistagecoprocessor$simpleparserstage.onevent(mysqlmultistagecoprocessor.java:246) [canal.parse-1.1.4.jar:na] at com.lmax.disruptor.batcheventprocessor.processevents(batcheventprocessor.java:168) [disruptor-3.4.2.jar:na] at com.lmax.disruptor.batcheventprocessor.run(batcheventprocessor.java:125) [disruptor-3.4.2.jar:na] at java.util.concurrent.executors$runnableadapter.call(executors.java:511) [na:1.8.0_181] at java.util.concurrent.futuretask.run(futuretask.java:266) [na:1.8.0_181] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) [na:1.8.0_181] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) [na:1.8.0_181] at java.lang.thread.run(thread.java:748) [na:1.8.0_181]
mysql ime 00:00:01 anal 0:00:01 00 01:00:01 debug owslogbuffer ug 59 >= 100
``` if (d > 100) { builder.append(string.valueof(d)); } else { appendnumber2(builder, d); }
``` public static void appendnumber2(stringbuilder builder, int d) { if (d >= 10) { builder.append(digits[(d / 10) % 10]).append(digits[d % 10]); } else { builder.append('0').append(digits[d]); } }
appendnumber2 00 0
canal afka estinations afka
estination anal egintransaction() egintransaction() afka exception trace:
error com.alibaba.otter.canal.server.canalmqstarter - transactionalid canal-transactional-id: invalid transition attempted from state in_transact
ion to state in_transaction
org.apache.kafka.common.kafkaexception: transactionalid canal-transactional-id: invalid transition attempted from state in_transaction to state in_transaction at org.apache.kafka.clients.producer.internals.transactionmanager.transitionto(transactionmanager.java:758) ~[kafka-clients-1.1.1.jar:na] at org.apache.kafka.clients.producer.internals.transactionmanager.transitionto(transactionmanager.java:751) ~[kafka-clients-1.1.1.jar:na] at org.apache.kafka.clients.producer.internals.transactionmanager.begintransaction(transactionmanager.java:216) ~[kafka-clients-1.1.1.jar:na] at org.apache.kafka.clients.producer.kafkaproducer.begintransaction(kafkaproducer.java:587) ~[kafka-clients-1.1.1.jar:na] at com.alibaba.otter.canal.kafka.canalkafkaproducer.send(canalkafkaproducer.java:106) ~[canal.server-1.1.3.jar:na] at com.alibaba.otter.canal.server.canalmqstarter.worker(canalmqstarter.java:182) [canal.server-1.1.3.jar:na] at com.alibaba.otter.canal.server.canalmqstarter.access$500(canalmqstarter.java:22) [canal.server-1.1.3.jar:na] at com.alibaba.otter.canal.server.canalmqstarter$canalmqrunnable.run(canalmqstarter.java:224) [canal.server-1.1.3.jar:na] at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) [na:1.8.0_171] at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) [na:1.8.0_171] at java.lang.thread.run(thread.java:748) [na:1.8.0_171]
canal json "null" "null" mysql son "null" [mysql]( [rfc 7159]( json
json literal > 3
values a json value must be an object, array, number, or string, or one of the following three literal names: false null true the literal names must be lowercase
no other literal names are allowed
value = false / null / true / object / array / number / string mysql json "null" null/null "null" canal
case literal_null: buf.append("null"); break
"null"
kafka canal.properties
######### binlog filter config
canal.instance.filter.druid.ddl = true
canal.instance.filter.query.dcl = true
canal.instance.filter.query.dml = false
canal.instance.filter.query.ddl = true
canal.instance.filter.table.error = true
canal.instance.filter.rows = false
canal.instance.filter.transaction.entry = false
##################################################
######### mq #############
##################################################
canal.mq.servers = 192.168.1.15:9092,192.169.1.16:9092,192.168.1.15:9092
canal.mq.retries = 3
canal.mq.batchsize = 16384
canal.mq.maxrequestsize = 1048576
canal.mq.lingerms = 1
canal.mq.buffermemory = 33554432
canal.mq.canalbatchsize = 50
canal.mq.canalgettimeout = 100
canal.mq.flatmessage = false
canal.mq.compressiontype = none
canal.mq.acks = all
######### use transaction for kafka flatmessage batch produce
canal.mq.transaction = false instance.properties
######### table regex
canal.instance.filter.regex=schema.table
######### table black regex
canal.instance.filter.black.regex=
######### mq config
canal.mq.topic=topic
canal.mq.partition=0
######### hash partition config
canal.mq.partitionsnum=8
canal.mq.partitionhash=.\\*\\\\\\\\..\\* ######### kafka ########
@kafkalistener(topics = "${spring.kafka.consumer.topic}", containerfactory = "kafkalistenercontainerfactory") public void consumerlistener(kafkamessage message, acknowledgment ack) { try { boolean success = true; message canalmessage = message.getmessage(); if(canalmessage != null) { if (canalmessage.getid() != -1 && canalmessage.getentries().size() > 0) { success = printentry(canalmessage.getentries()); } } if(success) ack.acknowledge(); }catch (exception e) { logger.error(e.getmessage(), e); } }
> ysql anal lter anal --> kafka dapter base
afka anal inlog opic opic afka esize opic edis_cachecloud_qrtz_fired_triggers
error error while creating log for redis_cachecloud_qrtz_fired_triggers-0 in dir e:\\kafka\\logs\\kafka2 (kafka.server.logdirfailurechannel)
java.io.ioexception: at java.io.randomaccessfile.setlength(native method) at kafka.log.abstractindex$$anonfun$resize$1.apply$mcz$sp(abstractindex.scala:186) at kafka.log.abstractindex$$anonfun$resize$1.apply(abstractindex.scala:173) at kafka.log.abstractindex$$anonfun$resize$1.apply(abstractindex.scala:173) at kafka.utils.coreutils$.inlock(coreutils.scala:251) at kafka.log.abstractindex.resize(abstractindex.scala:173) at kafka.log.abstractindex$$anonfun$trimtovalidsize$1.apply$mcz$sp(abstractindex.scala:242) at kafka.log.abstractindex$$anonfun$trimtovalidsize$1.apply(abstractindex.scala:242) at kafka.log.abstractindex$$anonfun$trimtovalidsize$1.apply(abstractindex.scala:242) at kafka.utils.coreutils$.inlock(coreutils.scala:251) at kafka.log.abstractindex.trimtovalidsize(abstractindex.scala:241) at kafka.log.logsegment.recover(logsegment.scala:377) at kafka.log.log.kafka$log$log$$recoversegment(log.scala:467) at kafka.log.log.kafka$log$log$$recoverlog(log.scala:581) at kafka.log.log$$anonfun$2.apply$mcj$sp(log.scala:552) at kafka.log.log$$anonfun$2.apply(log.scala:552) at kafka.log.log$$anonfun$2.apply(log.scala:552) at kafka.log.log.retryonoffsetoverflow(log.scala:1938) at kafka.log.log.loadsegments(log.scala:551) at kafka.log.log.<init>(log.scala:276) at kafka.log.log$.apply(log.scala:2071) at kafka.log.logmanager$$anonfun$getorcreatelog$1.apply(logmanager.scala:691) at kafka.log.logmanager$$anonfun$getorcreatelog$1.apply(logmanager.scala:659) at scala.option.getorelse(option.scala:121) at kafka.log.logmanager.getorcreatelog(logmanager.scala:659) at kafka.cluster.partition$$anonfun$getorcreatereplica$1.apply(partition.scala:199) at kafka.cluster.partition$$anonfun$getorcreatereplica$1.apply(partition.scala:195) at kafka.utils.pool$$anon$2.apply(pool.scala:61) at java.util.concurrent.concurrenthashmap.computeifabsent(concurrenthashmap.java:1660) at kafka.utils.pool.getandmaybeput(pool.scala:60) at kafka.cluster.partition.getorcreatereplica(partition.scala:194) at kafka.cluster.partition$$anonfun$makefollower$1$$anonfun$apply$mcz$sp$3.apply(partition.scala:439) at kafka.cluster.partition$$anonfun$makefollower$1$$anonfun$apply$mcz$sp$3.apply(partition.scala:439) at scala.collection.mutable.resizablearray$class.foreach(resizablearray.scala:59) at scala.collection.mutable.arraybuffer.foreach(arraybuffer.scala:48) at kafka.cluster.partition$$anonfun$makefollower$1.apply$mcz$sp(partition.scala:439) at kafka.cluster.partition$$anonfun$makefollower$1.apply(partition.scala:431) at kafka.cluster.partition$$anonfun$makefollower$1.apply(partition.scala:431) at kafka.utils.coreutils$.inlock(coreutils.scala:251) at kafka.utils.coreutils$.inwritelock(coreutils.scala:259) at kafka.cluster.partition.makefollower(partition.scala:431) at kafka.server.replicamanager$$anonfun$makefollowers$3.apply(replicamanager.scala:1244) at kafka.server.replicamanager$$anonfun$makefollowers$3.apply(replicamanager.scala:1238) at scala.collection.mutable.hashmap$$anonfun$foreach$1.apply(hashmap.scala:130) at scala.collection.mutable.hashmap$$anonfun$foreach$1.apply(hashmap.scala:130) at scala.collection.mutable.hashtable$class.foreachentry(hashtable.scala:236) at scala.collection.mutable.hashmap.foreachentry(hashmap.scala:40) at scala.collection.mutable.hashmap.foreach(hashmap.scala:130) at kafka.server.replicamanager.makefollowers(replicamanager.scala:1238) at kafka.server.replicamanager.becomeleaderorfollower(replicamanager.scala:1076) at kafka.server.kafkaapis.handleleaderandisrrequest(kafkaapis.scala:185) at kafka.server.kafkaapis.handle(kafkaapis.scala:110) at kafka.server.kafkarequesthandler.run(kafkarequesthandler.scala:69) at java.lang.thread.run(thread.java:748)
abstractrequest tc ![image](
![image]( ![image](
2018-12-26 11:36:30.202 [destination = chess , address = mysql/10.0.0.5:3306 , eventparser] warn c.a.o.c.p.inbound.mysql.rds.rdsbinlogeventparserproxy - ---> begin to find start position, it will be long time for reset or first position
2018-12-26 11:36:30.202 [destination = chess , address = mysql/10.0.0.5:3306 , eventparser] warn c.a.o.c.p.inbound.mysql.rds.rdsbinlogeventparserproxy - prepare to find start position just show master status
2018-12-26 11:36:30.204 [destination = chess , address = mysql/10.0.0.5:3306 , eventparser] error c.a.o.c.p.inbound.mysql.rds.rdsbinlogeventparserproxy - dump address mysql/10.0.0.5:3306 has an error, retrying
caused by java.lang.illegalargumentexception: invalid charset id: 255 at com.taobao.tddl.dbsync.binlog.charsetconversion.getentry(charsetconversion.java:41) ~[canal.parse.dbsync-1.1.2.jar:na] at com.taobao.tddl.dbsync.binlog.charsetconversion.getjavacharset(charsetconversion.java:299) ~[canal.parse.dbsync-1.1.2.jar:na] at com.taobao.tddl.dbsync.binlog.event.querylogevent.<init>(querylogevent.java:503) ~[canal.parse.dbsync-1.1.2.jar:na] at com.taobao.tddl.dbsync.binlog.logdecoder.decode(logdecoder.java:168) ~[canal.parse.dbsync-1.1.2.jar:na] at com.taobao.tddl.dbsync.binlog.logdecoder.decode(logdecoder.java:111) ~[canal.parse.dbsync-1.1.2.jar:na] at com.alibaba.otter.canal.parse.inbound.mysql.mysqlconnection.seek(mysqlconnection.java:137) ~[canal.parse-1.1.2.jar:na] at com.alibaba.otter.canal.parse.inbound.mysql.mysqleventparser.findaspertimestampinspecificlogfile(mysqleventparser.java:743) ~[canal.parse-1.1.2.jar:na] at com.alibaba.otter.canal.parse.inbound.mysql.mysqleventparser.findendpositionwithmasteridandtimestamp(mysqleventparser.java:392) ~[canal.parse-1.1.2.jar:na] at com.alibaba.otter.canal.parse.inbound.mysql.mysqleventparser.findstartpositioninternal(mysqleventparser.java:447) ~[canal.parse-1.1.2.jar:na] at com.alibaba.otter.canal.parse.inbound.mysql.mysqleventparser.findstartposition(mysqleventparser.java:366) ~[canal.parse-1.1.2.jar:na] at com.alibaba.otter.canal.parse.inbound.abstracteventparser$3.run(abstracteventparser.java:186) ~[canal.parse-1.1.2.jar:na] at java.lang.thread.run(thread.java:748) [na:1.8.0_181]
2018-12-26 11:36:30.205 [destination = chess , address = mysql/10.0.0.5:3306 , eventparser] error com.alibaba.otter.canal.common.alarm.logalarmhandler - destination:chess[java.lang.illegalargumentexception: invalid charset id: 255 at com.taobao.tddl.dbsync.binlog.charsetconversion.getentry(charsetconversion.java:41) at com.taobao.tddl.dbsync.binlog.charsetconversion.getjavacharset(charsetconversion.java:299) at com.taobao.tddl.dbsync.binlog.event.querylogevent.<init>(querylogevent.java:503) at com.taobao.tddl.dbsync.binlog.logdecoder.decode(logdecoder.java:168) at com.taobao.tddl.dbsync.binlog.logdecoder.decode(logdecoder.java:111) at com.alibaba.otter.canal.parse.inbound.mysql.mysqlconnection.seek(mysqlconnection.java:137) at com.alibaba.otter.canal.parse.inbound.mysql.mysqleventparser.findaspertimestampinspecificlogfile(mysqleventparser.java:743) at com.alibaba.otter.canal.parse.inbound.mysql.mysqleventparser.findendpositionwithmasteridandtimestamp(mysqleventparser.java:392) at com.alibaba.otter.canal.parse.inbound.mysql.mysqleventparser.findstartpositioninternal(mysqleventparser.java:447) at com.alibaba.otter.canal.parse.inbound.mysql.mysqleventparser.findstartposition(mysqleventparser.java:366) at com.alibaba.otter.canal.parse.inbound.abstracteventparser$3.run(abstracteventparser.java:186) at java.lang.thread.run(thread.java:748)
error com.alibaba.otter.canal.common.alarm.logalarmhandler - destination:assetsync[com.alibaba.otter.canal.parse.exception.canalparseexception: com.alibaba.otter.canal.parse.exception.canalparseexception: java.lang.classcastexception: com.alibaba.fastsql.sql.visitor.sqlastoutputvisitor cannot be cast to com.alibaba.fastsql.sql.dialect.mysql.visitor.mysqlastvisitor
caused by: com.alibaba.otter.canal.parse.exception.canalparseexception: java.lang.classcastexception: com.alibaba.fastsql.sql.visitor.sqlastoutputvisitor cannot be cast to com.alibaba.fastsql.sql.dialect.mysql.visitor.mysqlastvisitor
caused by: java.lang.classcastexception: com.alibaba.fastsql.sql.visitor.sqlastoutputvisitor cannot be cast to com.alibaba.fastsql.sql.dialect.mysql.visitor.mysqlastvisitor at com.alibaba.fastsql.sql.dialect.mysql.ast.expr.mysqlorderingexpr.accept0(mysqlorderingexpr.java:64) at com.alibaba.fastsql.sql.ast.sqlobjectimpl.accept(sqlobjectimpl.java:51) at com.alibaba.fastsql.sql.ast.sqlobjectimpl.output(sqlobjectimpl.java:92) at com.alibaba.fastsql.sql.ast.sqlobjectimpl.output(sqlobjectimpl.java:77) at com.alibaba.fastsql.sql.ast.sqlobjectimpl.tostring(sqlobjectimpl.java:99) at com.alibaba.otter.canal.parse.inbound.mysql.tsdb.memorytablemeta.getsqlname(memorytablemeta.java:251) at com.alibaba.otter.canal.parse.inbound.mysql.tsdb.memorytablemeta.processtableelement(memorytablemeta.java:228) at com.alibaba.otter.canal.parse.inbound.mysql.tsdb.memorytablemeta.parse(memorytablemeta.java:155) at com.alibaba.otter.canal.parse.inbound.mysql.tsdb.memorytablemeta.find(memorytablemeta.java:110) at com.alibaba.otter.canal.parse.inbound.mysql.tsdb.databasetablemeta.find(databasetablemeta.java:98) at com.alibaba.otter.canal.parse.inbound.mysql.dbsync.tablemetacache.gettablemeta(tablemetacache.java:162) at com.alibaba.otter.canal.parse.inbound.mysql.dbsync.logeventconvert.gettablemeta(logeventconvert.java:889) at com.alibaba.otter.canal.parse.inbound.mysql.dbsync.logeventconvert.parserowseventfortablemeta(logeventconvert.java:484) at com.alibaba.otter.canal.parse.inbound.mysql.mysqlmultistagecoprocessor$simpleparserstage.onevent(mysqlmultistagecoprocessor.java:252) at com.alibaba.otter.canal.parse.inbound.mysql.mysqlmultistagecoprocessor$simpleparserstage.onevent(mysqlmultistagecoprocessor.java:222) at com.lmax.disruptor.batcheventprocessor.processevents(batcheventprocessor.java:168) at com.lmax.disruptor.batcheventprocessor.run(batcheventprocessor.java:125) at java.util.concurrent.executors$runnableadapter.call(executors.java:511) at java.util.concurrent.futuretask.run(futuretask.java:266) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
, , eata pringbatch @stepscope
seata harding jdbc failed to fetch schema of trend_chart rend_chart
oracle elect for update racle does not support release save point, but this is not a error.
hardingjdbc , ql ow()
ervice @globallock@transactional
ava.lang.runtimeexception: unknow situation!
elete
elete a from test_tbl a where a.'id' = ?
seata v1.1.0
commit commit 61 server commit commit commit 61 commit
![image](
efault current_timestamp on update current_timestamp pdate sql ollback
mysql
heartbeatmessage o.seata.common.util.stringutils#tostring
method threw 'java.lang.stackoverflowerror' exception
cannot evaluate io.seata.core.protocol.rpcmessage.tostring()
mergeresultmessage xid=192.168.202.137:8091:2051472139;extradata=null;
![seata](
![seata](
![seata](
![seata](
seata-server1.1.0 ql
eata pring-cloud-alibaba-seata 2.2.0.release
![image](
![image](
pring-cloud-starter-sleuth leuth,seata
sleuth eata pring-cloud-starter-sleuth eata leuth - jdk version : 1.8
- os : win10
cc ubbo reference ean m m
tc(server) m channel lientid hannel esourceid lientid m lientid
tc c m hannel m s econnect
![image](
![image](
the above configuration items should be converted to camel style.
seata 1.0.0 ,tcc m erver pc ####
pring cloud
edis edis.db
eata1.0 springboot pa racle " " pa eata "demo_table" bstractundoexecutor.java uerycurrentrecords string checksql = string.format(check_sql_template, columnutils.addescape(sqlundolog.gettablename(), dbtype),
tablemeta.getescapepkname(dbtype), replace.substring(0, replace.length() - 1));
elect * from "demo_table" elect * from "demo_table" pa
schedule retry rollback cause repeated rollback
startup failure when dynamic proxy is turned on and use druid-spring-boot-starter
eata-all eata-spring-boot-starter , cript ml
when enable auto proxying of datasouce which has final modifier,it will cause a exception means the class can't be proxied by using cglib.
mysql 5.7.22 tinyint 1 , undo_log true false, , 4, 1, undo_log true ,
environment: - jdk version : 1.8
- os : centos7.4
- others: mysql 5.7.22
travis-ci exceeded the maximum log length
duplicated cache key in tablemetacache in some case because the single quote or double quote or case sensitive.
rootcontext.java 2
idtype==null
throw invalid argument value: java.io.notserializableexception when give null to parameter in mapper.xml
if the serializer is protostuff, invoking getdefaultcontent() method would return a byte array with no elements
it would eventually throw serialexception when executing insertundologwithglobalfinished method
because setblob method of clientpreparedquerybindings class would fetch bytes from the position 1 in mysql-connector-java jar.
the branch register request failed while having multiple locks on one row
1 racle varchar2 archar2
2 racle ould not found any index in the table bmd chema
when we use the sql like "select * from table where id = 1 for update", would cause this exception.
if the database table name uses a keyword such as order ybatis automatically symbolizes the table name when sql is executed(`order`) he resulting tablemeta is null
if the table has clob or blob column, and the column value was null, it will cause rollback failed.
this is the sql
update a_ru_temp tmp
set tmp.cur_node_ins_id = ( select b.node_ins_id from b_ru_temp b where tmp.cur_process_ins_id = b.process_ins_id and tmp.cur_node_id = b.node_id
where exists ( select 1 from b_ru_temp b where tmp.cur_process_ins_id = b.process_ins_id and tmp.cur_node_id = b.node_id )
insert sql can not rs.getgeneratedkeys() because genkeys.getgeneratedkeys() operation in insertexecutor, cause the rs cursor move to last.
o.seata.rm.tcc.interceptor.actioninterceptorhandler 126 : tcc branch register error, xid:10.35.226.31:8091:2016957836 io.seata.core.exception.transactionexception id 1
class o.seata.server.coordinator.defaultcore private globalsession assertglobalsessionnotnull(string xid) throws transactionexception { globalsession globalsession = sessionholder.findglobalsession(xid); if (globalsession == null) { throw new transactionexception(transactionexceptioncode.globaltransactionnotexist, "" + xid + ""); } return globalsession; } 2 id:10.35.226.31:8091:2016957836 3 ootcontext.unbind() id class o.seata.tm.api.defaultglobaltransaction public void commit() throws transactionexception { if (role == globaltransactionrole.participant) { // participant has no responsibility of committing if (logger.isdebugenabled()) { logger.debug("ignore commit(): just involved in global transaction [" + xid + "]"); } return; } if (xid == null) { throw new illegalstateexception(); } status = transactionmanager.commit(xid); if (rootcontext.getxid() != null) { if (xid.equals(rootcontext.getxid())) { rootcontext.unbind(); } } if (logger.isinfoenabled()) { logger.info("[" + xid + "] commit status:" + status); } } 4 d class io.seata.tm.api.transactionaltemplate public object execute(transactionalexecutor business) throws throwable { // 1
get or create a transaction globaltransaction tx = globaltransactioncontext.getcurrentorcreate(); // 1.1 get transactioninfo transactioninfo txinfo = business.gettransactioninfo(); if (txinfo == null) { throw new shouldneverhappenexception("transactioninfo does not exist"); } try { // 2
begin transaction begintransaction(txinfo, tx); object rs = null; try { // do your business rs = business.execute(); } catch (throwable ex) { // 3.the needed business exception to rollback
completetransactionafterthrowing(txinfo,tx,ex); throw ex; } // 4
everything is fine, commit
committransaction(tx); return rs; } finally { //5
clear triggeraftercompletion(); cleanup(); } } class o.seata.tm.api.globaltransactioncontext /** * get globaltransaction instance bind on current thread
* * @return null if no transaction context there
*/ private static globaltransaction getcurrent() { string xid = rootcontext.getxid(); if (xid == null) { return null; } return new defaultglobaltransaction(xid, globalstatus.begin, globaltransactionrole.participant); } /** * get globaltransaction instance bind on current thread
create a new on if no existing there
* * @return new context if no existing there
*/ public static globaltransaction getcurrentorcreate() { globaltransaction tx = getcurrent(); if (tx == null) { return createnew(); } return tx; }
with the table name named as mysql keyword
sql as 'order', when tablemetacache#fetchschemeindefaultway() invoked
there will be throw exception; ysql tring order
tring ``
when i use oracle, i found it can not refresh table meta when i change the table structure
because the thread of oracle that use to call refresh method that was use for mysql and it can not found any cache information that base on thread.
hibernate batch insert example:
`for (int j = 0; j < logs.length; j++) {` `operationlog log = logs[j];` `operationlogdao.save(log);`
`}` exception example: `java.lang.arrayindexoutofboundsexception`
`2019-09-25 09:24:32,897 warn [org.hibernate.util.jdbcexceptionreporter] - sql error: 0, sqlstate: null`
`2019-09-25 09:24:32,898 error [org.hibernate.util.jdbcexceptionreporter] - error`
`2019-09-25 09:24:32,898 error [org.hibernate.event.def.abstractflushingeventlistener] - could not synchronize database state with session`
`org.hibernate.exception.genericjdbcexception: could not execute jdbc batch update`
`2019-09-25 09:24:32,900 error [com.alibaba.druid.util.jdbcutils] - close connection error`
`java.sql.sqlexception: : [8, 1]`
2019-09-25 09:24:32,901 error [com.alibaba.druid.pool.druiddatasource] - discard connection
java.sql.sqlexception: : [0]
`2019-09-25 09:24:32,902 error [org.hibernate.transaction.jdbctransaction] - could not toggle autocommit`
`java.sql.sqlexception: connection holder is null`
unit test class: io.seata.server.event.defaultcoreforeventbustest error message:
[error] tests run: 1, failures: 1, errors: 0, skipped: 0, time elapsed: 1.042 s <<< failure! - in io.seata.server.event.defaultcoreforeventbustest
[error] test time elapsed: 1.041 s <<< failure!
org.opentest4j.assertionfailederror: expected: <1> but was: <2> at io.seata.server.event.defaultcoreforeventbustest.test(defaultcoreforeventbustest.java:82)
when sql like this
delete from table where id in (1)
delete from table where id between 1 and 2
will cause the exception
pringcloud penfeign acos eata odel: db
c ![image](
![image]( ### f5
![image]( ### /b
io.seata.core.exception.globaltransactionexception: could not found global transaction xid = 192.168.2.12:8091:2022968728 at io.seata.server.coordinator.defaultcore.assertglobalsessionnotnull(defaultcore.java:99) id ranchid
1 id=192.168.2.12:8091:2022968725
![image]( 2 id=192.168.2.12:8091:2022968728 ![image]( ![image](
i used seata in my dubbo project
there were three projects, two of which used sharding-jdbc
i configured and tested that errors in these two projects could be rolled back, and data was generated in the undo_log table and the table data was deleted after the rollback was successful
but when i added a new project method to the previous method, the data could not be rolled back successfully, and no data was generated in the undo_log table
i carefully compared the configuration files of the three projects and the logs of seata-server at startup
the only difference was that the third project first reminded registerrmrequest {resourceids='null'at startup, but the second one successfully printed the link address of the database resources
i hope i can get some help
thank you very much
there is the log : ```
019-09-21 14:40:32.716 [configoperate_1_2] warn io.seata.config.fileconfiguration-could not found property service.disableglobaltransaction, try to use default value instead
2019-09-21 14:40:32.718 [main] info i.seata.spring.annotation.globaltransactionscanner-initializing global transaction clients ..
2019-09-21 14:40:33.498 [main] info io.seata.core.rpc.netty.abstractrpcremotingclient-rpcclientbootstrap has started 2019-09-21 14:40:33.503 [main] info i.seata.spring.annotation.globaltransactionscanner-transaction manager client is initialized
applicationid[my_test_tx_group] txservicegroup[my_test_tx_group] 2019-09-21 14:40:33.541 [main] info io.seata.rm.datasource.asyncworker-async commit buffer limit: 10000 2019-09-21 14:40:33.672 [main] info io.seata.core.rpc.netty.abstractrpcremotingclient-rpcclientbootstrap has started 2019-09-21 14:40:33.674 [main] info i.seata.spring.annotation.globaltransactionscanner-resource manager is initialized
applicationid[my_test_tx_group] txservicegroup[my_test_tx_group] 2019-09-21 14:40:33.674 [main] info i.seata.spring.annotation.globaltransactionscanner-global transaction clients are initialized
2019-09-21 14:40:38.509 [timeoutchecker_1] info io.seata.core.rpc.netty.nettyclientchannelmanager-will connect to 10.33.250.239:8091 2019-09-21 14:40:38.515 [timeoutchecker_1] info io.seata.core.rpc.netty.nettypoolablefactory-nettypool create channel to transactionrole:tmrole,address:10.33.250.239:8091,msg:< registertmrequest{applicationid='my_test_tx_group', transactionservicegroup='my_test_tx_group'} > 2019-09-21 14:40:38.673 [timeoutchecker_1] info io.seata.core.rpc.netty.nettyclientchannelmanager-will connect to 10.33.250.239:8091 2019-09-21 14:40:38.674 [timeoutchecker_1] info io.seata.core.rpc.netty.rmrpcclient-rm will register :null 2019-09-21 14:40:38.675 [timeoutchecker_1] info io.seata.core.rpc.netty.nettypoolablefactory-nettypool create channel to transactionrole:rmrole,address:10.33.250.239:8091,msg:< registerrmrequest{resourceids='null', applicationid='my_test_tx_group', transactionservicegroup='my_test_tx_group'} > 2019-09-21 14:40:39.283 [configoperate_1_2] warn io.seata.config.fileconfiguration-could not found property transport.serialization, try to use default value instead
2019-09-21 14:40:39.286 [configoperate_1_2] warn io.seata.config.fileconfiguration-could not found property transport.compressor, try to use default value instead
2019-09-21 14:40:39.374 [nettyclientselector_rmrole_1] info io.seata.common.loader.enhancedserviceloader-load codec[seata] extension by class[io.seata.codec.seata.seatacodec] 2019-09-21 14:40:39.498 [timeoutchecker_1] info io.seata.core.rpc.netty.nettypoolablefactory-register success, cost 185 ms, version:0.8.0,role:tmrole,channel:[id: , l:/10.33.250.207:58936 - r:/10.33.250.239:8091] 2019-09-21 14:40:39.498 [timeoutchecker_1] info io.seata.core.rpc.netty.rmrpcclient-register rm success
server version:0.8.0,channel:[id: , l:/10.33.250.207:58937 - r:/10.33.250.239:8091] 2019-09-21 14:40:39.501 [timeoutchecker_1] info io.seata.core.rpc.netty.nettypoolablefactory-register success, cost 222 ms, version:0.8.0,role:rmrole,channel:[id: , l:/10.33.250.207:58937 - r:/10.33.250.239:8091] 2019-09-21 14:40:41.134 [main] info com.alibaba.druid.pool.druiddatasource-{datasource-1} inited 2019-09-21 14:40:41.514 [main] info io.seata.core.rpc.netty.rmrpcclient-register to rm resourceid:jdbc:mysql://10.33.250.20:3306/shby_db_agma 2019-09-21 14:40:41.516 [main] info io.seata.core.rpc.netty.rmrpcclient-register resource, resourceid:jdbc:mysql://10.33.250.20:3306/shby_db_agma ```
when set support.spring.datasource.autoproxy = true,and druid-spring-boot-starter is used, it creates a druiddatasourcewrapper instead of creating the original druiddatasource directly, but druiddatasourcewrapper does not use the "public" modifier to modify it, it only has access to the package.
![image]( ![image](
when set useinformationschema equals ture like this
jdbc:mysql://127.0.0.1:3306/xxx?useinformationschema=false
mysql will use databasemetadatausinginfoschema instead of databasemetadata if your table name is a keyword like 'order' will cause the exception.
when pass jvm parameter to seata-server.sh,will cause the follwoing error:
` option error was passed main parameter '-dseataenv=test' but no main parameter was defined in your arg class.`
seata-all 0.8.1 t db 2 global lock wait timout
![image](
oracle 0.8.1-snapshot
create table "testx" ( "id" int not null , "name" varchar(32) not null, primary key ("id")
jdbctemplate.update("insert into \\"test\\".\\"testx\\" (\\"id\\",\\"name\\") values(1,\'123\')");
![image](
create table test_keyword( `in` varchar(45) primary key, `desc` varchar(45)
) insert into test_keyword values(?, ?)
bug 1: when seata-server runs in memory mode, get global lock failure always happens(seata-server couldn't get the memorylocker because branchsession is null)
when i resolve first bug, the second shows up
bug 2: i change a sample project(springboot-dubbo-seata), and add a global lock test to it.
when global transaction running, global lock feature will lost retry mechanism, because retry mechanism located in selectforupdateexecutor, but it only put the pks in context, and these pks's useability will been **checked only if do commit**, however at this time, retry process already finished
this is only a little issue, campare with what i will talk about next
bug 3: in description of bug 2, we already know that global lock will check pks useability when do commit
now consider follow situation: 1
i wanna use `select for update` as a lock(with @globallock)
2.another global transaction(gt) is runing too, and phase 1 just finished, but pks' lock is still holding by this global transaction in tc
now i try to execute `select for update` in a local transaction(lt), with @globallock
because gt phase 1 finished, so i get the db's row lock, but because i need to do some jobs with holding this db's lock, so i amn't finish my lt immediately.
because lt isn't been committed, so seata will not check these pks' lock to tc,now in my view, there isn't concurrent global transaction using these pks' lock, then i do my jobs with holding db's row lock
after i finish my jobs, and do lt commit, a lock conflict exception throwed, but i already finish my jobs in my opinion, once i use @globallock and `select for update`, my transaction is in read_commited level, but actually it isn't.
the sql returned by getqueryglobaltransactionsqlbystatus method in logstoresqls doesn't support oracle.
if druid version is a little old (< 1.1.3), nosuchmethoderror occured, `com.alibaba.druid.util.stringutils.isempty(ljava/lang/string;)z` is not included in those druid releases.
server will send the delete undo log request every 24 hours, but i fount the problems is, if i use oracle, it will throw the exception.
develop branch: ![image](
![image](
![image](
![image]( ![image]( electforupdateexcute indows10
statementproxy.getconnectionproxy().checklock(lockkeys);
seata ession ull ession ile
there are two global transactionals such as:
@globaltransactional
a() @globaltransactional
a() and b() use diffenert schemas and do not influence each other.
now i call a() and b() in the same function:
fuction c() { a(); b();
![image]( ranch_update ranch_remove
when a branch transcation deal the same table and same record more than once ,such as insert into table test(id,name) values(1, yname )
delete from table test where id =1; the seata will record the undolog in this order insert----delete shoudn't the order of the undolog be the reverse of the actual operation.
when build afterimage or undo error,branch transaction is still executing.
when meta-inf/services/xxxx file class depend library or class not found , enhancedserviceloader#loadfile execute `class.forname(line, true, classloader)` may be throw linkageerror or classnotfoundexception
when project lack serialization dependence can't generate undo_log.
such as jackson
if not sql exception will call report(false) and report(true)
![95)@t 8~}9{6}_y`exkao2](
![$y76d v~$mobwva v2m7n0]( create table `test1`.`order_tbl` ( `order_id` int(11) not null auto_increment, `order_num` int(11) not null, `order_date` timestamp(0) not null default current_timestamp, primary key (`order_id`) using btree
) engine = innodb auto_increment = 4 character set = utf8 collate = utf8_general_ci row_format = dynamic; when i use sql 'insert into order_tbl(order_id,order_num,order_date) values (1, 100, ?) ', it will throw an exception, then i check the exception and i find that if i have no value of primary key, building after-image sql will get an unnecessary 'where' and then throw exception and what does cyclenums means? update:
i see that i must use parameter list to build sql and seata use cyclenums to check the value of primary key how can i just use sql without no parameters? like insert into order_tbl(order_id,order_num,order_date) values (1, 100, '2019-08-16') ? seata version: 0.8.0-snapshot
got branchrollback failed reason [2019387415/192.168.0.55:8091:2019387410 has dirty records when undo.]
i run the seata-example for **springcloud-eureka-seata** is ok.
and the first call to the **/purchase/commit** interface, whether it is a successful or failed rollback, is ok, if successful, the page returns as follows
![image](
or the stock is insufficient or the balance is insufficient
the return is like this:
![image](
but when i call this interface for the second time, it will return to me whether it is in stock or not:
![image](
i'm using activiti for work flow process, when i start a process, it will insert an execution in database, but i got an exception says 'java.sql.sqlsyntaxerrorexception: you have an error in your sql syntax; check the manual that corresponds to your mysql server version for the right syntax to use near '' at line 1', i try to execute the sql use the same params in navicat, there is no problem, when i remove the @globaltransactional, it's work fine too.
eata-samples eata-samples-dubbo
ithub own eata-example pring cloud eureka odule
h seata-server.sh -p 8091 -h 127.0.0.1 -m db erver
![image](
ureka 761
![image](
ccount
![image](
ccount
![image](
![image](
![image](
![image](
![image](
![image](
seata+druild + mybatis
![image]( i'm not sure it's a bug
but i need help!
![image]( - jdk version :1.8
missing exception detail , no log ,no throw, ![ ](
at @globaltransactional method idea debug, business console print **warn** log
at idea no debug running is normal
pa ackson
bom/pom
``` <dependency> <groupid>com.fasterxml.jackson.datatype</groupid> <artifactid>jackson-datatype-hibernate5</artifactid> <version>${jackson.version}</version> </dependency> <dependency> <groupid>com.fasterxml.jackson.datatype</groupid> <artifactid>jackson-datatype-hppc</artifactid> <version>${jackson.version}</version> </dependency> <dependency> <groupid>com.fasterxml.jackson.datatype</groupid> <artifactid>jackson-datatype-jsr310</artifactid> <version>${jackson.version}</version> </dependency> <dependency> <groupid>com.fasterxml.jackson.module</groupid> <artifactid>jackson-module-afterburner</artifactid> <version>${jackson.version}</version> </dependency>
2. m-datasource om :
``` <dependency> <groupid>com.fasterxml.jackson.datatype</groupid> <artifactid>jackson-datatype-hibernate5</artifactid> </dependency> <dependency> <groupid>com.fasterxml.jackson.datatype</groupid> <artifactid>jackson-datatype-hppc</artifactid> </dependency> <dependency> <groupid>com.fasterxml.jackson.datatype</groupid> <artifactid>jackson-datatype-jsr310</artifactid> </dependency> <dependency> <groupid>com.fasterxml.jackson.module</groupid> <artifactid>jackson-module-afterburner</artifactid> </dependency>
3. m-datasource om racle
``` <dependency> <groupid>com.oracle</groupid> <artifactid>ojdbc8</artifactid> <version>18.3.0.0</version> <scope>system</scope> <systempath>${basedir}/src/main/lib/ojdbc8-18.3.0.0.jar</systempath> </dependency>
4. m-datasource m-datasource\\src\\main\\java\\io\\seata\ m\\datasource\\undo\\parser\\jacksonundologparser.java tatic :
``` static { mapper.registermodule(new javatimemodule()); mapper.registermodule(new hibernate5module()); mapper.configure(jsongenerator.feature.escape_non_ascii, true); mapper.disable(serializationfeature.write_dates_as_timestamps); mapper.configure(deserializationfeature.fail_on_unknown_properties, false); mapper.enabledefaulttyping(objectmapper.defaulttyping.non_final, jsontypeinfo.as.property); }
5. m-datasource\\src\\main\\java\\io\\seata\ m\\datasource\\sql\\struct\\tablerecords.java racle.timestamp uildrecords :
``` /** * build records table records
* * @param tmeta the tmeta * @param resultset the result set * @return the table records * @throws sqlexception the sql exception */ public static tablerecords buildrecords(tablemeta tmeta, resultset resultset) throws sqlexception { tablerecords records = new tablerecords(tmeta); resultsetmetadata resultsetmetadata = resultset.getmetadata(); int columncount = resultsetmetadata.getcolumncount(); while (resultset.next()) { list<field> fields = new arraylist<>(columncount); for (int i = 1; i <= columncount; i++) { string colname = resultsetmetadata.getcolumnname(i); columnmeta col = tmeta.getcolumnmeta(colname); field field = new field(); field.setname(col.getcolumnname()); if (tmeta.getpkname().equals(field.getname())) { field.setkeytype(keytype.primarykey); } field.settype(col.getdatatype()); object object = resultset.getobject(i); if (col.getdatatype() == types.timestamp) {# racle.timestamp timestamp timestamp = (timestamp) object; field.setvalue(timestamp == null ? null : timestamp.timestampvalue());# ackson } else { field.setvalue(object); } fields.add(field); } row row = new row(); row.setfields(fields); records.add(row); } return records; }
in idea debug [springcloud-jpa-seata/order-service]( ```java
@transactional(rollbackfor = exception.class)
public void create(string userid, string commoditycode, integer count) { bigdecimal ordermoney = new bigdecimal(count).multiply(new bigdecimal(5)); order order = new order(); order.setuserid(userid); order.setcommoditycode(commoditycode); order.setcount(count); order.setmoney(ordermoney); orderdao.save(order); /** debug breakpoint */ storagefeignclient.deduct(commoditycode, count);
"**seata-server java.lang.outofmemoryerror: direct buffer memory**" appears during debugging.
seata0.7.1 ureka db
eata-server ( )
seta-server
io.seata.core.exception.transactionexception: null
at io.seata.server.coordinator.defaultcore.lambda$branchregister$0(defaultcore.java:79)
at io.seata.server.session.globalsession.lockandexcute(globalsession.java:594)
at io.seata.server.coordinator.defaultcore.branchregister(defaultcore.java:66)
at io.seata.server.coordinator.defaultcoordinator.dobranchregister(defaultcoordinator.java:174)
at io.seata.server.abstracttcinboundhandler$4.execute(abstracttcinboundhandler.java:148)
at io.seata.server.abstracttcinboundhandler$4.execute(abstracttcinboundhandler.java:144)
at io.seata.core.exception.abstractexceptionhandler.exceptionhandletemplate(abstractexceptionhandler.java:117)
at io.seata.server.abstracttcinboundhandler.handle(abstracttcinboundhandler.java:144)
at io.seata.core.protocol.transaction.branchregisterrequest.handle(branchregisterrequest.java:136)
at io.seata.server.coordinator.defaultcoordinator.onrequest(defaultcoordinator.java:430)
at io.seata.core.rpc.defaultservermessagelistenerimpl.ontrxmessage(defaultservermessagelistenerimpl.java:87)
at io.seata.core.rpc.netty.rpcserver.dispatch(rpcserver.java:252)
at io.seata.core.rpc.netty.abstractrpcremoting$3.run(abstractrpcremoting.java:371)
at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)
at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)
at io.netty.util.concurrent.fastthreadlocalrunnable.run(fastthreadlocalrunnable.java:30)
at java.lang.thread.run(thread.java:748)
harding-proxy a eata
not the same as issues[#1203](
this problem occurs when the rollback, datavalidation afterimage and currentimage, afterimage is an instance of emptyrecords.
java11 grpc-core compile error ut java8 work normally ![image](
<dependency> <groupid>io.seata</groupid> <artifactid>seata-metrics-all</artifactid> <version>0.7.0</version>
</dependency>
shows error: "failed to read artifact descriptor for io.seata:seata-metrics-all:jar:0.7.0"
just run seata server with default config, the server just not work
springboot+web+spring cloud ebapplication bstractmethoderror
error happened when integrate with nacos an not started
rm fails to acquire global lock for it's operated record.
spring boot can not start with seata,please read the error info.
i am using @globallock to execute my sql , but get a response with `response[runtimeexception[null]]` from seata.
when i write a insert sql which the primary key is uppercase, rm cannot generate afterimge.
i find insertexecutor.containspk() judge if pk exists by comparing mysql table metadata with the result of sql recognizer
which compare the lowercase pk and uppercase pk.
when this table dosenot have auto-increase pk, rm throw exception.
branchregistertest error
normally, seata supports the isolation level of read uncommited, but it does support read committed level by forupdate sql which is dealed in selectforupdateexecutor.java
but in the method 'doexecute' of selectforupdateexecutor.java, the code `rs = this.statementcallback.execute(this.statementproxy.gettargetstatement(), args);` is firstly executed, then span checking the global lock
in extremly condition, it will cause dirty read in two global transactional
for example (global transactional-1 as gt1 and global transactional-1 as gt2 , a record is already updated in a finished branch transactional of gt1, then gt2 query this record before gt1 release global lock, then gt2 rollback because of a runtimeexception, then gt1 break span checking and `return rs;` because the record in gt2 is queried between gt1's update sql and rollback action, it is a instant dirty data; time axis like this:
gt1: --update record a--------------------rollback--------------------------------------->
gt2:-------------------- query record a--------------break span and return record a----->
i used seata for spring cloud, and seata version is 0.6.1 when i get an exception and it should be rollback, but it's always failed and status is `phasetwo_rollbackfailed_retryable`
after change seata version as 0.5.2, it work correct
and it caused by json deserialized lost type reference.
global lock don't release.
when i use the following dependencies and @enableoauth2client
```xml <dependency> <groupid>org.springframework.cloud</groupid> <artifactid>spring-cloud-starter-oauth2</artifactid> </dependency> <dependency> <groupid>org.springframework.security.oauth</groupid> <artifactid>spring-security-oauth2</artifactid> <version>2.3.3.release</version> </dependency>
table create table `test_jackson` ( `id` int(11) not null auto_increment, `int_test` bigint(11) default null, `date_test` date default null, `time_test` time default null, `timespan_test` timestamp not null default current_timestamp on update current_timestamp, primary key (`id`)
) engine=innodb auto_increment=1 default charset=utf8 2
jdbctemplate.update("insert into test_jackson(id,int_test,date_test,time_test,timespan_test) values(1,1234567890,\'2019-06-04\',\'12:00:00\',\'2019-06-04 12:12:12\')"); rollback ok
jdbctemplate.update("insert into test_jackson values(1,1234567890,\'2019-06-04\',\'12:00:00\',\'2019-06-04 12:12:12\')") ; rollback failed.
in the @globaltransactional scope,when i use "for update" statement,will cause lockwaittimeoutexception.
unable to commit against jdbc connection] with root cause,
io.seata.rm.datasource.exec.lockconflictexception: null
eg: update table1 set id = '1' where id = '2' ; branchstatus=phasetwo_rollbackfailed_retryable undosql: update table1 set where id = ? io.seata.rm.datasource.sql.struct.row.nonprimarykeys(),this method may need to be changed
when deploying multiple seata server instance, branch transaction may not be committed after starting committing global transaction.
it throws an `mysqldatatruncation` exception with message 'truncated incorrect double value' when batch deleting undo log of which xid value contains ip address.
batch delete bug in sqlbuilder
when i run server in ide,it can't be started properly.i've found the reason,will fix it soon.
seata/bom.xml and seata/all/pom.xml have repeated content 2)
`<packaging>jar</packaging>` in seata/all/pom.xml is lost 3) deploy a snapshot version to verify the kinds of bineries: all in one, bom , common
error ignoring code file
seata server retry rollback and always fail
the rm/tm can't connect to server
**server log:** > 2019-05-13 09:27:02.800 info [retryrollbacking_1]io.seata.core.rpc.channelmanager.getchannel:436 -no channel is available for resource[jdbc:mysql://127.0.0.1:3306/db_gts_fescar?usessl=false&useunicode=true&characterencoding=utf-8&allowmultiqueries=true] as alternative of order-gts-fescar-example:127.0.0.1:63094
2019-05-13 09:27:02.800 error[retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:294 -exception rollbacking branch br:2011436840/2011436837
java.lang.runtimeexception: rm client is not connected
dbkey:jdbc:mysql://127.0.0.1:3306/db_gts_fescar?usessl=false&useunicode=true&characterencoding=utf-8&allowmultiqueries=true,clientid:order-gts-fescar-example:127.0.0.1:63094 **rm log**
> 2019-05-13 09:38:43.355 info [timeoutchecker_1]io.seata.core.rpc.netty.rmrpcclient.onregistermsgsuccess:428 -register rm success
server version:0.6.0,channel:[id: , l:/127.0.0.1:55542 - r:/127.0.0.1:8091]
2019-05-13 09:38:43.356 info [timeoutchecker_1]io.seata.core.rpc.netty.nettypoolablefactory.makeobject:82 -register success, cost 5 ms, version:0.6.0,role:rmrole,channel:[id: , l:/127.0.0.1:55542 - r:/127.0.0.1:8091]
2019-05-13 09:38:43.360 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.abstractrpcremotingclient.channelinactive:304 -channel inactive: [id: , l:/127.0.0.1:55542 ! r:/127.0.0.1:8091]
2019-05-13 09:38:43.360 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.rmrpcclient.releasechannel:250 -return to pool, rm channel:[id: , l:/127.0.0.1:55542 ! r:/127.0.0.1:8091]
2019-05-13 09:38:43.360 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.nettypoolablefactory.validateobject:132 -channel valid false,channel:[id: , l:/127.0.0.1:55542 ! r:/127.0.0.1:8091]
2019-05-13 09:38:43.360 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.nettypoolablefactory.destroyobject:119 -will destroy channel:[id: , l:/127.0.0.1:55542 ! r:/127.0.0.1:8091] > 2019-05-13 09:38:48.357 info [timeoutchecker_1]io.seata.core.rpc.netty.rmrpcclient.onregistermsgsuccess:428 -register rm success
server version:0.6.0,channel:[id: , l:/127.0.0.1:55558 - r:/127.0.0.1:8091]
2019-05-13 09:38:48.357 info [timeoutchecker_1]io.seata.core.rpc.netty.nettypoolablefactory.makeobject:82 -register success, cost 5 ms, version:0.6.0,role:rmrole,channel:[id: , l:/127.0.0.1:55558 - r:/127.0.0.1:8091]
2019-05-13 09:38:48.359 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.abstractrpcremotingclient.channelinactive:304 -channel inactive: [id: , l:/127.0.0.1:55558 ! r:/127.0.0.1:8091]
2019-05-13 09:38:48.359 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.rmrpcclient.releasechannel:250 -return to pool, rm channel:[id: , l:/127.0.0.1:55558 ! r:/127.0.0.1:8091]
2019-05-13 09:38:48.359 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.nettypoolablefactory.validateobject:132 -channel valid false,channel:[id: , l:/127.0.0.1:55558 ! r:/127.0.0.1:8091]
2 > 2019-05-13 09:38:53.348 info [timeoutchecker_1]io.seata.core.rpc.netty.rmrpcclient.connect:272 -will connect to 127.0.0.1:8091
2019-05-13 09:38:53.348 info [timeoutchecker_1]io.seata.core.rpc.netty.rmrpcclient.doconnect:297 -rm will register :jdbc:mysql://127.0.0.1:3306/db_gts_fescar?usessl=false&useunicode=true&characterencoding=utf-8&allowmultiqueries=true
2019-05-13 09:38:53.348 info [timeoutchecker_1]io.seata.core.rpc.netty.nettypoolablefactory.makeobject:57 -nettypool create channel to transactionrole:rmrole,address:127.0.0.1:8091,msg:< registerrmrequest{resourceids='jdbc:mysql://127.0.0.1:3306/db_gts_fescar?usessl=false&useunicode=true&characterencoding=utf-8&allowmultiqueries=true', applicationid='order-gts-fescar-example', transactionservicegroup='my_test_tx_group'} >
2019-05-13 09:38:53.350 debug[nettyclientselector_rmrole_1]io.seata.core.rpc.netty.messagecodechandler.encode:115 -send:registerrmrequest{resourceids='jdbc:mysql://127.0.0.1:3306/db_gts_fescar?usessl=false&useunicode=true&characterencoding=utf-8&allowmultiqueries=true', applicationid='order-gts-fescar-example', transactionservicegroup='my_test_tx_group'}
2019-05-13 09:38:53.352 debug[nettyclientselector_rmrole_1]io.seata.core.rpc.netty.messagecodechandler.decode:190 -receive:version=0.6.0,extradata=null,identified=true,resultcode=null,msg=null,messageid:431
2019-05-13 09:38:53.352 debug[nettyclientselector_rmrole_1]io.seata.core.rpc.netty.abstractrpcremoting.channelread:385 -io.seata.core.rpc.netty.rmrpcclient@4d85bd01 msgid:431, future :io.seata.core.protocol.messagefuture@4e6ffd26, body:version=0.6.0,extradata=null,identified=true,resultcode=null,msg=null
2019-05-13 09:38:53.352 info [timeoutchecker_1]io.seata.core.rpc.netty.rmrpcclient.onregistermsgsuccess:428 -register rm success
server version:0.6.0,channel:[id: , l:/127.0.0.1:55576 - r:/127.0.0.1:8091]
2019-05-13 09:38:53.352 info [timeoutchecker_1]io.seata.core.rpc.netty.nettypoolablefactory.makeobject:82 -register success, cost 2 ms, version:0.6.0,role:rmrole,channel:[id: , l:/127.0.0.1:55576 - r:/127.0.0.1:8091]
2019-05-13 09:38:53.354 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.abstractrpcremotingclient.channelinactive:304 -channel inactive: [id: , l:/127.0.0.1:55576 ! r:/127.0.0.1:8091]
2019-05-13 09:38:53.354 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.rmrpcclient.releasechannel:250 -return to pool, rm channel:[id: , l:/127.0.0.1:55576 ! r:/127.0.0.1:8091]
2019-05-13 09:38:53.354 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.nettypoolablefactory.validateobject:132 -channel valid false,channel:[id: , l:/127.0.0.1:55576 ! r:/127.0.0.1:8091]
2019-05-13 09:38:53.354 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.nettypoolablefactory.destroyobject:119 -will destroy channel:[id: , l:/127.0.0.1:55576 ! r:/127.0.0.1:8091]
2019-05-13 09:38:53.354 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.abstractrpcremoting.close:436 -channelhandlercontext(rmrpcclient#0, [id: , l:/127.0.0.1:55576 ! r:/127.0.0.1:8091]) will closed
2019-05-13 09:38:53.355 info [nettyclientselector_rmrole_1]io.seata.core.rpc.netty.abstractrpcremoting.close:436 -channelhandlercontext(rmrpcclient#0, [id: , l:/127.0.0.1:55576 ! r:/127.0.0.1:8091]) will closed
mergedwarpmessage.decode line 77: `public boolean decode(bytebuf in) { int i = in.readablebytes(); if (i < 4) { return false; }` `i -= 4; int length = in.readint(); if (i < length) { return false; }` wait a time, start a transaction, seatamergemessage decode error happen
transaction will finish normally, only error print
trace variable when error:
> int i = in.readablebytes(); // i = 50
> int length = in.readint(); // length = 173 some logs: > 2019-05-08 20:33:11.410 error[nettyservernioworker_1_8]io.seata.core.rpc.netty.messagecodechandler.decode:189 -seatamergemessage decode error.
2019-05-08 20:33:11.722 error[nettyservernioworker_5_8]io.seata.core.rpc.netty.messagecodechandler.decode:189 -seatamergemessage decode error.
2019-05-08 20:33:41.259 error[retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:278 -successfully rolled back branch br:2010946637/2010946634
2019-05-08 20:33:41.265 error[retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:278 -successfully rolled back branch br:2010946636/2010946634
2019-05-08 20:33:41.271 error[retryrollbacking_1]io.seata.server.coordinator.defaultcore.doglobalrollback:278 -successfully rolled back branch br:2010946635/2010946634
2019-05-08 20:39:14.250 error[nettyservernioworker_1_8]io.seata.core.rpc.netty.messagecodechandler.decode:189 -seatamergemessage decode error.
2019-05-08 20:39:14.401 error[nettyservernioworker_5_8]io.seata.core.rpc.netty.messagecodechandler.decode:189 -seatamergemessage decode error.
version: 0.5.1 **problem 1:**
line 200: > } catch (sqlintegrityconstraintviolationexception e) {
> logger.info("xid {} branch {}, undo_log inserted, retry rollback",
> xid, branchid);
> } if insertundologwithglobalfinished fail because of dup key, should this place throw transactionexception(branchrollbackfailed_retriable)? **problem 2:**
> catch (throwable e) { if (conn != null) { try { conn.rollback(); } catch (sqlexception rollbackex) { logger.warn("failed to close jdbc resource while undo ..
", rollbackex); } } throw new transactionexception(branchrollbackfailed_retriable, string.format("%s/%s", branchid, xid), e); } if rollback undo log always fail, who is response of stoping to retry rollback ?
buffer size is hard-code as 1k, which cannot support bulk update cases
can't find flush-disk-mode in the file config
rm register request is async, if response was failed, our result is error
i used eureka as the registry, but when the project was started, the project kept reporting errors repeatedly
i could not find the documents and examples related to eureka, and i did not know whether it was my configuration error
the following is my configuration: **seata-server:** **registry.conf ** registry { type = "eureka" nacos { serveraddr = "localhost" namespace = "public" cluster = "default" } eureka { serviceurl = " " application = "seata" weight = "1" } redis { serveraddr = "localhost:6379" db = "0" } zk { cluster = "default" serveraddr = "127.0.0.1:2181" session.timeout = 6000 connect.timeout = 2000 } consul { cluster = "default" serveraddr = "127.0.0.1:8500" } file { name = "file.conf" }
} config { type = "file" nacos { serveraddr = "localhost" namespace = "public" cluster = "default" } apollo { app.id = "seata-server" apollo.meta = " " } zk { serveraddr = "127.0.0.1:2181" session.timeout = 6000 connect.timeout = 2000 } file { name = "file.conf" }
} **serivce-server ** **registry.conf ** registry { type = "eureka" eureka { serviceurl = " " application = "seata" weight = "1" } file { name = "file.conf" }
} **file.conf ** service { vgroup_mapping.service-module-user-fescar-service-group = "service-module-user" service-module-user.grouplist = "127.0.0.1:8091" enabledegrade = false disable = false
the select for update statement can not get the latest value in the database
unable to register to the custom namespace by nacos ll registered are ublic default namespace
if the select for update query result set is empty, an exception occurs when getting the global lock.
simulating multiple threads concurrent requests has a protocol decode error.
seata 0.5.0 : server restart cannot retry the uncomplete transaction in root.data
copyright check `copyright 1999-2019 seata.io group`
seata error when executing select for update statement with mybatis
if i remove the for update, the service will not report an error.
service interface use @globaltransactional ullpointerexception triggered when updating sql
conditions are primary key use in
the globaltransactionscanner can't generate the proxy of dubbo:reference , when it load after dubbo:reference factory bean.
bugfix: at mode at the 2th stage should always returns committed to user
![image](
i upgraded to v0.4.2
when i run the application,the druiddatasource show sqlexception:url not set
there are two decode method of abstractbranchendresponse, but only one methed decode the xid and branchid, the other didn't.
the code of the latest develop branch has a protocol header parsing error when globally rollback.
raises a bug when the global timeout of @globaltransactional is triggered
can not start global transaction when the fescar server has multiple ip addresses
the full file name is not right.
branchcommit retry always failed
service interface use @globaltransactional nd there are three sqls in it
first two of them has succeed
but when run the third sql t throw a nullpointerexception.
![image]( it seems that data is not completed but seata start to decode it, it is the normal scenes of the protocol process
com.alibaba.fescar.core.rpc.netty.messagecodechandler#decode it has no effect **but only confused to users** aybe when data is not completed do not print logs to error level
nettypoolkey tojsonstring error because of bytebuffer
i downloads the newest source code, get the dependencies, open the server module run the servertest.java , it has errors
after traceing the errors, i found the code execute on this line " registryfactory.getinstance().register(new inetsocketaddress(xid.getipaddress(), xid.getport()));" in abstractrpcremotingserver.java file, the error just happend
it seem that xid have no values, so the xid.getipaddress()'s call return null, then **checkhost** method catch that and throw the exception
so i want to know is there something wrong or i have some mistakes.
bugfix:add nacos init config and some config
when tc send branchcommit request to rm, rm log "failed at async committing ..
the flag in the pic doesn't work! and user stringbuilder instead of stringbuffer
![image](
a id fescar escarmergemessage decode error
fescar-dubbo filter spi reference error
transid needs to loop within a section to prevent inter-cluster transid coverage from causing transaction failure
should not throw exception when no globalsession/branchsession exists while restoring.
applicationid and txservicegroup in branchsession are useless
fescar server xid get a unreachable ip address
netutil.java can't recognition the ip.
tc estore root.data oot.data p
estore oot.data lientip ort
i noticed that in com.alibaba.fescar.rm.datasource.exec.abstractdmlbaseexecutor#executeautocommittrue, there is a logic that when rm failed to register branch transaction due to lockconflictexception, rm will retry to register branch transaction 30 times with 10ms interval by default
now assuming a global transaction named g1, which is currently holding the global lock
it has only one branch transaction named b1.
another global transaction named g2, with a branch transaction named b2 who failed to get the same global lock and now is retrying
from my point of view
(1) when g1 is going to rollback, b2's behavior of retrying to register branch transaction is useless
because when b1 is going to rollback the branch transaction,it will be blocked by b2's local transaction(mysql lock)
when i test this scene, b2 will get `global lock wait timeout exception`, so b1 can be rollbacked sucessfully
(2) when g1 is going to commit, this can be harmful.
because when b2 is retrying, it's repeatedly execute the same biz sql in the same local transaction.
transactionaltemplate#execute doesn't call globaltransactioncontext#clean, which result in leaking threadlocal variables
update clause without where condition will cause updateexecutor#beforeimage to raise sql syntax error
on windows the fescar-server.bat used $extra_jvm_arguments variable has an error
at com.alibaba.fescar.server.coordinator.defaultcore#doglobalrollback,
when the branchrollbackrequest from tc to rm failed ( rm hang ), rm channel will be destroyed and globalsession will be added to retry queue
when retrying at com.alibaba.fescar.server.coordinator.defaultcore#doglobalrollback, tc will ask one of other rms with the same resources (channelmanager#getchannel) to help dealing branchrollbackrequest
if success, then global session status will be rollbacked.
but if failure, global session will still be rollbacked instead of rollbackfailed or somethings else.
sqlvisitorfactory should recognize for update from normal select sql
it's wrong that it just take any select sql in transaction context as select for update.
fix of duplicated rm init on demo was missed by mr
in the class `transactionaltemplate`, in step 4, we will sent `globalcommitrequest` to remote tc server
if application is crash before sent the `globalcommitrequest`
this global transaction will timeout in the future.
flush undo_log pending before committing until the server notifies the branch to roll back when it finds that the global transaction has timed out.
finally undolog inserted and business sql executed
it is wrong
netty `so_keepalive` option not works on `serverbootstrap#option()`, should replace with `serverbootstrap#childoption()`
i dont know why! but sequelize is creating a column called "true".
i need help with this please! here my codes: `import { maindbmodeloption } from '..'
import {model, date, integer, string} from "sequelize";
import sequelize from "sequelize";
import { contactcreate, contact_attributes } from "../../@types/contact_interface"; class contact extends model <contact_attributes,contactcreate> implements contact_attributes{ public id!:number public user!: number public email!:string public name!:string public firstname!:string public lastname!:string public phonenumber!:string public companyname!:string public website!:string public address1!:string public address2!:string public postalcode!:string public state!:string public city!:string public country!:string public createdat!:date public updatedat!:date public deletedat!:date
} contact.init({ id: { type: integer, primarykey: true, autoincrement: true }, user: { type: string }, email: { type: string }, name:{ type:string }, firstname: { type: string }, lastname: { type: string }, phonenumber: { type: string }, companyname: { type: string }, website: { type: string }, address1: { type: string }, address2: { type: string }, postalcode: { type: string }, state: { type: string }, city: { type: string }, country: { type: string, }, createdat: { type: date, defaultvalue: sequelize.now }, updatedat: { type: date, defaultvalue: null }, deletedat: { type: date, defaultvalue: null } },maindbmodeloption('contacts')); export default contact` `
import { sequelize, initoptions } from 'sequelize'
import database from './database.config' /** * sequelize configuration */
const maindb = new sequelize( database.database, database.username, database.password, { host: database.host, port: database.port, dialect: database.dialect, define: { underscored: true, timestamps: true, createdat: true, updatedat: true, deletedat: true, paranoid: true, } }
) export default maindb
/** * model options factory * @param db */
export const modeloptionsfactory = (db: sequelize) => ( modelname: string
): initoptions => { return { sequelize: db, modelname: modelname }
/** * main db models options */
export const maindbmodeloption = modeloptionsfactory(maindb)
/** * connection factory to db * @param db */
export const connectfactory = (db: sequelize): (() => promise<boolean>) => { let connected = false return async (): promise<boolean> => { if (connected) return connected await db.authenticate() await db.sync() connected = !connected return connected }
![screenshot from 2020-07-24 16-45-37](
using sqlite and sequelize 6.2.3: if you create a table with a multi-column unique constraint, then remove an unrelated column, you are left with multiple single-column unique constraints
i've confirmed that it was introduced in 6.2.3 with this change: 6.2.2 has the old behavior where removing a column removes constraints from the target table.
i add defaultscope in model definition to exclude some columns
but `.upsert()` still return the exclude columns.
it turns out that there is no way to use literal both in attributes and ordering, when `minifyaliases = true`
when a column already exists in database, creating a virtual field by the same name and syncing tries to set database column type to `virtual`, which results in an error since the type is invalid.
under sequelize v6, when using sqlite for upserts and a uuid primary key, it seems like subsequent upserts with the same data are not returning the first instance uuid/pk value, and instead a returning a new uuid
this appears to differ under `postrgres`, which under subsequent requests is returning the original pk/uuid.
while using model.bulkcreate, as we pass the options, an object which contains transaction, it comes modified after the execution
i use mysql and bulkcreate , db result is right, but bulkcreate return not as expected.
according to the documentation it should work.
mysql logging can lose cls context when benchmark flag is true
when we pass an empty list to the `group` property, `sequelize` generates an sql query with syntax errors.
i am upgrading a project which used ..
"sequelize": "4.41.0",
"tedious": "2.6.4" to new versions...
"sequelize": "5.21.5",
"tedious": "8.2.0" ..
and my raw queries now return [undefined, 1] as the result unless i change the query type to select
has something changed to break returning data from raw or insert query types? let sqlresult try { sqlresult = await sequelize.query( ` insert into players (username, emailaddress, phonenumber, passwordhash) output inserted.* values ($username, $emailaddress, $phonenumber, $passwordhash) `, { bind: sqldata, type: sequelize.querytypes.insert } ) } catch (error) { .
removed } console.log("sqlresult", sqlresult)
when calling sync method with alter enabled and logging option set, the logging method only receive the database creation messages and not the alter nor drop ones.
also, when benchmark is enabled, we don't get the timings for alter and drop commands
built-in function calls within mysql default constraints must be enclosed in parantheses, sequelize omits these and causes a syntaxerror.
sequelize generates a wrong query when function `count()` is used for a model containing a column named `count`
if a non-primary key column is named "id" in the model, the value of this field would always override the value of the actual primary key in the data returned from model.create() function
when an "id" column is defined in the model but is not set as the primary key, when creating a new record with association, the record insertion ends up in error
this error only occurs in mssql.
it seems to me that sequelize generates an incorrect sql query when the operator `[op.substring]` is used together with `sequelize.literal`.
bulkcreate generate the wrong values for the updated key fields with ``uv`=values(`uv`)` not ``uv`=`uv`+1`
43069.0122916667 value will not be written correctly to mssql
the following code will generate an invalid sql statement when running against an sqlite database const found = await foo.findone({ attributes: [],
``` the generated sql is something like: ```sql
select from "database"."table"
``` a common workaround is adding a fixed result column, like `select 1 from ...`, although i'm not sure how that will play with the next step, when the records are parsed
## issue template checklist ### is this issue dialect-specific? - [ ] no
this issue is relevant to sequelize as a whole.
this issue only applies to the following dialect(s): sqlite
- [ ] i don't know.
### is your feature request related to a problem? please describe
i have a model `exercise` and i would like to specify a function for order by for children association.
for example, i have the following scope defined in `exercise` : // to deal with the horrible order by clauses generically generated
orderbyclauses(fields) { // to handle order by clauses // the last item in the values array will be the choice of the user (instead of the \'\') const order_by_fields = { "state": ["state", \'\'], "id": ["id", \'\'], "title": ["title", \'\'], "date": [\'updatedat\', \'\'], "avg_score": [ {model: sequelize.models.exercise_metrics, as: "metrics"}, \'avg_vote_score\', \'\' ], "vote_count": [ {model: sequelize.models.exercise_metrics, as: "metrics"}, \'vote_count\', \'\' ], }; return { order: fields.map(field => { let order_by_clause = order_by_fields[field.field]; // remove the last empty value so that we can add order_by_clause.pop(); order_by_clause.push(field.value); return order_by_clause; }) };
``` currently, it works as expected but i would like a custom filter on array so i added a new order by clause possibility in `order_by_fields` : ```js
"tags_count": [ {model: sequelize.models.exercise_metrics, as: "metrics"}, sequelize.fn("coalesce", sequelize.fn( "array_length", sequelize.col("tags_ids"), 1 ), 0 ), \'\' ]
``` but sequelize generates something wrong : ```sql
some select stuff
from "exercises_library"."exercises" as "exercise" inner join "exercises_library"."exercises_metrics" as "metrics"
order by "metrics".coalesce(array_length("tags_ids", 1), 0) desc
rest, like offset or limit
``` ### describe the solution you'd like as showcase in [docs]( #ordering-and-grouping), we could use a complex object for ordering column
[{model: task, as: 'task'}, 'createdat', 'desc']
``` so why not allow something like this ? ```js
const customfn = sequelize.fn("coalesce", sequelize.fn( "array_length", sequelize.col("tags_ids"), 1 ), 0
[{model: sequelize.models.exercise_metrics, as: "metrics", fn: customfn }, \'desc\']
``` that way, no breaking change and still backwards compatibility
### why should this be in sequelize it could be useful for order by clauses for many functions : [`coalesce`]( #functions-coalesce-nvl-ifnull), [`length`]( , etc ..
### describe alternatives/workarounds you've considered
- string manipulation with fn : no maintenable in long term
- include properties ( but not possible in many case ) ## issue template checklist ### is this issue dialect-specific? - [x] no
this issue is relevant to sequelize as a whole.
this issue only applies to the following dialect(s): xxx, yyy, zzz
sequelize was throwing the following error:
``` error: where parameter "id" has invalid "undefined" value at array.foreach (<anonymous>) at runcallback (timers.js:705:18) at tryonimmediate (timers.js:676:5) at processimmediate (timers.js:658:5) at process.topleveldomaincallback (domain.js:126:23)
``` this was pretty hard to diagnose, but i eventually tracked it down to this code:
``` return user.findone({ attributes: ["id", "username", "firstname", "lastname", "email"], where: {username: "user@whatever.com"} }).then(user => { if (user) { return user.destroy(); } else { return promise.resolve(); } }).then(() => { ...
the destroy command works
there's a user in the users table with that username
that user is properly deleted
i can see the delete sql on the console log
it's just that it's throwing that strange error as well.
i am trying to use a string as the primary key for one of my tables instead of `id`, but on `create` sequelize always tries to insert a default `id`, which crashes.
virtual dependency fields are being ignore if virtual field is set as attribute in included association,
while creating a new model, the model get's created, but then the function fails because sequelize attempts to insert already existing associations (and fails).
ms sql query fails with the following error: `the column 'id' was specified multiple times for 'channel'.` this issue started with the version 5.18.4
same code works perfectly fine with versions below, even with the version 5.18.3.
mysql create table without foreign key when model associate with hasmany.
{ id: { type: datatypes.uuid, defaultvalue: datatypes.uuidv4, primarykey: true, lowercase: true, }, firstname: { type: datatypes.string(255), }, lastname: { type: datatypes.string(255), }, displayname: { type: datatypes.virtual(datatypes.string, [ 'firstname', 'lastname', ]), get() { return `${this.get('firstname') || ''} ${this.get('lastname') || ''}`.trim(); }, },
{ sequelize, hooks: { afterupdate: (item, options) => { console.log(item._previousdatavalues.displayname); // undefined console.log(item.previous('displayname')); // undefined console.log(item._previousdatavalues.firstname); // value console.log(item.previous('firstname')); // value } },
findone produces 'missing from-clause entry for table' error on postgresql.
if i have a column of the geometry type (postgis) and tries to select its value i get geojson without srid information
setting limit option on a query with a where statement that contains dollars signs doesn't work.
i tried to use belongstomany association with binary key,
but it's not working fine, always return false.
the `bulkcreate` fails if the model contains a composite key and doesn't explicitly define a primary key
the `upsertkeys` array is emptied when the model contains a composite key since the length of the fields array of the `compositekey` object will be of size > 1 (which causes this filter to skip it): #l2705 my model looks like this:
```javascript
"use strict";
module.exports = (sequelize, datatypes) => { const user = sequelize.define( "user", { username: { type: datatypes.string, unique: "compositekey" }, discordid: { type: datatypes.string, unique: "compositekey" } }, {} ); user.associate = function(models) { // associations can be defined here }; return user;
in this case, the `model.uniquekeys` object only contains a single `compositekey` object.
shouldn't the `model.uniquekeys` object _also_ contain the automatically generated `id` primary key for this model? changing the model to this works:
```javascript
"use strict";
module.exports = (sequelize, datatypes) => { const user = sequelize.define( "user", { username: { type: datatypes.string, unique: true }, discordid: { type: datatypes.string, unique: true } }, {} ); user.associate = function(models) { // associations can be defined here }; return user;
im trying to use afterconnect hook to intercept notice and notiification events from a postgresql database
when using upsert on postgres, the string `returning *` anywhere inside a text or json column value is being replaced with `returning \\"id\\" into primary_key`
besides changing the data to be upserted, this also makes it throw an error when inserting or updating into a json column since its not valid json.
@sushantdhiman in 5.18.4, that commit introduced in issue in which the findone logic no longer returns results it did prior to 5.18.4
as soon as you add an association that is a hasmany or belongstomany it just returns null
the query data from the database comes back with data but from sequelize it just returns null.
mapping a column/field to the same name in a query causes the field to be omitted from the response.
can't query col is not null with sequelize.where function.
in the ms sql dialect, `showtablesquery()` returns a query that selects both tables and views.
this affects among others, sequelize-auto which uses showtablesquery() to retrieve the list of tables for which to generate models
and sequelize does not like when models exist for views.
bulkcreate with updateonduplicate throws error when one of the model's primary key fields has a different name from its db column name
bulkcreate generates the field names in the: `on conflict (column1...)` part of the query by looking at: `this.primarykeys.fieldname` which is the model's field name, instead of looking at `this.primarykeys.field` which is the db's column name
the error received by postgres and thrown by sequelize is, expectedly: `unhandled rejection sequelizedatabaseerror: column "fieldname" does not exist`
something broke with the 5.18.x releases that caused a regression in the group by behavior
i am now getting `unknown structure passed to order / group` errors while trying to get some aggregates while grouping by an included model.
- breaks use of defining indexes manually as per #indexes
when multiple models are wired up to the same table
the model's static update method can incorrectly map the returned instance to the wrong model
when you select to use a custom logo, the url input renders under the analytics setting rather than under the logo setting
after upgrade to ce 2.0.0, portainer is no longer displaying all existing stacks.
also counts of stacks are displayed incorrectly in multiple places
- however that's repro with 1.24.1 too.
when creating a custom template and choosing to upload a compose file, creation fails.
when portainer is deployed to a docker swarm, and portainer is restarted and moves to a different node, it will start up asking for a fresh administrator username and password, and all existing users, and endpoints, will be empty
**expected behaviour**
when using a network mounted data volume, portainer should not care which node it is running on.
when you add repository to portainer registry having special characters in password results in failure when pulling images.
adding a quay registry through the quay registry option in our ui is broken
pushing an image results in a 404
the url we use is simply `quay.io` whereas the url should be built to include username like so `quay.io/<provided-username>`
in kubernetes, when a user tries to expose an application over an external load balancer and specifies at least two ports with different protocols, the application won't be deployed and an error message will be displayed
![portainer - 2020-10-05t172608 411](
today, i decided to update my portainer image
i have not updated it for a long time
so first i remove the current container, and i recreate the container keeping the data volume.
it seems that the container is trying to start, but fails to start because of a migrtion (i guess so, because the migration is launching again and again).
the container is not starting, and the port are not opened, so i don't think the servce manages to start
upgrade from 1.22.0 to 1.22.1 fails during db migration with `an error occurred during database migration: object not found inside the database`
the formatting of text in the attach console is broken
[screen](
viewing logfiles of stopped containers leaves the "auto-refresh logs" switch enabled, which is pointless as the logfile will never change in this state, but auto refresh interferes with scrolling etc
additionally, changing the number of lines does not trigger a refresh of the logfile.
the icons in the left column and the icons for quick actions are not showing in google chrome version 85.0.4183.102 (official build) (64-bit)
not sure if its a chrome think but the icons display fine in old and new 'edge'.
try and save an invalid snapshot interval and you will see a go panic in portainer logs.
the [new privacy policy]( which was introduced with the release of portainer 2.0.0, states that > you can opt out of being tracked by our matomo analytics instance by simply removing the analytics acceptance at portainer initialization, or by changing the setting in portainer at any time
but i\'ve observed that portainer attempts to load the matomo analytics script even if the option "allow the collection of anonymous statistics" is disabled.
console button is missing from containers of some endpoints
when using portainer 2.0's new feature, kompose deployment,
it does not work with following erorr
http error: unable to deploy kubernetes stack (err=open /var/run/secrets/kubernetes.io/serviceaccount/token: no such file or directory) (code=500)
extra commas are being added to log text when copying out of the log window
commas not displayed in the log window when viewing
commas do not appear when "copying selected lines" - only when copying the whole log
when pasting clipboard copy of entire log, each line has a trailing comma added
when viewing the endpoint details view of a kubernetes endpoint, tls settings and information about docker tls is incorrectly shown
changing the tls settings has no effect.
with authentication over ldap, it is possible to get a new user by change random characters to uppercase and/or lowercase
login "smith" is configured as admin
login "smith" is configured as user
login "smith" is configured as user
login "smith" is configured as user
login "smith" is configured as user they are all authenticated correctly, but the system thinks they are different users
when authenticating with oauth cannot get authenticated
using keycloak as the oauth provider
i'm sure my certificate is ok
it's trusted by my browser.
i created a stack with rest api, and it always shows as limited control.
i expected it to be created as fully controllable stack, since i used portainer rest api to create it.
i looked inside portainer volume, and docker-compose.yml existed there safe and sound
post /api/stacks?type=1&method=string&endpointid=2 { "name": "test-stack", "swarmid": "some_swarm_id", "stackfilecontent": "version: \'3.4\'\ \ services:\ mt-ko2en:\ build:\ context: ..\ dockerfile: docker/dockerfile\ image: localhost:5000/test_image:$version\ environment:\ - version=$version\ - log_level=$log_level\ ports:\ - 23000:80\ ", "env": [ { "name": "version", "value": "1.0.0" }, { "name": "log_level", "value": "debug" } ]
``` ![image]( also it can't be deleted with web ui, it only can be deleted with rest api.
when i try to delete it with web ui, it produces following error
![image]( since docker-compose.yml exists and delete message says it cannot use external delete method,
i think is is created as internal, fully controllable stack,
but somehow on web ui it is shown as limited control stack.
it's just my opinion.
it's not possible to connect to a no swarm agent with portainer ce 2.0
after updating a stack to a new version of portainer, the version number isn't shown when the user logs in
to fix it they have to login, log out and login again
yesterday portainer was working fine and i enabled ldap auth which worked
this morning after logging in and clicking on my primary endpoint i receive errors along the lines of `unable to connect to the environment`, `unable to find an agent` etc
![image]( ![image]( the dashboard summary area shows most of the information correctly except for the stacks
it'll show 3 stacks and then later 0 stacks intermittently
then later i can click into the endpoint and load it but it will sporadically list errors: ![image]( in the console: ![image]( when i query the agent service i see it's running
user@docker_staging01:~$ sudo docker service ps portainer_agent
id name image node desired state current state error ports
p3y01o5s2pwn portainer_agent.eec8uvo2jrdwokwc4itrg6684 portainer/agent:latest docker_staging01 running running 15 hours ago
gh2lifcf6rnq portainer_agent.nxy4hk5xb9y4sp4rz3bl2dgg0 portainer/agent:latest docker_staging02 running running 15 hours ago
uk19xjwy22lm portainer_agent.eec8uvo2jrdwokwc4itrg6684 portainer/agent:latest docker_staging01 shutdown failed 15 hours ago "no such container: portainer_ "
svm148xwxafp portainer_agent.4ju5triwdota22fr1vqwaokl6 portainer/agent:latest docker_staging03 running running 15 hours ago
lom6501awapv \\_ portainer_agent.4ju5triwdota22fr1vqwaokl6 portainer/agent:latest docker_staging03 shutdown shutdown 15 hours ago
imbut2xlnwy6 portainer_agent.nxy4hk5xb9y4sp4rz3bl2dgg0 portainer/agent:latest docker_staging02 shutdown shutdown 15 hours ago
ikyuexp48z71 portainer_agent.eec8uvo2jrdwokwc4itrg6684 portainer/agent:latest docker_staging01 shutdown shutdown 15 hours ago
</pre> when i check the [portainer logs]( i see errors like: <pre>
user@docker_staging01:~$ sudo docker service logs portainer_portainer portainer_portainer.1.hzgl6k6epjy4@docker_staging01 | 2020/08/28 12:48:35 [warn] [docker,snapshot] [message: unable to snapshot engine information] [endpoint: primary] [err: error response from daemon: the agent was unable to contact any other agent located on a manager node]
portainer_portainer.1.hzgl6k6epjy4@docker_staging01 | 2020/08/28 12:52:19 http error: invalid jwt token (err=invalid jwt token) (code=401)
</pre> the [agent logs]( show errors like: <pre>
user@docker_staging01:~$ sudo docker service logs portainer_agent portainer_agent.0.svm148xwxafp@docker_staging03 | 2020/08/28 06:55:30 [warn] memberlist: was able to connect to docker_staging02-86e41464af50 but other probes failed, network may be misconfigured
portainer_agent.0.svm148xwxafp@docker_staging03 | 2020/08/28 07:03:35 [error] [http,docker,proxy] [request: /info] [message: unable to redirect request to a manager node: no manager node found]
portainer_agent.0.svm148xwxafp@docker_staging03 | 2020/08/28 07:03:35 http error: the agent was unable to contact any other agent located on a manager node (err=unable to find an agent on any manager node) (code=500)
portainer_agent.0.svm148xwxafp@docker_staging03 | 2020/08/28 08:03:35 [error] [http,docker,proxy] [request: /info] [message: unable to redirect request to a manager node: no manager node found]
when trying to create a new container with an image from the nvidia container registry, after 2 minutes, portainer shows the error: "failure: no such image"
pulling the same image in a local docker desktop environment works
when i try to create a new container in portainer with a non-existent image from the nvidia container registry, the same error is shown immediately, not just after 2 minutes
this is just speculation but could this be caused by some sort of timeout? i tested this several times and the error always occured after 2 minutes
also the image i am trying to pull is quite large
edit: i just tried pulling a smaller image (`nvcr.io/hpc/gromacs:2020.2`) from the nvidia container registry and it worked
this would fit my speculation that this is some sort of timeout issue ![annotation 2020-08-27 112443](
unable to import an image running on a portainer+agent instance running on a vm on a remote host
no error is thrown when it fails.
when in a stack a container is renamed with the `container_name` property, the container seems to be recreated but the name is not adjusted.
when changing ownership of a stack, inherited ownership from the stack is applied to wrong volume
i have written a program which listens for docker node events
it does this currently by piping the output of a "docker events" command:
docker events --filter type=node ```
technically the above is in a while-read loop on the output of this command
when the portainer agent is not running, every time a service is stopped or started on a node, docker actually sends a node event along with the service event
i am using this as a trigger point for simplicity sake to trap these events
this works well and i've tested it several different ways
if the portainer agent is running, however, these node events when a service gets started/stopped are not sent
i'm not sure how, but these events are somehow suppressed
when i stop portainer, i immediately start getting the correct docker node events again when other swarm services start/stop.
when trying to view env vars via container inspect an error is thrown to console and they aren't rendered.
as of 1.24.1, when using `--no-auth`, all of a sudden all admin abilities are gone.
we have a config in docker swarm with a binary file (ex
a certificate in a p12 file) and get the front-end error `unable to retrieve configs` in every service page view or in the configs view.
the container logs sometimes are not immediate
portainer docker-compose.yml ``` extra_hosts: - "ldap.server.com:192.168.10.20"
``` portainer -> settings -> authentication -> ldap server:
`ldap.server.com` portainer popups a failure because it still get the public ip address of `ldap.server.com`, but i don't want and need ldap port 636 open on the public ip address for security reasons.
trying to deploy a container template with a network that only exists on a single swarm node (different to the one portainer is running on) fails, as that network doesn't exist where portainer is trying to deploy the container
i have a container (goacme/lego:latest) which i'm using to generate certificates.
by default, it has an entrypoint set, but i can override this with command (this works) - by deleting anything in entrypoint
as the container stops once the cert is generated/renewed, i want to re-deploy the container again.
when i go to click "deploy the container" - i can see that entrypoint is blank (as i left it originally) however, when the container runs, it fails as it has re-inserted the default entrypoint command
if however, i enter and delete a space character in the blank entrypoint box, and then click deploy, it works as expected/desired
if i simply (re)start the container, it works
it is something do with deploying - it remembers that entrypoint was cleared in the ui, and it shows clear, but then re-inserts the default on redeploy unless something is keyed in the ui.
after a fresh install, the docker container keeps restarting
the ingress network is [special]( #issuecomment-312524929) and is reserved only for swarm usage when publishing ports
the docker cli prevents assigning a service to it on creation, however we allow it
the result is that services joined to ingress via portainer fail to start.
on the services page `/#/services`, there is a checkbox and an arrow to view the current containers of that service
problem is.
that when you click on the checkbox, sometimes it's like if you click the arrow and that's hyper annoying
i mean, the arrow "clickable zone" is entering the checkbox zone (bottom right part of the checkbox)
using 1.24.0 to setup a macvlan network, excluded address(es) can be entered but do not take effect, and the excluded address can then be assigned to a container, causing collisions.
image pull with `codait/max-object-detector:arm-arm32v7-latest` is failing in portainer, but pulls correctly via cli
when deploying custom stack\'s app template with environment variables of "select" type, those variables are not propagated to stack\'s environment
only those of another types ("preset" and "text") are.
if you browse to a view that has a `details view` and expects an id, i.e ` #/endpoints/` without an id then an angular error is thrown.
the configuration screen should not be shown to endpoint admins, as this should be configured by admins only.
if a stack is updated to reference a volume that already exists on another node, another one is created and the ownership of the existing volume is applied to the new volume as well as the stack.
through the volume type-ahead in the template deploy view, non-admin users can type in the name of volume they shouldn't have access to and then deploy a template with it mounted.
portainer allows adding multiple gitlab 'registries' as there is one allocated for each project
when there are multiple defined, you cannot give access to them as you get the error `failure a registry is already defined for this url`
the error message for incorrect syntax in stack editor shows behind some elements it should not
image import does not report errors correctly
i tried different invalid tar files and portainer always says "image successfully uploaded" but the image is not listed later
this is problematic when you think you have a valid image like i did
the image i had was created using windows powershell and redirection operator `docker save busybox > busybox.tar`
this does produce broken images (
when i tried to load these images locally docker does report correctly `error processing tar file(exit status 1): archive/tar: invalid tar header`.
if i delete a repository from a gitlab registry using the registry manager, it is still shown in the ui
browsing it gives the error `failure unable to retrieve tags`
go to containers
select a container
type a filter and select another container actual behavior: "item(s) selected" count stays as 1
if i create a stack via api using the postman tool, the ownership is set to private with no owner.
a non-admin user joining a public container to a public network results in an error.
i would like my non-admin user to be able to browse his volume
when viewing the volumes ui he cannot see the "browse" button beside the volume he owns and created
however when i give him a direct link to the volume with something like:
#/volumes/uservolume/browse?nodename=xyz it loads the ui for him.
export image fails.
i have successfully added a gitlab registry to portainer and tested + saved the configuration
if i browse to another view and come back, a lot of the time portainer has 'forgotten' my saved configuration and asks me again to configure it
it will also almost always show me the config screen just after successfully adding the registry.
we trying to deploy stack to an endpoint connected by edge agent, but it failed to deploy with error message "portainer cannot connect to the docker daemon at tcp://localhost:0." we found this edge agent\'s url was set as \'tcp://localhost:0.\'
but other previously added edge agent's url was set as our portainer address.
windows: container statistics error soon if refresh rate is too short (2 seconds or shorter).
- 1 second: fail after 6 seconds
- 1.5 seconds: fail after 15 seconds
- 2 seconds: fail after 75 seconds
- 3 seconds or longer: no error
using the portainer ui to update a container using the latest tag fails to use the updated entrypoint command inside the image
linked post for affected users
previous entrypoint command
#l39 new entrypoint
#l61
when i remove a "total control" stack using the portainer ui, and then redeploy the stack directly to docker using the docker cli, the stack shows up, again, as "total control" **expected behaviour**
i expect to be able to deploy stacks with the same same as previously removed portainer managed stacks, and have them display as "limited" in portainer.
the image list is empty although there are images available on the host via `docker image ls`.
if i click on an image of a container, the image details page get opened and on the endpoint status page the number of images seems valid
![](
when trying to access the local endpoint on windows 10 you get `error during connect`
based on [this comment]( #issuecomment-589896528) on a recent issue this is likely caused by the outdated `go-winio` library we are using which we should update.
when using a label/value pair in the 1.23.1 ui to \'hide\' a container (ie portainer\'s container) the corresponding image (ie portainer/portainer:latest) shows as "unused" in ui filters but errors when interacted with (ie, removing all unused images as a part of cleanup.)
when requesting to recreate a container and check pull latest image, if there was a problem between docker process and remote registry, for example a timeout error, portainer reports result of operation as success while new image not successfully pulled.
when i try to deploy a container i get the following error message:
deployment error
json: connot unmarshal array into go value of type types.networkressource
so this isn't very practically relevant, but containers with empty env vars don't have them displayed correctly in portainer: ```
$ docker run -d --rm -it --name rwos-test --env this_is_an_env_var alpine sleep 3600
$ docker inspect rwos-test
"config": {
"env": [ "this_is_an_env_var", "path=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" ],
portainer displays that like so:
<img width="808" alt="bildschirmfoto 2020-02-13 um 13 48 54" src=" ">
![image](
deploying a stack with the same name and stack definition as a previously deployed stack that was deleted gives error deployment failed, but deploys anyway.
searching for a service by it's label it doesn't show the related tasks in the dropdown table
if user names are entered multiple times or with spaces in the docker compose file, the access rights are not set correctly
from #3337: there seem to be problems with double entries
`- "io.portainer.accesscontrol.users=bob,adam,bob"` this changes the ownership of the group to _restricted_
but neither bob nor adam are listed
probably, the strings should be trimmed
otherwise adam will not have access to the resource.
`- "io.portainer.accesscontrol.users=bob, adam"`
i often get errors when working with containers, sometimes long ones, and the error popop shows behind other elements.
when trying to create a stack which uses an explicit ipv6 address in `ports`, portainer responds with an error.
using an ipv4 address instead works fine
docker-compose supports both ipv4 and ipv6 syntax and starts the docker-proxy with the specified configuration derived from `ports`.
a user was created in native ldap, assigned to an ldap group, auto-provisioned & assigned to their (manually created) team in portainer, which is assigned an endpoint-admin rbac role gets:
`failure unable to update endpoint status` after logging in and clicking the endpoint they should have access to.
_edit: occurs with ad ldap also_
after selecting a container network, switching to bridge does not remove the container name from the network name.
it looks like fonts are not found
and icons are sometimes not working too.
when publishing the same port on 2 different ip\'s, only one is detected in the "create/edit/duplicate container"
an endpoint admin user is receiving intermittent access denied (403) responses for requests
the request that fails is different each time and has once included a ping which should not happen imo.
unable create container with volume, the error message is always say that the volume name is invalid character
i have change the name many times but it won't solved
![tempsnip]( i'm trying to create a container or pull image a docker image from gitlab registry by using the _simple mode_
when i select my gitlab registry the image form is autofilled by the complet image name
only think i have to do is to type my tag
but i got error: failure
no such image: registry.gitlab.com/mygroup/mysubgroup/myproject/latest:latest as workaround i type `:latest`
i've just updated my portainer to 1.23 and it seems that my endpoint (connected by local unix socket `/var/run/docker.sock`) shows there is 0 stacks, containers, volumes or images in home tab, but also zero processors and zero bytes of ram :) as demonstrated in screenshot: ![image]( 0 processors and 0 bytes of ram is also visible in dashboard tab of this particular endpoint, but number of stacks/containers or images is correct: ![image]( in the host tab, both cpu number and memory number is shown correctly: ![image](
if an administrator has set ownership of a service related to a 'limited' stack to a non-admin user or team, then these users can see the stack in portainer and remove it
this also removes the related resources to the stack.
non-admin users & teams cannot manage resources associated to their services
this issue is probably related to #3259, with the difference being that we create stacks outside of portainer (and are therefore unable to configure stack ownership, only service).
when i click on the column headers in the endpoints screen a little [az] icon appears and an arrow toggles indicating the sorting direction has changed but rows do not change.
when portainer is freshly installed, the ldap reader dn and password are both empty and anonymous access to an ldap server works as expected
however, if you set a reader password in the settings, there is no way to set it back to empty and thus no way for anonymous access to the ldap server to work again unless you wipe the settings storage
this happens both, using the portainer ui and the portainer api
the problem seems to be that when sending an empty password `"password":""` inside `ldapsettings`, the backend api considers this as *do not change the password* instead of *set the password to empty* and therefore retains any previously set password in the settings storage
the ldap password is then impossible to be set back to empty, which is required for anonymous ldap access
setting the reader dn to empty `"readerdn":""` after having a value works as expected
related issue: #1118
rbac does not assign permissions to newly created & autoprovisioned ad users
auto suggest for images on multinode swarm suggests the same image multiple times
the users list shows under the image input in the create image widget
![image](
- as a team leader visiting the users, teams and roles screens produces a red "failure, unauthorised" toast.
- the roles screen does not list the roles that are visible to the administrator.
- the users screen does not show any users, not even the users in my own team.
- the add user feature is disabled as there are no teams, not even my own team that i am a leader of, to select.
- selecting my own team in the teams screen shows 0 leaders, 0 total team members, even when there are other members and leaders.
assigning a user to two teams (each having helpdesk and standard user roles respectively) results in the user having read-only abilities
**expected behaviour**
the user should have abilities associated to the standard user role, as this is expected to take precedence.
stack restricted to a non-admin user is shown as assigned to administrators for all other non-admin users.
removing a service that is part of a stack makes it dissapear for all rbac users, however it is still visible for administrators.
stacks owned by administrators are showing as limited for rbac users.
endpoint admin & standard rbac users cannot use the attach functionality of containers, when they try to attach it just hangs.
if a resource is restricted to a non-admin user, e.g
`container restricted to helpdesk user eve` then endpoint-admins cannot manage it.
disabling the rbac extension after assigning users rbac roles, leaves the users with their previous role's abilities & no way to remove them.
after refreshing the browser, rbac users no longer have abilities in the ui such as container console or volume browser
log out and log back in and they have abilities again.
when i try to update portainer from version 1.22.1 to version 1.22.2 i get the following error: ```bash
2019/11/06 09:33:24 migrating database from version 20 to 21.
2019/11/06 09:33:24 an error occurred during database migration: unexpected end of json input
2019/11/06 09:33:24 unexpected end of json input
it seems that the database has been corrupted because when i rolledback to 1.22.1 i can only login with admin user (local user) but not with ldap user
when i go to users section of portainer i get a "json invalid" error and inspecting the console i can see: ```bash
{"message":"unable to retrieve users from the database","details":"unexpected end of json input"}
``` now i have a broken portainer.
re-creating (or editing) a container won't update healthchecks if they specification changes inside the image specification.
we are not able to deploy any app from templates as we are receiving a deployment error.
after upgrading to 1.22.1 our members granted via rbac can not login anymore
the /api/users/<id> response 403 and the jwt token is too short comparing to 1.22.0 jwt.
i am trying to pull an image from my internal registry
the ui interface shows the "green" message saying that the image is correctly pulled
the page is automatically refreshed but the new image is not displayed in the list of the image
in fact, if i take a look at the docker log (/var/log/daemon.log), i can see the followiing log `oct 25 21:29:07 clus-portainer-1 dockerd[17001]: time="2019-10-25t21:29:07.623754245+02:00" level=info msg="attempting next endpoint for pull after error: failed to register layer: error processing tar file(exit status 1): write /usr/sbin/mysqld: no space left on device"
non-admins can create but cannot start containers.i.e `/images/create /containers/create` works but `/containers/$id/start` returns a 403.
no login fields displayed, it juat says loading portainer with a spinning gear.
when deleting a team a user is part of, the user's permissions are not updated to remove permissions inherited from the team.
when i atempt to install an application template such as "iron functions" in portainer which depends on the ` ` the deployment eventually fails as git times out attempting to access the resource.
as a non-admin, creating a volume with same name as an admin-only stack gives ownership of the stack to the non-admin user
if a non-admin creates a volume with same name as a stack volume, they get ownership of the volume
non-admin users & teams cannot manage resources associated to stacks or services **steps to reproduce**
have a stack or service owned by a non-admin user or team
try to perform a management action on a resource from the stack or service such as service update or container restart
see error `failure unable to force update the service` or `failure unable to restart container` **additional info**
- in the xhr log of chrome, i have the result "access denied to resource".
- it is working fine with the admin user.
- it was working perfectly in the 1.22.0 version.
- most commonly you will see access denied to container logs and stats as a non-admin user.
hello, this might be totally pebkac, but when i try to deploy a stack using a git repository as build context, i always get the following error: ![capture]( the docker-compose config i'm using is just ```
version: '2'
services: web: build:
``` no clue what could be the problem here...
cannot connect to portainer on windows 2019 swarm on port 9000 following instructions in blog post
when trying to add a host in the network section and re-deploying the container an error is displayed in the upper right corner that says "error: cannot read property \'push\' of null"
container fails to start.
i get the ` registry management configuration required` message when:
- updating an azure registry without re-entering password (possible on the develop image of portainer) - adding an azure registry with an invalid password and updating it with the correct password
unable to login with ldap users when they are not admins, but have endpoints assigned to them.
deploying a service from a private github package registry fails with error no such image, unless it is pulled before deploying
similarly, once an updated image is pushed, a service update with pull latest image toggle enabled leads to failing tasks with `no such image`
after adding an internal registry, when i try to browse or test i\'m receiving the error "invalid management configuration"
no logs appear in portainer container that can help me figure out what is the problem.
the added registry is using http and does not have authentication (and already verified that the v2 api is available in our internal docker registry)
when oauth is activated and someone tries to login with form and invalid credentials, backend panics
<details> ```
2019/09/19 13:54:18 server: reverse tunnelling enabled
2019/09/19 13:54:18 server: fingerprint 20:51:b5:63:e8:60:d9:cf:c7:1c:0f:c5:b6:75:98:14
2019/09/19 13:54:18 server: listening on 0.0.0.0:8000...
2019/09/19 13:54:18 starting portainer 1.22.0 on :9000
2019/09/19 13:54:18 [debug] [chisel, monitoring] [check_interval_seconds: 10.000000] [message: starting tunnel management process]
2019/09/19 13:55:28 http error: no administrator account found inside the database (err=object not found inside the database) (code=404)
2019/09/19 13:55:28 http error: no administrator account found inside the database (err=object not found inside the database) (code=404)
2019/09/19 13:55:46 http error: invalid credentials (err=unauthorized) (code=422)
2019/09/19 13:55:46 http error: invalid credentials (err=unauthorized) (code=422)
2019/09/19 14:32:47 http error: invalid credentials (err=unauthorized) (code=422)
2019/09/19 14:32:47 http error: invalid credentials (err=unauthorized) (code=422)
2019/09/19 14:35:04 http: panic serving 172.17.0.1:43668: runtime error: invalid memory address or nil pointer dereference
goroutine 15368 [running]:
net/http.(*conn).serve.func1( ) /usr/lib/go/src/net/http/server.go:1767 +
panic( , ) /usr/lib/go/src/runtime/panic.go:679 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticateinternal( , , , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:86 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticate( , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:68 +
github.com/portainer/libhttp/error.loggerhandler.servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/libhttp/error/error.go:28 +
github.com/portainer/portainer/api/http/security.mwsecureheaders.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/bouncer.go:318 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/security.(*ratelimiter).limitaccess.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/rate_limiter.go:36 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/gorilla/mux.(*router).servehttp( , , , ) /home/baron_l/go/src/github.com/gorilla/mux/mux.go:210 +
net/http.stripprefix.func1( , , ) /usr/lib/go/src/net/http/server.go:2046 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/handler.(*handler).servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/handler.go:65 +
net/http.serverhandler.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2802 +
net/http.(*conn).serve( , , ) /usr/lib/go/src/net/http/server.go:1890 +
created by net/http.(*server).serve /usr/lib/go/src/net/http/server.go:2927 +
2019/09/19 14:35:04 http: panic serving 172.17.0.1:43662: runtime error: invalid memory address or nil pointer dereference
goroutine 15367 [running]:
net/http.(*conn).serve.func1( ) /usr/lib/go/src/net/http/server.go:1767 +
panic( , ) /usr/lib/go/src/runtime/panic.go:679 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticateinternal( , , , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:86 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticate( , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:68 +
github.com/portainer/libhttp/error.loggerhandler.servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/libhttp/error/error.go:28 +
github.com/portainer/portainer/api/http/security.mwsecureheaders.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/bouncer.go:318 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/security.(*ratelimiter).limitaccess.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/rate_limiter.go:36 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/gorilla/mux.(*router).servehttp( , , , ) /home/baron_l/go/src/github.com/gorilla/mux/mux.go:210 +
net/http.stripprefix.func1( , , ) /usr/lib/go/src/net/http/server.go:2046 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/handler.(*handler).servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/handler.go:65 +
net/http.serverhandler.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2802 +
net/http.(*conn).serve( , , ) /usr/lib/go/src/net/http/server.go:1890 +
created by net/http.(*server).serve /usr/lib/go/src/net/http/server.go:2927 +
2019/09/19 14:35:04 http: panic serving 172.17.0.1:43654: runtime error: invalid memory address or nil pointer dereference
goroutine 15499 [running]:
net/http.(*conn).serve.func1( ) /usr/lib/go/src/net/http/server.go:1767 +
panic( , ) /usr/lib/go/src/runtime/panic.go:679 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticateinternal( , , , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:86 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticate( , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:68 +
github.com/portainer/libhttp/error.loggerhandler.servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/libhttp/error/error.go:28 +
github.com/portainer/portainer/api/http/security.mwsecureheaders.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/bouncer.go:318 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/security.(*ratelimiter).limitaccess.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/rate_limiter.go:36 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/gorilla/mux.(*router).servehttp( , , , ) /home/baron_l/go/src/github.com/gorilla/mux/mux.go:210 +
net/http.stripprefix.func1( , , ) /usr/lib/go/src/net/http/server.go:2046 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/handler.(*handler).servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/handler.go:65 +
net/http.serverhandler.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2802 +
net/http.(*conn).serve( , , ) /usr/lib/go/src/net/http/server.go:1890 +
created by net/http.(*server).serve /usr/lib/go/src/net/http/server.go:2927 +
2019/09/19 14:35:04 http: panic serving 172.17.0.1:43670: runtime error: invalid memory address or nil pointer dereference
goroutine 15369 [running]:
net/http.(*conn).serve.func1( ) /usr/lib/go/src/net/http/server.go:1767 +
panic( , ) /usr/lib/go/src/runtime/panic.go:679 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticateinternal( , , , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:86 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticate( , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:68 +
github.com/portainer/libhttp/error.loggerhandler.servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/libhttp/error/error.go:28 +
github.com/portainer/portainer/api/http/security.mwsecureheaders.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/bouncer.go:318 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/security.(*ratelimiter).limitaccess.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/rate_limiter.go:36 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/gorilla/mux.(*router).servehttp( , , , ) /home/baron_l/go/src/github.com/gorilla/mux/mux.go:210 +
net/http.stripprefix.func1( , , ) /usr/lib/go/src/net/http/server.go:2046 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/handler.(*handler).servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/handler.go:65 +
net/http.serverhandler.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2802 +
net/http.(*conn).serve( , , ) /usr/lib/go/src/net/http/server.go:1890 +
created by net/http.(*server).serve /usr/lib/go/src/net/http/server.go:2927 +
2019/09/19 14:35:04 http: panic serving 172.17.0.1:43658: runtime error: invalid memory address or nil pointer dereference
goroutine 15366 [running]:
net/http.(*conn).serve.func1( ) /usr/lib/go/src/net/http/server.go:1767 +
panic( , ) /usr/lib/go/src/runtime/panic.go:679 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticateinternal( , , , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:86 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticate( , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:68 +
github.com/portainer/libhttp/error.loggerhandler.servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/libhttp/error/error.go:28 +
github.com/portainer/portainer/api/http/security.mwsecureheaders.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/bouncer.go:318 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/security.(*ratelimiter).limitaccess.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/rate_limiter.go:36 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/gorilla/mux.(*router).servehttp( , , , ) /home/baron_l/go/src/github.com/gorilla/mux/mux.go:210 +
net/http.stripprefix.func1( , , ) /usr/lib/go/src/net/http/server.go:2046 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/handler.(*handler).servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/handler.go:65 +
net/http.serverhandler.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2802 +
net/http.(*conn).serve( , , ) /usr/lib/go/src/net/http/server.go:1890 +
created by net/http.(*server).serve /usr/lib/go/src/net/http/server.go:2927 +
2019/09/19 14:35:04 http: panic serving 172.17.0.1:44868: runtime error: invalid memory address or nil pointer dereference
goroutine 16461 [running]:
net/http.(*conn).serve.func1( ) /usr/lib/go/src/net/http/server.go:1767 +
panic( , ) /usr/lib/go/src/runtime/panic.go:679 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticateinternal( , , , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:86 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticate( , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:68 +
github.com/portainer/libhttp/error.loggerhandler.servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/libhttp/error/error.go:28 +
github.com/portainer/portainer/api/http/security.mwsecureheaders.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/bouncer.go:318 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/security.(*ratelimiter).limitaccess.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/rate_limiter.go:36 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/gorilla/mux.(*router).servehttp( , , , ) /home/baron_l/go/src/github.com/gorilla/mux/mux.go:210 +
net/http.stripprefix.func1( , , ) /usr/lib/go/src/net/http/server.go:2046 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/handler.(*handler).servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/handler.go:65 +
net/http.serverhandler.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2802 +
net/http.(*conn).serve( , , ) /usr/lib/go/src/net/http/server.go:1890 +
created by net/http.(*server).serve /usr/lib/go/src/net/http/server.go:2927 +
2019/09/19 14:35:04 http: panic serving 172.17.0.1:44872: runtime error: invalid memory address or nil pointer dereference
goroutine 16149 [running]:
net/http.(*conn).serve.func1( ) /usr/lib/go/src/net/http/server.go:1767 +
panic( , ) /usr/lib/go/src/runtime/panic.go:679 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticateinternal( , , , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:86 +
github.com/portainer/portainer/api/http/handler/auth.(*handler).authenticate( , , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/auth/authenticate.go:68 +
github.com/portainer/libhttp/error.loggerhandler.servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/libhttp/error/error.go:28 +
github.com/portainer/portainer/api/http/security.mwsecureheaders.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/bouncer.go:318 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/security.(*ratelimiter).limitaccess.func1( , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/security/rate_limiter.go:36 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/gorilla/mux.(*router).servehttp( , , , ) /home/baron_l/go/src/github.com/gorilla/mux/mux.go:210 +
net/http.stripprefix.func1( , , ) /usr/lib/go/src/net/http/server.go:2046 +
net/http.handlerfunc.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2007 +
github.com/portainer/portainer/api/http/handler.(*handler).servehttp( , , , ) /home/baron_l/go/src/github.com/portainer/portainer/api/http/handler/handler.go:65 +
net/http.serverhandler.servehttp( , , , ) /usr/lib/go/src/net/http/server.go:2802 +
net/http.(*conn).serve( , , ) /usr/lib/go/src/net/http/server.go:1890 +
created by net/http.(*server).serve /usr/lib/go/src/net/http/server.go:2927 +
on portainer 1.22.0 containers with status of healthy, paused or created are not displayed in the containersoverview list
when attempting to access an associated edge agent on a synology host, the action fails and the error message: > endpoint is unreachable and there is no snapshot available for offline browsing
is displayed.
i have a local registry where an image `nginx:test` is available referenced by my templates server
when trying to deploy the container on an edge agent the following red pop-up appears: "failure
no such image: myregistry:5000/nginx:latest" even if this is not the tag i asked for.
doing a stack creation via git clone fails saying the following error message:
2019/09/03 05:41:50 http error: open /data/compose/1/docker-stack.yml: no such file or directory (err=open /data/compose/1/docker-stack.yml: no such file or directory
) (code=500)
``` ![image]( ![image](
when browsing a repo's tags, items selected on a page of the tags datatable aren't persisted after selecting more items on another page.
try pull an image that isn\'t multiarch and portainer says `image pulled`, because docker api returns a "success operation" response, but it doesn\'t actually pull
also sometimes caused when registry access is blocked by a strict firewall
in the home view, we ping each endpoint before we try to connect, if the backend status of the endpoint is `down` the backend responds directly, this results in the ping failing, even in the endpoint is up, running and accessible (responding to pings outside of portainer etc.)
an agent endpoint associated to one portainer instance, still shows as `up` after being associated as an endpoint to another portainer instance
clicking on the endpoint in the orginal portainer instance will give an error message `failure: unable to connect to the docker environment` but portainer still shows it as up.
when using auto-refresh on the services table, all expanded services are collapsed after a refresh.
portainer allows you to select numbers for some number inputs which do not make sense
for the number of replicas for a service you can select `negative` numbers.
after clicking on a services checkbox it makes the task status table show up, pushing the rest of the services down in the table
this makes selecting specific services difficult.
persistent volumes added to a service when deploying are not saved
- volumes named by docker arent persisted, but named ones are in v1.19.0 & v1.20.0
- volumes named by docker & named volumes arent persisted in v1.21.0 & v1.22.0
the containers are always sorted by state.
if you've enabled authentication for a private registry, you cannot grant access to that registry to users or groups at the `registries/1/access` url.
resizing window where network usage (for a container) shows, may end it up showing incorrect y-values.
when deploying a new stack in portainer, the containers don't have any variables passed to them but when deployed via `docker stack deploy` it works perfectly.
when updating the url of a registry, the new url is not used to browse the registry unless you access the `registry/:id/configure` url and test the configuration.
a merged pr request in the development branch has introduced a bug where tables in portainer are not defaulting to sorting alphabetical by name.
there is a checkbox next to the service webhook button on the service details view that should not be there.
after portainer has been running a while, it can't connect to the primary endpoint any more
we're not using agents, see docker-compose-file below.
in the logs i can see lots of those: `background schedule error (endpoint snapshot)
unable to update endpoint (endpoint=primary, url=unix:///var/run/docker.sock) (err=input/output error)` if we restart portainer, e
using `docker service update --force portainer_portainer`, it's running ok for about a day again
i've seen issues about this regarding the agent but couldn't find an issue about /var/run/docker.sock, so maybe this is something different.
portainer implementation of oauth is missing the state parameter which is needed to integrate with okta.
if i set an `env` variable within my dockerfile, build and deploy it (i.e
make a container using that image) the `env` variables are displayed in portainer's ui, which is great
but if i now build a new image version with the variable set to a different value, that change is not taken on neither `recreate`, nor `duplicate/edit`
it seems as if portainer reads the variables from the image and saves them in its own database
when creating new versions of a container these variables are then applied to the container, overriding the ones set in the `dockerfile`
i can see how this behavior makes sense on variables entered on portainer's ui
i am willing to discuss this behavior on variables passed in by an external call of `docker` cli
but for variables set in `dockerfile` this is at least highly unintuitive.
when a docker command takes a long time to execute (such as fetching all volumes) portainer and the agent both experience errors
- with an agent enabled endpoint, it shows as up in portainer but clicking on it gives the error that it is down.
- when using the portainer ui and browsing to the dashboard and other views where a docker a command times out, elements of the ui fail to load and there are errors in the browser.
it seems that portainer is blocking on a read or write to its underlying data volume "/data", when it is backed by an nfs share (or something remote)
when this is the case, the portainer binary blocks waiting indefinitely and never becomes responsive.
when a agent becomes unavailable (such as the node it's on being drained), portainer can be impacted with a failed request
this could potentially lead to an endpoint going down if a snapshot request is issued around the same time that the drain request is issued.
ui settings not persisted after log-out
i just updated to version 1.21.0 and now the ui settings keep to be reset after logout event.
settings the "items per page" on container view or hiding a column is not persisted.
on previous version 1.20.2 this was working as expected i can successfully see the following cookie set and persisted, but looks like is ignored: ```
portainer.pagination_containers:"100" creationtime:"thu, 06 jun 2019 08:10:51 gmt" domain:"<hidden>" expires:"sat, 06 jul 2019 08:10:51 gmt" hostonly:true httponly:false lastaccessed:"sat, 08 jun 2019 12:19:46 gmt" path:"/" secure:false samesite:"unset"
after add new private registry,i create new app template and deploy container,portainer give me message "failure:invalid reference format".portainer shows image has pulled.
deploying new stack from git repository fails with "deployment error, unable to clone git repository"
portainer logs show: `2019/05/29 10:24:48 http error: unable to clone git repository (err=read c:\\data\\compose\\1\\.git\\head: the process cannot access the file because another process has locked a portion of the file.) (code=500)`
can\'t add volumes using "local-persist" driver from interface
i need to add them through command line, but portainer won't save them.
i am running a local registry on my host windows 10 machine
after purchasing and enabling the registry manager extension, i'm able to visualize the repository with different image tags that i have pushed
however, if i click into any of the repository and refresh the page, it gives me an error saying: "failure: unable to retrieve tag <tag name>" the repositories are still there, just unable to retrieve the images with tags
i first thought it might be the registry, so i tried to "docker pull" images from the local registry and i am able to do that.
getting an error "build invalid reference format" when trying to build powerdns-admin container.
deploying container with nfs volume fails with "failed to chmod"
clicking on container console button throws an error message: unable to retrieve images details.
if you type the text in the terminal, then after you switch to another language for example (in my case it's russian), then switching back you will find that you can no longer write anything to the terminal.
when creating a secret that has a label added with a blank name, the label is applied.
in swarm mode in windows container mode, portainer is unable to connect to the local running docker daemon
connecting to a tcp-enabled docker daemon on another manager server works fine.
ldap user credentials not recognized
ldap configuration is ok as test connectivity return green flag.
at the time the snapshot task runs, there's a schedule error, and then the endpoint goes offline and becomes unavailable.
during service creation you can assign the same secret/config multiple times which you should not be able to do, as the service create will fail.
when creating a user with space in the name (which is not allowed) an incorrect error message is shown.
if all or part of a tag name is entered in the home view search box, all endpoints (including ones that match) are hidden.
specifying the `--admin-password-file` option logs a message that it creates an admin user with a calculated password hash, but the plain-text password in the given file doesn't work on the login page
consider this docker-compose config file:
version: "3.7"
services: portainer: image: portainer/portainer container_name: portainer restart: always command: --admin-password-file /run/secrets/portainer_admin_password -h unix:///var/run/docker.sock ports: - "9000:9000" volumes: - /var/run/docker.sock:/var/run/docker.sock - /home/ubuntu/docker/portainer/data:/data secrets: - portainer_admin_password test: image: centos:7 entrypoint: "cat /run/secrets/portainer_admin_password" secrets: - portainer_admin_password
secrets: portainer_admin_password: file: /home/ubuntu/docker/portainer_admin_password
``` additionally, i created `/home/ubuntu/docker/portainer_admin_password` with my desired plain-text password
if i remove the portainer data directory (to ensure a clean up) and run `docker-compose up portainer`, the output looks like this: ```
creating portainer ..
attaching to portainer
portainer | 2019/04/07 19:18:39 creating admin user with password hash <redacted>
portainer | 2019/04/07 19:18:39 starting portainer 1.20.2 on :9000
``` however, attempting to log in with the password contained in the secret file fails
i considered that there may be a problem with the secrets file
since i can't exec bash into the portainer container, i defined the test service
`docker-compose up test` outputs the exact contents of the secrets file
this tells me that `/run/secrets/portainer_admin_password` should exist with the correct contents on the portainer container.
when 'authorize all' or 'deny all' is used, with multiple users or teams present in the users and teams or authorized users and teams tables, not all entries are moved.
each time a team leader is removed from a team, the team leader count is not reset to reflect this.
unable to get the cpu stats from windows containers other than from the container on endpoint host.
endpoint is not listed on dashboard, neither local named-pipe nor tcp.
i don;t know what microsoft try to do here, but they have change the hostname event the image is available in docker hub
but portainer do not handle it well: the docker registry for the mcr.microsoft.com/azure-pipelines/vsts-agent:ubuntu-16.04-docker-18.06.1-ce-standard image is not registered inside portainer, you will not be able to create a container
please register that registry first.
when using the portainer development environment on mac i am unable to deploy a stack.
when the portainer agent is not running globally in a swarm, i can click the stats and console task actions on all nodes under the service.
i'm unable to update any stack definition on portainer after upgrading from 1.20.0 to 1.20.1
version 1.20.2 fails to start on windows 10 v1809.
error message returned from: ```
docker : error response from daemon: container 5fb0aa8da94f5862adc267727babc0a09386286928fea8b708cb6d03415ff353 encountered an error during start: failure in a windows system call: the virtual machine or container exited unexpectedly
( )
at line:1 char:1
+ docker start portainer
+ ~~~~~~~~~~~~~~~~~~~~~~ + categoryinfo : notspecified: (error response ...y
( ):string) [], remoteexception + fullyqualifiederrorid : nativecommanderror error: failed to start containers: portainer ```
there is no registries option in the side-bar when using no-auth.
portainer 1.20.1 ui hangs when i try to add endpoint with tls certs
i have placed ca.pem, cert.pem and key.pem in the /home/ash/certs folder using the bind-mount
i then try to add a remote endpoint and upload the tls files using the ui from /home/ash/certs and the ui hangs and i see no response from the target docker engine showing that there was communication was between the engine and portainer
however, the endpoint is added when i use the cli as follows: `docker run -d -p 9000:9000 --name portainer -v /home/ash/certs:/certs -v portainer_data:/data portainer/portainer -h tcp://192.168.100.2:2376 --tlsverify`
possibly related to #2306 if a variable list is created in the app template with several values, when creating a stack the selected variable is replaced by the preset value if a preset exists in the list
if the preset is blank, or does not exist, the variable is blanked out.
when the firewall block the connection to some registries ip, portainer shows a "image downloaded successfully" even if the download failed.
i am unable to view stacks, produces red box that says "unable to retrieve stacks" also, the login button nolonger logs you in
have to hit refresh after clicking on login button to get it to log me in
(using chrome 69.0.3497.100 )
logout portainer
login portainer
visit #/templates
page is blank
`get`ing a network that doesn't exist (i.e
`/api/endpoints/$id/docker/v1.25/networks/does_not_exist`) returns a `502` without any content (and logs out `http: proxy error: docker network identifier not found`)
docker itself responds with `404` and an error message in that case.
after portainer session timeout, and the user clicks any page, it will go to login page
however, clicking login button has no response, staying in `/auth`
in fact the login is successful.
then user has to press f5
it will go to `/home`
windows container: ajax docker api frequently respond "i/o timeout"
user may see red toast of following messages:
`unable to proxy the request via the docker socket`
`unable to retrieve stacks`
`unable to retrieve images`
containers -> add container, red toast "typeerror: object expected" shown js console (edge):
http500: server error - the server encountered an unexpected condition that prevented it from fulfilling the request.
(xhr)get - http500: server error - the server encountered an unexpected condition that prevented it from fulfilling the request.
(xhr)get - http500: server error - the server encountered an unexpected condition that prevented it from fulfilling the request.
(xhr)get - typeerror: object expected at anonymous function ( at h ( at anonymous function ( at o.prototype.$eval ( at o.prototype.$digest ( at o.prototype.$apply ( at i ( at u ( at x.onload (
``` js console (firefox)
http 500 error: can't convert null to object
x/<@
h@
i/<@
$eval@
$digest@
$apply@
i@
u@
kb/</x.onload@
``` js console (chrome)
app.261b69fc.js:29 get 500 (internal server error)
(anonymous) @ app.261b69fc.js:29
q @ app.261b69fc.js:29
i @ app.261b69fc.js:29
h @ app.261b69fc.js:29
(anonymous) @ app.261b69fc.js:29
$eval @ app.261b69fc.js:30
$digest @ app.261b69fc.js:30
$apply @ app.261b69fc.js:30
(anonymous) @ app.261b69fc.js:30
f @ app.261b69fc.js:28
(anonymous) @ app.261b69fc.js:28
settimeout (async)
k.defer @ app.261b69fc.js:28
f @ app.261b69fc.js:30
(anonymous) @ app.261b69fc.js:40
dispatch @ app.261b69fc.js:3
q.handle @ app.261b69fc.js:3
app.261b69fc.js:29 typeerror: cannot convert undefined or null to object at function.keys (<anonymous>) at app.261b69fc.js:51 at h (app.261b69fc.js:29) at app.261b69fc.js:29 at o.$eval (app.261b69fc.js:30) at o.$digest (app.261b69fc.js:30) at o.$apply (app.261b69fc.js:30) at i (app.261b69fc.js:29) at u (app.261b69fc.js:29) at xmlhttprequest.x.onload (app.261b69fc.js:29)
can't reset resources to unlimited for a container
unable to pull image `localhost:5000/asp-service:latest` from the image page since it has two `:` in the name
portainer does a `post ` incorrectly
it splits the first colon and sets `5000/asp-service` as the tag
i have this app template:
{ "type": 2, "title": "xxx", "description": "xxx", "categories": ["xxx"], "platform": "linux", "repository": { "url": " ", "stackfile": "docker-cloud.yml" },
``` i have a private git server running in my server to provide this repo: ` `
but when cloning portainer fails with:
{"err":"unable to clone git repository","details":"object not found"}
``` the thing is, this repo `universal-webdev` repo is a submodule of another repo
cloning normal repos through app templates works, but a submodule is failing
and there is no problem with the container that serves this repo
when i attempted to clone it through another container it worked
here's a experiment that i did running a container on the same network as the git server one:
/ # git clone
cloning into 'universal-webdev'...
remote: counting objects: 21, done.
remote: compressing objects: 100% (15/15), done.
remote: total 21 (delta 5), reused 16 (delta 4)
unpacking objects: 100% (21/21), done.
note: checking out 'ec5f4ba37bae701b212337c346dfb29666e7dd57'
you are in 'detached head' state
you can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by performing another checkout
if you want to create a new branch to retain commits you create, you may
do so (now or later) by using -b with the checkout command again
example: git checkout -b <new-branch-name> / # cd universal-webdev/
/universal-webdev # ls -la
drwxr-xr-x 4 root root 4096 jan 31 18:25 .
drwxr-xr-x 1 root root 4096 jan 31 18:25 ..
drwxr-xr-x 8 root root 4096 jan 31 18:25 .git
-rw-r--r-- 1 root root 76 jan 31 18:25 readme.md
drwxr-xr-x 3 root root 4096 jan 31 18:25 cloud9
-rw-r--r-- 1 root root 2327 jan 31 18:25 docker-cloud.yml
volume download works for plain text files, but if the file is a zip, somehow the downloaded one cannot be extracted by any zip tools.
in the network tab underneath the advanced container settings section of a created container, if you\'re using the "container" network, the chosen container sub-option reverts to "select a container" when you save and view/edit the container settings again
![screenshot of problem]( as far as i have seen, this is only a cosmetic issue, and the container is still properly configured to use the network of another container
an additional issue that this causes is that when editing a container, you receive a "failure invalid network mode: invalid container format container:" error when trying to deploy
the error vanishes when you select the proper container sub-option again.
when creating stacks concurrently using portainer api all created stacks share the same stack id
- only last deployed stack have "total" control, all remaining stack have "limited" control.
- all stacks share the same `/data/compose/<stack_id>` directory with the first deployed stack specifications.
we are using --external-endpoints command line to specify the endpoint so it doesnt have to be setup
it looks like in portainer 1.20 the client does a get to /endpoints/1/docker/_ping, receives an ok and then tries to do a put to /api/endpoints/1 which then fails with `{"err":"endpoint management is disabled","details":"endpoint management is disabled"}`
`failure: unable to query endpoint` on endpoints list on portainer home page after connecting to the console of any container on an endpoint using the portainer agent
the docker host is still online and available directly through ssh.
happens exclusively with endpoints using the portainer agent.
a 2nd endpoint with the alternative socket method to the same host still works, while the agent doesn't.
as the subject says
i tried connecting the container to a network (tried multiple times with multiple networks)
when going into the container's page, clicking on each of the networks resulted in opening the network page with empty details and an error `unable to retrieve network details` when checking the url of the networks page it was missing the network id, when i went back to the container page i found that the network url was missing the network id
inspecting the network object resulted in missing id for the network
i did a few checks and also running `network connect <network-id> <container-id>` had the same results, seems like a bug with docker
posting this here to think of a workaround.
creating a new team containing the character '&' results in the ampersand character being transformed to `&amp;` which prevents the 'automatic user provisioning' functionality to work as expected while using ldap.
when starting a container/stack with acl turned on, the volume does not appear in the volume view, only for administrators, as it is has the ownership 'administrators'.
new nodes are unable to pull images from remote registry that requires authentication
i have private registry in aws ecr, nodes are running outside of aws and this requires authentication in ecr then
when new node joins, portainer will attempt to start containers on it including those defined as global
the automatic pull fails every time, right until i manually pull image via portainer dashboard specifying that registry
looking at docker logs when this issue happens i see it fails to pull image from that registry, which makes me think that the auth credentials are not used in that case (even though saved), but used (added) to node when manually pull image.
when attempting to deploy a stack that has the following config, an error is encountered
version: '2' services: test: image: docker/hello-world networks: network_1: priority: 100 default: networks: network_1:
time="2019-01-08t13:48:44z" level=error msg="could not parse config for project test : service \'test\' configuration key \'networks\' \ unsupported config option for network_1 service: \'priority\'\ unsupported config option for test service: \'network_1\'"
i\'ve created an overlay network named "cluster" in docker by using following command: `docker network create -d=overlay --attachable=false --subnet=10.1.1.0/24 --subnet=10.1.2.0/24 --subnet=10.1.3.0/24 --gateway=10.1.1.1 --gateway=10.1.2.1 --gateway=10.1.3.1 cluster` when i review its detail from portainer\'s "networks" page, it just shows one subnet and one gateway, other two subnets(10.1.2.0/24, 10.1.3.0/24) and gateways are disappeared
[![image](
when using service webhooks or the `update the service` (along with the `pull latest image version` option), the related app is updated **but the image is not updated**.
it seems that this issue is related to
when attempting to login to portainer from the firefox ios app, it simply says the login information is incorrect
i have it saved with firefox so it auto-populates the username and password so maybe that is causing some type of snafu, but even if i type in the login information manually it still won't let me login.
cannot launch new stacks with portainer running on synology nas.
have tried various docker-compose files in the "deploy stack" web ui, all with the same results (see below).
i created a container, wanted to edit some env variables and redeploy it.
after that the published ports are missing
if i edit the container again the ports show up in the configuration but they are not published.
frequent error messages:
frequent **offline mode** with 1.20.0
**endpoint is down**
**unable to query endpoint**
recreate/edit leads to the command & logging showing: ```
''./docker/docker-entrypoint.sh''
``` manually removing the single quotes leads to this working again
updated from 1.19.2 to 1.20.0 and portainer can't start
setting a portainer agent stack as described in the official documentation, leads to an unstable endpoint, sometimes up, sometimes down, sometimes showing correct info, sometimes giving error messages inside portainer.
there are some missing characters in container logs please download `log.txt` and then build below `dockerfile`
from ubuntu:bionic add log.txt / entrypoint [ "cat", "/log.txt" ]
``` [log.txt]( then run a container of this image.
go to portainer **container logs** to see the log
these lines are wrong: first 2 characters are missing
`ing over pending ways`
`ing over pending ways`
`mpleted planet_osm_roads`
`m2pgsql took 22s overall`
after starting a new portainer instance via docker and creating the admin user, one ends up on the login page with the error message "your session has expired", unable to log in with the user just created.
flags seems to be ignored when starting portainer.
as the title says, if for example i just created the portainer instance and didn't select the initial endpoint, and i change the url to `/dashboard` i get an error in my console about missing endpoint.
when pulling an image, ```get http:: http: no host in request url``` is returned.
i've used the cloudstor:azure storage plugin in order to set up a swarm with multiple manager nodes.
(this is the microsoft recommended approach, it uses smb under the hood.) leaving this configuration running for several hours, all swarm-related operations stop working
due to file-handle errors
restarting only the portainer instance solves the issue until it happens again
note that non-swarm operations, such as aggregating and start/stopping containers still works in this state
<details><summary>reference stack.yml file</summary> ```yml
version: '3.4'
services: portainer: image: portainer/portainer:latest command: -h tcp://tasks.agents:9001 --tlsskipverify networks: - portainer-agents volumes: - portainer-data:/data deploy: mode: replicated replicas: 1 restart_policy: condition: any delay: 3s placement: constraints: - node.role == manager agents: image: portainer/agent:latest environment: agent_cluster_addr: tasks.agents networks: - portainer-agents volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes deploy: mode: global restart_policy: condition: any delay: 3s update_config: order: start-first parallelism: 1 delay: 3s monitor: 5s failure_action: rollback volumes: portainer-data: driver: cloudstor:azure networks: portainer-agents: driver: overlay attachable: true
``` </details><br /> due to #1588's revert this doesn't resolve itself and requires manual restarts on a daily basis.
a proper ha solution like #523 would likely resolve this.
for stopped container, container stat page shows red prompt at top right corner.
but it is showing some javascript error message
when container is configured with logging driver and option, it's not preserved or parsed out from docker inspect when trying to duplicate/edit
it basically falls back to default logging always, and user then needs to re-type the logging options and drviers
this is from testing on portainer/portainer:pr2384
cannot create/modify/save any environment variables after container creation
bug only on synology.
after a restart of the host portainer says that the swarm it is managing is down
the swarm is still up and portainer is running in the swarm
the agents are running as well
after removing the portainer container, so that the swarm spins a new one, solves the issue.
i do two simultaneous call on post /api/stacks?endpointid=1&method=string&type=1
curl --request post \\ --url \' \\ --header \'authorization: bearer $token\' \\ --header \'content-type: application/json\' \\ --data \'{ "name": "test1", "swarmid": "owc19h4fn3hj86vyxpdquwl2s", "stackfilecontent": "version: \'\\\'\'3.6\'\\\'\'\ services:\ alertmanager:\ image: prom/alertmanager:v0.15.1\ deploy:\ replicas: 1\ restart_policy:\ condition: on-failure\ ports:\ - \\"9093\\"\ volumes:\ - \\"alertmanager:/alertmanager\\"\ command:\ - \\"--config.file=/etc/alertmanager/config.yml\\"\ - \\"--storage.path=/alertmanager/data\\"\ \ volumes:\ alertmanager:"
``` request 2:
curl --request post \\ --url \' \\ --header \'authorization: bearer $token\' \\ --header \'content-type: application/json\' \\ --data \'{ "name": "test2", "swarmid": "owc19h4fn3hj86vyxpdquwl2s", "stackfilecontent": "version: \'\\\'\'3.6\'\\\'\'\ services:\ prometheus:\ image: prom/prometheus:v2.3.2\ deploy:\ replicas: 1\ restart_policy:\ condition: on-failure\ ports:\ - \\"9090\\"\ volumes:\ - \\"prometheus:/prometheus\\"\ - \\"prometheus_file_sd:/etc/prometheus/file_sd\\"\ command:\ - \\"--web.enable-admin-api\\"\ - \\"--config.file=/etc/prometheus/prometheus.yml\\"\ - \\"--storage.tsdb.path=/prometheus\\"\ - \\"--log.level=debug\\"\ volumes:\ prometheus:\ prometheus_file_sd:"
``` response 1:
{"id":20,"name":"test1","type":1,"endpointid":1,"swarmid":"owc19h4fn3hj86vyxpdquwl2s","entrypoint":"docker-compose.yml","env":null,"projectpath":"/data/compose/20"}
``` response 2:
{"id":20,"name":"test2","type":1,"endpointid":1,"swarmid":"owc19h4fn3hj86vyxpdquwl2s","entrypoint":"docker-compose.yml","env":null,"projectpath":"/data/compose/20"}
using latest portainer 1.19.2 when trying to add a stack which resides in our private repository, portainer show an error "unable to clone repository", portainer logs show the errors: ```
2018/10/25 12:14:07 http error: unable to clone git repository (err=zlib: invalid checksum) (code=500)
2018/10/25 12:16:14 http error: invalid jwt token (err=invalid jwt token) (code=401)
2018/10/25 12:16:14 http error: invalid jwt token (err=invalid jwt token) (code=401)
2018/10/25 12:16:14 http error: invalid jwt token (err=invalid jwt token) (code=401)
2018/10/25 12:20:14 http error: unable to clone git repository (err=zlib: invalid checksum) (code=500)
2018/10/25 12:22:04 http error: unable to clone git repository (err=zlib: invalid checksum) (code=500)
2018/10/25 12:24:17 http error: invalid credentials (err=unauthorized) (code=422)
2018/10/25 12:24:17 http error: invalid credentials (err=unauthorized) (code=422) ```
the volume which portainer uses is empty before starting the portainer container
using git clone for the same repository from command line works as expected.
when deplying a stack on a non-swarm instance, the network ip is ignored.
when trying to edit an existing container, portainer fails to remove the old container property, and the new container fails to deploy.
i have several stack created on "docker" endpoint
say enpointid 1
i then added portainer agent and had to recreated the endpoint, lets say it's enpointid 2
now all my stack are associated with endpointid 1, so when i try to edit the stack i get a failure message saying it's unable to find the endpoint
so i queried the api to get the stack information: get :
[ { "id": 3, "name": "mystack", "type": 1, "endpointid": 1, "swarmid": "x2mhmp4h9xdb1qecnso10abro", "entrypoint": "docker-compose.yml", "env": [], "projectpath": "/data/compose/3", "resourcecontrol": { "id": 0, "resourceid": "", "subresourceids": null, "type": 0, "useraccesses": null, "teamaccesses": null, "public": false } }
] so i tried to update the endpointid using the api: put :
"endpointid":2
} and i get : { "err": "unable to find the endpoint associated to the stack inside the database", "details": "object not found inside the database"
portainer dont start in smbglobalmapping, same with symbolic link enable.
portainer mounts the volume not based on absolute path of the host
but relative to container root?
when a stack is added via api, the docker-compose.yml file is created as expected, while the "env" list of dictionaries is ignored.
i created some stacks via api which shared the same network
i tried to remove both, but is not possible to remove the second one, because the network is no more available.
portainer hangs if i dinamically leave a managed docker machine from swarm and ingress it in another one.
a stack has been created via api with status code 200, but it is not listed in the web interface nor in the api.
triggering a service to update & selecting `pull latest image verison` will not pull the image and update to it, when the image it uses is in a private registry.
a bit of a long shot but i got deployment of private aws ecr images in a swarm stack working by following the solution in #1533 with the [`amazon-ecr-credential-helper`](
however if i try and use the service webhooks #1663 to update the created service the update gets rejected with ```
rejected xx seconds ago "no such image: 012345678901.dkr.ecr.eu-west-1.amazonaws.com/someimage:latest"
but if i update the stack it pulls the image just fine
it seems like authorisation is being handled differently between the service and stack pages.
when recreating a container that was previously on the bridge with mapped ports and changing the network to container:<container name> the following error shows: "conflicting options: port exposing and the container type network mode"
when i upgrade from portainer 1.19.1 to 1.19.2, i can no longer start any container
the deployment fails with the following error "failure shim error: docker-runc not installed on system" containers are created but not able to start
if i downgrade to 1.19.1, i still can not start the container i created with 1.19.2
i need to destroy it and recreate it with 1.19.1 the portainer docker logs is not showing any relevant message:
2018/09/28 09:36:41 migrating database from version 13 to 14.
2018/09/28 09:36:41 templates already registered inside the database
skipping template import.
2018/09/28 09:36:41 instance already has defined endpoints
skipping the endpoint defined via cli.
2018/09/28 09:36:41 starting portainer 1.19.2 on :9000 i think this is related to a combination of something recently introduced in portainer 1.19.2 with the docker version distributed in by redhat if i install docker-ce from the repos, it seems to work nice in combination 1.19.2
with ie 11 the webui fails on 'connecting to the docker endpoint' .
when i log in with a non admin user, the endpoints' group name is empty
![home view]( also the model doesn't have a group name:
![model](
variables for an app template that are defined via select from predefined values are not inserted ito the compose file
when hitting "deploy stack", the value in the drop downs change to "select value" as well.
title says it all.
after scaling a service from 1 -> 0 -> 1 containers, the scaled-up container does not have environment variables, configured in the portainer ui, set in the container.
if the entry point has one or more arguments, making any change in the entry point field will make the container invalid, because it gets saved as a string rather than an array.
i can't pull a private image from the docker hub althought login details were entered on the registry screen.
add new external endpoint in json file and restart portainer, it shows in interface, but when you want to manage access to this new endpoint, it gives error:
> unable to find an endpoint group with the specified identifier inside the database and it doesn't load access management interface part.
http/1.1 100 continue http/1.1 400 bad request
date: sat, 25 aug 2018 05:49:40 gmt
server: apache/2.4.6 (scientific linux)
content-type: application/json
x-content-type-options: nosniff
x-frame-options: deny
content-length: 34
via: 1.1 portainer.tools.rentpath.com
connection: close {"err":"invalid request payload"}
when linking container `foo` to container `bar`, the name displayed for container `bar` changes to be `foo/bar`
this does not align with what shows up in `docker container list`, nor is it a desirable behavior (for me).
on a service details page, long image names are truncated (expected), but very difficult to see and edit
the text field wraps the image name, and forces focus to the top of the field
this means that it is not possible to scroll/drag past the right edge of the text field, like a normal text field
it is also not possible to scroll or move the text cursor down to see the overflowed text, because the scroll position is forced to the top.
when a service details page is opened (e.g., by clicking on a service on the services page), it immediately scrolls to the bottom of the page because the focus is set to the search field in the tasks list
i then have to scroll to the top of the page in order to see service details or access the quick navigation.
after configuring ldap authentication against active directory, portainer panics after creating the user but before allowing the user to log in.
in stacks view, clicking on an action in the actions column leads to a js error
app.c7ffb2f9.js:16 error: param values not valid for state 'docker.containers.container.logs'
invalid params: [ id ]
docker networ alias is not created from portainer (dupplicate/edit -> deploy container )
the custom docker registry doesn't work without a trick workaround - see steps for more details.
any empty environment variables set (e.g
my_var="") are rendered with a trailing = in their name after a "duplicate/edit" ui action on the container
(see screenshot)
docker registry from gitlab.com cannot be accessed through a fqdn, hence cannot be accessed in portainer.
when update agent from `v1.0.0` to `v1.1.1` (tried `v1.1.0` also) today:
# docker service ls |grep portainer-agent
mphbzaqggbwx portainer-agent global 3/5 portainer/agent:1.1.1 # docker service logs -f portainer-agent
portainer-agent.0.xygaf4h8klec@node-03 | panic: runtime error: index out of range
portainer-agent.0.xygaf4h8klec@node-03 | portainer-agent.0.xygaf4h8klec@node-03 | goroutine 1 [running]:
portainer-agent.0.xygaf4h8klec@node-03 | main.retrieveadvertiseaddress( , , , )
portainer-agent.0.xygaf4h8klec@node-03 | /src/cmd/agent/main.go:92 +
portainer-agent.0.xygaf4h8klec@node-03 | main.main()
portainer-agent.0.xygaf4h8klec@node-03 | /src/cmd/agent/main.go:133 +
portainer-agent.0.ssr43heib0hq@node-04 | panic: runtime error: index out of range
portainer-agent.0.ssr43heib0hq@node-04 | portainer-agent.0.ssr43heib0hq@node-04 | goroutine 1 [running]:
portainer-agent.0.ssr43heib0hq@node-04 | main.retrieveadvertiseaddress( , , , )
portainer-agent.0.ssr43heib0hq@node-04 | /src/cmd/agent/main.go:92 +
portainer-agent.0.ssr43heib0hq@node-04 | main.main()
portainer-agent.0.ssr43heib0hq@node-04 | /src/cmd/agent/main.go:133 + ``` downgrade to v1.0.0
# docker service ls |grep portainer-agent
p71id0brrvhn portainer-agent global 5/5 portainer/agent:1.0.0 ```
the "registry" parameter for container templates seems to have some issues, both with usage on container deployment and setting of the parameter via the new portainer template ui
the docs don\'t have a sample for "registry", but from the code it appears that "registry" should be set using the hostname of the alternate registry like "docker.ourdomain.com" rather than the vanity name of the registry setup in portainer
when doing this via template.json for initial load like: ```
"image": "docker/ourimage:latest", "registry": "docker.ourdomain.com",
with a registry configured in portainer (with auth) for docker.ourdomain.com, then trying to deploy a container based on that template, portainer replies: `failure no such image: docker.ourdomain.com/docker/ourimage:latest` however, that image **can be pulled** using "docker/ourimage:latest" and the registry from the pulldown in the portainer image ui
also, if you go into edit the template via the new portainer template ui, the "registry" parameter doesn\'t seem to be picked up properly (always shows default dockerhub), and any attempt to select another from the list and save it doesn\'t seem to change things
returning to edit, the registry is still shown as the default dockerhub.
the "network" template parameter for container templates doesn\'t seem to get handled properly by the new portainer template ui
using a customer template.json for initial load, the "network" parameter seems to get set properly (i.e
deploying a container off the template shows proper network config), however when going into "update" the template via the new ui, the "network" parameter isn\'t set (shows "select a network") and any attempt to select and save results in `invalid request payload` with the portainer log giving: `http error: invalid request payload (err=json: cannot unmarshal object into go struct field templateupdatepayload.network of type string) (code=400)` the object posted to /api/templates/{id} does include the network parameter, so it seems to be an issue with the api endpoint handling that data.(?)
if i run a container which has volumes defined in its image and i don't specific bind or mount all the volumes, the unnamed volumes will be added with ownership public
with the new browse feature this becomes a security risk.
git authentication not works in portainer 1.19.1
using the `--no-auth` flag during start-up does not seem to work correctly anymore
going to the url brings me to `<url>/#/auth` with blank username/password fields
clicking `login` generates this message in the log: `http error: cannot authenticate user
portainer was started with the --no-auth flag (err=authentication is disabled) (code=503)`
network list in portainer display is not correct
services task list in portainer display is not correct ![image](
![image](
when using the recreate function, it sometimes does not always completely remove the previous containers endpoint so the new container is stuck in the ' created ' status **expected behaviour**
when using the recreate function it should remove the previous container and its dependencies before creating the new container so the old end point doesn't remain.
creating a stack on a docker environment (not swarm) using a docker-compose.yml that contains an external network returns the following error: ```
deployment error
json: cannot unmarshal array into go value of type types.networkresource
without the `external` parameter there is no error
error message may also look like:
deployment error
network declared as external, but could not be found.
after a while (more than 2000 lines can't tell when) having container running and watching the logs it jumps around showing the latest line than jumps back to way way back old lines, than to old lines than again back to latest lines and so on..
i couldn't figure out how many lines it exactly starts jumping around
- can not access container console from portainer web interface
however, running "docker exec ..." in the physical host works
the error is "no such exec" as similar to the one reported in issue #1671
- google chrome is showing me the following errors:
websocket connection to 'wss://xxxxxxx:9000/api/websocket/exec?id=27ed1cd0f73c uiojesimv4cci6mtuzmduymtk5m30.inwnapnz7ppkezilimqvobgzs5kwtdoohw2rlmp_7wu' failed: error in connection establishment: net::err_cert_authority_invalid
app.c628b0f2.js:3
post 404 ()
- portainer is not behind a proxy.
- portainer is installed in a single docker host
- using self sign certificates
- following advise from @deviantony tried to deployed a plain http instance
the problem does not appear up to now.
when i create a stack via the ui, the stack is created and indicated as total control.
when access the detail page, the stack indicate no container available.
in the same time i can see a second stack created and indicated as limited control, the second stack contains the container that should be associated to the first stack.
i remove one stopped container from the container list in swarm mode.but i recieve an error
"no such container: 78ebbced0498fdd07925914c775a064a85571ff7d359bba4771515c542ed8457"
which expect i can remove the container sucessfully but if i click the container name enter the container detail page, i can remove the container.
i debug it , find the request head is different.
from containers list remove operation
![image](
from container detail page remove operation
![image](
i'm unable to open a console in a running windows container
the process fails with:
_failure resize could not find containerid <containerid> to resize_ happens for powerhell as well as cmd.exe
after installing portainer 1.18.1, it's not possible to create stack in a node managed by portainer but not in swarm cluster
the node is registered by tls client and server authentication
it's possible to run and manage containers in this node from portainer but not create stack.
after manually deploying roughly 40 stacks and hitting random errors about every 4-5 stacks - after 3 hours i finished adding all of my stacks
portainer is using a docker volume backed by the default volume driver / local disk
random errors "is a directory", "unable to clone repository", and odd compose file corruption issues when deploying stacks from custom templates
portainer now reports it cannot retrieve any compose files from disk
the majority of these stacks were deployed from the same custom template
any stacks that were not were manually deployed by pasting the compose from the git repo (because this seemed to reset some state in portainer and allow me to continue deploying stacks from the template again)
**adding more: so it looks like the bug is hit by deploying stacks from the same template
for some reason the name of the directory created in /data/compose appears to be the byte value of the stack id, instead of the integer.**
the "create stack" failed when trying to deploy
after deploying an arbitrary number of stacks using the same template, portainer will no longer accept new stack deploys from any template
instead it gives this error: `http error: read /data/compose/: is a directory`
i am running a docker swarm with 7 nodes 3 managers and 4 workers
i have deployed portainer via the stack file, with agents and portainer it's self
after some time an agent instance will report high cpu usage 60-70% and the portainer instance will not load any data about services, stacks etc
when i look at the log files for the agent with the high cpu i get:
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
2018/06/22 13:48:35 [err] memberlist: error accepting tcp connection: accept tcp [::]:7946: accept4: too many open files
i have deployed a stack (outside of portainer) that contains a global service which should only be deployed on manager nodes
my swarm has 3 managers and 1 worker
in `docker service ls` it's shown correctly: > management_traefik global 3/3 traefik:1.6.4-alpine however in the services list in portainer it's shown as 3/4.
we have set a swarm cluster with 4 linux managers and 4 windows nodes (2 with 1709 version and 2 with 1803)
the linux machines are running docker version 18.03.1-ce while windows 17.06.2-ee-12.
the point is, when i use the stack option of portainer to deploy a stack it works perfectly for linux containers, but when i try to create a stack deploy for a windows node i get error on mount volumes: "invalid bind mount source, must be an absolute path..."
i have uploaded a docker image to my google container registry (gcr.io); and registered in the registry using a service account using this guide to setup authentication: i can create a container utilizing my full image path: `gcr.io/<project id>/<path/to/image>:<tag>` when i click \'recreate\' on the image, i get the alert in the ui: "cannot read property url of null" my container gets deleted, but not recreated with the latest version of the image.
i have a stack deployed via portainer stacks functionality, with a local-scoped named volume for one of the defined services
when looking at the service page in portainer, the volume is not listed, instead the default 'select a volume' is selected
if i open the combo box i can see several volumes listed
i am running portainer-agent across my swarm, if that's relevant.
since i have switched to 1.17.0 i'm unable to see volumes on dashboard
i was able before
now after some loading it just shows o volume available .
i'm using rex ray plugin for persistent volumes on digital ocean, it could be slow sometime error i get in agent logs: 2018/05/23 13:46:40 http: response.write on hijacked connection
2018/05/23 15:05:45 http error: get net/http: request canceled (client.timeout exceeded while awaiting headers) (code=500)
2018/05/23 15:42:45 http error: get net/http: request canceled (client.timeout exceeded while awaiting headers) (code=500) what i got on slack support is that timeout is set to 10s and that it is hardcoded
maybe that should be increased or feature to set the value you want should be implemented.
when using the `put` endpoint `/api/endpoints/:endpointid/stacks/:stackid ` to update a stack with a new compose file
the compose file does update inside portainer - it just never updates the swarm.
when i using web console to connect to container and paste some commands in it, it got all messed up
words get mixed, words from end gets into middle and similar
at first i thought it is only presentation issue, but command is really paste in wrong way and it is not working
command example: **mandrillmailer.new(p, { template_slug: \xa1\xb -url-test , email: est@test.com , tags: [\xa1\xb -url-test ], locale: n , recipient_id: p.id, recipient_type: rovider }).send_message** when i paste it into console i get this: **mandrillmailer.new(p test@test.com xxxxxxxxxxx-url- recipient_id: p.id, recipient_).send_messageprovidertype: , enlocale: testtags: [comemail: , { template_xxxxxxxxxx-url-testslug:**
vsts git urls look like this: ```text
``` where `repo` is the name of the repository
the bug is that portainer fails to pull a valid repo with the following error message: ```text
deployment error
unexpected client error: unexpected requesting " " status code: 400
portainer in swarm mode shows all vsphere driver volumes once for each container (might be intensional ?) and as unused
i'm unable to update any stack definition in portainer on v 1.17.0 running on a docker swarm with engine v17.12
in the stack detail page, it's not possible to filter the tasks clicking on the search function.
the page doesn't filter any task after filtered some thing.
- add docker hub credentials to settings
- flipped authentication switch to on
- go to images and try to pull a private image
- fails with: > failure: pull access denied for ***/frontend, repository does not exist or may require 'docker login'
since the upgrade to version 1.17.0 portainer no longer allows console access into any containers when sitting behind a nginx reverse proxy
the web page pops up with an error in the top right reading:
no such exec
it's also worth noting that rolling back to version 1.16.5 restores console access.
can not deploy stacks due to this error message:
error during connect: get dial tcp: lookup /var/run/docker.sock: no such host
after portainer (with agent-support) runs for a while, we get instant "failure unable to create stack" errors (top right, red popup) when attempting to *update* any existing stacks
these existing stacks have not changed at all since they were last updated or deployed, and they are already running
updating the `portainer` and `portainer-agent` services and reloading my browser fixes the problem, and i am again able to update existing stacks
when viewing the network tab firefox dev tools, it shows a 500 put response to each request, and `{}` as the response payload
some recent `portainer-agent` tasks show as "failed" and "rejected" with `task: non-zero exit (137)` and `assigned node no longer meets constraints` error messages, respectively
the 4 `portainer-agent` task logs from immediately before the update (which fixed the error) are: ## 1
2018/05/07 04:15:08 [info] serf: eventmemberjoin: b196d483aa43 10.0.11.50,
2018/05/07 04:15:08 [info] serf: eventmemberjoin: bd1ce98ea57e 10.0.11.16,
2018/05/07 04:15:08 [info] serf: eventmemberjoin: 9d5a4cbb9dfb 10.0.11.47,
2018/05/07 04:15:08 [info] serf: eventmemberjoin: c50733e59df3 10.0.11.37,
2018/05/07 04:15:08 [info] serf: eventmemberjoin: 1714c4152033 10.0.11.43,
2018/05/07 04:15:08 [info] serf: eventmemberjoin: 760ab0ce8a5c 10.0.11.44,
2018/05/07 04:15:21 [info] memberlist: suspect 1714c4152033 has failed, no acks received,
2018/05/07 04:15:25 [info] memberlist: marking 1714c4152033 as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 04:15:25 [info] serf: eventmemberfailed: 1714c4152033 10.0.11.43,
2018/05/07 04:15:25 [info] memberlist: suspect 1714c4152033 has failed, no acks received,
2018/05/07 04:18:08 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:18:57 [info] serf: eventmemberjoin: 15a2ac26888e 10.0.11.53,
2018/05/07 04:19:17 [info] memberlist: suspect c50733e59df3 has failed, no acks received,
2018/05/07 04:19:21 [info] memberlist: marking c50733e59df3 as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 04:19:21 [info] serf: eventmemberfailed: c50733e59df3 10.0.11.37,
2018/05/07 04:19:21 [info] memberlist: suspect c50733e59df3 has failed, no acks received,
2018/05/07 04:19:24 [err] memberlist: push/pull with c50733e59df3 failed: dial tcp 10.0.11.37:7946: i/o timeout,
2018/05/07 04:20:18 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:22:21 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:23:01 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:24:05 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:26:15 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:30:18 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:30:51 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:32:54 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:33:09 [info] memberlist: suspect 760ab0ce8a5c has failed, no acks received,
2018/05/07 04:33:10 [info] memberlist: marking 760ab0ce8a5c as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 04:33:10 [info] serf: eventmemberfailed: 760ab0ce8a5c 10.0.11.44,
2018/05/07 04:33:14 [info] serf: eventmemberjoin: 071a0271690c 10.0.11.54,
2018/05/07 04:33:27 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:33:29 http: proxy error: dial tcp 10.0.11.44:9001: getsockopt: no route to host,
2018/05/07 04:34:00 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:34:33 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:36:06 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:37:40 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:38:13 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:39:46 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:40:19 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:41:22 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:41:55 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:42:58 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:43:31 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:44:05 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:44:38 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:45:11 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:47:14 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:48:17 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:48:50 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:49:23 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:50:26 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:50:59 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:51:33 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:52:06 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:52:39 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:54:12 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:54:45 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:55:18 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:55:51 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:56:24 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:56:58 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:58:01 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:59:04 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:00:07 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:00:40 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:02:43 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:03:16 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:03:49 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:04:23 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:04:56 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:05:29 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:06:02 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:06:35 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:07:08 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:08:11 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:09:14 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:10:17 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:10:51 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:11:24 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:11:57 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:12:30 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:13:03 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:13:36 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:14:09 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:17:42 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:18:16 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:18:49 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:20:22 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:21:25 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:21:58 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:22:31 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:23:04 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:24:07 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:25:11 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:26:14 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:26:47 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:27:50 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:28:53 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:31:26 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:32:59 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:33:32 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:35:35 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:36:39 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:37:12 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:37:45 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:39:48 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:40:21 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:41:24 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:41:57 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:42:30 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:43:04 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:44:37 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:45:10 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:45:43 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:46:46 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:47:19 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:47:52 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:49:25 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:50:29 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:52:02 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:52:35 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:53:12 [info] memberlist: suspect 9d5a4cbb9dfb has failed, no acks received,
2018/05/07 05:53:16 [info] memberlist: suspect 9d5a4cbb9dfb has failed, no acks received,
2018/05/07 05:53:16 [info] memberlist: marking 9d5a4cbb9dfb as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 05:53:16 [info] serf: eventmemberfailed: 9d5a4cbb9dfb 10.0.11.47,
2018/05/07 05:53:23 http error: get net/http: request canceled while waiting for connection (client.timeout exceeded while awaiting headers) (code=500),
2018/05/07 05:53:38 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:54:11 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 05:54:44 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 05:55:17 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:55:50 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:56:23 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:56:57 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 05:57:30 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 05:58:03 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:58:36 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:59:09 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:59:42 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:00:15 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:00:48 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:01:22 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:01:55 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:02:28 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:03:01 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:03:34 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:04:07 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:04:40 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:05:13 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:05:47 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:05:47 [info] memberlist: suspect 071a0271690c has failed, no acks received,
2018/05/07 06:05:50 [info] memberlist: suspect 071a0271690c has failed, no acks received,
2018/05/07 06:05:51 [info] memberlist: marking 071a0271690c as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 06:05:51 [info] serf: eventmemberfailed: 071a0271690c 10.0.11.54,
2018/05/07 06:05:55 [info] serf: eventmemberjoin: 7d48c02b7cde 10.0.11.55,
2018/05/07 06:06:20 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:06:53 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:07:33 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:08:06 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:08:39 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:09:12 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:09:45 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:10:18 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:10:51 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:11:25 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:11:43 http: tls handshake error from 10.0.11.22:51720: eof,
2018/05/07 06:11:43 http: tls handshake error from 10.0.11.22:51722: eof,
2018/05/07 06:11:58 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:12:31 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:12:44 http: tls handshake error from 10.0.11.22:52334: eof,
2018/05/07 06:13:04 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:13:37 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:14:10 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:14:43 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:15:16 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:15:50 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:16:23 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:16:56 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:17:29 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:18:02 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:18:35 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:19:08 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:19:41 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:20:15 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:20:48 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:21:21 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:21:54 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:22:27 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:23:00 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:23:33 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:24:06 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:24:39 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:25:13 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:25:46 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:26:19 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:26:34 http: tls handshake error from 10.0.11.22:60226: eof,
2018/05/07 06:26:52 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:27:25 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:27:58 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:28:31 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:29:04 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:29:38 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:30:11 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:30:44 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:31:03 [info] memberlist: suspect 15a2ac26888e has failed, no acks received,
2018/05/07 06:31:06 [info] serf: eventmemberfailed: 15a2ac26888e 10.0.11.53,
2018/05/07 06:31:06 [info] memberlist: suspect 15a2ac26888e has failed, no acks received,
2018/05/07 06:31:09 [info] serf: eventmemberjoin: 589ab3deeaf8 10.0.11.57,
2018/05/07 06:31:10 [info] memberlist: suspect 7d48c02b7cde has failed, no acks received,
2018/05/07 06:31:12 [info] serf: eventmemberjoin: 0184d15a9f8e 10.0.11.58,
2018/05/07 06:31:13 [info] memberlist: suspect 7d48c02b7cde has failed, no acks received,
2018/05/07 06:31:14 [info] memberlist: marking 7d48c02b7cde as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 06:31:14 [info] serf: eventmemberfailed: 7d48c02b7cde 10.0.11.55,
2018/05/07 06:31:15 [info] memberlist: suspect bd1ce98ea57e has failed, no acks received,
2018/05/07 06:31:17 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:31:17 [info] memberlist: suspect bd1ce98ea57e has failed, no acks received,
2018/05/07 06:31:18 [info] memberlist: marking bd1ce98ea57e as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 06:31:18 [info] serf: eventmemberfailed: bd1ce98ea57e 10.0.11.16,
2018/05/07 06:31:20 [info] memberlist: suspect bd1ce98ea57e has failed, no acks received,
``` ## 2 ```
2018/05/06 14:48:12 [info] serf: eventmemberjoin: bd1ce98ea57e 10.0.11.16,
2018/05/06 14:48:12 [info] serf: eventmemberjoin: ede774f01afe 10.0.11.10,
2018/05/06 14:48:12 [info] serf: eventmemberjoin: 3d63581607bb 10.0.11.12,
2018/05/06 14:48:12 [info] serf: eventmemberjoin: 1fc58f144a73 10.0.11.11,
2018/05/06 14:48:12 [info] serf: eventmemberjoin: 052fbd3ec0c7 10.0.11.9,
2018/05/06 14:48:15 [info] memberlist: suspect 052fbd3ec0c7 has failed, no acks received,
2018/05/06 14:48:17 [info] serf: eventmemberfailed: 052fbd3ec0c7 10.0.11.9,
2018/05/06 14:48:21 [info] serf: eventmemberjoin: 6169177281ec 10.0.11.17,
2018/05/06 14:48:23 [info] memberlist: suspect ede774f01afe has failed, no acks received,
2018/05/06 14:48:27 [info] memberlist: marking ede774f01afe as failed, suspect timeout reached (2 peer confirmations),
2018/05/06 14:48:27 [info] serf: eventmemberfailed: ede774f01afe 10.0.11.10,
2018/05/06 14:48:27 [info] memberlist: suspect ede774f01afe has failed, no acks received,
2018/05/06 14:48:31 [info] serf: eventmemberjoin: 3590334b4d88 10.0.11.18,
2018/05/06 14:48:35 [info] serf: eventmemberjoin: e1e7836911ab 10.0.11.19,
2018/05/06 14:48:35 [info] memberlist: suspect 1fc58f144a73 has failed, no acks received,
2018/05/06 14:48:37 [info] memberlist: marking 1fc58f144a73 as failed, suspect timeout reached (2 peer confirmations),
2018/05/06 14:48:37 [info] serf: eventmemberfailed: 1fc58f144a73 10.0.11.11,
2018/05/06 14:48:39 [info] memberlist: suspect 1fc58f144a73 has failed, no acks received,
2018/05/06 14:48:42 [info] serf: eventmemberfailed: 3d63581607bb 10.0.11.12,
2018/05/06 14:48:42 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 14:48:43 [info] memberlist: suspect 3d63581607bb has failed, no acks received,
2018/05/06 14:48:45 [info] serf: eventmemberjoin: af7851d17334 10.0.11.20,
2018/05/06 14:49:22 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 14:50:02 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 14:50:42 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 14:51:16 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 14:51:56 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 14:52:29 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 14:53:02 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 14:53:35 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 14:54:08 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 14:54:41 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 14:55:14 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 14:56:47 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 14:57:21 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 14:57:54 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 14:58:27 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 14:59:00 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:00:03 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:00:36 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:01:09 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:01:42 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:02:15 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:03:19 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:04:22 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:05:25 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:05:58 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:06:31 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:07:04 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:07:37 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:08:10 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:09:14 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:09:47 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:10:20 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:10:53 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:11:26 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:11:59 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:12:32 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:13:05 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:13:39 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:14:12 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:14:45 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:15:18 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:15:51 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:16:24 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:16:57 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:18:30 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:19:03 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:19:37 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:20:10 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:21:13 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:21:46 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:22:19 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:22:52 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:23:25 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:23:58 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:24:32 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:25:05 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:25:38 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:26:11 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:26:44 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:27:47 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:28:20 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:28:53 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:29:27 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:30:00 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:30:33 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:31:06 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:31:39 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:32:12 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:32:45 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:33:18 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:33:51 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:34:25 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:34:58 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:35:31 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:36:04 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:36:37 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:37:10 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:37:43 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:38:16 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:38:50 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:39:05 http error: get eof (code=500),
2018/05/06 15:39:05 http: proxy error: dial tcp 10.0.11.19:9001: getsockopt: connection refused,
2018/05/06 15:39:07 [info] memberlist: suspect e1e7836911ab has failed, no acks received,
2018/05/06 15:39:11 [info] memberlist: suspect e1e7836911ab has failed, no acks received,
2018/05/06 15:39:11 [info] memberlist: marking e1e7836911ab as failed, suspect timeout reached (2 peer confirmations),
2018/05/06 15:39:11 [info] serf: eventmemberfailed: e1e7836911ab 10.0.11.19,
2018/05/06 15:39:14 [info] serf: eventmemberjoin: 5ede34cc8bcf 10.0.11.23,
2018/05/06 15:39:23 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:39:55 http: proxy error: context canceled,
2018/05/06 15:39:56 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:40:29 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:41:02 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:41:35 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:42:08 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:42:41 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:43:15 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:43:48 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 15:44:21 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:44:54 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:45:27 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 15:46:00 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:46:33 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:47:06 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:47:39 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:48:13 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:48:46 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:49:19 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:49:52 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:50:25 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:50:58 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 15:51:31 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 15:52:04 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:52:38 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 15:53:11 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 15:53:44 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:54:17 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:54:50 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:55:23 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:55:56 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:56:29 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 15:57:03 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:57:36 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:58:09 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 15:58:42 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 15:59:15 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 15:59:48 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:00:21 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 16:00:54 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 16:01:27 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:02:01 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 16:02:34 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 16:03:07 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:03:28 [info] memberlist: suspect af7851d17334 has failed, no acks received,
2018/05/06 16:03:30 [info] memberlist: marking af7851d17334 as failed, suspect timeout reached (2 peer confirmations),
2018/05/06 16:03:30 [info] serf: eventmemberfailed: af7851d17334 10.0.11.20,
2018/05/06 16:03:32 [info] memberlist: suspect af7851d17334 has failed, no acks received,
2018/05/06 16:03:36 [info] serf: eventmemberjoin: 1fa66aa776f6 10.0.11.24,
2018/05/06 16:03:40 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 16:04:13 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 16:04:46 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:05:19 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:05:52 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:06:26 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:06:59 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:07:32 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 16:08:05 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:08:38 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 16:09:11 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:09:44 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:10:17 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 16:10:51 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 16:11:24 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:11:57 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:12:30 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:13:03 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:13:36 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 16:14:09 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:14:42 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:15:15 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:15:49 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:16:22 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 16:16:55 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:17:28 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:18:01 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 16:18:34 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:19:07 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:19:40 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:20:14 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:20:25 [info] memberlist: suspect 6169177281ec has failed, no acks received,
2018/05/06 16:20:29 [info] serf: eventmemberfailed: 6169177281ec 10.0.11.17,
2018/05/06 16:20:29 [info] memberlist: suspect 6169177281ec has failed, no acks received,
2018/05/06 16:20:35 [info] serf: eventmemberjoin: 9f5940239d03 10.0.11.25,
2018/05/06 16:20:47 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:21:20 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:21:53 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 16:22:26 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:22:59 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:23:32 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:24:05 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:24:39 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:25:12 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:25:37 [info] memberlist: suspect 3590334b4d88 has failed, no acks received,
2018/05/06 16:25:41 [info] memberlist: marking 3590334b4d88 as failed, suspect timeout reached (2 peer confirmations),
2018/05/06 16:25:41 [info] serf: eventmemberfailed: 3590334b4d88 10.0.11.18,
2018/05/06 16:25:41 [info] memberlist: suspect 3590334b4d88 has failed, no acks received,
2018/05/06 16:25:45 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:25:46 [info] serf: eventmemberjoin: da56ef59b628 10.0.11.26,
2018/05/06 16:26:18 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 16:26:51 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:27:24 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:27:57 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 16:28:30 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 16:29:10 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 16:29:43 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:30:17 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 16:30:50 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:31:23 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:31:32 [info] memberlist: suspect 1fa66aa776f6 has failed, no acks received,
2018/05/06 16:31:34 [info] memberlist: marking 1fa66aa776f6 as failed, suspect timeout reached (2 peer confirmations),
2018/05/06 16:31:34 [info] serf: eventmemberfailed: 1fa66aa776f6 10.0.11.24,
2018/05/06 16:31:35 [info] memberlist: suspect 1fa66aa776f6 has failed, no acks received,
2018/05/06 16:31:39 [info] serf: eventmemberjoin: e170bec61413 10.0.11.27,
2018/05/06 16:31:56 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:32:29 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:33:02 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:33:35 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 16:34:08 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:34:42 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 16:35:15 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 16:35:48 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:36:21 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:36:54 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:37:27 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 16:37:35 [info] memberlist: suspect 9f5940239d03 has failed, no acks received,
2018/05/06 16:37:37 [info] serf: eventmemberfailed: 9f5940239d03 10.0.11.25,
2018/05/06 16:37:43 [info] serf: eventmemberjoin: d89be26bab51 10.0.11.28,
2018/05/06 16:38:00 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 16:38:40 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 16:39:13 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:39:47 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:40:20 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:40:53 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:41:26 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 16:41:59 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:42:32 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 16:43:05 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 16:43:38 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:43:39 [info] memberlist: suspect e170bec61413 has failed, no acks received,
2018/05/06 16:43:43 [info] memberlist: suspect e170bec61413 has failed, no acks received,
2018/05/06 16:43:43 [info] memberlist: marking e170bec61413 as failed, suspect timeout reached (2 peer confirmations),
2018/05/06 16:43:43 [info] serf: eventmemberfailed: e170bec61413 10.0.11.27,
2018/05/06 16:43:50 [info] serf: eventmemberjoin: 5ed80232b4d9 10.0.11.29,
2018/05/06 16:44:11 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 16:44:45 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:45:18 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:45:51 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 16:46:31 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 16:47:04 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 16:47:37 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 16:48:10 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:48:43 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 16:49:16 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:49:50 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:49:54 [info] memberlist: suspect da56ef59b628 has failed, no acks received,
2018/05/06 16:49:57 [info] serf: eventmemberfailed: da56ef59b628 10.0.11.26,
2018/05/06 16:49:58 [info] memberlist: suspect da56ef59b628 has failed, no acks received,
2018/05/06 16:50:02 [info] serf: eventmemberjoin: 93c9c6334af5 10.0.11.30,
2018/05/06 16:50:23 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:50:56 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:51:29 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 16:52:09 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 16:52:42 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 16:53:15 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 16:53:48 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 16:54:21 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 16:54:55 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 16:55:28 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 16:56:01 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 16:56:34 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 16:57:07 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 16:57:40 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 16:58:13 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 16:58:46 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 16:59:19 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 16:59:53 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 17:00:26 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:00:59 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 17:01:32 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 17:02:05 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:02:38 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 17:03:11 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:03:44 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 17:04:18 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 17:04:27 [info] memberlist: suspect d89be26bab51 has failed, no acks received,
2018/05/06 17:04:31 [info] memberlist: suspect d89be26bab51 has failed, no acks received,
2018/05/06 17:04:31 [info] memberlist: marking d89be26bab51 as failed, suspect timeout reached (2 peer confirmations),
2018/05/06 17:04:31 [info] serf: eventmemberfailed: d89be26bab51 10.0.11.28,
2018/05/06 17:04:37 [info] serf: eventmemberjoin: d77bcb15854f 10.0.11.31,
2018/05/06 17:04:51 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 17:05:24 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:05:57 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 17:06:30 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 17:07:03 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 17:07:36 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 17:08:09 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 17:08:43 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 17:09:16 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:09:49 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 17:10:29 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 17:11:02 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:11:35 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 17:12:08 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 17:12:41 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 17:13:14 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 17:13:47 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 17:14:21 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 17:14:54 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 17:15:27 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 17:16:00 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:16:33 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 17:17:06 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:17:30 [info] memberlist: suspect 93c9c6334af5 has failed, no acks received,
2018/05/06 17:17:33 [info] memberlist: marking 93c9c6334af5 as failed, suspect timeout reached (2 peer confirmations),
2018/05/06 17:17:33 [info] serf: eventmemberfailed: 93c9c6334af5 10.0.11.30,
2018/05/06 17:17:39 [info] serf: eventmemberjoin: ae7c26b2e33f 10.0.11.32,
2018/05/06 17:17:39 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 17:18:19 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:18:52 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 17:19:26 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 17:19:59 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 17:20:32 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 17:21:05 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 17:21:38 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:22:11 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 17:22:44 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 17:23:17 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:23:51 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 17:24:24 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:24:57 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 17:25:30 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 17:26:03 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 17:26:36 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 17:27:09 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 17:27:42 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:28:15 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 17:28:49 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 17:29:22 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:29:55 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 17:30:28 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:31:01 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 17:31:34 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 17:32:07 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 17:32:40 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 17:33:14 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 17:33:47 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 17:34:20 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 17:34:53 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 17:35:26 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 17:35:59 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 17:36:32 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:37:05 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 17:37:39 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 17:38:12 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 17:38:45 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 17:39:25 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 17:39:58 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:40:31 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:41:04 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:41:37 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 17:42:10 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 17:42:43 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 17:43:17 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 17:43:50 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 17:44:23 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 17:44:56 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 17:45:29 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 17:46:02 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:46:35 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 17:47:08 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:47:42 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:48:15 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 17:48:48 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:49:21 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 17:49:54 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 17:50:27 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 17:51:00 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:51:33 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 17:52:07 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 17:52:40 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 17:53:13 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 17:53:46 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 17:54:19 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 17:54:52 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 17:55:25 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 17:55:58 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 17:56:31 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 17:57:05 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 17:57:38 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 17:58:11 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 17:58:44 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 17:59:17 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 17:59:50 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 18:00:23 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 18:00:56 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 18:01:30 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 18:02:03 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 18:02:36 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 18:03:09 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 18:03:42 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 18:04:15 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 18:04:48 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 18:05:21 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 18:05:55 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 18:06:28 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 18:07:01 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 18:07:34 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 18:08:07 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 18:08:40 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 18:09:13 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 18:09:46 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 18:10:19 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 18:10:53 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 18:11:26 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 18:11:59 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 18:12:12 [info] serf: eventmemberfailed: ae7c26b2e33f 10.0.11.32,
2018/05/06 18:12:12 [info] memberlist: suspect ae7c26b2e33f has failed, no acks received,
2018/05/06 18:12:17 [info] serf: eventmemberjoin: e047520362fd 10.0.11.33,
2018/05/06 18:12:32 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 18:13:05 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 18:13:38 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 18:14:11 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 18:14:44 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 18:15:18 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 18:15:51 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 18:16:24 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 18:16:57 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 18:17:30 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 18:18:03 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 18:18:36 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 18:19:09 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 18:19:43 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 18:20:16 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 18:20:49 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 18:21:29 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 18:22:02 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 18:22:35 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 18:23:08 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 18:23:39 [info] memberlist: suspect 5ede34cc8bcf has failed, no acks received,
2018/05/06 18:23:41 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 18:23:43 [info] memberlist: suspect 5ede34cc8bcf has failed, no acks received,
2018/05/06 18:23:43 [info] memberlist: marking 5ede34cc8bcf as failed, suspect timeout reached (2 peer confirmations),
2018/05/06 18:23:43 [info] serf: eventmemberfailed: 5ede34cc8bcf 10.0.11.23,
2018/05/06 18:23:46 [info] serf: eventmemberjoin: 08089a56a4f1 10.0.11.34,
2018/05/06 18:24:14 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 18:24:47 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 18:25:21 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 18:25:54 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 18:26:27 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 18:27:00 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 18:27:33 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 18:28:06 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 18:28:39 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 18:29:12 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 18:29:46 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 18:30:19 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 18:30:52 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 18:31:25 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 18:32:05 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 18:32:38 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 18:33:11 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 18:33:44 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 18:34:17 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 18:34:51 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 18:35:24 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 18:35:57 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 18:36:30 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 18:37:03 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 18:37:36 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 18:38:09 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 18:38:42 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 18:39:15 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 18:39:49 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 18:40:22 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 18:41:02 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 18:41:35 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 18:42:08 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 18:42:41 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 18:43:14 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 18:43:47 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 18:44:20 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 18:44:54 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 18:45:27 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 18:46:00 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 18:46:33 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 18:47:06 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 18:47:39 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 18:48:12 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 18:48:45 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 18:49:19 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 18:49:52 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 18:50:25 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 18:50:58 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 18:51:31 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 18:52:04 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 18:52:37 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 18:53:10 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 18:53:43 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 18:54:17 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 18:54:50 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 18:55:23 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 18:55:56 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 18:56:29 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 18:57:02 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 18:57:35 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 18:58:08 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 18:58:42 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 18:59:15 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 18:59:48 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 19:00:21 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 19:00:54 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 19:01:27 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 19:02:00 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 19:02:33 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 19:03:07 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 19:03:40 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 19:04:13 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 19:04:46 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 19:05:19 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 19:05:52 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 19:06:25 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 19:06:58 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 19:07:31 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 19:08:05 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 19:08:38 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 19:09:11 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 19:09:44 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 19:10:17 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 19:10:50 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 19:11:23 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 19:11:56 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 19:12:30 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 19:13:03 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 19:13:36 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 19:14:09 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 19:14:42 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 19:15:15 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 19:15:48 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 19:16:21 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 19:16:55 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 19:17:28 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 19:18:01 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 19:18:34 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 19:19:07 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 19:19:40 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 19:20:13 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 19:20:46 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 19:21:19 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 19:21:53 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 19:22:26 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 19:22:59 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 19:23:32 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 19:24:05 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 19:24:38 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 19:25:11 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 19:25:44 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 19:26:18 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 19:26:51 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 19:27:24 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 19:27:57 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 19:28:30 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 19:29:03 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 19:29:36 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 19:30:09 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 19:30:43 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 19:31:16 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 19:31:49 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 19:32:22 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 19:32:55 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 19:33:28 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 19:34:01 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 19:34:34 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 19:35:07 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 19:35:41 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 19:36:14 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 19:36:47 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 19:37:20 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 19:37:53 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 19:38:26 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 19:38:59 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 19:39:32 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 19:40:06 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 19:40:39 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 19:41:12 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 19:41:45 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 19:42:18 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 19:42:51 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 19:43:24 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 19:43:57 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 19:44:31 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 19:45:04 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 19:45:37 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 19:46:10 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 19:46:43 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 19:47:16 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 19:47:49 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 19:48:22 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 19:48:55 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 19:49:29 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 19:50:02 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 19:50:35 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 19:51:08 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 19:51:41 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 19:52:14 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 19:52:47 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 19:53:20 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 19:53:54 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 19:54:27 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 19:55:00 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 19:55:33 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 19:56:06 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 19:56:39 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 19:57:12 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 19:57:45 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 19:58:19 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 19:58:52 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 19:59:25 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 19:59:58 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 20:00:31 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 20:01:04 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 20:01:37 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 20:02:10 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 20:02:43 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 20:03:17 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 20:03:50 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 20:04:23 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 20:04:56 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 20:05:29 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 20:06:02 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 20:06:35 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 20:07:08 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 20:07:42 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 20:08:15 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 20:08:48 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 20:09:21 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 20:09:54 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 20:10:27 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 20:11:00 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 20:11:33 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 20:12:07 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 20:12:40 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 20:13:13 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 20:13:46 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 20:14:19 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 20:14:52 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 20:15:25 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 20:15:58 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 20:16:31 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 20:17:05 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 20:17:38 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 20:18:11 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 20:18:44 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 20:19:17 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 20:19:50 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 20:20:23 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 20:20:56 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 20:21:30 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 20:22:03 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 20:22:36 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 20:23:09 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 20:23:42 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 20:24:15 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 20:24:48 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 20:25:21 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 20:25:55 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 20:26:28 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 20:27:01 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 20:27:34 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 20:28:07 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 20:28:40 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 20:29:13 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 20:29:46 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 20:30:19 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 20:30:53 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 20:31:26 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 20:31:59 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 20:32:32 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 20:33:05 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 20:33:38 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 20:34:11 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 20:34:44 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 20:35:18 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 20:35:51 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 20:36:24 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 20:36:57 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 20:37:30 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 20:38:03 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 20:38:36 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 20:39:09 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 20:39:43 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 20:40:16 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 20:40:49 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 20:41:22 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 20:41:55 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 20:42:28 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 20:43:01 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 20:43:34 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 20:44:07 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 20:44:41 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 20:45:14 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 20:45:47 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 20:46:20 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 20:46:53 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 20:47:26 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 20:47:59 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 20:48:32 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 20:49:06 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 20:49:39 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 20:50:12 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 20:50:45 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 20:51:18 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 20:51:51 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 20:52:24 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 20:52:57 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 20:53:31 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 20:54:04 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 20:54:37 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 20:55:10 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 20:55:43 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 20:56:16 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 20:56:49 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 20:57:22 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 20:57:55 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 20:58:29 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 20:59:02 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 20:59:35 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 21:00:08 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 21:00:41 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 21:01:14 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 21:01:47 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 21:02:20 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 21:02:54 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 21:03:27 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 21:04:00 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 21:04:33 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 21:05:06 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 21:05:39 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 21:06:12 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 21:06:45 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 21:07:19 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 21:07:52 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 21:08:25 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 21:08:58 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 21:09:31 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 21:10:04 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 21:10:37 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 21:11:10 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 21:11:43 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 21:12:17 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 21:12:50 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 21:13:23 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 21:13:56 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 21:14:29 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 21:15:02 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 21:15:35 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 21:16:08 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 21:16:42 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 21:17:15 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 21:17:48 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 21:18:21 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 21:18:54 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 21:19:27 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 21:20:00 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 21:20:33 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 21:21:07 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 21:21:40 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 21:22:13 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 21:22:46 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 21:23:19 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 21:23:52 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 21:24:25 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 21:24:58 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 21:25:31 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 21:26:05 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 21:26:38 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 21:27:11 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 21:27:44 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 21:28:17 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 21:28:50 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 21:29:23 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 21:29:56 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 21:30:30 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 21:31:03 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 21:31:36 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 21:32:09 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 21:32:42 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 21:33:15 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 21:33:48 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 21:34:21 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 21:34:55 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 21:35:28 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 21:36:01 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 21:36:34 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 21:37:07 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 21:37:40 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 21:38:13 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 21:38:46 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 21:39:19 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 21:39:53 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 21:40:26 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 21:40:59 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 21:41:32 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 21:42:05 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 21:42:38 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 21:43:11 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 21:43:44 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 21:44:18 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 21:44:51 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 21:45:24 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 21:45:57 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 21:46:30 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 21:47:03 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 21:47:36 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 21:48:09 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 21:48:43 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 21:49:16 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 21:49:49 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 21:50:22 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 21:50:55 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 21:51:28 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 21:52:01 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 21:52:34 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 21:53:07 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 21:53:41 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 21:54:14 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 21:54:47 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 21:55:20 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 21:55:53 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 21:56:26 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 21:56:59 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 21:57:32 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 21:58:06 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 21:58:39 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 21:59:12 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 21:59:45 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 22:00:18 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 22:00:51 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 22:01:24 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 22:01:57 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 22:02:31 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 22:03:04 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 22:03:37 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 22:04:10 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 22:04:43 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 22:05:16 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 22:05:49 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 22:06:22 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 22:06:55 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 22:07:29 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 22:08:02 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 22:08:35 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 22:09:08 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 22:09:41 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 22:10:14 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 22:10:47 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 22:11:20 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 22:11:54 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 22:12:27 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 22:13:00 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 22:13:33 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 22:14:06 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 22:14:39 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 22:15:12 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 22:15:45 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 22:16:19 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 22:16:52 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 22:17:25 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 22:17:58 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 22:18:31 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 22:19:04 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 22:19:37 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 22:20:10 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 22:20:43 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 22:21:17 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 22:21:50 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 22:22:23 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 22:22:56 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 22:23:29 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 22:24:02 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 22:24:35 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 22:25:08 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 22:25:42 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 22:26:15 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 22:26:48 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 22:27:21 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 22:27:54 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 22:28:27 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 22:29:00 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 22:29:33 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 22:30:07 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 22:30:40 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 22:31:13 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 22:31:46 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 22:32:19 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 22:32:52 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 22:33:25 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 22:33:58 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 22:34:31 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 22:35:05 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 22:35:38 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 22:36:11 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 22:36:44 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 22:37:17 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 22:37:50 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 22:38:23 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 22:38:56 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 22:39:30 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 22:40:03 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 22:40:36 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 22:41:09 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 22:41:42 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 22:42:15 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 22:42:48 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 22:43:21 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 22:43:55 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 22:44:28 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 22:45:01 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 22:45:34 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 22:46:07 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 22:46:40 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 22:47:13 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 22:47:46 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 22:48:19 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 22:48:53 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 22:49:26 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 22:49:59 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 22:50:32 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 22:51:05 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 22:51:38 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 22:52:11 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 22:52:44 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 22:53:18 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 22:53:51 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 22:54:24 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 22:54:57 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 22:55:30 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 22:56:03 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 22:56:36 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 22:57:09 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 22:57:43 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 22:58:16 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 22:58:49 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 22:59:22 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 22:59:55 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 23:00:28 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 23:01:01 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 23:01:34 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 23:02:07 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 23:02:41 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 23:03:14 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 23:03:47 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 23:04:20 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 23:04:53 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 23:05:26 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 23:05:59 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 23:06:32 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 23:07:06 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 23:07:39 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 23:08:12 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 23:08:45 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 23:09:18 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 23:09:51 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 23:10:24 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 23:10:57 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 23:11:31 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/06 23:12:04 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 23:12:37 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 23:13:10 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 23:13:43 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 23:14:16 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 23:14:49 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 23:15:22 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 23:15:55 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 23:16:29 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 23:17:02 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:17:35 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 23:18:08 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 23:18:41 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 23:19:14 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:19:47 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 23:20:20 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 23:20:54 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 23:21:27 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 23:22:00 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 23:22:33 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:23:06 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 23:23:39 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 23:24:12 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 23:24:45 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 23:25:19 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 23:25:52 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 23:26:25 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 23:26:58 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 23:27:31 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:28:04 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 23:28:37 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:29:10 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 23:29:43 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 23:30:17 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 23:30:50 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 23:31:23 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 23:31:56 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 23:32:29 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 23:33:02 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 23:33:35 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 23:34:08 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 23:34:42 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 23:35:15 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 23:35:48 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/06 23:36:21 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 23:36:54 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:37:27 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/06 23:38:00 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 23:38:33 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:39:07 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 23:39:40 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 23:40:13 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 23:40:46 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 23:41:19 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 23:41:52 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:42:25 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 23:42:58 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:43:31 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 23:44:05 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 23:44:38 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 23:45:11 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 23:45:44 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/06 23:46:17 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:46:50 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/06 23:47:23 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/06 23:47:56 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/06 23:48:30 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 23:49:03 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 23:49:36 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 23:50:09 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 23:50:42 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:51:15 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 23:51:48 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/06 23:52:21 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 23:52:55 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 23:53:28 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 23:54:01 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/06 23:54:34 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:55:07 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/06 23:55:40 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:56:13 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/06 23:56:46 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/06 23:57:19 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/06 23:57:53 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/06 23:58:26 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/06 23:58:59 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/06 23:59:32 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 00:00:05 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 00:00:38 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 00:01:11 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 00:01:44 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 00:02:18 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 00:02:51 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 00:03:24 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 00:03:57 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 00:04:30 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 00:05:03 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 00:05:36 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 00:06:09 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 00:06:43 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 00:07:16 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 00:07:49 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 00:08:22 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 00:08:55 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 00:09:28 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 00:10:01 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 00:10:34 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 00:11:07 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 00:11:41 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 00:12:14 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 00:12:47 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 00:13:20 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 00:13:53 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 00:14:26 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 00:14:59 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 00:15:32 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 00:16:06 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 00:16:39 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 00:17:12 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 00:17:45 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 00:18:18 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 00:18:51 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 00:19:24 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 00:19:57 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 00:20:31 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 00:21:04 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 00:21:37 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 00:22:10 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 00:22:43 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 00:23:16 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 00:23:49 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 00:24:22 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 00:24:55 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 00:25:29 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 00:26:02 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 00:26:35 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 00:27:08 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 00:27:41 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 00:28:14 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 00:28:47 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 00:29:20 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 00:29:54 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 00:30:27 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 00:31:00 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 00:31:33 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 00:32:06 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 00:32:39 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 00:33:12 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 00:33:45 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 00:34:19 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 00:34:52 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 00:35:25 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 00:35:58 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 00:36:31 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 00:37:04 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 00:37:37 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 00:38:10 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 00:38:43 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 00:39:17 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 00:39:50 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 00:40:23 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 00:40:56 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 00:41:29 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 00:42:02 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 00:42:35 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 00:43:08 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 00:43:42 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 00:44:15 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 00:44:48 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 00:45:21 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 00:45:54 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 00:46:27 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 00:47:00 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 00:47:33 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 00:48:07 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 00:48:40 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 00:49:13 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 00:49:46 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 00:50:19 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 00:50:52 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 00:51:25 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 00:51:58 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 00:52:31 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 00:53:05 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 00:53:38 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 00:54:11 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 00:54:44 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 00:55:17 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 00:55:50 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 00:56:23 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 00:56:56 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 00:57:30 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 00:58:03 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 00:58:36 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 00:59:09 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 00:59:42 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 01:00:15 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 01:00:48 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 01:01:21 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 01:01:55 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 01:02:28 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 01:03:01 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 01:03:34 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 01:04:07 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 01:04:40 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 01:05:13 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 01:05:46 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 01:06:19 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 01:06:53 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 01:07:26 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 01:07:59 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 01:08:32 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 01:09:05 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 01:09:38 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 01:10:11 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 01:10:44 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 01:11:18 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 01:11:51 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 01:12:24 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 01:12:57 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 01:13:30 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 01:14:03 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 01:14:36 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 01:15:09 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 01:15:43 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 01:16:16 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 01:16:49 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 01:17:22 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 01:17:55 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 01:18:28 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 01:19:01 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 01:19:34 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 01:20:07 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 01:20:41 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 01:21:14 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 01:21:47 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 01:22:20 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 01:22:53 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 01:23:26 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 01:23:59 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 01:24:32 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 01:25:06 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 01:25:39 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 01:26:12 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 01:26:45 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 01:27:18 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 01:27:51 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 01:28:24 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 01:28:57 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 01:29:31 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 01:30:04 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 01:30:37 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 01:31:10 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 01:31:43 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 01:32:16 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 01:32:49 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 01:33:22 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 01:33:55 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 01:34:29 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 01:35:02 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 01:35:35 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 01:36:08 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 01:36:41 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 01:37:14 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 01:37:47 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 01:38:20 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 01:38:54 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 01:39:27 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 01:40:00 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 01:40:33 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 01:41:06 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 01:41:39 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 01:42:12 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 01:42:45 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 01:43:19 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 01:43:52 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 01:44:25 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 01:44:58 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 01:45:31 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 01:46:04 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 01:46:37 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 01:47:10 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 01:47:43 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 01:48:17 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 01:48:50 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 01:49:23 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 01:49:56 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 01:50:29 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 01:51:02 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 01:51:35 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 01:52:08 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 01:52:42 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 01:53:15 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 01:53:48 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 01:54:21 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 01:54:54 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 01:55:27 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 01:56:00 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 01:56:33 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 01:57:07 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 01:57:40 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 01:58:13 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 01:58:46 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 01:59:19 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 01:59:52 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 02:00:25 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 02:00:58 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 02:01:31 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 02:02:05 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 02:02:38 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 02:03:11 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 02:03:44 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 02:04:17 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 02:04:50 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 02:05:23 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 02:05:56 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 02:06:30 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 02:07:03 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 02:07:36 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 02:08:09 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 02:08:42 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 02:09:15 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 02:09:48 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 02:10:21 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 02:10:55 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 02:11:28 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 02:12:01 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 02:12:34 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 02:13:07 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 02:13:40 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 02:14:13 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 02:14:46 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 02:15:19 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 02:15:53 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 02:16:26 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 02:16:59 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 02:17:32 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 02:18:05 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 02:18:38 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 02:19:11 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 02:19:44 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 02:20:18 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 02:20:51 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 02:21:24 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 02:21:57 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 02:22:30 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 02:23:03 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 02:23:36 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 02:24:09 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 02:24:43 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 02:25:16 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 02:25:49 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 02:26:22 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 02:26:55 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 02:27:28 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 02:28:01 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 02:28:34 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 02:29:07 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 02:29:41 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 02:30:14 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 02:30:47 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 02:31:20 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 02:31:53 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 02:32:26 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 02:32:59 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 02:33:32 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 02:34:06 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 02:34:39 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 02:35:12 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 02:35:45 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 02:36:18 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 02:36:51 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 02:37:24 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 02:37:57 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 02:38:31 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 02:39:04 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 02:39:37 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 02:40:10 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 02:40:43 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 02:41:16 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 02:41:49 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 02:42:22 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 02:42:55 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 02:43:29 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 02:44:02 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 02:44:35 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 02:45:08 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 02:45:41 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 02:46:14 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 02:46:47 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 02:47:20 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 02:47:54 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 02:48:27 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 02:49:00 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 02:49:33 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 02:50:06 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 02:50:39 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 02:51:12 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 02:51:45 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 02:52:19 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 02:52:52 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 02:53:25 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 02:53:58 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 02:54:31 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 02:55:04 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 02:55:37 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 02:56:10 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 02:56:43 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 02:57:17 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 02:57:50 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 02:58:23 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 02:58:56 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 02:59:29 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 03:00:02 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 03:00:35 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 03:01:08 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 03:01:42 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 03:02:15 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 03:02:48 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 03:03:21 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 03:03:54 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 03:04:27 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 03:05:00 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 03:05:33 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 03:06:07 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 03:06:40 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 03:07:13 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 03:07:46 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 03:08:19 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 03:08:52 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 03:09:25 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 03:09:58 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 03:10:31 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 03:11:05 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 03:11:38 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 03:12:11 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 03:12:44 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 03:13:17 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 03:13:50 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 03:14:23 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 03:14:56 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 03:15:30 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 03:16:03 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 03:16:36 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 03:17:09 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 03:17:42 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 03:18:15 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 03:18:48 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 03:19:21 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 03:19:55 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 03:20:28 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 03:21:01 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 03:21:34 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 03:22:07 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 03:22:40 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 03:23:13 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 03:23:46 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 03:24:19 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 03:24:53 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 03:25:26 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 03:25:59 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 03:26:32 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 03:27:05 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 03:27:38 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 03:28:11 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 03:28:44 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 03:29:18 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 03:29:51 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 03:30:24 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 03:30:57 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 03:31:30 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 03:32:03 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 03:32:36 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 03:33:09 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 03:33:43 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 03:34:16 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 03:34:49 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 03:35:22 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 03:35:55 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 03:36:28 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 03:37:01 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 03:37:34 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 03:38:07 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 03:38:16 [info] memberlist: suspect 5ed80232b4d9 has failed, no acks received,
2018/05/07 03:38:17 [info] memberlist: marking 5ed80232b4d9 as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 03:38:17 [info] serf: eventmemberfailed: 5ed80232b4d9 10.0.11.29,
2018/05/07 03:38:20 [info] memberlist: suspect 5ed80232b4d9 has failed, no acks received,
2018/05/07 03:38:41 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 03:39:14 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 03:39:47 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 03:40:20 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 03:40:53 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 03:41:15 [info] memberlist: suspect d77bcb15854f has failed, no acks received,
2018/05/07 03:41:18 [info] memberlist: suspect d77bcb15854f has failed, no acks received,
2018/05/07 03:41:19 [info] serf: eventmemberfailed: d77bcb15854f 10.0.11.31,
2018/05/07 03:41:26 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 03:41:28 [info] serf: eventmemberjoin: c50733e59df3 10.0.11.37,
2018/05/07 03:41:59 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 03:42:32 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 03:43:06 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 03:43:39 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 03:44:12 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 03:44:45 [info] serf: eventmemberjoin: f7fbe0967ef0 10.0.11.40,
2018/05/07 03:44:45 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 03:45:10 [info] memberlist: suspect e047520362fd has failed, no acks received,
2018/05/07 03:45:13 [info] serf: eventmemberfailed: e047520362fd 10.0.11.33,
2018/05/07 03:45:18 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 03:45:51 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 03:46:24 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 03:46:57 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 03:47:31 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 03:48:11 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 03:48:44 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 03:49:06 [info] serf: eventmemberjoin: 1714c4152033 10.0.11.43,
2018/05/07 03:49:17 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 03:49:50 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 03:50:23 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 03:50:56 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 03:51:29 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 03:52:02 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 03:52:35 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 03:53:15 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 03:53:49 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 03:54:22 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 03:54:55 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 03:55:28 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 03:56:01 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 03:56:34 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 03:57:07 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 03:57:40 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 03:58:14 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 03:58:47 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 03:59:20 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 03:59:53 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 04:00:26 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 04:00:59 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 04:01:32 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 04:02:05 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 04:02:39 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 04:03:12 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 04:03:45 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 04:04:18 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 04:04:51 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 04:05:24 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 04:05:57 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 04:06:30 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 04:07:03 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 04:07:37 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 04:08:10 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 04:08:43 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 04:09:16 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 04:09:49 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 04:10:22 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 04:10:44 [info] memberlist: suspect 08089a56a4f1 has failed, no acks received,
2018/05/07 04:10:46 [info] serf: eventmemberfailed: 08089a56a4f1 10.0.11.34,
2018/05/07 04:10:48 http error: unable to find an agent on any manager node (code=500),
2018/05/07 04:10:48 http error: unable to find an agent on any manager node (code=500),
2018/05/07 04:10:50 [info] serf: eventmemberjoin: 760ab0ce8a5c 10.0.11.44,
2018/05/07 04:10:55 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 04:11:28 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 04:12:02 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 04:12:35 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 04:12:58 [info] serf: eventmemberjoin: 9d5a4cbb9dfb 10.0.11.47,
2018/05/07 04:13:08 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 04:13:09 [info] memberlist: suspect f7fbe0967ef0 has failed, no acks received,
2018/05/07 04:13:13 [info] memberlist: marking f7fbe0967ef0 as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 04:13:13 [info] serf: eventmemberfailed: f7fbe0967ef0 10.0.11.40,
2018/05/07 04:13:14 [info] memberlist: suspect f7fbe0967ef0 has failed, no acks received,
2018/05/07 04:13:41 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 04:14:14 [info] serf: attempting reconnect to 08089a56a4f1 10.0.11.34:7946,
2018/05/07 04:14:54 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 04:15:09 [info] serf: eventmemberjoin: b196d483aa43 10.0.11.50,
2018/05/07 04:15:21 [info] memberlist: suspect 1714c4152033 has failed, no acks received,
2018/05/07 04:15:25 [info] memberlist: marking 1714c4152033 as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 04:15:25 [info] serf: eventmemberfailed: 1714c4152033 10.0.11.43,
2018/05/07 04:15:26 [info] memberlist: suspect 1714c4152033 has failed, no acks received,
2018/05/07 04:15:27 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 04:16:00 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 04:16:33 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 04:17:07 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 04:17:40 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 04:18:13 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 04:18:46 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 04:18:57 [info] serf: eventmemberjoin: 15a2ac26888e 10.0.11.53,
2018/05/07 04:19:16 [info] memberlist: suspect c50733e59df3 has failed, no acks received,
2018/05/07 04:19:19 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:19:20 [info] memberlist: marking c50733e59df3 as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 04:19:20 [info] serf: eventmemberfailed: c50733e59df3 10.0.11.37,
2018/05/07 04:19:21 [info] memberlist: suspect c50733e59df3 has failed, no acks received,
2018/05/07 04:19:52 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 04:20:25 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 04:20:58 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 04:21:31 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 04:22:05 [info] serf: attempting reconnect to f7fbe0967ef0 10.0.11.40:7946,
2018/05/07 04:22:45 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 04:23:18 [info] serf: attempting reconnect to 08089a56a4f1 10.0.11.34:7946,
2018/05/07 04:23:51 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:24:24 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 04:24:57 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 04:25:30 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 04:26:03 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 04:26:36 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 04:27:10 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 04:27:43 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 04:28:16 [info] serf: attempting reconnect to f7fbe0967ef0 10.0.11.40:7946,
2018/05/07 04:28:49 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 04:29:22 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 04:29:55 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 04:30:28 [info] serf: attempting reconnect to f7fbe0967ef0 10.0.11.40:7946,
2018/05/07 04:31:01 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 04:31:35 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 04:32:08 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 04:32:41 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 04:33:06 [info] memberlist: suspect 760ab0ce8a5c has failed, no acks received,
2018/05/07 04:33:10 [info] serf: eventmemberfailed: 760ab0ce8a5c 10.0.11.44,
2018/05/07 04:33:14 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 04:33:14 [info] serf: eventmemberjoin: 071a0271690c 10.0.11.54,
2018/05/07 04:33:47 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 04:34:20 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 04:34:53 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 04:35:26 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:35:59 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 04:36:33 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 04:37:06 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 04:37:39 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 04:38:12 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 04:38:45 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 04:39:18 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 04:39:51 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 04:40:24 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 04:40:58 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 04:41:31 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 04:42:04 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 04:42:37 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:43:17 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 04:43:50 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 04:44:23 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 04:44:56 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 04:45:29 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:46:03 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 04:46:36 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 04:47:09 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 04:47:42 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:48:15 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 04:48:48 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 04:49:21 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 04:49:54 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 04:50:27 [info] serf: attempting reconnect to 08089a56a4f1 10.0.11.34:7946,
2018/05/07 04:51:01 [info] serf: attempting reconnect to f7fbe0967ef0 10.0.11.40:7946,
2018/05/07 04:51:34 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 04:52:07 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 04:52:40 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 04:53:13 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:53:46 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 04:54:19 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 04:54:52 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 04:55:26 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 04:55:59 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 04:56:32 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 04:57:05 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 04:57:38 [info] serf: attempting reconnect to 08089a56a4f1 10.0.11.34:7946,
2018/05/07 04:58:11 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 04:58:44 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 04:59:17 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 04:59:51 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 05:00:24 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 05:00:57 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 05:01:30 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 05:02:03 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 05:02:36 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 05:03:09 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:03:42 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 05:04:15 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 05:04:49 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 05:05:22 [info] serf: attempting reconnect to 08089a56a4f1 10.0.11.34:7946,
2018/05/07 05:05:55 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 05:06:28 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 05:07:01 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 05:07:34 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 05:08:07 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 05:08:40 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 05:09:14 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 05:09:47 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 05:10:20 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 05:10:53 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 05:11:26 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 05:11:59 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 05:12:32 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:13:05 [info] serf: attempting reconnect to 08089a56a4f1 10.0.11.34:7946,
2018/05/07 05:13:39 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 05:14:12 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 05:14:45 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 05:15:18 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 05:15:51 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 05:16:24 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 05:16:57 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 05:17:30 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:18:03 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 05:18:37 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 05:19:10 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 05:19:43 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 05:20:16 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 05:20:49 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 05:21:22 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 05:21:55 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 05:22:28 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 05:23:02 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 05:23:35 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:24:08 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 05:24:41 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:25:14 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 05:25:47 [info] serf: attempting reconnect to f7fbe0967ef0 10.0.11.40:7946,
2018/05/07 05:26:20 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 05:26:53 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 05:27:27 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 05:28:00 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 05:28:33 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 05:29:06 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 05:29:39 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 05:30:12 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 05:30:45 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 05:31:18 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 05:31:51 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:32:25 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 05:32:58 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 05:33:31 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 05:34:04 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 05:34:37 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 05:35:10 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 05:35:43 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 05:36:16 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 05:36:50 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 05:37:23 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:37:56 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 05:38:29 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 05:39:02 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 05:39:35 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:40:08 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 05:40:41 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 05:41:15 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 05:41:48 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 05:42:21 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 05:42:54 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:43:27 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 05:44:00 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 05:44:33 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 05:45:06 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:45:39 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 05:46:13 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 05:46:46 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 05:47:19 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:47:52 [info] serf: attempting reconnect to 08089a56a4f1 10.0.11.34:7946,
2018/05/07 05:48:25 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 05:48:58 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 05:49:31 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 05:50:04 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 05:50:38 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 05:51:11 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 05:51:44 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 05:52:17 [info] serf: attempting reconnect to f7fbe0967ef0 10.0.11.40:7946,
2018/05/07 05:52:50 [info] serf: attempting reconnect to f7fbe0967ef0 10.0.11.40:7946,
2018/05/07 05:53:13 [info] memberlist: suspect 9d5a4cbb9dfb has failed, no acks received,
2018/05/07 05:53:17 [info] memberlist: marking 9d5a4cbb9dfb as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 05:53:17 [info] serf: eventmemberfailed: 9d5a4cbb9dfb 10.0.11.47,
2018/05/07 05:53:23 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 05:53:23 http error: get net/http: request canceled while waiting for connection (client.timeout exceeded while awaiting headers) (code=500),
2018/05/07 05:53:56 [info] serf: attempting reconnect to 08089a56a4f1 10.0.11.34:7946,
2018/05/07 05:54:29 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 05:54:39 http: tls handshake error from 10.0.11.22:59634: eof,
2018/05/07 05:55:03 [info] serf: attempting reconnect to 1fc58f144a73 10.0.11.11:7946,
2018/05/07 05:55:36 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 05:56:09 [info] serf: attempting reconnect to f7fbe0967ef0 10.0.11.40:7946,
2018/05/07 05:56:42 [info] serf: attempting reconnect to f7fbe0967ef0 10.0.11.40:7946,
2018/05/07 05:57:15 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 05:57:48 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 05:58:21 [info] serf: attempting reconnect to f7fbe0967ef0 10.0.11.40:7946,
2018/05/07 05:58:54 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:59:27 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 06:00:01 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 06:00:34 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:01:07 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 06:01:40 [info] serf: attempting reconnect to 08089a56a4f1 10.0.11.34:7946,
2018/05/07 06:02:13 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 06:02:46 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 06:03:19 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:03:52 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 06:04:26 [info] serf: attempting reconnect to 93c9c6334af5 10.0.11.30:7946,
2018/05/07 06:04:59 [info] serf: attempting reconnect to 9f5940239d03 10.0.11.25:7946,
2018/05/07 06:05:32 [info] serf: attempting reconnect to 6169177281ec 10.0.11.17:7946,
2018/05/07 06:05:51 [info] memberlist: suspect 071a0271690c has failed, no acks received,
2018/05/07 06:05:51 [info] memberlist: marking 071a0271690c as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 06:05:51 [info] serf: eventmemberfailed: 071a0271690c 10.0.11.54,
2018/05/07 06:05:55 [info] serf: eventmemberjoin: 7d48c02b7cde 10.0.11.55,
2018/05/07 06:06:05 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:06:45 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:07:25 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 06:07:58 [info] serf: attempting reconnect to 052fbd3ec0c7 10.0.11.9:7946,
2018/05/07 06:08:31 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 06:09:04 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 06:09:37 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 06:10:11 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 06:10:44 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 06:11:17 [info] serf: attempting reconnect to 08089a56a4f1 10.0.11.34:7946,
2018/05/07 06:11:50 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 06:12:23 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 06:12:56 [info] serf: attempting reconnect to 3590334b4d88 10.0.11.18:7946,
2018/05/07 06:13:29 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 06:14:02 [info] serf: attempting reconnect to 08089a56a4f1 10.0.11.34:7946,
2018/05/07 06:14:35 [info] serf: attempting reconnect to ede774f01afe 10.0.11.10:7946,
2018/05/07 06:15:09 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:15:42 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 06:16:15 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 06:16:48 [info] serf: attempting reconnect to d77bcb15854f 10.0.11.31:7946,
2018/05/07 06:17:21 [info] serf: attempting reconnect to ae7c26b2e33f 10.0.11.32:7946,
2018/05/07 06:17:54 [info] serf: attempting reconnect to f7fbe0967ef0 10.0.11.40:7946,
2018/05/07 06:18:27 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:19:00 [info] serf: attempting reconnect to da56ef59b628 10.0.11.26:7946,
2018/05/07 06:19:34 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 06:20:07 [info] serf: attempting reconnect to 5ede34cc8bcf 10.0.11.23:7946,
2018/05/07 06:20:40 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 06:21:13 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:21:53 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 06:22:26 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:22:59 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:23:32 [info] serf: attempting reconnect to 3d63581607bb 10.0.11.12:7946,
2018/05/07 06:24:05 [info] serf: attempting reconnect to e047520362fd 10.0.11.33:7946,
2018/05/07 06:24:39 [info] serf: attempting reconnect to f7fbe0967ef0 10.0.11.40:7946,
2018/05/07 06:25:12 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 06:25:45 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 06:26:18 [info] serf: attempting reconnect to 5ed80232b4d9 10.0.11.29:7946,
2018/05/07 06:26:34 http: tls handshake error from 10.0.11.22:49372: eof,
2018/05/07 06:26:51 [info] serf: attempting reconnect to 1714c4152033 10.0.11.43:7946,
2018/05/07 06:27:24 [info] serf: attempting reconnect to 1fa66aa776f6 10.0.11.24:7946,
2018/05/07 06:27:57 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 06:28:30 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:28:59 http: tls handshake error from 10.0.11.22:50774: eof,
2018/05/07 06:29:03 [info] serf: attempting reconnect to e170bec61413 10.0.11.27:7946,
2018/05/07 06:29:37 [info] serf: attempting reconnect to af7851d17334 10.0.11.20:7946,
2018/05/07 06:30:10 [info] serf: attempting reconnect to e1e7836911ab 10.0.11.19:7946,
2018/05/07 06:30:43 [info] serf: attempting reconnect to d89be26bab51 10.0.11.28:7946,
2018/05/07 06:31:02 [info] memberlist: suspect 15a2ac26888e has failed, no acks received,
2018/05/07 06:31:06 [info] serf: eventmemberfailed: 15a2ac26888e 10.0.11.53,
2018/05/07 06:31:06 [info] memberlist: suspect 15a2ac26888e has failed, no acks received,
2018/05/07 06:31:09 [info] serf: eventmemberjoin: 589ab3deeaf8 10.0.11.57,
2018/05/07 06:31:10 [info] memberlist: suspect 7d48c02b7cde has failed, no acks received,
``` ## 3 ```
2018/05/07 06:05:55 [info] serf: eventmemberjoin: 7d48c02b7cde 10.0.11.55,
2018/05/07 06:05:55 [info] serf: eventmemberjoin: bd1ce98ea57e 10.0.11.16,
2018/05/07 06:05:55 [info] serf: eventmemberjoin: 15a2ac26888e 10.0.11.53,
2018/05/07 06:05:55 [info] serf: eventmemberjoin: b196d483aa43 10.0.11.50,
2018/05/07 06:31:02 [info] memberlist: suspect 15a2ac26888e has failed, no acks received,
2018/05/07 06:31:05 [info] memberlist: suspect 15a2ac26888e has failed, no acks received,
2018/05/07 06:31:06 [info] memberlist: marking 15a2ac26888e as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 06:31:06 [info] serf: eventmemberfailed: 15a2ac26888e 10.0.11.53,
``` ## 4 ```
2018/05/07 04:18:57 [info] serf: eventmemberjoin: 15a2ac26888e 10.0.11.53,
2018/05/07 04:18:57 [info] serf: eventmemberjoin: 760ab0ce8a5c 10.0.11.44,
2018/05/07 04:18:57 [info] serf: eventmemberjoin: bd1ce98ea57e 10.0.11.16,
2018/05/07 04:18:57 [info] serf: eventmemberjoin: b196d483aa43 10.0.11.50,
2018/05/07 04:18:57 [info] serf: eventmemberjoin: 9d5a4cbb9dfb 10.0.11.47,
2018/05/07 04:18:57 [info] serf: eventmemberjoin: c50733e59df3 10.0.11.37,
2018/05/07 04:19:19 [info] memberlist: suspect c50733e59df3 has failed, no acks received,
2018/05/07 04:19:21 [info] serf: eventmemberfailed: c50733e59df3 10.0.11.37,
2018/05/07 04:20:57 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:21:31 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:24:04 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:27:07 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:30:10 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:33:09 [info] memberlist: suspect 760ab0ce8a5c has failed, no acks received,
2018/05/07 04:33:10 [info] memberlist: marking 760ab0ce8a5c as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 04:33:10 [info] serf: eventmemberfailed: 760ab0ce8a5c 10.0.11.44,
2018/05/07 04:33:14 [info] serf: eventmemberjoin: 071a0271690c 10.0.11.54,
2018/05/07 04:34:00 http: proxy error: context canceled,
2018/05/07 04:34:43 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:36:16 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:37:19 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:38:52 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:41:26 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:43:59 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:45:32 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:46:05 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:47:08 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:49:11 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:49:44 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:50:17 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:51:20 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:53:24 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:53:57 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 04:56:30 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 04:59:33 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:00:06 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:03:09 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:04:42 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:05:15 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:06:19 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:06:52 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:07:55 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:09:58 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:12:31 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:13:04 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:15:37 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:17:10 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:21:14 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:22:47 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:23:20 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:23:53 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:26:56 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:27:59 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:30:32 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:31:35 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:32:08 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:33:12 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:33:45 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:34:18 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:34:51 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:37:54 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:40:27 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:41:00 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:43:03 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:45:07 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:45:40 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:46:13 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:47:16 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:49:19 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:51:22 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:51:55 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:52:58 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:53:16 [info] memberlist: suspect 9d5a4cbb9dfb has failed, no acks received,
2018/05/07 05:53:16 [info] memberlist: marking 9d5a4cbb9dfb as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 05:53:16 [info] serf: eventmemberfailed: 9d5a4cbb9dfb 10.0.11.47,
2018/05/07 05:53:32 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:55:05 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:55:38 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:56:11 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:56:44 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 05:57:17 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 05:57:57 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:58:30 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:59:03 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 05:59:36 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:00:10 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:01:13 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:01:46 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:02:19 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:04:22 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:05:50 [info] memberlist: suspect 071a0271690c has failed, no acks received,
2018/05/07 06:05:51 [info] memberlist: marking 071a0271690c as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 06:05:51 [info] serf: eventmemberfailed: 071a0271690c 10.0.11.54,
2018/05/07 06:05:55 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:05:55 [info] serf: eventmemberjoin: 7d48c02b7cde 10.0.11.55,
2018/05/07 06:06:28 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:07:01 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:07:35 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:08:08 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:08:41 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:09:14 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:09:47 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:10:20 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:10:53 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:11:26 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:12:00 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:12:33 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:13:06 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:13:07 http: tls handshake error from 10.0.11.22:46722: eof,
2018/05/07 06:13:39 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:14:12 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:14:45 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:15:18 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:15:29 http: tls handshake error from 10.0.11.22:48106: eof,
2018/05/07 06:15:51 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:16:24 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:16:58 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:17:31 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:18:04 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:18:37 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:19:10 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:19:43 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:20:16 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:20:49 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:21:23 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:21:56 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:22:29 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:23:02 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:23:35 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:24:08 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:24:41 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:25:14 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:25:48 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:26:21 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:26:54 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:27:27 [info] serf: attempting reconnect to 071a0271690c 10.0.11.54:7946,
2018/05/07 06:28:00 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:28:33 [info] serf: attempting reconnect to 760ab0ce8a5c 10.0.11.44:7946,
2018/05/07 06:29:06 [info] serf: attempting reconnect to 9d5a4cbb9dfb 10.0.11.47:7946,
2018/05/07 06:29:39 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:30:12 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
2018/05/07 06:30:46 [info] serf: attempting reconnect to c50733e59df3 10.0.11.37:7946,
``` the `portainer` task log from immediately before the shutdown is: ```
2018/05/06 15:02:53 instance already has defined endpoints
skipping the endpoint defined via cli.,
2018/05/06 15:02:53 starting portainer 1.16.5 on :9000,
2018/05/06 15:09:21 http: proxy error: docker network identifier not found,
2018/05/06 15:09:25 http: proxy error: docker network identifier not found,
2018/05/06 15:39:05 http: panic serving 10.0.5.13:53492: interface conversion: interface {} is map[string]interface {}, not []interface {},
goroutine 1431 [running]:,
net/http.(*conn).serve.func1( ), /usr/local/go/src/net/http/server.go:1697 + ,
panic( , ), /usr/local/go/src/runtime/panic.go:491 + ,
github.com/portainer/portainer/http/proxy.getresponseasjsonarray( , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/response.go:42 + ,
github.com/portainer/portainer/http/proxy.containerlistoperation( , , , ), /go/src/github.com/portainer/portainer/http/proxy/containers.go:23 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).executerequestandrewriteresponse( , , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:407 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).rewriteoperationwithlabelfiltering( , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:374 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).proxycontainerrequest( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:131 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).proxydockerrequest( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:80 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).roundtrip( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:55 + ,
net/http/httputil.(*reverseproxy).servehttp( , , , ), /usr/local/go/src/net/http/httputil/reverseproxy.go:201 + ,
net/http.stripprefix.func1( , , ), /usr/local/go/src/net/http/server.go:1957 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/handler.(*dockerhandler).proxyrequeststodockerapi( , , , ), /go/src/github.com/portainer/portainer/http/handler/docker.go:91 + ,
github.com/portainer/portainer/http/handler.(*dockerhandler).(github.com/portainer/portainer/http/handler.proxyrequeststodockerapi)-fm( , , ), /go/src/github.com/portainer/portainer/http/handler/docker.go:35 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/security.(*requestbouncer).mwcheckauthentication.func1( , , ), /go/src/github.com/portainer/portainer/http/security/bouncer.go:157 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/security.mwsecureheaders.func1( , , ), /go/src/github.com/portainer/portainer/http/security/bouncer.go:78 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/gorilla/mux.(*router).servehttp( , , , ), /go/src/github.com/gorilla/mux/mux.go:162 + ,
net/http.stripprefix.func1( , , ), /usr/local/go/src/net/http/server.go:1957 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/handler.(*handler).servehttp( , , , ), /go/src/github.com/portainer/portainer/http/handler/handler.go:60 + ,
net/http.serverhandler.servehttp( , , , ), /usr/local/go/src/net/http/server.go:2619 + ,
net/http.(*conn).serve( , , ), /usr/local/go/src/net/http/server.go:1801 + ,
created by net/http.(*server).serve, /usr/local/go/src/net/http/server.go:2720 + ,
2018/05/06 15:39:05 http: proxy error: unexpected end of json input,
2018/05/06 15:39:15 http: panic serving 10.0.5.13:53488: interface conversion: interface {} is map[string]interface {}, not []interface {},
goroutine 1427 [running]:,
net/http.(*conn).serve.func1( ), /usr/local/go/src/net/http/server.go:1697 + ,
panic( , ), /usr/local/go/src/runtime/panic.go:491 + ,
github.com/portainer/portainer/http/proxy.getresponseasjsonarray( , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/response.go:42 + ,
github.com/portainer/portainer/http/proxy.containerlistoperation( , , , ), /go/src/github.com/portainer/portainer/http/proxy/containers.go:23 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).executerequestandrewriteresponse( , , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:407 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).rewriteoperationwithlabelfiltering( , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:374 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).proxycontainerrequest( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:131 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).proxydockerrequest( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:80 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).roundtrip( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:55 + ,
net/http/httputil.(*reverseproxy).servehttp( , , , ), /usr/local/go/src/net/http/httputil/reverseproxy.go:201 + ,
net/http.stripprefix.func1( , , ), /usr/local/go/src/net/http/server.go:1957 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/handler.(*dockerhandler).proxyrequeststodockerapi( , , , ), /go/src/github.com/portainer/portainer/http/handler/docker.go:91 + ,
github.com/portainer/portainer/http/handler.(*dockerhandler).(github.com/portainer/portainer/http/handler.proxyrequeststodockerapi)-fm( , , ), /go/src/github.com/portainer/portainer/http/handler/docker.go:35 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/security.(*requestbouncer).mwcheckauthentication.func1( , , ), /go/src/github.com/portainer/portainer/http/security/bouncer.go:157 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/security.mwsecureheaders.func1( , , ), /go/src/github.com/portainer/portainer/http/security/bouncer.go:78 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/gorilla/mux.(*router).servehttp( , , , ), /go/src/github.com/gorilla/mux/mux.go:162 + ,
net/http.stripprefix.func1( , , ), /usr/local/go/src/net/http/server.go:1957 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/handler.(*handler).servehttp( , , , ), /go/src/github.com/portainer/portainer/http/handler/handler.go:60 + ,
net/http.serverhandler.servehttp( , , , ), /usr/local/go/src/net/http/server.go:2619 + ,
net/http.(*conn).serve( , , ), /usr/local/go/src/net/http/server.go:1801 + ,
created by net/http.(*server).serve, /usr/local/go/src/net/http/server.go:2720 + ,
2018/05/06 15:39:21 http: panic serving 10.0.5.13:54228: interface conversion: interface {} is map[string]interface {}, not []interface {},
goroutine 1799 [running]:,
net/http.(*conn).serve.func1( ), /usr/local/go/src/net/http/server.go:1697 + ,
panic( , ), /usr/local/go/src/runtime/panic.go:491 + ,
github.com/portainer/portainer/http/proxy.getresponseasjsonarray( , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/response.go:42 + ,
github.com/portainer/portainer/http/proxy.containerlistoperation( , , , ), /go/src/github.com/portainer/portainer/http/proxy/containers.go:23 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).executerequestandrewriteresponse( , , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:407 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).rewriteoperationwithlabelfiltering( , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:374 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).proxycontainerrequest( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:131 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).proxydockerrequest( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:80 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).roundtrip( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:55 + ,
net/http/httputil.(*reverseproxy).servehttp( , , , ), /usr/local/go/src/net/http/httputil/reverseproxy.go:201 + ,
net/http.stripprefix.func1( , , ), /usr/local/go/src/net/http/server.go:1957 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/handler.(*dockerhandler).proxyrequeststodockerapi( , , , ), /go/src/github.com/portainer/portainer/http/handler/docker.go:91 + ,
github.com/portainer/portainer/http/handler.(*dockerhandler).(github.com/portainer/portainer/http/handler.proxyrequeststodockerapi)-fm( , , ), /go/src/github.com/portainer/portainer/http/handler/docker.go:35 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/security.(*requestbouncer).mwcheckauthentication.func1( , , ), /go/src/github.com/portainer/portainer/http/security/bouncer.go:157 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/security.mwsecureheaders.func1( , , ), /go/src/github.com/portainer/portainer/http/security/bouncer.go:78 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/gorilla/mux.(*router).servehttp( , , , ), /go/src/github.com/gorilla/mux/mux.go:162 + ,
net/http.stripprefix.func1( , , ), /usr/local/go/src/net/http/server.go:1957 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/handler.(*handler).servehttp( , , , ), /go/src/github.com/portainer/portainer/http/handler/handler.go:60 + ,
net/http.serverhandler.servehttp( , , , ), /usr/local/go/src/net/http/server.go:2619 + ,
net/http.(*conn).serve( , , ), /usr/local/go/src/net/http/server.go:1801 + ,
created by net/http.(*server).serve, /usr/local/go/src/net/http/server.go:2720 + ,
2018/05/06 15:39:46 http: proxy error: unexpected end of json input,
2018/05/06 15:39:46 http: proxy error: unexpected end of json input,
2018/05/06 15:39:55 http: proxy error: context canceled,
2018/05/06 15:39:56 http: proxy error: context canceled,
2018/05/06 15:39:58 http: proxy error: context canceled,
2018/05/06 15:39:58 http: proxy error: context canceled,
2018/05/06 15:40:00 http: proxy error: context canceled,
2018/05/06 18:24:27 http: proxy error: context canceled,
2018/05/06 18:24:30 http: proxy error: context canceled,
2018/05/06 18:24:30 http: proxy error: context canceled,
2018/05/06 18:24:31 http: proxy error: context canceled,
2018/05/07 00:23:31 http: proxy error: docker container identifier not found,
2018/05/07 04:10:48 http: panic serving 10.0.5.13:52306: interface conversion: interface {} is map[string]interface {}, not []interface {},
routine 27120 [running]:,
net/http.(*conn).serve.func1( ), /usr/local/go/src/net/http/server.go:1697 + ,
panic( , ), /usr/local/go/src/runtime/panic.go:491 + ,
github.com/portainer/portainer/http/proxy.getresponseasjsonarray( , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/response.go:42 + ,
github.com/portainer/portainer/http/proxy.tasklistoperation( , , , ), /go/src/github.com/portainer/portainer/http/proxy/tasks.go:23 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).executerequestandrewriteresponse( , , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:407 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).rewriteoperation( , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:389 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).proxytaskrequest( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:261 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).proxydockerrequest( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:94 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).roundtrip( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:55 + ,
net/http/httputil.(*reverseproxy).servehttp( , , , ), /usr/local/go/src/net/http/httputil/reverseproxy.go:201 + ,
net/http.stripprefix.func1( , , ), /usr/local/go/src/net/http/server.go:1957 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/handler.(*dockerhandler).proxyrequeststodockerapi( , , , ), /go/src/github.com/portainer/portainer/http/handler/docker.go:91 + ,
github.com/portainer/portainer/http/handler.(*dockerhandler).(github.com/portainer/portainer/http/handler.proxyrequeststodockerapi)-fm( , , ), /go/src/github.com/portainer/portainer/http/handler/docker.go:35 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/security.(*requestbouncer).mwcheckauthentication.func1( , , ), /go/src/github.com/portainer/portainer/http/security/bouncer.go:157 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/security.mwsecureheaders.func1( , , ), /go/src/github.com/portainer/portainer/http/security/bouncer.go:78 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/gorilla/mux.(*router).servehttp( , , , ), /go/src/github.com/gorilla/mux/mux.go:162 + ,
net/http.stripprefix.func1( , , ), /usr/local/go/src/net/http/server.go:1957 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/handler.(*handler).servehttp( , , , ), /go/src/github.com/portainer/portainer/http/handler/handler.go:60 + ,
net/http.serverhandler.servehttp( , , , ), /usr/local/go/src/net/http/server.go:2619 + ,
net/http.(*conn).serve( , , ), /usr/local/go/src/net/http/server.go:1801 + ,
created by net/http.(*server).serve, /usr/local/go/src/net/http/server.go:2720 + ,
2018/05/07 04:10:48 http: panic serving 10.0.5.13:52308: interface conversion: interface {} is map[string]interface {}, not []interface {},
routine 27128 [running]:,
net/http.(*conn).serve.func1( ), /usr/local/go/src/net/http/server.go:1697 + ,
panic( , ), /usr/local/go/src/runtime/panic.go:491 + ,
github.com/portainer/portainer/http/proxy.getresponseasjsonarray( , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/response.go:42 + ,
github.com/portainer/portainer/http/proxy.servicelistoperation( , , , ), /go/src/github.com/portainer/portainer/http/proxy/services.go:22 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).executerequestandrewriteresponse( , , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:407 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).rewriteoperation( , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:389 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).proxyservicerequest( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:159 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).proxydockerrequest( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:82 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).roundtrip( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:55 + ,
net/http/httputil.(*reverseproxy).servehttp( , , , ), /usr/local/go/src/net/http/httputil/reverseproxy.go:201 + ,
net/http.stripprefix.func1( , , ), /usr/local/go/src/net/http/server.go:1957 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/handler.(*dockerhandler).proxyrequeststodockerapi( , , , ), /go/src/github.com/portainer/portainer/http/handler/docker.go:91 + ,
github.com/portainer/portainer/http/handler.(*dockerhandler).(github.com/portainer/portainer/http/handler.proxyrequeststodockerapi)-fm( , , ), /go/src/github.com/portainer/portainer/http/handler/docker.go:35 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/security.(*requestbouncer).mwcheckauthentication.func1( , , ), /go/src/github.com/portainer/portainer/http/security/bouncer.go:157 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/security.mwsecureheaders.func1( , , ), /go/src/github.com/portainer/portainer/http/security/bouncer.go:78 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/gorilla/mux.(*router).servehttp( , , , ), /go/src/github.com/gorilla/mux/mux.go:162 + ,
net/http.stripprefix.func1( , , ), /usr/local/go/src/net/http/server.go:1957 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/handler.(*handler).servehttp( , , , ), /go/src/github.com/portainer/portainer/http/handler/handler.go:60 + ,
net/http.serverhandler.servehttp( , , , ), /usr/local/go/src/net/http/server.go:2619 + ,
net/http.(*conn).serve( , , ), /usr/local/go/src/net/http/server.go:1801 + ,
created by net/http.(*server).serve, /usr/local/go/src/net/http/server.go:2720 + ,
2018/05/07 04:11:33 http: proxy error: context canceled,
2018/05/07 04:11:33 http: proxy error: context canceled,
2018/05/07 04:11:33 http: proxy error: context canceled,
2018/05/07 04:33:29 http: proxy error: unexpected end of json input,
2018/05/07 04:34:00 http: proxy error: context canceled,
2018/05/07 04:34:00 http: proxy error: context canceled,
2018/05/07 05:51:28 http error: (code=500),
2018/05/07 05:53:23 http: panic serving 10.0.5.13:51272: interface conversion: interface {} is map[string]interface {}, not []interface {},
routine 30067 [running]:,
net/http.(*conn).serve.func1( ), /usr/local/go/src/net/http/server.go:1697 + ,
panic( , ), /usr/local/go/src/runtime/panic.go:491 + ,
github.com/portainer/portainer/http/proxy.getresponseasjsonarray( , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/response.go:42 + ,
github.com/portainer/portainer/http/proxy.containerlistoperation( , , , ), /go/src/github.com/portainer/portainer/http/proxy/containers.go:23 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).executerequestandrewriteresponse( , , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:407 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).rewriteoperationwithlabelfiltering( , , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:374 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).proxycontainerrequest( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:131 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).proxydockerrequest( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:80 + ,
github.com/portainer/portainer/http/proxy.(*proxytransport).roundtrip( , , , , ), /go/src/github.com/portainer/portainer/http/proxy/transport.go:55 + ,
net/http/httputil.(*reverseproxy).servehttp( , , , ), /usr/local/go/src/net/http/httputil/reverseproxy.go:201 + ,
net/http.stripprefix.func1( , , ), /usr/local/go/src/net/http/server.go:1957 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/handler.(*dockerhandler).proxyrequeststodockerapi( , , , ), /go/src/github.com/portainer/portainer/http/handler/docker.go:91 + ,
github.com/portainer/portainer/http/handler.(*dockerhandler).(github.com/portainer/portainer/http/handler.proxyrequeststodockerapi)-fm( , , ), /go/src/github.com/portainer/portainer/http/handler/docker.go:35 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/security.(*requestbouncer).mwcheckauthentication.func1( , , ), /go/src/github.com/portainer/portainer/http/security/bouncer.go:157 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/security.mwsecureheaders.func1( , , ), /go/src/github.com/portainer/portainer/http/security/bouncer.go:78 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/gorilla/mux.(*router).servehttp( , , , ), /go/src/github.com/gorilla/mux/mux.go:162 + ,
net/http.stripprefix.func1( , , ), /usr/local/go/src/net/http/server.go:1957 + ,
net/http.handlerfunc.servehttp( , , , ), /usr/local/go/src/net/http/server.go:1918 + ,
github.com/portainer/portainer/http/handler.(*handler).servehttp( , , , ), /go/src/github.com/portainer/portainer/http/handler/handler.go:60 + ,
net/http.serverhandler.servehttp( , , , ), /usr/local/go/src/net/http/server.go:2619 + ,
net/http.(*conn).serve( , , ), /usr/local/go/src/net/http/server.go:1801 + ,
created by net/http.(*server).serve, /usr/local/go/src/net/http/server.go:2720 + ,
2018/05/07 05:56:24 http error: (code=500),
2018/05/07 05:57:07 http error: (code=500),
2018/05/07 06:12:22 http error: (code=500),
2018/05/07 06:20:25 http error: (code=500),
2018/05/07 06:20:33 http error: (code=500),
2018/05/07 06:20:47 http error: (code=500),
2018/05/07 06:20:49 http error: (code=500),
2018/05/07 06:20:50 http error: (code=500),
2018/05/07 06:20:51 http error: (code=500),
2018/05/07 06:20:52 http error: (code=500),
2018/05/07 06:20:53 http error: (code=500),
2018/05/07 06:20:54 http error: (code=500),
2018/05/07 06:20:55 http error: (code=500),
2018/05/07 06:22:57 http error: (code=500),
2018/05/07 06:24:41 http error: (code=500),
2018/05/07 06:25:05 http error: (code=500),
2018/05/07 06:25:41 http error: (code=500),
2018/05/07 06:29:07 http error: (code=500),
``` since the restart, still running `portainer-agent` task logs are: ## 1 ```
2018/05/07 06:31:29 [info] serf: eventmemberjoin: 8816f6a5cc2f 10.0.11.60,
2018/05/07 06:31:29 [info] serf: eventmemberjoin: 66781a799178 10.0.11.59,
2018/05/07 06:31:29 [info] serf: eventmemberjoin: 0184d15a9f8e 10.0.11.58,
2018/05/07 06:31:29 [info] serf: eventmemberjoin: 589ab3deeaf8 10.0.11.57,
2018/05/07 06:55:54 http: tls handshake error from 10.0.11.56:41550: eof,
``` ## 2 ```
2018/05/07 06:31:21 [info] serf: eventmemberjoin: 66781a799178 10.0.11.59,
2018/05/07 06:31:21 [info] serf: eventmemberjoin: b196d483aa43 10.0.11.50,
2018/05/07 06:31:21 [info] serf: eventmemberjoin: 0184d15a9f8e 10.0.11.58,
2018/05/07 06:31:21 [info] serf: eventmemberjoin: 589ab3deeaf8 10.0.11.57,
2018/05/07 06:31:25 [info] memberlist: suspect b196d483aa43 has failed, no acks received,
2018/05/07 06:31:27 [info] serf: eventmemberfailed: b196d483aa43 10.0.11.50,
2018/05/07 06:31:28 [info] memberlist: suspect b196d483aa43 has failed, no acks received,
2018/05/07 06:31:29 [info] serf: eventmemberjoin: 8816f6a5cc2f 10.0.11.60,
2018/05/07 06:32:21 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:33:01 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:36:04 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:36:38 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:37:41 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:39:14 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:43:47 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:44:20 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:46:53 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:55:26 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
``` ## 3 ```
2018/05/07 06:31:12 [info] serf: eventmemberjoin: 0184d15a9f8e 10.0.11.58,
2018/05/07 06:31:12 [info] serf: eventmemberjoin: 589ab3deeaf8 10.0.11.57,
2018/05/07 06:31:12 [info] serf: eventmemberjoin: bd1ce98ea57e 10.0.11.16,
2018/05/07 06:31:12 [info] serf: eventmemberjoin: b196d483aa43 10.0.11.50,
2018/05/07 06:31:14 [info] memberlist: suspect bd1ce98ea57e has failed, no acks received,
2018/05/07 06:31:18 [info] memberlist: suspect bd1ce98ea57e has failed, no acks received,
2018/05/07 06:31:18 [info] memberlist: marking bd1ce98ea57e as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 06:31:18 [info] serf: eventmemberfailed: bd1ce98ea57e 10.0.11.16,
2018/05/07 06:31:21 [info] serf: eventmemberjoin: 66781a799178 10.0.11.59,
2018/05/07 06:31:23 [info] memberlist: suspect b196d483aa43 has failed, no acks received,
2018/05/07 06:31:26 [info] memberlist: suspect b196d483aa43 has failed, no acks received,
2018/05/07 06:31:27 [info] memberlist: marking b196d483aa43 as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 06:31:27 [info] serf: eventmemberfailed: b196d483aa43 10.0.11.50,
2018/05/07 06:31:29 [info] serf: eventmemberjoin: 8816f6a5cc2f 10.0.11.60,
2018/05/07 06:32:12 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:32:46 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:33:19 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:34:22 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:34:55 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:35:28 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:36:01 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:37:24 http: tls handshake error from 10.0.11.56:42910: eof,
2018/05/07 06:37:34 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:38:37 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:39:11 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:40:44 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:41:17 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:41:50 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:42:23 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:43:26 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:43:59 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:45:02 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:50:36 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:51:39 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:54:42 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:55:15 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:57:18 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
``` ## 4 ```
2018/05/07 06:31:09 [info] serf: eventmemberjoin: 589ab3deeaf8 10.0.11.57,
2018/05/07 06:31:09 [info] serf: eventmemberjoin: b196d483aa43 10.0.11.50,
2018/05/07 06:31:09 [info] serf: eventmemberjoin: 7d48c02b7cde 10.0.11.55,
2018/05/07 06:31:09 [info] serf: eventmemberjoin: bd1ce98ea57e 10.0.11.16,
2018/05/07 06:31:11 [info] memberlist: suspect 7d48c02b7cde has failed, no acks received,
2018/05/07 06:31:12 [info] serf: eventmemberjoin: 0184d15a9f8e 10.0.11.58,
2018/05/07 06:31:14 [info] memberlist: suspect 7d48c02b7cde has failed, no acks received,
2018/05/07 06:31:14 [info] memberlist: marking 7d48c02b7cde as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 06:31:14 [info] serf: eventmemberfailed: 7d48c02b7cde 10.0.11.55,
2018/05/07 06:31:18 [info] memberlist: suspect bd1ce98ea57e has failed, no acks received,
2018/05/07 06:31:19 [info] memberlist: marking bd1ce98ea57e as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 06:31:19 [info] serf: eventmemberfailed: bd1ce98ea57e 10.0.11.16,
2018/05/07 06:31:21 [info] serf: eventmemberjoin: 66781a799178 10.0.11.59,
2018/05/07 06:31:24 [info] memberlist: suspect b196d483aa43 has failed, no acks received,
2018/05/07 06:31:27 [info] memberlist: marking b196d483aa43 as failed, suspect timeout reached (2 peer confirmations),
2018/05/07 06:31:27 [info] serf: eventmemberfailed: b196d483aa43 10.0.11.50,
2018/05/07 06:31:28 [info] memberlist: suspect b196d483aa43 has failed, no acks received,
2018/05/07 06:31:29 [info] serf: eventmemberjoin: 8816f6a5cc2f 10.0.11.60,
2018/05/07 06:31:39 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:32:19 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:32:59 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:33:39 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:34:42 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:35:15 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:35:48 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:36:21 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:36:54 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:37:27 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:38:01 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:38:34 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:39:07 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:39:40 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:40:13 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:40:46 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:41:19 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:41:52 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:42:26 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:42:59 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:44:02 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:44:35 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:45:08 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:45:41 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:46:14 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:47:17 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:47:50 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:48:54 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:49:27 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:50:00 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:50:33 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:51:06 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:51:39 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:52:12 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:52:45 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:53:49 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
2018/05/07 06:54:45 http: tls handshake error from 10.0.11.56:55460: eof,
2018/05/07 06:54:52 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:55:25 [info] serf: attempting reconnect to b196d483aa43 10.0.11.50:7946,
2018/05/07 06:55:58 [info] serf: attempting reconnect to 7d48c02b7cde 10.0.11.55:7946,
2018/05/07 06:56:31 [info] serf: attempting reconnect to bd1ce98ea57e 10.0.11.16:7946,
and the log from still running `portainer` task after the shutdown: ```
2018/05/07 06:31:02 instance already has defined endpoints
skipping the endpoint defined via cli.,
2018/05/07 06:31:02 starting portainer 1.16.5 on :9000,
``` this is a 3 worker, 1 manager cluster provisioned by docker for aws 18.03.0-ce, letting them create the vpc which i believe allows "all traffic" between all nodes and managers within the cluster by default.
sometimes (not always) the containers page has duplicate entries for many containers
not every container is duplicated
if i reload the page several times, the problem occurs for some page reloads only
the links are also identical *except* for `?nodename=...` in the querystring
so portainer thinks the same container (with the same task-id/slot) has been deployed to multiple nodes in the swarm
when i click on one, i get the expected container detail page
when i click on another (with a different `?nodename=...` in the querystring, i get an error about being unable to retrieve the container.
the ui allows me to add multiple host file entries under the advanced network setup but when i save and provision the container is only saves and applies the first host file entry and all other entries are lost.
elect nd <> and <>
ercentile
install tdengine-server-2.0.6.0-linux-x64.deb to debian failed.
i'm running the installation in a container based on debian
and no /usr/lib64 dir in my container, only /usr/lib exist
need to get 0 b/2303 kb of archives.
after this operation, 68.3 mb of additional disk space will be used.
get:1 /root/sky-eye/tdengine-server-2.0.6.0-linux-x64.deb tdengine amd64 2.0.6.0 [2303 kb]
debconf: delaying package configuration, since apt-utils is not installed
selecting previously unselected package tdengine.
(reading database ..
16330 files and directories currently installed.)
preparing to unpack .../tdengine-server-2.0.6.0-linux-x64.deb ...
unpacking tdengine (2.0.6.0) ...
setting up tdengine (2.0.6.0) ...
start to install tdengine...
ln: failed to create symbolic link '/usr/lib64/libtaos.so.1': no such file or directory
ln: failed to create symbolic link '/usr/lib64/libtaos.so': no such file or directory
cp: cannot stat '%{init_d_dir}/taosd': no such file or directory
update-rc.d: error: unable to read /etc/init.d/taosd
xample pringjdbctemplate
**jdbctemplate.execute("use metric_data");** **org.springframework.jdbc.uncategorizedsqlexception: statementcallback; uncategorized sqlexception for sql [use metric_data]; sql state [null]; error code [0]; this operation is not supported currently!; nested exception is java.sql.sqlexception: this operation is not supported currently!** yml
tdengine: datasource: #tdengine driverclassname: com.taosdata.jdbc.tsdbdriver jdbcurl: jdbc:taos://192.168.155.46:6030/ username: root password: taosdata druid: initialsize: 5 minidle: 5 maxactive: 5 # max wait time for get connection, ms maxwait: 60000 validationquery: select server_status(); validationquerytimeout: 5000 testonborrow: false testonreturn: false testwhileidle: true timebetweenevictionrunsmillis: 60000 minevictableidletimemillis: 600000 maxevictableidletimemillis: 900000 datasourceconfig @primary @bean(name = "basedatasource") @configurationproperties(prefix="spring.datasource") public datasource basedatasource() { return datasourcebuilder.create().build(); } @bean(name = "tdenginedatasource") @configurationproperties(prefix="tdengine.datasource") public datasource tdenginedatasource() { return datasourcebuilder.create().build(); } dao: jdbctemplate jdbctemplate = new jdbctemplate(tdenginedatasource);//tdengine
jdbctemplate.execute("use metric_data");
docker 11/03 02:49:48.773068 utl error invalid locale:en_us.utf-8, please set the valid locale in config file
11/03 02:49:48.773408 utl timezone is set to asia/shanghai by config file
11/03 02:49:48.773491 utl timezone format changed to (asia, +0000)
11/03 02:50:20.603024 dnd , msg:heartbeat will be processed in mread queue
11/03 02:50:20.972614 dnd msg:status will be processed in mpeer queue
11/03 02:50:21.392700 dnd , msg:heartbeat will be processed in mread queue
11/03 02:50:21.977584 dnd msg:status will be processed in mpeer queue
11/03 02:50:22.107463 dnd , msg:heartbeat will be processed in mread queue
docker top aos connect failed, reason: unable to establish connection.
: zure buntu dengine v2.0.6
in10 pringbootdemo, pring.datasource.url=jdbc:taos://node1:6030/log
ao.exe -h p ing
![image]( qdn springboot :unable to resolve fqdn
![image](
.0.4/2.0.6/2.0.8,
![image](
i found call "select * from super table" sql statement will crash the taosd.
estful
1 _1 -2 _1,a_2
3 _1 -2 _1,a_2 aos ql
aosd pu 00+%
00ms/ **environment **
os: centos 7.8
memory 16g, cpu 6 core , current disk space: 1t
tdengine version 2.5.0.1
taos-jdbcdriver version: 2.0.8
ava aosd
# a fatal error has been detected by the java runtime environment:
# sigsegv ( ) at pc= , pid=3634, tid=
# jre version: java(tm) se runtime environment (8.0_231-b11) (build 1.8.0_231-b11)
# java vm: java hotspot(tm) 64-bit server vm (25.231-b11 mixed mode linux-amd64 compressed oops)
# problematic frame:
# c [libtaos.so.2.0.5.1+ ] taosallocateid+
# failed to write core dump
core dumps have been disabled
to enable core dumping, try "ulimit -c unlimited" before starting java again
# an error report file with more information is saved as:
# /home/dell/spei/code/hs_err_pid3634.log
# if you would like to submit a bug report, please visit:
#
``` **environment ** - os: centos 7.8 - memory, cpu, current disk space - tdengine version 2.5.0.1 - taos-jdbcdriver version: 2.0.8
r
cmakelists.txt under src/sync tries to remove src/tarbitrator.c from src when building libsync.a because src/tarbitrator.c includes a main() function which pollutes the library
` list(remove_item src ./src/tarbitrator.c)
` unfortunately, the path "./src/tarbitrator.c" doesn\'t work
it should be "src/tarbitrator.c" ithout "./").
case 1: ows 2 escribe : {"status":"succ","head":["field","type","length","note"],"data":[["ts","timestamp",8,""],["table_name","binary",128,""],["symbol","binary",64,""],["partition_tag","int",4,""],["user_id","bigint",8,""]],"rows":12} case 2: ow elect
{"status":"succ","head":["ts","table_name","symbol","partition_tag","user_id"],"data":[],"rows":5} ase
elect * from table limit 0,10; // ata size ows
escribe table; ase 1
elect * from table limit 10,10; ase 2 bug **environment:** - os: ubuntu 18.04.1 lts - tdengine version 2.0.5.1
exception in thread "[threadpoolexecutor]dc3-thread-700" org.springframework.jdbc.uncategorizedsqlexception: error updating database
cause: java.sql.sqlexception: tdengine error: last session not finished
the error may exist in file [d:\\fanwu-datamonitor\\dc3-center\\dc3-manager\\target\\classes\\mapper\\tdenginemapper.xml]
the error may involve defaultparametermap
the error occurred while setting parameters
sql: import into db000117vo using voltages tags (beijing.daxing0117,did100117,mid200117,uid300115) (ts,voltagea,voltageb,voltagec) values (?,?, ?,?)
cause: java.sql.sqlexception: tdengine error: last session not finished
; uncategorized sqlexception; sql state []; error code [-2147483641]; tdengine error: last session not finished; nested exception is java.sql.sqlexception: tdengine error: last session not finished at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:89) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) at org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) at org.mybatis.spring.mybatisexceptiontranslator.translateexceptionifpossible(mybatisexceptiontranslator.java:88) at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:440) at com.sun.proxy.$proxy153.insert(unknown source) at org.mybatis.spring.sqlsessiontemplate.insert(sqlsessiontemplate.java:271) at com.baomidou.mybatisplus.core.override.mybatismappermethod.execute(mybatismappermethod.java:60) at com.baomidou.mybatisplus.core.override.mybatismapperproxy.invoke(mybatismapperproxy.java:96) at com.sun.proxy.$proxy154.insertvoltage(unknown source) at com.dc3.center.data.service.impl.pointvalueserviceimpl.lambda$addpointvalue$0(pointvalueserviceimpl.java:270) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
caused by: java.sql.sqlexception: tdengine error: last session not finished at com.taosdata.jdbc.tsdbjniconnector.executequery(tsdbjniconnector.java:135) at com.taosdata.jdbc.tsdbstatement.executeupdate(tsdbstatement.java:87) at com.taosdata.jdbc.savedpreparedstatement.executesql(savedpreparedstatement.java:450) at com.taosdata.jdbc.savedpreparedstatement.executebatchinternal(savedpreparedstatement.java:259) at com.taosdata.jdbc.tsdbpreparedstatement.execute(tsdbpreparedstatement.java:304) at com.zaxxer.hikari.pool.proxypreparedstatement.execute(proxypreparedstatement.java:44) at com.zaxxer.hikari.pool.hikariproxypreparedstatement.execute(hikariproxypreparedstatement.java) at org.apache.ibatis.executor.statement.preparedstatementhandler.update(preparedstatementhandler.java:47) at org.apache.ibatis.executor.statement.routingstatementhandler.update(routingstatementhandler.java:74) at com.baomidou.mybatisplus.core.executor.mybatissimpleexecutor.doupdate(mybatissimpleexecutor.java:54) at org.apache.ibatis.executor.baseexecutor.update(baseexecutor.java:117) at com.baomidou.mybatisplus.core.executor.mybatiscachingexecutor.update(mybatiscachingexecutor.java:83) at org.apache.ibatis.session.defaults.defaultsqlsession.update(defaultsqlsession.java:197) at org.apache.ibatis.session.defaults.defaultsqlsession.insert(defaultsqlsession.java:184) at sun.reflect.generatedmethodaccessor183.invoke(unknown source) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.mybatis.spring.sqlsessiontemplate$sqlsessioninterceptor.invoke(sqlsessiontemplate.java:426) ..
aos aosd
dnd error failed to lock file:/var/lib/taos/dnode/.running ret:-1[resource temporarily unavailable], database may be running, quit
the function taosipstr() converts a 32-bit uint32_t to an ip address string like "127.0.0.1"
it defines two static variables, ipstrarray and ipstrinex, to store the convertedip string
when a thread calls this function the array pointed by ipstrindex is used to store the ip string
the problem is that "ipstrindex" isn\'t protected by any synchronization mechanism
both threads may use the same array if they call this function simultaneously.
java.sql.sqlexception: tdengine error: unable to resolve fqdn
i used windows client(version 2.0.5.1) connect to server side(version 2.0.5.1) on centos7, but server crashed and reported this backtrace.
======= backtrace: =========
/lib64/libc.so.6(+ )[ ]
/app/install/git-storage/tdengine/debug/build/lib/libtaos.so.1(rpcfreecont+ )[ ]
taosd(mnodecleanupmsg+ )[ ]
taosd[ ]
taosd[ ]
taosd[ ]
/lib64/libpthread.so.0(+ )[ ]
/lib64/libc.so.6(clone+ )[ ]
======= memory map: ========
00400000-004cd000 r-xp 00000000 fd:00 14232332 /usr/local/taos/bin/taosd
006cc000-006cd000 r--p 000cc000 fd:00 14232332 /usr/local/taos/bin/taosd
006cd000-006d0000 rw-p 000cd000 fd:00 14232332 /usr/local/taos/bin/taosd
006d0000-006d4000 rw-p 00000000 00:00 0 01804000-01a71000 rw-p 00000000 00:00 0 [heap]
7f9238000000-7f9238022000 rw-p 00000000 00:00 0 7f9238022000-7f923c000000 ---p 00000000 00:00 0 7f9240000000-7f9240021000 rw-p 00000000 00:00 0 7f9240021000-7f9244000000 ---p 00000000 00:00 0 7f9244000000-7f9244035000 rw-p 00000000 00:00 0 7f9244035000-7f9248000000 ---p 00000000 00:00 0 7f9248000000-7f9248021000 rw-p 00000000 00:00 0 7f9248021000-7f924c000000 ---p 00000000 00:00 0 7f924c000000-7f924c021000 rw-p 00000000 00:00 0 7f924c021000-7f9250000000 ---p 00000000 00:00 0 7f9250000000-7f9250021000 rw-p 00000000 00:00 0 7f9250021000-7f9254000000 ---p 00000000 00:00 0 7f9254000000-7f9254021000 rw-p 00000000 00:00 0 7f9254021000-7f9258000000 ---p 00000000 00:00 0 7f9258000000-7f9258021000 rw-p 00000000 00:00 0 7f9258021000-7f925c000000 ---p 00000000 00:00 0 7f925f7ff000-7f925f800000 ---p 00000000 00:00 0 7f925f800000-7f9260000000 rw-p 00000000 00:00 0 7f9260000000-7f9260021000 rw-p 00000000 00:00 0 7f9260021000-7f9264000000 ---p 00000000 00:00 0 7f9264000000-7f9264075000 rw-p 00000000 00:00 0 7f9264075000-7f9268000000 ---p 00000000 00:00 0 7f9268000000-7f9268021000 rw-p 00000000 00:00 0 7f9268021000-7f926c000000 ---p 00000000 00:00 0 7f926c7e9000-7f926c7ea000 ---p 00000000 00:00 0 7f926c7ea000-7f926cfea000 rw-p 00000000 00:00 0 7f926cfea000-7f926cfeb000 ---p 00000000 00:00 0 7f926cfeb000-7f926d7eb000 rw-p 00000000 00:00 0 7f926d7eb000-7f926d7ec000 ---p 00000000 00:00 0 7f926d7ec000-7f926dfec000 rw-p 00000000 00:00 0 7f926dfec000-7f926dfed000 ---p 00000000 00:00 0 7f926dfed000-7f926e7ed000 rw-p 00000000 00:00 0 7f926e7ed000-7f926e7ee000 ---p 00000000 00:00 0 7f926e7ee000-7f926efee000 rw-p 00000000 00:00 0 7f926efee000-7f926efef000 ---p 00000000 00:00 0 7f926efef000-7f926f7ef000 rw-p 00000000 00:00 0 7f926f7ef000-7f926f7f0000 ---p 00000000 00:00 0 7f926f7f0000-7f926fff0000 rw-p 00000000 00:00 0 7f926fff0000-7f926fff1000 ---p 00000000 00:00 0 7f926fff1000-7f92707f1000 rw-p 00000000 00:00 0 7f92707f1000-7f92707f2000 ---p 00000000 00:00 0 7f92707f2000-7f9270ff2000 rw-p 00000000 00:00 0 7f9270ff2000-7f9270ff3000 ---p 00000000 00:00 0 7f9270ff3000-7f92717f3000 rw-p 00000000 00:00 0 7f92717f3000-7f92717f4000 ---p 00000000 00:00 0 7f92717f4000-7f9271ff4000 rw-p 00000000 00:00 0 7f9271ff4000-7f9271ff5000 ---p 00000000 00:00 0 7f9271ff5000-7f92727f5000 rw-p 00000000 00:00 0 7f92727f5000-7f92727f6000 ---p 00000000 00:00 0 7f92727f6000-7f9272ff6000 rw-p 00000000 00:00 0 7f9272ff6000-7f9272ff7000 ---p 00000000 00:00 0 7f9272ff7000-7f92737f7000 rw-p 00000000 00:00 0 7f92737f7000-7f92737f8000 ---p 00000000 00:00 0 7f92737f8000-7f9273ff8000 rw-p 00000000 00:00 0 7f9273ff8000-7f9273ff9000 ---p 00000000 00:00 0 7f9273ff9000-7f92747f9000 rw-p 00000000 00:00 0 7f92747f9000-7f92747fa000 ---p 00000000 00:00 0 7f92747fa000-7f9274ffa000 rw-p 00000000 00:00 0 7f9274ffa000-7f9274ffb000 ---p 00000000 00:00 0 7f9274ffb000-7f92757fb000 rw-p 00000000 00:00 0 7f92757fb000-7f92757fc000 ---p 00000000 00:00 0 7f92757fc000-7f9275ffc000 rw-p 00000000 00:00 0 7f9275ffc000-7f9275ffd000 ---p 00000000 00:00 0 7f9275ffd000-7f92767fd000 rw-p 00000000 00:00 0 7f92767fd000-7f92767fe000 ---p 00000000 00:00 0 7f92767fe000-7f9276ffe000 rw-p 00000000 00:00 0 7f9276ffe000-7f9276fff000 ---p 00000000 00:00 0 7f9276fff000-7f92777ff000 rw-p 00000000 00:00 0 7f92777ff000-7f9277800000 ---p 00000000 00:00 0 7f9277800000-7f9278000000 rw-p 00000000 00:00 0 7f9278000000-7f9278021000 rw-p 00000000 00:00 0 7f9278021000-7f927c000000 ---p 00000000 00:00 0 7f927c3ce000-7f927c3e3000 r-xp 00000000 fd:00 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1
7f927c3e3000-7f927c5e2000 ---p 00015000 fd:00 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1
7f927c5e2000-7f927c5e3000 r--p 00014000 fd:00 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1
7f927c5e3000-7f927c5e4000 rw-p 00015000 fd:00 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1
7f927c5e4000-7f927c5e5000 ---p 00000000 00:00 0 7f927c5e5000-7f927cde5000 rw-p 00000000 00:00 0 7f927cde5000-7f927cdf1000 r-xp 00000000 fd:00 34832 /usr/lib64/libnss_files-2.17.so
7f927cdf1000-7f927cff0000 ---p 0000c000 fd:00 34832 /usr/lib64/libnss_files-2.17.so
7f927cff0000-7f927cff1000 r--p 0000b000 fd:00 34832 /usr/lib64/libnss_files-2.17.so
7f927cff1000-7f927cff2000 rw-p 0000c000 fd:00 34832 /usr/lib64/libnss_files-2.17.so
7f927cff2000-7f9282ffe000 rw-p 00000000 00:00 0 7f9282ffe000-7f9282fff000 ---p 00000000 00:00 0 7f9282fff000-7f92837ff000 rw-p 00000000 00:00 0 7f92837ff000-7f9283800000 ---p 00000000 00:00 0 7f9283800000-7f9284000000 rw-p 00000000 00:00 0 7f9284000000-7f928405d000 rw-p 00000000 00:00 0 7f928405d000-7f9288000000 ---p 00000000 00:00 0 7f9288000000-7f9288021000 rw-p 00000000 00:00 0 7f9288021000-7f928c000000 ---p 00000000 00:00 0 7f928c000000-7f928c12e000 rw-p 00000000 00:00 0 7f928c12e000-7f9290000000 ---p 00000000 00:00 0 7f92900e6000-7f92903e9000 rw-p 00000000 00:00 0 7f92903e9000-7f92903ea000 ---p 00000000 00:00 0 7f92903ea000-7f9290bea000 rw-p 00000000 00:00 0 7f9290bea000-7f9290beb000 ---p 00000000 00:00 0 7f9290beb000-7f92913eb000 rw-p 00000000 00:00 0 7f92913eb000-7f92913ec000 ---p 00000000 00:00 0 7f92913ec000-7f9291bec000 rw-p 00000000 00:00 0 7f9291bec000-7f9291bed000 ---p 00000000 00:00 0 7f9291bed000-7f92923ed000 rw-p 00000000 00:00 0 7f92923ed000-7f92923ee000 ---p 00000000 00:00 0 7f92923ee000-7f9292bee000 rw-p 00000000 00:00 0 7f9292bee000-7f9292bef000 ---p 00000000 00:00 0 7f9292bef000-7f92933ef000 rw-p 00000000 00:00 0 7f92933ef000-7f92933f0000 ---p 00000000 00:00 0 7f92933f0000-7f9293bf0000 rw-p 00000000 00:00 0 7f9293bf0000-7f9293bf1000 ---p 00000000 00:00 0 7f9293bf1000-7f92943f1000 rw-p 00000000 00:00 0 7f92943f1000-7f92943f2000 ---p 00000000 00:00 0 7f92943f2000-7f9294bf2000 rw-p 00000000 00:00 0 7f9294bf2000-7f9294bf3000 ---p 00000000 00:00 0 7f9294bf3000-7f92954b0000 rw-p 00000000 00:00 0 7f92954b0000-7f92954b1000 ---p 00000000 00:00 0 7f92954b1000-7f9295cb1000 rw-p 00000000 00:00 0 7f9295cb1000-7f9295cb2000 ---p 00000000 00:00 0 7f9295cb2000-7f9296507000 rw-p 00000000 00:00 0 7f9296507000-7f9296508000 ---p 00000000 00:00 0 7f9296508000-7f9296d08000 rw-p 00000000 00:00 0 7f9296d08000-7f9296d09000 ---p 00000000 00:00 0
the limit of database name's length is not `33` as stated in [doc]( #%e6%94%af%e6%8c%81%e7%9a%84%e6%95%b0%e6%8d%ae%e7%b1%bb%e5%9e%8b)
ava ql
insert into product1_device2_ai_point1 using st_device_data_up tags ("product1","device1","ai_point1"," ","double","0","100000","1"," "," ") values ("2020-10-16 16:58:32.277",3258); elect count(tbname) from st_device_data_up
taosd crashes when filtering by a stable tag field of nchar(n), which is fully filled with chars.
taos_validate_sql deadlock
how tables how stables
ables
how streams; treamid
select ai_pick_udata from qch_test.st_device_data_up order by time desc limit 10;
taos: /home/ubuntu/zyyang/v2.0/tdinternal/community/src/query/src/qextbuffer.c:583: median: assertion `comparefn(pdescriptor, numofrows, mididx, start, data) <= 0 && comparefn(pdescriptor, numofrows, start, end, data) <= 0' failed.
aborted (core dumped) ![image](
use spring boot, mybatis, tdengine java driver connect to tdengine on the same machine fter running some time(about one or two day), jvm crash and left a crash report file: `hs_err_<pid>.txt` here is how my java application look like: *build.gradle:* ```groovy
buildscript { repositories { maven { url \' } } dependencies { classpath "org.springframework.boot:spring-boot-gradle-plugin:2.3.3.release" }
} apply plugin: 'java'
apply plugin: 'org.springframework.boot'
apply plugin: 'io.spring.dependency-management' sourcecompatibility = 1.8 configurations { compileclasspath { extendsfrom annotationprocessor }
} repositories { maven { url ' }
} dependencies { // .....
implementation 'org.springframework.boot:spring-boot-starter-web' implementation 'com.taosdata.jdbc:taos-jdbcdriver:2.0.4' implementation 'com.baomidou:mybatis-plus-boot-starter:3.4.0' implementation 'com.baomidou:dynamic-datasource-spring-boot-starter:3.2.0' implementation 'com.alibaba:fastjson:1.2.73' // ......
``` my application `only has a few query methods` connect to tdengine: **table structure:** ```bash
taos> select * from d000348 limit 0,10; ts | imp_ep | u | i | p | q | s | pf |
=========================================================================================================================================================================================== 2020-09-28 15:22:10.000 | 40.65000 | 224.00000 | 0.00000 | 0.00000 | 0.00000 | 0.00000 | 1.00000 | 2020-09-28 15:23:10.000 | 40.65000 | 223.89999 | 0.00000 | 0.00000 | 0.00000 | 0.00000 | 1.00000 | 2020-09-28 15:24:10.000 | 40.65000 | 223.70000 | 0.00000 | 0.00000 | 0.00000 | 0.00000 | 1.00000 | 2020-09-28 15:25:10.000 | 40.65000 | 224.00000 | 0.00000 | 0.00000 | 0.00000 | 0.00000 | 1.00000 | 2020-09-28 15:26:10.000 | 40.65000 | 224.10001 | 0.00000 | 0.00000 | 0.00000 | 0.00000 | 1.00000 | 2020-09-28 15:27:10.000 | 40.65000 | 224.10001 | 0.00000 | 0.00000 | 0.00000 | 0.00000 | 1.00000 | 2020-09-28 15:28:10.000 | 40.65000 | 224.10001 | 0.00000 | 0.00000 | 0.00000 | 0.00000 | 1.00000 | 2020-09-28 15:29:10.000 | 40.65000 | 224.20000 | 0.00000 | 0.00000 | 0.00000 | 0.00000 | 1.00000 | 2020-09-28 15:30:10.000 | 40.65000 | 224.10001 | 0.00000 | 0.00000 | 0.00000 | 0.00000 | 1.00000 | 2020-09-28 15:31:10.000 | 40.65000 | 224.39999 | 0.00000 | 0.00000 | 0.00000 | 0.00000 | 1.00000 | ``` *tdengineservice.java:* ```java
package com.xxx.wulian.service; import com.alibaba.fastjson.jsonobject;
import com.baomidou.mybatisplus.core.metadata.ipage;
import com.gsta.wulian.model.tdmeter; import java.util.list; public interface tdengineservice { boolean istableexists(string tablename); void findpagedevicehistorymsg(ipage<jsonobject> page, string devicetablename, list<string> props, long start, long end); list<jsonobject> findlistdevicehistorymsg(string devicetablename, list<string> props, long start, long end);
``` *tdengineserviceimpl.java:* ```java
package com.xxx.wulian.service.impl; import cn.hutool.core.collection.collectionutil;
import cn.hutool.core.date.betweenformater;
import cn.hutool.core.date.dateutil;
import cn.hutool.core.util.strutil;
import com.alibaba.fastjson.jsonobject;
import com.baomidou.dynamic.datasource.annotation.ds;
import com.baomidou.mybatisplus.core.metadata.ipage;
import com.gsta.wulian.dao.tdenginemapper;
import com.gsta.wulian.model.automaticreclosingrecorddata;
import com.gsta.wulian.model.tdmeter;
import com.gsta.wulian.service.tdengineservice;
import lombok.extern.slf4j.slf4j;
import org.springframework.beans.factory.annotation.autowired;
import org.springframework.stereotype.service; import java.util.arraylist;
import java.util.list;
import java.util.concurrent.timeunit;
import java.util.stream.collectors; @slf4j
@ds("tdengine")
public class tdengineserviceimpl implements tdengineservice { @autowired private tdenginemapper tdenginemapper; @override public boolean istableexists(string tablename) { list<jsonobject> list = tdenginemapper.showtableslike(tablename); return collectionutil.isnotempty(list); } @override public void findpagedevicehistorymsg(ipage<jsonobject> page, string devicetablename, list<string> propnames, long start, long end) { // dynamic columns: ts,imp_ep,u,i,p,q,s,pf list<string> columns = propnames.stream() .filter(strutil::isnotblank) .map(n->strutil.tounderlinecase(n).tolowercase()) .collect(collectors.tolist()); log.info(" : {}, : {}",devicetablename,columns); long offset = page.offset(); long size = page.getsize(); // count total record integer total = tdenginemapper.countdevicehistorymsg(devicetablename,start,end); if (total!=null && !total.equals(0)){ // find page data list<jsonobject> records = tdenginemapper.findpagedevicehistorymsg(offset,size,devicetablename, columns,start,end); page.settotal(total); page.setrecords(records); } } @override public list<jsonobject> findlistdevicehistorymsg(string devicetablename, list<string> propnames, long start, long end) { // dynamic columns: ts,imp_ep,u,i,p,q,s,pf list<string> columns = propnames.stream() .filter(strutil::isnotblank) .map(n->strutil.tounderlinecase(n).tolowercase()) .collect(collectors.tolist()); log.info(" : {}, : {}",devicetablename,columns); // find all data list<jsonobject> records = tdenginemapper.findlistdevicehistorymsg(devicetablename, columns,start,end); return records; }
} ``` *tdenginemapper:* ```java
package com.gsta.wulian.dao; import com.alibaba.fastjson.jsonobject;
import com.baomidou.mybatisplus.core.mapper.basemapper;
import com.gsta.wulian.model.automaticreclosingrecorddata;
import com.gsta.wulian.model.tdmeter;
import org.apache.ibatis.annotations.mapper;
import org.apache.ibatis.annotations.param;
import org.springframework.stereotype.repository; import java.util.list; @mapper
@repository
public interface tdenginemapper extends basemapper<tdmeter> { list<jsonobject> showtableslike(@param("tablename")string tablename); integer countdevicehistorymsg(@param("tablename") string devicetablename, @param("start") long start, @param("end") long end); list<jsonobject> findpagedevicehistorymsg(@param("offset")long offset, @param("size")long size, @param("tablename") string devicetablename, @param("columns") list<string> columns, @param("start") long start, @param("end") long end); list<jsonobject> findlistdevicehistorymsg(@param("tablename") string devicetablename, @param("columns") list<string> columns, @param("start") long start, @param("end") long end);
``` *tdenginemapper.xml:* ```xml
<?xml version="1.0" encoding="utf-8"?>
<!doctype mapper public "-//mybatis.org//dtd mapper 3.0//en" " ">
<mapper namespace="com.gsta.wulian.dao.tdenginemapper"> <select id="showtableslike" resulttype="com.alibaba.fastjson.jsonobject"> show tables like #{tablename} </select> <select id="countdevicehistorymsg" resulttype="java.lang.integer"> select count(*) from ${tablename} where <![cdata[ ts >= #{start} and ts <= #{end} ]]> </select> <select id="findpagedevicehistorymsg" resulttype="com.alibaba.fastjson.jsonobject"> select ts, <foreach collection="columns" item="c" separator=","> ${c} </foreach> from ${tablename} where <![cdata[ ts >= #{start} and ts <= #{end} ]]> order by ts desc limit #{offset},#{size} </select> <select id="findlistdevicehistorymsg" resulttype="com.alibaba.fastjson.jsonobject"> select <foreach collection="columns" item="c" separator="," close=", ts"> ${c} </foreach> from ${tablename} where <![cdata[ ts >= #{start} and ts <= #{end} ]]> order by desc </select>
``` the crash report is too long, please download it: [hs_err_pid7046.log](
[hs_err_pid2360.log](
ava
1 hile lter table st_device_data_up drop column di_updownnvalopovt;
2 lter table st_device_data_up add column di_updownnvalopovt double;
3 elect time, ai_pick_udata, di_updownnvalopovt, productkey, devicename from st_device_data_up order by time desc limit 10; i_updownnvalopovt ull
4 ava
![image](
dbc elect first(price),last(price) from tbl interval(1h); first ast ull
when i use jdbc (2.0.4.0) busrt insert data into tdengine, sometime may throw this exception:
java.lang.runtimeexception: invalid result set pointer at com.taosdata.jdbc.tsdbjniconnector.freeresultset(tsdbjniconnector.java:187) at com.taosdata.jdbc.tsdbstatement.executeupdate(tsdbstatement.java:96) at cn.bigdata.flink.dataclean.function.tdenginesinkfunction.invoke(tdenginesinkfunction.java:90) at org.apache.flink.streaming.api.operators.streamsink.processelement(streamsink.java:56) at org.apache.flink.streaming.runtime.io.streaminputprocessor.processinput(streaminputprocessor.java:202) at org.apache.flink.streaming.runtime.tasks.oneinputstreamtask.run(oneinputstreamtask.java:105) at org.apache.flink.streaming.runtime.tasks.streamtask.invoke(streamtask.java:300) at org.apache.flink.runtime.taskmanager.task.run(task.java:711) at java.lang.thread.run(thread.java:748)
.0.4.0 .0.5.0
aosd
in `taos` cli, cannot interrupt `select * from table` if table is very big.
2.0.5.0 sudo systemctl start taosd
go build error when import github.com/taosdata/driver-go/taossql
ac ocker dengine, ava
#3732
![image](
erver crash(docker xit) rash
java.sql.sqlexception: tdengine error: invalid resultset pointer! at com.taosdata.jdbc.tsdbresultset.next(tsdbresultset.java:129)
java.sql.sqlexception: tdengine error: invalid resultset pointer! at com.taosdata.jdbc.tsdbresultset.next(tsdbresultset.java:129)
java.sql.sqlexception: tdengine error: invalid resultset pointer! at com.taosdata.jdbc.tsdbresultset.next(tsdbresultset.java:129)
java.sql.sqltransientconnectionexception: tdengine-hikari - connection is not available, request timed out after 30000ms
at com.zaxxer.hikari.pool.hikaripool.createtimeoutexception(hikaripool.java:695) at com.zaxxer.hikari.pool.hikaripool.getconnection(hikaripool.java:197) at com.zaxxer.hikari.pool.hikaripool.getconnection(hikaripool.java:162) at com.zaxxer.hikari.hikaridatasource.getconnection(hikaridatasource.java:128) ```
b error: invalid vgroup id 00 b error: unable to establish connection og
![image](
user sends a request by curl to create table, response shows succeeded but table does not exist.
user cannot login by taos -u <username> -p <password> or taos -u=<username> -p=<password>
>~$ taos -u=test -p=123456 welcome to the tdengine shell from linux, client version:2.0.3.0
copyright (c) 2017 by taos data, inc
all rights reserved
taos connect failed, reason: invalid user
>~$ taos -u test -p 123456
taos: too many arguments
try `taos --help' or `taos --usage' for more information.
the right way of login is that has to use full spell:
>~$ taos --user=test --password=123456 welcome to the tdengine shell from linux, client version:2.0.3.0
copyright (c) 2017 by taos data, inc
all rights reserved
taos> show users; name | privilege | create_time | account |
================================================================================================= _root | writable | 2020-09-27 05:39:12.344 | root | test | writable | 2020-09-27 05:44:09.714 | root | monitor | writable | 2020-09-27 05:39:12.344 | root | root | super | 2020-09-27 05:39:12.344 | root |
query ok, 4 row(s) in set (0.002310s) ```
in the help information of taos command line, it seems user can use -u and -p to login.
micl@tdengine:~$ taos --help
usage: taos [option...] -a, --user=auth the user auth to use when connecting to the server
-c, --config-dir=config_dir configuration directory
-d, --database=database database to use when connecting to the server
-d, --directory=directory use multi-thread to import all sql files in the directory separately
-e, --endport=endport net test end port, default is 6042
-f, --file=file script to run without enter the shell
-h, --host=host tdengine server ip address to connect
the default host is localhost
-l, --pktlen=pktlen packet length used for net test, default is 1000 bytes
-n, --netrole=netrole net role when network connectivity test, default is null, valid option: client | server
-p, --password[=password] the password to use when connecting to the server
-p, --port=port the tcp/ip port number to use for the connection
-r, --raw-time output time as uint64_t
-s, --commands=commands commands to run without enter the shell
-t, --timezone=timezone time zone of the shell, default is local
-t, --thread=threadnum number of threads when using multi-thread to import data
-u, --user=user the user name to use when connecting to the server
-?, --help give this help list --usage give a short usage message -v, --version print program version mandatory or optional arguments to long options are also mandatory or optional
for any corresponding short options
report bugs to <support@taosdata.com>.
ount(*)
for i in {1..10000}
echo "----------------"
taos -h 127.0.0.1 -s "select count(*) from access_log.http;"
```
taos> select count(*) from access_log.http; count(*) |
======================== 1605924 |
query ok, 1 row(s) in set (0.224237s) 2020 09 25 17:24:51 cst ---------------- welcome to the tdengine shell from linux, client version:2.0.2.1
copyright (c) 2017 by taos data, inc
all rights reserved
taos> select count(*) from access_log.http; count(*) |
======================== 1593501 |
query ok, 1 row(s) in set (0.141304s) 2020 09 25 17:25:01 cst
windows elect count(*) nvalid message
elect * from xxx
![image](
ql
.6.5 sv .0.4
after alter user root pass an not exec taos ,
taosdemo
caused by: java.sql.sqlexception: tdengine error: syntax error near ' (invalid data or symbol)
dbc
when using idea to explore taos after connected,idea report `java.lang.indexoutofboundsexception: index 0 out of bounds for length 0`
order by imit
group by ount
select remote_addr,count(*) as ss from http group by remote_addr order by ss desc limit 1000; 221.192.180.155 | 1 | 221.192.180.177 | 262 | 221.192.180.252 | 54 | 221.210.180.254 | 355 | 221.229.166.191 | 536 | 221.229.204.132 | 205 | 222.174.234.158 | 317 | 222.186.180.132 | 265 | 222.216.160.142 | 572 | 222.217.136.203 | 733 | 222.217.237.143 | 347 | 222.217.246.213 | 1876 | 222.218.112.235 | 849 | 222.248.218.157 | 4 | 222.248.241.184 | 1150 | 223.104.103.148 | 2 | 223.104.178.234 | 97 | 223.104.182.192 | 6 | 223.104.193.153 | 10 | 223.104.213.238 | 9 | 223.104.246.229 | 1 | 223.104.255.164 | 14 | 223.150.112.195 | 475 | 223.155.208.116 | 24 | 223.166.151.233 | 30 | 223.166.151.234 | 78 | 223.166.151.235 | 54 | 223.166.151.237 | 86 | 223.167.152.124 | 107 | 223.167.152.125 | 54 | 223.213.112.145 | 1717 |
, , timestamp data out of range
, , timestamp data out of range
ava -jar ar indows inux
failed to write core dump
core dumps have been disabled.
2.0.3.1 sql:
select last_row(*) ,location, admiddate, adidate, pname, age , psex, height, weight from db_mrnost.st_mrnxst where onoff = "no" and location ="x4f" group by tbname;
err: db error: invalid sql: only one selectivity function allowed in presence of tags f
taos_res* taos_query(taos *taos, const char *sql)
insert ull o
err=success no=-2147482782
ython ultiprocessing ool.map 0000
dengine 1 | 192.168.4.66:6030 | 1 | 1 | ready | any | 2020-09-15 11:08:34.134 | 2 | 168.192.6.66:6030 | 0 | 3 | offline | any | 2020-09-15 11:10:02.532 |
dengine lient lient
taosd core when query with roup by
windows dengine-client-2.0.3.0-windows-x64.exe
dengine-server-2.0.3.0-linux-x64.rpm
springboot ybatis
mapper ql elect last(peroid_time) as peroid_time,last(value) as value from iot_data.td_01_012e00000011_00d00017_01
<resultmap id="baseresultmap" type="com.glodon.data.entity.scadavaluevo" > <result column="peroid_time" property="peroidtime" jdbctype="timestamp" /> <result column="value" property="value" jdbctype="double" /> <result column="gather_key" property="gatherkey" jdbctype="varchar" /> </resultmap>
create table td_012e000000a1 (peroid_time timestamp,value float,data_type int) tags (type int);
cause: java.sql.sqlexception: tdengine error: invalid num of fields!
; uncategorized sqlexception; sql state [null]; error code [0]; tdengine error: invalid num of fields!; nested exception is java.sql.sqlexception: tdengine error: invalid num of fields!
[hs_err_pid32192.log](
egmentation fault
[root@na-production-01 ~]# taos --version
version: 2.0.1.0 [root@na-production-01 ~]# systemctl status taosd.service -l
taosd.service - tdengine server service loaded: loaded (/etc/systemd/system/taosd.service; enabled; vendor preset: disabled) active: failed (result: signal) since fri 2020-09-04 14:02:52 cst; 57min ago process: 6822 execstart=/usr/bin/taosd (code=killed, signal=abrt) main pid: 6822 (code=killed, signal=abrt) sep 04 14:02:52 na-production-01 systemd[1]: taosd.service: service restartsec=100ms expired, scheduling restart.
sep 04 14:02:52 na-production-01 systemd[1]: taosd.service: scheduled restart job, restart counter is at 8.
sep 04 14:02:52 na-production-01 systemd[1]: stopped tdengine server service.
sep 04 14:02:52 na-production-01 systemd[1]: taosd.service: start request repeated too quickly.
sep 04 14:02:52 na-production-01 systemd[1]: taosd.service: failed with result 'signal'.
sep 04 14:02:52 na-production-01 systemd[1]: failed to start tdengine server service
``` ```bash
taos> select sum(val) sum, first(val) first,last(val) last,min(val) min,max(val) max,avg(val) avg, spread(val) diff,count(*) count from eiot_online.point_data_1031 where ts >'2020-09-03 00:00:00.000' and ts <'2020-09-03 23:59:59.000' interval(1d) ;
query interrupted (unable to establish connection), 0 row(s) in set (0.624396s)
** 2020.09.03 ** ```bash
taos> select first(val) first,last(val) last,min(val) min,max(val) max,avg(val) avg, spread(val) diff,count(*) count from eiot_online.point_data_1031 where ts >'2020-09-01 00:00:
00.000' and ts <'2020-09-04 23:59:59.000' interval(1d) ; ts | first | last | min | max | avg | di ff | count |
=================================================================================================================================================================================== ======================================= 2020-09-01 00:00:00.000 | 63594000.000000000 | 63594000.000000000 | 63594000.000000000 | 63594000.000000000 | 63594000.000000000 | 0.000000000 | 4309 | 2020-09-02 00:00:00.000 | 63594000.000000000 | 63594000.000000000 | 63594000.000000000 | 63594000.000000000 | 63594000.000000000 | 0.000000000 | 4282 | 2020-09-03 00:00:00.000 | 63594000.000000000 | 63594000.000000000 | 63594000.000000000 | 63594000.000000000 | 63594000.000000000 | 0.000000000 | 4167 | 2020-09-04 00:00:00.000 | 63594000.000000000 | 63594000.000000000 | 63594000.000000000 | 63594000.000000000 | 63594000.000000000 | 0.000000000 | 2660 |
query ok, 4 row(s) in set (0.005309s) ```
build by alpine and success
trl+c egmentation fault
select * from temperature; emperature
trl+c ![ _20200903102918]( ** environment ** - os: ubuntu 20.04
- memory :8g , cpu:4 core, current disk space:20g
- tdengine version : 2.0.1.1
dbc dbc ql aos ![ _20200903100235]( 0% **environment ** - os: ubuntu 20.04 - memory :8g , cpu:4 core, current disk space:20g - tdengine version : 2.0.1.1 - jdbc version: 2.0.4
taos link aos .0.2.1 link .7.1.flink
caused by: java.lang.noclassdeffounderror: could not initialize class com.taosdata.jdbc.tsdbjniconnector at com.taosdata.jdbc.tsdbdriver.connect(tsdbdriver.java:133) at java.sql.drivermanager.getconnection(drivermanager.java:664) at java.sql.drivermanager.getconnection(drivermanager.java:208)
caused by: java.lang.unsatisfiedlinkerror: native library /usr/local/taos/driver/libtaos.so.2.0.2.1 already loaded in another classloader at java.lang.classloader.loadlibrary0(classloader.java:1907) at java.lang.classloader.loadlibrary(classloader.java:1857) at java.lang.runtime.loadlibrary0(runtime.java:870) at java.lang.system.loadlibrary(system.java:1122)
aos ibtao.so link esource ava aos
insert 1 elect count(*)..
1 1010 1020
http
curl -s -h \'authorization: taosd /kfeazx/f9na8qdtnzmtonryp201ma04bel8lcvlud7a8qdtnzmtonryp201ma04\' -d "select count(*) as count from zhidou.pay_flow where pay_time >= \'2020-06-01 00:00:00\' and pay_time < \'2020-06-02 00:00:00\' and month=\'2006\' group by client_id, branch_no slimit 10;" | jq "[.rows]"
10, 1
![image]( dnodes
taos> show dnodes; id | end_point | vnodes | cores | status | role | create_time |
================================================================================================================== 1 | master:6030 | 37 | 12 | ready | any | 2020-09-01 03:06:12.542 | 2 | slave:6030 | 36 | 12 | ready | any | 2020-09-01 03:07:05.623 | 3 | slave2:6030 | 36 | 12 | ready | any | 2020-09-01 03:07:12.805 |
query ok, 3 row(s) in set (0.001581s)
``` name | created_time | ntables | vgroups | replica | quorum | days | keep1,keep2,keep(d) | cache(mb) | blocks | minrows | maxrows | wallevel | fsync | comp | precision | status | =================================================================================================================================================================================================================================================================== log | 2020-09-01 03:06:15.561 | 6 | 1 | 1 | 1 | 10 | 30,30,30 | 1 | 3 | 100 | 4096 | 1 | 3000 | 2 | us | ready | zhidou | 2020-09-01 03:07:28.079 | 85294 | 36 | 3 | 1 | 2 | 3650,3650,3650 | 16 | 6 | 100 | 4096 | 1 | 3000 | 2 | ms | ready | ```
i just installed the latest v2.0.2.1 by the rpm package downloaded from your official website on centos 7.8
$ systemctl status taosd
taosd.service - tdengine server service loaded: loaded (/etc/systemd/system/taosd.service; enabled; vendor preset: disabled) active: active (running) since 2020-08-27 16:35:24 cst; 5min ago main pid: 17264 (taosd) tasks: 70 memory: 5.4m cgroup: /system.slice/taosd.service 7264 /usr/bin/taosd 8 27 16:35:24 fibret-node1 systemd[1]: started tdengine server service.
8 27 16:35:24 fibret-node1 tdengine:[17264]: starting tdengine service...
8 27 16:35:24 fibret-node1 tdengine:[17264]: started tdengine service successfully.
``` and i also can connect the "taosd" by the "taos" on the same server
but when i tried to
create the database demo, i got the "**db error: unexpected generic error in rpc**"
$ taos welcome to the tdengine shell from linux, client version:2.0.2.1
copyright (c) 2017 by taos data, inc
all rights reserved
taos> create database demo; db error: unexpected generic error in rpc
ocker nexpected generic error in rpc ocker ocker entos7 windows
restfulrowlimit 0240 0240 [103,20242110,20200820],[104,20242112,20200820 ows
indow nexpected generic error in rpc
docker
node
node 8, 10 .
restful api node connector ?
taosdta 2.0.1.0 let query = cursor.query('insert into' + ' ' ....
query.execute().then(function (result)
{ tderror.databaseerror.operationalerror: invalid use of fetchall, either result or fields from query are null
first execute a query first at tdenginecursor.fetchall (/usr/local/k/node_modules/td2.0-connector/nodetaos/cursor.js:176:11) at /usr/local/k/node_modules/td2.0-connector/nodetaos/taosquery.js:42:71 at new promise (<anonymous>) at taosquery.execute (/usr/local/k/node_modules/td2.0-connector/nodetaos/taosquery.js:35:26)
dbc onn.preparestatement(string sql) ql reparestatement etstring(int parameterindex, string x) ql ql avedpreparedstatement eplacetemplateparam tring eplacefirst
the prepare query return empty data.
trying to create database demo days 10 cache 16000 rows 2000 throws an sql error
removing cache and rows executes
inux aos
taos connect failed, reason: unexpected generic error in rpc.
db error: too many sessions on server
![1596781229(1)](
.0.0.0
ostname pm dengine
1 ostname aos.cfg
2 1hostname
1 2 nd error status rsp is received, error:unable to establish connection
telnet
source data.sql .6.5.6
taosdump -n 1000 --all-databases -o test1.sql .6.5.6
.6
.6 .0
pm /var/log/taos entos7 taosd.service - tdengine server service loaded: loaded (/etc/systemd/system/taosd.service; enabled; vendor preset: disabled) active: failed (result: start-limit) since mon 2020-08-03 21:03:08 cst; 6min ago process: 320475 execstart=/usr/bin/taosd (code=exited, status=127) main pid: 320475 (code=exited, status=127) aug 03 21:03:08 hbase systemd[1]: unit taosd.service entered failed state.
aug 03 21:03:08 hbase systemd[1]: taosd.service failed.
aug 03 21:03:08 hbase systemd[1]: taosd.service holdoff time over, scheduling restart.
aug 03 21:03:08 hbase systemd[1]: stopped tdengine server service.
aug 03 21:03:08 hbase systemd[1]: start request repeated too quickly for taosd.service
aug 03 21:03:08 hbase systemd[1]: failed to start tdengine server service.
aug 03 21:03:08 hbase systemd[1]: unit taosd.service entered failed state.
aug 03 21:03:08 hbase systemd[1]: taosd.service failed.
there are chars ^m at every line end in the file packaging/tools/get_version.sh to make it fail to run, while build tdengine using cmake
i remove these chars manually then can build mormally.
when we used apache calcite jdbcschema query on tdengine,it could not get metadata ,because of tdengine jdbc driver method nullsaresortedatstart and nullsaresortedatend in ``tdengine/src/connector/jdbc/src/main/java/com/taosdata/jdbc/tsdbdatabasemetadata.java`` both return false.
java: /home/ubuntu/version_release_workroom/release_workspace/tdinternal/community/src/client/src/tscparseinsert.c:1494: tscprocessmultivnodesinsert: assertion `pmetermetainfo->vnodeindex >= 1 && pcmd->pdatablocks != null' failed
/home/ubuntu
taos *taos_connect(char *ip, char *user, char *pass, char *db, int port)
aos_connect aos
too many authentication failed,try 10 minutes later
ast_row
taos> select last_row(*) from tab_jf1;
query ok, 0 row(s) in set (0.001926s) aos / ast_row() elect * from tab_jf1 where dt>=now-1m and dt<now;
pi , ptuuy aosdata , 99
insert into yxsj1(t,v,s) values(1537487903000,96.791,1),(1537487905000,94.341,1),(1537487909000,94.695,1),.....,(1537488503000,91.329,1);
failure, reason: invalid submit message putty select max(t) as m from ysxj1;
srpingboot ybatis loat igdecinal
1 jdbc batch 5000 2046
2 batch statement.executeupdate();
** **
package com.example.tdengine; import com.zaxxer.hikari.hikariconfig;
import com.zaxxer.hikari.hikaridatasource; import java.sql.connection;
import java.sql.statement;
import java.util.concurrent.executorservice;
import java.util.concurrent.executors; public class test5 { private static hikaridatasource ds; // static volatile int ddf = 819; // static string tagname = "t" + ddf; // sql static string sb11 = ""; public static void main(string[] args) { hikariconfig config = new hikariconfig(); config.setjdbcurl("jdbc:taos://localhost:6030/ctest"); config.setusername("root"); config.setpassword("taosdata"); config.setminimumidle(3); config.setmaximumpoolsize(51); config.setconnectiontimeout(10000); config.setidletimeout(60000); config.setconnectiontestquery("describe log.dn"); config.setvalidationtimeout(10000); ds = new hikaridatasource(config); executorservice executorservice = executors.newfixedthreadpool(21); // ql stringbuilder sb1 = new stringbuilder(); for (int i = 0; i < 250; i++) { sb1.append((10 * math.random())); if (i == 249) { sb1.append(")"); } else { sb1.append(","); } } sb11 = sb1.tostring(); while(true) { system.out.println("run ---> " + tagname); for (int i = 0; i < 20; i++) { final int j = i; executorservice.execute(new runnable() { @override public void run() { connection connection = null; // get connection try { connection = ds.getconnection(); connection.setautocommit(false); long starttime = system.currenttimemillis(); statement statement = connection.createstatement(); // get statement for (int ts = 1; ts <= 5000; ts++) { stringbuilder sb = new stringbuilder(); sb.append("insert into tbz"); sb.append(j); sb.append(" values (0, \'"); sb.append(tagname); sb.append("\',"); sb.append(ts); sb.append(","); sb.append(sb11); statement.addbatch(sb.tostring()); } // statement.executebatch(); connection.commit(); system.out.println(" ---> " + (system.currenttimemillis() - starttime)); statement.close(); connection.close(); } catch (exception e) { e.printstacktrace(); } } }); } try { thread.sleep(20000); tagname = "t" + (++ddf); } catch (interruptedexception e) { e.printstacktrace(); } } }
![1594720307(1)](
![1594720404(1)]( ** :** - os: [centos 7.0] - memory 1t, cpu 128 , current disk space .6t - tdengine version [1.6.6.1]
![image](
1 pm dengine
.6.5.5 .6.6.5
2 /etc/taos/taos.cfg
datadir /home/data/taos
systemctl start taosd
s
![ff10d5537fffd8f22fa0866e0bb6246](
1 sdb ata
2 sdb ata
3 > 1020 java.sql.sqlexception: tdengine error: invalid resultset pointer!
dbc ruid shellactivitytimer 0
![image]( cp vm
![image](
, ![image](
---------------------------------------------------------------------------
programmingerror traceback (most recent call last)
<ipython-input-78-d31499dacc54> in <module>
----> 1 cursor.execute("create table a00a090dfb using th tags (1)") /usr/local/lib/python3.6/dist-packages/taos/cursor.py in execute(self, operation, params) 119 return self._handle_result() 120 else:
--> 121 raise programmingerror(ctaosinterface.errstr(self._connection._conn)) 122 123 def executemany(self, operation, seq_of_parameters): programmingerror: failed to connect to server
dengine ms 00 ava ava 000ms .5ms-2.5ms ,
dengine dbc ava indows dengine server inux indows aos client aos client ava ava dengine server ava 00ms,taos ms ** **
create table if not exists mt (ts timestamp, v1 int) tags(t1 int)
create table if not exists t0 using mt tags(0);
create table if not exists t1 using mt tags(1);
create table if not exists t2 using mt tags(2);
create table if not exists t3 using mt tags(3);
create table if not exists t4 using mt tags(4);
create table if not exists t5 using mt tags(5);
create table if not exists t6 using mt tags(6);
create table if not exists t7 using mt tags(7);
create table if not exists t8 using mt tags(8);
create table if not exists t9 using mt tags(9);
create table if not exists t10 using mt tags(10);
create table if not exists t11 using mt tags(11);
create table if not exists t12 using mt tags(12);
create table if not exists t13 using mt tags(13);
create table if not exists t14 using mt tags(14);
create table if not exists t15 using mt tags(15);
create table if not exists t16 using mt tags(16);
create table if not exists t17 using mt tags(17);
create table if not exists t18 using mt tags(18);
create table if not exists t19 using mt tags(19);
create table if not exists t20 using mt tags(20);
create table if not exists t21 using mt tags(21);
create table if not exists t22 using mt tags(22);
create table if not exists t23 using mt tags(23);
create table if not exists t24 using mt tags(24);
create table if not exists t25 using mt tags(25);
create table if not exists t26 using mt tags(26);
create table if not exists t27 using mt tags(27);
create table if not exists t28 using mt tags(28);
create table if not exists t29 using mt tags(29);
create table if not exists t30 using mt tags(30);
create table if not exists t31 using mt tags(31);
create table if not exists t32 using mt tags(32);
create table if not exists t33 using mt tags(33);
create table if not exists t34 using mt tags(34);
create table if not exists t35 using mt tags(35);
create table if not exists t36 using mt tags(36);
create table if not exists t37 using mt tags(37);
create table if not exists t38 using mt tags(38);
create table if not exists t39 using mt tags(39);
create table if not exists t40 using mt tags(40);
create table if not exists t41 using mt tags(41);
create table if not exists t42 using mt tags(42);
create table if not exists t43 using mt tags(43);
create table if not exists t44 using mt tags(44);
create table if not exists t45 using mt tags(45);
create table if not exists t46 using mt tags(46);
create table if not exists t47 using mt tags(47);
create table if not exists t48 using mt tags(48);
create table if not exists t49 using mt tags(49);
create table if not exists t50 using mt tags(50);
create table if not exists t51 using mt tags(51);
create table if not exists t52 using mt tags(52);
create table if not exists t53 using mt tags(53);
create table if not exists t54 using mt tags(54);
create table if not exists t55 using mt tags(55);
create table if not exists t56 using mt tags(56);
create table if not exists t57 using mt tags(57);
create table if not exists t58 using mt tags(58);
create table if not exists t59 using mt tags(59);
create table if not exists t60 using mt tags(60);
create table if not exists t61 using mt tags(61);
create table if not exists t62 using mt tags(62);
create table if not exists t63 using mt tags(63);
create table if not exists t64 using mt tags(64);
create table if not exists t65 using mt tags(65);
create table if not exists t66 using mt tags(66);
create table if not exists t67 using mt tags(67);
create table if not exists t68 using mt tags(68);
create table if not exists t69 using mt tags(69);
create table if not exists t70 using mt tags(70);
create table if not exists t71 using mt tags(71);
create table if not exists t72 using mt tags(72);
create table if not exists t73 using mt tags(73);
create table if not exists t74 using mt tags(74);
create table if not exists t75 using mt tags(75);
create table if not exists t76 using mt tags(76);
create table if not exists t77 using mt tags(77);
create table if not exists t78 using mt tags(78);
create table if not exists t79 using mt tags(79);
create table if not exists t80 using mt tags(80);
create table if not exists t81 using mt tags(81);
create table if not exists t82 using mt tags(82);
create table if not exists t83 using mt tags(83);
create table if not exists t84 using mt tags(84);
create table if not exists t85 using mt tags(85);
create table if not exists t86 using mt tags(86);
create table if not exists t87 using mt tags(87);
create table if not exists t88 using mt tags(88);
create table if not exists t89 using mt tags(89);
create table if not exists t90 using mt tags(90);
create table if not exists t91 using mt tags(91);
create table if not exists t92 using mt tags(92);
create table if not exists t93 using mt tags(93);
create table if not exists t94 using mt tags(94);
create table if not exists t95 using mt tags(95);
create table if not exists t96 using mt tags(96);
create table if not exists t97 using mt tags(97);
create table if not exists t98 using mt tags(98);
create table if not exists t99 using mt tags(99); ** **
insert into t0 values(0,0) t1 values(0,1) t2 values(0,2) t3 values(0,3) t4 values(0,4) t5 values(0,5) t6 values(0,6) t7 values(0,7) t8 values(0,8) t9 values(0,9) t10 values(0,10) t11 values(0,11) t12 values(0,12) t13 values(0,13) t14 values(0,14) t15 values(0,15) t16 values(0,16) t17 values(0,17) t18 values(0,18) t19 values(0,19) t20 values(0,20) t21 values(0,21) t22 values(0,22) t23 values(0,23) t24 values(0,24) t25 values(0,25) t26 values(0,26) t27 values(0,27) t28 values(0,28) t29 values(0,29) t30 values(0,30) t31 values(0,31) t32 values(0,32) t33 values(0,33) t34 values(0,34) t35 values(0,35) t36 values(0,36) t37 values(0,37) t38 values(0,38) t39 values(0,39) t40 values(0,40) t41 values(0,41) t42 values(0,42) t43 values(0,43) t44 values(0,44) t45 values(0,45) t46 values(0,46) t47 values(0,47) t48 values(0,48) t49 values(0,49) t50 values(0,50) t51 values(0,51) t52 values(0,52) t53 values(0,53) t54 values(0,54) t55 values(0,55) t56 values(0,56) t57 values(0,57) t58 values(0,58) t59 values(0,59) t60 values(0,60) t61 values(0,61) t62 values(0,62) t63 values(0,63) t64 values(0,64) t65 values(0,65) t66 values(0,66) t67 values(0,67) t68 values(0,68) t69 values(0,69) t70 values(0,70) t71 values(0,71) t72 values(0,72) t73 values(0,73) t74 values(0,74) t75 values(0,75) t76 values(0,76) t77 values(0,77) t78 values(0,78) t79 values(0,79) t80 values(0,80) t81 values(0,81) t82 values(0,82) t83 values(0,83) t84 values(0,84) t85 values(0,85) t86 values(0,86) t87 values(0,87) t88 values(0,88) t89 values(0,89) t90 values(0,90) t91 values(0,91) t92 values(0,92) t93 values(0,93) t94 values(0,94) t95 values(0,95) t96 values(0,96) t97 values(0,97) t98 values(0,98) t99 values(0,99) **environment** - tdengine server os: ubuntu 18.04 - memory 4g - tdengine version 1.6.6.0
1 00000 00000 elect count(*) from chaojibiao b file orrupted 2 00000 0000 /var/lib/taos aos.cfg elect count(*) from chaojibiao b file orrupted elect count(*) from chaojibiao
i just downloaded tdengine-server-1.6.6.0-linux-x64.tar.gz, and install it with: ./install.sh, after that i ran: systemctl start taosd, then "taos", but the error is occured.
double free or corruption (!prev) eb
taos.dll
ts rice ty ava bean elect last_row(*) from esult head ast_row(ts) last_row(price) last_row(qty) ybatis ean
upgrade version 1.6.6.0 from version 1.6.5.6 esult of taoshell query is different from tdconnetor query?
~~~~~~~~~~~~~~~~~~~~~~~~~
result of taoshell query : 112|23|3|4
~~~~~~~~~~~~~~~~~~~~~~~
result of tdconnector query 1.334444555555456467e+25
6.978653786439856332e+24
elect * from table where tag='xxx' order by ts desc limit 1;
b error: too many results from vnodes for sort ssue #2260
1 maxnumoforderedres 0w ssue #2260
2 ast_row dbc ybatis ug ** **
1 rder by ts desc limit 1 axnumoforderedres ug
2 0w rder by limit aos axnumoforderedres ...... ow
when the number of records in the table exceeds 100,000, the following statement will report an error
![image](
0 240 * 4 w+ count -2
select count(*) from order_info where ts>='2020-06-01 00:00:00.000000'; // ok select count(*) from order_info; // taosd
implementation httpprocessdata is `block-mode`, which will break if request is received piece by piece.
with help of **curl/socat,** it can be reproduced as follows.
insert into test.t_1(ts, price) values(1591847933452, 0.00); // ok
insert into 'test.t_1'(ts, price) values(1591847933452, 0.00); // db error: invalid db
compile and run the c demo(tests/examples/c/demo.c) error emo.c 0 aos_errno() aos 2020-06-08
alter table m123 set tag c1=111;
a) taoshell escribe m123; b) taoshell elect lastrow(*) ,c1....
c) query.excute()---->select lastrow(*) ,c1....
ag 0min
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
query.excute()
alter table db_mrnost.m3683093s6 set tag cheii='33';
query ok, 0 row(s) in set (0.00024412s) check table: tag ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
alter table db_mrnost.m3683093s6 set tag cheii='33';
query ok, 0 row(s) in set (0.00024412s) check table ag
tests/pytest/query/filter.py failed at "select * from db.st where name like \'_econd\'"
ybatis+druid dengine nvalid resultset pointer ithub issue #1477 ockettype cp aos ava ava reate connection error, url: jdbc:taos://192.168.17.230:6020/manufacture, errorcode 79, state ailed to connect to server.
ockettype cp aos 05/25 17:21:14.484141 8077 7f322c709700 error utl failed to connect socket, ip:192.168.17.230, port:6030, reason: connection refused
java
![wrvl$dfqhyogg5% d%u)1pq](
db error: vg init failed happened.
when i execute some continuous query, failed at sql grammar error, that's ok
i continue test continuous query, some problem happened, the database crashed(crash log a is below) , i spend some time try to find out the reason, but i failed, after that, i upgrade the version from 1.6.5.7 to 1.6.5.9, and the database is working, then i check the log, i found the database still reload the bad grammar continuous query sql(error log b is below).
error mnd pshow: , type:14 vpeers-rsp, failed to get meta, code:76
java dbc ql
everytime when `?;` entered in tdengine shell, a runtime assertion arises.
in develop branch, commit to file may cause coredump.
b udo make
ql imit 10 offset 120; offset 20
win7
''
i want to build an arm-based taosdb, and i specified cmake_install_prefix, but the default path is still installed to / usr
my cross compilation environment is ubuntu
but the default behavior is to install the taosdb of the arm architecture to the / usr directory of ubuntu
is there any way for me to specify the installation path? so that i can copy the generated installation directory to the embedded system.
ystemctl start taosd.service
ystemctl status taosd
`cat "/var/log/taos/taosdlog.1"`
`03/20 10:28:01.883841 26781 7f4987f6d700 error tmr failed to create timer`
jdbctemplate.execute(" create database if not exists wzfdd5 ");
wzfdd5 | 20-03-18 14:40:28.303| 0| 0| 1| 10|3650,3650,3650 | 1000| 4096| 16384| 4.00000| 50| 3600| 1| 2|ms |ready |
according to official guide, can't make.
the java source code will always recompile even when no source code is modified.
1.run sql "select count(*) from mysupertable on server shell, taosd crashed
2.press ctrl+c, get debug info:
^ctaos: /home/ubuntu/release_workspace/tdinternal/community/src/client/src/tscserver.c:1159: tscretrievefromvnodecallback: assertion `pstate->numofcompleted < pstate->numoftotal && pstate->numofcompleted >= 0 && ppobj->numofsubs == pstate->numoftotal' failed.
taos: /home/ubuntu/release_workspace/tdinternal/community/src/client/src/tscserver.c:1159: tscretrievefromvnodecallback: assertion `pstate->numofcompleted < pstate->numoftotal && pstate->numofcompleted >= 0 && ppobj->numofsubs == pstate->numoftotal' failed.
aborted **environment : - os: ubuntu 16.4 - memory 32g, cpu, current disk space 400g - tdengine version: 1.6.5.5
[root@test-trace-other_app-020044 bin]# ./taosd -c /etc/taos/
02/20 07:35:27.066049 7066 7f6dca4b6700 utl timezone not configured, set to system default: (local time zone must be set--see zic manual page, +0000)
02/20 07:35:27.066079 7066 7f6dca4b6700 utl charset not configured, set to system default:utf-8
invalid locale:zh_cn.utf-8, please set the valid locale in config file
02/20 07:35:27.066148 7066 7f6dca4b6700 utl invalid locale:zh_cn.utf-8, please set the valid locale in config file 02/20 07:35:27.067886 7066 7f6dca4b6700 utl taos config & system info:
02/20 07:35:27.067901 7066 7f6dca4b6700 utl ==================================
02/20 07:35:27.067904 7066 7f6dca4b6700 utl localip: 100.73.20.44
02/20 07:35:27.067908 7066 7f6dca4b6700 utl httpip: 0.0.0.0
02/20 07:35:27.067911 7066 7f6dca4b6700 utl httpport: 6020
02/20 07:35:27.067914 7066 7f6dca4b6700 utl mgmtshellport: 6030
02/20 07:35:27.067916 7066 7f6dca4b6700 utl vnodeshellport: 6035
02/20 07:35:27.067919 7066 7f6dca4b6700 utl configdir: /etc/taos/
02/20 07:35:27.067921 7066 7f6dca4b6700 utl logdir: /var/log/taos
02/20 07:35:27.067931 7066 7f6dca4b6700 utl scriptdir: /etc/taos
02/20 07:35:27.067934 7066 7f6dca4b6700 utl datadir: /var/lib/taos
02/20 07:35:27.067936 7066 7f6dca4b6700 utl numofthreadspercore: 1.000000
02/20 07:35:27.067947 7066 7f6dca4b6700 utl ratioofquerythreads: 0.500000
02/20 07:35:27.067959 7066 7f6dca4b6700 utl numofvnodespercore: 8
02/20 07:35:27.067962 7066 7f6dca4b6700 utl numoftotalvnodes: 0
02/20 07:35:27.067964 7066 7f6dca4b6700 utl tables: 1000
02/20 07:35:27.067967 7066 7f6dca4b6700 utl cache: 16384(byte)
02/20 07:35:27.067969 7066 7f6dca4b6700 utl rows: 4096
02/20 07:35:27.067972 7066 7f6dca4b6700 utl fileblockminpercent: 0.050000
02/20 07:35:27.067975 7066 7f6dca4b6700 utl ablocks: 4
02/20 07:35:27.067977 7066 7f6dca4b6700 utl tblocks: 100
02/20 07:35:27.067980 7066 7f6dca4b6700 utl affectedrowsmod: 0
02/20 07:35:27.067982 7066 7f6dca4b6700 utl monitorinterval: 30(s)
02/20 07:35:27.067985 7066 7f6dca4b6700 utl rpctimer: 300(ms)
02/20 07:35:27.067987 7066 7f6dca4b6700 utl rpcmaxtime: 600(s)
02/20 07:35:27.067990 7066 7f6dca4b6700 utl ctime: 3600(s)
02/20 07:35:27.067992 7066 7f6dca4b6700 utl statusinterval: 1(s)
02/20 07:35:27.067994 7066 7f6dca4b6700 utl shellactivitytimer: 3(s)
02/20 07:35:27.067997 7066 7f6dca4b6700 utl metermetakeeptimer: 7200(s)
02/20 07:35:27.067999 7066 7f6dca4b6700 utl metricmetakeeptimer: 600(s)
02/20 07:35:27.068002 7066 7f6dca4b6700 utl maxusers: 1000
02/20 07:35:27.068004 7066 7f6dca4b6700 utl maxdbs: 1000
02/20 07:35:27.068006 7066 7f6dca4b6700 utl maxtables: 650000
02/20 07:35:27.068009 7066 7f6dca4b6700 utl maxvgroups: 1000
02/20 07:35:27.068011 7066 7f6dca4b6700 utl minslidingtime: 10(ms)
02/20 07:35:27.068014 7066 7f6dca4b6700 utl minintervaltime: 10(ms)
02/20 07:35:27.068016 7066 7f6dca4b6700 utl maxstreamcompdelay: 20000(ms)
02/20 07:35:27.068018 7066 7f6dca4b6700 utl maxfirststreamcompdelay:10000(ms)
02/20 07:35:27.068021 7066 7f6dca4b6700 utl retrystreamcompdelay: 10(ms)
02/20 07:35:27.068023 7066 7f6dca4b6700 utl clog: 1
02/20 07:35:27.068026 7066 7f6dca4b6700 utl comp: 2
02/20 07:35:27.068028 7066 7f6dca4b6700 utl days: 10
02/20 07:35:27.068031 7066 7f6dca4b6700 utl keep: 3650
02/20 07:35:27.068033 7066 7f6dca4b6700 utl defaultdb:
02/20 07:35:27.068036 7066 7f6dca4b6700 utl defaultuser: root
02/20 07:35:27.068038 7066 7f6dca4b6700 utl sockettype: udp
02/20 07:35:27.068041 7066 7f6dca4b6700 utl compressmsgsize: -1
02/20 07:35:27.068044 7066 7f6dca4b6700 utl maxsqllength: 65380(byte)
02/20 07:35:27.068046 7066 7f6dca4b6700 utl timezone: (local time zone must be set--see zic manual page, +0000)
02/20 07:35:27.068051 7066 7f6dca4b6700 utl locale: zh_cn.utf-8
02/20 07:35:27.068054 7066 7f6dca4b6700 utl charset: utf-8
02/20 07:35:27.068056 7066 7f6dca4b6700 utl maxshellconns: 2000
02/20 07:35:27.068059 7066 7f6dca4b6700 utl maxmeterconnections: 10000
02/20 07:35:27.068062 7066 7f6dca4b6700 utl maxmgmtconnections: 2000
02/20 07:35:27.068064 7066 7f6dca4b6700 utl maxvnodeconnections: 10000
02/20 07:35:27.068067 7066 7f6dca4b6700 utl minimallogdirgb: 0.100000(gb)
02/20 07:35:27.068069 7066 7f6dca4b6700 utl minimaltmpdirgb: 0.100000(gb)
02/20 07:35:27.068072 7066 7f6dca4b6700 utl minimaldatadirgb: 0.500000(gb)
02/20 07:35:27.068075 7066 7f6dca4b6700 utl http: 1
02/20 07:35:27.068077 7066 7f6dca4b6700 utl monitor: 1
02/20 07:35:27.068080 7066 7f6dca4b6700 utl monitordbname: log
02/20 07:35:27.068082 7066 7f6dca4b6700 utl httpcachesessions: 100
02/20 07:35:27.068091 7066 7f6dca4b6700 utl httpenablerecordsql: 0
02/20 07:35:27.068093 7066 7f6dca4b6700 utl telegrafusefieldnum: 0
02/20 07:35:27.068096 7066 7f6dca4b6700 utl httpmaxthreads: 2
02/20 07:35:27.068098 7066 7f6dca4b6700 utl restfulrowlimit: 10240
02/20 07:35:27.068101 7066 7f6dca4b6700 utl httpenablecompress: 0
02/20 07:35:27.068103 7066 7f6dca4b6700 utl numofloglines: 10000000
02/20 07:35:27.068105 7066 7f6dca4b6700 utl asynclog: 1
02/20 07:35:27.068108 7066 7f6dca4b6700 utl debugflag: 131
02/20 07:35:27.068110 7066 7f6dca4b6700 utl mdebugflag: 135
02/20 07:35:27.068113 7066 7f6dca4b6700 utl ddebugflag: 131
02/20 07:35:27.068120 7066 7f6dca4b6700 utl sdbdebugflag: 135
02/20 07:35:27.068123 7066 7f6dca4b6700 utl rpcdebugflag: 131
02/20 07:35:27.068125 7066 7f6dca4b6700 utl tmrdebugflag: 131
02/20 07:35:27.068127 7066 7f6dca4b6700 utl cdebugflag: 131
02/20 07:35:27.068130 7066 7f6dca4b6700 utl jnidebugflag: 131
02/20 07:35:27.068144 7066 7f6dca4b6700 utl odbcdebugflag: 131
02/20 07:35:27.068147 7066 7f6dca4b6700 utl udebugflag: 131
02/20 07:35:27.068150 7066 7f6dca4b6700 utl httpdebugflag: 131
02/20 07:35:27.068152 7066 7f6dca4b6700 utl monitordebugflag: 131
02/20 07:35:27.068159 7066 7f6dca4b6700 utl qdebugflag: 131
02/20 07:35:27.068162 7066 7f6dca4b6700 utl tscenablerecordsql: 0
02/20 07:35:27.068164 7066 7f6dca4b6700 utl enablecorefile: 0
02/20 07:35:27.068166 7066 7f6dca4b6700 utl gitinfo: 918cb2220f6a1f71966f7e94e697885d50fc241f
02/20 07:35:27.068169 7066 7f6dca4b6700 utl gitinfoofinternal:
02/20 07:35:27.068171 7066 7f6dca4b6700 utl buildinfo: built by root at 2020-02-09 11:06
02/20 07:35:27.068174 7066 7f6dca4b6700 utl version: 1.6.5.5
02/20 07:35:27.068176 7066 7f6dca4b6700 utl datadir: /var/lib/taos
02/20 07:35:27.068559 7066 7f6dca4b6700 utl os pagesize: 4096(kb)
02/20 07:35:27.068574 7066 7f6dca4b6700 utl os openmax: 65535
02/20 07:35:27.068578 7066 7f6dca4b6700 utl os streammax: 16
02/20 07:35:27.068582 7066 7f6dca4b6700 utl os numofcores: 4
02/20 07:35:27.068585 7066 7f6dca4b6700 utl os totaldisk: 44.697632(gb)
02/20 07:35:27.068594 7066 7f6dca4b6700 utl os totalmemory: 7872(mb)
02/20 07:35:27.068602 7066 7f6dca4b6700 utl os sysname: linux
02/20 07:35:27.068606 7066 7f6dca4b6700 utl os nodename: test-trace-other_app-020044
02/20 07:35:27.068609 7066 7f6dca4b6700 utl os release: 2.6.32-431.el6.x86_64
02/20 07:35:27.068613 7066 7f6dca4b6700 utl os version: #1 smp fri nov 22 03:15:09 utc 2013
02/20 07:35:27.068617 7066 7f6dca4b6700 utl os machine: x86_64
02/20 07:35:27.068621 7066 7f6dca4b6700 utl ==================================
02/20 07:35:27.068627 7066 7f6dca4b6700 dnd server ip address is:100.73.20.44
02/20 07:35:27.068636 7066 7f6dca4b6700 dnd starting to initialize tdengine ...
02/20 07:35:27.068814 7066 7f6dca4b6700 mnd starting to initialize tdengine mgmt ...
02/20 07:35:27.069485 7066 7f6dca4b6700 mnd dnode first access, set total vnodes:50
02/20 07:35:27.086101 7066 7f6dca4b6700 mnd tdengine mgmt is initialized successfully
02/20 07:35:27.088828 7066 7f6dca4b6700 dnd vid:0, cache pool is allocated:
02/20 07:35:27.089014 7066 7f6dca4b6700 dnd vid:0, commit log is initialized
02/20 07:35:27.089038 7066 7f6dca4b6700 dnd vid:0, storage initialized, version:407110 fileid:1831 numoffiles:4
02/20 07:35:27.089131 7066 7f6dca4b6700 dnd vid:1, cache pool is allocated:
02/20 07:35:27.089267 7066 7f6dca4b6700 dnd vid:1, commit log is initialized
02/20 07:35:27.089291 7066 7f6dca4b6700 dnd vid:1, storage initialized, version:9 fileid:1821 numoffiles:2
02/20 07:35:27.089371 7066 7f6dca4b6700 dnd vid:2, cache pool is allocated:
02/20 07:35:27.089527 7066 7f6dca4b6700 dnd vid:2, commit log is initialized
02/20 07:35:27.089547 7066 7f6dca4b6700 dnd vid:2, storage initialized, version:8009656 fileid:1822 numoffiles:3
02/20 07:35:27.089648 7066 7f6dca4b6700 dnd vid:3, cache pool is allocated:
02/20 07:35:27.089753 7066 7f6dca4b6700 dnd vid:3, commit log is initialized
02/20 07:35:27.089773 7066 7f6dca4b6700 dnd vid:3, storage initialized, version:73156 fileid:1821 numoffiles:1
02/20 07:35:27.089840 7066 7f6dca4b6700 dnd vid:4, cache pool is allocated:
02/20 07:35:27.089918 7066 7f6dca4b6700 dnd vid:4, commit log is initialized
02/20 07:35:27.089937 7066 7f6dca4b6700 dnd vid:4, storage initialized, version:39979 fileid:1821 numoffiles:1
02/20 07:35:27.090019 7066 7f6dca4b6700 dnd vid:5, cache pool is allocated:
02/20 07:35:27.090126 7066 7f6dca4b6700 dnd vid:5, commit log is initialized
02/20 07:35:27.090147 7066 7f6dca4b6700 dnd vid:5, storage initialized, version:971869 fileid:1821 numoffiles:1
02/20 07:35:27.090237 7066 7f6dca4b6700 dnd vid:6, cache pool is allocated:
02/20 07:35:27.090341 7066 7f6dca4b6700 dnd vid:6, commit log is initialized
02/20 07:35:27.090364 7066 7f6dca4b6700 dnd vid:6, storage initialized, version:38 fileid:1831 numoffiles:2
02/20 07:35:27.090441 7066 7f6dca4b6700 dnd vid:7, cache pool is allocated:
02/20 07:35:27.090575 7066 7f6dca4b6700 dnd vid:7, commit log is initialized
02/20 07:35:27.090597 7066 7f6dca4b6700 dnd vid:7, storage initialized, version:0 fileid:0 numoffiles:0
02/20 07:35:27.090676 7066 7f6dca4b6700 dnd vid:8, cache pool is allocated:
02/20 07:35:27.090766 7066 7f6dca4b6700 dnd vid:8, commit log is initialized
02/20 07:35:27.090780 7066 7f6dca4b6700 dnd vid:8, storage initialized, version:897189 fileid:1831 numoffiles:2
02/20 07:35:27.090855 7066 7f6dca4b6700 dnd vid:9, cache pool is allocated:
02/20 07:35:27.090968 7066 7f6dca4b6700 dnd vid:9, commit log is initialized
02/20 07:35:27.090997 7066 7f6dca4b6700 dnd vid:9, storage initialized, version:0 fileid:0 numoffiles:0
02/20 07:35:27.091068 7066 7f6dca4b6700 dnd vid:10, cache pool is allocated:
02/20 07:35:27.091197 7066 7f6dca4b6700 dnd vid:10, commit log is initialized
02/20 07:35:27.091221 7066 7f6dca4b6700 dnd vid:10, storage initialized, version:41005362 fileid:1831 numoffiles:2
02/20 07:35:27.091315 7066 7f6dca4b6700 dnd vid:11, cache pool is allocated:
02/20 07:35:27.091425 7066 7f6dca4b6700 dnd vid:11, commit log is initialized
02/20 07:35:27.091446 7066 7f6dca4b6700 dnd vid:11, storage initialized, version:1000 fileid:1792 numoffiles:4
02/20 07:35:27.091552 7066 7f6dca4b6700 dnd vid:12, cache pool is allocated:
02/20 07:35:27.091622 7066 7f6dca4b6700 dnd vid:12, commit log is initialized
02/20 07:35:27.091636 7066 7f6dca4b6700 dnd vid:12, storage initialized, version:0 fileid:0 numoffiles:0
02/20 07:35:27.091755 7066 7f6dca4b6700 dnd vid:13, cache pool is allocated:
02/20 07:35:27.091854 7066 7f6dca4b6700 dnd vid:13, commit log is initialized
02/20 07:35:27.091876 7066 7f6dca4b6700 dnd vid:13, storage initialized, version:22794965 fileid:1831 numoffiles:1
02/20 07:35:27.091946 7066 7f6dca4b6700 dnd vid:19, cache pool is allocated:
02/20 07:35:27.092031 7066 7f6dca4b6700 dnd vid:19, commit log is initialized
02/20 07:35:27.092046 7066 7f6dca4b6700 dnd vid:19, storage initialized, version:5337556 fileid:1821 numoffiles:3
02/20 07:35:27.092108 7066 7f6dca4b6700 dnd vid:22, cache pool is allocated:
02/20 07:35:27.092204 7066 7f6dca4b6700 dnd vid:22, commit log is initialized
02/20 07:35:27.092220 7066 7f6dca4b6700 dnd vid:22, storage initialized, version:1473 fileid:1821 numoffiles:2
02/20 07:35:27.092289 7066 7f6dca4b6700 dnd vid:34, cache pool is allocated:
02/20 07:35:27.092373 7066 7f6dca4b6700 dnd vid:34, commit log is initialized
02/20 07:35:27.092394 7066 7f6dca4b6700 dnd vid:34, storage initialized, version:42696 fileid:1821 numoffiles:2
02/20 07:35:27.092460 7066 7f6dca4b6700 dnd vid:35, cache pool is allocated:
02/20 07:35:27.092677 7066 7f6dca4b6700 dnd vid:35, commit log is initialized
02/20 07:35:27.092698 7066 7f6dca4b6700 dnd vid:35, storage initialized, version:3284903 fileid:1829 numoffiles:10
02/20 07:35:27.093130 7066 7f6dca4b6700 dnd vid:0, status:offline, start to open
02/20 07:35:27.093199 7066 7f6dca4b6700 dnd vid:0, sessions:33, shell is opened
02/20 07:35:27.093220 7066 7f6dca4b6700 dnd vid:0, status:master numofpeers:0
02/20 07:35:27.093233 7066 7f6dca4b6700 dnd vid:0, stream role is changed from stop to start
02/20 07:35:27.093256 7066 7f6dca4b6700 dnd vid:0, vnode is opened, openvnodes:1, status:master
02/20 07:35:27.093264 7066 7f6dca4b6700 dnd vid:1, status:offline, start to open
02/20 07:35:27.093337 7066 7f6dca4b6700 dnd vid:1, sessions:1001, shell is opened
02/20 07:35:27.093350 7066 7f6dca4b6700 dnd vid:1, status:master numofpeers:0
02/20 07:35:27.093357 7066 7f6dca4b6700 dnd vid:1, stream role is changed from stop to start
02/20 07:35:27.093369 7066 7f6dca4b6700 dnd vid:1, vnode is opened, openvnodes:2, status:master
02/20 07:35:27.093382 7066 7f6dca4b6700 dnd vid:2, status:offline, start to open
02/20 07:35:27.093431 7066 7f6dca4b6700 dnd vid:2, sessions:1001, shell is opened
02/20 07:35:27.093448 7066 7f6dca4b6700 dnd vid:2, status:master numofpeers:0
02/20 07:35:27.093456 7066 7f6dca4b6700 dnd vid:2, stream role is changed from stop to start
02/20 07:35:27.093468 7066 7f6dca4b6700 dnd vid:2, vnode is opened, openvnodes:3, status:master
02/20 07:35:27.093479 7066 7f6dca4b6700 dnd vid:3, status:offline, start to open
02/20 07:35:27.093568 7066 7f6dca4b6700 dnd vid:3, sessions:1001, shell is opened
02/20 07:35:27.093593 7066 7f6dca4b6700 dnd vid:3, status:master numofpeers:0
02/20 07:35:27.093604 7066 7f6dca4b6700 dnd vid:3, stream role is changed from stop to start
02/20 07:35:27.093618 7066 7f6dca4b6700 dnd vid:3, vnode is opened, openvnodes:4, status:master
02/20 07:35:27.093625 7066 7f6dca4b6700 dnd vid:4, status:offline, start to open
02/20 07:35:27.093662 7066 7f6dca4b6700 dnd vid:4, sessions:1001, shell is opened
02/20 07:35:27.093674 7066 7f6dca4b6700 dnd vid:4, status:master numofpeers:0
02/20 07:35:27.093681 7066 7f6dca4b6700 dnd vid:4, stream role is changed from stop to start
02/20 07:35:27.093693 7066 7f6dca4b6700 dnd vid:4, vnode is opened, openvnodes:5, status:master
02/20 07:35:27.093701 7066 7f6dca4b6700 dnd vid:5, status:offline, start to open
02/20 07:35:27.093748 7066 7f6dca4b6700 dnd vid:5, sessions:1001, shell is opened
02/20 07:35:27.093769 7066 7f6dca4b6700 dnd vid:5, status:master numofpeers:0
02/20 07:35:27.093794 7066 7f6dca4b6700 dnd vid:5, stream role is changed from stop to start
02/20 07:35:27.093809 7066 7f6dca4b6700 dnd vid:5, vnode is opened, openvnodes:6, status:master
02/20 07:35:27.093826 7066 7f6dca4b6700 dnd vid:6, status:offline, start to open
02/20 07:35:27.093872 7066 7f6dca4b6700 dnd vid:6, sessions:1001, shell is opened
02/20 07:35:27.093884 7066 7f6dca4b6700 dnd vid:6, status:master numofpeers:0
02/20 07:35:27.093891 7066 7f6dca4b6700 dnd vid:6, stream role is changed from stop to start
02/20 07:35:27.093904 7066 7f6dca4b6700 dnd vid:6, vnode is opened, openvnodes:7, status:master
02/20 07:35:27.093916 7066 7f6dca4b6700 dnd vid:7, status:offline, start to open
02/20 07:35:27.093970 7066 7f6dca4b6700 dnd vid:7, sessions:1001, shell is opened
02/20 07:35:27.093986 7066 7f6dca4b6700 dnd vid:7, status:master numofpeers:0
02/20 07:35:27.093993 7066 7f6dca4b6700 dnd vid:7, stream role is changed from stop to start
02/20 07:35:27.094006 7066 7f6dca4b6700 dnd vid:7, vnode is opened, openvnodes:8, status:master
02/20 07:35:27.094012 7066 7f6dca4b6700 dnd vid:8, status:offline, start to open
02/20 07:35:27.094060 7066 7f6dca4b6700 dnd vid:8, sessions:1001, shell is opened
02/20 07:35:27.094077 7066 7f6dca4b6700 dnd vid:8, status:master numofpeers:0
02/20 07:35:27.094095 7066 7f6dca4b6700 dnd vid:8, stream role is changed from stop to start
02/20 07:35:27.094122 7066 7f6dca4b6700 dnd vid:8, vnode is opened, openvnodes:9, status:master
02/20 07:35:27.094138 7066 7f6dca4b6700 dnd vid:9, status:offline, start to open
02/20 07:35:27.094190 7066 7f6dca4b6700 dnd vid:9, sessions:1001, shell is opened
02/20 07:35:27.094205 7066 7f6dca4b6700 dnd vid:9, status:master numofpeers:0
02/20 07:35:27.094211 7066 7f6dca4b6700 dnd vid:9, stream role is changed from stop to start
02/20 07:35:27.094225 7066 7f6dca4b6700 dnd vid:9, vnode is opened, openvnodes:10, status:master
02/20 07:35:27.094236 7066 7f6dca4b6700 dnd vid:10, status:offline, start to open
02/20 07:35:27.094287 7066 7f6dca4b6700 dnd vid:10, sessions:1001, shell is opened
02/20 07:35:27.094307 7066 7f6dca4b6700 dnd vid:10, status:master numofpeers:0
02/20 07:35:27.094316 7066 7f6dca4b6700 dnd vid:10, stream role is changed from stop to start
02/20 07:35:27.094341 7066 7f6dca4b6700 dnd vid:10, vnode is opened, openvnodes:11, status:master
02/20 07:35:27.094350 7066 7f6dca4b6700 dnd vid:11, status:offline, start to open
02/20 07:35:27.094388 7066 7f6dca4b6700 dnd vid:11, sessions:1001, shell is opened
02/20 07:35:27.094398 7066 7f6dca4b6700 dnd vid:11, status:master numofpeers:0
02/20 07:35:27.094404 7066 7f6dca4b6700 dnd vid:11, stream role is changed from stop to start
02/20 07:35:27.094417 7066 7f6dca4b6700 dnd vid:11, vnode is opened, openvnodes:12, status:master
02/20 07:35:27.094433 7066 7f6dca4b6700 dnd vid:12, status:offline, start to open
02/20 07:35:27.094463 7066 7f6dca4b6700 dnd vid:12, sessions:1001, shell is opened
02/20 07:35:27.094481 7066 7f6dca4b6700 dnd vid:12, status:master numofpeers:0
02/20 07:35:27.094490 7066 7f6dca4b6700 dnd vid:12, stream role is changed from stop to start
02/20 07:35:27.094548 7066 7f6dca4b6700 dnd vid:12, vnode is opened, openvnodes:13, status:master
02/20 07:35:27.094580 7066 7f6dca4b6700 dnd vid:13, status:offline, start to open
02/20 07:35:27.094637 7066 7f6dca4b6700 dnd vid:13, sessions:1001, shell is opened
02/20 07:35:27.094667 7066 7f6dca4b6700 dnd vid:13, status:master numofpeers:0
02/20 07:35:27.094677 7066 7f6dca4b6700 dnd vid:13, stream role is changed from stop to start
02/20 07:35:27.094694 7066 7f6dca4b6700 dnd vid:13, vnode is opened, openvnodes:14, status:master
02/20 07:35:27.094709 7066 7f6dca4b6700 dnd vid:19, status:offline, start to open
02/20 07:35:27.094768 7066 7f6dca4b6700 dnd vid:19, sessions:1001, shell is opened
02/20 07:35:27.094789 7066 7f6dca4b6700 dnd vid:19, status:master numofpeers:0
02/20 07:35:27.094798 7066 7f6dca4b6700 dnd vid:19, stream role is changed from stop to start
02/20 07:35:27.094822 7066 7f6dca4b6700 dnd vid:19, vnode is opened, openvnodes:15, status:master
02/20 07:35:27.094838 7066 7f6dca4b6700 dnd vid:22, status:offline, start to open
02/20 07:35:27.094886 7066 7f6dca4b6700 dnd vid:22, sessions:1001, shell is opened
02/20 07:35:27.094904 7066 7f6dca4b6700 dnd vid:22, status:master numofpeers:0
02/20 07:35:27.094913 7066 7f6dca4b6700 dnd vid:22, stream role is changed from stop to start
02/20 07:35:27.094943 7066 7f6dca4b6700 dnd vid:22, vnode is opened, openvnodes:16, status:master
02/20 07:35:27.094967 7066 7f6dca4b6700 dnd vid:34, status:offline, start to open
02/20 07:35:27.095021 7066 7f6dca4b6700 dnd vid:34, sessions:1001, shell is opened
02/20 07:35:27.095040 7066 7f6dca4b6700 dnd vid:34, status:master numofpeers:0
02/20 07:35:27.095049 7066 7f6dca4b6700 dnd vid:34, stream role is changed from stop to start
02/20 07:35:27.095072 7066 7f6dca4b6700 dnd vid:34, vnode is opened, openvnodes:17, status:master
02/20 07:35:27.095088 7066 7f6dca4b6700 dnd vid:35, status:offline, start to open
02/20 07:35:27.095146 7066 7f6dca4b6700 dnd vid:35, sessions:1001, shell is opened
02/20 07:35:27.095172 7066 7f6dca4b6700 dnd vid:35, status:master numofpeers:0
02/20 07:35:27.095182 7066 7f6dca4b6700 dnd vid:35, stream role is changed from stop to start
02/20 07:35:27.095213 7066 7f6dca4b6700 dnd vid:35, vnode is opened, openvnodes:18, status:master
02/20 07:35:27.095244 7066 7f6dca4b6700 dnd vnode is initialized successfully
02/20 07:35:27.095262 7066 7f6dca4b6700 htp starting to initialize http service ...
02/20 07:35:27.097965 7066 7f6dca4b6700 dnd tdengine is initialized successfully
02/20 07:35:27.098013 7066 7f6d110da700 htp http service init success at ip:0.0.0.0:6020
02/20 07:35:27.109646 7066 7f6dc67cb700 mon starting to initialize monitor service ..
02/20 07:35:27.109920 7066 7f6dc8630700 mnd user:monitor login from 100.73.20.44, code:0
(core dumped) ![](
the build script itself, when building the software, actually tries to "install" java artifacts into my home directory outside the build directories
i followed the documentation to build the software, and then tried the commands in the "quick run" section, but am unable to figure out exactly what to run, and what result i should be getting.
000 00w
1 aos shell
2 ancle drop atabase
i'm trying to migrate our database from mongodb to tdengine.
my application base on node.js, thanks for your efforts, tdengine already have node.js connectors.
according to the documentation of the tdengine's node.js connector, we run the following command
`install td-connector --save`
the installation could not be finished, the error message in terminal: ```shell
binding.target.mk:109: recipe for target 'release/obj.target/binding/src/binding.o' failed
make: *** [release/obj.target/binding/src/binding.o] error 1
make: leaving directory '/home/clint/git/mongo2tdengine/node_modules/ref/build'
gyp err! build error gyp err! stack error: `make` failed with exit code: 2
gyp err! stack at childprocess.onexit (/home/clint/.nvm/versions/node/v12.14.1/lib/node_modules/npm/node_modules/node-gyp/lib/build.js:194:23)
gyp err! stack at childprocess.emit (events.js:223:5)
gyp err! stack at process.childprocess._handle.onexit (internal/child_process.js:272:12)
gyp err! system linux 4.15.0-76-generic
gyp err! command "/home/clint/.nvm/versions/node/v12.14.1/bin/node" "/home/clint/.nvm/versions/node/v12.14.1/lib/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js" "rebuild"
gyp err! cwd /home/clint/git/mongo2tdengine/node_modules/ref
gyp err! node -v v12.14.1
gyp err! node-gyp -v v5.0.5
gyp err! not ok npm warn mongo2tdengine@1.0.0 no repository field.
npm err! code elifecycle
npm err! errno 1
npm err! ref@1.3.5 install: `node-gyp rebuild`
npm err! exit status 1
npm err! npm err! failed at the ref@1.3.5 install script.
npm err! this is probably not a problem with npm
there is likely additional logging output above.
npm err! a complete log of this run can be found in:
npm err! /home/clint/.npm/_logs/2020-02-03t08_38_25_491z-debug.log
**i have tried some approaches according to existing issues**( the follows commands are what i have tried, it was useless:
`node-gyp rebuild`
`npm install`
`npm clean-install` i'm sure node-gyp, gcc and python 2.7 are installed, and `taos` was active.
diff function failed to return correct result when handling the bigint/float/double column in desc order query
the results rows needs to more than the number of rows in one block.
in document [python-connector]( #python-connector) he example miss '
`print("row%d: ts=%s, temperature=%d, humidity=%f" %(irow, data[irow][0], data[irow][1],data[irow][2])`
nsert 50 0
![ 2020-01-12 172707](
dbc dengine 6
asynchronous insertion cause the client crash
the new thread has release the sqlobj, and continue use this sqlobj will cause client crash.
i failed to build version accord document [tdengine arm-64 ](
the query engine failed to generate correct result with respect to the sliding like :
interval(1m) sliding(5s), when the sliding is not aligned with the query time window
select count(*) from table_name interval(1m) sliding (5s);
select last(sjsj) as sjsj aosd crash
for the shell of taos, during the invoking of the ```source``` command, check the extence before checking if it is readable
and add one more error message.
the source file is tdengine/src/rpc/src/ttcpserver.c
line 471, 1st parameter of sprintf( ) is missing
code pasted: while (pfdobj) { sprintf(" ip:%s port:%hu\ ", pfdobj->ipstr, pfdobj->port); msg = msg + strlen(msg); numoffds++; numofconns++; pfdobj = pfdobj->next; }
filter on all null value cause the server crashed apply the filter condition to the null column of bigint data type if the null block is more than 1 block
there server will crashed due to the assert check failure.
group by on normal columns may result in taosd crashed.
create database sample;
use sample;
create table temp_stable (ts timestamp, temperature float, humidity tinyint, status tinyint) tags(deviceid binary(12), location binary(20));
create table pressure_stable(ts timestamp, height float, pressure float, devstat tinyint) tags(id bigint, city nchar(20), longitude float, latitude float);
create table temp_tb_1 using temp_stable tags('u879abef', 'beijing');
create table temp_tb_2 using temp_stable tags('u98601ab', 'beijing'); create table press_tb_1 using pressure_stable tags(91234, 'haidian', 116.333, 39.969);
create table press_tb_2 using pressure_stable tags(54197, 'chaoyang',116.411, 40.007); insert into temp_tb_1 values('2019-4-28 14:22:07', 20, 34, 1);
insert into temp_tb_2 values('2019-4-28 14:22:07', 21, 37, 1);
insert into temp_tb_1 values('2019-4-28 14:22:08', 21.5, 38, 1);
insert into temp_tb_1 values('2019-4-28 14:22:09', 21.3, 38, 1);
insert into temp_tb_1 values('2019-4-28 14:22:10', 21.2, 38, 1);
insert into temp_tb_1 values('2019-4-28 14:22:11', 21.3, 35, 0);
insert into temp_tb_1 values('2019-4-28 14:22:12', 22.0, 34, 0);
select status, count(*) as num from temp_stable group by status;
repeatly issue the query sql, and there is a chance that the taosd will crash.
the function in question is taosprocessalarmsignal( ) tdengine/src/os/linux/src/tlinux.c
the last 2 lines before "}", return null will never run because the function will exit at assert(0), so the function will have no return value, which is expected to be void *
without a return value, it may result in undefined behavior.
auth aosd auth ```js
{ "status": "error", "code": 1011, "desc": "no auth info input"
``` 1.6.4.3 wsl wsl 1.6.3.0
add the detailed error information for the following two kinds of sql error:
select max(tbname) from super_table_name
select * from super_table group by tag_columns;
taosd op a aos sof aosd , 5548 aosdlog.0 oo many open files
linux gyp err! cwd /home/ksl/node_modules/ffi/node_modules/ref
gyp err! node -v v12.13.0
gyp err! node-gyp -v v5.0.5
gyp err! not ok npm warn enoent enoent: no such file or directory, open '/home/ksl/package.json'
npm warn ksl no description
warn ksl no repository field.
npm warn ksl no readme data
npm warn ksl no license field.
npm err! code elifecycle
npm err! errno 1
npm err! ref@1.3.5 install: `node-gyp rebuild`
npm err! exit status 1npm err! npm err! failed at the ref@1.3.5 install script.npm err! this is probably not a problem with npm
there is likely additional logging output above.
npm err! a complete log of this run can be found in:
npm err! /home/ksl/.npm/_logs/2019-12-13t17_33_58_035z-debug.log windows c:\\windows\\system32\ ode_modules\ ef>if not defined npm_config_node_gyp (node "d
:\\software\ odejs\ ode_modules\ pm\ ode_modules\ pm-lifecycle\ ode-gyp-bin\\\\..\\.
.\ ode_modules\ ode-gyp\\bin\ ode-gyp.js" rebuild ) else (node "d:\\software\ ode
js\ ode_modules\ pm\ ode_modules\ ode-gyp\\bin\ ode-gyp.js" rebuild )
msbuild : error msb1009:
:build/binding.sln
gyp err! build error
gyp err! stack error: `d:\\software\\microsoft visual studio\\2017\\community\\msbuil
d\\15.0\\bin\\msbuild.exe` failed with exit code: 1
gyp err! stack at childprocess.onexit (d:\\software\ odejs\ ode_modules\ pm\
ode_modules\ ode-gyp\\lib\\build.js:194:23)
gyp err! stack at childprocess.emit (events.js:210:5)
gyp err! stack at process.childprocess._handle.onexit (internal/child_proces
s.js:272:12)
gyp err! system windows_nt 6.1.7601
gyp err! command "d:\\\\software\\\ odejs\\\ ode.exe" "d:\\\\software\\\ odejs\\\ ode_mo
dules\\\ pm\\\ ode_modules\\\ ode-gyp\\\\bin\\\ ode-gyp.js" "rebuild"
gyp err! cwd c:\\windows\\system32\ ode_modules\ ef
gyp err! node -v v12.13.1
gyp err! node-gyp -v v5.0.5
gyp err! not ok
npm warn system32@1.0.0 no description
npm warn system32@1.0.0 no repository field
npm err! code elifecycle
npm err! errno 1
npm err! ref@1.3.5 install: `node-gyp rebuild`
npm err! exit status 1
npm err! failed at the ref@1.3.5 install script.
npm err! this is probably not a problem with npm
there is likely additional log
ging output above
npm err! a complete log of this run can be found in:
npm err! d:\\software\ odejs\ ode_cache\\_logs\\2019-12-13t09_41_22_345z-debug.
taos err=invalid sql: syntax error near "lear:30:27"]##1575958344356220@#http.retry@#0##1575958344356220" (invalid data or symbol)
welcome to the tdengine shell from linux, community client version:1.6.4.3 community server version:1.6.4.3
copyright (c) 2017 by taos data, inc
all rights reserved
taos> select count(*) from single ; count(*) |
====================== 1541267|
query ok, 1 row(s) in set (0.011454s) taos> select max(cmis_servo_m12v_power) from single; db error: failed to connect to server
taos> ``` cmis_servo_m12v_power loat vg in ax 50w 99 imit 100
![qq 0191206183149](
find several bugs not handling standard library errors
the source code is src/client/src/tscprofile.c : 98 char *sql = malloc(200); ##potential risk: the return value may be null 2
the source code is src/client/src/tscprofile.c : 100 int len = snprintf(sql, 200, "insert into %s.slowquery values(now, \'%s\', %lld, %lld, \'", tsmonitordbname, psql->ptscobj->user, psql->stime, psql->res.useconds); ##potential risk: the return value may be negative reference:
dereference a null pointer, thereby causing a segmentation fault
**the source file is src\\client\\src\\tscasync.c**
![image]( **the code pasted here for quick reference.**
static void tscprocessasyncretrieveimpl(void *param, taos_res *tres, int numofrows, void (*fp)()) { ssqlobj *psql = (ssqlobj *)tres; if (psql == null) { // error tscerror("sql object is null"); tscqueueasyncerror(psql->fetchfp, param); return; }
.\\tdengine-develop\\src\\util\\src\\ttimer.c has:
![image]( **timer is free by removetimer(),but it is reused at tmrtrace
heap memory is assessed after it has been freed
use of the original pointer or the memory location is now accessing illegal memory and will cause denial of service or remote execution** **the code is pasted here for quick reference:**
static bool dostoptimer(tmr_obj_t* timer, uint8_t state) { if (state == timer_state_waiting) { bool reusable = false; if (removefromwheel(timer)) { removetimer(timer->id); // only safe to reuse the timer when timer is removed from the wheel
// we cannot guarantee the thread safety of the timr in all other cases
reusable = true; } const char* fmt = "%s timer[id=" priuptr ", fp=%p, param=%p] is cancelled."; tmrtrace(fmt, timer->ctrl->label, timer->id, timer->fp, timer->param); return reusable; }
there are issues in format string used in printf/scanf/snprintf..
ths would case illegal read of write out of bound or output difference
the code in question is .\\tdengine-develop\\src\\client\\src\\tscsqlparser.c **the declare:**
void getrevisedname(char* resultfieldname, int32_t functionid, int32_t maxlen, char* columnname) { snprintf(resultfieldname, maxlen, "%s(%s)", aaggs[functionid].aname, columnname);
} **the caller is below:** getrevisedname(columnname, functionid, tsdb_col_name_len, pschema[pcolindex->columnindex].name); in this case, variable columnname is an array with size sdb_col_name_len , but pschema[idx].name is also an array with size sdb_col_name_len
also, the second arguments for snprintf() - axlen s also sdb_col_name_len , but the snprintf() must assure the last char of maximum resultfieldname is \\0
so, whatever aaggs[functionid].aname, it most possible to get an error output for resultfieldname.
there are 2 declaration with the same function name mgmtcheckmeterlimit, but the one with 2 arguments is not implemented, but called.
int mgmtcheckmeterlimit(sacctobj *pacct, screatetablemsg *pcreate);
int mgmtcheckmeterlimit(sacctobj *pacct) { return 0; }
1.6.4.0 \\' 1.6.3.0 \\' 1.6.4.0 (string data overflow)
1.6.3.0
an import to old data on file may cause service coredump
sim script: lite/alter/import.sim
client gets error message "failed to connect to server", taosd stop accepting new insert requests
oom
sudo systemctl start taosd
taosd.service - tdengine server service loaded: loaded (/etc/systemd/system/taosd.service; enabled; vendor preset: disabled) active: failed (result: start-limit) since sat 2019-11-30 12:37:51 cst; 13min ago process: 11546 execstart=/usr/bin/taosd (code=dumped, signal=segv) main pid: 11546 (code=dumped, signal=segv) nov 30 12:37:50 spider04 systemd[1]: taosd.service: main process exited, code=dumped, status=11/segv
nov 30 12:37:50 spider04 systemd[1]: unit taosd.service entered failed state.
nov 30 12:37:50 spider04 systemd[1]: taosd.service failed.
nov 30 12:37:51 [spider04](`url`) systemd[1]: taosd.service holdoff time over, scheduling restart.
nov 30 12:37:51 spider04 systemd[1]: stopped tdengine server service.
nov 30 12:37:51 spider04 systemd[1]: start request repeated too quickly for taosd.service
nov 30 12:37:51 spider04 systemd[1]: failed to start tdengine server service.
nov 30 12:37:51 spider04 systemd[1]: unit taosd.service entered failed state.
nov 30 12:37:51 spider04 systemd[1]: taosd.service failed.
affected rows
ffected rows insert rows ** **
![ ](
![ ](
![ ](
** **
![ ](
** **
![ ](
there are numerous bad characters in the documentation
![ ](
ruid , : `
15:32:57.225 [main] warn com.alibaba.druid.pool.druiddatasource - removeabandoned is true, not use in production.
15:32:57.232 [main] error com.alibaba.druid.pool.druiddatasource - testonborrow is true, testonreturn is true, testwhileidle is true, validationquery not set
15:32:57.305 [main] error com.alibaba.druid.pool.druiddatasource - {datasource-1} init error
java.lang.arrayindexoutofboundsexception: 1 at com.taosdata.jdbc.tsdbdriver.parseurl(tsdbdriver.java:282) at com.taosdata.jdbc.tsdbdriver.connect(tsdbdriver.java:128) at com.alibaba.druid.filter.filterchainimpl.connection_connect(filterchainimpl.java:156) at com.alibaba.druid.filter.stat.statfilter.connection_connect(statfilter.java:218) at com.alibaba.druid.filter.filterchainimpl.connection_connect(filterchainimpl.java:150) at com.alibaba.druid.pool.druidabstractdatasource.createphysicalconnection(druidabstractdatasource.java:1645) at com.alibaba.druid.pool.druidabstractdatasource.createphysicalconnection(druidabstractdatasource.java:1709) at com.alibaba.druid.pool.druiddatasource.init(druiddatasource.java:932) at com.alibaba.druid.pool.druiddatasource.getconnection(druiddatasource.java:1369) at com.alibaba.druid.pool.druiddatasource.getconnection(druiddatasource.java:1365) at cn.meirenji.core.service.testtdenginedruid.main(testtdenginedruid.java:68)
exception in thread "main" java.lang.arrayindexoutofboundsexception: 1 at com.taosdata.jdbc.tsdbdriver.parseurl(tsdbdriver.java:282) at com.taosdata.jdbc.tsdbdriver.connect(tsdbdriver.java:128) at com.alibaba.druid.filter.filterchainimpl.connection_connect(filterchainimpl.java:156) at com.alibaba.druid.filter.stat.statfilter.connection_connect(statfilter.java:218) at com.alibaba.druid.filter.filterchainimpl.connection_connect(filterchainimpl.java:150) at com.alibaba.druid.pool.druidabstractdatasource.createphysicalconnection(druidabstractdatasource.java:1645) at com.alibaba.druid.pool.druidabstractdatasource.createphysicalconnection(druidabstractdatasource.java:1709) at com.alibaba.druid.pool.druiddatasource.init(druiddatasource.java:932) at com.alibaba.druid.pool.druiddatasource.getconnection(druiddatasource.java:1369) at com.alibaba.druid.pool.druiddatasource.getconnection(druiddatasource.java:1365) at cn.meirenji.core.service.testtdenginedruid.main(testtdenginedruid.java:68)
imported rows is 0 although there are some valid rows to be imported
key maybe messed up too, it causes the system to generate tons of files
if a database has a big name over 30 characters, it cannot be deleted.but drop command return a ok.
import code [here]( #l375) only reserve space for data not including checksum part
when the data is written to file, if the data part cannot be compressed, the checksum part can be overwritten [here]( #l1244).
windows olang driver aos_connect() fail!
indows taos.exe
golang driver dsn oot:taosdata@tcp(172.16.35.46:60300)/db
taos.exe taos.exe -h 172.16.35.46 -p 60300
![qq 0191114203708](
![qq 0191114203828](
make error with linux 2.6.32-431.el6.x86_64 cd /usr/local/ashe/tdengine/build && /usr/bin/cmake -e cmake_depends "unix makefiles" /usr/local/ashe/tdengine /usr/local/ashe/tdengine/src/os/linux /usr/local/ashe/tdengine/build /usr/local/ashe/tdengine/build/src/os/linux /usr/local/ashe/tdengine/build/src/os/linux/cmakefiles/os.dir/dependinfo.cmake --color=
scanning dependencies of target os
gmake[2]: leaving directory `/usr/local/ashe/tdengine/build'
/usr/bin/gmake -f src/os/linux/cmakefiles/os.dir/build.make src/os/linux/cmakefiles/os.dir/build
gmake[2]: entering directory `/usr/local/ashe/tdengine/build'
/usr/bin/cmake -e cmake_progress_report /usr/local/ashe/tdengine/build/cmakefiles 12
[ 11%] building c object src/os/linux/cmakefiles/os.dir/src/tlinux.c.o
cd /usr/local/ashe/tdengine/build/src/os/linux && /usr/bin/cc -dlinux -d_libc_reentrant -d_m_x64 -d_reentrant -d__use_posix -g -std=gnu99 -wall -fpic -malign-double -g -wno-char-subscripts -malign-stringops -msse4.2 -d_file_offset_bits=64 -d_large_file -o0 -ddebug -i/usr/local/ashe/tdengine/src/os/linux/inc -i/usr/local/ashe/tdengine/src/inc -o cmakefiles/os.dir/src/tlinux.c.o -c /usr/local/ashe/tdengine/src/os/linux/src/tlinux.c
/usr/local/ashe/tdengine/src/os/linux/src/tlinux.c: __sync_val_load_32 :
/usr/local/ashe/tdengine/src/os/linux/src/tlinux.c:345: __atomic_load_n
/usr/local/ashe/tdengine/src/os/linux/src/tlinux.c:345: __atomic_acquire ( )
/usr/local/ashe/tdengine/src/os/linux/src/tlinux.c:345: (
/usr/local/ashe/tdengine/src/os/linux/src/tlinux.c:345: )
/usr/local/ashe/tdengine/src/os/linux/src/tlinux.c: __sync_val_restore_32 :
/usr/local/ashe/tdengine/src/os/linux/src/tlinux.c:349: __atomic_store_n
/usr/local/ashe/tdengine/src/os/linux/src/tlinux.c:349: __atomic_release ( )
gmake[2]: *** [src/os/linux/cmakefiles/os.dir/src/tlinux.c.o] 1
gmake[2]: leaving directory `/usr/local/ashe/tdengine/build'
gmake[1]: leaving directory `/usr/local/ashe/tdengine/build'
gmake[1]: *** [src/os/linux/cmakefiles/os.dir/all] 2
gmake: *** [all] 2
`select avg(vol_c),max(vol_c),min(vol_c) from fmex.btc_p_info where ts<now interval(3m) order by ts desc limit 10;` 30w
sql aosd
log data efaultpass
taosd: /mnt/hgfs/work/tdengine/src/system/src/vnodequeryimpl.c:1297: validatequeryrangeanddata: assertion `(startkey >= pquery->lastkey && startkey <= pquery->ekey && pquery->skey <= pquery->lastkey && query_is_asc_query(pquery)) || (startkey <= pquery->lastkey && startkey >= pquery->ekey && pquery->skey >= pquery->lastkey && !query_is_asc_query(pquery))' failed.
no client can connect to server since no free sessions available
1: tranid may be set to 0
2: system api send may crash in multi-thread scenarios
3: tcp connection may have been already released when app wants to close it
non-atomic allocating cache block and inserting data into cache block cause the check data in cache failure.
query failed with the error message "corrupted head file"
rpc module frees the msg body while other threads still access that struct to cause the sigsegv error.
1 indows 10 aos shell elect last(*) from aos shell elect last(*) from ast_row irst
2 aos server entos aos shell ast ast_row irst
dengine 020 cp p
error when monitor initialize monitor service error code : -28
create database if not exists log ....
a b estful b a
`import into table_name file '~/a_csv_format_file` may cause the shell crash.
### 8
![image](
###
![image](
td-connector insert data into taosdatd ,alert error sometimes create tables with st_tablename :
insert into `${dataname}` using st_tablename values(file1,file2,file3...);====>tderror.databaseerror.programmingerror:-48; create tables without st_tablename :+1: insert into `${dataname}` values(file1,file2,file3...);====> ok when column(binary) includ "" or "^" or else ======> tderror.databaseerror.programmingerror:--64 or 112; alert err sometime
the null-terminated `\\0` of a binary/nchar column data may be put into final string by `taos_print_row`
so the final string may be incorrect
> create table tut(ts timestamp, k binary(1), a binary(1), c binary(1), k1 int);
> insert into tut values(1570715947978, '1', 'a', 'b', 9);
> select * from tut; `taos_print_row` function produces an error final result string.
> 1570715947978 1 while the correct string is: >1570715947978 1 a b 9
i'm using taos.dll for my .net application to insert massive data into tdenging database
everything looks fine as the application started
but after running for about 46 hours, the application hangs up
by stepping into the code, i figured out the problem was caused by calling taos_query method in taos.dll, taos_query blocked like forever.
i've tried to solve this problem by restarting the application, it doesn't work, taos_query blocked at the first call
restarting tdenging database can solve it, but with serious side effect witch is another issue i'll discuss later
.net aos.dll denging 6 aos.dll aos_query
aos_query dengine -
the service won't start
it shows failed
timestamp limits on tdengine server version:1.6.2.2
when doing `make install` inside a docker environment with ubuntu 16.04 or 18.04 image, the `make_install.sh` always try to install sysvinit service which is not needed inside a docker environment
since the init service is not installed, the `make_install.sh` always raise errors and stop running
after i comment the `install_service` function inside the script
all is done.
memory leak happens when parsing a invalid create table sql string
input the following sql: "create table t1 (ts timestamp,t2 binary(30),\\u2028mrn int,\\u2028ptname binary(20)) tags(type int)" memory leak detected by valgrind.
failed to set the error code if client (taos) version is not matched with server(taosd) version
![ 2019-09-27 37 37](
telegraf failed to write data to tdengin.
indow elect count(*) from lient no disk space
.0.1 dbcdriver ar aven river ,
able-schema table ables
uery
![image](
6 6:03:28
![image](
query
![image](
onsole
![image](
uery mport atch 250 4k **environment - os: ubuntu 16.04.1 - tdengine version [1.6.1.7]
raise programmingerror(ctaosinterface.errstr(self._connection._conn))
taos.error.programmingerror: db file corrupted
centos7.6 emove.sh dengine
ql :
import into t_306678704044507136(state_timestamp, state_type, state_active, state_delay)values(1567102667000, 3, 0, 0);
import into t_306678704044507136(state_timestamp, state_type, state_active, state_delay)values(1567102739000, 2, 0, 0);
2019-08-30 14:51:40.477 [dubboserverhandler-10.0.0.101:35401-thread-100] error cn.meirenji.data.service.impl.datatdengineserviceimpl - dengine
java.sql.sqlexception: tdengine error: timestamp out of range at com.taosdata.jdbc.tsdbjniconnector.executequery(tsdbjniconnector.java:129) at com.taosdata.jdbc.tsdbstatement.executeupdate(tsdbstatement.java:69) at com.taosdata.jdbc.tsdbpreparedstatement.executeupdate(tsdbpreparedstatement.java:142) at cn.meirenji.data.service.impl.datatdengineserviceimpl.savedevicestate(datatdengineserviceimpl.java:380) at com.alibaba.dubbo.common.bytecode.wrapper8.invokemethod(wrapper8.java) at com.alibaba.dubbo.rpc.proxy.javassist.javassistproxyfactory$1.doinvoke(javassistproxyfactory.java:45) at com.alibaba.dubbo.rpc.proxy.abstractproxyinvoker.invoke(abstractproxyinvoker.java:71) at com.alibaba.dubbo.config.invoker.delegateprovidermetadatainvoker.invoke(delegateprovidermetadatainvoker.java:48) at com.alibaba.dubbo.rpc.protocol.invokerwrapper.invoke(invokerwrapper.java:52) at com.alibaba.dubbo.rpc.filter.exceptionfilter.invoke(exceptionfilter.java:61) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.monitor.support.monitorfilter.invoke(monitorfilter.java:74) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.filter.timeoutfilter.invoke(timeoutfilter.java:41) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.tracefilter.invoke(tracefilter.java:77) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.filter.contextfilter.invoke(contextfilter.java:71) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.filter.genericfilter.invoke(genericfilter.java:131) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.filter.classloaderfilter.invoke(classloaderfilter.java:37) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.filter.echofilter.invoke(echofilter.java:37) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.protocol.dubbo.dubboprotocol$1.reply(dubboprotocol.java:98) at com.alibaba.dubbo.remoting.exchange.support.header.headerexchangehandler.handlerequest(headerexchangehandler.java:96) at com.alibaba.dubbo.remoting.exchange.support.header.headerexchangehandler.received(headerexchangehandler.java:168) at com.alibaba.dubbo.remoting.transport.decodehandler.received(decodehandler.java:50) at com.alibaba.dubbo.remoting.transport.dispatcher.channeleventrunnable.run(channeleventrunnable.java:79) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
java.sql.sqlexception: tdengine error: timestamp out of range at com.taosdata.jdbc.tsdbjniconnector.executequery(tsdbjniconnector.java:129) at com.taosdata.jdbc.tsdbstatement.executeupdate(tsdbstatement.java:69) at com.taosdata.jdbc.tsdbpreparedstatement.executeupdate(tsdbpreparedstatement.java:142) at cn.meirenji.data.service.impl.datatdengineserviceimpl.savedevicestate(datatdengineserviceimpl.java:380) at com.alibaba.dubbo.common.bytecode.wrapper8.invokemethod(wrapper8.java) at com.alibaba.dubbo.rpc.proxy.javassist.javassistproxyfactory$1.doinvoke(javassistproxyfactory.java:45) at com.alibaba.dubbo.rpc.proxy.abstractproxyinvoker.invoke(abstractproxyinvoker.java:71) at com.alibaba.dubbo.config.invoker.delegateprovidermetadatainvoker.invoke(delegateprovidermetadatainvoker.java:48) at com.alibaba.dubbo.rpc.protocol.invokerwrapper.invoke(invokerwrapper.java:52) at com.alibaba.dubbo.rpc.filter.exceptionfilter.invoke(exceptionfilter.java:61) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.monitor.support.monitorfilter.invoke(monitorfilter.java:74) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.filter.timeoutfilter.invoke(timeoutfilter.java:41) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.tracefilter.invoke(tracefilter.java:77) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.filter.contextfilter.invoke(contextfilter.java:71) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.filter.genericfilter.invoke(genericfilter.java:131) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.filter.classloaderfilter.invoke(classloaderfilter.java:37) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.filter.echofilter.invoke(echofilter.java:37) at com.alibaba.dubbo.rpc.protocol.protocolfilterwrapper$1.invoke(protocolfilterwrapper.java:68) at com.alibaba.dubbo.rpc.protocol.dubbo.dubboprotocol$1.reply(dubboprotocol.java:98) at com.alibaba.dubbo.remoting.exchange.support.header.headerexchangehandler.handlerequest(headerexchangehandler.java:96) at com.alibaba.dubbo.remoting.exchange.support.header.headerexchangehandler.received(headerexchangehandler.java:168) at com.alibaba.dubbo.remoting.transport.decodehandler.received(decodehandler.java:50) at com.alibaba.dubbo.remoting.transport.dispatcher.channeleventrunnable.run(channeleventrunnable.java:79) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624) at java.lang.thread.run(thread.java:748)
import into t_306678704044507136(state_timestamp, state_type, state_active, state_delay)values(1567102786000, 3, 0, 0) ql
ava dbc .
a "too slow" exception is found.
win7 dengine client ll dbc
class.forname("com.taosdata.jdbc.tsdbdriver"); string jdbcurl = "jdbc:taos://192.168.0.44:0/db?user=root&password=baian20198"; connection conn = drivermanager.getconnection(jdbcurl); return conn;
error: java.sql.sqlexception: tdengine error: authentication failure at com.taosdata.jdbc.tsdbjniconnector.connect(tsdbjniconnector.java:100) at com.taosdata.jdbc.tsdbconnection.connect(tsdbconnection.java:64) at com.taosdata.jdbc.tsdbconnection.<init>(tsdbconnection.java:56) at com.taosdata.jdbc.tsdbdriver.connect(tsdbdriver.java:135) at java.sql.drivermanager.getconnection(drivermanager.java:664) at java.sql.drivermanager.getconnection(drivermanager.java:270) at com.ba.locationdata.test.testtdengine.getconn(testtdengine.java:34) at com.ba.locationdata.test.testtdengine.main(testtdengine.java:15) hell tdengine .6.0.0
ug
the client got error code:5 (last session not finished) from the server
using yarn 1.21.1, running `yarn policies set-version` with `^1.21.1` or `1.21.1` crashes with: `request.filter is not a function`
passing `berry` works
this happens even in a new directory with `package.json` containing just `{}`
`yarn-error.log` contents:
arguments: /users/me/.nvm/versions/node/v12.14.1/bin/node /usr/local/cellar/yarn/1.21.1/libexec/bin/yarn.js policies set-version ^1.21.1 path: /users/me/.nvm/versions/node/v12.14.1/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/yarn/bin yarn version: 1.21.1 node version: 12.14.1 platform: darwin x64 trace: typeerror: request.filter is not a function at /usr/local/cellar/yarn/1.21.1/libexec/lib/cli.js:90113:28 at generator.next (<anonymous>) at step (/usr/local/cellar/yarn/1.21.1/libexec/lib/cli.js:310:30) at /usr/local/cellar/yarn/1.21.1/libexec/lib/cli.js:321:13 at processticksandrejections (internal/process/task_queues.js:94:5) npm manifest: {} yarn manifest: no manifest lockfile: no lockfile
following the steps in the [end to end testing example]( and cypress isn't working
i kept getting the error: ```
exports is not defined because this error occurred during a before each hook we are skipping the remaining tests in the current suite: accessibility tests
``` i tried updating cypress-axe to the latest version, [per this github issue]( and i still see the same error
i'm not using typescript in my project
i checked out this repo and tried to run the [example cypress project]( and i got the error
i just started a new gatsby project using my configuration from a previous project
however, after running `npm install` and `gatsby build`, i get an error: ```
failed building static html for pages - 3.529s
error building static html failed for path "/404/"
typeerror: cannot read property 'pathname' of undefined
``` here's my `package.json`: ```
{ "name": "tribesafe-headless", "private": true, "description": "tribesafe\'s gatsby site", "version": "0.0.1", "scripts": { "build": "gatsby build", "develop": "gatsby develop", "format": "prettier --write \\"**/*.{js,jsx,ts,tsx,json,md}\\"", "start": "npm run develop", "serve": "gatsby serve", "clean": "gatsby clean", "test": "echo \\"write tests! -> " && exit 1", "production": "npm run clean && npm run build && npm run serve" }, "dependencies": { "gatsby": "^2.23.12", "gatsby-cli": "^2.12.60", "gatsby-plugin-google-tagmanager": "^2.3.15", "gatsby-plugin-html-attributes": "^1.0.5", "gatsby-plugin-no-javascript": "^2.0.5", "gatsby-plugin-no-javascript-utils": "^0.5.0", "gatsby-plugin-purgecss": "^5.0.0", "gatsby-plugin-react-helmet": "^3.3.9", "gatsby-plugin-sass": "^2.3.7", "gatsby-plugin-sharp": "^2.6.14", "gatsby-plugin-split-css": "^1.0.2", "gatsby-react-router-scroll": "^3.0.3", "gatsby-source-filesystem": "^2.3.14", "gatsby-source-graphql": "^2.6.1", "gatsby-transformer-json": "^2.4.12", "gatsby-transformer-remark": "^2.8.35", "react": "^16.12.0", "react-body-classname": "^1.3.1", "react-dom": "^16.12.0", "react-helmet": "^6.1.0", "react-markdown": "^4.3.1", "sass": "^1.26.10" }, "devdependencies": { "prettier": "2.0.5" }, "repository": { "type": "git", "url": " " }, "bugs": { "url": " " }
i've encountered a weird error where gatsby is not building images in production
this behaviour is based on the local state of .cache & public folders - if one of them is missing, then the resulting build contains no images.
since update of gatsby version `^2.24.86` the error `react is not defined` started to occur when following the new jsx transformer setup: #gatsby here is the changes since the latest working version:
i keep getting this error when trying to build gatsby
every once and awhile an it will start successfully
i am getting the same error 3 times when running gatsby develop
ive tried many available solutions to this common problem
this includes moving around plugins in gatsby-config
ive also confirmed that the image paths are correct in the code.
node_modules/gatsby-cli/lib/reporter/reporter.d.ts:86:1 - error ts1128: declaration or statement expected
86 export type { reporter }; ~~~~~~ node_modules/gatsby-cli/lib/reporter/reporter.d.ts:86:13 - error ts1005: ';' expected.
``` 86 export type { reporter }; ~ found 2 errors
something wrong with rimraf or how can we resolve this?
based on the react v17 documentation page gatsby has support of the new jsx transform
new jsx transform however does not require to have `import react` at the top of each file
[how to upgrade to new jsx transform.]( #how-to-upgrade-to-the-new-jsx-transform)
after the upgrade to react v17 and removing react import from a file, i\'m getting the error "react is not defined".
hi! i keep on getting the following message: ![error-static-query](
after updating the gatsby cli to the latest version, i tried to start the development server from vscode's integrated terminal, it compiles fine, yet when opening the page on the browser the following error message appears: error: it appears like gatsby is misconfigured
jsonstore is gatsby internal development-only component and should never be used in production
unless your site has a complex or custom webpack/gatsby configuration this is likely a bug in gatsby
please report this at with steps to reproduce this error
only if run from a separate terminal it seems to work
i am using macos btw.
no errors on `gatsby develop` or `gatsby build`
on `gatsby serve` site loads without images or styles and crashes immediately with multiple `t.test is not a function` errors in the console.
**this issue appeared sometime after version `2.24.79`** i\'m currently using the following scripts to remove the `.cache` and `public` directory before running/building gatsby: ``` "build": "rimraf .cache && rimraf public && gatsby build", "develop": "rimraf .cache && rimraf public && gatsby develop",
``` on the latest version `2.24.85` it logs that there is a `.cache` directory when running `yarn develop`, even though there hasn't been one: ```
success open and validate gatsby-configs - 0.009s
success load plugins - 0.025s
success onpreinit - 0.019s
info we've detected that the gatsby cache is incomplete (the .cache directory exists
but the public directory does not)
as a precaution, we're deleting your site's
cache to ensure there's no stale data.
i read this page and placticed it.
but in this page, the build failuring was facing me and i couldn't do it
#l189
hot reload does not work with since 2.24.9 related issues: -
-
-
-
calling the same page with a state change `navigate('/page', { state: { newstate }})` doesn't cause the page to rerender.
downgrading gatsby to version `2.24.69` fix the issue and the page is rerendered correctly.
i have an issue with gatsby refreshing changes
issue happens with versions newer than 2.24.0
as i started to simplify my project for reproduction example i noticed that the issue also happens when i save a page quickly multiple times
the changes doesn't show
if i pause and then save, changes show up
maybe it's related somehow why my project isn't refreshing, maybe not, but that's all i got so far...
the gatsby plugin prefetch fonts throws this error suddenly starts to throw the error `error: enoent: no such file or directory, stat '.cache/google-fonts//fonts'`
in production: client only routes works fine until i refresh a page different from the base one (/), for example if i have two pages, / and /profile, when i try to reload /user seems to be loading / instead, or a mix of both pages in development: client only routes works fine even with a page refresh
the problem is also happening if i use private routes (following this guide i saw in a previous bug report the same issue, and the workaround was to disable ssr, but i think is not the ideal solution `exports.replacerenderer = ({ replacebodyhtmlstring }) => { replacebodyhtmlstring(\'<div id="___gatsby"></div>\');
};` (added to gatsby-ssr.js)
**related report:**
path prefix ( does not work when page url starts with path prefix
for example, if path prefix is `/blog` and page's url is `blog`, navigating to `/blog/blog` does not work
this can be demonstrated in: (page works with javascript disabled, but not with javascript enabled) working example of path prefix can be found in:
for typescripts, `actions` in `createschemacustomizationargs` is missing a declaration for `printtypedefinitions`
newly created gatsby website errors with: ![image](
this issue is a regression in the typescript types, caused by [pr 27381]( specifically this commit: it pulls the type from the `src` folder, which is fine in development, but the `src` folder is not included in the distributed npm package so you just get a file missing error.
make svg favicon come after png one, because chrome chooses the favicon which comes last, thus preferring png over svg
### documentation see chrome bugreport: ## related issues fixes #26083
uses [`fromfile()`]( #filetypefromfilefilepath), [`frombuffer()`]( #filetypefrombufferbuffer) methods to infer filetype/extension from the file/buffer, if not specified
this fixes an issue where `createremotefilenode` may fail on urls without an extension in the path
### documentation * n/a ## related issues * fixes #21901
have seen this issue being reported a couple of times before and have scoured the previous bug reports for suggestions with no avail
from what seems like out of nowhere, `usestaticquery` hooks that were working fine are now causing the site to break when in development mode
when i run `yarn develop` the process runs smoothly and returns all green before prompting me to go to localhost/8000, however when i do i get the error 'error: the result of this staticquery could not be fetched.' steps i've already tried: 1
run `gatsby clean`
remove `node_modules` folder and `yarn.lock` before then running `yarn install`
run `yarn upgrade` to make sure everything is up to date
git reset to a previous commit and try running `yarn develop` from there _(still produces the same result)_
running `gatsby build` under local environment works while no generated html file with the same condition under alpine linux.
hello, i'm a newbie in gatsby, everytime i try to create a gatsby site i am getting this error: error: command failed with exit code 1: npm install
my current stack is contentful as cms, gatsby which is hosted on netlify
the current issue is that in some time (not always), when creating new pages in contentful it's not reflected in gatsby
in gatsby-node we are iterating over the pages we have in contentful and use createpage api to create a new web page for it
when creating new web pages, we can't see that this page got created in gatsby until we do a **delete of the cache** and trigger a new build
i have an issue i need help with that seems to have popped up a few times over the years
i have burned 8 hours, one full work day, and this is too much
**backstory:** have a working page that needed updates
unfortunately for some reason, after 2.5 months of no updates and no changes, it has stopped building, on both netlify and local development, throwing either
a) `rangeerror: maximum call stack size exceeded`
b) `typeerror: cannot read property 'internal' of null`
after the upgrades in #27037 (and possibly before), passing in invalid arguments in the config file for csvtojson causes it to throw an error, but one without helpful information
`typeerror: onrejected is not a function` i'm working on the fix in #27494, but figured filing a bug might be easier for other affected users to find.
apologies in advance, it appears this is a frequently asked question, but i've been unable to fix my issue by following many of the answers listed previously
i'm building a basic blog template using gatsby, and opted to use the styled-components plugin to handle the css side of things
styling works well throughout the site when using `gatsby develop`, but the navigation bar appears to break when using `gatsby serve`
it appears that the styling does not load specifically for the navigation bar if users don't first visit the site's index, although other components are unaffected
### attempted solutions - verified that "gatsby-plugin-styled-components" was included in the plugins array in gatsby-config.js
- tried adding "babel-plugin-styled-components" as a dependency to see if the issue relates to server-side rendering
- in [navigation.js]( the component's body is wrapped in a @reach/router `<location>` tag
attempted to remove it to see if that was the culprit - the instant i submitted this ticket, i remembered that the `<navigation>` component is the only one being passed props in order to determine styling
sure enough, removing the props allows the component to display properly.
i installed [gatsby-plugin-sitemap]( #readme) and next added to plugins inside gatsby-config.js file
after running gatsby build
build gives me errors
i can no longer run gatsby develop after updating the cli.
`gatsby-source-drupal` has the `filters` option which has an issue
the filters are only applied starting from the second page of the results
the first one doesn't get them
first call: `/jsonapi/node/page`
second call: `/jsonapi/node/page?page[offset]=50&page[limit]=50?filter=value`
`typeerror` issue with `npm run develop` after updating to latest packages
`localhost:8000` is flickering on and off viewing the error when trying to get to development mode.
the plugin outputs the incorrect protocol and port when a build succeeds: compare gatsby's output:
> you can now view sleepstation-public in the browser.
> to the plugin's output:
> netlify cms is running at
when using `gatsby develop --https`, i see a lot of `err_ssl_protocol_error` errors in the console, for what seems to be `socket.io` related requests
i am using the (currently) latest version of gatsby
![image]( it happens about every 5 seconds, which makes it annoying to use the console to debug other things
the page seems to work fine, and hmr works without issues too, regardless of the errors.
this is a proposed fix for which i just reported with a more detailed description of the problem itself
the issue appears to be this line of `gatsby-plugin-postcss`: #l33 the `postcssoptions` object is being used with the spread (`...`) syntax, meaning that its properties are being included directly to the object literal passed to the `options` property of the postcss loader
this means that the `options` property evaluates to `{ sourcemap: !isproduction, plugins: [/* plugin objects */] }`
this is invalid because the [postcss-loader]( #options) only accepts three top-level options: `execute`, `postcssoptions`, and `sourcemap`
the `plugins` property belongs to the `postcssoptions` object, but because of the spread operator, it's getting hoisted up a level
given that the variable name in this gatsby plugin is spelled exactly as `postcssoptions`, matching the postcss loader option name, i am assuming that this was a mistake and that the original intent was to pass in the entirety of the `postcssoptions` object into the postcss loader
i tested this by hot-editing the version of this file in my `node_modules/` directory with the exact same change to confirm that this fixes it
### documentation this fixes the plugin to actually match the behavior described by the documentation in and
## related issues fixes #27417.
according to and one should be able to configure custom postcss plugins with gatsby by adding the following to `gatsby-config.js`: ```javascript
plugins: [ { resolve: `gatsby-plugin-postcss`, options: { postcssplugins: [require(`postcss-preset-env`)({ stage: 0 })], }, },
``` however, when i actually try running gatsby with those settings, i get the following error message: ```
generating development javascript bundle failed invalid options object
postcss loader has been initialized using an options object that does not match the api schema
- options has an unknown property 'plugins'
these properties are valid: object { postcssoptions?, execute?, sourcemap? }
i'm getting an error 11328 with unhelpful debugging information when i run gatsby build
running gatsby develop works very fine.
i createad a simple component: `
import styled from "@emotion/styled";
export const vblist = styled.ul`some_css`;
` and used it in my component: ```
export const list = ({items}) => { return <vblist> <div></div> </vblist>
which then i use in one of my pages multiple times: `<list/>` for each time i use the <list/> component i get exact the same css code injected into my .html file
i expected to contains the css just one time
its a huge overload to inlude it multiple times
<img width="305" alt="bildschirmfoto 2020-10-12 um 11 11 21" src=" ">
<img width="309" alt="bildschirmfoto 2020-10-12 um 11 11 12" src=" ">
<img width="344" alt="bildschirmfoto 2020-10-12 um 11 11 02" src=" ">
npm install failed with error "autoreconf -fiv"
i have a lerna monorepo with 20+ gatsby sites all pulling from a shared component library
i added a netlify-cms-gatsby site to the monorepo and it works fairly well with one show stopping caveat..
no dom events make it through the build process
no onclicks, no onmousedowns, nothing
in fact after some targeted testing, i can't do anything other than a basic href, which is too limiting for my needs.
hi! i am writing this because i didn't find any recent help for this issue
this morning i started working on 2 gatsby projects (basically the same site in 2 versions)
when i opened the first one in vs code and started the development with "gatsby develop", i had no issue
then, i opened the second one and i saw that i can update gatsby-cli, so i thought to myself , i'd better do that before starting developing the second project
except, after i updated, the commands wouldn\'t work anymore :( i got an error "permission denied", which i, unfortunately, didn\'t copy right away, but it was something similar to this: [ - with no answer
or this: [ -closed without a solution
or this [ -also closed without a solution
i hope i didn\'t break anything with the "npm config set prefix " command :( any help would be very much appreciated :)
apologies if i'm missing something obvious here
while running `gatsby build` i see the following error message in `gatsby-plugin-styled-components`: ```
error #11329 your plugins must export known apis from their gatsby-node.js
see for the list of gatsby node apis
- the plugin gatsby-plugin-styled-components@3.3.14 is using the api "pluginoptionsschema" which is not available in your version of gatsby.
``` not sure if i should be using a different version of gatsby? i found [this]( - again, not sure how relevant it is here?
introduced in `gatsby@2.24.51` as a result of [#26644](
i started to look into what the cause of the issue might be and i've shared my findings below
we have a custom resolver for a nested date field, and a static query with a sort on that date field
we also have a page query with both a sort on the date field and a filter on a category field
when running the static query, gatsby determines that the date subfield of the meta field needs to be resolved before sorting and resolves it
when running the page query, gatsby knows that date has already been resolved in the static query so it doesn't need to be resolved again, but categories is a new nested field that needs to be resolved
#l369-l372 3
gatsby resolves the categories field, and the value for date is populated from the same node (which doesn't have the value of date from the custom resolver).
#l711-l715 4
the query results are sorted using the original value of the date field instead of the value generated by the custom resolver and they're returned in the wrong order.
i've tried to debug the build process following the docs - [vs code debugger (manual config)]( #vs-code-debugger-manual-config), after saving and running `gatsby develop` config i got the following error: ```text
c:\\devl\\workspace\\my-project\ ode_modules\\.bin\\gatsby:2
basedir=$(dirname "$(echo "$0" | sed -e \'s,\\\\,/,g\')") ^^^^^^^ syntaxerror: missing ) after argument list
[90m at wrapsafe (internal/modules/cjs/loader.js:1053:16) [39m [90m at module._compile (internal/modules/cjs/loader.js:1101:27) [39m
[90m at object..js (internal/modules/cjs/loader.js:1157:10) [39m [90m at module.load (internal/modules/cjs/loader.js:985:32) [39m
[90m at function._load (internal/modules/cjs/loader.js:878:14) [39m
[90m at function.executeuserentrypoint [as runmain] (internal/modules/run_main.js:71:12) [39m
[90m at internal/main/run_main_module.js:17:47 [39m
``` i workaround this by changing the config to: ```diff
{ "name": "gatsby develop", "type": "pwa-node", "request": "launch", "program": "${workspaceroot}/node_modules/.bin/gatsby",
+ "windows": {
+ "program": "${workspaceroot}/node_modules/gatsby/dist/bin/gatsby"
+ }, "args": ["develop"], "runtimeargs": ["--nolazy"], "console": "integratedterminal"
``` it worked but logged `debugger attached.` 4 times, which i'm not sure is the correct behavior.
starting with version 2.24.70 my website's search field stopped working.
at some point in the last six months or so the shouldupdatescroll browser api hook and related functionality seems to have been changed under the hood and introduced breaking changes to scroll restoration for gatsby sites that use a simple animated page transition implementation (as introduced by @ryanwiemer:
i'd guess there could be a significant number of sites affected considering the many themes and starters that make use of this page transition technique
here's the bit of code that gets added to gatsby-browser.js to support scroll restoration with animated page transitions (which rely on gatsby-plugin-layout and your animation library of choice): ```
const transitiondelay = 600;
export const shouldupdatescroll = ({ routerprops: { location }, getsavedscrollposition }) => { if (location.action === "push") { window.settimeout(() => window.scrollto(0, 0), transitiondelay); } else { const savedposition = getsavedscrollposition(location); window.settimeout( () => window.scrollto(...(savedposition || [0, 0])), transitiondelay ); } return false; }; ```
essentially, scroll restoration no longer works correctly on popstate when page transitions are involved
console logging the `savedposition` that gets retrieved in the code snippet above always returns 0
there are two issues here: 1
the function is returning a single number rather than an `[x, y]` coordinate array as expected per the documentation here: #shouldupdatescroll
the function always returns 0 despite the scroll position saved in session storage, so even when modifying the code above to `window.scrollto(0, savedposition || 0)`, the user is always sent to the top of the page when using browser back or forward buttons.
`gatsby develop` results in a typescript error
i am new to gatsby
i created a new site with gatsby-starter-hello-world, follwoing this link
the hello world program works perfectly
i try to add the `gatsb-theme-blog` to this existing hello world site, i followed as given in the documentation
#installing-the-blog-theme
i run `gatsby develop` after completing the above instructions i got error and can't fix
kindly guide me on how to use themes in existing sites
![image](
some times the website loads without styles, just the content and html, sometimes it also happends with only oen component and the rest loads ok.
when i run `yarn develop`, the process hangs at `source and transform nodes`
when i resize my terminal, everything starts running again smoothly
so i need to hit the command and keep changing my terminal width to actually get to the end of building
![image](
when i trigger a new build by submitting an empty post to the build webhook, i get an empty 204 (no content) response
however, it would be more logical to return a 200 code, as this is the general http code for successful requests.
can't download directly html file from public
i want to download tutorial.html from public folder directly using markdown link
[tutorial txt](/downloads/tutorial.txt 'tutorial.txt')
[tutorial html](/downloads/tutorial.html 'tutorial.html')
[tutorial txt](/downloads/tutorial.txt 'tutorial.txt')
![image]( ![image](
if i use txt file:
![image](
if i use html file:
page 404 error appears.
error: the result of this staticquery could not be fetched
this is likely a bug in gatsby and if refreshing the page does not fix it, please open an issue in
usestaticquery
d:/accuindex/stagging-accuindex.com/.cache/gatsby-browser-entry.js:77 74 | if (context?.[query]?.data) { 75 | return context[query].data 76 | } else {
> 77 | throw new error( 78 | `the result of this staticquery could not be fetched.\ \ ` + 79 | `this is likely a bug in gatsby and if refreshing the page does not fix it, ` + 80 | `please open an issue in ` ### error cause my application was working fine, i just did some in prismic data and which is building fine with netlify, but when i do it on my local, with command , gatasby build , it throws this error ### expected result
it should develop/build and start running without error, or give a specific error
we're following your instructions here: ..
on how to use the seo component to build googlebot friendly pages but we\'re constantly getting errors in the most recent gatsby: the error we\'re receiving is: " webpackerror: it appears like gatsby is misconfigured
gatsby related `graphql` calls are supposed to only be evaluated at compile time, and then compiled away
unfortunately, something went wrong and the query was left in the compiled code." the error is non-deterministic and seems to happen say 20% of the time per page but since we added the seo component in all our pages it happens at least 9/10 builds.
fluid images that are using `img` from `gatsby-image` stuck on the svg placeholder mode and not being rendered
normal images (*i'm referring to `<img src={...}/>`*) on the other hand, works fine.
this behavior only exist on iphone's safari apparently, i've tried it on my chrome, and they are all working fine
i can't really do a check on an iphone safari because i am in no possession of one.
i've tried adding
require("babel-polyfill")
in my `gatsby-browser.js` but still experiencing the same result.
the [gatsby-plugin-canonical-urls]( plugin adds a rel=canonical <link> tag to the head of each html page
here is an example of code added to the head of the html document: `<link rel="canonical" href=" " data-baseprotocol="https:" data-basehost="www.abc.com">` the potential problem is with the protocol
it states the protocol is "https:"
but shouldn\'t it be "https" without the colon? ## how to reproduce 1
start with the [gatsby starter default](
install the [gatsby-plugin-canonical-urls]( plugin.
run "gatsby develop"
open "localhost:8000" in google chrome.
open the developer tools (click f12).
select "elements"
expand the "head" section.
look for the rel=canonical <link> tag.
find the property data-baseprotocol
it should be equal to "https" not "https:" ## solution open the [gatsby-srr.js]( file
and modify line 29 to remove the colon
here is what line 29 should look like: `data-baseprotocol={parsed.protocol.slice(0, -1)}`
since macos catalina, the root volume of the os is read-only
[to create a folder in the root one has to use synthetic firmlinks](
i happened to have a gatsby project in a path under one such folder
it looks like `gatsby develop` is unable to hot reload if a project is located in such place
the same project moved to path outside the synthetic firmlink (for example user's home folder) results in hot reload working properly.
when [react-icons ]( is used, all of the icons in the set are included in the bundle.
the build is failing with the following error on this pr i'm unable to figure out what caused it and how it can be fixed:
typeerror: cannot create property 'context' on string 'operating system not recognized.'
``` ![image]( i tried running `yarn lint` & `yarn check-types` to make sure that there are no typing or linting errors.
the gatsby project builds locally but on deploy, displays blank page.
so, i have a layout component using static query hook, fetching data from wordpress
the query works, as i have tested it in the __graphql environment, however - no matter how i use this hook or static query component, i always get the error of if 'could not be fetched.' i've downgraded / upgraded packages and i still get the same error
it worked when i first started the stater-site and has now suddenly not started working at all
query and code below: path: 'src/components/layout' query: ```
import react from 'react'
import { graphql, usestaticquery } from 'gatsby'
import globalstyle from './globalstyle'
import header from \'../header\' export default layout = ({ children }) => { const { wordpresswpapimenusmenusitems: { items } } = usestaticquery( graphql` query { wordpresswpapimenusmenusitems(slug: {eq: "primary"}) { items { object_slug title } } }` ) return ( <> <globalstyle /> <header menuitems={items} /> { children } </> )
hi there! i am using gatsby together with `gatsby-plugin-mdx` and `netlify-cms` for blog content creation - meaning i am sourcing mdx files from a `netlify-cms` content folder into my gatsby project
at some point during the development graphql started to throw the following internal error for the images coming from my mdx frontmatter: ```
there was an error in your graphql query: cannot read property 'dir' of null 19 | } 20 | authorname 21 | metatitle 22 | metadescription 23 | metalinks { 24 | rel 25 | href 26 | hreflang 27 | } 28 | categories
> 29 | mainimage { | ^ 30 | childimagesharp { 31 | fluid(quality: 100) { 32 | ...gatsbyimagesharpfluid 33 | } 34 | } 35 | } 36 | mainimagealttext 37 | } 38 | } 39 | }
``` nevertheless, - the images from my query, the ones that the error points at, are rendered correctly on the static
it's not blocking anything.
up to gatsby 2.24.64 is was possible to use link from @reach/router to link between pages
starting from 2.24.65 you get 404-errors
we need to use link from @reach/router in our project because we have to rebundle our components without a gatsby dependency
with link from "gatsby" it works fine
i suspect that this issue is related to this fix, but i'm not totally sure: [
build gets stuck at this stage indefinitely:
success run page queries - 8.438s - 46/46 5.45/s
[============================] 188.240 s 2081/2082 100% generating image thumbnails
``` also on netlify it does not build anymore:
build exceeded maximum allowed runtime
``` maybe related to [#14078]( but the proposed workaround (downgrading node) does not fix the problem.
using a webp image, only `.webp` files are generated.
we are experiencing extremely slow builds for gatsby + contentful
the issue arises sporadically when content is changed in contentful
(using bitbucket pipelines)
builds usually take 5-8 minutes on pipelines, but for no apparent reason suddenly things start taking up 90+ minutes and it stays this way, until i revert all the changes to this point
reverting makes the build fast again
republishing the reverted changes, yields a quick build as well
so at the end there seems to be nothing particular causing the bug
the code between the two builds does not change and bitbucket pipelines run a clean install every time including all libraries etc
but suddenly it takes ages to compile
i have no idea how to debug it
we get warnings about slow queries sporadically too: `
warn query takes too long:
file path: /users/artifex/work/projects/ln-website/src/templates/contactpage.tsx
url path: /kontakt
` another weirdness is that a blank project (that i created for testing), that simply pulls in the data from the same contentful repository, but does not display any content and executes only one gql-query for one page, compiles fine and fairly quickly no matter what
so it seems to be related to the conjunction of code, data and build chain
some more info: - we are using gatsby-plugin-graphql-codegen that generates a file that is about a 100mb in size and always gives warnings that it is deoptimized, due to big file size
- the build seems to hang in the step "building production javascript and css bundles" this is the output for a build that runs as it should in about 7 minutes:
success createpages - 0.811s
success createpagesstatefully - 0.089s
success updating schema - 0.442s
success onpreextractqueries - 0.002s
success extract queries from components - 2.127s
success write out redirect data - 0.002s
info [gatsby-plugin-graphql-codegen] definition for queries of schema default-gatsby-schema has been updated at graphql-types.ts
success build manifest and related icons - 0.287s
success onpostbootstrap - 44.590s
info bootstrap finished - 89.415s
success run static queries - 1.381s - 11/11 7.96/s
success run page queries - 1.664s - 61/61 36.66/s
success write out requires - 0.005s
info using stage environment
success created cachedvariables.json
success making environment variables available as globals
error [babel] note: the code generator has deoptimised the styling of /opt/atlassian/pipelines/agent/build/graphql-types.ts as it exceeds the max of 500kb.
success building production javascript and css bundles - 262.154s
success rewriting compilation hashes - 0.003s
info using stage environment
success created cachedvariables.json
success making environment variables available as globals
error [babel] note: the code generator has deoptimised the styling of /opt/atlassian/pipelines/agent/build/graphql-types.ts as it exceeds the max of 500kb.
success building static html for pages - 173.369s - 61/61 0.35/s
success generating image thumbnails - 439.972s - 8/8 0.02/s
success onpostbuild - 0.002s
info done building in 529.824 sec
``` this is the build that slows down to 90+ minutes ```
success createpages - 1.876s
success createpagesstatefully - 0.061s
success updating schema - 0.732s
success onpreextractqueries - 0.001s
success extract queries from components - 3.152s
success write out redirect data - 0.001s
info [gatsby-plugin-graphql-codegen] definition for queries of schema default-gatsby-schema has been updated at graphql-types.ts
success build manifest and related icons - 0.401s
success onpostbootstrap - 104.440s
info bootstrap finished - 198.792s
success run static queries - 2.828s - 11/11 3.89/s
success run page queries - 2.908s - 61/61 20.98/s
success write out requires - 0.009s
info using stage environment
success created cachedvariables.json
success making environment variables available as globals
error [babel] note: the code generator has deoptimised the styling of /opt/atlassian/pipelines/agent/build/graphql-types.ts as it exceeds the max of 500kb.
success building production javascript and css bundles - 3334.661s
success rewriting compilation hashes - 0.007s
info using stage environment
success created cachedvariables.json
success making environment variables available as globals
error [babel] note: the code generator has deoptimised the styling of /opt/atlassian/pipelines/agent/build/graphql-types.ts as it exceeds the max of 500kb.
success building static html for pages - 2236.973s - 61/61 0.03/s
success generating image thumbnails - 5580.829s - 8/8 0.00/s
success onpostbuild - 0.007s
info done building in 5780.588 sec
``` are there any ways to figure out what might be causing this issue and how to debug the process?
my terminal window shows a long list of missing peer dependencies on a fresh install of gatsby-cli: ![image]( as far as i know it's not best practice to install some of these packages globally
i think this may be a bug?
hi, it seems that fast-refresh/prefresh stops working while using gatsby-plugin-preact version ^4.0.11
it works if i revert back to 4.0.10
seems like the only change on 4.0.11 is an upgrade of @prefresh/webpack to version ^1.0.2 from ^0.8.1.
gatsby-plugin-manifest provides an option to generate a svg icon with png fallback
this is great because it allows us to embed `@media (prefers-color-scheme: dark) {}` queries in our icons
unfortunately, the fallback icon is preferred by chome.
i am using below mentioned gatsby verison, my compilation getting failed fro 4pm today `"[gatsby]( ": "^2.24.27",`
it seems that creating a new project with `gatsby-plugin-mdx` always throws an `error: invalid hook call.` when using the dev server.
the material ui styles are applied to the wrong components on the 2nd render.
[gatsby-plugin-manifest]( resizes svg incorrectly.
when i make localized paths like routes `/en/`, `/fr/`, etc, and for that i have delete the page `/` for recreate with localized path
but i have error when access to `/`.
while creating the development bundle, sometimes it stucks on `onpostboostrap` and `build manifest and related icons`
the problem is related with the plugin _gatsby-plugin-manifest_ or with the cache: - if i comment out the plugin in _gatsby-config.js_ the problem will not occur again - if i delete the cache with the command `gatsby clean` the problem will not occur again the problem is certainly related only to the development bundle not the building one.
i'm using the gatsby image plugin with webp spefificly `gatsbyimagesharpfluid_withwebp` in the docs its says _if you want to automatically use webp images when the browser supports the file format, use the withwebp fragments
if the browser doesn support webp, gatsby-image will fall back to the default image format._ how very when i test it on safari its not falling back attached screenshot <img width="1252" alt="screen shot 2020-09-21 at 9 21 06 pm" src=" ">
function that generates urls in `gatsby-remark-copy-linked-files` is not compatible with `assetprefix` - current path joining result in something like `/https:/cdn.your-domain.com/{generated-hash-values}/demo.svg` (note that first character in front of protocol part)
this pr changes to url generation to match what `gatsby-plugin-sharp` already do (which is just doing string manipulation, because `pathprefix` is already passing in form that allows for it - it strips trailing slash always, which means that using `${prefix}/some/path` will work correctly): #l142-l145 ## related issues fixes #25918
error: the result of this staticquery could not be fetched.
this is likely a bug in gatsby and if refreshing the page does not fix it, please open an issue in ( - production environment
- white page in some clients
- mobile client for the most part
when i run `gatsby develop`, i get the following error message: ```
wyrd00@laptop-umc77naa:~/project$ gatsby develop
debugger listening on ws://127.0.0.1:9229/5648d06d-6b1d-4570-a086-102ebe17534a
for help, see:
success open and validate gatsby-configs - 0.037s
success load plugins - 0.702s
success onpreinit - 0.091s
success initialize cache - 0.115s
success copy gatsby files - 0.137s
success onprebootstrap - 0.019s
success createschemacustomization - 0.004s error the path passed to gatsby-source-filesystem does not exist on your file system:
please pick a path to an existing directory.
see docs here -
``` in my `gatsby-config`
const path = require("path") module.exports = { sitemetadata: { title: `project`, description: `a description`, author: `@wyrd00`, }, plugins: [ `gatsby-plugin-react-helmet`, `gatsby-plugin-styled-components`, `gatsby-plugin-sharp`, { resolve: `gatsby-source-filesystem`, option: { name: `src`, path: `${__dirname}/src`, }, }, { resolve: `gatsby-plugin-alias-imports`, options: { alias: { "@common": path.resolve(__dirname, "src/components/common"), "@sections": path.resolve(__dirname, "src/components/sections"), "@styles": path.resolve(__dirname, "src/styles"), }, }, }, ],
``` there's no doubt my `src` folder exist.
also tried downgrading the gatsby-source-filesystem to a version that worked in my previous projects - no luck.
individual node changes aren't reflected on gatbsy preview due to build errors.
13:54:12 pm: success createschemacustomization - 0.007s
13:54:12 pm: error cannot read property 'attributes' of undefined
13:54:12 pm: typeerror: cannot read property 'attributes' of undefined - normalize.js:17 nodefromdata [frontend]/[gatsby-source-drupal]/normalize.js:17:7 - utils.js:113 handlewebhookupdate [frontend]/[gatsby-source-drupal]/utils.js:113:19 - gatsby-node.js:98 object.exports.sourcenodes [frontend]/[gatsby-source-drupal]/gatsby-node.js:98:15 - api-runner-node.js:256 runapi [frontend]/[gatsby]/dist/utils/api-runner-node.js:256:37 - api-runner-node.js:375 promise.catch.decorateevent.pluginname [frontend]/[gatsby]/dist/utils/api-runner-node.js:375:15 - debuggability.js:384 promise._execute [frontend]/[bluebird]/js/release/debuggability.js:384:9 - promise.js:518 promise._resolvefromexecutor [frontend]/[bluebird]/js/release/promise.js:518:18 - promise.js:103 new promise [frontend]/[bluebird]/js/release/promise.js:103:10 - api-runner-node.js:374 [frontend]/[gatsby]/dist/utils/api-runner-node.js:374:12 - util.js:16 trycatcher [frontend]/[bluebird]/js/release/util.js:16:23 - reduce.js:166 object.gotvalue [frontend]/[bluebird]/js/release/reduce.js:166:18 - reduce.js:155 object.gotaccum [frontend]/[bluebird]/js/release/reduce.js:155:25 - util.js:16 object.trycatcher [frontend]/[bluebird]/js/release/util.js:16:23 - promise.js:547 promise._settlepromisefromhandler [frontend]/[bluebird]/js/release/promise.js:547:31 - promise.js:604 promise._settlepromise [frontend]/[bluebird]/js/release/promise.js:604:18 - promise.js:649 promise._settlepromise0 [frontend]/[bluebird]/js/release/promise.js:649:10
13:54:12 pm: failed loading drupal content changes - 0.031s
``` looks similar to
i am only 3 days with gatsby but i see strange issues
for example: 1
the graphql officials example stop working with an error `error: the result of this staticquery could not be fetched`
(full details on that issue here tried deleting the cache, modules, reinstalling, checking updats
did this in a loop for 5 hours
nothing helping
then i tried to use a hook like in here #composing-custom-usestaticquery-hooks and it started working
not only the hook but also the same, not touched first query that did not work for 5 hours
a lot of time the render not working
i edit, no change
then i edit another component (just added a space and save) and the render works again
i get a lot of other rander issues that are fixed with deleting cache, modules, reinstalled
is this only me? i wanted to use gatsby for a project but right now i have doubts
is gatsby safe to use at the moment? is something wrong with me or this is happening to you too? because when i google gatsby i see that a lot of people say it is super buggy =(
d:\\formation>gatsby
c:\\users\\jlouis.jlg.000\\appdata\ oaming\ pm\ ode_modules\\gatsby\ ode_modules\\yoga-layout-prebuilt\\yoga-layout\\build\ elease\ bind.js:53 throw ex; ^ error: cannot find module 'react'
require stack:
- c:\\users\\jlouis.jlg.000\\appdata\ oaming\ pm\ ode_modules\\gatsby\ ode_modules\\gatsby-recipes\\dist\\index.js
- c:\\users\\jlouis.jlg.000\\appdata\ oaming\ pm\ ode_modules\\gatsby\ ode_modules\\gatsby-cli\\lib\ ecipes.js
- c:\\users\\jlouis.jlg.000\\appdata\ oaming\ pm\ ode_modules\\gatsby\ ode_modules\\gatsby-cli\\lib\\create-cli.js
- c:\\users\\jlouis.jlg.000\\appdata\ oaming\ pm\ ode_modules\\gatsby\ ode_modules\\gatsby-cli\\lib\\index.js
- c:\\users\\jlouis.jlg.000\\appdata\ oaming\ pm\ ode_modules\\gatsby\\dist\\bin\\gatsby.js
- c:\\users\\jlouis.jlg.000\\appdata\ oaming\ pm\ ode_modules\\gatsby\\cli.js
the process is jammed/ stopped at ' load plugins..' when i run ' gatsby develop' in the terminal.
after installing gatsby-offline-plugin i get blank screen on some pages and errors like this in the console:
`typeerror: cannot read property 'uid' of undefined
at t.default (single-product.ks:164)
and after i reload the page the error disappears and everything looks normal
i think it has something to do with the service worker since installing `gatsby-plugin-remove-serviceworker` fixes the problem
but i don't want to disable the service worker
also 100% of the times i had a blank screen it was on a page with a query
not sure if it's important but i am using `gatsby-plugin-transition-link` so the menu doesn't reload between pages
for `gatsby-source-contentful` version 2.1.45 and newer, when trying to access content from a contentful space in another environment than `master` (for instance `development`) with an access token that is only allowed for this environment, but not also for `master`, gatsby fails to connect with the message _'accessing your contentful space failed.'_
it connects successfully if the access token also allows access to the `master` environment, but i need to have individual access tokens for each environment.
this behavior only occurs since `gatsby-source-contentful` version 2.1.45, including the most recent version 2.3.46
for older versions up to 2.1.44, it works fine.
the result provided from `gatsby build` is broken compared to `gatsby develop`
the classname of a specific component will either be not there at all whatsoever, not even an empty `class=""`, or, it will be a classname for some other component nearby.
update - i missed the fact that `assetpath` is expected to by a url and not just a path - i think the key question stands - should page urls have a assetpath prefix? when trying to segment the hosting of pages vs cdn assets using the gatsby-config#assetpath feature, the plugin `gatsby-plugin-netlify` outputs file prefixes `assetpath` on page urls
i believe that `assetprefix` is only supposed to apply to the css and js assets built by gatsby
in this case, the plugin behavior seems to be treating the `assetprefix` more like the `pathprefix` configuration option
i would expect that the html page references listed in `_headers` would not contain the `assetprefix` the path for `/page-2/` is the test page shown below
see codesandbox: - [ ] what is the behavior of pages and assetpath in _headers
- [ ] secondary issue - should the assets listed (e.g
`/app-140865cdb6a305440c80.js`) contain the prefix for their cache-control settings?
i cant build my app due to this error on build / develop:
error: cannot find module 'gatsby-telemetry' require stack: - /volumes/work/l+r/www/website-gatsby/node_modules/gatsby-plugin-page-creator/create-page-wrapper.js - /volumes/work/l+r/www/website-gatsby/node_modules/gatsby-plugin-page-creator/gatsby-node.js - /volumes/work/l+r/www/website-gatsby/node_modules/gatsby/dist/bootstrap/resolve-module-exports.js - /volumes/work/l+r/www/website-gatsby/node_modules/gatsby/dist/bootstrap/load-plugins/validate.js - /volumes/work/l+r/www/website-gatsby/node_modules/gatsby/dist/bootstrap/load-plugins/load.js - /volumes/work/l+r/www/website-gatsby/node_modules/gatsby/dist/bootstrap/load-plugins/index.js - /volumes/work/l+r/www/website-gatsby/node_modules/gatsby/dist/services/initialize.js - /volumes/work/l+r/www/website-gatsby/node_modules/gatsby/dist/services/index.js - /volumes/work/l+r/www/website-gatsby/node_modules/gatsby/dist/state-machines/develop/services.js - /volumes/work/l+r/www/website-gatsby/node_modules/gatsby/dist/state-machines/develop/index.js - /volumes/work/l+r/www/website-gatsby/node_modules/gatsby/dist/commands/develop-process.js - /volumes/work/l+r/www/website-gatsby/.cache/tmp-94644-7dznl5r3b00g - loader.js:794 function.module._resolvefilename internal/modules/cjs/loader.js:794:15 - loader.js:687 function.module._load internal/modules/cjs/loader.js:687:27 - loader.js:849 module.require internal/modules/cjs/loader.js:849:19 - v8-compile-cache.js:159 require [website-gatsby]/[v8-compile-cache]/v8-compile-cache.js:159:20 - create-page-wrapper.js:16 object.<anonymous> [website-gatsby]/[gatsby-plugin-page-creator]/create-page-wrapper.js:16:24 - v8-compile-cache.js:178 module._compile [website-gatsby]/[v8-compile-cache]/v8-compile-cache.js:178:30 - loader.js:973 object.module._extensions..js internal/modules/cjs/loader.js:973:10 - loader.js:812 module.load internal/modules/cjs/loader.js:812:32 - loader.js:724 function.module._load internal/modules/cjs/loader.js:724:14 - loader.js:849 module.require internal/modules/cjs/loader.js:849:19 - v8-compile-cache.js:159 require [website-gatsby]/[v8-compile-cache]/v8-compile-cache.js:159:20 - gatsby-node.js:24 object.<anonymous> [website-gatsby]/[gatsby-plugin-page-creator]/gatsby-node.js:24:26 - v8-compile-cache.js:178 module._compile [website-gatsby]/[v8-compile-cache]/v8-compile-cache.js:178:30 - loader.js:973 object.module._extensions..js internal/modules/cjs/loader.js:973:10 - loader.js:812 module.load internal/modules/cjs/loader.js:812:32 - loader.js:724 function.module._load internal/modules/cjs/loader.js:724:14
![image]( after upgrading `gatsby-plugin-mdx` and later `gatsby-remark-images` while debugging, image captions became broken
that is when writing markdown as `![caption](url)`
i can't tell if the bug is with `gatsby-remark-images` or with `gatsby-plugin-mdx`
the issue changed from saying `[object promise]` to the code printout in my screenshot when i upgraded gatsby-remark-images.
not able to run storybook with gatsby project (core-js problems?)
there is a z-indexing issue on page where the z-index of the dropdown menu is expected to be higher then the z-index of the template shown
when we hover over nav-links for the dropdown menu, the z-index of the dropdown menu is lower then the z-index of the template shown, so due to this few nav-links are not visible.
we recently started using `promise.allsettled` in our application code
this is correctly pulled into the polyfill bundle because some browsers don't support it yet
the gatsby babel preset currently uses `core-js@3` to polyfill syntax that is not supported by whatever browserslist config your project uses
however, if a particular syntax is a _proposal_ (e.g
`promise.allsettled`: this is currently **not** polyfilled automatically
this is confusing for developers and solvable by simple configuration change to gatsby's usage of babel preset env: #corejs
occasionally, when i run `gatsby develop`, i will get the error `error: enoent: no such file or directory, open '/users/jmeng/montavistamun/.cache/json/_dev-404-page_.json'` after gatsby finishes the build step
**it doesn't happen every time, and if i rerun gatsby develop it will usually go away.** you can see the error here:
in this recording, i clone the repo straight from github and make no modifications.
`gatsby develop` fails when transforming images with `gatsby-transformer-sharp`/`gatsby-plugin-sharp` with error: ```zsh
vipsjpeg: invalid sos parameters for sequential jpeg
vipsjpeg: out of order read at line 0
vipsjpeg: invalid sos parameters for sequential jpeg
``` likely that the error is related to incorrectly encoded samsung jpegs per this [issue]( in the `sharp` repository
if the `sharp` plugins for gatsby allowed the passing of an option for `failonerror: false` (as suggested in the [issue]( #issuecomment-474299429)), that might be enough to resolve this error
or perhaps instead of that specific option, allowing the passing through of an object with any of the acceptable options as outlined in the `sharp` [docs]( #parameters).
the page does not display images
the components are not styled correctly, but when i am routed to another page the problem seems to fix itself
some types of images cause gatsby to throw an error during build
there's no error message or context that shows **which specific image** is causing the problem
while i'm pretty sure the actual error lies in a dependency of gatsby, may aim with this bug report is to find out how to **figure out which image is causing the problem**
that, i believe, gatsby could tell me
i have a site with ~2k images, and some of them throw this error
it's quite laborious to try to figure out which ones by trial an error!
onrouteupdate function in gatsby-browser fires only one time after page is loaded, afterwards it never gets called
the bug can be seen here:
getting 'building production javascript and css bundles' - error - during build process
![200908 gatsby retro_unhandled_rejection](
i have been having this problem with every new project i start using gatsby-cli
i upgraded brew, node, npm, gatsby-cli..
i tried using yarn
still, i get a problem with the "gatsby new" command because of something with "install.js".
**i\'m getting this error after saving a file in my local environment.** `" warning: event "xstate.after(1000)#waitingmachine.batchingnodemutations" was sent to stopped service "waitingmachine"
this service has already reached "` also **hot reloading** is working whenever it wants too
sometimes i even have to restart the whole server to see my changes.
access this url from chrome browser breaks the page
#% don't have reproducible code yet, will update this thread soon
internal/modules/cjs/loader.js:979 throw err; ^ error: cannot find module '@mdx-js/mdx'
require stack:
- /users/mikey/sites/gimmix/node_modules/gatsby-recipes/dist/transform-recipe-mdx.js
- /users/mikey/sites/gimmix/node_modules/gatsby-recipes/dist/renderer/index.js
- /users/mikey/sites/gimmix/node_modules/gatsby-recipes/dist/validate-steps.js
- /users/mikey/sites/gimmix/node_modules/gatsby-recipes/dist/recipe-machine/index.js
- /users/mikey/sites/gimmix/node_modules/gatsby-recipes/dist/graphql-server/server.js at function.module._resolvefilename (internal/modules/cjs/loader.js:976:15) at function.module._load (internal/modules/cjs/loader.js:859:27) at module.require (internal/modules/cjs/loader.js:1036:19) at require (internal/modules/cjs/helpers.js:72:18) at object.<anonymous> (/users/mikey/sites/gimmix/node_modules/gatsby-recipes/dist/transform-recipe-mdx.js:12:35) at module._compile (internal/modules/cjs/loader.js:1147:30) at object.module._extensions..js (internal/modules/cjs/loader.js:1167:10) at module.load (internal/modules/cjs/loader.js:996:32) at function.module._load (internal/modules/cjs/loader.js:896:14) at module.require (internal/modules/cjs/loader.js:1036:19) { code: 'module_not_found', requirestack: [ '/users/mikey/sites/gimmix/node_modules/gatsby-recipes/dist/transform-recipe-mdx.js', '/users/mikey/sites/gimmix/node_modules/gatsby-recipes/dist/renderer/index.js', '/users/mikey/sites/gimmix/node_modules/gatsby-recipes/dist/validate-steps.js', '/users/mikey/sites/gimmix/node_modules/gatsby-recipes/dist/recipe-machine/index.js', '/users/mikey/sites/gimmix/node_modules/gatsby-recipes/dist/graphql-server/server.js' ]
i recently performed an 'npm install gatsby-cli' after it was reporting being out of date
after the update, all builds (both build and develop) are failing with the following message
verbose running command: develop
internal/modules/cjs/loader.js:895 throw err; ^ error: cannot find module '@mdx-js/mdx'
require stack:
- /usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/transform-recipe-mdx.js
- /usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/renderer/index.js
- /usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/validate-steps.js
- /usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/recipe-machine/index.js
- /usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/graphql-server/server.js at function.module._resolvefilename (internal/modules/cjs/loader.js:892:15) at function.module._load (internal/modules/cjs/loader.js:742:27) at module.require (internal/modules/cjs/loader.js:964:19) at require (internal/modules/cjs/helpers.js:88:18) at object.<anonymous> (/usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/transform-recipe-mdx.js:12:35) at module._compile (internal/modules/cjs/loader.js:1075:30) at object.module._extensions..js (internal/modules/cjs/loader.js:1096:10) at module.load (internal/modules/cjs/loader.js:940:32) at function.module._load (internal/modules/cjs/loader.js:781:14) at module.require (internal/modules/cjs/loader.js:964:19) { code: 'module_not_found', requirestack: [ '/usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/transform-recipe-mdx.js', '/usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/renderer/index.js', '/usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/validate-steps.js', '/usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/recipe-machine/index.js', '/usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/graphql-server/server.js' ]
} verbose transition to "initializing" original error: workererror: processing <path to png file> failed original error: - jobs-manager.ts:318 enqueuejob [gamedesignninja.com]/[gatsby]/src/utils/jobs-manager.ts:318:21 - task_queues.js:93 processticksandrejections internal/process/task_queues.js:93:5
``` i can confirm that @mdx-js/mdx is successfully installed in the node_modules folder.
gatsby cli fails with the following errors ```shell
/usr/local/lib/node_modules/gatsby-cli/node_modules/uuid/dist/esm-browser/index.js:1
export { default as v1 } from './v1.js';
^^^^^^ syntaxerror: unexpected token 'export' at wrapsafe (internal/modules/cjs/loader.js:1055:16) at module._compile (internal/modules/cjs/loader.js:1103:27) at object.module._extensions..js (internal/modules/cjs/loader.js:1159:10) at module.load (internal/modules/cjs/loader.js:988:32) at function.module._load (internal/modules/cjs/loader.js:896:14) at module.require (internal/modules/cjs/loader.js:1028:19) at require (internal/modules/cjs/helpers.js:72:18) at object.<anonymous> (/usr/local/lib/node_modules/gatsby-cli/node_modules/gatsby-telemetry/lib/telemetry.js:8:13) at module._compile (internal/modules/cjs/loader.js:1139:30) at object.module._extensions..js (internal/modules/cjs/loader.js:1159:10)
hello, everytime i try to install a gatsby theme i have this error: error: command failed with exit code 1: yarnpkg i tried this: gatsby new gatsby-graphcms-ecommerce-starter result:
![image]( environment:
v14.9.0 npm -v
6.14.8 yarn --v
yarn install v1.22.5 gatsby-cli@2.12.91
building and serving a deploy of the 'gatsby-starter-default' project throws several errors regarding fetching staticquery.
`error: the result of this staticquery could not be fetched.`
dropdown menu item gets the wrong position when changing the viewport
an error (`unhandled rejection lock is already released`) is thrown when closing a development session on macos using ctrl+c (sigint) after upgrading to gatsby 2.24.53
the error is only thrown when running development using `npm run develop`
it does not occur if using a globally installed instance of the cli using `gatsby develop` the issue occurs only on macos - i could not replicate under windows 10 on wsl2.
you can't use your keyboard to scroll through the documentation.
fixes #26776 ### documentation <!-- where is this feature or api documented? - if docs exist: - update any references, if relevant
this includes guides and gatsby internals docs
- if no docs exist: - create a stub for documentation including bullet points for how to use the feature, code snippets (including from happy path tests), etc
- tag @gatsbyjs/learning for review, pairing, polishing of the documentation
--> ## related issues <!-- link to the issue that is fixed by this pr (if there is one) e.g
fixes #1234 link to an issue that is partially addressed by this pr (if there are any) e.g
addresses #1234 link to related issues (if there are any) e.g
related to #1234
im running ```gatsby build``` it fails with
the following error ``` error #11328 a page component must export a react component for it to be valid
please make sure this file exports a react component: undefined not finished createpagesstatefully - 0.222s
``` the same does not happen in development env, i.e
gatsby develop
found another bug in file routing
you use slugify for cretaing slugs from strings
for some reason it is not removing "."s
so while slugify would output "mrs.-doubtfire" somewhere else the actual slug gets shortened to "mrs"
i'm trying to salvage an inherited project developed with gatsby
running into lots of issues with the build, particularly it hangs on the `source and transform` stage for quite some period of time
the build either hangs on `source and transform` and i'll need to kill it or the one time i just let it run and walked away to do some errands it finally progressed to: ```
gatsby build
success open and validate gatsby-configs - 0.054s
success load plugins - 0.487s
success onpreinit - 0.032s
success delete html and css files from previous builds - 0.006s
success initialize cache - 0.025s
success copy gatsby files - 0.047s
success onprebootstrap - 0.006s
success createschemacustomization - 0.008s gatsby source api server response error: plugin apiserver the server response was "408 request_timeout" error plugin apiserver http request failed
the server response was "408 request_timeout" request failed with status code 408 error: request failed with status code 408 - createerror.js:16 createerror [swap-console]/[axios]/lib/core/createerror.js:16:15 - settle.js:17 settle [swap-console]/[axios]/lib/core/settle.js:17:12 - http.js:236 incomingmessage.handlestreamend [swap-console]/[axios]/lib/adapters/http.js:236:11 - task_queues.js:84 processticksandrejections internal/process/task_queues.js:84:21 error #11321 plugin "gatsby-source-apiserver" threw an error while running the sourcenodes lifecycle: cannot read property \'response\' of undefined 116 | // interpolate entities from nested response 117 | if (entitylevel) {
> 118 | entities = objectref(entities, entitylevel); | ^ 119 | } 120 | 121 | // if entities is a single object, add to array to prevent issues with creating nodes file: node_modules/gatsby-source-apiserver/gatsby-node.js:118:22 typeerror: cannot read property 'response' of undefined - helpers.js:6 exports.objectref [swap-console]/[gatsby-source-apiserver]/helpers.js:6:14 - gatsby-node.js:118 [swap-console]/[gatsby-source-apiserver]/gatsby-node.js:118:22 - generator.next - gatsby-node.js:1 step [swap-console]/[gatsby-source-apiserver]/gatsby-node.js:1:253 - gatsby-node.js:1 [swap-console]/[gatsby-source-apiserver]/gatsby-node.js:1:423 - runmicrotasks - task_queues.js:97 processticksandrejections internal/process/task_queues.js:97:5 not finished source and transform nodes - 3601.021s
currently, i am using `gatsby-remark-prismjs` in order to add style to code blocks
i would expect that my theme would apply the styles, but currently i get just white text.
with the little documentation you have for `gatsby-remark-autolink-headers` and by traversing the test cases, applying the `enablecustomid` logic, the {#customid} string is not removed from the headings..
i'm getting an erroneous error
when i try to include a fragment in a page query, gatsby breaks, _supposedly_ because that fragment isn't being used ..
>success onpreextractqueries - 0.002s
> error #85901 graphql
> > there was an error in your graphql query:
> > fragment "productfields" is never used.
> > graphql request:53:3
> 53 | fragment productfields on postgraphile_product {
> 54 | title
> > file: src/pages/admin.js:60:3
> > failed extract queries from components - 0.990s but the thing is ..
that fragment _is_ being used (multiple times) in the query directly above it: export const query = graphql` # parts of query you don't care about products { ...productfields } also, perhaps more importantly, i'm using the _exact same_ query (i literally copy/pasted it) in my `gatsby-node.js` file, and it works perfectly fine there
unless there is some prohibition against using fragments in page queries this seems like a bug.
on gatsby cloud the user menu is overlapping with the contributors image.
running `gatsby develop` results in 2 errors stating: **"unknown option: .reactruntime"** it might be something to do with images, as i noticed the errors crop up just after the console statement: "generating image thumbnails"..
success createpages - 16.044s
success checking for changed pages - 0.002s
success createpagesstatefully - 0.102s
success update schema - 0.116s
success write out redirect data - 0.002s
success build manifest and related icons - 0.117s
success onpostbootstrap - 0.127s
info bootstrap finished - 77.267s
success onpreextractqueries - 0.003s
success extract queries from components - 0.406s
success write out requires - 0.046s
success run static queries - 0.212s - 1/1 4.72/s
success run page queries - 1.786s - 1679/1679 940.12/s
success generating image thumbnails - 4.130s - 6/6 1.45/s error #98123 webpack generating development javascript bundle failed unknown option: .reactruntime
check out #options for more information about options
file: .cache/polyfill-entry.js error #98123 webpack generating development javascript bundle failed unknown option: .reactruntime
check out #options for more information about options
file: .cache/app.js failed building development bundle - 0.747s
the gatsby mdx starter fails to build (when being used in a yarn workspace monorepo), returning a very confusing "invalid hook call" error in `@mdx-js/react`: <img width="674" alt="screen shot 2020-09-01 at 13 04 16" src=" "> error: ```sh
$ yarn build
yarn run v1.22.5
$ gatsby build
success open and validate gatsby-configs - 0.073s
success load plugins - 6.487s
success onpreinit - 0.086s
success delete html and css files from previous builds - 0.073s
info one or more of your plugins have changed since the last time you ran gatsby
a precaution, we're deleting your site's cache to ensure there's no stale data.
success initialize cache - 0.077s
success copy gatsby files - 0.183s
success onprebootstrap - 0.031s
success createschemacustomization - 0.031s
warn the gatsby-plugin-mdx plugin has generated no gatsby nodes
do you need it?
success checking for changed pages - 0.012s
success source and transform nodes - 0.148s
success building schema - 0.617s
success createpages - 0.005s
success checking for changed pages - 0.002s
success createpagesstatefully - 1.136s
success update schema - 0.097s
success onpreextractqueries - 0.006s
success extract queries from components - 0.958s
success write out redirect data - 0.042s
success build manifest and related icons - 0.005s
success onpostbootstrap - 0.018s
info bootstrap finished - 17.979s
success run static queries - 0.031s - 1/1 31.86/s
success run page queries - 0.102s - 1/1 9.80/s
success write out requires - 0.005s
success building production javascript and css bundles - 20.316s
failed building static html for pages - 4.340s error #95313 building static html failed for path "/" see our docs page for more info on this error: 118 | }; 119 | var usemdxcomponents = function usemdxcomponents(components) {
> 120 | var contextcomponents = react.usecontext(mdxcontext); | ^ 121 | var allcomponents = contextcomponents; 122 | 123 | if (components) { webpackerror: minified react error #321; visit for the full message or use the non-minified dev environment for full errors and additional helpful warnings
- esm.js:120 [gatsby-mdx-monorepo-bug-reproduction]/[@mdx-js]/react/dist/esm.js:120:32 - esm.js:113 [gatsby-mdx-monorepo-bug-reproduction]/[@mdx-js]/react/dist/esm.js:113:1 - context.js:1 [gatsby-mdx-monorepo-bug-reproduction]/[gatsby-plugin-mdx]/context.js:1:1 - invariant.js:28 [gatsby-mdx-monorepo-bug-reproduction]/[invariant]/invariant.js:28:1 error command failed with exit code 1.
info visit for documentation about this command.
``` if you visit the link to the minified error description, it says: > invalid hook call
hooks can only be called inside of the body of a function component
this could happen for one of the following reasons: 1
you might have mismatching versions of react and the renderer (such as react dom) 2
you might be breaking the rules of hooks 3
you might have more than one copy of react in the same app see for tips about how to debug and fix this problem.
newer versions of gatsby are not compatible with shopify-buy in ie11
on some of the latest versions of gatsby you will receive a console error about valueof being undefined, when trying to create an empty checkout
2.24.4 - console error valueof
2.24.0 - console error valueof if you will have a look at the response from graphql/shopify, you will notice that the checkoutid value is null on ie11
other browsers are working fine without any problems
![screen shot 2020-09-01 at 9 29 23 am](
error processing a .png file when running `gatsby develop`
i've been wrestling with this for the past day and i just can't figure out what is happening under the hood
the error i get on compile is: ```bash
error #98123 webpack generating development javascript bundle failed unexpected token 'export' file: ../gatsby-theme-wordpress-starter/src/assets/css/index.css failed building development bundle - 3.622s
``` the contents of index.css are: ```css
@tailwind base;
@tailwind components;
@tailwind utilities; h1 { @apply text-lg;
following the [visual testing tutorial ]( from gatsbyjs.com ends with a storybook setup that does not support css modules
here is a button component rendering via `gatsby develop`
<img width="323" alt="screen shot 2020-08-31 at 4 36 08 pm" src=" "> and here is the button rendering in storybook - the styles from the css modules are missing
<img width="488" alt="screen shot 2020-08-31 at 4 36 13 pm" src=" ">
npm v7 cannot install gatsby as a dependency without using `--legacy-peer-deps`
doing so results in a dependency tree with mismatched peer dependencies.
when using `gatsby-image` with multiple sizes of fixed images, using media queries for art direction, the inline sizing styles applied by default on static pages cause images to sometimes be displayed at the wrong size for the source file's resolution, and don't match the typical `<picture>` result.
it seems like `onbeforeexit` isn't called when the process gets killed by `sigint` and `sigtem`.
> the 'beforeexit' event is not emitted for conditions causing explicit termination, such as calling process.exit() or uncaught exceptions.
#process_event_beforeexit using singal-exit i'm sure everything gets called
i also switched to execa.node to use the same node version as it's started with
### related issues
fixes
hey there gatsby team, i am seeing duplicated entries for references many fields under these specific circumstances: 1
references many field with circular reference( main nav -> pages -> main nav)
after publishing, then `.cache` is cleared, duplicate and incorrect entries are returned querying the contentful graphql api directly works perfectly fine so it's an issue with a references many that has a circular reference with gscontentful
i\'ve tried filtering with `(filter: {node_locale: {eq: "en-us"}})` with no luck at all looking at: to fix the issue temporarily: 1
go to the problem type in the content editor
unpublish the entries
start your build/local dev and gatsby will have updated the entries and they will show correctly this will fix it until you clear your `.cache` and it will break again
here's the query that works in contentful: ```graphql
query { pagescollection(limit: 8) { items { componentsonpagecollection { items { ..
on mainnav { pagescollection(limit: 10) { items { route } } } } } } }
``` is this a regression perhaps? thanks for any insight!
attempting to upgrade to the latest version of mdx (2.0.0-next.7) breaks `gatsby-remark-images`.
gatsby develop is ok ,but gatsby build fail
try to use jwt auth with gatsby-source-wordpress and
but it's not working see the out put below, (removed email and password)
i'm not sure why does is say:
route discovered : /jwt-auth/v1
excluded route: blacklisted site hosted on wordpress.com: false
using acf: true
auth: jwt auth: email:password
verbose output: true mama route url: detected acf to rest namespace: acf/v2.
route discovered : /
excluded route: blacklisted
route discovered : /oembed/1.0
excluded route: blacklisted
route discovered : /oembed/1.0/embed
excluded route: blacklisted
route discovered : /oembed/1.0/proxy
excluded route: blacklisted
route discovered : /jwt-auth/v1
excluded route: blacklisted
route discovered : /jwt-auth/v1/token
excluded route: blacklisted
route discovered : /jwt-auth/v1/token/validate
when using `gatsby-remark-embed-snippet` (or any other plugin that read other file as remark transform) changes are not shown
not even after restart
i have to clean the cache or change the related `md` file where i want to see these changes.
use `gatsby-plugin-sass` to inject global style and use `gatsby-plugin-preload-fonts` to pre-load fonts in production mode causes flash of unstyled content.
the example execution error in the tutorial :
when building my site, i get an "unclosed comment" error with no further information when "building production javascript and css bundles"
the source code is available here: [![screenshot-2020-08-24-at-18-34-21.png](
the actions object is listed as undefined in `gatsby-node.js` in my `createpages` export
this is without any changes, just using (although i have installed gatsby-source-google-sheets)
i have a `onprerouteupdate` and a `onrouteupdate` in gatsby-browser, both log to the console
i also have a layout component that logs on render and wrapped via gatsby-browsers `wrappageelement`
on initial render, the logging order is: onprerouteupdate > layout > onrouteupdate
on subsequent navigations, the logging order is: layout > onprerouteupdate > onrouteupdate this seems confusing and wrong
if `onprerouteupdate` is supposed to be triggered _before_ a route update, layout cannot possibly be rerendered before that
ordering seems wrong here.
gatsby installed - ` "gatsby": "^2.24.47",`
syntaxerror: node_modules\\gatsby\\cache-dir\\gatsby-browser-entry.js: support for the experimental syntax 'jsx' isn't currently enabled
i\'m trying to use this `^(?!content\\/blog).*` in my query ```graphql query { allmdx( filter: { fileabsolutepath: { regex: "^(?!content\\/blog).*" } } ) { edges { node { id frontmatter { slug } } } }
``` but it gives me this error ```
invalid flags supplied to regexp constructor 'blog).*'
``` i have tested the regex on and it seems to work well there: ![image]( i don't know regex not sure how the regex that i have can be made valid
installing the plugin produced an npm audit warning
``` === npm audit security report === manual review some vulnerabilities require your attention to resolve visit for additional guidance high remote code execution package serialize-javascript patched in >=3.1.0 dependency of gatsby-plugin-netlify-cms path gatsby-plugin-netlify-cms > copy-webpack-plugin > serialize-javascript ```
when using a css included via a path provided by gatsby-plugin-resolve-src , this module throws with the following error: ```
file.js: cannot find module 'path/to/style.css'
when i click on an anchor link in a mdx page, the initial page animation that is based on `framer-motion`'s `animatepresence` kicks in - which it shouldn't
this happens because the location.hash change results in a rerender, all the way up from `root`, `locationhandler`, `routehandler`, via `wrappageelement` to my `layout` component
this is not supposed to happen on an anchor change - because if it does, i have no way to decide between an actual url change or an anchor change
interestingly enough, this works the way it\'s supposed to be on "normal" javascript pages.
attempt to fix character escape sequences in `regex` filters, i.e
queries like: ```js
export const query = graphql`
{ allfile(filter: {base: {regex: "/\\\\w+\\\\.png$/i"}}) { nodes { base } }
``` this is a follow-up to #25047 which was closed prematurely
- removes the backslash `replace`ing from [`utils/prepare-regex.ts`]( #l9-l12) which is not needed (any more? might have been before the switch away from relay)
- removes comment about double-escaping from the docs
- in tests, double-escaping is necessary when query is inline (see e.g
[this test here]( #l21-l55))
i have added two query tests in this pr to illustrate this (double-escaping when query defined inline, normal escaping when read via `fs.readfile`)
these are not strictly necessary and could be removed
- with these changes, queries with escape sequences will still break
this is an issue with `eslint-plugin-graphql` which gatsby uses - throws with "syntax error: invalid character escape sequence`
disabling the plugin [here]( #l18-l25) makes things work
i have opened upstream ## related issues #25047
i had an issue with consuming a third-party library packaged to esm with a rollup
they use yaml files for some default configs and rollup bundles them as `module.yml.js`
imports in distributed code look like this:
import importname from './module.yml.js'
with gatsby's current webpack config for yaml loader, such import ends up being processed as a yaml module instead of a js module
the proposed change is a no brainer as it simply makes the yaml rule test more strict requiring module paths to end with yaml or yml, just like the rest of the rules gatsby generates.
- 404 on link
- 404 on link
i'm trying to run `gatsby develop` on heroku to set up a custom gatsby preview server
this approach is recommended in the [gatsby docs here]( #rolling-your-own-preview) however, the page fails with `error: the result of this staticquery could not be fetched.`
when not using a static query the page renders fine.
i have deployed site through vercel and i'm facing following error
uncaught error: the result of this staticquery could not be fetched
this is likely a bug in gatsby and if refreshing the page does not fix it, please open an issue in at h (gatsby-browser-entry.js:77) at e.default (products.js:15) at ki (react-dom.production.min.js:153) at fa (react-dom.production.min.js:175) at vo (react-dom.production.min.js:263) at cu (react-dom.production.min.js:246) at ou (react-dom.production.min.js:246) at zo (react-dom.production.min.js:239) at react-dom.production.min.js:123 at kqks.t.unstable_runwithpriority (scheduler.production.min.js:19)
error shows when i click on `products` page or even `contact` page where isn't static query declared
this error didn't exist while developing
here's `products.js` file: ```
import { usestaticquery, graphql } from 'gatsby'
import product from '../components/product/product' const products = () => { const { allshopifyproduct: { edges }, } = usestaticquery(graphql` query products { allshopifyproduct { edges { node { title producttype shopifyid handle images { id localfile { childimagesharp { fluid { srcwebp tracedsvg base64 srcsetwebp } fixed { src } } } } variants { sku price title shopifyid } } } } } `) return ( <wrapper> <productsgrid> {edges.map(({ node }) => { return <product key={node.shopifyid} product={node} /> })} </productsgrid> </wrapper> )
} export default products
i added `query products` because i thought it'll help but it didn't.
i'm setting apollo client for using on hybrid app as described [here](
i've manage to create the private route with a normal react app so far, but i realized i started having hydration problems: elements on the dom appear with a different classname, even classnames from other components
they appear in different position causing it to look remotely different from the development version
i workarounded this by creating a <privateroute> component (that i named *protectbuild* to prevent the ssr of basically the whole appliction, even the pages that didn't have dynamic data.
this actually works well but basically is the same as having a pure react app with the benefit of having the data on the components without the need of fetching
still is better but it's not the desired behaviour.
i can\'t use sqip because of this "unknown fragment \\"gatsbycontentfulfixed_withwebp_nobase64\\"." error.
the typescript typings state that `parent` property of node interface can be of type `string` only, when in fact it also can be `null` in runtime when a node does not have a `parent` #l1520 ```
export interface node extends nodeinput { parent: string children: string[] internal: nodeinput["internal"] & { owner: string } [key: string]: unknown
i am not able to reopen issues, gatsbybot closing issues, but there is no chance to reopen them.
according to the `gatsby-link` typescript declaration file, `navigation` function returns a promise which resolves when react renders next screen
#l35 #l106 unfortunately, it's not a case, because `gatsby-link` exports `navigate` function which uses global `window.___navigate`:
#l269 `window.__navigate` uses `reach/router`'s `navigate` function under the hood:
#l49
i'm running into an issue where we add components to mdx global scope but those components don't render in the page if the theme is installed via npm, the compnents work fine if the theme is installed via yarn
we publish a theme (`gatsby-theme-minimal`) to a tag on github via `gitpkg`
this theme configures mdx via `gatsby-plugin-mdx`, configures pages and provides a component for rendering mdx files
several additional components are added to the `<mdxprovider>` in the theme: ```jsx
<mdxprovider components={{ box, test }}> <mdxrenderer>{mdx.body}</mdxrenderer>
</mdxprovider>
``` however when we install with `npm` in the `reproduction` folder we see this on the `/test/` page: ![2020-08-18_12-43-25]( we also see the following message in the console: ```
component box was not imported, exported, or provided by mdxprovider as global scope commons.js line 5071 > function:14:13
component test was not imported, exported, or provided by mdxprovider as global scope commons.js line 5071 > function:14:13
component box was not imported, exported, or provided by mdxprovider as global scope
``` installing with `yarn` in the reproduction folder produces this on the `/test/` page: ![2020-08-18_13-04-18](
sidebar updates from the pr #26106 are not synced there is a missing sync between .org/docs and .com/docs
- sidebar is not updated (`www/src/data/sidebars/doc-links.yaml`)
when using mdx plugin with `gatsby-remark-embed-snippet` and change the snippet file i don't see any changes in the browser.
my pages disappear after running `gatsby build` (it works just fine in my development environment (`gatsby develop`) and i get following error: ```error: enoent: no such file or directory, stat ``` **what i've tried so far**
ran `gatsby clean` before running `gatsby build`
deleted `.cache` folder and `public` folder manually before running `gatsby build`
deleted `.cache` folder and `public` folder and `node_modules` (+ reinstall) before running `gatsby build`
missing onerror handler for invocation 'rebuildschemawithsitepage', error was 'typeerror: cannot read property 'contents' of null'
stacktrace was 'typeerror: cannot read property 'contents' of null at get (/home/simon/tmp/bug-repro/node_modules/gatsby/src/utils/get-value-at.ts:10:20) at map (/home/simon/tmp/bug-repro/node_modules/gatsby/src/utils/get-value-at.ts:20:59) at array.map (<anonymous>) at getarray (/home/simon/tmp/bug-repro/node_modules/gatsby/src/utils/get-value-at.ts:19:6) at get (/home/simon/tmp/bug-repro/node_modules/gatsby/src/utils/get-value-at.ts:12:36) at get (/home/simon/tmp/bug-repro/node_modules/gatsby/src/utils/get-value-at.ts:13:50) at get (/home/simon/tmp/bug-repro/node_modules/gatsby/src/utils/get-value-at.ts:13:50) at get (/home/simon/tmp/bug-repro/node_modules/gatsby/src/utils/get-value-at.ts:13:50) at getvalueat (/home/simon/tmp/bug-repro/node_modules/gatsby/src/utils/get-value-at.ts:4:10) at getfirstvalueat (/home/simon/tmp/bug-repro/node_modules/gatsby/src/schema/infer/is-file.ts:14:15) at find (/home/simon/tmp/bug-repro/node_modules/gatsby/src/schema/infer/is-file.ts:84:13) at array.find (<anonymous>) at getfilepath (/home/simon/tmp/bug-repro/node_modules/gatsby/src/schema/infer/is-file.ts:83:41) at isfile (/home/simon/tmp/bug-repro/node_modules/gatsby/src/schema/infer/is-file.ts:91:20) at getsimplefieldconfig (/home/simon/tmp/bug-repro/node_modules/gatsby/src/schema/infer/add-inferred-fields.js:315:11) at getfieldconfig (/home/simon/tmp/bug-repro/node_modules/gatsby/src/schema/infer/add-inferred-fields.js:174:19)'
error #85923 graphql `there was an error in your graphql query:` `cannot query field "sitemetadata" on type "site".` `if you don\'t expect "sitemetadata" to exist on the type "site" it is most likely a typo.`
i noticed this on my own blog\'s "previous post" and "next post" links, and it\'s reproducible on `gatsby-starter-blog`
it may have broader implications beyond my use case as well
if you have links to "previous" and "next" posts on each blog post\'s page, then those are not updated on each build
as you add posts, they remember their cached "previous" link, but are never updated with the "next." if a post is removed, then existing "previous/next" links are preserved
(and its page will still exist in the build.)
there was the issue around [cannot find module 'gatsby-cli/lib/reporter']( - some of the starter repos have it updated now, but not the [starter repo]( referenced in the tutorial.
sometimes this [issue]( happens on the compare jamstack technologies page
sometimes when i stop gatsby server, it isn't actually being stopped
i run the command `gatsby develop -h 0.0.0.0` in vs code terminal, then stop the command with `control + c` and it is stopped in the terminal but then i run the command `gatsby develop -h 0.0.0.0` again and it says "something is already running at port 8000" and asks "would you like to run the app at another port instead?", i press `y` and it throws an error "looks like develop for this site is already running
try visiting maybe?" but nothing has even been run on port 8001
i'm not sure yet what could be the reason for such bug, i'm experiencing it all the time but can't understand the pattern yet to tell you how to reproduce it
maybe it has to do something with the changes it `gatsby-node.js` during the development and then me canceling to restart the server when gatsby asks for it
anyway, i'll post an update if i understand the pattern so you guys could reproduce this bug.
running `gatsby-cli` via npx fails with error `cb.apply is not a function`
when i follow the part three of the tutorial, after installing `gatsby-plugin-typography` using npm it gives me an error saying that it can't find module `react`.
i have this static query (in a node_module to another project
i got a common project for common gatsby stuff reused between many websites
so this file is not in my main project directly, is in node_modules) ``` export const recentposts: react.fc<{}> = () => { const data: data = usestaticquery(graphql` query { allmarkdownremark( sort: { order: desc, fields: [frontmatter___createdat] } limit: 20 filter: {frontmatter: {content: {eq:true}}} ) { edges { node { id excerpt(prunelength: 250) frontmatter { updatedat createdat path title description keywords } } } } } `) return ( <> <ul> {data.allmarkdownremark.edges.map((e, i) => { return ( <li key={i}> </li> ) })} </ul> </> )
} ``` and is built to this file: static/d/3852913098.json but the contents changed when i added a new post, but the file name is the same.
the **pathname** parameter in the **onrenderbody** function inside the **gatsby-ssr.js** file always return a slash(/) when running in development mode
but it's working fine in production mode
here's a snippet of my **gatsby-ssr.js** code: ```html
const config = require(\'./gatsby-config\') exports.onrenderbody = ( {pathname, setheadcomponents, setbodyattributes}, pluginoptions ) => { setheadcomponents([ <link rel="canonical" href={`${config.sitemetadata.siteurl}${pathname}`} />, ])
calling `createnodefield` with an incomplete node object will delete any fields on the node that are not attached to the `node` object you pass in.
my website is not displaying properly after `gatsby build` (or deployment on gatsby cloud) and my content is not showing, but it works just fine when i run `gatsby develop`
whenever i try to run `gatsby build`, it runs successfully but shows following warning: `chunk styles [mini-css-extract-plugin] conflicting order
following module has been added: * css ./node_modules/css-loader??ref--14-oneof-1-1!./node_modules/postcss-loader/src??postcss-3!./node_modules/sass-loader/dist/cjs.js??ref--14-oneof-1-3!./src/components/footer.scss despite it was not able to fulfill desired ordering with these modules: * css ./node_modules/css-loader??ref--14-oneof-1-1!./node_modules/postcss-loader/src??postcss-3!./node_modules/sass-loader/dist/cjs.js??ref--14-oneof-1-3!./src/components/forms.scss - couldn't fulfill desired order of chunk group(s) component---src-pages-index-js * css ./node_modules/css-loader??ref--14-oneof-1-1!./node_modules/postcss-loader/src??postcss-3!./node_modules/sass-loader/dist/cjs.js??ref--14-oneof-1-3!./src/components/headermain.scss - couldn't fulfill desired order of chunk group(s) component---src-pages-index-js - while fulfilling desired order of chunk group(s) component---src-pages-about-js, component---src-pages-books-js, component---src-pages-cart-js, component---src-pages-imprint-js, component---src-pages-product-details-js, component---src-pages-stockists-js` **what i've tried so far to resolve this issue**
i've tried to follow instructions in this [thread]( and it was suggested to re-order my imports
since my project is rather small, this is not a problem, but maybe i've messed something up while doing so
i'm using global styles
i've tried to only import my css only in the index.js (the error disappeared but the site was still displayed incorrectly after deployment) and i've tried to use the `sort-imports` plugin in vsc
(nothing changed)
two weeks ago i got a new bug-report in `gatsby-background-image`, [#125](
with the changes from pr #24306 `gbi` gets called again after its own `intersectionobserver` kicks in when scrolling down, which results in its given image getting loaded again for normal & adaptive images, stacked images seem to work.
only setting `critical` "rectifies" the repeated image loading, but that isn\'t a functional workaround in the long run.
and i guess in some cases this might happen for `gatsby-image` as well, but i didn't look into it
the "offending line" in the compiled output is the initialization (number 34 in `scroll-handler.js`): ```js
_this = _react$component.call.apply(_react$component, [this].concat(args)) || this;
``` i couldn't disable the behavior with a `shouldupdatescroll` in a `gatsby-browser.js`, or should this even be possible like this?
the workarounds from other issues like setting `"resolutions"` to `"gatsby-react-router-scroll": "3.0.0"` didn\'t work either
or is there any other way to prevent the `scrollhandler` from interrupting `gbi`s flow (or a thing i might be able to change)?
any help would be highly appreciated!
the `storybook-ts` gatsby recipe doesn't seem to be working
i am getting an error and a neverending installation phase
it also seems to be messing up when writing to `package.json` (see image) <img width="1440" alt="screenshot 2020-08-15 at 17 58 04" src=" "> <img width="1440" alt="screenshot 2020-08-15 at 17 58 00" src=" "> <img width="198" alt="image" src=" ">
after reaching the bottom of the table, scrolling further shows data (that was already there in the table) in an unformatted way.
typography does not work inside of theme npm package.
in a gatsby site with the `pathprefix` option set, fluid images generated by `gatsby-remark-images` with webp don't show (or show only the blur layer) in chrome and firefox
for a live example of this issue, see this [test page](
if you take a look at the generated html code you will see that `picture` elements have two `source` children: one for images in webp format and the other one for images in the original format (png or jpg)
note that __the paths in webp images do not include the pathprefix__, which is not the case of images on the original format.
sidebar updates from the pr #25503 are not synced there is a missing sync between .org/docs and .com/docs
- sidebar is not updated (`www/src/data/sidebars/doc-links.yaml`)
- redirects are not updated (`www/redirects.yaml`)
when using usescrollrestoration with a `div` i get:
property 'align' is missing in type 'htmlelement' but required in type 'htmldivelement'
error: cannot find module 'gatsby-cli/lib/reporter' require stack: - /users/jume/hello-world/node_modules/gatsby-plugin-page-creator/is-valid-col lection-path-implementation.js - /users/jume/hello-world/node_modules/gatsby-plugin-page-creator/create-pages -from-collection-builder.js - /users/jume/hello-world/node_modules/gatsby-plugin-page-creator/create-page- wrapper.js - /users/jume/hello-world/node_modules/gatsby-plugin-page-creator/gatsby-node
js - /users/jume/hello-world/node_modules/gatsby/dist/bootstrap/resolve-module-ex ports.js - /users/jume/hello-world/node_modules/gatsby/dist/bootstrap/load-plugins/vali date.js - /users/jume/hello-world/node_modules/gatsby/dist/bootstrap/load-plugins/load .js - /users/jume/hello-world/node_modules/gatsby/dist/bootstrap/load-plugins/inde x.js - /users/jume/hello-world/node_modules/gatsby/dist/services/initialize.js - /users/jume/hello-world/node_modules/gatsby/dist/services/index.js - /users/jume/hello-world/node_modules/gatsby/dist/state-machines/develop/serv ices.js - /users/jume/hello-world/node_modules/gatsby/dist/state-machines/develop/inde x.js - /users/jume/hello-world/node_modules/gatsby/dist/commands/develop-process.js - /users/jume/hello-world/.cache/tmp-53186-ih0e7pfkg9t2
we try to use bitbucket pipelines to build gatsby.js websites
time to time (not always) the build fails
the most often error is a segmentation fault:
success open and validate gatsby-configs - 0.040s
/bin/sh: lscpu: not found
success load plugins - 1.755s
success onpreinit - 0.061s
success delete html and css files from previous builds - 0.004s
success initialize cache - 0.009s
success copy gatsby files - 0.060s
success onprebootstrap - 0.022s
/bin/sh: lscpu: not found
success createschemacustomization - 0.016s
success checking for changed pages - 0.000s
success source and transform nodes - 0.494s
success building schema - 0.439s
success createpages - 0.004s
success checking for changed pages - 0.000s
success createpagesstatefully - 0.156s
success update schema - 0.241s
success onpreextractqueries - 0.001s
success extract queries from components - 0.700s
success write out redirect data - 0.005s
success onpostbootstrap - 0.000s
info bootstrap finished - 8.668s
segmentation fault (core dumped)
``` sometimes we get a different error:
success rewriting compilation hashes - 0.002s
error generating ssr bundle failed
can't resolve '../../../../../public/page-data/sq/d/440663142.json' in '/opt/atlassian/pipelines/agent/build/src/components/features/featuresheader/parallaxcontainer'
if you're trying to use a package make sure that '../../../../../public/page-data/sq/d/440663142.json' is installed
if you're trying to use a local file make sure that the path is correct.
error generating ssr bundle failed
not finished building static html for pages - 3.411s
npm err! code elifecycle
npm err! errno 1
npm err! website@0.1.0 build: `gatsby build`
npm err! exit status 1
npm err! npm err! failed at the website@0.1.0 build script.
npm err! this is probably not a problem with npm
there is likely additional logging output above.
npm err! a complete log of this run can be found in:
npm err! /root/.npm/_logs/2020-08-12t07_39_38_453z-debug.log
here is the pipeline script we use:
definitions: steps: - step: &build name: build image: node:14-alpine script: - npm ci --no-audit --progress=false --unsafe-perm - npm run build artifacts: - public/** pipelines: default: - step: *build
``` increasing build machine capacity with `size: 2x` helps a bit \xa8c failed builds appear less often.
when navigating using `gatsby`'s `navigate()` locally, `page-data.json` is fetched successfully from this location:
``` however, after a build, when serving locally, i get a 404 for this:
``` in production, i also get a 404
looks like there is only one `/` after `https:`:
i can not install gatsby-cli, this is the error i get: `(base) bilal@bilal-system:~/documents/gatsby-tutorial$ npm install -g gatsby-cli`
`npm warn deprecated @hapi/hoek@8.5.1: this version has been deprecated and is no longer supported or maintained`
`npm err! unexpected end of json input while parsing near \'....0.0","@babel/node":"\'`
`npm err! a complete log of this run can be found in:`
`npm err! /home/bilal/.npm/_logs/2020-08-13t18_16_01_911z-debug.log`` same with sudo:
`(base) bilal@bilal-system:~/documents/gatsby-tutorial$ sudo npm install -g gatsby-cli`
`[sudo] password for bilal:`
`npm warn deprecated @hapi/hoek@8.5.1: this version has been deprecated and is no longer supported or maintained`
`npm err! unexpected end of json input while parsing near \'....0.0","@babel/node":"\'` `npm err! a complete log of this run can be found in:`
`npm err! /home/bilal/.npm/_logs/2020-08-13t18_16_29_421z-debug.log`
hot reloading is not working at all.
i\'m getting "loading (staticquery)" in storybook for any component that uses `staticquery` and "the result of this staticquery could not be fetched." in storybook for any component that uses `usestaticquery`
everything seems to work fine locally and when built, but in storybook i am getting this: <img width="1552" alt="image" src=" "> <img width="1552" alt="image" src=" "> minimal reproduction: also opened an issue with storybook:
running `gatsby develop` ends in an error.
there are two scrollbars on ![screenshot from 2020-08-13 09-28-05](
i've encountered two css-related oddities that occur when using `gatsby develop` and not `gatsby build`
this seems to be (partly) related to #9911 but that issue remains closed so i'm re-reporting the problems here
problem 1: a page displayed under `gatsby develop` shows a bootstrap spinner but, under `gatsby build`, it does not
problem 2: a page displayed under `gatsby develop` changes colours when a completely unrelated line in a completely unrelated file is commented out & the file saved.
the starters page is broken
with the transition from gatsbyjs.org to gatsbyjs.com the path for the plugins is changed from `/packages/*` to `/plugins/*`, but this redirect is missing on gatsbyjs.com
incorrect description text rendering on new gatsby homepage.
when i create a new app and run it i get the error `error: cannot find module 'gatsby-cli/lib/reporter ` i believe the version of gatsby needs to be upgraded, per this issue: the application is currently being generated with version 2.24.41, rather than 2.24.42
$ gatsby build
success open and validate gatsby-configs - 0.026s
success load plugins - 0.136s
success onpreinit - 0.011s
success delete html and css files from previous builds - 0.035s
success initialize cache - 0.013s
success copy gatsby files - 0.271s
success onprebootstrap - 0.035s
success createschemacustomization - 0.008s
success source and transform nodes - 0.041s
success building schema - 0.264s
success createpages - 0.005s error #11328 a page component must export a react component for it to be valid
please make sure this file exports a react component: undefined not finished createpagesstatefully - 0.135s
in an attempt to fix the gatsby issue an error i was having when running gatsby build(this error):
a page component must export a react component for it to be valid
please make sure this file exports a react component i used this command: npm i -g gatsby-cli which seemed to download, but then brought up another issue bash: /c/users/joelr/appdata/roaming/npm/gatsby: permission denied in an attempt to go back i unistalled it using : npm uninstall gatsby-cli which worked but attempting to run any commands gatsby command runs into that permission denied error, and trying to reinstall gatsby globally results in this $ npm i gatsby-cli -g
npm warn deprecated core-js@2.6.11: core-js@<3 is no longer maintained and not recommended for usage due to the number of issues
please, upgrade your dependencies to the actual version of core-js@3.
npm warn optional skipping optional dependency: fsevents@~2.1.2 (node_modules\\gatsby-cli\ ode_modules\\chokidar\ ode_modules\\fsevents):
npm warn notsup skipping optional dependency: unsupported platform for fsevents@2.1.3: wanted {"os":"darwin","arch":"any"} (current: {"os":"win32","arch":"x64"})
npm warn ink@2.7.1 requires a peer of @types/react@>=16.8.0 but none is installed
you must install peer dependencies yourself.
npm warn gatsby-interface@0.0.166 requires a peer of gatsby@2.6.0 but none is installed
you must install peer dependencies yourself
npm warn gatsby-interface@0.0.166 requires a peer of react@16.8.1 but none is installed
you must install peer dependencies yourself.
npm warn gatsby-interface@0.0.166 requires a peer of react-dom@16.8.1 but none is installed
you must install peer dependencies yourself
npm warn acorn-dynamic-import@4.0.0 requires a peer of acorn@^6.0.0 but none is installed
you must install peer dependencies yourself.
npm warn @reach/tabs@0.10.3 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself.
npm warn @reach/alert@0.10.3 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself.
npm warn @reach/combobox@0.10.3 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself
npm warn @reach/popover@0.10.3 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself.
npm warn @reach/menu-button@0.10.3 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself.npm warn @reach/tooltip@0.10.3 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself
npm warn theme-ui@0.2.52 requires a peer of @mdx-js/react@^1.0.0 but none is installed
you must install peer dependencies yourself.
npm warn @reach/dialog@0.10.3 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself.
npm warn @reach/visually-hidden@0.10.4 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself.
npm warn @reach/utils@0.10.5 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself.
npm warn @reach/descendants@0.10.5 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself.npm warn @reach/auto-id@0.10.5 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself.
npm warn @reach/portal@0.10.5 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself.
npm warn @reach/rect@0.10.5 requires a peer of react-dom@^16.8.0 but none is installed
you must install peer dependencies yourself
npm err! code eperm
npm err! error: eperm: operation not permitted, open 'c:\\users\\joelr\\appdata\ oaming\ pm\\gatsby'
npm err! at isclobberable (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\gentle-fs\\lib\\bin-link.js:55:3)
npm err! at shimfiles.foreach.to (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\gentle-fs\\lib\\bin-link.js:38:27) npm err! at array.foreach (<anonymous>)
npm err! at binlink (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\gentle-fs\\lib\\bin-link.js:38:13)
npm err! at trycatcher (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\util.js:16:23)
npm err! at ret (eval at makenodepromisifiedeval (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\promisify.js:184:12), <anonymous>:13:39)
npm err! at linkbin (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bin-links\\index.js:126:10)
npm err! at bb.map.bin (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bin-links\\index.js:91:12)
npm err! at trycatcher (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\util.js:16:23)
npm err! at mappingpromisearray._promisefulfilled (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\map.js:61:38)
npm err! at mappingpromisearray.promisearray._iterate (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\promise_array.js:114:31)
npm err! at mappingpromisearray.init (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\promise_array.js:78:10)
npm err! at mappingpromisearray._asyncinit (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\map.js:30:10)
npm err! at _drainqueuestep (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\async.js:142:12) npm err! at _drainqueue (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\async.js:131:9)
npm err! at async._drainqueues (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\async.js:147:5)
npm err! { error: eperm: operation not permitted, open 'c:\\users\\joelr\\appdata\ oaming\ pm\\gatsby'
npm err! at isclobberable (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\gentle-fs\\lib\\bin-link.js:55:3)
npm err! at shimfiles.foreach.to (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\gentle-fs\\lib\\bin-link.js:38:27) npm err! at array.foreach (<anonymous>)
npm err! at binlink (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\gentle-fs\\lib\\bin-link.js:38:13)
npm err! at trycatcher (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\util.js:16:23)
npm err! at ret (eval at makenodepromisifiedeval (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\promisify.js:184:12), <anonymous>:13:39)
npm err! at linkbin (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bin-links\\index.js:126:10)
npm err! at bb.map.bin (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bin-links\\index.js:91:12)
npm err! at trycatcher (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\util.js:16:23)
npm err! at mappingpromisearray._promisefulfilled (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\map.js:61:38)
npm err! at mappingpromisearray.promisearray._iterate (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\promise_array.js:114:31)
npm err! at mappingpromisearray.init (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\promise_array.js:78:10)
npm err! at mappingpromisearray._asyncinit (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\map.js:30:10)
npm err! at _drainqueuestep (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\async.js:142:12) npm err! at _drainqueue (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\async.js:131:9)
npm err! at async._drainqueues (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\async.js:147:5) npm err! cause:
npm err! { error: eperm: operation not permitted, open 'c:\\users\\joelr\\appdata\ oaming\ pm\\gatsby'
npm err! at isclobberable (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\gentle-fs\\lib\\bin-link.js:55:3)
npm err! at shimfiles.foreach.to (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\gentle-fs\\lib\\bin-link.js:38:27)
npm err! at array.foreach (<anonymous>)
npm err! at binlink (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\gentle-fs\\lib\\bin-link.js:38:13)
npm err! at trycatcher (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\util.js:16:23)
npm err! at ret (eval at makenodepromisifiedeval (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\promisify.js:184:12), <anonymous>:13:39)
npm err! at linkbin (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bin-links\\index.js:126:10)
npm err! at bb.map.bin (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bin-links\\index.js:91:12)
npm err! at trycatcher (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\util.js:16:23)
npm err! at mappingpromisearray._promisefulfilled (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\map.js:61:38)
npm err! at mappingpromisearray.promisearray._iterate (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\promise_array.js:114:31)
npm err! at mappingpromisearray.init (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\promise_array.js:78:10)
npm err! at mappingpromisearray._asyncinit (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\map.js:30:10)
npm err! at _drainqueuestep (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\async.js:142:12) npm err! at _drainqueue (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\async.js:131:9)
npm err! at async._drainqueues (c:\\users\\joelr\\appdata\ oaming\ pm\ ode_modules\ pm\ ode_modules\\bluebird\\js\ elease\\async.js:147:5)npm err! message:
npm err! 'eperm: operation not permitted, open \\'c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\\gatsby\\'',
npm err! code: 'eperm' },
npm err! stack:
npm err! 'error: eperm: operation not permitted, open \\'c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\\gatsby\\'\ at isclobberable (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\gentle-fs\\\\lib\\\\bin-link.js:55:3)\ at shimfiles.foreach.to (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\gentle-fs\\\\lib\\\\bin-link.js:38:27)\ at array.foreach (<anonymous>)\ at binlink (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\gentle-fs\\\\lib\\\\bin-link.js:38:13)\ at trycatcher (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\bluebird\\\\js\\\ elease\\\\util.js:16:23)\ at ret (eval at makenodepromisifiedeval (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\bluebird\\\\js\\\ elease\\\\promisify.js:184:12), <anonymous>:13:39)\ at linkbin (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\bin-links\\\\index.js:126:10)\ at bb.map.bin (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\bin-links\\\\index.js:91:12)\ at trycatcher (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\bluebird\\\\js\\\ elease\\\\util.js:16:23)\ at mappingpromisearray._promisefulfilled (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\bluebird\\\\js\\\ elease\\\\map.js:61:38)\ at mappingpromisearray.promisearray._iterate (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\bluebird\\\\js\\\ elease\\\\promise_array.js:114:31)\ at mappingpromisearray.init (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\bluebird\\\\js\\\ elease\\\\promise_array.js:78:10)\ at mappingpromisearray._asyncinit (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\bluebird\\\\js\\\ elease\\\\map.js:30:10)\ at _drainqueuestep (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\bluebird\\\\js\\\ elease\\\\async.js:142:12)\ at _drainqueue (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\bluebird\\\\js\\\ elease\\\\async.js:131:9)\ at async._drainqueues (c:\\\\users\\\\joelr\\\\appdata\\\ oaming\\\ pm\\\ ode_modules\\\ pm\\\ ode_modules\\\\bluebird\\\\js\\\ elease\\\\async.js:147:5)',
npm err! code: 'eperm' }
npm err! the operation was rejected by your operating system.
npm err! it's possible that the file was already in use (by a text editor or antivirus),
npm err! or that you lack permissions to access it.
npm err! if you believe this might be a permissions issue, please double-check the
npm err! permissions of the file and its containing directories, or try running
npm err! the command again as root/administrator
npm err! a complete log of this run can be found in:
npm err! c:\\users\\joelr\\appdata\ oaming\ pm-cache\\_logs\\2020-08-12t12_05_49_735z-debug.log
when running "gatsby develop" after the latest maj, the development bundle seems to fail because of a wrong path parsing
this is blocking for deployment and build purpose.
i'm trying to filter records (blog articles in my case) by the `tags` field, which is an **array of strings**
i am looking to search for all articles which **contain** any tags from some array
example query is below: ```gql
query myquery { allcontentfularticle(filter: {tags: {in: ["environment","food"]}}) { nodes { id title tags } }
``` this should return any articles with *either* the `environment` tag or `food` tag
this does work, but for some reason this is returning duplicates for me, but only for cases when the article contains **both the tags** in the search array, with the exact same id (the actual response i get back is below): ```json
{ "data": { "allcontentfularticle": { "nodes": [ { "id": "89fd7eba-ccaf-5e43-aa4f-9455692f6940", "title": "hello world", "tags": [ "environment", "science" ] }, { "id": "7985f52d-048e-5f5d-8b18-52cf02624bb9", "title": "static sites are great", "tags": [ "environment", "food" ] }, { "id": "7985f52d-048e-5f5d-8b18-52cf02624bb9", "title": "static sites are great", "tags": [ "environment", "food" ] } ] } }
``` it's also worth noting that this is also the case for the `glob` operator (e.g
`environment|food`) or the regex operator.
using `--inspect-brk=0.0.0.0` with `gatsby develop` does not set debugger to listen on 0.0.0.0 [as node's docs indicate it does when used on node directly](
my site is pulling content from wordpress
as you can see from the query, the content has <p style=\\"text-align: center;\\"><a class=\\"button\\" href=\\"/get-started/\\">get started</a></p> there\'s a style for p tag
<img width="944" alt="screen shot 2020-08-11 at 12 41 13 pm" src=" "> when we run develop command
the page generated contain the style for the p tag
however, when we run build
the style disappears from the p tag
however the style in the h3 tag is still there
i don't know why the p tag style got striped only in build mode.
<img width="408" alt="screen shot 2020-08-11 at 12 45 39 pm" src=" ">
i'm new to gatsby and built a basic blog app
i installed a new theme and attempted to apply it and it completely broke my app
i\'m getting a bunch of "cannot query field x on type query" errors.
i have done a website using gatsby and when i tried to add icons i installed react-icons using npm but after this, the server is not launching
nearly every pending [add-starter pr]( is failing due to the `starters_validate` test on circleci failing
even the [past few merged prs]( were merged despite failing `starters_validate` which suggests that it is failing on valid submissions
![failed starter_validate tests](
i downloaded a baisc and simple `using-i18n` from
i installed gatsby plugin via `npm`
finally i ran `gatsby develop`, and it gave errors
the `gatsby-starter-default` also has problems with the same errors
i think it is because of `gatsby-cli`.
upgraded to v2.24.40 and can no longer develop a site using gatsby as it always fails.
gatsby develop will fail after a clean install
it fails starting on the createpagesstatefully step with the following error: ```
error #11321 plugin "gatsby-transformer-yaml" threw an error while running the oncreatenode lifecycle: bad indentation of a sequence entry at line 25, column 6: - title: inf mgt and vended svcs ^ 63 | 64 | const content = await loadnodecontent(node);
> 65 | const parsedcontent = jsyaml.load(content); | ^ 66 | 67 | if (_.isarray(parsedcontent)) { 68 | parsedcontent.foreach((obj, i) => { file: node_modules/gatsby-transformer-yaml/gatsby-node.js:65:32 yamlexception: bad indentation of a sequence entry at line 25, column 6: - title: inf mgt and vended svcs ^
this documentation page should list the guides in the plugins section
however, it appears that the output from the `guidelist` isn't producing the list in the published gatsbyjs site : `<guidelist slug={props.slug} />` here's the corresponding md file:
in [this pr]( there was a solution proposed to add custom queries for things like "quantityavailable" and "totalinventory"
however, neither of those fields seem to have been implemented in said pr
when adding the key `shopifyqueries` and providing the default product query provided in the repo to the config in `gatsby-config.js`, everything works fine
when i add `availablequantity` to the variants object (nested in the product query), i get: `field 'quantityavailable' doesn't exist on type 'productvariant'`
or `field 'totalinventory' doesn't exist on type 'product'` despite both being provided by the native shopify api.
i'm getting eslint warnings in a file that doesn't seem to exist when adding and configuring eslint using and
warn eslinterror:
/users/mrseanbaines/projects/gatsby-eslint/_this_is_virtual_fs_path_/$virtual/sync-requires.js 4:30 warning unexpected mix of '&&' and '||' no-mixed-operators 4:43 warning unexpected mix of '&&' and '||' no-mixed-operators
``` <img width="1440" alt="screenshot 2020-08-09 at 20 46 04" src=" ">
trying to use a hasura graphql endpoint that has a remote graphql to contentful throws the error: error: schema must contain uniquely named types but contains multiple types named "sys"
i'm trying to extend the `mdx` node type created by `gatsby-plugin-mdx`, with `gatsby-node`'s `createresolvers` or `createschemacustomization` api
in either case, this results in the `body` and `excerpt` fields (as well as others) not being available on the `mdx` node anymore.
solution renders as expected in dev but when built for prod it will not initialize custom css until going through a few pages
the asciidoc transformer seems to not return any data.
i cannot use the `gatsby develop` command because it leaves an empty `.cache/json` folder thus the dev server cannot serve the site
unforunately the codebase is private but i was able identify on which gatsby version the issue occured.
gatsby 2.24.8 and 2.24.10 => ok develop works normally gatsby 2.24.9 and 2.24.11 => develop works but output non blocking errors at the end of the script :
error loading a result for the page query in "/dev-404-page"
query was not run and no cached result was found.
error loading a result for the page query in "/404.html"
query was not run and no cached result was found.
error loading a result for the page query in "/"
query was not run and no cached result was found.
from gatsby 2.24.12 to current version 2.24.34 (i didn't test every version in between) =>.cache/json stays empty during develop script
this is the last output before crash :
success building development bundle - 55.715s error enoent: no such file or directory, open '/users/path/to/project/.cache/json/_...random..._page.json'
i've got this error during installing gatsby-cli globally
when i use `npm i gatsby-cli -g`, it happen error
![image]( node v10.21.0
npm v6.14.4
the deploy script fails and gives a message about node_modules being ignored
i am currently working on a project with gatsby and netlifycms, the site is live and working well at [herbamojo.id](
however recently my user started experiencing build failing issue due to "childimagesharp not defined"
after further investigation, the issue was caused by the sure using "double-space linebreak" inside an "ordered list"
i have created a repo from gatsby netlifycms starter [link](
i modified one blog post that originally looks like:
![screenshot 2020-08-05 at 21 05 33](
to this (notice the red mark to indicate double space)
![screenshot 2020-08-05 at 21 06 00]( this original blog has a featured image on the blog page, but after adding that double space the feature image disappear (a console log shows that childimagesharp is not defined).
<img width="1217" alt="screenshot 2020-08-05 at 22 08 20" src=" ">
<img width="1222" alt="screenshot 2020-08-05 at 22 10 15" src=" "> <img width="669" alt="screenshot 2020-08-05 at 22 32 14" src=" "> the issue doesn\'t show up initially during \'gatsby develop\'
the first tie i encounter it was during local 'gatsby build'
after further testing and reset, the error occurs on the second 'gatsby develop' and it is cached as well so that even if the double space is removed, only after using 'gatsby clean' we can reset the development back to normal
clearing the cache with gatsby clean and then running gatsby build manages to avoid the issue
i am still not sure why the error occurs on my netlify builds
replacing the double space line break with <br/> solves the issue
however, i am trying to avoid telling my user to use <br/> to smoothen the editorial experience
and the double space line break seems like [a default markdown syntax]( #line-breaks).
following the guidelines of [exporting javascript objects]( #using-javascript-exports) from mdx files is not possible due to the fact that the graphql type for the `exports` is an array of strings
when i look at the graphql types for the `allmdx` and `mdx` queries, the type of exports is marked to be an array of strings, while in the examples it is treated as an object
<img width="338" alt="screen shot 2020-08-04 at 8 37 25 pm" src=" ">
after 'react-dom' deletion can't run app using 'gatsby-plugin-preact' ( error: cannot find module 'react-dom/server').
if you include `childimagesharp` in your `gatsby-plugin-feed` query, then it will usually\\* crash on build
it seems to be that `gatsby-plugin-sharp` cannot generate new images when `gatsby-plugin-feed` runs
(\\*if the `childimagesharp` query is able to use cached images, then the build succeeds
if it has to generate new images, then the build fails.) an example of when this would be an issue: you have images in your markdown frontmatter to be used as ero images or ost thumbnails. even though they aren part of your markdown body, they e relevant to the content and you want to include them in your rss feed.
about once a day, when i restart my gatsby server it tells me that there is an instance of the project already running
it won't allow me to start another instance on a different port because it is already running
however, i have no interactive process open
i closed all terminals and reopened but the process is still running
when i check to see what is listening on the port with `lsof -n -i4tcp:8000 | grep listen`, i get a node pid
but the process won't be killed either with `kill pid` or `sudo kill pid`
the only fix i've found is to restart the machine.
after upgrading gatsby-cli to 2.12.70, when using gatsby commands, i am met with the following error: ```
/usr/lib/node_modules/gatsby-cli/node_modules/gatsby-recipes/dist/index.js:12851 return result?.value; ^ syntaxerror: unexpected token '.' at wrapsafe (internal/modules/cjs/loader.js:1053:16) at module._compile (internal/modules/cjs/loader.js:1101:27) at object.module._extensions..js (internal/modules/cjs/loader.js:1157:10) at module.load (internal/modules/cjs/loader.js:985:32) at function.module._load (internal/modules/cjs/loader.js:878:14) at module.require (internal/modules/cjs/loader.js:1025:19) at require (internal/modules/cjs/helpers.js:72:18) at object.<anonymous> (/usr/lib/node_modules/gatsby-cli/lib/recipes.js:8:22) at module._compile (internal/modules/cjs/loader.js:1137:30) at object.module._extensions..js (internal/modules/cjs/loader.js:1157:10)
when using `gatsby-plugin-sitemap` to generate sitemap.xml, `<lastmod>` was not available by default
manually adding this would output `<lastmod>` tags in the final sitemap.xml, but the date were written as `nan-nan-nan` **note:** even if we manually uses `lastmod: '2020-08-03t01:54:49.000z'` during the serialize below still outputs as nan
recent versions of `gatsby` have issues with hot-reload during `gatsby develop`
i'm constantly checking almost every release and this problem still persists as per `gatsby@2.24.23`
the latest ok version for me is `gatsby@2.24.9` so i keep rolling back to it.
this makes `findimports(...)` also run the `run(...)` phase from `unified`/`remark`
this is needed to allow plugins to inject esm imports via ast modifications
i have also added a test to cover this use case
### documentation #25437 broke a use case that i had a custom plugin for
basically, i need to inject imports via a plugin to enable code demos.
horizontal overflow when screen width < 750px only viewable when selecting a starter from starter library being caused by
<copy filename="install command" content={content} sx={{ borderradius: 1 }}
when selecting a starter from the starter library in dark mode, the page title is black on a dark background making it nearly impossible to be read
also, links to codesandbox, netlify, and the dependencies are dark blue, which also does not show up well on the dark background and doesn't match the rest of the site links.
in a project of mine, i process quite a lot of external images at build time
something weird started happening one day
the same image would appear on one page, and then not on another.
the queried field for the processed image would return `undefined`
i use gatsby image by the way
here is a simplified version of how i create the remote files at build time:
```javascript
const { createremotefilenode } = require("gatsby-source-filesystem"); exports.createschemacustomization = ({ actions }) => { const { createtypes } = actions; createtypes(` type mongodbvimcsrepositories implements node { processed_images: [file] } `);
}; exports.oncreatenode = ({ node, actions: { createnode }, store, cache, createnodeid,
}) => { if (node.internal.type === "<type>") { node.image_urls.foreach(async url => { const filenode = await createremotefilenode({ url, parentnodeid: node.id, createnode, createnodeid, cache, store, }); node.processed_images = [ ...(node.processed_images || []), filenode, ]; }); }
}; // page creation and more unrelated stuff below
``` to understand a little more what was happening, i started logging the url of the image after the `createremotefilenode` promise was resolved
i noticed some of them logged a little late in the build process, and coincidentally (or not), they were the images missing in the app on certain pages
in the screenshot below, all images between the two red lines do not get sent in the result of the page query
![screen shot 2020-07-31 at 18 06 12]( note that all the images are queried through page queries and not static queries
if it can be of any help, here is how i query the images on the page:
```javascript
export const query = graphql` query(<params>) { repository: <type>( <query> ) { <other fields> images: processed_images { childimagesharp { fluid(maxwidth: 1280, quality: 80) { ...gatsbyimagesharpfluid } } } } } `;
``` not sure if this is an issue with gatsby, or just how i create the remote nodes and the way i wait for the promises to resolve, or if it's an issue at all
anyway, i would appreciate a little insight into this as i thought it was interesting
### workaround i have found a way to work around this issue i've been having, but i'm not confident it's a good way to solve it.
what i did is accumulate the `createremotefilenode` promises in an array, and then await all the promises in the `onpostbootstrap` hook
then, i would be sure all the nodes were finished processing before passing onto the build phase
```javascript
exports.onpostbootstrap = async () => { await promise.all(imagepromises);
in [the documentation of `shouldupdatescroll`]( #shouldupdatescroll) it says that: > should return either an [x, y] array of coordinates to scroll to, a string of the id or name of an element to scroll to, false to not update the scroll position, or true for the default behavior
however, returning an array won't actually work.
this fixes line highlighting with other multiline token spans other than just `plain-text` (so for example various form of multiline comments, like triple quotes in python or `/*`, `*/` in js)
i added test case for it
## related issues fixes #26079
in the index page everything is working perfectly and other pages but when i created a folder and add more pages in the folder when going in to those pages some css and js are lost and all the icons when i refresh some css are back but not the icons
all other content that is output to public/static uses an md5 hash of the content in some way so that the content can be cached long term but some of the static files output by gatsby-source-contentful do not
this was causing some of our built files to not be visible after an update because for all the content in public/static we were using an immutable cache header
i'm not certain that all files within public/static should use some kind of file hash to ensure that if the content changes the file name also changes but all other content appears to follow some rule along these lines
also not certain that it is gatsby-source-contentful that is the problem but it is only page data related to contentful sourced data.
i\'m hung on the "source and transform nodes" step, and from the numerous related threads it seems this is a fairly common occurrence in gatsby ..
which is why this bug is _not_ yet another "please help me fix variant #972b of this bug" ;) instead, this bug is a plea to make it so users *don\'t need help*
surely it's possible to somehow surface greater information about this step, so that users can solve their own problems?
making e-commerce site with shopify
using this link
i am trying to implement it with my store but facing an issue as mentioned below in actual result.
fetching data via `usestaticquery` within a story causes storybook to break.
my gatsby project has suddenly started failing with the "error #98123 webpack generating development javascript bundle failed" error being generated for all pages and components as part of building the development bundle
the error has also appeared on netlify where the site is deployed
### error log ...
verbose transition to "runningqueries" > "writingrequires"
success write out requires - 0.040s
verbose transition to "runningqueries" > "calculatingdirtyqueries"
verbose transition to "runningqueries" > "runningstaticqueries"
verbose transition to "runningqueries" > "runningpagequeries"
success run page queries - 0.019s - 1/1 52.43/s
verbose transition to "runningqueries" > "waitingforjobs"
verbose transition to "runningqueries" > "done"
verbose transition to "startingdevservers" **error #98123** webpack generating development javascript bundle failed <path>/src/components/hero.js: file: src/components/hero.js **error #98123** webpack generating development javascript bundle failed <path>/src/components/layout.js: file: src/components/layout.js **this error is repeated for all pages and components on the site** and following by "failed re-building development bundle - 0.904s"
if you use the art direction feature with image objects differing in aspect ratios(fluid) or dimensions(fixed), ssr bakes in the css for the first image, but the first load(hydration) expects the initial state to match the css, this is not always the case if your breakpoint differs from ssr, react doesn't realize it needs to update the css
## notes an improvement would be to only block the initial render for art directed images, although that may burden maintenance due to adding another fork in the render path
this pr does not resolve the issue prior to react being ready, the wrong state for art directed images will still be an issue there, [pr available](
~~**warning:** this change makes `componentdidmount()` fire before `handleref()`, the `iscritical` logic will never work as the `imageref` will not be available at this point in time
[i have a fix for this as a part of larger pr here]( refactoring the behaviour it is a part of
[original pr related comment]( #issuecomment-662931510) (mostly the same information).~~ (shouldn't apply with september commits) ## related issues fixes #25938
fixes #24748
fixes #16888
fixes #16763 related: (original pr)
line hightlighting does not work for language python when line is inside span 'triple-quoted-string'.
site generated with `gatsby build` produces a mobile page that doesn't properly set the dom on page load
it works fine with `gatsby develop` in both desktop and mobile view, and the page works fine with vanilla react cra start and build
when generated with `gatsby build` the page produces incorrect page load in mobile view, but ok in desktop
resizing the browser from large to small, renders proper mobile page
as far as i have been able to dig, this is caused by missing `class` tags in html div entries in the dom of two components, `responsive` and `sidebar`, both `semantic-ui-react` components
#dom #l56-l84
per we embedded a greenhouse.io script `<script src=" "></script>` on our site and it loads fine the first time and the script then attaches an iframe to the target `<div id="grnhse_app"></div>` correctly
a subsequent reload does not execute the script though
it appears the script is only executed on initial load
a "unregister serviceworker" does allow it to be loaded on a normal refresh again.
i've been trying to troubleshoot why my use of the `withprefix` function doesn't seem to be working in production on my gh pages site
here is a snippet of the code where i use `withprefix` with `createpage`, in my `gatsby-node.js` file (link to the code is [here]( #l53)): note that if don't set the second argument to `withprefix`, i get `__base_path__ is undefined` when i run `npm run deploy`
exports.createpages = async ({ graphql, actions }) => { const { createpage } = actions const result = await graphql(` query { allimagesharp { nodes { fields { slug } } } } `) result.data.allimagesharp.nodes.foreach(node => { if (node && node.fields) { createpage({ path: withprefix(node.fields.slug, ''), component: path.resolve(`./src/templates/galleryitempage.js`), context: { // data passed to context is available // in page queries as graphql variables
slug: node.fields.slug, }, }) } })
i am defining my `pathprefix` in a `config.js` file (link [here]( which gets read in by my `gatsby-config.js` file
from my `config.js` file: ```
module.exports = { siteauthor: '', sitetitle: '', siteshorttitle: '', sitedescription: '', siteshortdescription: '', sitekeywords: 'comma, separated, list', // replace this with your seo keywords siteurl: ' pathprefix: '/again', sitelanguage: 'en', get copyright() { return `copyright \\u00a9 ${new date().getfullyear()} ${this.siteauthor}`; }, // returns copyright string with year of last build
``` my `gatsby-config.js` file: ```
const config = require(\'./config\') const pathprefix = config.pathprefix === \'/\' ? \'\' : config.pathprefix console.log("gatsby path prefix: ", pathprefix) // <-- confirmed: this logs \'/again\' module.exports = { sitemetadata: { author: config.siteauthor, title: config.sitetitle, description: config.sitedescription, siteurl: config.siteurl + pathprefix, settings: { ...config }, }, plugins: [ `gatsby-plugin-sass`, `gatsby-transformer-sharp`, `gatsby-plugin-sharp`, { resolve: `gatsby-plugin-typography`, options: { pathtoconfigmodule: `src/utils/typography` }, }, { resolve: `gatsby-source-filesystem`, options: { name: `src`, path: `${__dirname}/src`, }, }, ], pathprefix,
``` i've confirmed that `pathprefix` really is set to `/again` here
however, since it wasn't working (that is, the `/again` prefix wasn't showing up in the url path), i looked at the implementation of `withprefix` in the [gatsby code]( #l12-l40) and it seems like it depends on `__path_prefix__` and/or `__base_prefix__` variables
mine both seem to be set to the empty string
[this is from some logging in on my gallery page ]( #l9-l11)-- i gathered based on this issue that these variables are not on the window object (and i checked, it wasn't there) nor set as environment variables
``` console.log("path prefix on process.env: ", process.env.__path_prefix__) // yields undefined console.log("path prefix is empty string: ", __path_prefix__ === \'\') // yields true console.log("base path is empty string: ", __base_path__ === \'\') // yields true
``` it looks like `__path_prefix__` and `__base_path__` are set [here]( #l199-l200), based on whether `program.prefixpaths` is truthy
i'm not sure, but i'm assuming that `program.prefixpaths` is `true` if the `--prefix-paths` tag is used
for my deployment, it is used
here is a snippet from my `package.json`
``` "scripts": { "clean": "gatsby clean", "reset": "rm -rf .cache/ public/ node_modules/ package-lock.json", "prep": "rm -rf .cache/ public/ node_modules/ && npm ci", "develop": "debug=gatsby* gatsby develop --verbose", "build": "debug=gatsby* gatsby build --verbose", "serve": "debug=gatsby* gatsby serve --verbose", "test": "echo \\"error: no test specified -- " && exit 1", "deploy": "gatsby build --prefix-paths && gh-pages -d public" },
``` so, since my build *should* be setting `program.prefixpaths` to `true`, and since `pathprefix` is set in my config, i don't understand why __path_prefix__ is the empty string when i deploy
[here]( is a link to my repo
the `master` branch is up to date with what i've deployed, and if you want to see what was built, you can look at the `gh-pages` branch.
in some browsers like internet explorer, samsung internet and chrome android, opera mini (see svganimatedstring is not available
this produces a runtime undefinedvariableerror
i propose we check if `svganimated` is available in `window` before checking if `clickedanchor.href` is an instance of it.
after upgrading to the version which introduced granular chunking i started having strange issue with how production chunks are generated
this only happens to my homepage index page
almost every component on this page is added to the main bundle with shared packages
![screenshot 2020-07-27 at 12 18 39]( then my component--src-templates-index-js is only 700b with just two modules
![screenshot 2020-07-27 at 12 19 01]( the reason why my index page is in templates instead of page is because of the design of the website and multiple locales
however, it was correctly generated before the upgrade
the bunlde builds fine andcan be served via cloudfront
however, i noticed that i started getting some mixed content issue, which was not happening before
my index.html is now correctly served as a document but also as text/html and i have an issue with css main file also having wrong mime type : text/html
when using version `2.24.11` and `staticquery` we get `loading (staticquery)` (production only) ([code](
when using `2.23.22-static-query-template.8` the problem is solved.
hi guys, i have had a gatsby project running perfectly fine for 3 months
we are hosted on netlify and using contentful as the cms
as of friday 24th july, i am getting the below error: ``` react_devtools_backend.js:2273 error: the result of this staticquery could not be fetched
this is likely a bug in gatsby and if refreshing the page does not fix it, please open an issue in at h (gatsby-browser-entry.js:77) at b (sitelinks.js:9) at ki (react-dom.production.min.js:153) at fa (react-dom.production.min.js:175) at vo (react-dom.production.min.js:263) at cu (react-dom.production.min.js:246) at ou (react-dom.production.min.js:246) at zo (react-dom.production.min.js:239) at react-dom.production.min.js:123 at scheduler.production.min.js:19 ```
here are my current package versions ``` "@contentful/rich-text-react-renderer": "^13.4.0", "@fortawesome/fontawesome-svg-core": "^1.2.28", "@fortawesome/free-brands-svg-icons": "^5.13.0", "@fortawesome/free-solid-svg-icons": "^5.13.0", "@fortawesome/react-fontawesome": "^0.1.9", "@reach/dialog": "^0.10.1", "@reach/tabs": "^0.10.1", "@reach/visually-hidden": "^0.10.1", "@stripe/stripe-js": "^1.4.0", "bootstrap": "^4.4.1", "dotenv": "^8.2.0", "gatsby": "^2.23.18", "gatsby-background-image": "^1.1.1", "gatsby-image": "^2.3.1", "gatsby-plugin-create-client-paths": "^2.2.1", "gatsby-plugin-manifest": "^2.3.3", "gatsby-plugin-netlify-identity": "0.0.3", "gatsby-plugin-offline": "^3.1.2", "gatsby-plugin-prefetch-google-fonts": "^1.4.3", "gatsby-plugin-react-helmet": "^3.2.1", "gatsby-plugin-robots-txt": "^1.5.1", "gatsby-plugin-sharp": "^2.5.3", "gatsby-plugin-sitemap": "^2.4.3", "gatsby-plugin-transition-link": "^1.18.0", "gatsby-remark-responsive-iframe": "^2.3.3", "gatsby-source-contentful": "^2.3.32", "gatsby-source-filesystem": "^2.2.2", "gatsby-source-stripe": "^3.0.7", "gatsby-transformer-remark": "^2.7.3", "gatsby-transformer-sharp": "^2.4.3", "gsap": "^3.2.6", "hls.js": "^0.13.2", "lodash": "^4.17.15", "lodash.merge": "^4.6.2", "moment": "^2.25.3", "mux-embed": "^3.1.0", "netlify": "^4.1.5", "prop-types": "^15.7.2", "react": "^16.12.0", "react-bootstrap": "^1.0.0", "react-dom": "^16.12.0", "react-firebase-hooks": "^2.1.1", "react-helmet": "^5.2.1", "react-icons": "^3.10.0", "react-netlify-identity-widget": "^0.2.7", "react-spring": "^8.0.27", "redux": "^4.0.5", "styled-components": "^5.1.0", "video-react": "^0.14.1"
since it was decided that `gatsby-plugin-typescript` should be included by default, i have issues running `ts-loader` beside it
`ts-loader` winds up throwing a ton of type errors like some of these below
ts2683: 'this' implicitly has type 'any' because it does not have a type annotation.
ts7006: parameter '_ref3' implicitly has an 'any' type.
ts2307: cannot find module '@babel/runtime/helpers/esm/createclass' or its corresponding type declarations.
``` it's apparent to me that the types are being stripped from the code _**before**_ it reaches `ts-loader`, which seemed a bit odd
the webpack config snippet in question is here: ``` "rules": [ { "test": "/\\\\.tsx?$/", "exclude": "/node_modules/", "use": [ { "options": { "stage": "develop", "cachedirectory": "/home/jeremy/dev/autocorp-portal/apps/ac-dealer-portal/.cache/webpack/babel" }, "loader": "/home/jeremy/dev/autocorp-portal/apps/ac-dealer-portal/node_modules/.pnpm/gatsby@2.24.4_4c4b323380cb034cb63962d4309d544e/node_modules/gatsby/dist/utils/babel-loader.js" }, { "loader": "/home/jeremy/dev/autocorp-portal/apps/ac-dealer-portal/node_modules/.pnpm/ts-loader@8.0.1_typescript@3.9.7/node_modules/ts-loader/index.js", "options": { "compiler": "/home/jeremy/dev/autocorp-portal/apps/ac-dealer-portal/node_modules/.pnpm/ttypescript@1.5.10_typescript@3.9.7/node_modules/ttypescript/lib/typescript.js" } } ] }, { "test": "/\\\\.(js|mjs|jsx)$/", "include": "modulepath => {\ // when it\'s not coming from node_modules we treat it as a source file.\ if (!vendorregex.test(modulepath)) {\ return true;\ } // if the module uses gatsby as a dependency\ // we want to treat it as src so we can extract queries\ \ \ return modulesthatusegatsby.some(module => modulepath.includes(module.path));\ }", "type": "javascript/auto", "use": [ { "options": { "stage": "develop", "cachedirectory": "/home/jeremy/dev/autocorp-portal/apps/ac-dealer-portal/.cache/webpack/babel", "configfile": true, "compact": false }, "loader": "/home/jeremy/dev/autocorp-portal/apps/ac-dealer-portal/node_modules/.pnpm/gatsby@2.24.4_4c4b323380cb034cb63962d4309d544e/node_modules/gatsby/dist/utils/babel-loader.js" } ], },
``` this shouldn't be an issue because i've run `ts-loader` on top of `babel-loader` with `@babel/preset-typescript` set up before and never had any issues
to me, this sounds like another loader is hitting the `.ts` files first, which would make sense because `gatsby-plugin-typescript` sets up that loader
under normal circumstances, i would drop the entry from the webpack config, _**but...**_ i don't see it in the generated config
i have a function like this for debugging:
// gatsby-node.js
exports.oncreatewebpackconfig = ({ getconfig, stage }) => { require('fs').writefilesync( `./webpack.config-${stage}.json`, json.stringify( getconfig(), (key, val) => ( val instanceof regexp || val instanceof function ? val.tostring() : val ), 2, ), );
``` i have examined the generated config from top to bottom, and i don't see the loader that gets added by `gatsby-plugin-typescript`
i've confirmed that it is the culprit by dropping these lines, though:
#l267-l279 --- so i guess i have a couple of questions: * why isn't `oncreatewebpack()` getting hit with the correct webpack config
* can we set up a way to switch on/off the "typescript by default" feature? i frequently use typescript plugins, and it\'s just not possible to use them through babel, because it relies on typescript itself doing the transpiling/type-checking
hence, `ts-loader`
--- when i have the time in a couple days, i will create a reproduction
i'm on a time crunch right now, and i've already been on this issue for too long.
page components don't support export { default } syntax #25927 added condition to evaluate `export {default} from x` as valid ## related issues fixes
i am unable to install the `gatsby plugin for netlify cms` to my blog
i've been following a tutorial of [adding netlify cms to existing blog]( and also referred to this [doc](
i'm getting 404s for the examples in the [graphql query options reference page](
i'm fairly sure this is a new issue, i _think_ i've been on that page in the last few days before and had the examples be there
it's not browser-specific (i tried brave, chrome, and firefox)
(i initially clicked "documentation" to report this, but that was oriented on creating/improving documentation rather than reporting a bug delivering the documentation.)
images in a page wrapper reload when switching between pages.
relative url for links and images, definition in package readme results in 404
i've found several similar issues, that were closed but none of the solutions works for me or helps me understand what is going on
everything is worked as expected when i'm running gatsby develop command but issues appear when i'm using gatsby build
my problem has two parts:
if i disable js on the page, then the page looks like that (some of the styles from material ui are absent, f.e global styles that i override in the theme-config, or all styles for the header)
the similar result i can see for a moment when the page is loaded
i think that the first page appears is what i get from the ssr and the next one when js is loaded
first screen: ![image]( 2
if i enable js, or just wait for page fully load i can see that styles for header applied but: the styles are different from what i see on the develop (second screen) and the build (third screen)
interesting, that "grid" rule is disappeared - cause on the screen when js is disabled items container has it and now it\'s gone
second screen:
![image](
third screen:
![image](
moreover, some classes apply in a weird way (f.e on the header there is a class - 'jss5' and also for some reason one of the text blocks has class 'jss5' which leads to mess)
also, one more strange thing - i'm running gatsby develop in one console than in the other console gatsby build, and on my local server, i see the page from build instead of develop
to fix it i need to restart gatsby develop.
this error is appearing only when i build and serve the site, not in develop mode
there are already several of these issues which have been solved, i've tried all those solutions, couldn't get it to work
i understand this isn't a bug, i am assuming that the way i am using usestaticquery has something to do with it.
when i run `gatsby develop` i get error as in title
i've tried to remove `node_modules` and 'package-lock.json` but it didn't solve my problem
` error #11321 plugin "gatsby-source-shopify" threw an error while running the sourcenodes lifecycle: cannot read property \'includes\' of undefined 41 | shopifyqueries = {} 42 | }) => {
> 43 | const client = (0, _createclient.createclient)(shopname, accesstoken, apiversion); | ^ 44 | const defaultqueries = { 45 | articles: _queries.articles_query, 46 | blogs: _queries.blogs_query, file: node_modules/gatsby-source-shopify/gatsby-node.js:43:49 typeerror: cannot read property 'includes' o f undefined - create-client.js:14 createclient [fiventhree]/[gatsby-source-shopify]/creat e-client.js:14:16 - gatsby-node.js:43 object.sourcenodes [fiventhree]/[gatsby-source-shopify]/gatsb y-node.js:43:49 - api-runner-node.js:347 runapi [fiventhree]/[gatsby]/dist/utils/api-runne r-node.js:347:37 - api-runner-node.js:466 promise.catch.decor ateevent.pluginname [fiventhree]/[gatsby]/dist/utils/api-runne r-node.js:466:15 - from previous event: - api-runner-node.js:466 promise.catch.decor ateevent.pluginname [fiventhree]/[gatsby]/dist/utils/api-runne r-node.js:466:7 - from previous event: - api-runner-node.js:465 [fiventhree]/[gatsby]/dist/utils/api-runne r-node.js:465:12 - timers.js:439 processimmediate internal/timers.js:439:21 - from previous event: - api-runner-node.js:459 [fiventhree]/[gatsby]/dist/utils/api-runne r-node.js:459:11 - from previous event: - api-runner-node.js:366 module.exports [fiventhree]/[gatsby]/dist/utils/api-runne r-node.js:366:12 - source-nodes.js:89 _default [fiventhree]/[gatsby]/dist/utils/source-no des.js:89:36 - source-nodes.js:30 sourcenodes [fiventhree]/[gatsby]/dist/services/source -nodes.js:30:34 - interpreter.js:721 interpreter.exec [fiventhree]/[xstate]/lib/interpreter.js:7 21:27 - interpreter.js:223 interpreter.execute [fiventhree]/[xstate]/lib/interpreter.js:2 23:22 - interpreter.js:243 interpreter.update [fiventhree]/[xstate]/lib/interpreter.js:2 43:18 - interpreter.js:144 [fiventhree]/[xstate]/lib/interpreter.js:1 44:23 - scheduler.js:59 scheduler.process [fiventhree]/[xstate]/lib/scheduler.js:59: 13 - scheduler.js:43 scheduler.schedule [fiventhree]/[xstate]/lib/scheduler.js:43: 14 - interpreter.js:140 interpreter.send [fiventhree]/[xstate]/lib/interpreter.js:1 40:29 - interpreter.js:836 actor.id [fiventhree]/[xstate]/lib/interpreter.js:8 36:23 ` here's my `gatsby-config.js` file: `
{ resolve: `gatsby-source-shopify`, options: { shopname: process.env.gatsby_shop_name, accesstoken: process.env.gatsby_storefront_access_token, apiversion: '2020-04', verbose: true, includecollections: ['shop', 'content'], }, },
previously i was trying to fetch data with 2020-07 api version but it also didn't work.
when i run `npm uninstall -g gatsby-cli`, the gatsby-cli still seems to be installed
right afterwards i can run `gatsby -v`
--> `gatsby cli version: 2.12.65`
i'm using `gatsby-source-shopify2`
my problem is that when i run `gatsby develop` i see this error: `gatsby-source-shopify/undefined starting to fetch data from shopify error error an error occured while sourcing data error query: """ query getproducttypes($first: int!) { shop { producttypes(first: $first) { edges { node } } } } """
variables: first: 250` here is my `gatsby-config.js` file: `
{ resolve: `gatsby-source-shopify2`, options: { shopname: process.env.gatsby_shop_name, accesstoken: process.env.gatsby_storefront_access_token, apiversion: '2020-07', verbose: true, }, },
when i'm loading [this page]( on my ipad, half of the images aren't rendered (the right column), there's just empty space where images should be
everything works just fine on desktop
i suspect it happens because i\'m using "column-count" css property to organize images into columns
when i use a regular `<img/>` tag, everything works fine, the issue appears only when i'm switching to `<img/>` tag from `gatsby-image`
here's the link to the code of that page:
`gatsby info` throws error `unhandled rejection e.filter is not a function`
i'm seeing the following error during build
error copying file from /users/me/sites/example/static/uploads/example.svg to /users/me/sites/example/public/static/1dfbd614d33d3d25f117f78696579658/example.svg [error: enoent: no such file or directory, unlink '/users/me/sites/example/public/static/1dfbd614d33d3d25f117f78696579658/example.svg'] { errno: -2, code: 'enoent', syscall: 'unlink', path: '/users/me/sites/example/public/static/1dfbd614d33d3d25f117f78696579658/example.svg'
``` this doesn't happen on every build
probably two in every three builds
it happens regardless of whether `gatsby clean` has been run before the build, and errors appear to be emitted for some or all of the same set of images
the only consistency between all images is that they are:
- referenced from frontmatter of a markdown document
- either svgs or pdfs
(we use a large number of pngs and jpegs, so i think this is significant)
possibly related to #20602, #1693 note that it doesn't appear to have any negative consequences
the images are still present in the `/public/` directory and load successfully on the site
the same thing happens on our ci server (linux), with the same unpredictable pattern.
so i deployed a website created in gatsby
after using the command gatsby build
i uploaded it and it shows this error the result of this staticquery could not be fetched.
using a placeholder such as base64 is nice to have for first retrieval of assets
however when they are cached this results in: - brief flicker during hydration due to inlined placeholder.
- when navigating to a page with an image if no hit within the internal `gatsby-image` cache: - brief flicker for lazy loading via intersection observer
- transition triggered for native lazy loading
it's a minor ux issue, but it would be nice to smooth these out
## examples ![base64_flash_bug]( ## related
#issuecomment-471278211
> when the actual images load fast, the placeholder is more irritating then helpful
> `imgcached` will be false in situations that io isn't used for lazy-load, thus `shouldfadein` won't be disabled, which afaik means we'll probably run into `#12254` again? --- ## discussion i can put together a pr resolving these as best as possible if desirable
--- ### hydration flicker can be resolved by adding keyframe css in a `<style>` element
this allows for having the placeholder opacity at 0, and toggling it to 1 via `animation` rule
drawback is it adds to page weight (although compression may optimize that away), the more images there are each adding that same element and css
unless we place this in the html base within the `<head>` instead, then it can be toggled via `classname`
a delay would need to be around 200-300ms minimum(based on 200ms until `gatsby-image` code executed from `performance.now()` and 10-100ms for a cached response to update state to render), so a flicker would still be visible, it would just be similar to an externally linked `<img>` flashing in over whatever the background was, instead of a potentially large upscaled `20px` base64 pixelated looking image before the cached image renders
the `backgroundcolor` placeholder, especially with an appropriate colour can reduce that "flash" / flicker appearance
presently css can be used to add a blur filter and reduce the low quality pixelated flicker impact, but still may not be desirable
likewise, in this case a user could provide the keyframe css externally, so long as they have a reliable `classname` to target(not presently supported)
internally, this does not stop the fade transition
there are two cases to handle for this: - `imgcached` within `handleref()` can be used, this leverages the image `currentsrc` to know if the browser has the image in cache without always needing to make a network request
when it is a falsy value, the browser will always log a network request, pulling from disk-cache or querying the server if the asset has changed delaying the assignment of `currentsrc`, thus even if the asset is cached locally it may not be set reliably when `handleref()` fires.
- as a fallback to `imgcached`, using `performance.now()` only once within `gatsby-image` module, all instances can reference when it was first available since the page loaded
a value of `<500ms` would be a good indication that the page has been previously loaded before, the browser should reliably have access to the cache if the image to load is consistent, probably not reliable if the viewport dimensions have changed that a different image source would be selected
the keyframe css can be used after hydration as well and removed once `imgloaded` fires
doing so would momentarily defer the placeholder visibility, if a cached image is not quickly retrievable
on throttled `fast 3g` if the server needs to be queried if content has changed due to `cache-control` header expiring, the latency imposes ~500ms(chrome to local `gatsby serve` or caddy server) and 2sec for `slow 3g` to return a `304`(~128 bytes response)
the higher the latency, the less likely the user would witness this flickering issue, so this approach is still valid
#### tl;dr the `performance.now()` fallback is probably too much of an assumption to include, users would need to wait until v3 with `gatsby-image` modularized into a composable component to implement this approach if acceptable for them
`imgcached` is still worthwhile even if it fails sometimes (would not break anything)
i am not expecting the `animation` css with keyframe in `<script>` being part of the `gatsby-image` component by default would be welcomed, especially since it should be possible for a user to configure for, like they would an improved blur-up via css filter
the `classname` to target however would be required
--- ### intersection observer without the css keyframes approach, i don't see this feature being possible to skip the initial placeholder rendered frame with page transitions
that frame in my measurements was lasting ~40ms regardless of network throttled speed, when the resource was cached
hiding the placeholder via the css `animation` opacity toggle works, but effectively transfers the flicker issue to those loading the resource over network, however, this would only be visible afaik during initial page loads where hydration is involved, making it far less likely to be encountered
[blank] -> placeholder while retrieving js -> hydration -> [blank] -> placeholder while retrieving image -> image --- ### native lazy loading unlike intersection observer instances, these have `isvisible` as true and only hide visibility of the image element until it's loaded
using `imgcached` here works well too.
when using multiple sources for a fixed image, each with a media query set, the first source is rendered ignoring the media queries and the issue is fixed only after resizing the window, something end user will of course wont do.
with the retext-spell bot checks spelling against a dictionary.txt file
it's working okay, except that it doesn't run on prs
this results in changes going in without a notification of issues with the dictionary, causing builds on master to fail
contributors and team members should know whether a pr actually passes the linter, rather than guessing or causing a broken build
### motivation we need the status checks to accurately reflect the status of a pr, including spelling/dictionary issues, so we don't have to come back in and fix them after the fact (and cause a headache for other pr authors).
page components in `src/pages/` don\'t support `export { default } from "...";` syntax
whenever any of my page components has this syntax, i'm getting the following build error on `npm run build`: ```
using environment config: 'local'
success open and validate gatsby-configs - 0.088s
success load plugins - 0.390s
success onpreinit - 0.002s
success delete html and css files from previous builds - 0.017s
success initialize cache - 0.005s
success copy gatsby files - 0.028s
success onprebootstrap - 0.009s
success createschemacustomization - 0.004s
success source and transform nodes - 0.017s
success building schema - 0.160s
success createpages - 0.001s error #11328 a page component must export a react component for it to be valid
please make sure this file exports a react component: undefined not finished createpagesstatefully - 0.079s
npm err! code elifecycle
npm err! errno 1
npm err! landing-website-gatsby@0.1.0 build: `gatsby build`
npm err! exit status 1
npm err! failed at the landing-website-gatsby@0.1.0 build script.
npm err! this is probably not a problem with npm
there is likely additional logging output above
npm err! a complete log of this run can be found in:
npm err! /home/robert/.npm/_logs/2020-07-21t19_20_12_218z-debug.log
``` as soon as i refactor `export { default } from "...";` to `export { default as default } from "...";` the build process runs without errors
but then the linter raises warnings: `warning export default unnecessarily renamed no-useless-rename`
it\'s also worth noting that any non-page components in `src/components/` can have `export { default } from "...";` and the build process still works fine
the problem only appears in page components in `src/pages/`
so i assume it's some part of the building pages process that doesn't support that syntax
here is [documentation of export statement]( which clearly lists `export { deafult }` as a valid syntax.
i have a csv with 406 rows and 4 columns
when using graphiql it returns only rows
- 269 - using the following query ```const stationcsvdata = usestaticquery( graphql` query allstationsquery { allstationsgridviewcsv { totalcount nodes { line lon lat name id } } } ` )
``` looking at /__graphiql only returns the 269 results too so my query isn't causing the issues.
this is a first issue i am submitting, so if there is any information missing, apologies
after upgrading to `gatsby@2.23.5` and running `gatsby build` i am seeing a white screen with no errros in the console
running `gatsby develop` is working as expected
when running in a ci in aws codepipeline i can see the actual error ``` 36 \\| _this.withref = false;
540 | 37 \\| _this.setwrappedinstance = _this.setwrappedinstance.bind(_this);
541 | > 38 \\| return _this;
543 | 39 \\| }
544 | 40 \\| graphqlbase.prototype.getwrappedinstance = function () {
545 | 41 \\| process.env.node_env === "production" ? invariant(this.withref, 2) : invariant(this.withref, "to access the wrapped instance, you need to specify " +
546 | 547 | [0m
548 | [0m [0m [97m [41mwebpackerror [0m [37m [41m: [0m [37m [41m [0m [97m [41mthe result of this staticquery could not be fetched. [0m
549 | [0m [0m
550 | [0m [0m [90m- [0m [0m [93mbuild-html.js [0m [90m: [0m [93m107 [0m [37m [0m [37mdobuildpages [0m
551 | [0m [0m [0m [90m[src]/[gatsby]/dist/commands/build-html.js:107:24 [0m
552 | [0m [0m
553 | [0m ``` i have not made any changes to staticqueries in any of the components since the last successful build.
the build command for asset prefix does not work with .svg files
if you use `img/demo.svg` in markdown then it get's converted to ` {generated-hash-values}/demo.svg`
i see some commits in the last days related on `mdx` and in some way, upgrading `@mdx-js/mdx` and `@mdx-js/react` from 1.6.10 into 1.6.13 and gatsby-plugin-mdx from 1.2.26 into 1.2.27 broke my _application_ logging a: ```
typeerror: cannot read property 'gatsbyremarkplugins' of undefined
since i am using `createmdxnode` from `gatsby-plugin-mdx/utils/create-mdx-node`, probably the problem is in my implementation, but downgrading to the previous (patch) versions, everything works well
i am using it like the code below: ```js
exports.oncreatenode = async ({ node, actions, createnodeid }) => { const { createnodefield, createnode, createparentchildlink } = actions // const mdxnodedesc = await createmdxnode({ id: createnodeid(`${node.id} >>> desc mdx`), node, content: node.description, }) //
``` hope it helps debugging in case is a `bug` related to the _dependencies_
otherwise, i will be very grateful in case someone could advice something to that _internal_ method and a _safe_ way to create `mdx` nodes from an internal node creation in `gatsby-node.js`
thanks in advance,
[graphql 15]( has been out for a while now (3.5 months), and some libs are starting to upgrade
as a result, today i got this error message: ``` error: cannot use graphqldirective "@cachecontrol" from another module or realm
ensure that there is only one instance of "graphql" in the node_modules directory
if different versions of "graphql" are the dependencies of other relied on modules, use "resolutions" to ensure only one version is installed
duplicate "graphql" modules cannot be used at the same time since different versions may have different capabilities and behavior
the data from one version used in the function from another could produce confusing and spurious results.
``` pinning graphql to 15.3.0 in resolutions makes gatsby crash when running `gatsby develop`.
build fails with:
> webpackerror: the result of this staticquery could not be fetched
pointing to this query:
const data = usestaticquery(graphql` query componentsquery { allfile( filter: { relativepath: { regex: "/^components/.*/index.js/" } } sort: { order: asc, fields: relativepath } ) { edges { node { relativedirectory } } } }
i'm linking between pages using a hash to link to a specific section
after a site re-deploy, which i think in turn triggers a service worker update, the page reloads after navigation and loses the hash
which in turns mean a user isn't taken to the section related to the link they clicked
from digging around, i _think_ it's caused by this: #l68-l73 where the `___swupdated` comes from: #l27-l30
i think i _might_ be able to work round it by using `onserviceworkerupdateready` to reload the window myself (keeping the hash), or by setting `window.___swupdated = false` [like this blog post]( #how-to-prevent-auto-reload-on-page-navigation)
but this seems wrong to have to do this, when the default behaviour is to refresh after an update - it feels like navigation.js should reload the page, and keep the hash
maybe by using `window.reload(true)` rather than setting `window.location`? ```diff
-window.location = pathname
+window.reload(true)
after upgrading `gatsby` to `2.24.7` and `gatsby-cli` to `2.12.63`it will not build or start the development sever
each time the refresh endpoint is hit, memory increases a little bit and it doesn't go down, eventually leading to a heap out of memory after multiple refreshes
develop process memory previous to a refresh:
![image]( develop process memory after a refresh:
![image]( and hitting more times refresh it just goes higher
adding **--max_old_space_size** to a high value just delays the out of memory.
with a query that returns no results, `context.nodemodel.runquery` returns `promise<null>`, but [the documentation]( #runquery) specifies non-null type `promise<node[]>`
i'd prefer to get back `[]` instead of `null`, because dealing with one type is easier than dealing with two, and because it's consistent with how the rest of gatsby graphql works
if i pass the same filter to a static query and `runquery`, i think both should return the same result, `[]`.
links to codesandbox getting 404, when codesandbox app suspends
the app should restarted.
i was following the [setup your development environment]( instructions on the gatsby-js site.when i try to [create a gatsby site]( #create-a-gatsby-site) using the gatsby new command for the first time, i get a weird mix of characters on the cmd line
![image]( upon closer inspection in this part it wants me to select the default package manager (yarn/npm)
i was unable to select the right one because of the display but this is a weird issue.
after upgrading from `gatsby@2.20.26` to `gatsby@2.24.3` i noticed an issue where navigating within the app sets incorrect scroll top position
- this has been recently addressed by @blainekasten here -
- related issue -
in the "using tailwind css" reference guide, under step **[1
install tailwind]( #1-install-tailwind)**, there should be a command listed: `npm install tailwindcss --save-dev` but it seems to be missing on the live site
when one navigates to the .md file via the "[edit this page on github]( " link, the command appears to be there
i'm not sure why it is not displaying correctly.
for very long time we have used "gatsby": "2.21.0" in our app, but lately we faced that issue #issuecomment-653207216 so we\'ve upgraded it to the latest version
after that status bar stopped showing up in develop mode.
currently 404 page is served on a dev server with the status code 200.
any quoted code on the documentation web site seems to be missing at the moment.
hi all! i have a problem with the gatsby-image plugin
i hope you can help me because i looked everywhere and i can't find the solution
when i run the project using gatsby develop i see the images correctly and in good quality, whether they are static or fluid, but when i deploy the images are totally out of focus, pixelated as you will see in the image that i copy below, even up to i started a new project from scratch with the default project that comes with gatsby and the problem continues.
i would really appreciate your help with this problem that is driving me totally crazy
internal anchors with hashes stop working after the first click
see the minimal test case repo at and demo site at
click into page 2 and click the various internal anchors on that page
note: this is using simple anchor tags as per the docs for [gatsby link]( #recommendations-for-programmatic-in-app-navigation): > neither `<link>` nor `navigate` can be used for in-route navigation with a hash or query parameter
if you need this behavior, you should either use an anchor tag..
i thought this was fixed by #25749 and released in [2.24.3]( but it still seems to be an issue
i think it's related to, if not the same as, #25554, #25745 and #25522
i wonder if it was caused by #24306 (or at least related in some way)
the _first_ anchor seems to be ok but it's definitely something to do with subsquent clicks
*weirdly* though it's non-determinate: sometimes it will work fine and sometimes it won't and i can't seem to work out the pattern
looking into it, session storage is used under the hood for the scroll position, so i wonder if it's something to do with that - maybe the key used isn't including the anchor hash or something? anyway, that's as far as i got with my digging, sorry
hoping @blainekasten you might be able to take a look as you've looked at the other related issues
thank you very much.
deployment to aws amplify gives me a constant error: `"can\'t resolve \'header\' in \'/codebuild/output/src800686228/src/gatsby-website/src/components\'"` gatsby version: **2.23.12** full build log attached at the bottom of this message.
getting the following error while using `gatsby-plugin-react-native-web` plugin & `gatsby` with `expo` error #98123 webpack
generating ssr bundle failed
missing external configuration for type:commonjs2
error command failed with exit code 1.
after upgrading to the latest version of gatsby, ie11 no longer works with async await functions.
after upgrading from `gatsby@2.20.26` to `gatsby@2.24.2` i noticed an issue where navigating within the app sets incorrect scroll top position
note: i previously raised this here - and suggested fix through ```
"resolutions": { "gatsby-react-router-scroll": "3.0.3"
``` didn't fix it for me
and as @blainekasten suggested, i'm creating a new issue as it's different to that raised by the author of
when running gatsbyjs.org locally with `gatsby develop` (i.e
for pr reviews of docs changes), syntax highlighting doesn't render and there is no filename or copy button rendered
this makes it difficult to do pr reviews with tutorial/guide changes with large diffs, as you can't see filenames and the `highlight-next-line`-type functionality is broken
this has been happening for a few weeks, at least
it may be cached on the build or a diff between develop and prod (according to @laurieontech)
i do see some warnings in the terminal when i run the site locally, but these have been happening way longer than this issue as far as i can tell
warn code block or inline code language not specified in markdown
warn unable to find prism language 'jsxharmony' for highlighting
warn unable to find prism language 'sh' for highlighting
applying generic
warn unable to find prism language 'flowconfig' for highlighting
gatsby cloud uploading to s3 isn't taking this morning
i launched my website this morning and wanted to push a hotfix
the deploy step where i upload assets to s3 usually takes 3-6 seconds tops, but today my first upload took 13 minutes, and the second one is 30 minutes and counting
the change has only been a few text/copy changes, so no new assets, packages uploaded or large files from my previous deploys
is there any way for me to get clarity on why this is the case? can i cancel a deploy that is currently uploading? the aws status board doesn't list any downtimes
is it because i have traffic now on the site, and i can only upload when those static files aren't currently being accessed?
i noticed while working on a gatsby project, that the whole page gets repainted after some time, likely after hydration happened
you will see images disappear and later on, reappear after some time lag due to some scripting.
gatsby new gatsby-starter-business causes a host of node-gyp error messages
when i try to run `gatsby build` or `gatsby develop` i keep running into the following issue ```
generating ssr bundle failed can't resolve 'gatsby-link' in 'xxx/.cache' if you're trying to use a package make sure that 'gatsby-link' is installed
if you're trying to use a local file make sure that the path is correct
file: .cache/gatsby-browser-entry.js
while running `gatsby develop` it is #98123 error
i'm using mapbox api and its maps
i tried to unmount component which uses maps as well as reinstalling npm, deleting node_modules and package-lock.json but it didn't solve problem
it looks like it is something wrong with mapbox files but yesterday everything worked without issues
i have also commented `wraprootelement` with redux but it generated other error.
hi, i came across an issue, while trying to use the gatsby-starter-default
at first, adding the sass dependencies and plugin (per the docs was causing the site to work fine locally, but to break on deploys (both the local netlify live link, and the deploy via netlify's site)
even though i had not added any new links or content, it was giving this error (showing the error seemed to be logging to the console pretty rappidly): netlify has a policy that all of the resources have to be https, not http
but the error is showing something in the gatsby project is making an http request: ``` error: polling-xhr.js:268 mixed content: the page at ' was loaded over https, but requested an insecure xmlhttprequest endpoint '
this request has been blocked; the content must be served over https
the errors would not go away, even if i reset the git to before the plugin was installed/ basically the fresh boilerplate
so, i recreated the project step by step
strangely, this time, the errors appeared **immediately** in the local live link (before adding sass or changing the repo in any way); however, when i deployed the site to netlify, they did not appear anymore at all - even after adding sass dependencies in the same way i had with the original repo.
so this [new call here]( #diff-63db4ae0a4f04331e4397f310e7b26c1r236) to `mdx.createcompiler(compileroptions)` from which i'm now picking up when upgrading from `gatsby-plugin-mdx` 1.2.22 -> 1.2.25 (3 patches), is suddenly causing my build to fail because `mdx.createcompiler` is not a function:
> docz-app@ build /dds/docs/.docz
> gatsby build "--prefix-paths" warn configuring yargs through package.json is deprecated and will be removed in the next major release, please use the js api instead.
warn configuring yargs through package.json is deprecated and will be removed in the next major release, please use the js api instead.
success open and validate gatsby-configs - 1.366s
success load plugins - 1.152s
success onpreinit - 0.020s
success delete html and css files from previous builds - 0.012s
success initialize cache - 0.009s
success copy gatsby files - 0.135s
success onprebootstrap - 0.408s
success createschemacustomization - 0.005s error #11321 plugin "gatsby-plugin-mdx" threw an error while running the oncreatenode lifecycle: mdx.createcompiler is not a function typeerror: mdx.createcompiler is not a function - gen-mdx.js:236 findimports [dds]/[gatsby-plugin-mdx]/utils/gen-mdx.js:236:24 - on-create-node.js:59 object.module.exports [as oncreatenode] [dds]/[gatsby-plugin-mdx]/gatsby/on-create-node.js:59:46 not finished source and transform nodes - 2.187s
i am getting a wired issue regarding react
the tables featured in pages like [gatsby vs next.js]( are inaccessible to screenreader users
among the issues: * the tables are not [semantic `<table>` tags]( #l23)
this means that table cells will not be read with proper context to screenreader users.
* none of the markers are picked up by screenreaders
they need some sr-only text or aria-labels to make sure that information is being read to screenreader users.
* the [legend table]( does not use a `<table>` tag either i just think it\'s ironic that a page that\'s supposed to advertise gatsby\'s accessibility features is itself not accessible: <img width="682" alt="screenshot of a feature page showing gatsby with high marks for accessibility" src=" ">
the gatsby image component misuses the media tag
see errors reported by the w3c checkers below.
![image](
the <link> component is placing the target path after the current page url
for example, the `blog/blog/` in this url: ![image]( i'm seeing that when using the link component on [this page]( ![image]( my link looks like this: ```js
<link to={`blog/${node.slug}`} aria-label={`continue reading ${node.title}`}
``` what's _really_ weird is that i get a different result on different builds
when it was building in netlify as part of the pr checks it worked fine
but when i actually deployed it from master i got this behavior (you can see it [here]( - i manually deployed the pr check deploy preview to my live site since that one worked for whatever reason)
important to note, though, is that i **am** seeing this bug in my local development environment.
i am using this [gatsby-ghost-starter](
i successfully installed the app, and ran `yarn` to installed all dependencies
but when i ran `gatsby develop` i kept getting this error: ```bash error #98124 webpack generating development javascript bundle failed can't resolve 'core-js/modules/es.array.flat' in <file path> if you're trying to use a package make sure that 'core-js/modules/es.array.flat' is installed
if you're trying to use a local file make sure that the path is correct
file: .cache\\error-overlay-handler.js error #98124 webpack generating development javascript bundle failed can't resolve 'core-js/modules/es.array.unscopables.flat' in <file path> if you're trying to use a package make sure that 'core-js/modules/es.array.unscopables.flat' is installed
if you're trying to use a local file make sure that the path is correct
file: .cache\\error-overlay-handler.js failed building development bundle - 3.868s
i tried adding the react tool tip mentioned in this post [#25453]( and still getting the same error.
after switching to use `navigate` from the gatsby package rather than @reach/router, i'm getting a window not defined error when i run gatsby build
is this expected? i feel like i must be doing something silly.
introduced regression where setting `total` on progress activities in plugins just doesn't do anything this is because of creating new activity with spreading, and it appears that spreading doesn't preserve setters:
![screenshot 2020-07-09 at 17 27 13]( and `total` is using setter: #l126-l129 instead of creating copy of activity, this mutates `start`/`end`/`done` to achieve same tracking mechanism
i have a build that fails on macos and linux environments because a generated cache filename is too long
error looks like this: ```
enametoolong: name too long, open '/users/ben/code/redacted/.cache/json/a-really-long-page-name-here..json' error unhandled rejection cannot read property 'sourcemessage' of undefined typeerror: cannot read property 'sourcemessage' of undefined - error-map.js:15 object.text [vrdx-application]/[gatsby-cli]/lib/structured-errors/error-map.js:15:37 - construct-error.js:30 constructerror [vrdx-application]/[gatsby-cli]/lib/structured-errors/construct-error.js:30:18 - reporter.js:128 reporter.error [vrdx-application]/[gatsby-cli]/lib/reporter/reporter.js:128:59 - reporter.js:116 [vrdx-application]/[gatsby-cli]/lib/reporter/reporter.js:116:48 - array.map - reporter.js:116 reporter.error [vrdx-application]/[gatsby-cli]/lib/reporter/reporter.js:116:26 - reporter.js:68 reporter.panic [vrdx-application]/[gatsby-cli]/lib/reporter/reporter.js:68:34 - create-cli.js:35 [vrdx-application]/[gatsby-cli]/lib/create-cli.js:35:85
``` the path name has 275 characters
is there a way we could limit these generated cache file names so that they work cross-os?
when using `fit: contain background: "#ffffff"` on a `childimagesharp` with the `...gatsbyimagesharpfluid_withwebp` fragment the initial blurred base64 image has a black background which changes to the white background with the image loaded.
when running gatsby develop, i get the error: ' 'node_modules\\pngquant- bin\\vendor\\pndor\\pngquant.exe' is not recognized as an internal or external command, operable program or batch file.'
i understand that gatsby supports ie11 by default
however, react totally did not work in one of the pages in my gatsby app.
the page name is product and when i navigate to that page, the following error can be seen in the console: ```unhandled promise rejection error, page resources not found for /product
not rendering react``` so the page was loaded, but javascript did not work at all on that page (onclick event was not triggered,...etc)
following the instructions at when i start the development server and browse to i get an error page
there are also warnings about case sensitivity in filenames.
when linking gatsby-theme with `yarn link` to the gatsby site using that theme, `gatsby build` fails with the following error: ```
$ gatsby build --prefix-paths
success open and validate gatsby-configs - 0.093s
success load plugins - 4.355s
success onpreinit - 0.016s
success delete html and css files from previous builds - 0.013s
success initialize cache - 0.013s
success copy gatsby files - 0.167s
success onprebootstrap - 0.019s
success createschemacustomization - 0.011s
success source and transform nodes - 1.489s
error cannot create as typecomposer the following value: imageformat
error: cannot create as typecomposer the following value: imageformat
- schemacomposer.js:365 schemacomposer.createtemptc [docs]/[graphql-compose]/lib/schemacomposer.js:365:11 - schemacomposer.js:563 schemacomposer.addascomposer [docs]/[graphql-compose]/lib/schemacomposer.js:563:27 - schema.js:467 processaddedtype [docs]/[gatsby]/dist/schema/schema.js:467:35 - schema.js:392 [docs]/[gatsby]/dist/schema/schema.js:392:9 - array.foreach - schema.js:310 addtypes [docs]/[gatsby]/dist/schema/schema.js:310:9 - schema.js:173 updateschemacomposer [docs]/[gatsby]/dist/schema/schema.js:173:9 - schema.js:99 buildschema [docs]/[gatsby]/dist/schema/schema.js:99:9 - index.js:141 build [docs]/[gatsby]/dist/schema/index.js:141:24 - build-schema.js:20 async buildschema [docs]/[gatsby]/dist/services/build-schema.js:20:3 - index.js:34 async bootstrap [docs]/[gatsby]/dist/bootstrap/index.js:34:3 - build.js:96 async build [docs]/[gatsby]/dist/commands/build.js:96:7 not finished building schema - 0.112s
error command failed with exit code 1.
info visit for documentation about this command.
after pulling the gatsby personal starter blog and running gatsby develop, i am getting the following error: "gatsby-plugin-mdx" threw an error while running the oncreatenode lifecycle: cannot find module \'gatsby-remark-vscode\'
i decided to upgrade a bunch of outdated gatsby dependencies (see a screenshot from the pr below)
then i discovered a bug (see
i found that the problem was in a particular version of gatsby, so i thought if i simply roll it back to a version before the issue was introduced, it would work smoothly
<img width="1241" alt="screenshot 2020-07-08 at 13 58 06" src=" "> these are headline summaries of me trying to pin versions of gatsby with versions of gatsby-cli (it was pointed out in one of the issues that a version of gatsby-cli should be pinned): gatsby@2.18.0 + gatsby-cli@2.8.12 - broken - error: reducers may not dispatch actions
gatsby@2.18.25 - broken - activities of undefined error (yoga layout)
see - gatsby@2.19.0 + gatsby-cli@2.8.27 - broken - error: reducers may not dispatch actions
gatsby@2.19.39 - broken - activities of undefined error (yoga layout) gatsby@2.19.50 + gatsby-cli@2.10.13 - broken - error: reducers may not dispatch actions
gatsby@2.20.24 - broken - error: reducers may not dispatch actions
gatsby@2.20.26 + gatsby-cli@2.11.12 - broken - error: reducers may not dispatch actions
gatsby@2.21.0 - broken i tried to pin versions of gatsby-cli by adding the following to package.json: ```
"resolutions": { "**/gatsby-cli": "2.8.12",
``` what i came to realise is that every gatsby dependency is prefixed with a caret, so even if i `yarn add gatsby@2.19.0`, all gatsby's own dependencies would be whatever is the latest version than that defined at the time of release, unless i specifically pin them through `resolutions` object (see above) ```
"@babel/code-frame": "^7.5.5"
"@babel/core": "^7.7.2"
"@babel/parser": "^7.7.3"
"@babel/polyfill": "^7.7.0"
"@babel/runtime": "^7.7.2"
"@babel/traverse": "^7.7.2"
"@gatsbyjs/relay-compiler": "2.0.0-printer-fix.4"
"@hapi/joi": "^15.1.1"
"@mikaelkristiansson/domready": "^1.0.9"
"@pieh/friendly-errors-webpack-plugin": "1.7.0-chalk-2"
"@reach/router": "^1.2.1"
"@typescript-eslint/eslint-plugin": "^2.7.0"
"@typescript-eslint/parser": "^2.7.0"
"address": "1.1.2"
"autoprefixer": "^9.7.1"
"axios": "^0.19.0"
"babel-core": "7.0.0-bridge.0"
"babel-eslint": "^10.0.3"
"babel-loader": "^8.0.6"
"babel-plugin-add-module-exports": "^0.3.3"
"babel-plugin-dynamic-import-node": "^2.3.0"
"babel-plugin-remove-graphql-queries": "^2.7.16"
"babel-preset-gatsby": "^0.2.22"
"better-opn": "1.0.0"
"better-queue": "^3.8.10"
"bluebird": "^3.7.1"
"browserslist": "3.2.8"
"cache-manager": "^2.10.1"
"cache-manager-fs-hash": "^0.0.7"
"chalk": "^2.4.2"
"chokidar": "3.3.0"
"common-tags": "^1.8.0"
"compression": "^1.7.4"
"convert-hrtime": "^3.0.0"
``` what i would like to do is be able to add a version of gatsby at the time it was released
currently, i have all sorts of incompatibility issues that break my builds, which is due to all gatsby's own dependencies being newer than gatsby itself
i spent hours on this and got nowhere
in the end i rolled back my gatsby version to what it was before: `~2.13.x`
redirecting from `/` to `/foo` with `createredirect` using the `redirectinbrowser` option set to `true` causes the page to flicker
while it's clear in the docs `createredirect` isn't a stand-alone feature it's useful to set `redirectinbrowser` for development builds for demonstration purposes and sane dev workflow.
when running `gatsby build`, all `console.log()` calls except for the last one are printed to stdout.
the graphql embeds in doc pages like the [graphql refrence]( do not load
### repro steps 1
go to a page with graphql embeds in the docs (e.g
initially my problem was that my og meta tags weren't being fetched by the sharing debbuger or the twitter card validator, therefore i searched various issues on github i found out that the major reason was the chunk of css that were present before my tags then i got to know about onrenderbody function in gatsby-ssr api, i tried implementing it but i couldn't succeed
i hope i have not made any silly mistakes and most probably this is a bug.
my onrenderbody function fails silently with no warnings and error.
when the image is gif, it said you can't use childimagesharp together with abc.gif use publicurl instead
the childimagesharp portion of the query in this file will return null: /src/templates/post.js
i get cors errors that look like this whenever i open up my locally hosted project in the browser
failed to load resource: net::err_connection_refused
:42421/socket.io/?eio=3&transport=polling&t=ncfy1_1:1 failed to load resource: net::err_connection_refused
:42421/socket.io/?eio=3&transport=polling&t=ncfy2s7:1 failed to load resource: net::err_connection_refused
:42421/socket.io/?eio=3&transport=polling&t=ncfy3_a:1 failed to load resource: net::err_connection_refused **i am not using docker or apache2.** **i have no other servers open and running** **opening the browser in incognito mode does not stop the errors** (could have been caused by an extension) **errors appear in chrome, not firefox**
**gatsby-cli command: gatsby develop auto exit becouse of emacs editor tmp file such as .#about.jsx**
an error about reaching a random websocket port not being reachable, as docker cannot be configured to know in advance what the random port will be.
tutorial 4, "data in gatsby" documentation encourages the step of installing the typography library, but then `$ gatsby develop` results in `invalid hook call.` error.
i use `gatsby-transformer-remark` to parse markdown files and [get table of contents]( #getting-table-of-contents)
if i hit an item in table of contents (anchor link), the browser doesn't scroll to the section.
i was following the source plugin tutorial ([here](
i noticed that when my plugin is in this 'plugins' folder, oncreatenode wasn't called everytime a new node was created
if i move my plugin to another place and use 'require.resolve', it works as it's suppose to.
development mode is not started on a gatsby-based documentation, built with `gatsby-theme-carbon`:
`gatsby develop` freezes on windows 10 on "build manifest and related icons"
a chrome debug apparently shows what seems an infinite loop in the `gatsby-plugin-manifest`: ![image]( ![image](
this bug is present when deployed but not during development
essentially, i have a switch that toggles between two views using a localstorage boolean
the problem is that when you switch to the "code" view and refresh, the layout and footer glitches out and the topbar doesn\'t seem to recognize its state
this doesn\'t happen on the "regular" view
interestingly, the glitched view seems to take up the space of the initial "regular" view
this can be seen when reproducing the bug on my resume page
my apologies if i'm missing something obvious, but this has been driving me nuts
i use **netlify** for hosting but aws amplify gave me the same problem.
when clicking a link on front page with a list of posts after scrolling down for example, would result in the new content being scrolled down as much as previous page
at first i have read many other posts and issues mentioning it was related to css / body height etc but could not find a solution to this
i have setup gatsby completely from scratch to reconfirm my problem is not related to css
things seems to work fine in development mode
**this happens on production**
`gatsby develop` currently exits with `0` code in some scenarios where it shouldn\'t - in particular when fatal out-of-memory happens in develop child process: when oom happens child process exit handler will get `code = null` and `signal = "sigabrt"`, because right now we don\'t check signal part we exit parent process with `null` code (`process.exit(null)`), which actually translates into `process.exit(0)` which is wrong.
in the local dev server i can navigate to all pages and reload them : the app stays on the same page when deploying the production build: some page load fine: other pages will redirect to home when you reload them or try to load them from the url
i'm quite new to gatsby but as the production build doesn't have errors, and the console.log on production is completely blanco i find it very hard to debug what actually could be wrong here.
when trying to use `gatsby build` to prepare my site for deployment, i receive an error: `webpackerror: typeerror: cannot read property 'length' of undefined`
since some days there is an "gatsby-cloud-staging" bot running
but i expect the gatsby www site should be in the stage and not the gatsbygram
i have both yarn and npm installed on my system and when gatsby asks which package manager to use the selection dialog looks wrong.
![image](
creating a schema object with fields containing underscore (see `x_qlik_stability` below) does not fetch the data
the field can be queried for, but the value is always null.
since today 2nd july 16:00 cet when trying to run yarn install + gatsby build with gatsby 2.6.7 the following error is outputted
codebase was not changed
error #11321 plugin "gatsby-theme-style-guide" threw an error while running the createpages lifecycle: reducers may not dispatch actions
error: reducers may not dispatch actions
- redux.js:214 dispatch [build_blog]/[redux]/lib/redux.js:214:13 - index.js:67 [build_blog]/[gatsby]/dist/redux/index.js:67:88 - index.js:14 object.dispatch [build_blog]/[redux-thunk]/lib/index.js:14:16 - index.js:45 dispatch [build_blog]/[gatsby-cli]/lib/reporter/redux/index.js:45:9 - redux.js:483 object.createlog [build_blog]/[redux]/lib/redux.js:483:12 - reporter.js:168 reporter.warn [build_blog]/[gatsby-cli]/lib/reporter/reporter.js:168:41 - patch-console.js:22 object.console.warn [build_blog]/[gatsby-cli]/lib/reporter/patch-console.js:22:14 - utils.js:449 object.warn [build_blog]/[xstate]/lib/utils.js:449:26 - statenode.js:1313 [build_blog]/[xstate]/lib/statenode.js:1313:29 - array.map - statenode.js:1311 statenode.formattransitions [build_blog]/[xstate]/lib/statenode.js:1311:18 - statenode.js:321 statenode.get [as transitions] [build_blog]/[xstate]/lib/statenode.js:321:51 - statenode.js:296 statenode.get [as on] [build_blog]/[xstate]/lib/statenode.js:296:36 - statenode.js:230 [build_blog]/[xstate]/lib/statenode.js:230:93 - array.foreach - statenode.js:230 statenode._init [build_blog]/[xstate]/lib/statenode.js:230:45 failed createpages - 101.229s
when trying to run `npm install` with `gatsby: 2.23.16` the following error is outputted
`no matching version found for babel-plugin-remove-graphql-queries@^2.9.10.`
running `gatsby develop` isn't working with latest versions of gatsby and the cli.
i know there's already a lot of issues similar to this one (e.g and more...), but none of them describes my issue and i couldn't find a solution in any of them
when running `gatsby develop` (`npm run develop`) i get this error:
> gatsby-starter-default@0.1.0 develop c:\\users\\ori\\code\ ew_agra_site
> gatsby develop c:\\users\\ori\\code\ ew_agra_site\ ode_modules\\yoga-layout-prebuilt\\yoga-layout\\build\ elease\ bind.js:53 throw ex; ^ error: spawn node enoent at process.childprocess._handle.onexit (internal/child_process.js:267:19) at onerrornt (internal/child_process.js:469:16) at processticksandrejections (internal/process/task_queues.js:84:21)
emitted 'error' event on childprocess instance at: at process.childprocess._handle.onexit (internal/child_process.js:273:12) at onerrornt (internal/child_process.js:469:16) at processticksandrejections (internal/process/task_queues.js:84:21) { errno: 'enoent', code: 'enoent', syscall: 'spawn node', path: 'node', spawnargs: [ 'c:\\\\users\\\\ori\\\\code\\\ ew_agra_site\\\\.cache\\\\tmp-13908-kho9ccgjekxb' ]
npm err! code elifecycle
npm err! errno 7
npm err! gatsby-starter-default@0.1.0 develop: `gatsby develop`
npm err! exit status 7
npm err! failed at the gatsby-starter-default@0.1.0 develop script.
npm err! this is probably not a problem with npm
there is likely additional logging output above
npm err! a complete log of this run can be found in:
npm err! c:\\users\\ori\\appdata\ oaming\ pm-cache\\_logs\\2020-07-02t08_18_45_906z-debug.log
``` i tried some things like running `npm install` and `npm update`
i also tried removing the local installation of the cli and installing it globally (as recommended in one of the issues mentioned above), but got the same result.
i am using gatsby via [docz](
after the latest release, the static build has started failing
it works fine when i pin the package to the immediately previous version
since it was a patch release, there shouldn't be any breaking changes in the release.
cannot get image's uri after updating content in contentful can go back to normal if i use `gatsby clean` after updating things in contentful and then `gatsby develop` again
development compilation of my styles is failing after changing from `node-sass` to `sass` (dart implementation)
the error message doesn't tell me anything about what's going on - it seems it's a syntax error on a perfectly legal sass syntax
when i try compiling that same file that's throwing an error manually using the same `sass` executable: `npx sass <name-of-the-file>` the complication is successful - doesn't produce any errors and outputs proper css
so the problem seems to be somewhere within the chain of loaders that are applied in the webpack compilation process.
i am working on gatsby with strapi.
i receive that message when i run develop
(node:43092) [dep0066] deprecationwarning: outgoingmessage.prototype._headers is deprecated
i'm creating a multi-language site, so what i did was delete the original pages, and recreate them with the language slug in front resulting in: /pages/page1 => /en/page1, all this part of multilanguage works perfectly, but a problem arose at least strange, when i click on a link gatsby within the site, and i go to an internal page for example, it duplicates that page in the browser history, this causes me to have to click 2 times on the button back to be able to return to the previous page.
we are trying to make use of an existing apollo graphql server for a new gatsby site
i am not sure why but we are getting this error on `gatsby develop`
error: `query.node defined in resolvers, but not in schema`
our apollo server has been working with no issues and the above error we are getting from gatsby doesn't seem to be legitimate
our schema does have the `node` definition as shown below: ```
interface node { id: id!
type query{ ....
node(id: id!): node
i enabled the playground for the graphql server also if you need any additional info.
the "last updated" field will always display the date that the site was last deployed
for example, the [docs index]( hasn\'t been updated since may but still says "last updated: june 27, 2020" <img width="243" alt="last updated: june 27, 2020" src=" "> i think this is because the gatsby cloud builds only take a shallow copy of the git history of the gatsby monorepo
the "last updated" field is derived from git log data, so nothing will have its actual git history
this means the "latest update" information is useless and misleading: it implies that deprecated and outdated files are up-to-date
## potential solutions 1
build the gatsby site with a full commit log
this would probably slow down the site build significantly.
do something clever with loading the commit data from github.
just get rid of the "latest update" feature.
following the documentation tutorial for a quick start from gatsby, the application breaks when running.
* quick-start:
we've had a regression in our output for build errors recently as called out by @pieh [here]( #discussion_r445720017)
we were no longer displaying source maps or proper stack traces, leading to confusing outputs with unhelpful action like #25327 this fixes the two regressions we had, namely that we weren't properly passing error keys to the error class properly as well as add two integration tests to ensure we capture and log the proper error outputs for build issues
### documentation <!-- where is this feature or api documented? - if docs exist: - update any references, if relevant
this includes guides and gatsby internals docs
- if no docs exist: - create a stub for documentation including bullet points for how to use the feature, code snippets (including from happy path tests), etc
- tag @gatsbyjs/learning for review, pairing, polishing of the documentation
--> ## related issues #17445
i'm seeing errors in sentry for our gatsby site being caused by one of gatsby's internal utilities using `string.endswith` which is not being correctly polyfilled with [core-js]( `/es.string.ends-with.js` the error originates [here]( #l33):
function absolutify(path) { // if it's already absolute, return as-is if ( path.startswith(`/`) || path.startswith(`https://`) || path.startswith(`http://`) ) { return path } // calculate path relative to current location, adding a trailing slash to // match behavior of @reach/router return new url( path, window.location.href + (window.location.href.endswith(`/`) ? `` : `/`) ).pathname
} looks like the same is true for `startswith` and possibly others.
``` i'm using gatsby's default browserlist which should include polyfills for ie11.
my build fails with the following error: ``` typeerror: cannot read property 'startswith' of undefined - get-resources-from-html.js:40 node.<anonymous> [blog]/[gatsby-plugin-offline]/get-resources-from-html.js:40:42
``` i think that this line: #l46 doesn't check the url for nullability.
including a gatsby image on a page without any parameters, like so `<img />`, crashes the page at runtime with the error message `typeerror: cannot read property '0' of undefined`
i came across this in a [stackoverflow question]( #62622605)
when using `gatsby-plugin-preact` on a project that has a runtime error, component doesn't render and error doesn't show up.
i'm trying to use gatsby with react-spring and react-three-fiber
i'm able to successfully get my example code to work while in develop mode
however, after a build and serving that page, i get an in-browser console error
**uncaught (in promise) error: page resources for / not found
not rendering react at production-app.js:128 ** there are no build errors
the problem is not present when i change a.mesh to mesh
that initially led me to believe that this is a react-spring and or three-fiber problem (and it still may very well be), but after checking issues here, i see other gatsby users having similar "not rendering react" errors in the built version and thought it would be wise to check.
queries on fields with the `link` field extension broke with gatsby@2.23.
if the background prefetch request triggered by hovering `<link />` elements does not complete, subsequent clicks on the link appear to be broken
hovering over a link on a page that has not yet been prefetched (or is stale) leads to a prefetch requests to `/page-data/app-data.json` (due to [the call to `loader.loadpage()` in `cache-dir/navigation.js` -> `navigate()`]( #l76))
![kapture 2020-06-26 at 16 27 11](
i build documentation site using `gatsby-plugin-mdx` and `gatsby-remark-images`
when i include image to my page, blur is visible and it does not disappear after image is loaded
also loaded image does not appear
i have been playing around with plenty of different settings, but none of them worked
i also walked through #15486 and #17017, but none of solutions there solved my issue.
success rewriting compilation hashes - 0.007s
failed building static html for pages - 16.059s error #95313 building static html failed see our docs page for more info on this error: webpackerror: referenceerror: self is not defined - build-html.js:107 dobuildpages [my-default-starter]/[gatsby]/dist/commands/build-html.js:107:24 - build-html.js:121 async buildhtml [my-default-starter]/[gatsby]/dist/commands/build-html.js:121:3 - build.js:219 async build [my-default-starter]/[gatsby]/dist/commands/build.js:219:5 not finished generating image thumbnails - 175.794s
say i have a bunch of entries of type `document` in contentful
each of these has three fields:
title (short text)
slug (short text)
body (rich text) within `body`, we frequently use the `entry-hyperlink` type to link to other `documents`
suppose that each of these entries has a `body` containing roughly 1000 words and each contains 10 or more `entry-hyperlinks`
in my component, it's handy to have some fields resolved for me
however, because _every_ field is resolved, including `body`, i end up with the unused full text content for all 10 hyperlinked references in `page-data.json`, bloating file size by 10x and producing warnings:
warn the size of at least one page context chunk exceeded 500kb, which could lead to degraded...
``` total field resolution makes sense for embedded entries, but less so for hyperlinked ones
not sure exactly what the fix would be (would schema customization work here?)
maybe the solution is adding a plugin option that prevents the resolution of certain field types (rich text, potentially long text) when creating rich text nodes for nodes with type 'entry-hyperlink'
would love to hear other's thoughts.
i don't use ```window``` anywhere in my code without checking if it's defined first.
in build i constantly get the dreaded 'window is not defined' error from files i'm sure how to tackle
these are files i suspect have to do something with the page build and they consistently throw this error only in build time.
i major change i did today is re-installing the ```package-lock.json``` file to solve another issue
but this came up after the initial issue was solved.
repo:
in build i constantly get the dreaded 'window is not defined' error from files i'm sure how to tackle
these are files i suspect have to do something with the page build and they consistently throw this error only in build time.
i major change i did today is re-installing the ```package-lock.json ```file to solve another issue
but this came up after the initial issue was solved
repo:
i've been using gatsby-source-shopify and it's been working just fine
however, after following the guides for exposing/whitelisting metafields to the storefront api, i still get the following error when trying to query for the metafield like so: ```
query($handle: string!) { shopifyproduct(handle: { eq: $handle }) {
metafield(namespace: "custom_fields", key: "seo_title") { value }
i'm trying to build a page based on a theme locally with yarn workspaces
everything works fine when running `gatsby develop`, but as soon as i run `gatsby build` i get the following error: ```
error #98124 webpack generating javascript bundles failed can't resolve '../../../pagename/public/static/d/103120742.json' in '/users/username/.../.../gatsby-theme-name/src/components' if you're trying to use a package make sure that '../../../pagename/public/static/d/103120742.json' is installed
if you're trying to use a local file make sure that the path is correct.
``` the query that is failing: ```
query navlinkquery { site { sitemetadata { navlinks { name link } } }
``` when i remove that query, everything works fine.
seems to be related to this: #issuecomment-642140380 i already tried `gatsby clean` in both the theme and the page folder
i removed all `node_modules` and reinstalled the packages
contents of `gatsby info --clipboard`: ```
system: os: macos mojave 10.14.5 cpu: (4) x64 intel(r) core(tm) i7-4558u cpu @ 2.80ghz shell: 5.3 - /bin/zsh binaries: node: 12.13.1 - ~/.nvm/versions/node/v12.13.1/bin/node yarn: 1.22.0 - /usr/local/bin/yarn npm: 6.14.5 - ~/.nvm/versions/node/v12.13.1/bin/npm languages: python: 2.7.10 - /usr/bin/python browsers: chrome: 83.0.4103.116 edge: 83.0.478.56 firefox: 76.0.1 safari: 13.1.1 npmglobalpackages: gatsby-cli: 2.12.51 gatsby: 2.22.0`
implementing dns-prefetch fallback in the same <link> tag causes a bug in safari where preconnect gets cancelled
a png image added inline in a md or mdx file using `gatsby-remark-images` shows a white background, when the backgroundcolor has been specified in `gatsby-config.js`.
with merged, there are some lint failures on the master branch that can be inspected with circle ci: looks like retext-spell is having a tough time with proper nouns, and the `--frail` flag fails them by default: `remark --quiet --frail "./docs/"`
is it possible to disable this somehow, so we don't have to add every proper noun to the dictionary? until we make a change to the lint configuration, every docs pr will fail the linter.
i add an acf field `tags` to media objects on wordpress
thus, installed gatsby config with: ``` resolve: `gatsby-source-wordpress`, options: { baseurl: `${process.env.gatsby_wp_domain}`, protocol: `http`, hostingwpcom: false, useacf: true, }, },
``` and using this graphql query: ``` allwordpresswpmedia(limit: 24, filter: { acf: { tags: { eq: $id } } }) { edges { node { id caption alt_text post slug source_url title localfile { childimagesharp { fluid { ...gatsbyimagesharpfluid_withwebp } } } } } }
``` **it used to work just fine**, but now i tried to build again, i got this error: ```
there was an error in your graphql query: field "acf" is not defined by type wordpress__wp_mediafilterinput
``` this filter `filter: { acf: { tags: { eq: $id } } }` just disappeared on docs inside graphql explorer `localhost/__graphql` - the endpoint is working fine, i can query using the api the data of custom field.
- im using wp multisite.
hello, i try to create images gallery in my gatsby project
i decided to use cloudinary, however it do not want to work
i used static query the component
how can i fix it?
when i try to deploy my gatsby project to heroku after i didn't touch for a while, the deployment just keeps failing
it gets to building the js and css but then runs into a bunch of errors
when i run ```gatsby build``` it finishes successfully.
after not touching a certain project for a while, i changed a few minor things and tried to push to heroku
i noticed that the build keeps crushing and sharp always fails to install
i referred to old issues and cleared npm cache, deleted node_modules and ran ```npm install```
but now every time i run ```npm install``` it runs into an error while installing sharp
when running gatsby 2.23.5 or above, local https doesn't work
rolling back to 2.23.4, https works properly.
since 2.23.6, if you put in a hash that isn't a valid selector (for example including a `=` character), then we get an error when gatsby tries to scroll to that hash, and the whole application dies.
404 error on docs/node-apis/ for source code
apparently, gatsby react helmet doesn't pre-render all my tags
i use both gatsby-plugin-react-helmet and react-helmet for managing my site tags, but instead of being rendered in server side, it renders in client side
which affects the seo really bad
you can view my company's site here :
using `gatsby-starter-blog` as a base, i recently switched over to mdx files using `gatsby-plugin-mdx` and am receiving an error on build
it appears that "data" used in my template file is undefined
`gatsby develop` runs fine, however
the error: ```
building static html failed for path "/blog/fixing-fouc/" see our docs page for more info on this error: webpackerror: typeerror: cannot read property \'mdx\' of undefined
my build is failing at building static html for pages with a message below while the development works as expected
also the failed path can and does change with each build
sometimes it is a different doc page, sometimes it is the 404.html page
building static html failed for path "/docs/class/class-calendar/" see our docs page for more info on this error: webpackerror: referenceerror: open is not defined - build-html.js:107 dobuildpages [certground-main-website]/[gatsby]/dist/commands/build-html.js:107:24 - build-html.js:121 async buildhtml [certground-main-website]/[gatsby]/dist/commands/build-html.js:121:3 - build.js:215 async build [certground-main-website]/[gatsby]/dist/commands/build.js:215:5 ```
hi, i followed the steps: && and kept facing issues with fetching data from contentful **plugin version:** "gatsby-source-contentful": "^2.3.16",
i am creating a portfolio for high resolution pictures and would like to optimize the images that are produced by the sharp plugin
when i provide both maxwidth and maxheight to my graphql query, images that are returned are considerably smaller than the original image provided.
my project can't build with last 2 gatsby versions (2.23.5, 2.23.6)
it was working fine with 2.23.4
can't be of pretty much help as it's my first gatsby project.
the gatsby website isn't loading at all in microsoft edge on windows
it doesn\'t render and goes to a browser page that says "this page is having a problem loading." no markup or javascript errors, and it happens on all sections as far as i can tell
i can reproduce it on a virtual machine and a surface both running windows 10
changes are coming to the website, so this may be irrelevant over time
but i didn't see anyone report it yet and thought it should be tracked/fixed.
i'm trying to use markdown in captions on images using the `gatsby-plugin-mdx` and the `gatsby-remark-images` by toggling `markdowncaptions`, but instead of markdown being rendered, i'm getting raw jsx (or something).
when passing `components` to `<mdxrenderer />` , those components are ignored
the 2.23.6 version of gatsby cli throws a type error in /lib/reporter/reporter.d.ts
when on the graphql playground page, clicking the chema link on the side crashes the page.
i create a branch few commit behind the head and then switch branch and do sthg
and then it fail to develop and it give me this error
i am trying to setup a gatsby site using gatsby blog theme starter, everything works as expected, till the time i run `gatsby develop`
i got a critical security vulnerability alert to update [graphql-playground-html]( from 1.6.19 to 1.6.25
after upgrading, whenever i run `gatsby develop` locally, any components with a `<staticquery>` render with the words "loading {staticquery}" inline instead of the contents of the component
it's similar the same behavior described in some old issues #7959 #24890 i've tried the resolution on that old issue, clearing my cache and node modules folder and that does not resolve the issue
downgrading the plugin works, but isn't a great solution since it is a critical security vulnerability
note, this only affects my `gatsby develop`, my `gatsby build` works fine
i haven't yet made a reproduction case, but if other people are experiencing the same issue with this plugin i can, i just wanted to document what i was seeing for now.
during a build, when the cli outputs the stage `source and transform nodes` and remote images are being downloaded, this activity and progress briefly flickers before disappearing again, unlike the later stages like `generating image thumbnails`
ideally, the feedback about download progress would not be hidden like that and would remain visible, nothing else was contending with it visually.
i am attempting to deploy to aws amplify but the build is failing but not producing an error message
this is the last bit of the build log: `- couldn't fulfill desired order of chunk group(s) component---src-pages-app-js, component---src-pages-quiz-js * css ./node_modules/css-loader??ref--12-oneof-1-1!./node_modules/postcss-loader/src??postcss-2!./src/components/swipenotification/swipenotification.css - couldn't fulfill desired order of chunk group(s) component---src-pages-app-js, component---src-pages-quiz-js * css ./node_modules/css-loader??ref--12-oneof-1-1!./node_modules/postcss-loader/src??postcss-2!./src/components/firstquestion/firstquestion.css (3) - couldn't fulfill desired order of chunk group(s) component---src-pages-app-js, component---src-pages-quiz-js - while fulfilling desired order of chunk group(s) component---src-pages-about-js, component---src-pages-index-js warning chunk styles [mini-css-extract-plugin] conflicting order
following module has been added: * css ./node_modules/css-loader??ref--12-oneof-1-1!./node_modules/postcss-loader/src??postcss-2!./src/components/firstquestion/firstquestion.css (3) despite it was not able to fulfill desired ordering with these modules: * css ./node_modules/css-loader??ref--12-oneof-1-1!./node_modules/postcss-loader/src??postcss-2!./src/components/mobilenav/mobilenav.css - couldn't fulfill desired order of chunk group(s) component---src-pages-about-js, component---src-pages-index-js - while fulfilling desired order of chunk group(s) component---src-pages-app-js, component---src-pages-quiz-js * css ./node_modules/css-loader??ref--12-oneof-1-1!./node_modules/postcss-loader/src??postcss-2!./src/components/navbar/navbar.css (1) - couldn't fulfill desired order of chunk group(s) component---src-pages-about-js, component---src-pages-index-js - while fulfilling desired order of chunk group(s) component---src-pages-app-js, component---src-pages-quiz-js
2020-06-16t14:59:09.013z [info]: success building production javascript and css bundles - 14.148s
2020-06-16t14:59:09.086z [info]: success rewriting compilation hashes - 0.001s`
the `gatsby-plugin-mdx` mangles does not handle output from rehype plugins correctly
i'm trying to handle inline math using the `remark-math` and `rehype-mathjax` plugins
the `rehype-mathjax` plugin defaults to produce inline svg images
the plugin correctly parses the math nodes produced by the `remark-math` plugin, but somewhere along the line some of the attributes are translated to camel-case (e.g
`class` -> `classname` `xmlns:xlink` -> `xmlnsxlink`, and `xlink:href` -> `xlinkhref`), and not translated back when producing the html.
my page content should have different images for desktop and mobile
and these images have different ratios
i use the same structure as described in your documentation ( #art-directing-multiple-images ) and it works great on development mode.
when my site is build and i access to the page on desktop screen, it works well
the image change and is resized when the window is resized
but when i access to the page on a small screen, the right image is displayed, but it has the proportions of the desktop image
i need to resize the screen to fix the image ratio
the child div of .gatsby-image-wrapper has the padding that should be set on desktop instead of mobile
it looks like the padding is cached.
**tl;dr: when gatsby-plugin-mdx is enabled, it will not respect `browserslist` config in `package.json`.** i'm customizing browserslist
and i followed the instruction in [browser supper | gatsbyjs]( #specify-what-browsers-your-project-supports-using-browserslist)
for test purpose, i have set the `browserslist` in `package.json` to `chrome > 80`
but to my surprise, things like `es6.promise` still appear in the final production bundle
![image]( after that, i **remove gatsby-plugin-mdx** from my repo and rebuild my project with `chrome > 80`
this time it works! ![image]( and i change the `browserslist` back to `defaults`
and here is the result: ![image](
i see a lot of polling errors from socket.io in my console
after i have activated https using this documentation
cant fetch from usestaticquery(graphql)
there is error in console of gatsby website telling **uncaught referenceerror: firebase is not defined**
attempting to configure webpack externals fails
actions.setwebpackconfig({ externals: {} })
results in the following error: ```sh
error there was an error compiling the html.js component for the development server
see our docs page on debugging html builds for help syntaxerror: unexpected token '.' webpackerror: syntaxerror: unexpected token '.' - build-html.ts:127 dobuildpages [gatsby-theme-cs125]/[gatsby]/src/commands/build-html.ts:127:24 - build-html.ts:147 buildhtml [gatsby-theme-cs125]/[gatsby]/src/commands/build-html.ts:147:3 - develop-process.ts:121 createindexhtml [gatsby-theme-cs125]/[gatsby]/src/commands/develop-process.ts:121:7 - develop-process.ts:144 startserver [gatsby-theme-cs125]/[gatsby]/src/commands/develop-process.ts:144:3 - develop-process.ts:448 module.exports [gatsby-theme-cs125]/[gatsby]/src/commands/develop-process.ts:448:39
``` (obviously this is a silly example, since there is no need to override externals with an empty object
but trying to pass in a valid configuration object also fails.)
with any gatsby project that i run locally i see the same problem
it infinitely reloads with an error when i look at localhost:8000 but works fine on other network interfaces.
i observed, that the plugin has an npm dependency to `idb-keyval` and copies `idb-keyval-iife.min.js` from the node_modules folder into the public folder in `onpostbuild`: #l163-l166 the [official caching recommendations]( are oblivious of that file and it would be cached with `cache-control: public, max-age=31536000, immutable`
furthermore, the plugin itself will cache the file with the `cachefirst` strategy by default: #l135-l140 this is based on the assumption that all `.css` and `.js` files are fingerprinted, yet `idb-keyval-iife.min.js` is not
if a future version of the plugin decides to use another version of `idb-keyval` this will become a problem since clients will not receive the update of the new version of `idb-keyval` because it is cached as immutable
### idea for a fix read the version of `idb-keyval` from `package.json` in `node_modules/idb-keyval` and include it in the filename
instead of calling `importscripts` with a literal file name in `sw-append.js`, it could be prepended here with the filename that includes the version: #l184-l187 this solves the problem without the need to alter any existing caching configurations
i can send a pr if this is wanted.
i had some weird, apparently random rendering issues after i renamed some fields in a graphql page query
on the initial load, ui components were displayed with empty texts, whenever they were sourced from updated page query data
after a reload, the page appeared correctly
i do believe it's a service worker caching issue and i think this piece of configuration is the source of the problem: #l142-l144 i think it should be `networkfirst` since `stalewhilerevalidate` creates the possibility that changed code that expects an updated page query structure can potentially run on temporarily served, outdated `page-data.json` the [official plugin documentation]( #overriding-workbox-configuration) states, that it is `networkfirst` by default, but in code, it is not
i will send a pr if this is approved.
running `develop` calls `gatsby-config.js` twice
i am showing some "welcome" message in my gatsby config with some information, having them printed twice doesn\'t look pretty nice and i think it is not necessary to get it twice anyway.
typo in the usage documentation for the pageprops generic type
there is currently a circular reference of indexpageprops
this pr updates the first generic type argument in the example to be the dataprops, as reflected in the [default starter]( #l14).
i have an `.md` file that contains words `import` and `export` in the same sentence
this throws an error when trying to run `yarn start`
- changed types for postcss plugins from webpack `plugin` type to postcss `plugin<t>` type
- added a check of each plugin's `postcssplugin` property; a plugin with a `postcssplugin` property equal to `autoprefixer` will have its options assigned to the default
### documentation
hopefully this is just a fix and should not change the public interface
there are however references to it here #postcss-plugins and here #postcss-plugins
<!-- where is this feature or api documented? - if docs exist: - update any references, if relevant
this includes guides and gatsby internals docs
- if no docs exist: - create a stub for documentation including bullet points for how to use the feature, code snippets (including from happy path tests), etc
- tag @gatsbyjs/learning for review, pairing, polishing of the documentation
--> ## related issues
addresses #15509, #17428, #11984
<!-- link to the issue that is fixed by this pr (if there is one) e.g
fixes #1234 link to an issue that is partially addressed by this pr (if there are any) e.g
addresses #1234 link to related issues (if there are any) e.g
related to #1234
gatsby-source-filesystem's remote file node will occasionally throw a [got.timeouterror]( #gottimeouterror) if the tcp socket was queued
the solution was to target the specific `send` timeout which starts when the socket is connected and ends with the request has been written to the socket
this keeps with what i assume is the intended purpose of the timeout while hopefully throwing the error simply because the tcp connection was queued
this also removes the retries option from the got request since the [docs]( #retry) note streams ignore this option due to the errors that would cause a retry would need to be handled correctly to avoid duplicates (which they are)
note: the got.timeouterror is a separate timeout and wouldn't be triggered here
### documentation #gottimeouterro
#retry ## related issues
fixes #22010 fixes the got part of #23123
the `gatsby-remark-images-contentful` plugin causes builds to break if an image url with a search param is used
the axios call inside of the`getbase64img` function fails when the image url contains a search param, since the `buildresponsivesizes` that calls it appends a `?w=40` search param at the end of the provided url
the url then becomes something like `example.com?foo=bar?w=40` which is an invalid url
this pr adds a try/catch block around the axios call inside of the`getbase64img` function.
it also strips out search params from the image url, since the `metadata` object passed into `buildresponsivesizes` already has all of the sizing information that it needs
more information around the issue can be found here #24896 ## related issues
fixes #24896
if a contentful entry with markdown has an inline image url that contains a query parameter (ex: `example.com?foo=bar`, the build breaks and the logs report a failed request with a 502 error
this is because the `getbase64img` function is called, which initiates an axios request with an invalid url
the url is constructed in the following way:
`${imageurl}?w=40` if `imageurl` already has a search param, the url is invalid
for example:
`imageurl = "example.com?foo=bar"` becomes `example.com?foo=bar?w=40"` which is an invalid url
the "real-world-scenario" i ran into is that at the company i work at, our content team added an image url in markdown with `?h=40` at the end
while we asked them to remove it, it would be best if the build didn't break because of it
potential solutions:
- wrap the request in a try/catch, and log out a warning that images with search params in markdown content are not supported.
- in the `buildresponsivesizes` function, strip out search params for new image urls (like the base64 image and srcset urls)
if i understand the code correctly, the `metadata` param passed to `buildresponsivesizes` already provides all the sizing information about the image that it needs to construct the srcset urls
sizing data in the search params like `?h=40` are unnecessary at that point.
gatsby admin is using an alpha version of `theme-ui`, at the time of writing this, `0.4.0-alpha-3`
this is causing issues given `gatsby-plugin-theme-ui` uses `0.2.52`
as of 0.3.x of theme-ui the `colormode` component was removed from a named export from the root `theme-ui` package
`gatsby-plugin-theme-ui` 0.2.x uses it here: this is causing issues with npm's module resolution
if you install with yarn it works fine
cc @mxstbr @johno @jxnblk
gatsby-plugin-google-gtag - optimize_id should only be sent to analytics.js and not to other platforms like google ad words
returning `false` from `shouldupdatescroll` should prevent scrolling to the top of the page on a route change.
the vendor files are placed in /public, and they work perfectly fine in all top level routes
the issue is when using a nested route, suddenly the app throws an error: `uncaught syntaxerror: unexpected token '<'`
there are several bugs that emerge because of the fact that we don't use ssr in develop
this pr handles some of those cases by using reactdom.rendertostring in develop
this is the approach suggested by @gaearon here #issuecomment-594093783 this does not cover other ssr issues, such as different handling of styles, or the availability of browser globals, because it still runs in the browser context
this only works with fast-refresh, and is also ignored if `replacehydratefunction` has been implemented.
a javascript library i'm using needs to be available as static files, and is also required in the code
hence, i put it in `src/components/something/charting_library` and symlinked it to `static`.
this symlink gets served properly in development mode, but cannot be built.
it appears this messages in dev tools: ![image](
access to xmlhttprequest at ' from origin ' has been blocked by cors policy: the value of the 'access-control-allow-origin' header in the response must not be the wildcard '*' when the request's credentials mode is 'include'
the credentials mode of requests initiated by the xmlhttprequest is controlled by the withcredentials attribute.
polling-xhr.js:268 get net::err_failed
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
(index):1 access to xmlhttprequest at ' from origin ' has been blocked by cors policy: the value of the 'access-control-allow-origin' header in the response must not be the wildcard '*' when the request's credentials mode is 'include'
the credentials mode of requests initiated by the xmlhttprequest is controlled by the withcredentials attribute.
polling-xhr.js:268 get net::err_failed
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
xmlhttprequest.send (async)
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.create @ polling-xhr.js:268
request @ polling-xhr.js:170
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.request @ polling-xhr.js:96
./node_modules/engine.io-client/lib/transports/polling-xhr.js.xhr.dopoll @ polling-xhr.js:126
./node_modules/engine.io-client/lib/transports/polling.js.polling.poll @ polling.js:118
./node_modules/engine.io-client/lib/transports/polling.js.polling.doopen @ polling.js:63
./node_modules/engine.io-client/lib/transport.js.transport.open @ transport.js:84
./node_modules/engine.io-client/lib/socket.js.socket.open @ socket.js:250
socket @ socket.js:122
socket @ socket.js:28
./node_modules/socket.io-client/lib/manager.js.manager.open.manager.connect @ manager.js:226
(anonymous) @ manager.js:540
settimeout (async)
./node_modules/socket.io-client/lib/manager.js.manager.reconnect @ manager.js:530
(anonymous) @ manager.js:544
(anonymous) @ manager.js:247
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/socket.js.socket.onerror @ socket.js:690
(anonymous) @ socket.js:281
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transport.js.transport.onerror @ transport.js:71
(anonymous) @ polling-xhr.js:132
./node_modules/component-emitter/index.js.emitter.emit @ index.js:145
./node_modules/engine.io-client/lib/transports/polling-xhr.js.request.onerror @ polling-xhr.js:314
(anonymous) @ polling-xhr.js:261
settimeout (async)
xhr.onreadystatechange @ polling-xhr.js:260
error while processing an error generated by a source plugin
gatsby tries to open an invalid filename from the stack trace
this causes a new error that hides the original plugin error.
having 2 issue's with socket.io crop up since 2.22.1 and later
everything worked fine in 2.21.29 1) socket.io.js has no content-type which means when running with nosniff it can't be run
2) calls to socket.io are all coming over http instead of https both of these issue's are cropping up when serving the develop version over nginx reverse proxy with ssl done at the web server level.
i'm getting a funky error 11328 with unhelpful debugging information when i run `gatsby build`
running `gatsby develop` works fine.
i tried to port an existing repository i use with gatsby and sanity into yarn workspaces
as a standalone repository, the code runs and builds fine
but once i move it into a yarn workspace and delete all the node_modules, public & .cache within that repo and run it again through workspace using `yarn workspace personalsite install` & `yarn workspace personalsite develop` i get this error
failed we've encountered an error: objects are not valid as a react child (found: graphqldocumenterror: graphqldocumenterror: unknown fragment
"gatsbysanityimagefixed".)
if you meant to render a collection of
children, use an array instead
in div (created by box) in box in unknown (created by cli) in div (created by static) in static (created by cli) in div (created by box) in box (created by cli) in div (created by box) in box (created by cli) in cli (created by connectedcli)
here's my package.json
{ "name": "personalsite", "private": true, "description": "extended starter to gatsby typescript", "version": "0.1.0", "author": "kyle mathews <mathews.kyle@gmail.com>", "dependencies": { "@babel/helper-validator-identifier": "^7.10.1", "@hot-loader/react-dom": "^16.11.0", "@sanity/block-content-to-react": "^2.0.7", "canvas-sketch": "^0.7.3", "gatsby": "^2.19.10", "gatsby-image": "^2.2.39", "gatsby-plugin-google-analytics": "^2.1.35", "gatsby-plugin-graphql-codegen": "^2.2.1", "gatsby-plugin-layout": "^1.1.21", "gatsby-plugin-manifest": "^2.2.40", "gatsby-plugin-nprogress": "^2.3.0", "gatsby-plugin-offline": "^3.0.33", "gatsby-plugin-react-helmet": "^3.1.21", "gatsby-plugin-react-svg": "^3.0.0", "gatsby-plugin-sharp": "^2.4.4", "gatsby-plugin-styled-components": "^3.1.19", "gatsby-plugin-tslint": "^0.0.2", "gatsby-plugin-typescript": "^2.1.26", "gatsby-plugin-typography": "^2.3.21", "gatsby-source-filesystem": "^2.1.47", "gatsby-source-graphql": "^2.1.32", "gatsby-source-sanity": "^5.0.5", "gatsby-transformer-sharp": "^2.3.13", "graphql": "^14.6.0", "react": "^16.12.0", "react-dom": "^16.12.0", "react-helmet": "^5.2.1", "react-reveal": "^1.2.2", "react-toggle": "^4.1.1", "react-typography": "^0.16.19", "styled-components": "^5.0.0", "styled-theming": "^2.2.0", "typography": "^0.16.19" }, "devdependencies": { "@graphql-codegen/cli": "^1.12.1", "@graphql-codegen/typescript": "^1.12.1", "@types/node": "^13.5.2", "@types/react": "^16.9.19", "@types/react-dom": "^16.9.5", "@types/react-helmet": "^5.0.15", "@types/react-toggle": "^4.0.2", "@types/styled-components": "^4.4.2", "@types/styled-theming": "^2.2.2", "@types/typography": "^0.16.3", "prettier": "^1.19.1", "tslint": "^6.0.0", "tslint-config-prettier": "^1.18.0", "tslint-loader": "^3.5.4", "tslint-react": "^4.2.0", "typescript": "^3.7.5", "yarn-upgrade-all": "^0.5.2" }, "keywords": [ "gatsby" ], "license": "mit", "scripts": { "build": "gatsby build", "develop": "gatsby develop", "format": "prettier --write src/**/*.{js,jsx}", "start": "npm run develop", "serve": "gatsby serve", "test": "echo \\"write tests! -> "", "now-build": "yarn run build", "generate": "graphql-codegen" }, "repository": { "type": "git", "url": " " }, "bugs": { "url": " " }
``` my project structure ```
site - frontend - node module - public - .cache - studio
package.json ``` **even worse part is once i have removed the workspace and re-run the project standalone within the same project structure after deleting all public, cache and node_module files, it still continues to throw this error
looks like a one way road and i'm unable to revert back**
if i rename or delete a file on /src/pages folder during **"gatsby develop"** and update any file got an "failed to compile" on web browser and **error #98123 webpack** with the message **enoent: no such file or directory** that is looking for the file that was deleted o renamed (the old name).
working with `.mdx` files
tried to included one jsx component within another jsx component, where child is being parsed as if it is mdx
it seems there are some issues with indentation within child mdx content
"gatsby-plugin-mdx" threw an error while running the oncreatenode lifecycle: unknown: expected corresponding jsx closing tag for <table> (68:2) 66 | </tablecell> 67 | `}</code></pre>
> 68 | </tablerow> | ^ 69 | 70 | <tablerow> 71 | <tablecell type="propname">title</tablecell>/users/x/workspace/project_x/src/documents/path_a/path_a/file_a.mdx: unknown: expected corresponding jsx closing tag for <table> (68:2)
``` ### example ```jsx
// example_file.mdx
--- # some title more md text..
<jsxcomponenta> <jsxcomponentachild> some text <jsxcomponenta> <jsxcomponentachild> inner component child text </jsxcomponentachild>
// it all depends if there is empty row here
// if there is, then is it indented at same level as inner component child
// if not, then it throws error similar to written above <jsxcomponentachild> inner component child text </jsxcomponentachild> </jsxcomponenta> more text </jsxcomponentachild>
</jsxcomponenta>
``` this seems some limitation on how mdx file is being parsed
most likely possible to improve, but i don't know how to improve this to make it more bullet proof, so that client/end_user would not need to worry about putting space or indentation incorrectly and making everything not working.
when both remark transforms are used together inside of `gatsby-transformer-remark` the contentful markdown images fade out to opacity 0.
when use gatsby with @mdx-js/runtime an error occurs in the bundle:
error #98124 webpack generating development javascript bundle failed can't resolve 'fs' in '/volumes/projects/gatsby-site/node_modules/@babel/core/lib/transformation' if you're trying to use a package make sure that 'fs' is installed
if you're trying to use a local file make sure that the path is correct
file: node_modules/@babel/core/lib/transformation/normalize-file.js
i am using `gatsby-transformer-remark` write blogs via mdx and i need to embed images in the blogs
i used `gatsby-remark-images` plugin and i got the image optimization and the default blur up effect when loading the image
however i want to change it to using the background color technique described in here i tried to set the `backgroundcolor` inside the of the `options` of `gatsby-remark-images` like this
``` { resolve: `gatsby-remark-images`, options: { maxwidth: 1024, showcaptions: true, linkimagestooriginal: false, withwebp: true, backgroundcolor: "red", }, },
``` however images still blur up the images when loading
![image](
running unit tests in my project (jest and react testing library) triggers a failure in the link component in the withprefix function
the specific issue is the following line (which was recently changed):
export function withprefix(path, prefix = __base_path__) {
if `__base_path__` is not defined, this triggers an error
the previous version of this file guarded against this case by checking that `typeof __base_path__` is defined
i will be submitting a pr shortly with a fix.
during the build step, this error happens **vipspng: libpng read error vips2png: unable to write to target** please, could you provide me with a way to debug which image might be breaking vips2png (used by sharp plugin)? we have a thousand of them the error happens in circleci, and it's difficult to replicate in our local because of x number of reasons
more context:
info bootstrap finished - 39.546s warning [] 0/96 0.0 s 0% generating image thumbnailswarning the requested height "500px" for a resolutions field for the file /home/circleci/project/.cache/caches/gatsby-source-drupal/7f6345e68e32e87cf256a6dbc8a1b279/example.png was larger than the actual image height of 330px! if possible, replace the current image with a larger one
[] 0/135 0.0 s 0% generating image thumbnails [] 0/182 0.0 s 0% generating image thumbnails [] 0/185 0.0 s 0% generating image thumbnails [] 1739/1749 34.5 s 99% downloading remote files [] 1741/1749 34.6 s 99% downloading remote fileserror there was an error in your graphql query: vipspng: libpng read error vips2png: unable to write to target 57 | langcode 58 | title 59 | created 60 | path { 61 | alias 62 | } 63 | relationships { 64 | field_recipe_image { 65 | localfile { 66 | childimagesharp { > 67 | fixed(height: 500) | ^ 68 | ...gatsbyimagesharpfixed_withwebp 69 | } 70 | } 71 | } 72 | } 73 | } 74 | } 75 | 76 | query listingquery { 77 | allnodeproductpage { file path: /home/circleci/project/src/components/listing.js
plugin: none not finished run queries - 3.854s
not finished generating image thumbnails - 3.828s ```
in the latest release of gatsby, the typescript typings are (still) broken
someone made a bug report about this ~5 days ago, but changed his description later on (
this issue is now closed, but the actual behavior he originally explained is still present in the latest release of gatsby.
bind top level server to host provided by user (we fallback to `localhost` if not specified)
## related issues #issuecomment-638330741
on the example website, linked from kyle's avatar picture is a deadlink
the url is not getting the image of kyle's avatar in this example
![missing kyle avatar](
when loading images with different aspect ratios the wrong ratio is applied on initial page load.
in the following example this is shown by loading a 2x3 image on mobile (<678px) and a 16x9 on desktop (>678px)
this only occurs when on the built version of the website
dev mode is working as expected.
the "next" link on the [docs & blog components]( is broken, with the `to` prop null
this was causing build failures (since fixed)
i'm not aware of the details of how the navigation is handled with these, othewrwise i would've fixed it myself
`gatsby-link` throws an error when a number is passed to its `navigate()` function
this is caused by `parsepath()` not expecting number parameters
see #l50 reach router's `navigate()` function accepts number parameters to navigate the history (e.g
`-1` goes back)
see
based on the props in a theme, styles are rendered
the header logo svg changes colours based on a prop in the theme
.name { fill: #000; fill: ${(props) => (props.theme.colours.themes.header.lightlogo === true && `#fff`)};
if it has the `lightlogo` prop, it should fill with white, otherwise black
but on the homepage of the site, it currently renders the logo with a white fill, despite the fact that the `lightlogo` prop is false this only happens during a production build (`gatsby build`), not in dev mode (`gatsby develop`) in react dev tools, can see the theme prop on the logo, and the `lightlogo` prop is set to false on the homepage, however the white fill style is still being rendered
![image](
![image](
the develop status bar doesn't always show in develop mode even though it should: #l8-l12 this isn't expected behavior and we need to see why `showstatusbar` is false.
it seems like the types for `creatermotefilenodeargs['cache']` are no longer consistent with the types from gatsby
this causes a type error when directly passing the `cache` from the `createresolversargs` to `createremotefilenode`.
in the last few days it looks like @emotion was added as a dependency of gatsby-admin but it is getting bundled up into the distributable app.js bundle
that doesn't seem right to me
running a `yarn why` points only back to: gatsby => gatsby-admin
i have a [basic blog setup]( that is nearly identical to [`gatsby-theme-blog-core`]( #readme)
after adding a new post (markdown file) to a folder which is being used to incrementally build pages (/content/posts), i need to manually edit a pagequery to reflect the changes
even after building the site, the new post won't show up
i recorded a short [screen capture describing the issue](
npm install found 5 high severity vulnerabilities
i'm developing a gatsby theme in typescript, which i'm transpiling to a commonjs module before publishing
one of its components uses the `usestaticquery` hook
however, this usage is not detected properly when the theme is added to another gatsby site, leading to "error: the result of this staticquery could not be fetched." i\'ve traced this down to this bit of `file-parser.js`: ```js
function isusestaticquery(path, file) { return path.node.callee.type === `memberexpression` && path.node.callee.property.name === `usestaticquery` && path.get(`callee`).get(`object`).referencesimport(`gatsby`) || path.node.callee.name === `usestaticquery` && path.get(`callee`).referencesimport(`gatsby`);
``` breaking the conditional as follows causes the check to work properly, so it's a problem with the second bit: ```js
function isusestaticquery(path, file) { // my file ends with single.js, so this was a quick hack to isolate my code if (file.endswith("single.js") && path.node.callee.type === "memberexpression" && path.node.callee.property.name === "usestaticquery") { return true; } return path.node.callee.type === `memberexpression` && path.node.callee.property.name === `usestaticquery` && path.get(`callee`).get(`object`).referencesimport(`gatsby`) || path.node.callee.name === `usestaticquery` && path.get(`callee`).referencesimport(`gatsby`);
``` here is the bit of my transpiled code that should trigger this check: ```js
exports.single = ({ children }) => { const data = gatsby_1.usestaticquery(gatsby_2.graphql ` query single { site { sitemetadata { title } } file(relativepath: { eq: "logo.png" }, sourceinstancename: { eq: "images" }) { childimagesharp { fixed(width: 48, height: 48) { base64 width height src srcset } } } } `);
``` note that if i manually trigger the static component context wrapper by adding a dummy static query in the main repository, everything works as expected
so the problem here is the static query usage detection
(note that my package does have `gatsby` in the name, as required.) as an aside, i'm not sure exactly what this search process is trying to accomplish
are the actual static queries being extracted and run for some reason, or is this just to determine that a static query is being used so that the correct context provider can be added? if it's the latter aybe not, but the fact that a dummy query then causes my theme to work is suspicious ouldn't it be simpler to just let packages mark that they use static queries somehow, maybe under a `gatsby` key in `package.json` and avoid this search which seems at least somewhat brittle? just a thought
alternatively, is there a way to add the appropriate static query context provider manually?
i have made a plugin for gatsby name `gatsby-source-hashnode-devblog` and it is listed in the plugins page but clicking on it gives a error
(
typescript typings got broken after upgrading gatsby from 2.22.12 to 2.22.13 probably related pr: .
the goal is to fetch 2,000+ wordpress posts using the gatsby-source-wordpress plugin from this website: [
unfortunately, only (at most) 100 posts are fetched
this issue is applicable for every resource from the wp api (media, comments, etc.)
one interesting fact is that once in a while (~1/30), everything works perfectly fine without me changing a single line of code
i already tried to increase the `per_page` value but the limit is 100 posts per page otherwise the api throws a `404`
when i set the `perpage` value in the `gatsby-config.js` to a value between 0 and 100, the plugin will fetch that exact number of resources
i know that the plugin is supposed to loop over every page in order to fetch all of the posts.
screen reader reads hidden navigation menu items that the user cannot interact with on mobile.
the imgstyle gatsby-image attribute is not reflected in noscript img.
here is the code, we can see the static styling : #l259 thank you for your help !
when using the [webp format]( the quality is degraded compared to a png or jpg format.
the source plugin does crash when a previously added rich text field was added and changed with the option `richtext.resolvefieldlocales` on true
this does only happen with a cache already in place
the error seems to be happening in the normalization step
more specific in the getentrywithfieldlocaleesresolved function
when a stale entry is detected no `entry.fields` or no `entry.sys.contenttype` is present.
when using `yarn@1.22` it has different shape of `yarn workspaces info --json` command than previous versions of yarn - because gatsby-dev-cli relies on this output when running it in workspaces - we need some error catching / sanitization
following setup instructions from various sources (e.g
[here]( `gatsby-source-prismic-graphql` throws the following error: ```sh
error: cannot find module './third-party/gatsby-node'
require stack:
- /users/mrseanbaines/projects/gatsby-prismic-blog/node_modules/gatsby-source-graphql-universal/gatsby-node.js
- /users/mrseanbaines/projects/gatsby-prismic-blog/node_modules/gatsby-source-prismic-graphql/gatsby-node.js
- /users/mrseanbaines/projects/gatsby-prismic-blog/node_modules/gatsby/dist/bootstrap/resolve-module-exports.js
- /users/mrseanbaines/projects/gatsby-prismic-blog/node_modules/gatsby/dist/bootstrap/load-plugins/validate.js
- /users/mrseanbaines/projects/gatsby-prismic-blog/node_modules/gatsby/dist/bootstrap/load-plugins/load.js
- /users/mrseanbaines/projects/gatsby-prismic-blog/node_modules/gatsby/dist/bootstrap/load-plugins/index.js
- /users/mrseanbaines/projects/gatsby-prismic-blog/node_modules/gatsby/dist/bootstrap/index.js
- /users/mrseanbaines/projects/gatsby-prismic-blog/node_modules/gatsby/dist/commands/develop.js
- /users/mrseanbaines/projects/gatsby-prismic-blog/node_modules/gatsby-cli/lib/create-cli.js
- /users/mrseanbaines/projects/gatsby-prismic-blog/node_modules/gatsby-cli/lib/index.js
- /users/mrseanbaines/projects/gatsby-prismic-blog/node_modules/gatsby/dist/bin/gatsby.js
when running any `gatsby` command, there's a missing modules error under the `yoga-layout-prebuilt` module.
after an update did using the command `npm update` and the gatsby updated from 2.21.17 to 2.22.12 no command did using `gatsby-cli` works anymore.
when `gatsby serve` conflicts it says it's serving on the wrong port
gatsby develop command fails immediately and displays error for yoga-layout and urql
not sure what caused this issue
i recently updated my gatsby site to the latest version using `yarn add gatsby@latest` to enable conditional page builds
it worked great, the dev and build processes worked fine
i reopened the project, added a new mdx post, spun up the dev server, and immediately started seeing this issue
i tried updating the rest of my dependencies but saw no improvement
i also tried clearing the `.cache` and `node_modules` and reinstalling dependencies multiple times -- i still see the same error
i think this might be related to and
i'm using node 13, which is a known issue?
when running develop, the console shows an error regarding missing package called `unified`
after installed latest gatsby-cli@2.12.35, then gatsby not working any more
here is the error - ```
/usr/local/lib/node_modules/gatsby-cli/node_modules/yoga-layout-prebuilt/yoga-layout/build/release/nbind.js:53 throw ex; ^ error: no valid exports main found for '/usr/local/lib/node_modules/gatsby-cli/node_modules/@urql/core' at resolveexportstarget (internal/modules/cjs/loader.js:625:9) at applyexports (internal/modules/cjs/loader.js:502:14) at resolveexports (internal/modules/cjs/loader.js:551:12) at function.module._findpath (internal/modules/cjs/loader.js:657:22) at function.module._resolvefilename (internal/modules/cjs/loader.js:960:27) at function.module._load (internal/modules/cjs/loader.js:855:27) at module.require (internal/modules/cjs/loader.js:1033:19) at require (internal/modules/cjs/helpers.js:72:18) at object.<anonymous> (/usr/local/lib/node_modules/gatsby-cli/node_modules/urql/dist/urql.js:1:12) at module._compile (internal/modules/cjs/loader.js:1144:30) { code: 'module_not_found'
if you create a gatsby-ssr.js like the following: ```js
import react from 'react';
export function wrappageelement({ props, element }) { throw new error('boom');
``` this does nothing
`wrappageelement` is never called
as mentioned in #4718, you can get around this with: ```js
import react from 'react';
export const wrappageelement = ({ props, element }) => { throw new error('boom');
``` and then you get the expected 'boom' error when you try to `gatsby build`.
sometimes we need to use apis of which not all asset urls contain the extension of the file type, this is something that gatsby is capable of handling because the [createremotefilenode]( #retrieving-the-remote-file-name-and-extension) will call the file-type npm package to infer file types when the extension is not in the url, nor in the [createremotefilenode options]( #retrieving-the-remote-file-name-and-extension)
this covers a lot of use-cases, but far from all
when we need to use an images endpoint for example, where some of the image file extensions are not part of the asset urls
on the first `gatsby build` or `gatsby develop` in a new environment this works fine, but in consecutive runs of the `gatsby develop` command, the system will try to look in its local cache whether the file node is still there
this step will fail given that the inferred file extension is not used to check whether said node exists, resulting in errors like this one: ```
unexpected error value: "failed to process
error: enoent: no such file or directory, stat \'.../.cache/gatsby-source-filesystem/7a1221ea4c61551f928908dd873a3738/30 \'"
``` but when you would go look, it could be that said file does exist as `30 .png` or `30 .jpg` implying that gatsby doesn't use the inferred extension to reuse the file node it created.
potential solutions could be to use a wildcard for the extension when the checking for a filenode fails or using the inferred file extension in looking for a locally created filenode by the createremotefilenode method.
on gatsby sites, navigating directly to a nonexistant page results in a `location` object with stale values
the location isn't rehydrated, and retains its values from build time
for instance, `location.pathname` will always read `404.html`
this is not an issue when clicking a bad internal link / using client-side routing
it only occurs on direct navigation.
buggy color character
i try to follow this tutorial, but i couldn't produce the same result as the tutorial my gatsbyjs repository
i upgraded `gatsby` and now i can't run `gatsby develop`
i am having issues with images not rendering in gatsby build
when i run the site in develop mode images seem to appear correctly
i use gatsby images in the following component: ```
import react from "react";
import img from 'gatsby-image';
import { usestaticquery, graphql} from 'gatsby';
import button from \'../button/button.component\'; import \'./gallery.styles.css\'; export default function galleryhomepage() { const data = usestaticquery(graphql` query myquery { # arthur_en_yvonne arthurenyvonne: file(relativepath: { eq: "gallery/arthur_en_yvonne/ceremony-7.jpg" }) { childimagesharp { # specify the image processing specifications right in the query
fluid { src srcset aspectratio base64 sizes } } } # end # maarten_en_heiline maartenenheiline: file(relativepath: { eq: "gallery/maarten_en_heiline/ceremony-28.jpg" }) { childimagesharp { # specify the image processing specifications right in the query
fluid { src srcset aspectratio base64 sizes } } } # end # manuel_en_marleen manuelenmarleen: file(relativepath: { eq: "gallery/manuel_en_marleen/ceremony-30.jpg" }) { childimagesharp { # specify the image processing specifications right in the query
fluid { src srcset aspectratio base64 sizes } } } # end # martijn_en_marscha martijnenmarscha: file(relativepath: { eq: "gallery/martijn_en_marscha/ceremony-40.jpg" }) { childimagesharp { # specify the image processing specifications right in the query
fluid { src srcset aspectratio base64 sizes } } } # end # mathijs_en_noortje mathijsennoortje: file(relativepath: { eq: "gallery/mathijs_en_noortje/ceremony-25.jpg" }) { childimagesharp { # specify the image processing specifications right in the query
fluid { src srcset aspectratio base64 sizes } } } # end # omer_en_ayse omerenayse: file(relativepath: { eq: "gallery/omer_en_ayse/ceremony-2.jpg" }) { childimagesharp { # specify the image processing specifications right in the query
fluid { src srcset aspectratio base64 sizes } } } } # end # end all queries `
) return ( <div class="site-section"> <div class="container"> <div class="row mb-5"> <div class="col-md-7 text-center mx-auto"> <h2 class="serif">trouwalbums</h2> </div> </div> <div class="row-gallery"> <div class="column-gallery"> <div> <div class="gallery-card-image-wrapper"> <img fluid={data.maartenenheiline.childimagesharp.fluid} alt=""/> <div class="description">maarten en heiline</div> </div> <div> <button cta="bekijk hele album" class="btn btn-light" ctalink="/portfolio/maarten-en-heiline"></button> </div> </div> </div> <div class="column-gallery"> <div> <div class="gallery-card-image-wrapper"> <img fluid={data.mathijsennoortje.childimagesharp.fluid} alt=""/> <div class="description">mathijs en noortje</div> </div> <div> <button cta="bekijk hele album" class="btn btn-light" ctalink="/portfolio/mathijs-en-noortje"></button> </div> </div> </div> <div class="column-gallery"> <div> <div class="gallery-card-image-wrapper"> <img fluid={data.omerenayse.childimagesharp.fluid} alt=""/> <div class="description">omery en ayse</div> </div> <div> <button cta="bekijk hele album" class="btn btn-light" ctalink="/portfolio/omer-en-ayse"></button> </div> </div> </div> </div> <div class="row-gallery"> <div class="column-gallery"> <div> <div class="gallery-card-image-wrapper"> <img fluid={data.arthurenyvonne.childimagesharp.fluid} alt=""/> <div class="description">arthur en yvonne</div> </div> <div> <button cta="bekijk hele album" class="btn btn-light" ctalink="/portfolio/arthur-en-yvonne"></button> </div> </div> </div> <div class="column-gallery"> <div> <div class="gallery-card-image-wrapper"> <img fluid={data.manuelenmarleen.childimagesharp.fluid} alt=""/> <div class="description">manuel en marleen</div> </div> <div> <button cta="bekijk hele album" class="btn btn-light" ctalink="/portfolio/manuel-en-marleen"></button> </div> </div> </div> <div class="column-gallery"> <div> <div class="gallery-card-image-wrapper"> <img fluid={data.martijnenmarscha.childimagesharp.fluid} alt=""/> <div class="description">martijn en marscha</div> </div> <div> <button cta="bekijk hele album" class="btn btn-light" ctalink="/portfolio/martijn-en-marscha"></button> </div> </div> </div> </div> </div> </div> )
i am writing my first gatsby-remark plugin and following the documentation it says > the first parameter is **_all_ of the default properties that can be used in plugins** (actions, store, getnodes, schema, etc.) plus a couple just for gatsby-transformer-remark plugins
the most relevant field for our purposes is the markdownast field which is destructured in the code snippet above
source: #setting-up-a-plugin because of this, i assumed i had access to `getnodesbytype` but it actually throws an error: ```
getnodesbytype is not a function
``` i think it was due to this recent fix by @johno (but it seems like it would have failed previously if someone tried using `getnodes` too)
`gatsby-source-contentful` returns empty `srcset` and `srcsetwebp` when querying `fixed` images with only `height` argument
these values are included when making the same query but passing in a `width` argument, and also included when passing a `height` argument if using `gatsby-plugin-sharp`
see screenshot for comparison: <img width="1552" alt="image" src=" ">
c:\\users\\clovi\\wordpress-jamstack>npm run develop error #10123 config
> gatsby-starter-hello-world@0.1.0 develop c:\\users\\clovi\\wordpress-jamstack
we encountered an error while trying to load your site's gatsby-config
please fix the error and try again
error: c:\\users\\clovi\\wordpress-jamstack\\gatsby-config.js:8 - /* your site config here */ ^ syntaxerror: unexpected token '-' - v8-compile-cache.js:226 nativecompilecache._modulecompile [wordpress-jamstack]/[v8-compile-cache]/v8-compile-cache.js:226:18 - v8-compile-cache.js:172 module._compile [wordpress-jamstack]/[v8-compile-cache]/v8-compile-cache.js:172:36 - loader.js:1153 object.module._extensions..js internal/modules/cjs/loader.js:1153:10 - loader.js:977 module.load internal/modules/cjs/loader.js:977:32 - loader.js:877 function.module._load internal/modules/cjs/loader.js:877:14 - loader.js:1019 module.require internal/modules/cjs/loader.js:1019:19 - v8-compile-cache.js:159 require [wordpress-jamstack]/[v8-compile-cache]/v8-compile-cache.js:159:20 - get-config-file.js:33 getconfigfile [wordpress-jamstack]/[gatsby]/dist/bootstrap/get-config-file.js:33:20 - index.js:130 module.exports [wordpress-jamstack]/[gatsby]/dist/bootstrap/index.js:130:46 - develop.js:439 module.exports [wordpress-jamstack]/[gatsby]/dist/commands/develop.js:439:36 - task_queues.js:97 processticksandrejections internal/process/task_queues.js:97:5 not finished open and validate gatsby-configs - 0.079s
npm err! code elifecycle
npm err! errno 1
npm err! gatsby-starter-hello-world@0.1.0 develop: `gatsby develop`
npm err! exit status 1
npm err! failed at the gatsby-starter-hello-world@0.1.0 develop script.
npm err! this is probably not a problem with npm
there is likely additional logging output above
npm err! a complete log of this run can be found in:
npm err! c:\\users\\clovi\\appdata\ oaming\ pm-cache\\_logs\\2020-05-23t09_02_07_530z-debug.log
in production, page rendering is partially wrong when using `usestate` with a default value that depends on `window`.
i have posted this question on the pm2 repository and had no response in two weeks
you can see it here
i am posting here becasue i can't tell if this is a gatsby issue or a pm2 issue
whats happening is pm2 will succesfully deploy and start the gatsby server but it will just keep killing it part way through the developmnent build
i need to do the development build
i can get it to work with gatsby develop manually when i navigate into the current folder which i think is what pm2 is running npm start from or the gatsby script itself i tried both
i am running on a ec2 instance
but i need to run this pm2 deploy so i can keep it running and push up updates
i don't want to use gatsby cloud, it's far to expensive for what i need to accomplish, these projects are small, but i want to have live editing through sanity right now.
in logic was added to re-evaluate page query when page context was changed
however, this doesn't work in all cases: sometimes pagecontext change and there's no way to retrigger a change this is the code that re-evaluates if page context have changed: #l475 but when we try to replace pages hooking into `createpage`, following this documentation #pass-context-to-pages with some logic like this one: ```
exports.oncreatepage = ({ page, actions }) => { const { createpage, deletepage } = actions if (page.data.replace) { deletepage(page) // you can access the variable "house" in your page queries now createpage({ ...page, context: { ...page.context, house: `gryffindor`, }, }) }
``` and when using gatsby develop, after hitting the `__refresh` data endpoint, if the conditions when the page gets replaced change, the `contextmodified` logic doesn\'t work, because after "deleting" the original page, the condition `const contextmodified = !!oldpage && !_.isequal(oldpage.context, internalpage.context)` evaluates to false (`oldpage` does not exist)..
can't debug `gatsby develop` in vs code
vs code v1.45.1
gatsby v2.22.4 using launch settings ```json
{ "version": "0.2.0", "configurations": [ { "name": "gatsby develop", "type": "node", "request": "launch", "protocol": "inspector", "program": "${workspaceroot}/node_modules/gatsby/dist/bin/gatsby", "args": ["develop"], "stoponentry": false, "runtimeargs": ["--nolazy"], "sourcemaps": true, } ]
``` if i downgrade gatsby to v2.21.37 it works perfectly
withing the debug terminal i can execute `.scripts` to check which files are loaded and there is no trace of `gatsby-node.js`
however, `gatsby-config.js` is and i can set bps in `gatsby-config.js` normally.
when i complete a local gatsby build it runs successfully
but if i push netlify and a new build is triggered i receive the following error in the netlify build console: **error there was a problem parsing the graphql query in file: /opt/build/repo/node_modules/gatsby-recipes/src/index.js** i'm not even knowingly using gatsby-recipes, how is this happening and why is it making it impossible to deploy to netlify?
using the newest version of `gatsby-plugin-styled-components@3.3.2` with `styled-components@5.1.0` (any `5.x` version) renders no css created with `createglobalstyles` to the `<head>`
it works only with javascript enabled
i upgraded from `styled-components@4.4.1` with the same plugin version and it stopped working.
when i try to use the `gatsby-remark-vscode` in the `gatsbyremarkplugins` field of the `gatsby-plugin-mdx` options, i get: ``` typeerror: cannot set property 'dirty' of undefined - inference-metadata.js:187 incrementalreducer [myproj]/[gatsby]/dist/redux/reducers/inference-metadata.js:187:27 - inference-metadata.js:55 module.exports [myproj]/[gatsby]/dist/redux/reducers/inference-metadata.js:55:25
``` this happens only if i have a code fence in my pages
everything is working smoothly with my cli but after bumping up my version to 2.12.31, my getting this error now
i tried downgrading to my previous version but still no luck.
when i installed the gatsby cli, i was unable to run it; it throws this exception in the command line: ![image]( this is only resolveable by globally installing `detect-port`, at which point everything is fine
perhaps a missing dependency that wasn't included?
in order to provide data consistency for consumers of `markdownremark` nodes and provide for a wider range of use cases, i would like to propose that this plugin populate its `fileabsolutepath` property regardless of the parent's type
[at this line]( #l57), the plugin does not populate `fileabsolutepath` unless the parent is a `file` type
an example scenario where this is a problem:
[my plugin `gatsby-plugin-json-remark`]( creates markdownremark nodes from markdown snippets contained in json files and in this use case, the `markdownremark` parent's type is `jsonremark`, not `file`
further down the lifecycle, `tinacms` consumes `markdownremark` nodes produced by `gatsby-plugin-json-remark` and expects the `fileabsolutepath` property to be present
[it fails]( #l37) because the value is not present
i think it would be ideal if this field is always populated as long as `absolutepath` property is present in the parent node
this would bring consistency for plugins that create `markdownremark` nodes outside the usual use case of source .md files
for reference, the issue opened by a user: [5](
i'm getting the following error after using the usestaticquery hook in a coffeescript file:
error: the result of this staticquery could not be fetched.
this is likely a bug in gatsby and if refreshing the page does not fix it, please open an issue in
``` ## code
```coffeescript import react from 'react'
import proptypes from 'prop-types'
import { helmet } from 'react-helmet'
import { usestaticquery, graphql } from \'gatsby\' export default seo = ({ title, description = \'\', lang = \'en\', meta = [] }) -> { site } = usestaticquery graphql" query { site { sitemetadata { title } } } " metadescription = description or site.sitemetadata.description <helmet htmlattributes={{ lang }} title={ title } titletemplate={ "%s | #{ site.sitemetadata.title }" } meta={ [ { name: \'description\', content: metadescription } { property: \'og:title\', content: title } { property: \'og:description\', content: metadescription } { property: \'og:type\', content: \'website\' } { name: \'twitter:card\', content: \'summary\' } { name: \'twitter:creator\', content: site.sitemetadata.author } { name: \'twitter:title\', content: title } { name: \'twitter:description\', content: metadescription } ].concat meta } /> ``` ## steps to reproduce
i'm simply using the gatsby-plugin-coffeescript plugin and trying to use the usestaticquery hook
## environment
system: os: macos 10.15.4 cpu: (8) x64 intel(r) core(tm) i7-7820hq cpu @ 2.90ghz shell: 5.7.1 - /bin/zsh binaries: node: 12.13.1 - ~/.nvm/versions/node/v12.13.1/bin/node yarn: 1.21.0 - ~/.nvm/versions/node/v12.13.1/bin/yarn npm: 6.12.1 - ~/.nvm/versions/node/v12.13.1/bin/npm languages: python: 2.7.16 - /usr/bin/python browsers: chrome: 81.0.4044.138 firefox: 76.0.1 safari: 13.1 npmglobalpackages: gatsby-cli: 2.12.24
after upgrade to 2.22.4, when using `npm run develop -- --https` to start the dev server, browser unable to open the page and show err_ssl_protocol_error
in our company we got gatsby files migrated to typescript (e.g
gatsby-config.ts)
after we are not able to start project.
when i use shortcodes for my components in mdx and the component is in the form of ```<nav.item as="li">hello</nav.item>``` a render error occurs
if i import the component directly in the mdx file everything works but with shortcodes no.
when i refresh my page, the logos all use the same preload image
it looks quite odd
![screen capture on 2020-05-20 at 11-52-51](
i'm trying to deploy project using vercel but getting this error
i'm using createpages function for each product from stripe and passing product to template where is error 'typeerror: cannot read property 'product' of undefined'
everything works as expected in dev mode but not in production
i follow the steps documented in [website contributions]( but after running `yarn develop` i get the following error: ![image](
i've noticed that the **query variable** field is reset every time i update a graphql query in the graphiql ide.
with `gatsby@2.22.0`, an error is now being generated on windows: ```sh
internal/modules/cjs/loader.js:985 throw err; ^ error: cannot find module 'd:devsourcegatsbygatsby-develop-repro
ode_modulesgatsbydistcommandsdevelop-process.js'
require stack:
- d:\\dev\\source\\gatsby\\gatsby-develop-repro\\.cache\\tmp-9704-ksknxyqxwyqp at function.module._resolvefilename (internal/modules/cjs/loader.js:982:15) at function.module._load (internal/modules/cjs/loader.js:864:27) at module.require (internal/modules/cjs/loader.js:1044:19) at require (internal/modules/cjs/helpers.js:77:18) at object.<anonymous> (d:\\dev\\source\\gatsby\\gatsby-develop-repro\\.cache\\tmp-9704-ksknxyqxwyqp:2:17) at module._compile (internal/modules/cjs/loader.js:1158:30) at object.module._extensions..js (internal/modules/cjs/loader.js:1178:10) at module.load (internal/modules/cjs/loader.js:1002:32) at function.module._load (internal/modules/cjs/loader.js:901:14) at function.executeuserentrypoint [as runmain] (internal/modules/run_main.js:74:12) { code: 'module_not_found', requirestack: [ 'd:\\\\dev\\\\source\\\\gatsby\\\\gatsby-develop-repro\\\\.cache\\\\tmp-9704-ksknxyqxwyqp' ]
``` the issue appears have been introduced by this new change (from #22759):
#l111-l119 the problem exists because `require("${developprocesspath}")` does not properly escape backslashes.
`gatsby develop` command is broken on windows now there are backslashes in `developprocesspath`, what should be properly escaped.
some hooks like `onrenderbody` expect to return `any`, when the documentation shows an example returning `void` (no return statement).
the logo page( is not working on mobile screen sizes, basically images are not showing up and scrolling feels like infinite scroll, the next section comes after scrolling a lot.
due to floating point precision error, or in some cases _carried_ floating point precision errors, the paddingbottom "don\'t re-layout" trick sometimes results in an image that\'s a pixel off in height
![image]( when displaying photos this isn't much of a problem, people won't notice, but displaying things like screenshots or graphics, that pixel difference can blur images noticeably
here's a difference map, it's just a 1px stretching, nothing amazing: ![difference]( instead of using: ```
const ratio = `${(1 / fluidresult.aspectratio) * 100}%`
``` we should probably use this? ```
const ratio = `${fluidresult.presentationheight / fluidresult.presentationwidth * 100}%`
``` in order to maintain precision? however in my reproduction i just happened to use an image where both versions produce incorrect final image heights, off by a pixel
it would probably be a breaking change to pass height and width to all the places where this trick is done, regardless? --- gatsby-image itself does this: ```
object-fit:cover;
object-position:center
``` **object fit cover**
> the replaced content is sized to maintain its aspect ratio while filling the element entire content box
if the object's aspect ratio does not match the aspect ratio of its box, then the object will be clipped to fit
this solves the visual blurriness problem, but the image is still off by a pixel in height, cut off
i think `object-fit:cover;` should be added to `gatsby-remark-image` at a minimum, and hopefully some discussion can happen regarding the pixel-off problem
at the end of the day, these images are supposed to be responsive, if pixel perfect matching is required, the `fixed` query should be used not `fluid`
that's fair enough
i can do prs for whatever we decide to do.
when using gatsby-cli@2.12.22 the `gatsby recipes` gives the error below:
/home/riley/.config/yarn/global/node_modules/yoga-layout-prebuilt/yoga-layout/build/release/nbind.js:53 throw ex; ^ error: error: gatsby recipes needs to be called with a specific recipe at /home/riley/.config/yarn/global/node_modules/gatsby-cli/lib/create-cli.js:308:15 at object.handler (/home/riley/.config/yarn/global/node_modules/gatsby-cli/lib/create-cli.js:35:19) at object.runcommand (/home/riley/.config/yarn/global/node_modules/yargs/lib/command.js:240:40) at object.parseargs [as _parseargs] (/home/riley/.config/yarn/global/node_modules/yargs/yargs.js:1154:41) at object.parse (/home/riley/.config/yarn/global/node_modules/yargs/yargs.js:627:25) at createcli (/home/riley/.config/yarn/global/node_modules/gatsby-cli/lib/create-cli.js:449:136) at object.<anonymous> (/home/riley/.config/yarn/global/node_modules/gatsby-cli/lib/index.js:153:26) at module._compile (internal/modules/cjs/loader.js:1133:30) at object.module._extensions..js (internal/modules/cjs/loader.js:1153:10) at module.load (internal/modules/cjs/loader.js:977:32) ``` `gatsby recipes emotion` produces no output, no effect
**this only occurs in gatsby-cli@2.12.22 in gatsby-cli@2.12.21 the recipes command works as expected**
i have gatsby project with pages created programmatically with `createpage` inside `createpages`
both dev and prod modes work good locally, but on the server, while typing direct link manually in the browser (like i've got redirect to the main page
nginx doesn't show any redirects, so i'm sure it's gatsby doing something :) i see no errors in the console of the browser and in my terminal while building this project.
when i have a proxy configured with gatsby during development and make a delete request with a request body, gatsby forwards the request but strips out the request body
(**edit** actually now i'm not so sure it actually forwards the request rather than hanging without forwarding)
i followed the steps on to create a gatsby pwa, and it worked in development using `gatsby build && gatsby serve` but in the netlify deploy preview the service worker fails to register, this is the error `the installing service worker became redundant.`
i am getting a error generating development javascript bundle failed, after installing react-big-calendar-like-google and moment.
the dropdown arrows on the gatsby docs point upwards to expand rather than downwards
am i crazy or should they point downward? ![image](
it looks like the `isexpanded` property imported at line 90 of `gatsby/www/src/components/sidebar/section-title.js` evaluates to either true if the dropdown is expanded and undefined if it is not
since a11y properties (`aria-expanded` at line 93) and probably other things depend on this, it should be initialized as false at the file where the property is originally defined.
i followed the entire set-up of parallel image processing via google cloud functions via
plugin description is not rendering the readme file properly, instead only _readme.md_ is visible.
running gatsby develop causes "the result of this staticquery could not be fetched"
i'm trying to use createnode after running a few fetch requests, but i'm finding that these nodes don't always get created
i've read a few other issues like [this one ]( and they mentioned to use promises which i've tried implementing but i still get issues.
should i be using the `oncreatenode` method instead of `sourcenodes`?
i super new to gatsby so please excuse my ignorance
### gatsby node code ```
const credcache = new map();
require('dotenv').config({ path: `.env.${process.env.node_env}`,
}); require('es6-promise').polyfill();
require('isomorphic-fetch'); const crypto = require('crypto');
const qs = require('qs'); exports.onpreinit = () => { return new promise(resolve => { fetch(process.env.token_uri, { method: 'post', headers: { 'content-type': 'application/x-www-form-urlencoded', }, body: qs.stringify({ grant_type: 'client_credentials', client_id: process.env.client_id, client_secret: process.env.client_secret, scope: 'squidex-api', }), }) .then(response => response.json()) .then(data => { credcache.set('token', `${data.token_type} ${data.access_token}`); resolve(); }); });
}; exports.sourcenodes = ({ actions }) => { const { createnode } = actions; // create nodes here, generally by downloading json // from a remote api
const token = credcache.get('token'); // get all the squidex schemas const getschemas = () => { return fetch(`${process.env.general_uri}`, { method: 'get', headers: { authorization: token, }, }) .then(result => result.json()) .then(json => json.items.map(item => item.name)); }; const getcontents = endpoints => { return promise.all( endpoints.map(endpoint => { return fetch(`${process.env.content_uri}${endpoint}`, { method: 'get', headers: { authorization: token, }, }).then(result => result.json()); }), ).then(result => { result.foreach(schemadata => { if (schemadata.items.length) { const name = `squidex-${schemadata.items[0].schemaname}`; const type = name.replace(/-/g, ''); schemadata.items.foreach(datum => { const { id, createdby, lastmodifiedby, data, ispending, created, lastmodified, status, version, children, parent } = datum; const internal = { type, contentdigest: crypto.createhash('md5').update(json.stringify(datum)).digest('hex'), }; const node = { id, createdby, lastmodifiedby, ispending, created, lastmodified, status, version, children, parent, internal, }; const keys = object.keys(data); keys.foreach(key => { node[key] = data[key].iv; }); createnode(node); }); } }); }); }; promise.resolve(getschemas()).then(schemas => getcontents(schemas));
`createschemacustomization` is not working as intended in `2.21.31` vs `2.21.19` is potentially related?
the gatsbyjs.org/creators/ site works as expected, but crashes when the user uses the tab "skip to main content button"
the broken link is: #reach-skip-nav
currently the bug shows up whenever i try to use the 'pathcontext' that's passed to the template props for a graphql query
specifically the id property inside the pathcontext
if i replace this with an ordinary string, it works
without it however, i see the bug
i notice once i change the favicon files in the static folder, the icons no longer work on mobile but still works on desktop
instead in mobile i just get a letter.
the href tag of the anchor tag was changed based on a state change in dev mode (gatsby develop)
when i switched to the production environment using gatsby build + gatsby server the href is no long affected i.e it stays the same no matter the change.
i am playing around with some childimagesharp queries for cropping my images, as i run into an error the following error: ```
> gatsby develop success open and validate gatsby-configs - 0.075s
success load plugins - 3.064s
warn the google analytics plugin requires a tracking id
did you mean to add it?
success onpreinit - 0.067s
info one or more of your plugins have changed since the last time you ran gatsby
a precaution, we're deleting your site's cache to ensure there's no stale data
error unhandled rejection processing /xxxxxxxxxx/src/images/people/jschulze_nah_72dpi.jpg failed original error:
expected number greater than zero for threshold but received true of type boolean workererror: processing /xxxxxxxxxx/src/images/people/jschulze_nah_72dpi.jpg failed original error: expected number greater than zero for threshold but received true of type boolean - jobs-manager.js:314 exports.enqueuejob [website]/[gatsby]/dist/utils/jobs-manager.js:314:23 ```
when using gatsby with `assetprefix` option and `gatsby-plugin-offline` i receive multiple corb errors while making pwa test in lighthouse (chrome version 81.0.4044.138)
![corb warnings](
gatsby-plugin-emotion adds styles inside body during build, but on rehidratation styles are moved to the header
when running gatsby build, it fails if cache is not deleted before running build.
error thrown in development when doing client side redirection using `redirect` component from `@reach/router`
typeerror: cannot read property 'innertext' of null
(anonymous function)
/sandbox/.cache/navigation.js:177 174 | pagename = pageheadings[0].textcontent 175 | } 176 | const newannouncement = `navigated to ${pagename}`
> 177 | const oldannouncement = this.announcementref.current.innertext 178 | if (oldannouncement !== newannouncement) { 179 | this.announcementref.current.innertext = newannouncement 180 | }
view compiled
i am trying to use `gatsby-plugin-typography` with a theme but the `pathtoconfigmodule` seems to searching in the site directory rather than the theme directory.
the manifest plugin rewrites the manifest href with assetsprefix.
i'm building themes, and if i shadow a pagequery, it works, but i have these warnings on build
as the only reason to shadow a pagequery is to have new elements to a fragment, it would be super useful to be able to shadow directly fragments
i tried, but it breaks as gatsby sees 2 fragments with the same name....
have a portfolio site with contentful + gatsby
i'm trying to replace regular img's with gatsby-image's fluid img
i have succesfully done this on my index.js landing page with a query that looks like this:
``` const data = usestaticquery(graphql` query { allcontentfulwork(sort: { fields: publisheddate, order: desc }) { edges { node { title slug tags featured publisheddate(formatstring: "yyyy") heroimage { fluid(maxwidth: 1800) { ...gatsbycontentfulfluid } title file { url contenttype } } } } } } `)
``` however, when i add that fluid query in gatsby-node.js, where i generate tag pages from a template using createpages, it breaks the build: > "gatsby-node.js" threw an error while running the createpages lifecycle:
> cannot read property 'allcontentfulwork' of undefined my gatsby-node.js file looks like this: ```
const path = require("path") removespaces = word => { return word.replace(/ /g, "")
} const createtagpages = (createpage, posts) => { const tagtemplate = path.resolve("./src/templates/tagged.js") const alltagtemplate = path.resolve("./src/templates/alltags.js") const postsbytags = {} posts.foreach(({ node }) => { const splittags = node.tags.split(",").map(t => t.trim()) //split tags is an array of strings of tags for each post [\'illustration\', \'motion\'] if (node.tags) { splittags.foreach(tag => { if (!postsbytags[tag]) { postsbytags[tag] = [] } //postsbytags[tag] is all the post objects with that tag postsbytags[tag].push(node) }) } }) const tags = object.keys(postsbytags) createpage({ path: `/tags`, component: alltagtemplate, context: { tags: tags.sort(), }, }) //create each tag page tags.foreach(tagname => { const posts = postsbytags[tagname] createpage({ path: `/${tagname.replace(/ /g, "")}`, component: tagtemplate, context: { posts, tagname, }, }) })
} module.exports.createpages = async ({ graphql, actions }) => { const { createpage } = actions const res = await graphql(` query { allcontentfulwork(sort: { fields: publisheddate, order: desc }) { edges { node { slug tags title heroimage { title file { url contenttype } } } } } } `) const posts = res.data.allcontentfulwork.edges
``` so in heroimage up there, right below it in gatsby-node.js, when i add
fluid(maxwidth: 1800) { ...gatsbycontentfulfluid }
i am getting a node package icompability error for gatsby-plugin-google-analytics on gatsby cloud preview install
it runs locally, but i can't figure out why it stalls at this plugin
i tried to customize a plugin so i cloned and then i run gatsby: i get this: error: unable to find plugin "gatsby-remark-table-of-contents"
perhaps you need to install its package?
querying for `timetoread` on `mdx` nodes recently started throwing in `gatsby develop` > gatsby-plugin-mdx: error querying the `html` field.
> this field is intended for use with rss feed generation.
> if you're trying to use it in application-level code, try querying for `mdx.body` instead.
> original error:
> error: rendermdxbody was unavailable when rendering html maybe there's been a regression here?
i'm working for a company which uses gatsby for building multilanguage website
for both seo reasons and aesthetics, we just don't want to see a trailing slash on the homepage, which in our case is the root of the prefixpath
www.mydomain.com/english
```` would always become ```
www.mydomain.com/english/
```` i know that `gatsby build --prefix-paths` and `gatsby serve` will cause an express 301, just to be clear, i'm *not* refering to that, i see gatsby serve as a devtool and don't care about a slash there
we use nginx to redirect trailing slash to urls without trailing slashes, but gatsby (or reach router, not sure) will still append a trailing slash, as you can see in my reproducible example here:
when including an object property in `<mdxrenderer>` like this:
const testing = { name: 'paul' }
<mdxrenderer testing={testing}>{post.body}</mdxrenderer>
and referencing it in a *.mdx file like this: `<pre>{props.testing.name}</pre>` `gatsby develop` renders this correctly (the string `paul` is displayed on the page) but running `gatsby build` results in an error: ```
gatsby-plugin-mdx
typeerror: cannot read property 'name' of undefined at mdxcontent (eval at _construct (evalmachine.<anonymous>:1624:584), <anonymous>:31:38)
i'm using anchor links like `/help#faqs`, but the page is not scrolled to the specified id on the initial load - `shouldupdatescroll` is not called
if the website was loaded - clicking the link works as expected and page scrolls
one possible solution is to add `componentdidmount` to and call `this.scrollbehavior.updatescroll` but it is not clear what to use for `prevrouterprops`
i just installed node.js and npm in this new system (windows 8.1 x64) and when i try to create and develop a new gatsby project i get `error: cannot find module 'array-reduce'`
i've tried deleting node_modules and doing npm install.
trying to build www package but getting errors.
when rendering content through `gatsby-plugin-mdx` with the `gatsby-remark-images-contentful` plugin, i am seeing the same image being rendered for all images in the content instead of different ones
i have narrowed this down to the image assets in contentful images having the same file name (`image.png` in my case)
this results in the `cachekey` generated by the plugin to be the same for all images served from contentful with that filename, even if they are separate assets with unique id's in contentful
this seems like it's a bug, as contentful and gatsby are separate and the former is often maintained by editors not knowing that having two image assets with the same file name might cause issues for the website
nor should they need to care, or am i not
i am getting the following error: `error: the result of this staticquery could not be fetched.`
i am trying to setup a gatsby dev server on heroku, everything is working according to the console, the page loads at first because i have a password setup, and once that component goes away and the site loads and tries to do it's first query this error happens
all working locally, and on gatsby cloud
the reason i am doing this is becasue gatsby cloud says i'm reaching my free limits, and i can't afford the $100 a month for more live edits
it's a pretty basic site.
upgrading from v1.2.1 to v1.2.4 now causes a number of errors: ```sh
warn query takes too long:
file path: /users/petermouland/dev/clearscore/global-website.ssg/src/templates/learn-articles.js
url path: /webview/learn/managing-money/balance-transfer-card-or-personal-loan-which-is-best-for-you
context: { "slug": "/learn/managing-money/balance-transfer-card-or-personal-loan-which-is-best-for-you", "locale": "en-gb", "market": "gb", "herofilename": "20fa1d677b40338c7e351b860282bf61-heroimage", "authorfilename": "8bf973f2a45212f8faa95f6be8563b6a-authorimage", "iswebview": true
error parsing bundle asset "/users/petermouland/dev/clearscore/global-website.ssg/public/0.output.js": no such file
error parsing bundle asset "/users/petermouland/dev/clearscore/global-website.ssg/public/1.output.js": no such file
error parsing bundle asset "/users/petermouland/dev/clearscore/global-website.ssg/public/output.js": no such file ``` ``` error gatsby-plugin-mdx: error querying the `html` field
this field is intended for use with rss feed generation
if you're trying to use it in application-level code, try querying for `mdx.body` instead
original error: error: rendermdxbody was unavailable when rendering html
``` ``` error gatsby-plugin-mdx
referenceerror: window is not defined at evalmachine.<anonymous>:1:1 at script.runincontext (vm.js:127:20) at script.runinnewcontext (vm.js:133:17) at module.exports (/users/petermouland/dev/clearscore/global-website.ssg/node_modules/eval/eval.js:73:12) at afteremit (/users/petermouland/dev/clearscore/global-website.ssg/node_modules/gatsby-plugin-mdx/utils/render-html.js:81:22) at asyncserieshook.eval [as callasync] (eval at create (/users/petermouland/dev/clearscore/global-website.ssg/node_modules/tapable/lib/hookcodefactory.js:33:10), <anonymous>:20:1) at asyncserieshook.lazycompilehook (/users/petermouland/dev/clearscore/global-website.ssg/node_modules/tapable/lib/hook.js:154:20) at /users/petermouland/dev/clearscore/global-website.ssg/node_modules/webpack/lib/compiler.js:482:27 at /users/petermouland/dev/clearscore/global-website.ssg/node_modules/neo-async/async.js:2818:7 at done (/users/petermouland/dev/clearscore/global-website.ssg/node_modules/neo-async/async.js:3522:9) ``` _reverting back to v1.2.1 fixes these errors_
i'm following the official gatsby tutorial [here](
replacing the contents of /srs/pages/index.js with: import react from "react"
export default function home() ( <div style={{ color: `purple`, fontsize: `72px` }}>hello gatsby!</div>
) ...causes the build to fail
i am given this error: error #98123 webpack
generating development javascript bundle failed
e:\\gatsby-starter-hello-world\\src\\pages\\index.js: unexpected token, expected "{" (2:31) 1 | import react from "react"
> 2 | export default function home() ( | ^ 3 | <div style={{ color: `purple`, fontsize: `72px` }}>hello gatsby!</div> 4 | )
file: src\\pages\\index.js:2:31
failed re-building development bundle - 0.094s
the pr added the ability to shadow queries that e.g
are used in createpage calls
but this [comment]( #issuecomment-588442955) (and i was able to reproduce it) showed a flaw: > i hit an edge case
create a site from `@lekoarts/gatsby-theme-minimal-blog` and attempt to shadow the `template/homepage-query.tsx` with a local `src/@lekoarts/gatsby-theme-minimal-blog-core/templates/homepage-query.js`
it won't shadow over the in-theme file
rename it with the same extension...it works
> the documents for `createpage` tells you to use an absolute path to the component
so, the theme author didn't do anything wrong
(per docs) the component will always have an extension, so the algorithm resolving the shadowed component will not allow extension overriding
:( it also shows a false warning: ```shell
warn the graphql query in the non-page component "/mnt/c/users/lennart/development/playground/minimal-blog-additional-field/node_modules/@lekoarts/gatsby-theme-minimal-blog-core/src/templates/page-query.tsx" will exported queries are only executed for page components
it's possible you're
trying to create pages in your gatsby-node.js and that's failing for some
when adding to gatsby-browser.js file `oncliententry` api to add intersectionobserver polyfill just like that (with async/await syntax):
export const oncliententry = async () => { if (typeof intersectionobserver === `undefined`) { await import(`intersection-observer`); }
``` it causes a resolve error in yarn 2:
```bash error #98123 webpack generating development javascript bundle failed your application tried to access regenerator-runtime, but it isn't declared in your dependencies; this makes the require call ambiguous and unsound
required package: regenerator-runtime (via "regenerator-runtime/runtime")
required by: /$home/my-default-starter/gatsby-browser.js file: gatsby-browser.js
but when you using promise based syntax - everything is okay:
export const oncliententry = () => { if (typeof intersectionobserver === 'undefined') { return import('intersection-observer'); } return promise.resolve();
``` as yarn 2 documentation [says]( #a-package-is-trying-to-access-another-package-) - it happens when you importing some dependency that is not declared in `package.json` file.
when trying to configure gatsby local development to use the preview api key i'm receiving rate limiting errors from contentful indefinitely
my current website is built with gatsby and netlify-cms
netlify cms is internally using
which in turn uses create-react-context
when i try to access the cms admin it breaks with this error: ```
managercontext.js:5 uncaught typeerror: createreactcontext is not a function at object../node_modules/react-aria-menubutton/dist/managercontext.js (managercontext.js:5) at __webpack_require__ (bootstrap:725) at fn (bootstrap:100) at object../node_modules/react-aria-menubutton/dist/wrapper.js (wrapper.js:12) at __webpack_require__ (bootstrap:725) at fn (bootstrap:100) at object../node_modules/react-aria-menubutton/dist/index.js (index.js:6) at __webpack_require__ (bootstrap:725) at fn (bootstrap:100) at object../node_modules/netlify-cms-ui-default/dist/esm/dropdown.js (dropdown.js:22) ``` at first i thought it was an issue with react-aria-menubutton but as it turns out whats happening is that when i start the app (gatsby develop) a file is added to the cache folder: .cache/create-react-context.js ```javascript
import react from "react" export default react.createcontext
``` this causes the error above as react-aria-menubutton doesnt add .default to the require.
after updating to gatsby version `>=2.21.3`, `gatsby develop` throws many errors of type `error #85923 graphql`: there was an error in your graphql query during step "extract queries from components"
interestingly, `gatbsy build` works as expected.
i am sourcing data to gatsby using gatsby-source-drupal plugin with authentication:
``` { resolve: 'gatsby-source-drupal', options: { baseurl: process.env.drupal_api_baseurl, preview: true, basicauth: { username: 'admin', password: 'password', }, } },
``` the sourcing of the data works but the remote images are not downloaded correctly
(the images are not local on the drupal site but stored on s3 using the drupal module s3fs)
when i remove the 'basicauth' part and connect as an anonymous user it works fine.
recently a node buffer crash has started occurring, this did not start after a specific gatsby update, and changing the gatsby version does not appear to fix it
this appears to be similar to some previous issues, however those were fixed by lowering the buffer size of the cache when passed to v8.serialize ```
success run queries - 312.371s - 14100/14100 45.14/s
/users/matthewmiller/.npm/bin/node[65919]: ../src/node_buffer.cc:455:maybelocal<v8::object> node::buffer::new(node::environment *, char *, size_t, bool): assertion `length <= kmaxlength' failed
1: node::abort() (.cold.1) [/users/matthewmiller/.npm/bin/node] 2: node::fatalerror(char const*, char const*) [/users/matthewmiller/.npm/bin/node] 3: node::appendexceptionline(node::environment*, v8::local<v8::value>, v8::local<v8::message>, node::errorhandlingmode) [/users/matthewmiller/.npm/bin/node] 4: node::buffer::new(node::environment*, char*, unsigned long, bool) [/users/matthewmiller/.npm/bin/node] 5: node::(anonymous namespace)::serializercontext::releasebuffer(v8::functioncallbackinfo<v8::value> const&) [/users/matthewmiller/.npm/bin/node] 6: builtins_callapicallback [/users/matthewmiller/.npm/bin/node] 7: error command failed with signal "sigabrt".
``` related issues:
it's worth noting that unlike the prior issue that has 100k+ pages, we only have 14k
during gatsby develop for local dev and gatsby build on netlify for production/live site path: /wp-json/yoast/v1/indexation/posts?per_page=100&page=1
the server response was "404 not found"
inner exception message: "no route was found matching the url and request method"
hi, i having issues with page templates not hot reloading
i have them wrapped with a layout component in *gatsby-browser.js*
the layout component updates just fine, but pages don
i tried wrapping my template files with `react.memo` idn work.
a recent change to gatsby-plugin-mdx adds html generation to the `timetoread` slug, which i believe is causing pretty severe issues with increasing build time (potentially causing oom issues in some environments)
i'd recommend we revert #19763 as we most likely won't want to render all mdx posts to html to get time to read.
i'm using styled components (and the gatsby plugin for it) but i can confirm this is an issue with css modules as well
hot reloading of css works great when you are editing a component on a page
however if you use the wrappageelement or wraprootelement api in `gatsby-browser.js` and have a styled component that lives in that layout, it's reloads the whole page - losing at state you might have
export function wrappageelement({ element, props }) { return <layout {...props}>{element}</layout>;
``` so for example, if i have a layout component: ```js
export default function layout({ children }) { return ( <> <div> <nav></nav> {children} </div> </> );
``` and then either in layout.js directry, or inside of another component - like nav - i have my styled component: ```js
const navstyles = styled.nav` background: green;
``` now if i change `green` to `blue`
the whole page reloads
if i were to move that nav component out of `layout.js` and into a page like `pages/index.js`, it hot reloads fine without reloading the page.
i\'m trying to run my project, but whatever i try i keep getting to error "source and destination must not be the same"
because there is no clear destination of the error either, i'm not able to find the issue and solve it.
i'm trying to importing header.js to index greyed out and white black page death.
this is the repo
one of the featured sites on the website ([gm capital one]( is actually built with angular.
`loader.ispagenotfound()` reports false positive if `page` variable is undefined in the return statement
this appears to be caused by a path name containing url encoded slashes and perhaps other characters that somehow tricks the function into returning true when it should not
this results in a flashing 404 page before throwing an error for unknown paths containing urlencoded slashes.
i'm currently developing a simple site using prismic, gatsby and netlify
when i use `gatsby develop` everything works and looks just like i would expect
however, after netlify builds, all of the `gatsby-images` do not work
technically, the gatsby-image-wrapper is there in the dom and the `img` that's used for the blur-up is there too
what's missing is the `picture` element
in my console i am seeing this error: `typeerror: cannot read property 'childimagesharp' of undefined` when i inspect a log of the object in the console, i can drill down and see that the image is in the static file
`object => node => splash_imagesharp => fluid` if i copy the `src` and tack it onto the end of my url i can see the image.
this is a more generalizable instance of the problem i mentioned in
in short, i create a graphql node that i can see in the graphiql ide but returns null on my page
am i creating the node in the wrong way, maybe not using async correctly in the plugin?
when using `gatsby-plugin-preact` on a project, hydration stops working and the whole website is re-rendered when js kicks in.
i created a blog stater project and add `assetprefix` to `gatsby-config.js`, but it generates a wired url for gif in markdown file when building.
when i run `gatsby build` or `npm install` i get the error `error: 856328897 typeerror: promise.finally is not a function`
i was able to fetch content until i changed the display name of the content model on contentful
looks like all graphql elements are bound to the display name (red) and not the api name (green) ![image](
the mdx plugin is using assetprefix rather than pathprefix to prefix local links
this caused incorrect `href` values to be created.
my gatsby site functions as expected for both browser and mobile views when i am in development mode
(`gatsby develop`)
however, once deploying to heroku and building the static site, css appears to not load when viewed from mobile devices (or chromes mobile view in dev tools)
its almost as if it doesn't get injected
i can inspect the elements to see the class names are there and the same, but no css gets injected and all my components lose their styling
i rely heavily on material-ui's `makestyles()` function to style my components
i find it so much easier to work with than separate css files.
not sure if this could be causing the issue
note: i have tried pretty much all permutations of `gatsby-plugin-material-ui`, `gatsby-theme-material-ui` and `gatsby-styled-components` in my `gatsby-config.json` file
also, considering the issue is there when i build and serve locally..
i can ignore heroku/the environment as a probable cause.
gatsby-image causes safari (both ios and macos) to request the same image 4 times
to be sure that this isn't something specific to my browser and machine i also tested this in an ios simulator for ios safari, on macos mojave with the latest safari and also on a clean macos catalina safari via browserstack
they all behave the same way: the same image is requested and downloaded 4 times
chromium-based browsers don't seem to have issues here
interestingly though in firefox there is similar but indeterministic behavior: in firefox (75, macos 10.15.4) the same image sometimes is requested 2 times and sometimes only once
this erratic behavior in firefox led me to believe that this might be some sort of race condition, but i couldn't find the culprit.
``` error #98123 webpack generating ssr bundle failed can't resolve 'react-dom' in '[...]/node_modules/@tippyjs/react/dist'
i run into an infinite loop if the `mdxprovider` provides a new definition of `h1` that depends on `h1`, for example: ```jsx
const myh1 = props => <h1 style={{ color: "tomato" }} {...props} />
``` it works as expected if i change the `h1` to an `h2`, for example.
when sharing links of the final built website, sharing links with whatsapp should show up preview of `og:image` or `icon` specified in `<meta>` produced by react helmet
however, i noticed that even with _correct_ `og:image` and `icons` specified, link preview does not show up in whatsapp
this actually happened due to inlined style, where link preview on whatsapp:
- *not shown*: all site css all inlined (~74kb including bootstrap etc) before meta tags
- *shown* without inlined css
- *shown* with the large `<style>` element placed _below_ meta tags
related to #12011, but with contentful
it was fine until i add more content on contentful.
contenttypes fetched 15
updated entries 1594
updated assets 2562
tried `graceful-fs` and `fs-extra` with no luck
note, the reason of using lower version of `gatsby-source-contentful` is related to #22792.
unable to create custom query on 3rd party schema sourced through gatsby-source-graphql
unable to extend 3rd party schemas sourced through gatsby-source-graphql.
build fail when **gatsby-transformer-remark** is upgraded _(from either 2.6.59 or 2.7.3)_ to **2.7.4** *(issue may be related to 82c05aa)*
ckeditor is working fine in develop mode, but when i try to build i get the error: webpackerror: referenceerror: window is not defined
when `gatsby-source-contentful` is [configured to work with the preview api]( #using-preview-api), this plugin does not delete gatsby nodes when entries are deleted from contentful
module.exports = { plugins: [ { resolve: `gatsby-source-contentful`, options: { spaceid: `...`, accesstoken: process.env.contentful_access_token, host: `preview.contentful.com`, }, }, ],
after talking to @askgatsby -ms which recommended that i should report a bug.
i wanted to use a .tif image with gatsby image and the "gatsby develop" command kept failing
i uploaded a gist.
my gatsby site works without issues when i run it with `gatsby develop`
however, the static version i deployed (made with `gatsby build`) does not render the markdown content correctly
there are no errors or warnings when running the build command, and no errors in the browser console
upon inspection of browser requests, it looks like the markdown content is present when the static page is fetched and is then being removed after the page renders fully
screenshots below.
i get this error when running `gatsby develop` or `gatsby build`
there are few entries which are present in docs/starters.yml does not show up in www.gatsbyjs.org/starters
as on 22 april, 2019
total starters in starters.yml is 413
total starters shown on main site is 395 (all starters, no filters)
gatsby v2 is reporting that the `sizebypixeldensity` option is deprecated (spamming our `gatsby develop` mode quite heavily in fact)
specifically [gatsby-plugin-sharp]( documents this as a deprecated config option, but [gatsby-remark-images]( doesn't
also the deprecation reason in `gatsby-plugin-sharp` is wrong
this feature does work fine for jpeg and png files in gatsby v1, but it is broken in gatsby v2
we are in fact using this extensively for
looking through some tickets that were opened around this topic, it seems this is the result of a lot of confusion
most specifically as a result of which was made
especially the deprecation commit removes a test which proves that it can work
as far as i can tell (as the original author of this feature as part of gatsby v1): a) the feature works as proven by the test and our own heavy usage in gatsby v1
b) the feature was broken as part of gatsby v2
b) there is demand for this feature as shown by at least one more [bug ticket asking for such a capability](
c) pixel density is not a simple topic and there is a lot of confusion around this
possibly needing more examples? additional test cases might have helped as well to avoid the breakage with gatsby v2.
this was originally reported as [issue #25 for gatsby-plugin-netlify-cache]( but the root cause is a breaking change in the gatsby jobs api
with the introduction of api v2, gatsby-transformer-sharp how uses completed jobs stored in redux, rather than existing output filenames to determine whether or not to reprocess an image
unfortunately, due to how plugins are called, by the time the caching plugin's `onpreinit()` function is called, the redux store has already been created and the cached version is not used
to fix this, we either need an api that allows the caching plugin to import the cached redux files or we need a way to run a plugin function _before_ the redux store is created
the only other option is to return to using hashed output filenames to determine whether to process files, which would require code to be created in each plugin that uses the jobs api v2..
please note: this is **breaking** builds on netlify and the only solutions currently require reverting gatsby and/or gatsby-transformer-sharp.
i'm getting this error on `gatsby develop` or `gatsby build`, in what is afaict an identically set up ubuntu 18 environment, with the only difference being that the error occurs on aws lightsail, but not locally
i used `npm ci` to make sure i install the same package versions - here's [package-lock.json](
> error #98123 webpack
> generating ssr bundle failed
> [babel] /home/dandv/website/.cache/develop-static-entry.js: unknown version 4 of samsung (while processing: "/home/dandv/website/node_modules/@babel/preset-env/lib/index.js")
> file: .cache/develop-static-entry.js searching for the error shows it occurring [with parcel too](
hopefully someone has a clue as to what the culprit is (browserlist?) and how to fix it.
i'm received error with **gatsby develop**
it's very similar to this one: but i'm received error with gatsby develop, not with gatsby build
i did a lot of research but i can't find working solution
at first i had a problem with **gatsby build**, like in this post: but i resolved it with custom oncreatewebpackconfig(you can find it below)
i tried also that: but with negative results
stack: - gatsby - firebase(error probably with that) - redux i'm also delete .cache and node_modules and install everything again, but it didn't work.
the following message prints out several times when running tests on `www`: ```
error: not implemented: navigation (except hash changes) at module.exports (/users/tesseralis/code/gatsby/www/node_modules/jsdom/lib/jsdom/browser/not-implemented.js:9:17) at navigatefetch (/users/tesseralis/code/gatsby/www/node_modules/jsdom/lib/jsdom/living/window/navigation.js:77:3) at exports.navigate (/users/tesseralis/code/gatsby/www/node_modules/jsdom/lib/jsdom/living/window/navigation.js:55:3) at timeout._ontimeout (/users/tesseralis/code/gatsby/www/node_modules/jsdom/lib/jsdom/living/nodes/htmlhyperlinkelementutils-impl.js:81:7) at listontimeout (internal/timers.js:549:17) at processtimers (internal/timers.js:492:7) undefined
``` the tests still pass, but this pollutes the logs and makes it hard to differentiate between actual errors
### context this seems to be [an issue with jsdom]( as it doesn't implement navigation
there are several solutions proposed in the thread, but since (i'm assuming) the cause of the error is gatsby's link (which is a rapper on reach router), i'm not sure the best way to fix it
`yarn test`
having a pretty weird issue
my gatsby app used to run just fine
today i updated to v2.20.26 using yarn as usual
from that point on, running any command, like `gatsby develop` returned me this error: ``` error there was a problem loading the local develop command
gatsby may not be installed
perhaps you need to run "npm install"? cannot find module \'date-fns/getdayofyear\'
``` i tried `gatsby clean` , `rm -rf node_modules`, even rolling back to a previously working app..
always triggering that error
then i tried `npm install` and that's working
so, after a couple of tests, i noticed that if i clean `node_modules` and use `npm install`, everything works
with `yarn install` it doesn't
tried also removing `package-lock.json` and `yarn.lock`
nothing seems to help yarn
if i install via npm and then run any command with yarn, it will work just fine
so apparently there's an issue with yarn install
i'm running yarn v1.22.4 and always worked fine till today
i tried comparing the contents of the `node_modules` directory using both package managers (with no lock files) and they actually differ.
when using the provided `pageprops` type for my gatsby page, i cannot type the location state: it is forced to be `{}`.
according to this code [www/src/pages/index.js]( #l175) and this code [www/src/views/starter-library/starter-list.js]( #l219) and from my previous browsing history, the starters list is sorted by stars on initial load
right now the starters list doesn't seem to respect that sort parameter
possibly bug introduced post this pr getting merged -
using a commit before this pr merge seems to work as expected.
i\'m trying to run gatsby, returns me "bash: gatsby: command not found"
tried reinstall of node , npm , gatsby-cli also
it was working good a day ago, suddenly came into this problem.
i tried changing permission to allow in node folder as well
tried almost all internet solutions.
please help
linear-gradient doesn't work with background-image plugin after implementing my sass styling
i am speaking on behalf of amcharts
our users have found some errors when using amcharts with gatsby
you can see more details [here](
our library internally uses `canvg`, which uses `core-js`
when compiling, gatsby is unable to find the `core-js` files, even though those files exist
this is a problem specifically with gatsby, it does not happen with create-react-app or angular.
after typing `gatsby recipes` i've got the error `cannot find module 'cors'`.
the project works perfectly fine in the development but after building and serving the project, the content of some pages is wrapped by a 'gatsby-announcer' div which has a 'position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0' style and therefore the content basically becomes hidden
the problem is that the page loads, i can see it flicker for a split second but very quickly disappears so i'm guessing it has something to do with some gatsby script.
i hope this is my doing something wrong but i really can't figure it out
i'm trying to use [`defaultlayouts`]( #default-layouts) for mdx and they're not being applied
exporting a layout directly in the mdx file is working fine
here is the lines in `gatsby-config`: #l44-l51 and here is the layout: #l1-l5 i added a layout directly to one of the mdx files to confirm that part was working
i added an example to [this repo]( and it's on netlify
[this page]( has no layout set even though `defaultlayouts` is set
[this page]( is using the layout, but it's being imported/exported directly in the mdx file.
neither gatsby-transformer-csv nor gatsby-transformer-json honor schema customization
also, there is inconsistent inference of fields for these 2 transformers
![gatsby-csv-issue](
gatsby build and gatsby develop both throw the error above.
when running `gatsby recipes` i get the following:
``` www % gatsby recipes
/users/john/.nvm/versions/node/v13.5.0/lib/node_modules/gatsby-cli/node_modules/yoga-layout-prebuilt/yoga-layout/build/release/nbind.js:53 throw ex; ^ error: no valid exports main found for '/users/john/node_modules/@urql/core' at resolveexportstarget (internal/modules/cjs/loader.js:622:9) at applyexports (internal/modules/cjs/loader.js:499:14) at resolveexports (internal/modules/cjs/loader.js:548:12) at function.module._findpath (internal/modules/cjs/loader.js:654:22) at function.module._resolvefilename (internal/modules/cjs/loader.js:953:27) at function.module._load (internal/modules/cjs/loader.js:859:27) at module.require (internal/modules/cjs/loader.js:1028:19) at require (internal/modules/cjs/helpers.js:72:18) at object.<anonymous> (/users/john/node_modules/urql/dist/urql.js:1:12) at module._compile (internal/modules/cjs/loader.js:1139:30) { code: 'module_not_found'
the page "converting a starter to a theme" has a section on [sourcing pages]( #sourcing-pages)
this is no longer relevant as it is built into gatsby core with this pr #16698
when using `mdxrenderer` from `gatsby-plugin-mdx`, firefox throws a warning in firefox, both in develop and production
import react from 'react';
import { graphql } from 'gatsby';
import mdxrenderer from 'gatsby-plugin-mdx/mdx-renderer'; export default function post({ data: { mdx } }) { return <mdxrenderer>{mdx.body}</mdxrenderer>;
} export const pagequery = graphql` query($id: string!) { mdx(fields: { id: { eq: $id } }) { body } }
`; ``` this results in the following warning in firefox console: ```
unreachable code after return statement
when i'm trying to query the data from nested reference field while hitting the url of the page which is dynamically created through create pages it shows awkward behaviour
sometime it query properly but sometime it doesn't work
`couponcards: allcontentfulcouponcard( filter: { storereference: { category: { eq: $categorytitle } } } ) { edges { node { discount coupontype discountdescription totalhits sitewide verified cardlogo { fluid(maxwidth: 400) { src } } details { details { details minimumorder exclusion } } storereference { slug } verified sitewide createdat id expirydate } } }` this code sometime works but it sometime fails to deliver the right result even though i have the
same field for both category title and category in the store reference.
graphql usestaticquery returns a different object when in production vs my development enviornment
heres a picture of usestaticquery generating the correct results (in development <img width="1410" alt="screen shot 2020-04-15 at 6 17 40 pm" src=" ">
) and heres a screenshot of the same query but in production
<img width="1432" alt="screen shot 2020-04-15 at 6 17 07 pm" src=" ">
when adding wpgraphql to a working basic gatsby install, `gatsby develop` produces `error: cannot find module 'react'`
blogposts la days higher than video 7 are not visible in: - and in - but i can open them direct:
- video 10
- video 9
on a graphql query i have a `date` field which is being reformatted to `dd mmm yyyy`
that worked fine for all entries until we entered british summer time, at which point any dates set to midnight are being formatted to the next day e.g
12th april becomes 13th april.
`gatsby build` command fails on latest version (v2.20.21) with error:
> error: cannot find module 'webpack' note: issue not reproducible on v2.20.20
so seems to be an issue in v2.20.21 only.
#20843 introduced a timeout for `createremotefilenode`
i'm almost certain this breaks localfile for contentful projects with ~15 or greater assets
i fixed transitive dependencies on `gatsby-source-filesystem` to 2.1.47 (right before #20843) and the issue was fixed.
when using a content type (on contentful\'s site) with a "reference" field that can point to the same type, it\'s possible to create a `maximum call stack` error that causes gatsby to fail to build
as an example, if you had a "page" content type that, at any point within, has a possible link to other "page" types, a sort of circular loop can happen if it ends up pointing back to the origin (e.g
page a contains a reference to page b and page b contains a reference to page a)
this error is thrown:
"gatsby-source-contentful" threw an error while running the sourcenodes lifecycle: maximum call stack size exceeded
``` subsequent schema errors followed for us, which ended up being red herrings
after finally realizing what the real issue was, i tracked down the origin of this bug to version `2.1.73` ( as it does not occur in `2.1.72` all the way back to `2.0.46`.
styled-components lets you use `createglobalstyle` to add arbitrary styles to the document
there appears to be a bug where those styles aren't included in the original ssr html _if_ the user implements a `wraprootelement` method inside `gatsby-ssr.js`
the effect of this is that for that initial mount (after the client has rendered the html but before the react app has rehydrated), none of the global styles are available
this leads to a flicker.
this is what i'm doing ```
import react from 'react'; import { graphql, usestaticquery } from 'gatsby'; export default () => { const data = graphql(` query { allfile { edges { node { name publicurl } } } } `) console.log('data', data); return ( <react.fragment> <h2>images</h2> {data.allfile.edges.map(edge => <div><img alt={edge.node.name} src={edge.node.publicurl} />{edge.node.name}</div>)} </react.fragment> )
} ``` this query renders fine on ` `
unable to add double quotes in a usestaticquery graphql (gatsby-source-graphql) request to a private api
the query works fine with double quotes (" ") when using graphiql but this does not work in gatsby usestaticquery i need the quotes to get an xact match
similar to when you do a google search with quotes
<img width="1012" alt="screen shot 2020-04-12 at 9 58 49 pm" src=" "> for example: { bills(first: 10, updatedsince: "2019-11-15" searchquery:"\\"paid family leave\\"") { edges { node { title } } }
since i updated gatsby from 2.18.5 to 2.18.17 i now always get the following error when i use `npx gatsby develop` in the browser: `referenceerror: _createsuper is not defined`
if i add gatsby-source-graphql to my project i got this: ```
error #11321 plugin "gatsby-source-graphql" threw an error while running the sourcenodes lifecycle: fetcher is not a function 79 | 80 | if (!sdl) {
> 81 | introspectionschema = await introspectschema(link); | ^ 82 | sdl = printschema(introspectionschema); 83 | } else { 84 | introspectionschema = buildschema(sdl); file: ../../node_modules/gatsby-source-graphql/gatsby-node.js:81:35 typeerror: fetcher is not a function - introspectschema.js:14 introspectschema [colombo]/[gatsby-source-graphql]/[graphql-tools-fork]/dist/stitch/introspectschema.js:14:12 - gatsby-node.js:81 object.exports.sourcenodes [colombo]/[gatsby-source-graphql]/gatsby-node.js:81:35
``` i removed cache, node modules and yarn.lock without success
here my `yarn why` responses for graphql-tools-fork and apollo-link: ```
=> found "graphql-tools-fork@9.0.1"
info has been hoisted to "graphql-tools-fork"
info reasons this module exists - "workspace-aggregator-3af4dbbb-e46e-42e0-8d9d-6742ac70aacd" depends on it - hoisted from "_project_#@colombo-it#website#graphql-tools-fork" - hoisted from "_project_#@colombo-it#website#gatsby-plugin-graphql-codegen#@graphql-toolkit#common#graphql-tools-fork" - hoisted from "_project_#@colombo-it#website#gatsby-plugin-graphql-codegen#@graphql-toolkit#url-loader#graphql-tools-fork" - hoisted from "_project_#@colombo-it#website#gatsby-plugin-graphql-codegen#@graphql-toolkit#core#@graphql-toolkit#schema-merging#graphql-tools-fork"
info disk size without dependencies: "2.22mb"
info disk size with unique dependencies: "3.05mb"
info disk size with transitive dependencies: "4.85mb"
info number of shared dependencies: 19
=> found "gatsby-source-graphql#graphql-tools-fork@8.10.0"
info this module exists because "_project_#@colombo-it#website#gatsby-source-graphql" depends on it.
info disk size without dependencies: "5.81mb"
info disk size with unique dependencies: "6.64mb"
info disk size with transitive dependencies: "8.44mb"
info number of shared dependencies: 19
=> found "apollo-link@1.2.14"
info has been hoisted to "apollo-link"
info reasons this module exists - "workspace-aggregator-612cc2d0-299d-4055-bf09-f33868daf8dc" depends on it - hoisted from "_project_#graphql-tools-fork#apollo-link" - hoisted from "_project_#@colombo-it#cms#apollo-boost#apollo-link" - hoisted from "_project_#graphql-tools-fork#apollo-link-http-common#apollo-link" - hoisted from "_project_#@colombo-it#cms#apollo-boost#apollo-client#apollo-link" - hoisted from "_project_#@colombo-it#cms#apollo-boost#apollo-link-error#apollo-link" - hoisted from "_project_#@colombo-it#cms#apollo-boost#apollo-link-http#apollo-link" - hoisted from "_project_#@colombo-it#bff-website#apollo-server-lambda#graphql-tools#apollo-link"
info disk size without dependencies: "224kb"
info disk size with unique dependencies: "1.31mb"
info disk size with transitive dependencies: "1.65mb"
info number of shared dependencies: 7
=> found "gatsby-source-graphql#apollo-link@1.2.13"
info this module exists because "_project_#@colombo-it#website#gatsby-source-graphql" depends on it.
info disk size without dependencies: "224kb"
info disk size with unique dependencies: "1.31mb"
info disk size with transitive dependencies: "1.65mb"
info number of shared dependencies: 7
=> found "gatsby-source-graphql#graphql-tools-fork#apollo-link@1.2.14"
info this module exists because "_project_#@colombo-it#website#gatsby-source-graphql#graphql-tools-fork" depends on it.
info disk size without dependencies: "3.45mb"
info disk size with unique dependencies: "4.54mb"
info disk size with transitive dependencies: "4.88mb"
info number of shared dependencies: 7
``` i also talked about that issue here: #issuecomment-612575347
i trying to build a blog site with drupal as a backend
the issue i having is accessing the image field data in the gatsby <img/> component
i e been following the lullabot and code karate tutorials
the issue is that if i use a regular <img/> tag, i can access and load the image in a query and successfully load it into the page
however, using the gatsby component, i started to get issues with the image object getting passed to the image module as undefined
after updating my code and accessing the image with a slightly modified query i started getting errors based on searching the gatsby issue queue i think it's related to [9818]( but i didn't find a solution there and the issue has been dead but open(?) since november last year.
i really appreciate the recent contentful rich text fix by @jessepinho but in implementing it i get build errors where it\'s still returning "en-us" localization our data model: `post.body` is a rich text field
it has `productcardset` embed
`productcardset.productcards` has is a many-entry link to `productcard`, which points to a single `product` via `productcard.product` when a `productcardset` embed has multiple `productcard` entries, only the first `product` is unlocalized
the second one looks like
```"fields": { "title": {"en-us": "some random hoop"}...``` which this fix was supposed to address
this is the inconsistent types message i get when i have multiple productcards
in this case i used the same `productcard` to prove it's not contingent: ```
warn there are conflicting field types in your data
if you have explicitly defined a type for those fields, you can safely ignore this warning message.
otherwise, gatsby will omit those fields from the graphql schema
if you know all field types in advance, the best strategy is to explicitly define them with the `createtypes` action, and skip inference with the `@dontinfer` directive.
contentfulpostbodyrichtextnode.content.data.target.fields.productcards.fields.title: - type: object value: { 'en-us': 'dorfman hat card' } - type: string value: 'dorfman hat card'
``` it breaks our build currently because the first `productcard` is localized and the second is not
a single card of any type works, but multiple cards will not
all of our contentful fields/entries are set to `"localized": false`
i am confident that this is a bug in the rich text fix not on code or data.
i'm refactoring my markdown blog posts to have the .md file and the images it references in the same folder
each .md is formatted the exact same way
querying the frontmatter with the image subfields (publicurl, childimagesharp, etc) continues to return an error saying the image field is a string, and cannot have subfields
i've followed the tutorials/docs closely and i do not know why it keeps saying it's a string of the image filename
here is an example of my frontmatter (`image` is the field of concern here):
slug: "getting-my-deactivated-instagram-account-back-2019-09-28"
title: "getting my deactivated instagram account back (sept
subtitle: "it was pretty annoying..
but i learned a cool lesson."
image: prateek-katyal-xv7-glvblfw-unsplash.jpg
imagetitle: "getting my deactivated instagram account back"
imagealt: "instagram \'likes\' notification with 0 new likes"
date: "2019-09-28t00:00:00-07:00"
tags: - "social media" - "instagram" - "content"
type: "blogpost"
``` my `gatsby-config.js` does include the plugins stated in the docs for it to work: ```javascript
// gatsby-config.js
plugins: [ 'gatsby-plugin-sharp', 'gatsby-transformer-sharp', { resolve: 'gatsby-source-filesystem', options: { name: 'images', path: path.join(__dirname, 'content'), // where all the .md files and their images live }, }, { resolve: 'gatsby-transformer-remark', options: { plugins: [ { // for inline blog images resolve: 'gatsby-remark-images', options: { maxwidth: 880, }, }, ], }, },
``` my query for my blogpost.js page templates looks like this:
```javascript
export const blog_post_query = graphql` query blog_post_query($slug: string!) { markdownremark(frontmatter: { slug: { eq: $slug } }) { id html excerpt(prunelength: 370) timetoread frontmatter { image { publicurl childimagesharp { fluid { ...gatsbyimagesharpfluid_withwebp } } } } } }
when trying to use gatsby-source-graphql and graphcms i get a "typeerror: fetcher is not a function" and it doesn\'t generate any nodes
it appears to be in the gatsby-node.js function inside of gatsby-source-graphql
it has something to do with the introspectschema call.
after update to gatsby `v2.20.16` while running development environment
(and also when building production code) a following warnings are printed
to the console: ```
warn error persisting state: exdev: cross-device link not permitted, rename '/tmp/reduxcacheyqgxl6' -> '~/bug-repro/.cache/redux'
warn error persisting state: exdev: cross-device link not permitted, rename '/tmp/reduxcacheyumf1i' -> '~/bug-repro/.cache/redux'
warn error persisting state: exdev: cross-device link not permitted, rename '/tmp/reduxcacheywlyqe' -> '~/bug-repro/.cache/redux'
``` this is probably caused by recently introduced fix to [#22959](
updating from v2.20.14 to v2.20.15 causes the site to fail: <img width="461" alt="2020-04-10_12h11_06" src=" "> this does not happen if your cache has not (yet) replaced index.html
so this error is rather hard to notice: to me it seemed that my app was working fine - while users were telling me they encountered a blank page.
when using the experimental page build optimisation (`gatsby_experimental_page_build_on_data_changes=true`), the webpack hash is not deterministic, resulting in unnecessary rebuilds
this is due to the fact that the pages are not always emitted in the same order, causing the keys in `.cache/async-requires.js` to be written in a different order and producing a different hash for the module, and therefore the build.
hey, just today my gatsby installation stopped working (i've cleaned cache)
i get the following error: `enum type wpgraphql_languagecodeenum must define one or more values.`
this issue occurs when using the [gatsby-remark-prism]( plugin to process code-fences in markdown
when enabling both line numbers and commented directives (ie
//highlight-start) within code-fences, the plugin's [line number generator]( does not compensate for lines removed by the commented directives
this leads to a discrepancy between the commented lines removed by the directive handler and the line number spans added beforehand, resulting in scrollable overflow of empty lines in the output code-fence
this obviously does not occur when either the code-fence is not selected to use line numbers in the header (\\`\\`\\`js{numberlines: true}) or the showlinenumbers: false option is passed to `gatsby-remark-prismjs` in `gatsby-config.js`
rather, when both line numbers and comment directives are used in conjunction with one another
#### example input:
1: function test() {
2: // highlight-start
3: return "this is a test"
4: // highlight-end
``` output (* indicating line highlighting):
1: function test() {
2: *return "this is a test"*
4: 5: ``` i've tested this for both highlighting and hiding directives
to get a better understanding of what's happening in the directive handler, check out [this part of my proposed solution]( #diff-5fd2ab3304a334d4977bdcb27e492e3e), described later in this issue.
i'm having an issue when hard-refreshing certain pages in chrome canary, the rendering of the page is inconsistent and just kind of weird
elements are printed multiple times in what seems to be somewhat random positions beyond the actual expected position
it seems to only be happening in canary from what i can tell
it appears to happen intermittently but for me the majority of times
if you notice in this gif below, when the page looks messed up, it's when i hard refresh (cmd+shift+r)
when it looks normal, its when i refresh normally (cmd+r)
![screen capture on 2020-04-08 at 18-51-55]( this is also happening on my team's website: - i'm not sure if that's coincidental or if it's something specific i'm doing
i was however not able to reproduce this on the gatsby blog
my website is deployed to netlify, my team's site is deployed to s3 + cloudfront
you can find my full source here if it helps: couldn't seem to find anything related but maybe i just don't know the right thing to search for
let me know if i can provide any additional information
i appreciate your time.
staticquery is returning a typeerror on render "typeerror: cannot read property \'publicurl\' of undefined" although the graphql query works fine in graphiql
karussel.js ```
import react, {usestate} from \'react\' import {staticquery, graphql } from "gatsby"
import {carousel, container, row, col } from \'react-bootstrap\' import \'../styles/network.css\' const network = () => { return ( <staticquery query = {graphql` query homepagequery { allstrapinetwork(filter: {factory: {eq: "sneaker factory"}}) { nodes { image { publicurl } } } } `} render = {data => ( <section id="network"> <container fluid classname="man-no-gutters"> <row> <col> <carousel classname="slide network-slider"> <carousel.item> <img classname="d-block w-100" src={data.allstrapinetwork.nodes.image.publicurl} alt="first slide" /> <carousel.caption> <h3>first slide label</h3> <p>nulla vitae elit libero, a pharetra augue mollis interdum.</p> </carousel.caption> </carousel.item> <carousel.item> <img classname="d-block w-100" src="holder.js/80 ?text=second slide&bg=282c34" alt="third slide" /> <carousel.caption> <h3>second slide label</h3> <p>lorem ipsum dolor sit amet, consectetur adipiscing elit.</p> </carousel.caption> </carousel.item> <carousel.item> <img classname="d-block w-100" src="holder.js/80 ?text=third slide&bg=20232a" alt="third slide" /> <carousel.caption> <h3>third slide label</h3> <p>praesent commodo cursus magna, vel scelerisque nisl consectetur.</p> </carousel.caption> </carousel.item> </carousel> </col> </row> </container> <div classname="pattern"></div> </section> ) } /> )
} export default network
``` graphiql query: ```
query homepagequery { allstrapinetwork(filter: {factory: {eq: "sneaker factory"}}) { nodes { image { publicurl } } }
``` graphiql output: ```
{ "data": { "allstrapinetwork": { "nodes": [ { "image": { "publicurl": "/static/364979de746f73967bcb68cb6d60b372-e92467e414211f2d489a746be73a6765.jpg" } } ] } }
``` complete error message: ```
typeerror: cannot read property 'publicurl' of undefined
src/components/karussel.js:32 29 | <carousel.item> 30 | <img 31 | classname="d-block w-100"
> 32 | src={data.allstrapinetwork.nodes.image.publicurl} 33 | alt="first slide" 34 | /> 35 | <carousel.caption>
view compiled
staticquerydatarenderer
/users/philipplaurim/desktop/footwear-studios/frontend/.cache/gatsby-browser-entry.js:25 22 | : staticquerydata[query] && staticquerydata[query].data 23 | 24 | return (
> 25 | <react.fragment> 26 | {finaldata && render(finaldata)} 27 | {!finaldata && <div>loading (staticquery)</div>} 28 | </react.fragment>
view compiled
16 stack frames were expanded.
renderwithhooks
node_modules/react-dom/cjs/react-dom.development.js:14826
mountindeterminatecomponent
node_modules/react-dom/cjs/react-dom.development.js:17506
node_modules/react-dom/cjs/react-dom.development.js:18630
htmlunknownelement.callcallback
node_modules/react-dom/cjs/react-dom.development.js:189
invokeguardedcallbackdev
node_modules/react-dom/cjs/react-dom.development.js:238
invokeguardedcallback
node_modules/react-dom/cjs/react-dom.development.js:293
beginwork$1
node_modules/react-dom/cjs/react-dom.development.js:23235
performunitofwork
node_modules/react-dom/cjs/react-dom.development.js:22186
workloopsync
node_modules/react-dom/cjs/react-dom.development.js:22162
performsyncworkonroot
node_modules/react-dom/cjs/react-dom.development.js:21788
scheduleupdateonfiber
node_modules/react-dom/cjs/react-dom.development.js:21220
updatecontainer
node_modules/react-dom/cjs/react-dom.development.js:24408
(anonymous function)
node_modules/react-dom/cjs/react-dom.development.js:24793
unbatchedupdates
node_modules/react-dom/cjs/react-dom.development.js:21935
legacyrendersubtreeintocontainer
node_modules/react-dom/cjs/react-dom.development.js:24792
node_modules/react-dom/cjs/react-dom.development.js:24875
16 stack frames were expanded.
(anonymous function)
/users/philipplaurim/desktop/footwear-studios/frontend/.cache/app.js:67 64 | const preferdefault = m => (m && m.default) || m 65 | let root = preferdefault(require(`./root`)) 66 | domready(() => {
> 67 | renderer(<root />, rootelement, () => { 68 | apirunner(`oninitialclientrender`) 69 | }) 70 | })
view compiled
index styles are broken initial load
it only happens with the production build, when i access it first
but when i access it from other pages, styles are loaded properly.
i'm trying to add [this feature]( from facebook that lets you integrate a page's messenger chat directly into a website
i did so by creating the following component:
import react from "react"; class messengerchat extends react.component { componentdidmount() { window.fbasyncinit = function() { fb.init({ //eslint-disable-line xfbml: true, version: \'v6.0\' }); }; (function(d, s, id) { var js, fjs = d.getelementsbytagname(s)[0]; if (d.getelementbyid(id)) return; js = d.createelement(s); js.id = id; js.src = \' fjs.parentnode.insertbefore(js, fjs); }(document, \'script\', \'facebook-jssdk\')); } render() { return ( <> <div id="fb-root" /> <div classname="fb-customerchat" attribution="setup_tool" page_id="xxxxxxxxxxxx" theme_color="#2f8dff" logged_in_greeting="hi there! have any questions?" logged_out_greeting="hi there! have any questions?" /> </> ); }
} export default messengerchat;
``` i then include this component in my layout like so:
const layout = withtheme((props) => ( <> <globalstyle theme={props.theme} /> <header /> <contentwrapper>{props.children}</contentwrapper> <messengerchat /> <footer/> </>
``` all my pages are wrapped in this layout so the chat appears in all of them
however, including this plugin seems to break routing, as when i click a gatsby link i get the following error: `typeerror: cannot read property 'getelementsbytagname' of null at navigation.js:174`, and nothing renders on the page (just a blank page)
here's the specific line that gets the error:
``` 171 | if (document.title) { 172 | pagename = document.title 173 | }
> 174 | const pageheadings = document 175 | .getelementbyid(`gatsby-focus-wrapper`) 176 | .getelementsbytagname(`h1`) 177 | if (pageheadings && pageheadings.length) {
``` removing the messengerchat component from my layout fixes this issue, but i'd like to include it
however i have no clue why it's breaking the routing (going to a page url directly, or refreshing after getting the error works).
requesting readme from ` ` results in "response code 429 (too many requests)"
updating our website (master branch) to the latest version of the npm packages breaks firefox as it begins to hang, which means the site cannot make of use of fixes and api changes
the website is using gatsby 2.9.6 but if i run `npm update gatsby` or just `npm update`, once it completes everything is fine on safari and chrome but firefox hangs when the page loads and eventually pops up saying the page is causing the computer to slow down
firefox will never sort it, so you have to stop the page and then it works as normal and the rest of the page pops in
we have tried to troubleshoot the issue, but the fact it is working on safari and chrome tell us it's some firefox specific issue, and the dev tools in firefox aren't providing any extra details
additionally, running a `gatsby develop` ends with nothing loading on firefox, the page is blank and nothing loads
running `gatsby build && gatsby serve` lets a full view of the website load but a scroll results in white space showing instead of the rest of the website and none of the website is interactive, until the warning happens and you click "stop", not "wait" after which the website loads and can be used as normal
clicking a link to a new page start the process again which tells me it might be something to do with the internal parts of the site like gastby node etc.
two problems here:
the regexp is not exact for some special characters, eg .
the regexp should validate the full image tag source: ![image](
throwing error on `gatsby develop` or `gatsby build`, failing to access env variables, as follows: "gatsby-source-graphql" threw an error while running the sourcenodes lifecycle: gatsby-source-graphql requires either option `url` or `createlink` callback 50 | invariant(typename && typename.length > 0, `gatsby-source-graphql requires option \\`typename\\` to be specified`); 51 | invariant(fieldname && fieldname.length > 0, `gatsby-source-graphql requires option \\`fieldname\\` to be specified`); > 52 | invariant(url && url.length > 0 || createlink, `gatsby-source-graphql requires either option \\`url\\` or \\`createlink\\` callback`); | ^ 53 | let link; 54 | 55 | if (createlink) { file: node_modules/gatsby-source-graphql/gatsby-node.js:52:3
in gatsby-browser.js, use the following code: ```javascript
let global = false; const app = (props) => { console.log('rendering') if (!global) { global = true navigate('/') } return <div>hello world!</div>
export const wraprootelement = _ => <app/>
this code works fine
however, changing the last line to: ```javascript
export const wraprootelement = _ => ( <location> {location => <app {...location} />} </location>
causes "rendering" to be printed twice.
i am using `gatsby-image/withiepolyfill` together with placeholder images (traced svg in my case)
the reason i use the polyfill is because i want to apply `object-fit: contain` to them
in google chrome everything looks fine
however, when testing in internet explorer 11 the traced svg is not styled correctly
it seems that `object-fit: contain` is not applied at all
after further investigation discovered that this is indeed the case
see the following references: #l16 #l28
styling done through scss variables in js file is not working in build version of project
i have a hamburger menu, with an onclick event
``` <div classname="flex flex-col pointer" onclick={() => handleoverlay(true)} > <div classname="hamburger"></div> <div classname="hamburger"></div> <div classname="hamburger"></div> </div>
this onclick event should open a overlay menu, which works perfectly fine on development
when i do a gatsby build and gatsby serve, the onclick event isn't triggered.
i am also facing some other build issue, where a gatsby-background-image is not rendered in the builded site, while working perfectly in gatsby develop.
when i use the `setheadcomponents` in `onrenderbody` in `gatsby-ssr.js`, instead of within the `<head>` tag, the component is rendered at the top of the `<body>` tag.
on deployment to server, at times the serviceworker:
a) won't update w/latest version
b) will update but doesn't seem to fully load in precache
c) when offline pages won't load
when i tried to add `sitemetadata` in config file and start running it
it shows error: reducers may not dispatch actions
this is new project using gatsby-starter-hello-world-template
in chinese, there are no spaces between words f i wrote a paragraph, your statistics here only think it is a word
i was following along the [fourth tutorial]( on the gatsbyjs site where i was querying data via graphql
my code was copied from the snippets provided in that section.
upgrading `gatsby-source-contentful` from 2.1.88 to 2.2.5 resulted in build errors, as we're unable to use gatsby's `getnode` function with a valid node id string
using the graphql search i can find the node
of note: it's a parent node to the current node we're inspecting
the latest version of `gatsby-source-graphql` fails because it's missing a file
having dug into this a bit, i think it's because that file (batching/dataloader-link) is gitignored - #l2
missing readme for some plugins
for 2 specific pages in my app, the app crashes and points to an error in the ```navigation.js``` file
i'm not sure what to make of this error message and not sure where to start trying to fix it.
the dynamic-imported script is included in `commons` chunk.
looking at configuration for `commons` chunk in webpack.config.js
``` commons: { name: `commons`, // if a chunk is used on all components we put it in commons minchunks: componentscount, priority: 20 },
``` now above `componentscount` is 1, so all dynamic components are included in commons chunk.
i think componentscount should be at least 2
another way is to set `test` function for commons to include all files from node_modules except those in frameworks chunk
by the way, `test` function uses module.identifier() method
is module.resource field better?
i am unable to install `gatsby-plugin-sharp`
seemed like `node-gyp` issue, but i am able to install `sharp` and similar native addons separately (eg `kerberos` `bufferutil`).
for some starters in the starters.yml there are no starters pages created and creating a 404
with the gatsbyjs starter there is a page with blurred preview but with fore reload there is an error page
this starters are affected: - gatsby-starter-stripe - -
when creating a header with html - if there is an anchor tag then this should be used
- or not use the text excerpt from the additional html
i'm using the gatsby cloud live preview
the build compiles fine, and the preview functionality works
when creating a new drupal node and gatsby cloud attempts to rebuild, it fails/crashes
a manual restart of the live preview works
this is a blocker since i can't expect the client to restart the live preview after each new drupal node.
using [`remark-external-links`]( with `gatsby-plugin-mdx` generates an invalid `rel` attribute: `nofollow,noopener,noreferrer` instead of `nofollow noopener noreferrer`, how it is supposed to be
### usage with `gatsby-plugin-mdx` and `remarkplugins` ![screen shot 2020-04-01 at 18 01 47]( ### usage alone ![screen shot 2020-04-01 at 17 50 16](
difference between the develop and build static sites
both commands are working
the styling is quite different
the develop site works as expected
the build site has the the css inline in the head tag but outside of any other tag
just appears as rendered text in the browser.
trace lqip svg placeholder is incorrectly positioned on one of the example images.
on the using-gatsby-image micro-site, the lqip for one of the images is out of alignment.
with the release of a change to the type of the innerref property inside linkprops, the gatsbylinkprops interface is wrong
that breaks any gatsby build using typescript due to incompatible types
context here:
### innerref prop currently defined in linkprops interface ```typescript
innerref?: react.refcallback<htmlanchorelement>;
``` ### current innerref type in gatsbylinkprops interface ```typescript
innerref?: function;
when visiting the starters on it appears that some of them are not loading correctly in a brave browser
this problem occurred for me in gatsby-image versions: **2.2.42** and **2.3.1** i have this component
```typescript
import * as classnames from 'classnames';
import { theme } from 'components/src/components/layout/themeprovider/themeprovider';
import { graphql, usestaticquery } from 'gatsby';
import img from 'gatsby-image';
import * as react from 'react'; type props = { classname?: string;
type imagesharpfixed = { aspectratio: number; base64: string; height: number; originalname: string; src: string; srcset: string; srcsetwebp: string; srcwebp: string; tracedsvg: string; width: number;
}; type devicetype = | \'small\' | \'mobile\' | \'tablet\' | \'laptop\' | \'desktop\'; type imagesqueryresult = record<devicetype, { childimagesharp: { fixed: imagesharpfixed } }>; const image: react.fc<props> = ({ classname }) => { const data = usestaticquery<imagesqueryresult>(graphql` query { small: file(relativepath: { eq: "isometric-2018x1408.png" }) { childimagesharp { fixed(width: 460){ ...gatsbyimagesharpfixed } } } mobile: file(relativepath: { eq: "isometric-2018x1408.png" }) { childimagesharp { fixed(width: 576){ ...gatsbyimagesharpfixed } } } tablet: file(relativepath: { eq: "isometric-2018x1408.png" }) { childimagesharp { fixed(width: 768){ ...gatsbyimagesharpfixed } } } laptop: file(relativepath: { eq: "isometric-2018x1408.png" }) { childimagesharp { fixed(width: 992){ ...gatsbyimagesharpfixed } } } desktop: file(relativepath: { eq: "isometric-2018x1408.png" }) { childimagesharp { fixed(width: 1200){ ...gatsbyimagesharpfixed } } } } `); const sources = [ { ...data.desktop.childimagesharp.fixed, media: theme.devicebreakpoints.desktop, }, { ...data.laptop.childimagesharp.fixed, media: theme.devicebreakpoints.laptop, }, { ...data.tablet.childimagesharp.fixed, media: theme.devicebreakpoints.tablet, }, { ...data.mobile.childimagesharp.fixed, media: theme.devicebreakpoints.mobile, }, { ...data.small.childimagesharp.fixed, media: theme.devicebreakpoints.small, }, ]; const tailwindclassnames = [ \'small:ml-8\', \'small:mt-16\', \'mobile:mt-20\', \'mobile:flex\', \'mobile:justify-center\', \'laptop:ml-24\', ]; return ( <div classname={classnames(tailwindclassnames)}> <img fixed={sources} fadein={false} critical={true} /> </div> );
export default image; ```
the theme variable is:
```typescript
const size = { small: '575px', mobile: '576px', tablet: '768px', laptop: '1366px', desktop: '1920px',
}; const devicebreakpoints = { small: `(max-width: ${size.small})`, mobile: `(min-width: ${size.mobile})`, tablet: `(min-width: ${size.tablet})`, laptop: `(min-width: ${size.laptop})`, desktop: `(min-width: ${size.desktop})`,
}; const mixins = { unselectable: ` -moz-user-select: none; -khtml-user-select: none; -webkit-user-select: none; -ms-user-select: none; user-select: none;`,
}; export const theme = { size, devicebreakpoints, mixins, space: [0, '1rem', '2rem', '3rem', '4rem'],
} ``` if i compile my project with `gatsby develop` command line, style on wrapping div (classname=gatsby-image-wrapper) on the desktop screen is ```
position: relative;
overflow: hidden;
display: inline-block;
width: 992px;
height: 692px;
but when i run `gatsby build` i get
position: relative;
overflow: hidden;
display: inline-block;
width: 1200px;
height: 837px;
i don't understand what is the source of the dimensions difference
![image](
when using gatsby in a monorepo (yarn workspaces), react-refresh is not hoisted and therefore there's an error: ``` error #98123 webpack generating development javascript bundle failed can't resolve '@pmmmwh/react-refresh-webpack-plugin/src/overlay' in '/fakepath/packages/service/.cache' file: .cache/error-overlay-handler.js
``` the only thing that "fixes" it is to specifically install `@pmmmwh/react-refresh-webpack-plugin`, because else it is in `node_modules/gatsby/node_modules/` and cannot be accessed.
i'm developing a website for a client using gatsby, and i'm having the following problem after i make the gatsby build process
in the css stylesheet for the menu component (i'm using css modules) i've created an animation in order to change the opacity of the links from 0% to 100%, when the menu dropdown is activated: ```
.dropdown a { margin-bottom: 35px; font-size: 18px; opacity: 0%; animation-name: fadein; animation-duration: 1.5s; animation-delay: 0.3s; animation-fill-mode: forwards;
} @keyframes fadein { from { opacity: 0%; } to { opacity: 100%; }
``` while using gatsby develop it works fine, but after the build process the stylesheets are changed and instead of "100%" the value is "1%"
here is a copy of the stylesheet editor of the firefox dev tools:
.menu-module--dropdown--20kxd a { margin-bottom:35px; font-size:18px; opacity:0; animation-name:menu-module--fadein--1yseo; animation-duration:1.5s; animation-delay:.3s; animation-fill-mode:forwards
@keyframes menu-module--fadein--1yseo { 0% { opacity:0 } to { opacity:1% }
``` i've also reproduced this prolem with other browsers and values without success.
i would like to change the url path where my website starts
for example, instead of starting at '/' index, i would like it to start at '/blog/'
i've tried following the instructions here: but it only sends me to a white screen
i am new to gatsby (ie
today is my first dive)
following the gatsby tutorials here i find i have to restart gatsby develop to view new pages.
while deploying a new site version where ci runs its own build for deployment, i am now running into a new error
when running `gatsby develop`, as it runs though plugin initialization, i am now getting the following error: ```
"gatsby-source-graphql" threw an error while running the sourcenodes lifecycle: cannot use graphqldirective "@include" from another module or realm
ensure that there is only one instance of "graphql" in the node_modules
if different versions of "graphql" are the dependencies of other
relied on modules, use "resolutions" to ensure only one version is installed
duplicate "graphql" modules cannot be used at the same time since different
versions may have different capabilities and behavior
the data from one
version used in the function from another could produce confusing and
spurious results
74 | if (!sdl) { 75 | introspectionschema = await introspectschema(link);
> 76 | sdl = printschema(introspectionschema); | ^ 77 | } else { 78 | introspectionschema = buildschema(sdl); 79 | } file: node_modules/gatsby-source-graphql/gatsby-node.js:76:13
``` which is followed by the following warning:
error: cannot use graphqldirective "@include" from another module or realm
ensure that there is only one instance of "graphql" in the node_modules directory
if different versions of "graphql" are the dependencies of other relied on modules, use "resolutions" to ensure only one version is installed
duplicate "graphql" modules cannot be used at the same time since different versions may have different capabilities and behavior
the data from one version used in the function from another could produce confusing and spurious results.
``` previous to this, the project was running gatsby-source-graphql@2.1.33
downgrade is however not fixing the issue.
when using fit: `inside` option in `gatsby-remark-images`.
`gatsby-resp-image-wrapper` class set wrong `maxwidth`
see reproduction repo
```gatsby-config.js
{ resolve: `gatsby-transformer-remark`, options: { plugins: [ { resolve: `gatsby-remark-images`, options: { maxwidth: 800, maxheight: 450, fit: `inside`, linkimagestooriginal: true, loading: `lazy`, disablebgimage: true, }, `gatsby-plugin-material-ui`, `gatsby-plugin-emotion`, `gatsby-transformer-sharp`, `gatsby-plugin-sharp`,
when running `gatsby build` with `gatsby_experimental_page_build_on_data_changes=true`, an error is thrown if anything is using `usestaticquery`
sample error:
can't resolve '../../public/static/d/856328897.json' in '/path/to/src/components
`pageresources` is undefined on build, works in develop
typings suggest that this is never undefined: #l68
i installed gatsby by doing ```npm install -g gatsby-cli``` then i did ```gatsby new gatsby-site``` according to the quickstart
but i got an error
i'm trying to use [react-sticky-nav]( in a gatsby site
after importing the library, the gatsby build fails with this error: ``` error #98123 webpack generating ssr bundle failed can't import the named export 'forwardref' from non ecmascript module (only default export is available) file: node_modules/react-sticky-nav/index.mjs
`building static html failed for path "/404/" see our docs page for more info on this error: error: minified react error #294; visit for the full message or use the non-minified dev environment f or full errors and additional helpful warnings
- react-dom-server.node.production.min.js:46 a.b.render [myproject]/[react-dom]/cjs/react-dom-server.node.production.min.js:46:17 - react-dom-server.node.production.min.js:44 a.b.read [myproject]/[react-dom]/cjs/react-dom-server.node.production.min.js:44:18 - react-dom-server.node.production.min.js:54 rendertostring [myproject]/[react-dom]/cjs/react-dom-server.node.production.min.js:54:364 - render-page.js:612 module../.cache/static-entry.js.__webpack_exports__.default e:/myproject/public/render-page.js:612:28 - render-html.js:28 [myproject]/[gatsby]/dist/utils/worker/render-html.js:28:36 - debuggability.js:384 promise._execute [myproject]/[bluebird]/js/release/debuggability.js:384:9 - promise.js:518 promise._resolvefromexecutor [myproject]/[bluebird]/js/release/promise.js:518:18 - promise.js:103 new promise [myproject]/[bluebird]/js/release/promise.js:103:10 - render-html.js:24 [myproject]/[gatsby]/dist/utils/worker/render-html.js:24:47 - util.js:16 trycatcher [myproject]/[bluebird]/js/release/util.js:16:23 - map.js:68 mappingpromisearray._promisefulfilled [myproject]/[bluebird]/js/release/map.js:68:38 - promise_array.js:115 mappingpromisearray.promisearray._iterate [myproject]/[bluebird]/js/release/promise_array.js:115:31 - promise_array.js:79 mappingpromisearray.init [myproject]/[bluebird]/js/release/promise_array.js:79:10 - map.js:37 mappingpromisearray._asyncinit [myproject]/[bluebird]/js/release/map.js:37:10 - async.js:97 _drainqueuestep [myproject]/[bluebird]/js/release/async.js:97:12 - async.js:86 _drainqueue [myproject]/[bluebird]/js/release/async.js:86:9 not finished generating image thumbnails - 228.649s`
recently, the connection via gatsby-source-wordpress has been incorrectly reporting complete when downloading remotely
this has seemingly started out of nowhere, without package updates
i've tried to resolve this with setting gatsby_concurrent_download, etc, with no success.
i am able to observe active users
but there is no reflection in the user, it always remains zero
this is the repository of my website =>
the issue is very easy to see
if you go to the [starter blog demo]( and load any page, the unstyled version of the page is shown for a fraction of a second before the styles are applied
the result is a jerky user experience for someone browsing around
i noticed this does not happen in the [default starter demo](
i have a docker setup for gatsby with the following configuration:
# docker-compose.yml
version: '3'
services: web: tty: true build: context:
dockerfile: dockerfile ports: - "8000:8000" - "9929:9929" - "9230:9230" volumes: - /app/.cache - /app/node_modules - /app/public - .:/app environment: - node_env=development - gatsby_webpack_publicpath=/ - chokidar_usepolling=1
# dockerfile
from node:12
expose 8000 9929 9230 run npm i -g gatsby-cli
run gatsby telemetry --disable workdir /app
copy ./package.json .
run npm i # run with `gatsby develop -h 0.0.0.0`
# .dockerignore
./node_modules
``` when i run `gatsby develop`, i get the following error:
warn error persisting state: enoent: no such file or directory, rename 'reduxcachef9pfse' -> '/app/.cache/redux'
warn error persisting state: enoent: no such file or directory, rename 'reduxcache7d8wgj' -> '/app/.cache/redux'
warn error persisting state: enoent: no such file or directory, rename 'reduxcachecpgs5r' -> '/app/.cache/redux'
``` this happens with version 2.19.22, and not with version 2.19.21
i was getting another error earlier, saying something along the lines of cannot move files between incompatible systems
my docker is on windows, using linux vm
i believe the error comes from trying to use system calls for moving files instead of npm package, but i might be wrong, since i don't know js well enough to debug this.
it all started after i updated gatsby to the latest version in my project that i would receive an error saying the gatsby-cli module could not be found (error written below) after running `gatsby develop` after a lot of troubleshooting, i tried creating a new gatsby site with a fresh install of `npm install -g gatsby-cli
` and `npm install -g gatsby`, but i was getting the same error
even after running `gatsby -v` i get the same error.
i cannot use typescript 3.8 with type-only imports and exports
gatsby-telemetry\'s index.js exports an ["istrackingenabled" function]( #l31)
that function is defined as: ``` istrackingenabled: () => instance.istrackingenabled,
``` where `instance` is: ```
const instance = new telemetry()
``` but `istrackingenabled` on `telemetry` is a **boolean returning function**, not a boolean
elsewhere in the code, e.g
in [`gatsby commands/build.js`]( #l138) uses `istrackingenabled` like so: ``` if (telemetry.istrackingenabled()) {
which will always be true, since it will return a function.
always getting an error "cannot destructure property `wpgraphql` of \'undefined\' or \'null\'" see screesnhot:
we run a documentation website that has hit a performance bottleneck at around 1000 pages
this led us to test the difference between **gatsby-transformer-remark** and **gatsby-plugin-mdx** to compare .md and .mdx build times
we realize that these are not the same plugin, but our expectations were that the build times of each would be closer in-line with one another (for the exact same files)
we used the following repo to benchmark results: here were the results of our test using the auto generated files: | | | | |----------------------------|-------|---------| | source and transform nodes | | | | # of pages | md | mdx | | 100 | 0.17s | 3.12s | | 1000 | 0.90s | 23.05s | | 8000 | 5.53s | 192.80s |
with gatsby-plugin-emotion and yarn@2, build must fail.
i use a tag system for my website's blog
i recently wrote a post about instantiating classes using a `constructor` function -- i added this as a tag to the post and `gastsby-node` broke
so too did my graphql query on my `tags` page
i _think_ this is likely because of some conversion where the runtime is viewing `constructor` as a reserved word..
though this is the _only_ reserved word i've come across with this behavior.
i'm getting the following error when compiling mdx files that contain a react fragment, `<></>` on a gatsby site
transform-react-jsx: pragma has been set but pragmafrag has not been set
``` the issue is because mdx specifies `/* @jsx mdx */ as the pragma, but never specifies a pragmafrag which is now a requirement with `babel-plugin-transform-react-jsx@7.9.x` see the note here:
#customizing-with-the-classic-runtime
i've followed and used it to help create tags and categories pages
i've also added graphql to the pages to render links to other pages within the same category: ```graphql query postpagequery( $id: string! $category: string! $previousid: string $nextid: string ) { site { sitemetadata { title } } post: markdownremark(id: { eq: $id }) { ...ytfull } all: allmarkdownremark( sort: { fields: date, order: desc } filter: { category: { eq: $category } } ) { nodes { ...navfrontmatter ...navcoverfluid } } }
``` this information now seems to remain cached if a new page is added to the same category, because gatsby doesn't realize that the page is dependent upon graphql:
```graphql all: allmarkdownremark( sort: { fields: date, order: desc } filter: { category: { eq: $category } } )
``` i acknowledge this is probably done for performance reasons, but it seems like we should have some way to indicate when a page should be re-rendered.
when #22381 was merged builds started failing for `www` (the docs site)
the error looks like this: ```text
11:01:06 am: error { "commentnumber": null, "level": 1, "id": "827a9a3a-6d53-5ec1-bde7-32147298b648", "parent": "ec28ebff-f198-59bc-9d97-9f0662e37679", "children": [ "f923a690-d5e9-5170-a02b-b51a17706ae7", "4bddd280-f7d7-5922-821a-89604b600b2f", "ed3d70f6-d142-5e7b-92f7-29ede823380d" ], "internal": { "type": "documentationjs", "contentdigest": "358a5703a82d2d403134479c9cf283fe", "counter": 7689, "owner": "gatsby-transformer-documentationjs" }, "kind": "function", "memberof": "plugins", "name": "minifyjs", "scope": "static", "examples": [], "tags": [], "optional": false, "docslocation": { "start": { "line": 519, "column": 2 }, "end": { "line": 522, "column": 5 } }, "codelocation": { "start": { "line": 523, "column": 2 }, "end": { "line": 551, "column": 6 } }, "description___node": "f923a690-d5e9-5170-a02b-b51a17706ae7", "params___node": [ "4bddd280-f7d7-5922-821a-89604b600b2f" ], "returns___node": [ "ed3d70f6-d142-5e7b-92f7-29ede823380d" ], "members": {} } error the node internal.owner field is set automatically by gatsby and not by plugins
11:01:06 am: not finished source and transform nodes - 21.021s
11:01:06 am: error failed to compile: error: exited with code 1
``` ```json
{ "commentnumber": null, "level": 1, "id": "827a9a3a-6d53-5ec1-bde7-32147298b648", "parent": "ec28ebff-f198-59bc-9d97-9f0662e37679", "children": [ "f923a690-d5e9-5170-a02b-b51a17706ae7", "4bddd280-f7d7-5922-821a-89604b600b2f", "ed3d70f6-d142-5e7b-92f7-29ede823380d" ], "internal": { "type": "documentationjs", "contentdigest": "358a5703a82d2d403134479c9cf283fe", "counter": 7689, "owner": "gatsby-transformer-documentationjs" }, "kind": "function", "memberof": "plugins", "name": "minifyjs", "scope": "static", "examples": [], "tags": [], "optional": false, "docslocation": { "start": { "line": 519, "column": 2 }, "end": { "line": 522, "column": 5 } }, "codelocation": { "start": { "line": 523, "column": 2 }, "end": { "line": 551, "column": 6 } }, "description___node": "f923a690-d5e9-5170-a02b-b51a17706ae7", "params___node": [ "4bddd280-f7d7-5922-821a-89604b600b2f" ], "returns___node": [ "ed3d70f6-d142-5e7b-92f7-29ede823380d" ], "members": {}
} ``` this error pointed at the `documentationjs` transformer and the lines it identified didn't seem problematic, but removing them is enough to fix builds
the problematic lines are: #l519-l522
#l625-l628 it only became a problem when the file changed to typescript
maybe there's a discrepancy between how it parses js and ts?
23, 2020, i tested a medium account with 4 articles.`gatsby-source-medium` didn't return the number of articles it should have return
it just returned totalcount: 3, which should be 4
additionally, i tested an account with more than 4 articles, it just returned 4 articles
then i tried to use ` {nameofbloghere}/?format=json&limit=10`
there were just 3 posts not 4
emasuriano also seemed to mention this at #issuecomment-530419977
hey folks, i recently moved my blog to gatsby, and here i am using netlify as my cms, the images which i added via netlify cms inline in markdown aren't showing up properly, instead, it is appearing blurred the live url of the same is here [demo](
pasting #plugin-readme-template into chrome, firefox or safari on mac loads the correct page on the gatsbyjs.org website but the site doesn't scroll to the correct location in the document
i've checked the html in the dev tools and there is only one element on the page with that `id` and it is on the correct `h` element
there is also a right hand `li` that references this `id` and clicking it after the page loads does scroll the correct element into view - but, obviously, only after the page has fully loaded.
i'm writing a schema that looks like this:
type transfer implements node @dontinfer { transferid: id! @proxy(from: "transfer-id")
} type client implements node @dontinfer { clientid: id! @proxy(from: "client-id") transfers: [transfer] @proxy(from: "client-transfers") @split(by: "|") @link(by: "transferid")
i'm sourcing data from csvs and i don't have control over the column header names, hence the `@proxy`s everywhere
for `client.transfers`, i wrote a custom extension `@split` that does `string.prototype.split` on the pipe-delimited transfer ids that it proxies from the source `client-transfers` field
i was hoping that i could then use the resultant array to link to `transfer` nodes
however, a query for `client.transfers` returns an array of `null`
the number of `null`s in the returned array matches up with the number of valid client ids that should be being linked, which made me think that it was mostly working, and when i stuck a console log after [schema/resolvers.js:170]( #l170), i get the correct nodes logged
from what i can tell, the `runquery` call to find the nodes is going all the way with resolving fields when searching for them (`transfer-id` to `transferid` in my case), but the [`map` call on 176]( #l176) is then returning `null` in their place because it's only looking for the `by` field in the node source fields, and for fields that are proxied like in my case it's not there.
calling `createremotefilenode` without an `ext` argument and with the `url` argument ending in `...` results in the wrong file extension
this plugin uses `.` as the extension, causing issues with other plugins down the pipe, like `gatsby-image`.
sometimes when deploying my gatsby page to gh-pages, going to the site gives the github pages 404
however, going to a subpage like /about loads properly, and the whole site is usable, including the home page
however, reloading on the home page or trying to go to it in the address bar results in the 404
after a while it resolves itself, but this is super confusing and i'd like to debug why it happens (i just don't know where to begin).
#### after install gatsby i was notified with this: run npm update mkdirp --depth 5 to resolve 1 vulnerability low prototype pollution package minimist dependency of gatsby path gatsby > eslint-loader > loader-fs-cache > find-cache-dir > mkdirp > minimist more info manual review some vulnerabilities require your attention to resolve visit for additional guidance low prototype pollution package minimist patched in >=0.2.1 <1.0.0 || >=1.2.3 dependency of gatsby path gatsby > eslint-loader > loader-fs-cache > mkdirp > minimist more info found 2 low severity vulnerabilities in 24298 scanned packages run `npm audit fix` to fix 1 of them
1 vulnerability requires manual review
see the full report for details
#### run gastby new shows: found 52 vulnerabilities (43 low, 9 high) run `npm audit fix` to fix them, or `npm audit` for details
info initialising git in test
initialized empty git repository in d:/projects/cs/test/.git/
info create initial git commit in test
your new gatsby site has been successfully bootstrapped
start developing it by running: cd test gatsby develop
on ff: 74.0, chrome 80.0.3987.149 & chromium 82.0.4083.0 (developer build) built on ubuntu 18.04, running on linuxmint 19.3 (64-bit) your pricing site has an infinite animation problem.
the up and down arrows spin endlessly, when an item's header is opened and focused.
i\'m creating a gatsby blog which should be located inside the directory `/blog`, so i\'ve added the path prefix `/blog` to `gatsby-config.js` and the build inside packages.json has the --prefix-paths prefix: ```"build": "gatsby build --prefix-paths"``` this looks good locally, but gatsby cloud doesn\'t seem to respect it.
trying to follow this [doc](
using `"typescript": "^3.7.5"` and `"gatsby": "^2.18.12"` am getting the following error:
property 'mockimplementationonce' does not exist on type 'typeof staticquery'.
hi! i often write css animations, and therefore often use translate3d (0,0,0), but when compiling it turns into translazez (0)
in safari, when creating @keyframes, animation stops working because of this.
we have a project using netlify-cms and have an issue where frontmatter links are getting manipulated when returned by the graphql queries when the values match a collection name
it doesn't seem to affect markdown content, just frontmatter values
we have an `about` collection that supports each site in our monorepo to have their own about page
if we try to link to `/about` from another collection (like if we have a `navbar` collection with a list of links that accept a string for each url), the url will get altered and does not return correctly from the graphql query
**collection data file** see the `link` value is `/about`
this is the correct value
![data about]( **graphql result** here, the query altered the `link` field, which is not desired: ![about]( it only seems to do it if the field does not have a subpath, when i tried a `/about/test` value, it did not alter the value: **collection data file** ![screen shot 2020-03-19 at 9 57 33 am]( **graphql result** ![:about:test]( these examples are test cases used while editing a `career` collection we have
if i change the `link` url to be the same name as the collection it's in (so in this case `/career`), it removes the link entirely: **collection data file** ![data_career]( **graphql result** ![career]( this is the plugin config for our base gatsby repo (or theme?) `gr8-gatsby`: ```
module.exports.remarktransformoptions = { // commonmark mode (default: true) commonmark: true, // footnotes mode (default: true) footnotes: true, // pedantic mode (default: true) pedantic: true, // github flavored markdown mode (default: true) gfm: true,
}; module.exports = () => ({ plugins: [ { resolve: "gatsby-source-filesystem", options: { name: "images", path: `${__dirname}/images`, }, }, `gatsby-transformer-sharp`, // run these plugins or gatsby-image breaks your build `gatsby-plugin-sharp`, // run these plugins or gatsby-image breaks your build { resolve: `gatsby-source-filesystem`, options: { name: `markdown`, path: `${__dirname}/data`, }, }, { resolve: `gatsby-transformer-remark`, options: object.assign({}, module.exports.remarktransformoptions, { // plugins configs plugins: [ { resolve: "gatsby-remark-component", options: { components: [] }, }, ], }), }, { resolve: `gatsby-plugin-styled-components`, options: { displayname: true }, }, ],
``` then in each individual site we have: ```
module.exports = { sitemetadata, plugins: [ { resolve: "gr8-gatsby", // our internal shared component repo/theme that has the above config }, { resolve: `gatsby-source-filesystem`, options: { name: `images`, path: `${__dirname}/src/images`, }, }, `gatsby-transformer-sharp`, `gatsby-plugin-sharp`, { resolve: `gatsby-plugin-netlify-cms`, options: { enableidentitywidget: false, modulepath: "./cms.js", manualinit: true, }, }, `gatsby-plugin-styled-components`, ],
``` i've tried looking through the gatsby, netlify, and various plugins code to see if i can find where/why this manipulation is happening, but i haven't been able to track it down
does this seem like expected behaviour with how collections and urls are handled?
one of my pages is constructed with multiple gql fragments, which in turn, have their own fragments.
everything was working fine until i added one more component/fragment
now i'm getting `response not successful: received status code 400` i ruled out any code issues, null, typos, duplications etc.
i found out that by removing any sufficient number of fields from any part of the query, it magically works again
### gatsby info
``` system: os: macos 10.15.2 cpu: (4) x64 intel(r) core(tm) i5-8210y cpu @ 1.60ghz shell: 5.0.11 - /usr/local/bin/bash binaries: node: 13.6.0 - ~/.nvm/versions/node/v13.6.0/bin/node yarn: 1.19.2 - /usr/local/bin/yarn npm: 6.13.4 - ~/.nvm/versions/node/v13.6.0/bin/npm languages: python: 2.7.16 - /usr/bin/python browsers: chrome: 80.0.3987.132 safari: 13.0.4 npmpackages: gatsby: ^2.19.23 => 2.19.23 gatsby-cli: ^2.9.0 => 2.9.0 gatsby-plugin-env-variables: ^1.0.1 => 1.0.1 gatsby-plugin-flow: ^1.0.4 => 1.1.19 gatsby-plugin-polyfill-io: ^1.1.0 => 1.1.0 gatsby-plugin-react-helmet: ^3.0.12 => 3.1.22 gatsby-plugin-react-svg: ^2.1.1 => 2.1.2 gatsby-plugin-robots-txt: ^1.4.0 => 1.5.0 gatsby-plugin-root-import: ^2.0.5 => 2.0.5 gatsby-plugin-sass: ^2.0.11 => 2.1.29 gatsby-plugin-sitemap: ^2.0.11 => 2.2.27 gatsby-plugin-styled-components: ^3.0.7 => 3.1.19 gatsby-plugin-typography: ^2.2.10 => 2.3.22 gatsby-source-graphql: ^2.1.33 => 2.1.33 gatsby-transformer-remark: ^2.6.50 => 2.6.53 npmglobalpackages: gatsby-cli: 2.8.27
``` ### example query
``` items { metadescription titletag url pencilbanner { ...pencilbannerfragment } hero { ...herocarouselfragment } itemscollection { items { __typename ...onefragment ...twolfragment ...threelfragment
...twentyfragment } } } }
``` ### screen recording
will edit with annotations if possible
given a css file is excluded leveraging null-loader from static build
when gatsby build triggered
then error is thrown
when the chinese text in a mdx file is too long, `excerpt(prunelength: 250)` returns an empty string
when the text is a bit shorter, it returns the expected string of length 250.
context: when using `gatsby-plugin-netlify-cms` with `enableidentitywidget: true` (the default), netlify identity widget iframe is created twice.
when any of pages used graphql query and run `gatsby develop` will lead to crash at the state of `onpostbootstrap`
but if i start develop server with no query first, and then add a new query into page, everything will work just fine.
i'm using yarn
but npm results the same thing.
when i run command `gatsby develop` everything works fine and i can see the website working properly, however when i run `gatsby build` command below error is logged to the terminal
while error seem to be related to contentful-plugin, the same error is not present when `gatsby develop` command is ran ` error problems with gatsby-source-contentful plugin options:
spaceid: undefined - "spaceid" is required
accesstoken: undefined - "accesstoken" is required
host (default value): "cdn.contentful.com"
environment (default value): "master"
downloadlocal (default value): false
localefilter (default value): [function]
forcefullsync (default value): false
pagelimit (default value): 100
usenameforid (default value): true`
[
i'm encountering error #95313 but no hints on why or where its happening
okay when running > gatsby develop and errors on > gatsby build
documentation page about a/b testing with google analytics and netlify isn't available.
url:
i'm trying to write some unit tests using `@testing-library/react` which is working absolutely fine on other components but as soon as i introduce gatsby link (`import { link } from 'gatsby'`) as a child component then my tests fail and complain about gatsby link
it's never happened on previous projects, on difference is the way it's imported now.
code block prims language is not visible above the codeblock
i remember that i see it at least for this languages:
when wrapping the root element with the gatsby-browser-api wraprootelement() with an react.fragment it creates two div\'s with the id "gatsby-announcer"
after creating a new gatsby site using `gatsby new`, things appear to work until another package is installed with `npm install`, at which point weird errors start to show up [video of the errors + steps to fix here](
i'm trying to use `setnodefield` in a plugin of mine
however, instead of the value being set, there is simply `null` being set for the field's value
this code previously worked, but sometime recently on upgrading the `gatsby` versions, it does not work any longer, which is why i feel that this is a regression.
cannot overwrite `workboxconfig.runtimecaching`.
i am trying to get jsx components to work globally in my markdown files for my blog as per the documentation: [importing and using components in mdx]( #make-components-available-globally-as-shortcodes) the proper html is not being rendered from my custom component inthe markdown, rather i get a plain <div> tag with the attributes set in the custom component
when i import my custom component into a .mdx file in src/pages and import the component from within the .md file as per [import-components-for-use-from-another-library]( #import-components-for-use-from-another-library) the proper html is rendered: ```html <blockquote class='sc-bdvaja jkmsod'> <p> <small> this is a foobar<cite>by some genius</cite> </small> </p> </blockquote>
``` i have simplified my test to putting a `<mdxrenderer>` right in the `blog.js` file which resides in `src/pages` to rule out any issues with pathing and `createpages` in `gatsby-node.js` the contents of my blog.js is: ```js
import bio from "../components/bio"
import layout from "../components/layout"
import seo from "../components/seo"
import { rhythm } from "../utils/typography"
import button from "../components/button" import { mdxrenderer } from "gatsby-plugin-mdx"
import { imgcaption } from "../components/imgcaption" class blog extends react.component { render() { const { data } = this.props const sitetitle = data.site.sitemetadata.title const posts = data.allmdx.edges const shortcodes = { imgcaption } return ( <layout location={this.props.location} title={sitetitle}> <seo title="all posts" /> <bio /> <div style={{ margin: "40px 0 40px" }}> {posts.map(({ node }) => { const title = node.frontmatter.title || node.fields.slug return ( <react.fragment> <div key={node.fields.slug} style={{paddingleft: \'15px\'}}> <mdxrenderer components={shortcodes} > {node.body} </mdxrenderer> <h3 style={{ marginbottom: rhythm(1 / 8), }} > <link style={{ boxshadow: `none` }} to={`blog${node.fields.slug}`} > {title} </link> </h3> <small>{node.frontmatter.date}</small> <p style={{ marginbottom: rhythm(1 / 2), margintop: rhythm(1 / 4) }} dangerouslysetinnerhtml={{ __html: node.frontmatter.description || node.excerpt, }} /> </div> <hr style={{bordertop: \'1px solid #bbb\', margin: \'0 0 15px\'}} /> </react.fragment> ) })} </div> <link to="/"> <button margintop="85px">go home</button> </link> </layout> ) }
} export default blog export const pagequery = graphql` query { site { sitemetadata { title } } allmdx(sort: { fields: [frontmatter___date], order: desc } filter: {fileabsolutepath: {regex: "/content/blog/"}}) { edges { node { excerpt fields { slug } frontmatter { date(formatstring: "mmmm dd, yyyy") title description } body } } } }
``` my custom component is here: `src/components/imgcaption.js`
and looks like this: ```js
import react from 'react'
import styled from 'styled-components'
import colors from '../../content/assets/style/colors.scss' export const imgcaption = ({description, citation}) => { return ( <container> <p> <small> {description} <cite> {citation} </cite> </small> </p> </container> )
} const container = styled.blockquote` border-left: 1px solid ${colors.charm_pink}; padding-left: .35em !important; p { small { font-size: 65%; cite { font-size: xx-small; } } }
``` my `gatsby-config.js` looks like this: ```js
module.exports = { sitemetadata: { // edit below title: `blah`, author: `blah bah`, description: `blah blah blah blah blah`, siteurl: ` `, social: { twitter: `blahblah`, }, }, plugins: [ { resolve:`gatsby-source-filesystem`, // this entry has to be the first or will not work as per faq options:{ path:`${__dirname}/static/assets`, name:`assets` } }, `gatsby-plugin-sass`, `gatsby-plugin-netlify-cms`, `gatsby-plugin-styled-components`, `gatsby-transformer-sharp`, `gatsby-plugin-sharp`, `gatsby-plugin-offline`, `gatsby-plugin-react-helmet`, `gatsby-plugin-feed-mdx`, { resolve: `gatsby-source-filesystem`, options: { path: `${__dirname}/content/blog`, name: `blog`, }, }, { resolve: `gatsby-source-filesystem`, options: { path: `${__dirname}/content/data`, name: `content`, }, }, { resolve: `gatsby-plugin-mdx`, options: { extensions: [".mdx", ".md"], gatsbyremarkplugins: [ { resolve: `gatsby-remark-images`, options: { maxwidth: 590, }, }, { resolve: "gatsby-remark-external-links", options: { target: "_blank", rel: "nofollow" } }, { resolve: `gatsby-remark-responsive-iframe`, options: { wrapperstyle: `margin-bottom: 1.0725rem`, }, }, { resolve: `gatsby-remark-vscode`, }, { resolve: `gatsby-remark-copy-linked-files`, }, { resolve: `gatsby-remark-smartypants`, }, ], }, }, { resolve: `gatsby-plugin-google-analytics`, options: { // edit below // trackingid: `add your tracking id here`, }, }, { resolve: `gatsby-plugin-manifest`, options: { name: `blah`, short_name: `blah`, start_url: `/`, background_color: `#ffffff`, theme_color: `#663399`, display: `minimal-ui`, // edit below icon: `content/assets/gatsby-icon.png`, }, }, /*{ resolve: `gatsby-plugin-typography`, options: { pathtoconfigmodule: `src/utils/typography`, }, },*/ ],
i've got an issue that i believe is related to yarn but just in case i want to point it to you as it affect gatsby/docz users using react-native
it's due to this committ adding `@pmmmwh/react-refresh-webpack-plugin` as a dependency
see
see also **steps to reproduce** 1
git clone
cd yarnissue
executing gatsby build command fails after adding , gatsby-plugin-sitemap .
a lot of typos across docs.
received a bug report for people using the gatsby-source-drupal plugin in gatsby cloud - they sometimes see this error on their when saving content
[drupal.org issue]( it's possible there could be an underlying issue in the drupal gatsby module, but i think we could get past this error for now by doing a safe check for `datum` before trying to destructure it
pr incoming ;) ```
16:41:00 pm: typeerror: cannot destructure property `attributes` of 'undefined' or 'null'
- normalize.js:16 nodefromdata [www]/[gatsby-source-drupal]/normalize.js:16:9 - utils.js:112 handlewebhookupdate [www]/[gatsby-source-drupal]/utils.js:112:19 - gatsby-node.js:184 [www]/[gatsby-source-drupal]/gatsby-node.js:184:11 - layer.js:95 layer.handle [as handle_request] [www]/[express]/lib/router/layer.js:95:5 - index.js:317 trim_prefix [www]/[express]/lib/router/index.js:317:13 - index.js:284 [www]/[express]/lib/router/index.js:284:7 - index.js:335 function.process_params [www]/[express]/lib/router/index.js:335:12 - index.js:275 next [www]/[express]/lib/router/index.js:275:10 - read.js:130 [www]/[body-parser]/lib/read.js:130:5 - index.js:224 invokecallback [www]/[raw-body]/index.js:224:16 - index.js:213 done [www]/[raw-body]/index.js:213:7 - index.js:273 incomingmessage.onend [www]/[raw-body]/index.js:273:7 - task_queues.js:80 processticksandrejections internal/process/task_queues.js:80:21 ```
i have been trying to get my gatsby project to connect to my contentful space
i made sure i added all the required fields (spaceid, accesstoken) in the config files, but i keep on getting the following error message.
accessing your contentful space failed.
try setting gatsby_contentful_offline=true to see if we can serve from cache
used options:
spaceid: "*********ppq"
accesstoken: "*********************************************z13o"
downloadlocal: true
environment: "develop"
host (default value): "cdn.contentful.com"
localefilter (default value): [function]
forcefullsync (default value): false
pagelimit (default value): 100
usenameforid (default value): true
when clicking and dragging somewhere on a page, text that is above gets highlighted, even if there is no relation between the element (if any) where the click/drag event happens and the text element.
following [this step]( #create-a-list-of-your-sites-markdown-files-in-srcpagesindexjs) in gatsby's official tutorial triggers this error: ```
generating development javascript bundle failed
src/pages/index.js
52:11 error cannot query field "frontmatter" on type "markdownremark" graphql/template-strings
graphiql shows no frontmatter field.
my graphiql query isn't returning tags when i execute the code in gatsby-node.js however the query is working properly in the graphiql interface.
`gatsby new hello-world ` issue with gatsby-cli 2.10.5 (
i've updated gatsby to version 2.19.38 (after being on 2.10) and have the `gatsby-source-graphql-universal` plugin installed (at version 3.1.11)
when trying to include our own graphql api (based on strapi) i get the following message: `schema must contain uniquely named types but contains multiple types named "cms".`
the traced svg placeholders for my images are not scaling in alignment to the actual images in internet explorer.
there are various typos present across the project
![screenshot from 2020-03-11 14-32-40](
when importing the `navigate` function
following the tutorial to create a new hello-world gatsby application on page: we are faced with a compilation error when running `gatsby develop` if we are on node v.13.10+
error with custom graphql sources with gatsby-source-graphql plugin: "gatsby-source-graphql" threw an error while running the sourcenodes lifecycle:
schema must contain uniquely named types but contains multiple types named "cachecontrolscope".
we're getting weird error during gatsby build process on our pipeline in gitlab
an error occurs like every 2-3 days
we're running build process on our custom docker image
vips2png: unable to write to buffer pipeline:
![pipelinefail](
when rendering a `<link>` from `gatsby-link` which points to the current location, then each click pushes a new entry into the history stack
thus, if i click a link (pointing to the page that i\'m on) multiple times, then i require the same amount of browser "back button" presses, in order to leave my current page
natively, browsers implement a history "replace" and not a "push" when the anchor tag points to the current url
i feel that gatsby's `link` should to the same
there was also a [related issue in reach router](
i\'m working on a website and would like to display a "work in progress" image when people get to my website
i used the basic config to make gatsby-image working
i use `usestaticquery` to query the image
for now, i managed to display the image when the code is into the `index.js` page
but as soon as i try to query the image from a component that i call in the index page, i get a "staticquery cannot be fetched" : ![staticquery](
differences in outputted `html` in deployed (`build`) versions - left has weird `<article>` tag workaround..
see: <img width="1337" alt="issue-b" src=" "> and: <img width="1274" alt="issue-a" src=" ">
so, i am trying to use gatsby-source-drupal and i\'m getting :- "error in "/app/node_modules/gatsby-plugin-sharp/gatsby-node.js": \'linux-x64\' binaries cannot be used on the \'linuxmusl-x64\' platform
please remove the 'node_modules/sharp/vendor' directory and run 'npm install'.
" but when i remove this plugin from the gatsby-config.js i get :- there was an error in your graphql query: unknown type "imagesharpsizes".
file: node_modules/gatsby-transformer-sharp/src/fragments.js:304:46
`yarn.lock` file is being ignored inside `.gitignore` , but i can see that the repository do have yarn.lock file.
in #l233, the noscriptimg function (which is responsible for displaying images when javascript is disabled) uses string interpolation to inject the passed props: #l239 this fails whenever one of the props contains double quotes, or more precisely, it causes the browser to fail parsing such attributes.
gatsby when building schema don't create file node in graphql base on relative path to file.
i think problen inside [is-file.js](
when querying a single node by a direct-id lookup, the query sometimes returns null
querying for the whole list, and filtering by something such as slug finds the document fine, with the same id
thanks to @dschau for helping me debug this
i had a feeling it was related to but after testing on a version from before that change (2.18.22), the issue still occurs.
if webpack rule for eslint uses the rule.loader webpack shortcut, `gatsby develop` will fail.
with ssr enabled, additional elements rendered client-side have incorrect styles.
styles are generated correctly if the changes occur after the component is mounted
backstory: i use a redux store that is preloaded from localstorage
some components are conditionally rendered client-side based on the state.
site build fails when trying to deploy from netlify
works and successfully builds when running locally.
resolves some of the issues discussed in #20692
- previously when querying pages using `allsitepage.nodes` instead of `allsitepage.edges` was impossible because the serializer and internal page filter expected the edges object structure
- previously you had to set your siteurl at `site.sitemetadata.siteurl` or the default resolver would fail
this seemed pointless when using other methods to resolve siteurl
you can now define a function that receives the query result as "data", and you can return a string that will be used for siteurl
## tbd while this solution works there is a lot of "odd" things i had to do to make it backwards compatible
specifically when filtering pages i convert the the data structure to an array of pages from either the `edges` or `nodes` structure
but it also still assumes use of `allsitepage` which kinda defeats the point of being able to write a custom query
logic has been added to handle both data structures
the absurd part is i have to return that data structure back to its original state to maintain backwards compatibility when handing the data back to the serializer
this applies to siteurl resolution as well
even if you write a custom resolver, accessing in in the serializer is still done at `site.sitemetadata.siteurl`
all this could be eliminated and the general api made more flexible and probably simpler, if we are okay with doing a major version bump
## documentation
//todo ## related issues closes #20692
i'm getting this error when trying to deploy this [site]( on netlify or gatsby cloud:
```8:59:24 pm: failed building static html for pages - 1.687s 8:59:24 pm: error building static html failed for path "/cursos/int2/" 8:59:24 pm: 15 | return (
8:59:24 pm: 16 | <layout>
8:59:24 pm: > 17 | <seo title={this.props.data.cursosjson.nome} />
8:59:24 pm: | ^
8:59:24 pm: 18 | <h1>{this.props.data.cursosjson.nome}</h1>
8:59:24 pm: 19 | <p>{this.props.data.cursosjson.descricao}</p>
8:59:24 pm: 20 | </layout>
8:59:24 pm: 8:59:24 pm: webpackerror: typeerror: cannot read property 'nome' of null
8:59:24 pm: 8:59:24 pm: - curso.js:17 cursotemplate.render
8:59:24 pm: src/templates/curso.js:17:52 ```
if you go to and start searching (the input field for searching starters, not the main search), you will get a blank page.
given that i replaced my `gatsby-config.js` sitemetadata section with a `require('content/site-metadata.json')` statement, when modifying this json file, the hot-reloading isn't occurring
the require statement and everything works nicely, only the hot-reloading is affected.
i don't know if this is due to an issue with the webpack config itself? i haven't extended my webpack config
for info, i'm using this json file so that it can be easily edited by my cms.
graphql queries not working in gatsbyjs mdx blog files.
i am finding `gatsby-image` is intermittently failing to display the full-size lazy loaded image, leaving the blurred variant visible
this only occurs when loading a web page from a cold cache
refreshing the browser window once renders the images as initially expected.
when a user tries to search for the gatsby starter app failed
![bug-docs]( ```
react-dom.production.min.js:4684 typeerror: cannot read property 'tolowercase' of undefined at filtered-starters.js:86 at array.filter (<anonymous>) at n.render (filtered-starters.js:85) at qi (react-dom.production.min.js:4289) at ki (react-dom.production.min.js:4280) at so (react-dom.production.min.js:6722) at hu (react-dom.production.min.js:5696) at pu (react-dom.production.min.js:5685) at au (react-dom.production.min.js:5441) at react-dom.production.min.js:2877
when using instructions from (e.g
using gatsby + prismic via graphql), there's a conflict in gatsby's webpack-dev-server configuration
the development server should ignore at least `gatsby-config.js`, since it's lazy requiring (e.g
`require.resolve()`) the templates
a workaround to get rid of this problem is to add `gatsby-node.js` file containing the following: ```js
const path = require('path'); exports.oncreatewebpackconfig = ({ actions, getconfig }) => { const config = getconfig(); config.devserver = { watchoptions: { ignored: [ path.resolve(__dirname, 'gatsby-config.js'), path.resolve(__dirname, 'public'), ] } }; actions.replacewebpackconfig(config);
when try to search for starters that use some plugin, the site broke and just show a blank page.
example:
pr #18721 seems to have broken my builds
i get errors thrown at typescript-specific keywords like `enum` and `as`, even though my eslint config doesn't throw any errors for those
reverting to `gatsby-plugin-typescript@2.1.27` resolves these issues.
calling `createremotefilenode` with an url (< without an extension crashes
unexpected error value: "failed to process enoent: no such file or directory, stat \'.../.cache/gatsby-source-filesystem/7a1221ea4c61551f928908dd873a3738/30 \'"
i think it has something to do with how the caching is handled.
gatbsy's website rss feed ( does not produce `pubdate` element under the `item` element
this leeds to confuse rss readers, because each time the global `pubdate` changes, all items are considered as new
exemple with netvibes: ![netvibes](
gatsby stater page error
when you filter by categories
when using gatsby-plugin-styled-jsx-postcss and a newer version of gatsbyjs, gatsby gets stuck at "building development module"
this previously worked for gatsby 2.0.75, but now hangs with gatsby 2.19.23.
when running the zipkin local tracer [as specified in the gatsby doc]( #local-zipkin-with-docker), it fails towards the end with error `typeerror: recorder._timedout is not a function`.
the starter library category page is not displayed
![mar-01-2020 06-18-08 (1)](
i followed [the instructions to install `gatsby-remark-katex`]( on a website using `gatsby-plugin-mdx` and it didn work
no errors, no nothing, it just didn transform the latex in the markdown.
i get this error : ```
see our docs page for more info on this error: 12 | const dispatch = usedispatch(); 13 | console.log({ props, pagecontext: props.pagecontext });
> 14 | const article = props.pagecontext.article; | ^ 15 | 16 | const [quantity, setquantity] = usestate(0); 17 | webpackerror: typeerror: cannot read property 'article' of undefined
``` only when i'm trying to make a build with gatsby, but it works great when i develop
the worst is that i can get the log result just before the error : ```
{ props: { path: '/*', '*': 'article/sku_ghehhoorv8nuuy', uri: '/', location: { pathname: '/article/sku_ghehhoorv8nuuy', search: '', hash: '' }, navigate: [function: navigate], children: undefined, pagecontext: { article: [object] }, pathcontext: { article: [object] } }, pagecontext: { article: { id: 'sku_ghehhoorv8nuuy', active: true, currency: 'eur', price: 500, attributes: [object], localfiles: [array], product: [object] } }
after running `gatsby clean && gatsby build` the public folder contains no index.html file
which leads to the project not working when served by a static server (in my case caddy on docker).
`createcontentdigest` produces the same digest for two buffers if they have the same length
hot reloading doesn work when i change the frontmatter in an `.mdx` file
i have to rerun `gatsby develop` to observe the changes.
the starters_validate check is failing on all builds because of vulnerabilities found by npm's automatic audit
run `npm audit fix` to resolve these.
`gatsby-plugin-mdx` fails to require plugins that have default exports.
i used the plugin and observed, that in some html files the preload links for the fonts were missing.
then i saw, that in `font-preload-cache.json`, some routes contain a trailing slash, but i generate all my pages without a trailing slash
for those routes, the lookup in the asset map fails
#l22 this could be replaced with ```js
const assetsofpath = cache.assets[pathname] ? cache.assets[pathname] : cache.assets[pathname + "/"]
if (!assetsofpath) { return
const assets = object.keys(assetsofpath)
when i'm running my site with javascript disabled (e.g
via the noscript browswer plugin), the styles i set with the`imgstyle` prop don't get propagated down to the image
just fyi, i think i already located the issue and wrote a fix for it here: [
if people think this is a valid bug and agree with my proposed fix i'm happy to (try to) add tests and open a pr for it.
getting errors when trying to create a new project with gatsby
when i use images inside my blog posts (which use mdx), i see the image twice in my post, once as the blurry/low-res version (or traced svg if i set that option), and again as the full size
both images are stacked on top of eachother, and break the full width of the content area
here's a screenshot of what's happening: ![blurry image on top of full size image]( there are no errors in the console that give notice to anything wrong
not sure if it has do with my config? [but here it is for reference](
gatsby-transformer-sharp@2.3.15 (released a few hours ago) introduced a regression where it warns for any file types (even supported ones)
see the regression is caused by using a [`default export`]( #diff-6ffe62631f12defe74d8bf931540b5e8r10), but importing the file using `require` (without using `.default`)
when looking over the codebase it is a mix of `import`, `default export`, `export`, `module.exports` and `require`
is the preferred coding style documented somewhere?
according to [developer.twitter.com]( #card-and-content-attribution) `twitter:creator` is used as attribution of the content to the twitter `@username`, while in seo.js it has the content of the site **author name**
for example, `john doe` may have the twitter username `johndoe_007`, so attributon on `twitter:creator` should not go to `john doe` but `johndoe_007`.
after running `npx gatsby new blog` and then going into the `blog` directory and running `npm run develop` or `npm run build` i get an error during build: ```
error #11321 plugin "gatsby-plugin-manifest" threw an error while running the onpostbootstrap lifecycle: input file contains unsupported image format
``` when running develop it additionally logs: ``` error failed to retrieve metadata from image /home/redacted/dev/projects/blog/src/images/gatsby-astronaut.png input file contains unsupported image format error: input file contains unsupported image format error #85925 graphql there was an error in your graphql query: cannot return null for non-nullable field imagesharpfluid.aspectratio
the field "imagesharpfluid.aspectratio." was explicitly defined as non-nullable via the schema customization api (by yourself or a plugin/theme)
this means that this field is not optional and you have to define a value
if this is not your desired behavior and you defined the schema yourself, go to "createtypes" in gatsby-node.js
if you're using a plugin/theme, you can learn more here on how to fix field types:
#fixing-field-types 1 | fragment gatsbyimagesharpfluid on imagesharpfluid { 2 | base64
> 3 | aspectratio | ^ 4 | src 5 | srcset 6 | sizes 7 | } 8 | 9 | query homeredacteddevprojectsblogsrccomponentsimagejs2969191536 { 10 | placeholderimage: file(relativepath: {eq: "gatsby-astronaut.png"}) { 11 | id 12 | childimagesharp { 13 | id file path: /home/redacted/dev/projects/blog/src/components/image.js
plugin: none ```
the blog starter template is a great way to have a blog site up and running, but while most of the stuff can be configured from the `gatsby-config.js` file, the author summary is missing and is hardcoded in `src/components/bio.js`.
when i do the following steps an error occur during the building of the bundle.
the algolia autocomplete doesn't work when using `tab` to navigate to it.
when using the `react-toast-notifications` npm package and running a gatsby production build, accessibility text indicating which page the user has navigated to gets rendered the page after each route transition
here is a screenshot showing the issue:
gatsbyjs.org doesn't have an `<html lang>` attribute
certain pages of dot-org are missing `id="reach-skip-nav"` in the `<main>` element meaning that our [skip-nav]( doesn\'t work: * template-contributor-page
* template-creator-details
* template-feature-comparison in addition, these pages don't have a `<main>` element at all and thus no `reach-skip-nav` id: * 404.js
* ecosystem.js
* newsletter.js
* pages/blog/tags.js
* templates/tags.js
* template-starter-page.js
* filtered-starters.js ## steps to reproduce 1
go to or any one of the listed pages
tab so that "skip to main content" is visible
press "enter"
press tab ## expected result the next tabbed content is the main content
## actual result the next tabbed content is the navigation.
in attempting to use `gatsby-source-contentful` in offline mode (`gatsby_contentful_offline` + wi-fi turned off), i hitting an issue that seems to be related to inferring graphql types for contentful assets
i only see the misbehavior when `downloadlocal: true` is set in the `gatsby-source-contentful` section of `gatsby-config.js` (and i'd like that to use that functionality)
i'd very much appreciate any ideas!
when generating `.mdx` pages using `gatsby-plugin-mdx`, any root-relative links such as `[hello](/some-page)` are prefixed with assetprefix for some reason
obviously, links are not assets and shouldn't receive an assetprefix.
the homepage of gatsbyjs.org is broken on landscape orientation
i have searched the open issues and didn see one already open
if this is a duplicate, feel free to close this issue.
i experienced weird behaviour when using polyfills with browserlist, which i tried to verify as [stackoverlow question with answer]( before posting an issue here
it feels like a bug but maybe someone with more in depth knowledge on the inner workings with babel-presets-env can confirm or deny this?
i'm attempting to redirect `/terms/` to a pdf that's sourced from wp and while the server side redirect works gatsby doesn't handle it well client side.
my end goal is to create my own blog theme which provides a `gatsby-config.js` file that loads and parses `markdown` files
using the [`using-multiple-local-plugins`][local] as a starting point, i added the `gatsby-plugin-twitter` as a dependency to the `gatsby-plugin-console-log-a` directory
after doing so, `npm start` fails to build the `gatsby-site-using-local-plugins`.
with two of my site's components, the navbar and the cookieconsentform
multiple instances are present on load
it appears that the components created during the build, which i imagine are created using the component tree described in the `gatsby-ssr.js` are overriding or existing with the components described in the `gatsby-browser.js` file
so in the example of the navbar, the component looks a little like this ```javascript
function navbar() { <router> <simplenavbar path="/landing-page/" /> <navbar default path="/" /> </router>
``` this displays the right components at the right routes when i start my development server locally
i imagine this is because gatsby's building the component tree according to `gatsby-browser.js` file
when i run the production build and serve it, and navigate to the landing page, the majority of the styles of `navbar` component are present, with some of the content of the `simplenavbar` also being present
it's as if gatsby has merged the components together
a similar thing happens in my `cookieconsentform` component
from a component standpoint it's just a div container, with some text and a button inside of it
when i run my development server, it appears just as it should
when i run my production build, it displays as it should, and when i click the button (to acknowledge that i accept the cookie terms), it closes the component rendered by the `gatsby-browser.js`, but keeps the container from the server-rendered component
my current workaround is to remove the `cookieconsentform` and `navbar` from the server-rendered components
i don't mind doing this for the ccf, but with the navbar only being rendered on the browser, it makes my site feel jerky
in the below image, you can see that i'm rendering two components, the top of the two is just the container and nothing else, while the other is contains the full component
it looks like the former is the left over from the server-rendered components
![image]( does gatsby somehow use a component equality check to match components built with ssr and the ones built in the browser, and then swaps them out? if so it could make sense as top why it's causing the navbar to break, because it's wrapped in a router (and i guess routing isn't something that the server is capable of dealing with)
up until now i've kept the `gatsby-browser` and `gatsby-ssr` files in sync, but it's making less sense to do so, considering that i don't need to render a cookie consent form on the server, and i don't need to perform any of the initialisation that's required when a user starts a session.
i've used the starter project
in the project, there are two pages: 1
page-2 (has import of demo.js) there is a demo.js which imports demo.module.css now this demo-module css in being returned in html of index page also even when it doesn't import that components and doesn't need the css of demo.module.css this results in fairly large page size in applications with lots of custom components
i am creating my home page dynamically from a template in `gatsby-node` instead of in the `pages` directory
the path is `/index.html`, because i need the production url for the homepage to be website.com/index.html
when i do this, i cannot access the homepage in both development and production
in development, i get the gatsby 404 page
in production, in my network tab, the request for `/page-data/index.html/page-data.json` fails
i have figured out a manual workaround at the moment.
1) i run a build
2) i rename the `index.html` directory under `public => page-data => index.html => page-data.json` in my build files to `index`.
3) i rename `<link as="fetch" rel="preload" href="/page-data/index.html/page-data.json" crossorigin="anonymous"/>` in my `index.html` file in the build to `<link as="fetch" rel="preload" href="/page-data/index/page-data.json" crossorigin="anonymous"/>`
i can then access that page via website.com/index.html in my production setup as intended
unfortunately, this breaks any automated build processes
i am using circleci to automate builds and deploys to aws
i now have to run a build manually, go into the files and update them myself, and then manually deploy
this has severely hampered the workflow on our client project because we are quickly iterating and pushing code updates and relying on quick rebuilds to staging to show the client
another interesting thing to note is that this only seems to happen for the home page (aka /index.html)
other page routes, such as `/articles/article-title/index.html` seem to work fine in development and production
i do not have any experience working on the gatbsy core library, so i do not know where or how to identify where this bug is coming from
any ideas or help is greatly appreciated! please see for more information and context.
i've been having this ui issue for so long now, i posted the issue in [netlify's cli github issues list]( as well
**please close if this feels unrelated to gatsby, and is solely netlify\'s problem to fix.** **issue:** the netlify cli ui get\'s cut off by an "in progress" bar that just sits there even though it\'s completed, cutting off the green "server now ready on localhost:8888" section
this issue doesn't happen when running the `gatsby develop` command, but does happen when running `netlify dev`, which in turn runs `gatsby develop`
i'm posting here in case anyone here might have some insights into the ui issue based on the two versions of gatsby i outline below
i decided to get to the bottom of it and figure out when this this issue starts..
**it doesn't happen on `gatsby@2.15.17`, but it does happen on `gatsby@2.16.0` and later**
but `gatsby@2.16.0` is the very specific moment things break
--- here\'s a screenshot on `gatsby@2.15.17`, running `netlify dev` when things look normal: <img width="1136" alt="hyper 2020-02-06 at 16 37 19@2x" src=" ">
<img width="1136" alt="hyper 2020-02-06 at 16 37 25@2x" src=" "> here\'s a screenshot on `gatsby@2.16.0`, running `netlify dev` when things look broken: <img width="1136" alt="hyper 2020-02-06 at 16 57 33@2x" src=" "> ---
performance on thirdandgrove.com drops by about 10-15 lighthouse points when upgrading the gatsby package
network waterfall is shifted.
after having upgraded to version 2.1.33 of `gatsby-source-graphql` i'm getting an error when trying to query
error does not occur in versions of the plugin using `graphql-tools` rather than `graphql-tools-fork` (ex.: previous version used was 2.1.15)
the graphql source in this case is an aws appsync endpoint
a test call to the endpoint with the parameters set in the `gatsby-config.js` file returns a successful response.
i am having a spa built with gatsby
i am using `<a href="/#sectionx">section x</a>` links for navigation in the header
this is working just fine
unfortunately, reloading the page (having the anchor link in the url) does not scroll to the expected section but stays unscrolled at the top of the page.
starting in gatsby 2.15 and up, page queries that filter on a reference field in `gatsby-source-contentful` are failing to hydrate in the initial `gatsby develop`
once the development server is running, changing any portion of the page query fixes the issue and the query works as expected.
we need to ensure the mdx-link component handles external links and passes through to an a tag instead of the gatsbylink component
[this file]( needs to handle the text: `/gatsby-cheat-sheet.pdf` as an "external" link specifically, `/gatsby-sheet-pdf` passes the `isinternal` function test, when it shouldn\'t
we could add a simple `\\.(.+)$` test to ensure we don't use a gatsbylink on files.
this morning i navigated to a gatsby project of mine which has been in production for a year, fully functional
i launch a `gatsby develop` command and i\'m getting an `unknown fragment "gatsbyimagesharpfluid_nobase64"` error even though it worked for months and i haven\'t changed anything..
i've tried reinstalling all my dependencies, double checked everything, searched for help online but this issue really puzzles me as, and i can't stress this enough, **nothing has changed since the last time it worked as expected**
i've checked the changelogs of the related packages (which i haven't updated, but i checked anyway) but no mentions as to why this would happen
nobody seems to be experiencing the issue (or i couldn't find reports like mine)
**what i've tried:** - deleted `node_modules`, `yarn.lock` & `.cache` files & directories, reinstalled everything normally (ie `yarn install`)
- tried against different branches of the project, all of which were building fine just yesterday and i'm getting this issue on all of them
- checked #15625, #16142 and other somewhat related reports elsewhere which didn't help
- updating all my dependencies
- removing the `gatsbyimagesharpfluid_nobase64` from the query below, which allows me to build the site just fine but, as you'd expect, i'm relying on this fragment so it's far from ideal **what's really strange:** - i haven't changed anything on the project nor the environment since it was working
- all my latest changes do not directly have anything to do with this part of the site
- i haven't installed new gatsby plugins or anything i appreciate the fact that this report is somewhat strange, but i'm here looking for guidance or ideas as to why this could possibly happen and i'll investigate
hopefully i'm just missing something super obvious someone will pick up
### the failing query ```graphql
fragment transform_transparent on file { childimagesharp { sqip(numberofprimitives: 12, blur: 5, width: 316) { datauri } fluid(maxheight: 316, maxwidth: 316, quality: 85, toformat: png) { ...gatsbyimagesharpfluid_nobase64 } }
``` the above custom fragment is the one reported to fail, however i use the `gatsbyimagesharpfluid_nobase64 ` fragment elsewhere and that doesn't seem to cause an issue
the images i apply this fragment on come from prismic.io using the `gatsby-source-prismic` plugin
### current workaround i can build and use the site as expected if i drop the dependency to the incriminated fragment (`gatsbyimagesharpfluid_nobase64`) and replacing it with `gatsbyimagesharpfluid_tracedsvg`
i\'ve tried using `gatsbyimagesharpfluid` too, but i\'m getting the same error "unknown fragment".
when loading gatsbyjs.com i get a blank white screen.
this appears to be a service worker issue
here's the console and network:
<img width="1715" alt="screen shot 2020-01-28 at 9 37 44 am" src=" ">
<img width="1715" alt="screen shot 2020-01-28 at 9 38 01 am" src=" "> when i clear storage the site loads without issue for the first reload
but then reloading the page i get a different error
<img width="1715" alt="screen shot 2020-01-28 at 9 40 45 am" src=" "> ```
idb-keyval-iife.min.js:1 uncaught (in promise) domexception: failed to execute 'transaction' on 'idbdatabase': the database connection is closing
at
i'm trying to test out gatsby builds which requires updating to the latest gatsby and sharp, and it also seem we need a more current gatsby-source-contentful
when i do this all our queries have an additional id added to the query, at each level
this breaks the queries, as an example: > fields "items" conflict because subfields "id" conflict because they return conflicting types id! and string
use different aliases on the fields to fetch both if this was intentional
<img width="960" alt="screenshot 2020-01-28 at 11 06 35" src=" "> however, when i look at the source code for we don\'t set these ids in our queries so they are being added automatically and then clashing
<img width="395" alt="screenshot 2020-01-28 at 11 10 54" src=" ">
i'm using typescript for my `gatsby-node` file so that i can use `gatsbynode` type definitions
when following the example in #configuring-pages-with-matchpath, i get ts errors such as: > property 'match' does not exist on type 'unknown'
ts(2339) <img width="472" alt="image" src=" "> the [gatsby typings]( #l211) have `page` typed as `node & tnode` which does not have a `path` property
injecting a `console.log` into the function and building the site shows that `page` does indeed have a `path` property, thus the args are incorrectly typed.
if you have two fragments and they reference each other `determineusedfragmentsfordefinition` hits a infinite loop
in localized pages, the sidebar doesn\'t show which page is currently "active"
## context the sidebar uses the router `location` to determine what is the currently active page
this breaks on localized pages, which are prefaced with the locale in their slug
## example [in this build]( the sidebar doesn't emphasize the active page/section.
since v2.18.23, changes to files which are watched by gatsby-source-filesystem trigger rebuilds which , after time, involve execution of hundreds of queries and poor rebuild performance.
404 on `gatsby-cypress`
when setting `stripmetadata` to false in the `gatsby-plugin-sharp` options in `gatsby-config.js`, metadata and embedded icc profiles are nevertheless stripped from the generated webp files
i took a look at the corresponding code, the problem seems to be that the `metadata` option is not provided to imagemin-webp (which defaults to `metadata: 'none'`, resulting in the metadata getting removed from the image -> see
gatsby throws an error when going to page-2 after renaming from default template.
#19290 seems to have introduced an axe a11y violation, citing the new `<div id="gatsby-announcer" ..
/>` element as not being contained within a landmark (the `region` rule)
this only occurs after navigation has taken place and the element contains text
it does not trigger on initial page load, as there is no inner text yet.
i'm seeing that whenever i use a `gatsby-transformer-remark` plugin that has a `createfieldnode` function call, it does not add said field to the gql instance
hi everyone, i am working on a gatsby website and i had created a page called "new-page"
this had the url "localhost:8000/new-page"
the page ran perfectly fine, but when i deleted the page and tried to go to the same url to check that it had been successfully deleted, i did not see the gatsby 404 development page that i usually see
instead, the browser displayed an error called "typeerror: cannot read property \'page\' of undefined"
it showed that the error was in "/ui/.cache/root.js:74" (line 74 of root.js file) in a command starting with "path={encodeuri("
no other page names i have tried throw up the same error
all of the following page names go to the gatsby 404 development page as expected (none of these pages exist on my site yet): new-mushroom
default-page
using `gatsby-image`'s `<img />` tag with a fluid image leads to the image being served 4 times on the front end.
`gatsby-source-shopify` is using a deprecated api
shopify only supports a stable version for 12-months, see:
when i run `gatsby develop` i randomly encounter many errors (in some cases / environments always happening) similar to the following (with `unlink` or `chmod` syscall): ``` error error copying file from /project/.cache/gatsby-source-filesystem/c15bd9f18d6833c5dd8e5b404f866e89/drawexamplenohyphen.png to /project/public/static/drawexamplenohyphen-81a5fc052b034037ac401c7b26d96a89.png { [error: enoent: no such file or directory, chmod '/project/public/static/drawexamplenohyphen-81a5fc052b034037ac401c7b26d96a89.png'] errno: -2, code: 'enoent', syscall: 'chmod', path: '/project/public/static/drawexamplenohyphen-81a5fc052b034037ac401c7b26d96a89.png' }
``` the files are copied in the destination regardless of the errors displayed
investigating this further i've isolated it to multiple async calls to `fsextra.copy()` in `createfields()` for the same file which the underlying `fs-extra` can't handle properly when overwriting files
i was able to resolve this locally by replacing the async call with sync `fsextra.copysync()` which may make more sense given the paired `fsextra.existssync()` call beforehand
however a similar issue ( was fixed in `gatsby-transformer-remark` using a different approach to preven the duplicate calls in the first place which might be preferred.
when running gatsby develop if you have the gatsby-transformer-json installed and anywhere in you file system you have a .json file directly inside a directory that starts with a number gatsby will crash with ```
unhandled rejection syntax error: unexpected int "20" graphqlerror: syntax error: unexpected int "20" - typemapper.js:113 typemapper.createtype [gatsby-json-crasher]/[graphql-compose]/lib/typemapper.js:113:43 - objecttypecomposer.js:80 function.createtemp [gatsby-json-crasher]/[graphql-compose]/lib/objecttypecomposer.js:80:28 - objecttypecomposer.js:56 function.create [gatsby-json-crasher]/[graphql-compose]/lib/objecttypecomposer.js:56:21 - index.js:59
when opening any gatsby page in ie10, the page is immediately scrolled down by a couple of hundred pixels (varies by screen size).
our team is leveraging the gatsby refresh endpoint (`enable_gatsby_refresh_endpoint`) for development purposes
the amount of time to build/refresh has increased over time
we are wanting to use a service that will make a post call to `__refresh` on demand
the problem that we are encountering is that if you make the post call in the middle of a refresh then unexpected behavior starts to occur and eventually the dev server crashes
it would be nice to have some way to either offer some kind of throttling or at least have a way to know if we are in the middle of a refresh
(with the latter at least a custom endpoint can be created) our understanding was that it did not behave like this before (2.16.5) and if this were to occur gatsby would wait until the existing refresh would finish.
i have created some custom components and i use them in my blogpost markdown files
these custom components render fine in the browser when they're supplied to `mdxprovider` via `shortcodes` in my layout file
unfortunately, these custom components are not rendered properly in the `html` field that is used by `gatsby-plugin-feed` when generating the rss feed
i've done some digging, and it seems that the custom component _will_ be rendered correctly if the component has been imported directly into the `.mdx` file, but the component _will not_ be rendered correctly if it has been supplied via `shortcodes` to `mdxprovider`
here's an example of one component, `caption`:
```javascript
import react from "react" const caption = ({children}) => { return( <div style={{ fontsize:"14px", textalign:"center", color:"grey", margintop:"-1rem", marginbottom:"2rem"}}> {children} </div> )
export default caption
it gets supplied to the blogpost.js layout file via a **shortcode** given to `mdxprovider`:
```javascript
import react from 'react'
import { graphql } from 'gatsby'
import caption from '../components/caption'
import { mdxprovider } from "@mdx-js/react"
import { mdxrenderer } from "gatsby-plugin-mdx" const shortcodes = { caption } export default function pagetemplate( { data, pagecontext } ) { const { mdx } = data const title = mdx.frontmatter.title const timetoread = mdx.timetoread const relativedate = mdx.frontmatter.date return ( <div> <div id=\'middle-column\'> <div> <h1 style={{fontfamily:"georgia", marginbottom:"8px"}}>{title}</h1> </div> <div classname=\'blogpost\'> <mdxprovider components={shortcodes}> <mdxrenderer>{mdx.body}</mdxrenderer> </mdxprovider> </div> </div> </div> )
} export const pagequery = graphql` query($pathslug:string!){ mdx(fields: { slug: { eq: $pathslug} }){ id body frontmatter { title date (fromnow: true) } timetoread } }
``` here's my plugin config in `gatsby-config.js`: ```javascript
plugins: [ { resolve: `gatsby-source-filesystem`, options: { name: `pages`, path: `${__dirname}/src/pages` } }, { resolve: `gatsby-source-filesystem`, options: { name: `content`, path: `${__dirname}/content` } }, { resolve: `gatsby-plugin-mdx`, }, { resolve:`gatsby-plugin-feed`, options: { query: ` { site { sitemetadata { title description siteurl site_url: siteurl } } } `, feeds: [ { serialize: ({ query: { site, allmdx } }) => { return allmdx.edges.map(edge => { const siteurl = site.sitemetadata.siteurl const slug = siteurl + edge.node.fields.slug const frontmatter = edge.node.frontmatter return object.assign({}, edge.node.frontmatter, { description: edge.node.excerpt, date: frontmatter.date, url: slug, guid: slug, custom_elements: [ { "content:encoded": edge.node.html } ], }) }) }, query: ` { allmdx( sort: { order: desc, fields: [frontmatter___date] }, ) { edges { node { excerpt html fields { slug } frontmatter { title date } } } } } `, output: "/rss.xml", title: "rss feed", }, ], }, }, ]
``` when the caption component is imported directly into the markdown file, i.e:
```markdown
date: "2020-01-11"
title: "blogpost test - title"
excerpt: "excerpty text"
import caption from "../../components/caption" ## something about this awesome image imagine an image goes here...
<caption>a custom caption for my image!</caption> # and so it begins something or other about my blogpost.
the following is rendered in the `allmdx.edges.node.html` field, and thus my rss feed (as expected): ```html
<div style="font-size: 14px; text-align: center; color: grey; margin-top: -1rem; margin-bottom: 2rem;">the moguls below the ski lifts</div>
``` when the caption component is supplied to `mdxprovider` via `shortcodes` (i.e
not imported directly), it is rendered as a div with none of the styling of the custom `caption` component:
<div>the moguls below the ski lifts</div>
``` additionally, i also get this error at `gatsby build` time:
```javascript
warn component caption was not imported, exported, or provided by mdxprovider as global scope
it could be that i just don't know how to properly supply shortcodes in a way that the `html` field knows about them
i've read the docs, but can't find anyway of doing this
otherwise, it seems like a potential feature request to me.
specifying a different datalayername from default "datalayer" in plugin options results in js error: "uncaught typeerror: cannot read property \'push\' of undefined".
if i try to build a gatsby site that happens to include any library that includes .proto files then i get this error:
``` error #95313 building static html failed see our docs page for more info on this error: 263 | //if the first dir fails its a real error 264 | if(path == _path) {
> 265 | emitter.emit('error',new error('error reading first path in the walk '+path+'\ '+err),err); | ^ 266 | } 267 | }); 268 | webpackerror: error reading first path in the walk /protos - walkdir.js:265 eventemitter.<anonymous> node_modules/walkdir/walkdir.js:265:1 - walkdir.js:100 fn node_modules/walkdir/walkdir.js:100:1 - walkdir.js:137 statter node_modules/walkdir/walkdir.js:137:1 - walkdir.js:269 walkdir node_modules/walkdir/walkdir.js:269:1 - walkdir.js:15 function../node_modules/walkdir/walkdir.js.walkdir.sync node_modules/walkdir/walkdir.js:15:1 - grpc.js:50 object.<anonymous> node_modules/google-gax/build/src/grpc.js:50:1 - index.js:33 object../node_modules/google-gax/build/src/index.js node_modules/google-gax/build/src/index.js:33:16 - util.js:18 object../node_modules/@google-cloud/firestore/build/src/util.js node_modules/@google-cloud/firestore/build/src/util.js:18:22 - validate.js:19 object../node_modules/@google-cloud/firestore/build/src/validate.js node_modules/@google-cloud/firestore/build/src/validate.js:19:16
``` it doesn't matter if i never use the file
just having it inside the project tree will fail to build.
native lazy loading **is not supported** in gatsby-image for version >= 2.1.0 in **chrome**.
we run a highly-trafficked gatsby site in production
recently, we've begun seeing a _massive_ uptick in these errors reported by our error monitoring tool (sentry): `undefined is not an object (evaluating 'r.page')`
this happened after we updated gatsby from `v2.17.7` to `v2.18.17`
you can find a few of the stack traces here: -
-
- these errors occur exclusively for older versions of chrome on windows devices
this would seem to point to a polyfill issue, except for the fact that we cannot reproduce it ourselves and even older chrome versions still have great support for modern js
example browsers (all on windows xp, vista, 7, 8, 8.1, or 10):
- chrome 50.0.2661
- chrome 56.0.2924
- chrome 61.0.3163 in the past, we've found errors like these generally correspond to some issue successfully loading the `page-data.json` file corresponding to a given page
i don't think anyone will be able to tell us exactly what's happening here, but if there are any gatsby folks who would be able to point us in the direction of what this `r.page` refers to or might know of any similar issues that could be related, we'd very much appreciate it! please let us know if any further information might be useful.
when attempting to add `gatsby-remark-autolink-headers` to a gatsby site based on `gatsby-gitbook-starter`, the plugin inserts link svgs as expected, but the css is not present.
related to comments [here]( #issuecomment-570251461) and [here]( #issuecomment-570448725) (issue number 3 in that comment)
when using `gatsby-plugin-netlify-cms` in development mode preview styles css can collide with the cms styles.
when using `gatsby-remark-images` and `gatsby-image`, the placeholder image never fades out, which is a problem for transparent images
it looks like this: <img width="788" alt="screen shot 2020-01-03 at 12 33 40 pm" src=" "> i had to write extra code to hide the placeholders, which i _think_ gatsby used to handle automatically in the past
uselayouteffect(() => { const wrappers = document.queryselectorall('.gatsby-resp-image-wrapper'); wrappers.foreach(wrapper => { const img = wrapper.queryselector('img'); const placeholder = wrapper.queryselector('span'); img.addeventlistener('load', () => (placeholder.style.opacity = 0)); });
``` after adding the above code to my post wrappers, i get the desired result: <img width="721" alt="screen shot 2020-01-03 at 12 34 12 pm" src=" ">
site with 20k pages, currently using version 2.17.6
we pass json data via context (hence not using graphql), so we have switched off type inference for sitepage.context to speed up compilation, as stated [here]( #switch-off-type-inference-for-sitepagecontext)
these are the timings we get using 2.17.6: ```
2.17.6 timings
=======================================
success source and transform nodes - 4.247s success building schema - 1.292s success createpages - 23.121s success createpagesstatefully - 0.079s success onpreextractqueries - 0.001s success update schema - 0.051s ```
after upgrading from 2.17.6 to 2.18.12, "update schema" step is taking ~40 seconds instead of 0.051s: ```
2.18.12 timings
=======================================
success source and transform nodes - 5.167s success building schema - 1.206s success createpages - 27.748s success createpagesstatefully - 0.108s success onpreextractqueries - 0.000s success update schema - 41.675s ``` it\'s this problem related to "update schema" step not taking into account that type inference is disabled for sitepage.context?
if generating pages from markdown and having a relatively positioned container in template that is generated into, window doesn't scroll to header, because element.offsettop takes offset from relative parent.
fresh gatsby instance created using the command `gatsby new my-themed-blog ` is printing a "functions that are interpolated in css calls will be stringified" error in browser console <img width="1371" alt="screen shot 2019-12-28 at 10 42 29 pm" src=" ">
we have a shop running, built with shopify api and gatsby
we have setup aws pipelines running after each shopify product/page/collection update to rebuild gatsby page.
we cache gatsby - if we drop the cache completely build time will rise to ~20 minutes (now it takes 8 min)
the issue which we are experiencing is that after we unpublish or remove a product/page the cached broken gatsby page is still shown until we clean gatsby cache on production
![em]( the server is responding with a static 404 html page
is there a chance it automatically updated by the react side of the page? like it finds reference somewhere in its static json, cached, pages and serves its content despite it?
the latest change introduced with pr #20258 causes a maximum call stack size exceeded error for me
running `gatsby develop --host 0.0.0.0` throws the error that i inserted below
downgrading to `gatsby-source-contentful@2.1.72` helps solve the issue.
according to documentation the pixel density of a processed image should be retained, but it's not
images in 144 44 resolution are displayed in twice the size they were intended to be displayed as a result.
when building my gatsby site, i'm seeing the following errors thrown even though my posts are written in plain markdown: on my personal site ([github repo]( i get it for all of these posts (there's no pattern that i'm seeing that makes them unique):
getblurb.js:5 {path: "blog/2019-09-02/change-default-shell-zsh/"}
getblurb.js:5 {path: "blog/2019-11-14/ssh-into-user/"}
getblurb.js:5 {path: "blog/2019-11-04/useeffect-basics/"}
getblurb.js:5 {path: "blog/2019-11-03/global-node-package-management/"}
getblurb.js:5 {path: "blog/2019-04-17/writing-is-the-beginning/"}
getblurb.js:5 {path: "blog/2019-10-22/cannot-read-property-match/"}
getblurb.js:5 {path: "blog/2019-09-15/compression-tar-vs-zip-vs-rar-vs-gz/"}
getblurb.js:5 {path: "blog/2019-09-07/adding-prettier/"}
getblurb.js:5 {path: "blog/2019-04-30/git-rename-branch-locally-and-remotely/"}
getblurb.js:5 {path: "blog/2019-01-04/better-form-submissions-with-event-preventdefault-and-htmlformelement-reset/"}
getblurb.js:5 {path: "blog/2018-08-12/the-best-time-to-get-started-was-yesterday/"}
``` ```shell
the graphql query from /users/stephen/_coding/personal/gatsby-bug-repo/bug-repo/src/pages/page-2.js failed
errors: this[ordered_map[node.ordered]] is not a function graphql request:5:9 4 | node { 5 | excerpt(format: markdown) | ^ 6 | fields {
url path: /page-2/
context: {}
plugin: none
query: query indexblogquery { allmarkdownremark { edges { node { excerpt(format: markdown) fields { slug } frontmatter { title } } } } }
'gatsby develop' reports a missing dependency issue after installing (with yarn) a starter project as per docs
after installing with npm 'gatsby develop' works fine
the issue seems to be related to the **optionaldependencies**
perhaps they are handled differently by yarn and npm
if i manually install ink and ink-spinner (using yarn) then run 'gatsby develop' it works.
fixes and allows the shopify plugin to work with shops that run on a custom domain
see the ticket for a discussion of the issue.
this pr fixes file inference on fields other than `[a-za-z0-9_]` which was broken before
take an example: ```js createnode({ id: `1`, "file-here": `./file_1.jpg`, parent: null, children: [], internal: { type: `test` }, })
``` before this pr, `file-here` was always inferred as `string` not `file`
but if you were to change the field name to `file_here` it correctly inferred it as `file`
after this pr both `file-here` and `file_here` are inferred as `file` (and any field with special characters in general)
### documentation
n/a ## related issues
fixes #20151
there are missing `https://` in the connected airtable in the events table for listing events on page: ### option a fixing data in the airtable ### option b add a check for the `https` to the link in `www/src/components/events/event.js` #### link 1
buld hackathon november 17, 2019 (coimbatore, tamil nadu, india) #### link 2 software freedom day september 21, 2019 (balkumari, lalitpur, nepal) #### link 3 software freedom day september 21, 2019 (balkumari, lalitpur, nepal) #### link 4 startup weekend youth edition november 15, 2019 (dubai,united arab emirates)
when using the `gatsby-image` `<img fluid={...} alt="..." />` in voiceover this results in a blank item where voiceover does not speak anything when you navigate into the item before the actual image item.
after a site change has occurred, gatsby's `prodloader` component loader errors on page load
after a refresh this fixes itself, which leads me to believe this is `gatsby-plugin-offline`
i stupidly didn't screenshot the error, however i remember the places it occurred
inside the `prodloader` constructor, it occurred during `asyncrequires.components[chunkname]()` due to the function call occurring on something that isn't a function
this does somewhat confuse me as the `chunkname` should not have changed, as no page templates were changed
only the contents
this also leads me to think it could be a race condition somehow? or for some reason the `asyncrequires.components` map hasn't yet been filled.
hi guys i still have some issues with a script tag changing html in my gatsby template, i found that for some reason if the function is fired multiple time with setinterval then it works there (it used to work in the live repo too but now for some reason it stopped working as well)
i have been working on a project using gatsby in conjunction with netlify cms and repeatedly ran into the graphql error \'field "image" must not have a selection since type "string" has no subfields\' when querying my page markdown files
it turned out that this occurred only when the name of the image's parent node contained a hyphen
this issue has previously been raised ( but was never resolved as it was closed by gatsbot.
i am trying to import a component to a blog post using `.mdx` file
there are no build errors, just console errors as detailed below.
modifies any path provided for a manifest icon to be prefixed with appropriate path or asset prefix
currently this affects all provided paths including those from manual, hybrid, and automatic modes
i think this makes the most sense, not sure if there will be any edge cases that need a work around
this change could potentially create a breaking change for people using asset prefix in manual/hybrid mode who have provided full paths to work around the plugin not handling this for them,
### documentation i haven't written any, do we think we should document this change in behavior? ## related issues fixes: #18497
i get the error : `react is not defined` when using fragment jsx syntax(<></>) inside an mdx file when using gatsby-plugin-typescript (bug originally reprorted here :
on build, the following error is thrown `"gatsby-source-graphql" threw an error while running the sourcenodes lifecycle:`; ` typeerror: createresolvetype is not a function`.
i found this issue in my continuos delivery process and was able to replicate locally after reinstalling node modules to get the latest version of `gatsby-source-graphql`, that was published to npm about 1 hour ago, 2.1.26
before, i was running "gatsby-source-graphql": "^2.0.18"
there seems to have been a regression and an error similar to the one reported in #16703 and fixed in #19288 is effected if `markdowncaptions: true` is specified in the `gatsby-remark-images` configuration within `gatsby-config.js` the error is the same, but the reported call stack is a little different.
i'm writing a transformer plugin in typescript
when calling `createparentchildlink`, typescript complains that i've not set owner in the child node
however, i believe the owner is set by gatsby itself
the definition of `createparentchildlink` is: ```ts createparentchildlink( args: { parent: node; child: node }, plugin?: actionplugin ): void
the issue is that yarn and npm will chmod a bin file on install
when gatsby-dev copies files over, the copied file needs to be chmod'd again
also in here, i noticed that gatsby-dev was copying over `__mocks__` files, so those were added to the ignore list
## related issues fixes #18809
as outlined in the number of `jest-worker` instances created to build the static html does not respect the number specified by the environment variable gatsby_cpu_count
this can result in `enomem` when running in a containerised environment
this pr stops forcing the `ignoreenvvar` argument to `true`
#l4 as a result of this change, we stopped experiencing enomem issues, but also a bump in page generation speed
## related issues
## tests
i'm happy to add any tests for this if required
sorry if this pr is premature.
scu is called on updates, not on mount, so if there are no resources, initially they are never fetched.
when having an error in a staticquery / usestaticquery the resulting error gets output twice
![image](
given there is a template that contains a graphql query
given there are no pages created with this template
given gatsby-source-filesystem plugin is configured
given new pages are created on adding new files to local file system
given gatsby develop is running
when a new file is added to filesystem and a page created for this file programmatically
when the page is opened in the browser
then there is a typeerror
after the changes made in specifically [these]( #diff-ac5196f8e8e35e4455b30b9164e3c45br148-r158) lines, my website no longer builds successfully
this is because async-requires.js previously imported components like this, which worked great:
``` "component---cache-page-templates-example-jsx": () => import("c:\\\\git\\\ exus-ui\\\\website\\\\.cache\\\\page-templates\\\\example.jsx" /* webpackchunkname: "component---cache-page-templates-example-jsx" */),
``` after the recent change, components are now imported like this:
"component---cache-page-templates-example-jsx": () => import("page-templates/example.jsx" /* webpackchunkname: "component---cache-page-templates-example-jsx" */),
``` it works if i change it to import files using ./ at the start:
import("./page-templates/example.jsx" /* webpackchunkname: "component---cache-page-templates-example-jsx" */)
the templates are dynamically generated so need to be in the cache folder so that they get cleaned up during ```gatsby clean```.
when using the default favicon set produced by `gatsby-plugin-manifest`, the icon used by firefox looks low-res (on my retina macbook)
**firefox** <img width="157" alt="screenshot 2019-12-01 at 10 41 38" src=" ">
<img width="314" alt="screenshot 2019-12-01 at 10 41 38" src=" "> **chrome** <img width="249" alt="screenshot 2019-12-01 at 14 14 30" src=" ">
<img width="498" alt="screenshot 2019-12-01 at 14 14 30" src=" ">
i have read the issue described in #15486 but i seem to have a slightly different use case, and can't get the workaround to work for myself
basically, the site has switched from md to mdx, but when i use the workaround of renaming `gatsbyremarkplugins` as just `plugins`, the autolink headers vanish and don't appear when you hover on a title and images do not load at all
if i leave the plugins section named as `gatsbyremarkplugins`, images load twice, once blurry and once properly and the auto link icons show permanently next to headers, and scroll incorrectly when you click them
the image below shows what happens when the `gatsby-config` is written like this:
{ resolve: `gatsby-plugin-mdx`, options: { extensions: [`.mdx`, `.md`], // commonmark mode (default: true) commonmark: true, // footnotes mode (default: true) footnotes: true, // pedantic mode (default: true) pedantic: false, // github flavored markdown mode (default: true) gfm: true, // plugins configs // plugins: [`gatsby-remark-images`, `gatsby-remark-autolink-headers`], gatsbyremarkplugins: [ { resolve: `gatsby-remark-autolink-headers`, options: { classname: `header-link-icon` } }, { resolve: `gatsby-remark-images`, options: { linkimagestooriginal: true, maxwidth: 1000, wrapperstyle: result => `width: 100%;margin-left: 0;`, } } ], } },
<img width="1680" alt="screenshot 2019-11-28 at 12 18 14" src=" "> if i change the code to rename `gatsbyremarkplugins` to `plugins`, as described in a few issues as a workaround, i get the following view (with header links not showing at all, even on hover): <img width="1680" alt="screenshot 2019-11-28 at 12 20 36" src=" ">
after updating gatsby from 2.17.7 to 2.18.4, running any kind of gatsby command causes an error
there is literally no context though
> gatsby clean the above error occurred in the <storestateprovider> component: in storestateprovider in app react will try to recreate this component tree from scratch using the error boundary you provided, app.
warning: app: error boundaries should implement getderivedstatefromerror()
in that method, return a state update to display an error message or fallback ui.
> gatsby build the above error occurred in the <storestateprovider> component: ...
html pages stored in the "static" folder now return 404 errors using "gatsby develop"
that was not the case with the previous version of the gatsby cli
(i am using gatsby-cli@2.8.14 ) the html pages still show up correctly when using "gatsby build" followed by "gatsby serve"
other extensions (.pdf, .css, .js, etc.) still show up correctly
only ".html" and ".htm" extensions are affected.
`gatsby-remark-images` inside `gatsby-plugin-mdx` seems to be completely breaking `styled-component` functionality if trying to render images inside a styled-component container `<div>` in `.mdx` files.
the options from gray-matter in gatsby-transformer-remark not working
```javascript //gatsby.config.js const toml = require("toml") module.exports = { plugins: [ ...
{ resolve: `gatsby-transformer-remark`, options: { excerpt_separator: ` `, engines: { toml: toml.parse.bind(toml), }, language: "toml", delimiters: "+++", }, }, ...
``` throw error ```bash expected "\ " but end of input found
seems like localfile node from gatsby-source-contentful is missing in graphql with the release of gatsby 2.18.0
worked in gatsby 2.17.17
gatsby 2.18.0 missing localfile:
![gatsby_localfile_2 18 0]( gatsby 2.17.17 not missing localfile:
![gatsby_localfile_2 17 17](
page's **next link ([gatsby brand identity]( goes to home page.
upgrading to `2.18.1` (`2.17.x` is fine) generates a bug in my code, where i'm using `createresolvers` with `createremotefilenode` exactly as described here: #feeding-remote-images-into-gatsby-image
inline code (i.e
`code`) isn't included in excerpt when using `gatsby-remark-prismjs`.
i use mdx with contentful
when i use `gatsby-remark-images-contentful` plugin and build the project
it throw me the error (posted bellow)
i have created a separate [repo]( for the `gatsby-remark-images-contentful` where i [required]( the `createcontentdigest` directly from `gatsby-core-utils`
in this case, plugin working correctly
i think when the `gatsby-plugin-mdx` load the plugins, it's missing the `createcontentdigest` function, and therefore error occurs.
i recently tried using `gatsby-plugin-schema-snapshot` to create an explicit snapshot of the schema for a project that uses `gatsby-source-contentful`
this works as expected with the exception of longtext fields in contentful
per the [documentation]( #a-note-about-longtext-fields) longtext fields should actually be an object rather than a string
generated type using `gatsby-plugin-schema-snapshot` for a field named `body` which is a longtext field in contentful
type contentfulpostbodytextnode implements node @dontinfer { body: string
this causes the following part of the query to fail if the actual content doesn't exist: ``` body { childmarkdownremark { timetoread html excerpt(prunelength: 320) }
i have a blog with gatsby and every time i update an existing blog posts .md file, the gatsby develop command crashes with the following error:
field "featuredimage" must not have a selection since type "string" has no subfields.
when using `gatsby new <starterurl>`, where starter uses `husky` (to be used together with `lint-staged`), husky fails to install complaining: ```sh
husky > setting up git hooks
command failed: git rev-parse --show-toplevel --git-common-dir
fatal: not a git repository (or any of the parent directories): .git
husky > failed to install
``` i have a suspicion, that while `gatsby new` [changes node process directory to install starter's packages]( #l105), `$git_dir` points to some different directory.
variables imported from a sass stylesheet are undefined on `gatsby build`, but work fine on `gatsby develop`
this results in obscure bugs that only manifest themselves on first page load in production
i believe this might be the cause of some of these 'mysterious' issues where `gatsby build` styles differ from `gatsby develop`, since this probably also happens to each theme or plugin that uses preprocessor imports.
to ensure reproducibility of my build environments, i'd like to package my build dependencies with nix package manager
this has the side-effect of `node_modules` becoming read-only to ensure immutability for integrity and security (technically it gets located under read-only mount)
unfortunately, gatsby expects files under `node_modules` have writable mode when it copies files into its `./cache`, resulting in errors like the following: ```
gatsby build
success open and validate gatsby-configs - 0.021s
success load plugins - 0.021s
success onpreinit - 0.007s
success delete html and css files from previous builds - 0.015s
success initialize cache - 0.009s error eacces: permission denied, open '/.../.cache/api-runner-browser-plugins.js'
i have problem with 301 redirects adding trailing slashes (/path => /path/) only when i build+serve my site (gatsby build && gatsby serve && open => i get redirected to
doesn't happen using gatsby develop.
for some inputs `excerpt(format: html)` crashes and return `null` (without crashing entire query run)
i was working with @pieh and discovered an issue with how gatsby remark transformer creates excerpts for posts
using my blog as an example, the transformer works appropriately for `html` on almost all of my posts, though we found at least one error
![screen shot 2019-11-14 at 8 49 37 am]( ![screen shot 2019-11-14 at 8 39 06 am]( some of the experiments i ran to try to narrow this down:
switch from `html` to `markdown` it works:
![screen shot 2019-11-14 at 8 41 26 am](
the default `plain` doesn't work because it strips out any code, but it doesn't error
![screen shot 2019-11-14 at 8 42 14 am](
remove the image that would appear in the excerpt
this seems to be where the error occurs and when i remove the image from the first 200 characters (the length of my excerpt), the `html` excerpt works as expected
![screen shot 2019-11-14 at 8 54 03 am]( the query i'm using is:
{ allmarkdownremark( filter:{frontmatter:{title:{eq: "repeat a terminal command in unix"}}}, sort: {fields: [frontmatter___date], order: desc}) { edges { node { excerpt(format: html) fields { slug } frontmatter { date(formatstring: "mmmm dd, yyyy") publish(formatstring: "mmmm dd, yyyy") title } } } }
anchor links are not responding as normal when using the `shouldupdateonscroll` method within `gatsby-browser.js`
the page does not move at all.
adding `/index` to url shows a blank page.
the screenshot service used by gatsby-transformer-screenshot is incorrectly marking sites as offline, resulting in missing screenshots
perhaps the screenshot service is incorrectly caching failed screenshots?
`gatsby develop` hangs
but unlike the issues experienced by people in [#17131]( this is not related to any connection or processing issues - it appears as if the spinner gets stuck and the only choice is to either restart the process (which i was doing until i discovered the trick) or resize the terminal window
now i just keep my window shaking to get it going
please see the other people with issue at bottom of thread on #17857 i am opening this so this issue can focus solely on the terminal resize issue.
there's some strange behaviour happening with i use an entity reference inside a paragraph with drupal
i can see the json:api is formatting everything as i expect
if i have an entity reference field on its own in a content type gatsby can see the data and i am able to query values of the reference in my local graphiql instance
however, as soon as that is nested inside a reference it just returns `null` i\'ve created two fields within my "page" content type
<img width="804" alt="screenshot 2019-11-12 at 14 59 13" src=" "> `field_test` an entity reference field `field_test2` a paragraph field (entity reference revisions)
inside that field, there is an entity reference field called `field_embed` which is identical to `field_test` <img width="748" alt="screenshot 2019-11-12 at 15 00 03" src=" "> on my content that i am querying, i\'ve referenced the same content
"travel tip-offs: the best places to visit in august" (node 56 in drupal) <img width="1474" alt="screenshot 2019-11-12 at 15 01 24" src=" ">
when using an image transformed with gatsy-plugin-sharp, the traced svg was cached without considering `fileargs`
this resulted in use of the same svg for all instances of the same image and a misalignment between image and traced svg if the image was used with different cropping options
this pr adds the necessary `fileargs` properties to the cache key which fixes the misalignment between image and traced svg
## related issues closes #12008
this updates **gatsby-transformer-javascript-frontmatter** with support for typescript files while parsing
## related issues fixes #19253
i'm following the plugin [instructions]( #shell-prompt) to designate output lines in a code block, but what's rendered doesn't match the lines i'm specifying.
cannot get access to fields we export from typescript files
looks like the plugin runs through babel/traverse which fails when trying to read typescript more specifically interfaces.
the command `gatbsy develop` with https option (-s) fails if no name is specified in the package.json file.
when trying to use the `resize` method from `gatsby-plugin-sharp` with a parameter of `base64: true` i get the following error: ```
errors: cannot read property 'toformatbase64' of undefined graphql request:4:7 3 | nodes { 4 | resize(width: 20, base64: true) { | ^ 5 | src
i created a schema with `actions.printtypedefinitions`
here is part of the output:
type imagesharp implements node @childof(types: ["file"]) @dontinfer { fixed(width: int, height: int, base64width: int, jpegprogressive: boolean = true, pngcompressionspeed: int = 4, grayscale: boolean = false, duotone: duotonegradient, tracesvg: potrace, quality: int, toformat: imageformat = no_change, toformatbase64: imageformat = no_change, cropfocus: imagecropfocus = attention, fit: imagefit = cover, background: string = "rgba(0,0,0,1)", rotate: int = 0, trim: float = 0): imagesharpfixed resolutions(width: int, height: int, base64width: int, jpegprogressive: boolean = true, pngcompressionspeed: int = 4, grayscale: boolean = false, duotone: duotonegradient, tracesvg: potrace, quality: int, toformat: imageformat = no_change, toformatbase64: imageformat = no_change, cropfocus: imagecropfocus = attention, fit: imagefit = cover, background: string = "rgba(0,0,0,1)", rotate: int = 0, trim: float = 0): imagesharpresolutions @deprecated(reason: "resolutions was deprecated in gatsby v2
it\'s been renamed to \\"fixed\\" ") fluid( maxwidth: int maxheight: int base64width: int grayscale: boolean = false jpegprogressive: boolean = true pngcompressionspeed: int = 4 duotone: duotonegradient tracesvg: potrace quality: int toformat: imageformat = no_change toformatbase64: imageformat = no_change cropfocus: imagecropfocus = attention fit: imagefit = cover background: string = "rgba(0,0,0,1)" rotate: int = 0 trim: float = 0 sizes: string = "" """ a list of image widths to be generated
example: [ 200, 340, 520, 890 ] """ srcsetbreakpoints: [int] = [] ): imagesharpfluid sizes( maxwidth: int maxheight: int base64width: int grayscale: boolean = false jpegprogressive: boolean = true pngcompressionspeed: int = 4 duotone: duotonegradient tracesvg: potrace quality: int toformat: imageformat = no_change toformatbase64: imageformat = no_change cropfocus: imagecropfocus = attention fit: imagefit = cover background: string = "rgba(0,0,0,1)" rotate: int = 0 trim: float = 0 sizes: string = "" """ a list of image widths to be generated
example: [ 200, 340, 520, 890 ] """ srcsetbreakpoints: [int] = [] ): imagesharpsizes @deprecated(reason: "sizes was deprecated in gatsby v2
it\'s been renamed to \\"fluid\\" ") original: imagesharporiginal resize(width: int, height: int, quality: int, jpegprogressive: boolean = true, pngcompressionlevel: int = 9, pngcompressionspeed: int = 4, grayscale: boolean = false, duotone: duotonegradient, base64: boolean = false, tracesvg: potrace, toformat: imageformat = no_change, cropfocus: imagecropfocus = attention, fit: imagefit = cover, background: string = "rgba(0,0,0,1)", rotate: int = 0, trim: float = 0): imagesharpresize
} enum imageformat { no_change jpg png webp
``` [full schema]( when i try to use this schema with
```javascript
actions.createtypes(fs.readfilesync(`schema.gql`, { encoding: `utf-8` }))
it throws with the following stack trace:
error: type with name "imageformat" does not exists - typestorage.js:44 schemacomposer.get [gatsby-site-builder]/[graphql-compose]/lib/typestorage.js:44:13 - typemapper.js:86 typemapper.get [gatsby-site-builder]/[graphql-compose]/lib/typemapper.js:86:44 - typemapper.js:612 typemapper.typedefnamed [gatsby-site-builder]/[graphql-compose]/lib/typemapper.js:612:23 - typemapper.js:707 [gatsby-site-builder]/[graphql-compose]/lib/typemapper.js:707:30 - array.foreach - typemapper.js:681 typemapper.makearguments [gatsby-site-builder]/[graphql-compose]/lib/typemapper.js:681:12 - typemapper.js:728 [gatsby-site-builder]/[graphql-compose]/lib/typemapper.js:728:20 - array.reduce - typemapper.js:724 typemapper.makefielddefmap [gatsby-site-builder]/[graphql-compose]/lib/typemapper.js:724:35 - typemapper.js:881 typemapper.maketypedef [gatsby-site-builder]/[graphql-compose]/lib/typemapper.js:881:20 - typemapper.js:642 typemapper.makeschemadef [gatsby-site-builder]/[graphql-compose]/lib/typemapper.js:642:21 - schema.js:1086 [gatsby-site-builder]/[gatsby]/dist/schema/schema.js:1086:52 - array.foreach - schema.js:1074 parsetypes [gatsby-site-builder]/[gatsby]/dist/schema/schema.js:1074:19
``` i am not an expert with graphql so i am lost.
my only clue is that `imageformat` is not a `type` but an `enum`
maybe we don't look for `enum`s therefore `imageformat` is not found at all and throws???
i am trying to use `gatsby-plugin-schema-snapshot` and it throws `typeerror: flatmap is not a function`.
this throws as well:
exports.createschemacustomization = ({ actions }) => { actions.printtypedefinitions({});
i have a custom `html.js` in the root of the `src` directory for a theme i have created.
however this is not being built in a site that consumes the theme
the `html.js` file seems to be completely ignored.
the develop mode is producing minified source code, which means i can't add breakpoints
processed images don't always get copied to public when needed
seems to be an overly aggressive caching.
when loading a page rendered by gatsby, the source for it is shown momentarily before it is rendered.
i generate events with the `createpage` action using an `event.js` template
but not all events are pre-generated using this method, so i also have an `event.js` page that has a `matchpath = '/:year/:month/:day/:slug'` to fallback and dynamically display unknown events.
this was working great, up to gatsby version 2.15.22
this is what runs at for example this is pre-generated:
and this is not:
the idea is to not generate all past events as it is resource-intensive
but with the recent modifications in gatsby about page metadata, this stopped working in my case, so i locked the gatsby version at 2.15.22
then i tried to upgrade again yesterday but even #18478 published in 2.17.3 does not fix it.
i am writing a source plugin in typescript
i have my source code (gatsby-node.ts in this instance) in a _src_ folder and am transpiling to the root
in order to have a strongly typed `sourcenodes` function, i am referencing the `sourcenodesargs` type from gatsby
this type contains the reporter object, which can be used to report activity whilst the plugin is retrieving data
unfortunately the [reporter documentation]( #reporter) is actually missing the docs for the `reporter.activitytimer` function which [can be used by plugins]( #l24) to report activities and statuses
it's this `activitytimer` function that has incorrect type definitions
the type definitions in gatsby's index.d.ts for `reporter` are incorrect and different from gatsby-cli's type defs for `reporter`
i believe (according to [this coment]( #issuecomment-543384184)) that gatsby uses the cli's reporter so the type definitions should match up
these are the 2 issues i've found in [gatsby's index.d.ts]( - the second argument of [`activitytimer`]( #l954) should be [optional]( #l219)
- the [returned `activitytracker` object]( #l957)'s status update method should be called [`setstatus`]( #l6) and not `status`.
gatsbyjs project works fine on nodejs v12.13.0 which is the current lts
when upgraded to nodejs v13.0.1, the npm install fails with a message of "error: not found: make" p.s
- i'm using nvm for managing nodejs versions
i have a site setup with gatsby and contentful
when running the preview server locally, if i make a change in a blogpost (one of our content types in contentful with its own query / createpage call in gatsby), when i reload the page, it does not show the updated content
however, if i make a change in a marketingpage (another one of our content types) the change is reflected in the page-data.json and in the browser
however, that data is updated correctly as visible by the ___graphql endpoint
digging into the system to see where the failure is happening, this line: #l89 ends up returning `undefined` instead of the page
this only seems to happen with a large number of blog posts, as if i trim down the amount of data in contentful, everything refreshes correctly.
schema customization api and a new `@childof` directive won't add a convenience argument for the root field (only happens when there are no nodes of the type)
it does add a convenience _field_ but not an _argument_
follow up after #18871
related to #15305
when using `@childof` in a type definition, it correctly assembles the parent-child relationship
however, deleting the parent doesn't delete the child unless you restart the dev server to clear redux
`createparentchildlink` works correctly.
when on a page e.g
`/test/`, i use `navigate` to replace the current location state to reference a marker on the page
navigate('/test/', { state: { marker }, replace: true })
``` even though i'm on the same page, the scroll position is set back to the top
i found this reference in the pakage: #l36-l46 to me this short circuit would never fire, as we are comparing two objects
shouldn't it rather be ```js
if (location.pathname === prevlocation.pathname) { return
``` the above is even described in `scroll-behaviour` #custom-scroll-behavior nb: this happens if i use navigate from the page prop or import @reach/router.
gatsby 2.13.50 uses a `^` to include `gatsby-cli`
this lead to in npm install causing us to pull in an incompatible version of the gatsby cli
![image]( this version causes the error: ```
the above error occurred in the <reduxstoreprovider> component: in reduxstoreprovider in app react will try to recreate this component tree from scratch using the error boundary you provided, app.
this pr does a few things
it upgrades `devcert` to `v1.1.0` to fix https issues
- ~the version is currently pointing to the release branch of my `devcert` fork, as a proof of concept~ - ~if/when `devcert` gets patched and published, i will update the version spec to point to the new version~
it adds a little functionality to trust self-signed, and privately signed, certs - if only flags `--cert-file` and `--key-file` are specified, it assumes it's self-signed, and tells node to trust it
- i've included a new cli flag, `--ca-file`
if the certificate is signed by a private ca, then include that ca's certificate using this flag in order for node to trust the cert/key pair
it adds functionality to collect the ca certificate path from `devcert` during the automatic setup, and tells node to trust it.
it updates the documentation to reflect the new changes/process
## tracking related external prs - [x] davewasmer/devcert#41
- [x] davewasmer/devcert#42 ## prerequisites - [x] devcert v1.1.0 ## related issues fixes #16212
fixes #14990
when you create a resolver that uses `context.nodemodel` a page dependency is not automatically added unless a path is specified, or you manually call `trackpagedependencies`
the [schema customisation docs]( #taking-care-of-hot-reloading) say: > when you retrieve nodes from the store with `context.nodemodel` methods, it is usually not necessary to do anything manually, because gatsby will register dependencies for the query results automatically
the exception is `getallnodes` which will not register data dependencies by default
it also implies that specifying a connection type in `gatallnodes` should be enough to add a page dependency
except hot reloading does not work unless you either specify a path or call `context.nodemodel.trackpagedependencies` in the resolver
```js // this does not add a page dependency: const things = context.nodemodel.getallnodes( { type: "blogpost" }, { connectiontype: "blogpost" } ) // neither does this: const things = await context.nodemodel.runquery({ type: "blogpost", query: { filter: { title: { eq: "a blog post"} } }, }) // this does work, but specifying the path manually should not be necessary: const things = context.nodemodel.getallnodes( { type: "blogpost" }, { connectiontype: "blogpost", path: context.path } ) // this will always work: const results = await context.nodemodel.runquery(...) context.nodemodel.trackpagedependencies(results, { connectiontype: "blogpost" })
in my browser firefox, page navigations are issued and then the website immediately refreshes which breaks the "single page application"
i am not sure if this is related, so i came here to report this issue
so after a page navigation, i see an error in the console from the service worker and then the page refreshes
> typeerror: messageapi[gatsbyapi] is not a function sw.js:106:39 which leads here: ```js
self.addeventlistener(`message`, event => { const { gatsbyapi } = event.data if (gatsbyapi) messageapi[gatsbyapi](event, event.data)
it seems that `gatsby-plugin-manifest` does not care about `assetprefix`.
custom `cache-control` headers are not output in `public/_headers`
in a monorepo project, adding gatsby-plugin-netlify-cms slows down the "building production javascript and css bundles" step
removing "gatsby-plugin-netlify-cms" from example/atsby-config.js brings build time back to normal.
highlighting comment needs to be visible in the examples for [code formatting: line highlighting]( #code-formatting-line-highlighting)
i fixed this behavior by adding the condition for highlighting only when classname is not `language-none`
so now if you add the language keyword `none` to code blocks in markdown, it will stop the highlighting behavior from `/www/src/components/code-block/normalize.js`
as suggested by @dschau #issuecomment-530470985
see result below
<img width="726" alt="screen shot 2019-10-09 at 12 41 53 am" src=" "> ## related prs
hey! i'm using the `gatsby-plugin-mdx` plugin and wanted to lock down my graphql typings/schema with `gatsby-plugin-schema-snapshot` to see how it would behave, but after running it twice, it doesn't seem to be picking up the file contents any longer and just breaks.
we are having issues when generating slugs for heading
we are using mdx
if the bove mentioned plugins are used together, line number have more lines than the actual code
it looks like it does not minus the removed comments for line hightlighter.
under the documentation describing how to use fragments with webp, the following appears: > if you want to automatically use webp images when the browser supports the file format, use the withwebp fragments
if the browser doesn support webp, gatsby-image will fall back to the default image format
while this is correct, webp images don't appear to render using the component from the gatsby-image package without also setting `toformat: webp` with `fixed` or `fluid` queries
this documentation should be updated to mention this, or if this is a bug it should be fixed.
we have an application with internationalization support
all pages created with gatsby-node createpages api
with garsby@2.15.22 and older there is normal behavior, but after update to 2.15.23 or newer (2.15.28), root page and localized versions of the root page displaying 404 template content
all other pages displayed correctly
if i roll back to 2.15.22 root page and localized versions displayed properly
this incorrect behavior is consistent in development and production
i do not have steps to reproduce, but expect other people to have same issue.
when i add a an empty line in a function in a jsx block of an mdx file `gatsby-plugin-mdx/loaders/mdx-loader.js` throws : ```
syntaxerror: unknown: adjacent jsx elements must be wrapped in an enclosing tag
did you want a jsx fragment <>...</>?
with `gatsby-plugin-offline` installed running `gatsby build` while `gatsby develop` is running causes for the service worker to be installed on the _development_ url
this causes major and somewhat non-obvious problems with hot reloading.
i've been experiencing random major slowdowns of `source and transform nodes` that don't appear to conform to the other posted issues
after managing to get it reproduced with the debugger running - i've found that deleting stale nodes from lokijs is the cause of the slowdown
when a large number of nodes become stale, this will take a very very long time, about 120ms per node
when there are 20000 stale nodes, this easily adds up to ~2400s
this is about the amount of time i'm seeing this step take whenever stale nodes need cleaning up
if there are a lot of stale nodes, would it make sense to just clear all of them and start again? in this case it is quite literally over 99% of the nodes that are stale.
when you use client only paths, if you refresh on any client only page the dom isn't properly updated
it causes the dom from the initial root page to stick around and breaks the other client side pages
this does not happen locally, but it happens in production environments both on netlify and s3/cloudfront i noticed this on my own project, where going directly to a client side route was adding the component into my root client side route's structure
so something like
// app/login
<div class="container"> <h1>login</h1>
``` and another component like
// app/profile
<div class="different-container"> <h2>profile</h2>
``` but instead in the browser i see
<div class="container"> <div class="different-container"> <h2>profile</h2> </div>
``` i am unable to reproduce using `npm run build && npm run serve` locally
in my gatsby project with gatsby `2.15.21` hot reloading is not working when editing existing markdown files (managed with `gatsby-plugin-mdx`).
when trying to run dev the build fails after upgrading to gatsby v2.15.24 from 2.15.22
``` error unhandled rejection cannot read property 'slice' of undefined typeerror: cannot read property 'slice' of undefined - index.js:138 [cco-gatsby-fe]/[gatsby]/dist/query/index.js:138:46 - lodash.js:497 arrayaggregator [cco-gatsby-fe]/[gatsby]/[lodash]/lodash.js:497:34 - lodash.js:4823 function.groupby [cco-gatsby-fe]/[gatsby]/[lodash]/lodash.js:4823:16 - index.js:138 object.groupqueryids [cco-gatsby-fe]/[gatsby]/dist/query/index.js:138:21 - develop.js:388 module.exports [cco-gatsby-fe]/[gatsby]/dist/commands/develop.js:388:17 ```
i've been working on a site that pulls content from local `.mdx` files
as part of my work on this site i wanted to start bringing in some content from contentful
the moment i tried to install the `gatsby-source-contentful` plugin i started getting errors that look like this: ```
"gatsby-plugin-mdx" threw an error while running the oncreatenode lifecycle: unknown: expected corresponding jsx closing tag for <entry> (16:3) 14 | print(error) 15 | }
> 16 | }`}</p> | ^ 17 | </mdxlayout> 18 | ) 19 | };undefined: unknown: expected corresponding jsx closing tag for <entry> (16:3) 14 | print(error) 15 | }
> 16 | }`}</p>
``` another example: ``` error #11321 plugin "gatsby-plugin-mdx" threw an error while running the oncreatenode lifecycle: unknown: expected corresponding jsx closing tag for <cdaarray> (15:27) 13 | .subscribe( 14 | new disposablesubscriber`}<cdaarray>{`() {
> 15 | cdaarray result;`}</p> | ^ 16 | <p>{` @override public void oncomplete() { 17 | new alertdialog.builder(context) 18 | .settitle("contentful")undefined: unknown: expected corresponding jsx closing tag for <cdaarray> (15:27) 13 | .subscribe( 14 | new disposablesubscriber`}<cdaarray>{`() {
> 15 | cdaarray result;`}</p> | ^ 16 | <p>{` @override public void oncomplete() { 17 | new alertdialog.builder(context) 18 | .settitle("contentful")
[gatsby-remark-images]( adds links to each image by default so that clicking on the image will open a new tab with the original image
however, the links are not created for images in markdown files if those markdown files contain raw html
for example, the following markdown file content will be correctly converted to a webpage with an image that is linked to the original image: ```md
title: hello world
date: "2015-05-01t22:12:03.284z"
description: "hello world"
--- ![chinese salty egg](./salty_egg.jpg)
``` however, adding raw html to the markdown will cause the image link to no longer be added to the converted webpage: ```md
title: hello world
date: "2015-05-01t22:12:03.284z"
description: "hello world"
--- <blockquote>i love <a href=" ">gatsbyjs</a></blockquote> ![chinese salty egg](./salty_egg.jpg)
the plugins page puts all query parameters (except for the first character) directly into the search box.
i have css modules working with `gatsby-plugin-less` in development (without having to use `.module.less`), however when i build the production site it's not working.
issue was automatically closed
reopening as new one
this issue is for gatsby-remark-prism plugin
when highlighting empty line it disappears due to rendering of empty span
![line-hidden-due-to-empty-span]( ex
in case line 3 is empty and lines 3, 5 and 6 should be highlighted the code will produce almost expected results but the lines 5 and 6 will have numbers 4 and 5 and line 3 will be not visible.
same issue as #11688; creating new issue since the previous one was marked as fixed with an attached code change
any gatsby site can fail to build with the following error provided you're building on windows and your cwd path is using a lower-case drive name: ``` error #85901 graphql there was an error in your graphql query: error: relayparser: encountered duplicate defintitions for one or more documents: each document must have a unique name
duplicated documents:
- ereposgrumpyv2gatsbystarterblogmdxsrctemplatesblogpostjs1876540457
- ereposgrumpyv2gatsbystarterblogmdxsrcpagesindexjs4125737639
i've gone through the documentation a dozen times now
i don't think there's anything i've missed, but i've been wrong before
mdx is configured with ```js { resolve: `gatsby-plugin-mdx`, options: { defaultlayouts: { default: require.resolve('./src/components/layout.js').default } } },
``` but my markdown files are rendered with no layout
layout works by manually importing in mdx, which i'd like to avoid
full source code is available [here](rawkode/modern-life) - preview available [here](
my gatsby site currently works on mac for all browsers but not for ie and edge on windows
on windows it'll just briefly show the page for less than a second and then display nothing
when i open the console it lists `<div id="___gatsby"></div>` with nothing inside the divs.
after installing the gatsby-plugin-mdx following instructions, it throws errors when starting.
when you visit the css does not load properly; the checkmarks are huge and the form is a mess
however, some css does work, like the bottom of the form and the footer/nav (these are from the seo component, though)
the weird thing is that if you hard refresh it does load properly..
a normal refresh following that will break it again
if you open the mobile nav it also seems to trigger the styles to be requested, as they load momentarily after.
this also seems to have started happening after i started using the gatsby-plugin-offline plugin so it could be related to that..
i also created a duplicate of the page at and it displays a white screen unless you hard refresh
here are the console errors on /trial/notregister/ :
app-47cd0a205929ec73be54.js:1 uncaught (in promise) typeerror: e.components[t] is not a function at r.loadcomponent (app-47cd0a205929ec73be54.js:1) at app-47cd0a205929ec73be54.js:1 ```
while trying to develop a gatsby plugin i get the following errors ```
warning: we noticed you're using the `usebuiltins` option without declaring a core-js version.
``` this is because `babel-preset-gatsby-package` does not specify corejs in the preset but `babel-preset-gatsby` does
callback is not a function when update gatsby related packages and react to latest.
i'm trying to redirect blog pages to a completely new location
i tried adding the redirect `/blog/* ` to `_redirects` file, but it only works in dev mode
then i found out you need to install `gatsby-plugin-netlify` in order to redirect pages, but that just breaks my netlify build
i don't know what else i'm missing
what am i doing wrong? any information / help would be greatly appreciated! <img width="1053" alt="cleanshot 2019-09-17 at 16 20 31@2x" src=" ">
i've built multiple sites/apps with **gatsby** already, but that's the first time i encounter such an issue
i'm working on an app based on **gatsby** and **material ui**
github issues reporting similar, but not the same behavior that i reviewed and tested #9911, #12360, #5100, #3741
**gif/recording of the issue **sometimes, on initial page load (server-side-rendered per my understanding) the styles get totally messed up
this does not happen on subsequent (client-side) rendered pages, but only on the initial page load
unfortunately, it occurs randomly and not on every build.** **setup**
the setup of gatsby and material ui is based on [mui's official gatsby example](
in short, `gatsby-plugin-material-ui` and changes to `gatsby-browser.js` and `gatsby-ssr.js` this very same setup, as described in the gh project itself, works perfectly fine on other projects
therefore, i speculate there's something that we're missing
- we do not use `styled-components` or any similar `css-in-js` library and such doesn't exist in `package.json`
- the only `.css` files we have are placed at the top of `gatsby-browser.js` like this
import 'slick-carousel/slick/slick-theme.css';
import 'slick-carousel/slick/slick.css';
import '~components/bar-bat-mitzvah/raleway-font.css';
- i tested using the `gatsby-plugin-material-ui`'s option for `injectfirst` [as described here]( #usage-with-styled-components-or-else), but without any success.
- clearing all "site data" from the developer tools console seems to fix the issue which might be a hint to something wrong with cached styles by the `gatsby-plugin-offline`
- in addition, i tested many of the solutions in the mentioned gh issues, but none of these worked.
the directory list of `gatsby-theme-notes` doesn't work because the link href uses backslashes instead of forward slashes
also, if we jump down one folder manually we get a white page.
when you use both a static query and page query in a file, it will override one of them even if i name the data variables differently.
i am working on a project using the gatsby-starter-default
when i run gatsby-develop, my project will spin up on localhost/8000, but it flashes in different css styles and will not stop hot reloading (even though no changes have been made during this time)
i had previously installed the gatsby manifest and offline plugins, but have since removed them from the config file
my project was loading properly without the flashing until today
i created a new gatsby-starter-default and did not make any changes to the repo
upon calling gatsby develop, localhost:8000 goes into an infinite loop and gives an error about staticquery.
the `gatsby-remark-images` plugin causes large blank space above images in rss readers that apply the page inline styles
this seems to be due to #14816, which moved the `<img>` tag positioning out of the `style` attribute and into a `<style>` tag that is not seen by rss readers
because of this, the `<img>` is not absolutely positioned over the background element, which causes either a large white space or a blurry background, depending on the html support in the reader
additionally, the image is not correctly sized.
it seems that the latest version of chrome (tested on v76) doesn't like the prefetch links for json files if they are used in combination with the `assetprefix` hosted on a different domain due to cors/corb concerns
<link rel="prefetch" href=" ">
``` **update**: looking at [/packages/gatsby/cache-dir/static-entry.js#l325-l335]( #l325-l335) it seems like this was added already any might have just been missed for parts of the code ([/packages/gatsby/cache-dir/prefetch.js#l16-l35]( #l16-l35))
having just upgraded to gatsby 2.5.15, `gatsby develop` started producing this error: > unhandled rejection encountered an error trying to infer a graphql type for: `localimage___node`
there is no corresponding node with the `id` field matching: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
if i perform a `gatsby clean` before every `develop` there are no errors
but as soon as i try to run `gatsby develop` on an existing cache, the errors kill the build
it appears that when running off cache, for whatever reason the `gatsby-plugin-remote-images` attempts to resolve before the `gatsby-source-thirdparty` plugin resolves, and everything fails
i've spent the day researching this, and have come up fairly empty
and i can't exactly tell if the issue is with gatsby, the `gatsby-source-thirdparty` plugin, or the `gatsby-plugin-remote-images` plugin.
`netlify-identity-widget` is always included in the app bundle, despite `gataby-plugin-netlify-cms` being configured not to use it
even then it shouldn't be included in the app bundle as it is only used on the admin page
repro based on [gatsby-starter-netlify-cms]( # to replicate 1
`git clone `
`cd gatsby-netlify-cms-bug-repro`
`npm install`
`npm build`
`npm run report` # result <img width="979" alt="screenshot 2019-09-11 at 20 09 47" src=" "> netlify-identity-widget is included in the app bundle, adding 166k
# expected netlify-identity-widget should not be included in any bundle
even if configured to use identity, it should only be included in the bundle for the `/admin/` page
# discussion the only import or reference to `netlify-identity-widget` is in the plugin's `cms.identity.js` which should be conditionally loaded from its `gatsby-node.js` and `netlify-identity-widget.js`.
looks like the plugin's `gatsby-node.js` _does_ receive the config correctly and _doesn't_ include `cms.identity.js` in the entries, however `netlify-identity-widget` is still included in the bundle
by commenting out the following lines in the plugin's `gatsby-browser.js`, i can prevent `netlify-identity-widget` from being added to the bundle
```javascript
if (enableidentitywidget && (routes.test(hash) || errorroute.test(hash) || accesstokenroute.test(hash))) { promise.resolve().then(function () { return (0, _interoprequirewildcard2["default"])(require("netlify-identity-widget")); }).then(function (_ref2) { var netlifyidentitywidget = _ref2["default"]; netlifyidentitywidget.on("init", function (user) { if (!user) { netlifyidentitywidget.on("login", function () { document.location.href = __path_prefix__ + "/" + publicpath + "/"; }); } }); netlifyidentitywidget.init(); }); }
``` not that without these lines commented out, i can place a console.log that confirms that `enableidentitywidget` is `false` as expected, and that the promise body of the `if` is never run
however gatsby still includes `netlify-identity-widget` in the bundle
looks like something has changed recently in gatsby core which means that dynamic importing is not working correctly
# relevant libs - `"gatsby": "^2.15.14"`
- `"gatsby-plugin-netlify-cms": "^4.1.14"`
- `"netlify-cms-app": "^2.9.7"` # plugin config ```
{ resolve: `gatsby-plugin-netlify-cms`, options: { htmltitle: `admin`, enableidentitywidget: false, }, }
``` there is an old, possibly related bug:
*_copied from the issue description_*:
between version 2.8.8 and 2.9.0 of gatsby a change was made that caused the configured pathprefix to be stripped from the path of pages that start with the same prefix
i will try my best to investigate the potential solution presented by the issue reporter, by modifying the `trimpathname` function so that it only strips the prefix if it matches the specified pathprefix followed by a `/`, and try to think of any problems with that solution
## related issues
fixes #16457:
with the updated matchpath sorting from nested client only routes are not correctly displayed
i believe it is also related to this issue:
having a strange issue where all images are being loaded from a blog index page when visiting the blog post page.
i left a comment in #10844 but realized this is actually a separate issue.
when creating a page from a node and then deleting that node in a subsequent build, the page is deleted but it's `page-data.json` remains
the result of this is that pages aren't fully deleted
the html for the page is removed but the pages data remains
if you visit a page that should be deleted you'll see the 404 page, and then the deleted page will load afterwards
this is related to the global page manifest updates in gatsby 2.9.0 ( as the issue isn't present in v2.8.8 (the last version before 2.9.0) since there is a `manifest.json` file instead of individual `page-data.json` files
if i manually go into the `public/page-data` directory and delete the corresponding `page-data.json` file, the issue goes away (although gatsby still tries to fetch this file).
html for a page isn't displayed when visiting a site with gatsby-plugin-offline initially with js enabled, then disabling it.
service worker tries to prefetch links that has `rel="preconnect"` or `rel="dns-prefetch"`
i think links with these properties should be excluded
also, if the domain root page does not exist, it will throw an error in the console, which in turn drastically impacts page speed score
specific place in code:
#l44
when i start up the development server an error occurs
i am using gatsby-plugin-mdx so i can have jsx within my md files, but i have a case where if i write the word import, it takes it as an import call.
using documentation and highlighted a small snippet in a code tag but the browser tab crashes when trying to highlight the first character
see:
any of the scheduled workflows for github actions as of this past monday just stopped triggering
i saw this in some of my projects as well and got similar issues
when i used the migration tool to migrate they switch from "schedule" to "schedules" which is interesting as it worked for the past few weeks until now
i opened an issue with github\'s migrate cli about this to check if this is an actual bug or if the "schedules" field should also work
when we get some feedback from github on this i will take action with a pr to fix this if we need to.
when a localized page is loaded using the `<link />` component, the localized manifest is not selected in `<head>`.
when trying to apply additional classes to a code block when using `gatsby-remark-prismjs`, the classes get weirdly combined together
```jsx live preview
const button = () => <button></button>
```` gets turned into ```
<code class="language-jsxlive preview">...</code>
``` when this is expected: ```
<code class="language-jsx live preview">...</code>
``` for some reason, the language and first class are combined together.
`v0.23` of sharp ([changelog]( #v0230-29th-july-2019)) removed the deprecated `overlaywith` which is still in the gatsby-plugin-sharp master:
#l111 `gatsby-plugin-sharp` current master and current latest released `2.2.18` [declare sharp>=0.23]( #l26) as a dependency: this causes duotone to fail when rendering graphql.
[gatsby-remark-images] does not hide the blurred image on initial page load in development mode
when adding a `resolve` on a field that extends a custom interface, the field isn't accessible for filtering: #l79 ![image]( with the title - which comes from the frontmatter - it works: ![image](
as part of some work was made to make sure `publicloader` was used across the board as `window.___loader`, instead of `prodloader`
but there was an instance in `production-app.js` where the `prodloader` is still used instead of `publicloader`
by using the right public loader, plugins can override it when necessary
in circleci during the build process while generating image thumbnails, the console "freezes" and after some time a memory leak message is displayed: ```
unhandled exception spawn enomem
``` my main suspicion is that something is not respecting the `gatsby_cpu_count=2` environment variable so the workers can't balance themselves, probably image sharp?
i'm trying to use `postcss.config.js` file to configure postcss but the config isn't loaded at all
- according to [gatsby 2 migration]( #3-include-postcss-plugins-in-your-postcssconfigjs-file) the config file is supported - the plugin [gatsby-plugin-sass]( also use postcss but it doesn't support the config file too.
`gatsby-remark-images` produces and error if using `markdowncaptions: true` in `gatsby-config.js`
i am running `gatsby build` and the output does not contain all of my css (compiled from sass)
at first, i thought it was an issue with `gatsby-plugin-sass`, however, that is not the case, as it does not load plain css files either
meanwhile, `gatsby develop` produces the correct result (which could indicate this is an ssr issue)
i have a very similar project, with a similar configuration, that actually works as expected
can someone point out why and what i can do to fix it?
when exiting `gatsby develop` via ^c, the terminal is almost always left in a noecho state
i have observed this on macos and linux both.
the [current docs]( currently describes the type signatures of all the `get...` fields as being `reactnode[]`, while they are actually functions
this is also an issue when using type checking with jsdoc in the config files.
if your list of nodes contains non-pixel images like svgs, sqip will fail and break your side
can be workaround via multiple queries and filtering, but, lets just fix the actual issue
return `null` when a file type is not supported
ps.: this issue has the potential to break a site only through content editing :scream:
the gatsby-theme-blog produces an error when trying to use markdown footnotes
i can't see anything that i type after running `gatsby` from the vscode terminal.
adding [`gatsby-plugin-use-dark-mode`]( (my plugin) causes the gatsby build to fail with a javascript heap out of memory error, as other people have reported with other plugins (e.g
`gatsby-plugin-netlify-cms`), specifically when using `npm` (not `yarn`) and node.js prior to v12
i suspect this is happening due to `node_modules` being run through babel now and this plugin depends on [terser]( which is a fairly hefty import
if that is the case, do plugin authors need to be conscious of this and include modifications to the gatsby webpack config to remove the `dependencies` rule like [`gatsby-plugin-netlify-cms` did]( cc @wardpeet similar issues:
-
-
- also related:
- (original change)
- (game plan)
- (partial fix?)
`production-runtime.js` tests are failing with offline plugin configuration on ci
this was uncovered by #16493 in which we reverted a previous fix to enable using the cypress gatsby api integration correctly.
between version 2.8.8 and 2.9.0 of gatsby a change was made that caused the configured `pathprefix` to be stripped from the path of pages that start with the same prefix
the issue is still present in 2.13.52
upgrading my gatsby site (and all official gatsby plugins) from `2.10.0` to `2.13.51` is causing my dependencies to not be read correctly
not sure if this is related to #2118-2019-07-02 steps below (broken example has issue) have nothing but official plugins updated
[diff of branches](
there is an option to include `resolve-url-loader` support for sass, but it does not include that support for sass modules
this is causing issues when a sass script i am importing in a `module.scss` uses a `url()` call.
queries from themes that aren't being used cause an app to fail
it's sort of an abrupt experience to have installing a package make your app crash when it isn't configured
i'm not sure if we should check to make sure a theme is being used or if we should error in a more friendly way that says to configure the theme or use it.
`findmatchpath` is missing from the defaultloader, and it fails in certain scenarios
clicking on any gatsby plugin in the plugins library causes 404
in a linux instance, gatsby cli is breaking currently because it doesn't find `src/postinstall.js` from gatsby-telemetry when running `gatsby new` with npx.
when i run in localhost works ok with all the browsers including firefox but when it goes to production the firefox v68.0.1 looks misaligned caused (i guess) for this `.finally` function
### steps i tried i tried to use `"gatsby-plugin-compile-es6-packages": "^2.1.0"` to compile es6 features like they are using in #2177 but without luck
also i tried:
``` exports.modifywebpackconfig = ({ config, stage }) => { switch (stage) { case "build-javascript": const app = config._config.entry.app; config._config.entry.app = [require.resolve("./polyfills"), app]; break; default: break; } return config;
i'm not able to add breakpoints in chrome devtools after updating gatsby to version: `2.13.45`
`gatsby-plugin-layout` is unmounting and rerendering when using a programmatic navigate between pages
in my layouts/index.js file i am using a usestate hook like `const [time] = usestate(date.now())` and can observe that occasionally the layout component is rerendered causing the time to be altered
demonstration: in cases when the bug occurs and state is lost, the time would progress:
![image]( in cases when the bug does not occur and state is maintaned, the time would not progress:
![image]( this is absolutely not desirable as the intention is use the plugin to keep state, which is a well documented use case
i can see that when this occurs, the page "flashes white", **not** acting like a spa app
when the bug **doesn\'t** occur you can see that the layout is not rerendered and the 2nd page component is rendered in a smooth "spa" fashion
i am unable to recreate this with `<link />`, i.e
seems to be only a navigate problem
command `gatsby run develop --https` fails in the generate certificate step if the path of the project contains spaces
unpublishing an entry in contentful leads to a runtime error in `gatsby build`.
the `gatsby-plugin-feed` completely ignores all custom feed / channel properties
{ resolve: \'gatsby-plugin-feed\', options: { feeds: [ { output: "/rss.xml", title: "i am ignored :(", // ignored language: "en", // ignored }, ], }
``` ## suspect i believe this is a bug in the default `setup()` method:
#l32
`...rest` should be outside the `query` object
## workaround a workaround is simply to override the default `setup` method with a fixed version:
{ resolve: \'gatsby-plugin-feed\', options: { setup: ({ query: { site: { sitemetadata }, }, ...rest // outside of the query }) => { return { ...sitemetadata, ...rest, } } , feeds: [ { output: "/rss.xml", title: "they see me :)", // not ignored language: "en", // not ignored }, ], }
currently, gatsby exposes `oncliententry` api so plugins can interact with gatsby lifecycle before the page renders
one of the pieces that plugins can change is `loader`, like is doing
but, unfortunately, if a plugin changes `window.__loader`, those changes are not available on closure scopes window.___loader = loader apirunnerasync(`oncliententry`).then(() => { /* if a plugin changes window.__loader, loader variable inside the closer doesn't have those changes
*/ this pr makes it possible for plugins to change `window.__loader` ## related issues fixes
hi team! i've been encountering some inconsistencies with match path sorting
with two pages with match paths of `/*` and `/txt/*`, the `/*` page gets sorted before the `/txt/*` page
but if i include a `/app/*` page, that gets correctly sorted before `/*`
this was addressed by @pieh in but the fix seems incomplete.
![console]( webpack cannot find `public/page-data/404.html/page-data.json` because the real path is `public/page-data/404/page-data.json` i also got a travis log for you here #l370
with gatsby develop and firefox developer edition (latest version, 69.07b), firefox throws a security error exception when `app.js` checks `if (`serviceworker` in navigator)`, and hence the app cannot be used: ![securityerror](
the `why mdx?` link on #read-more-about-mdx is returning a 404
the linked page is
using the gatsby-plugin-material-ui following the example, i get styles that are ssr rendered that supercede my applied styles (which are based on screen width and stored in state)
if i navigate directly to a page that was ssr rendered, i have to trigger a state change in order to get the correct styles
this only happens in production build obviously.
`gatsby-transformer-remark` update from v2.5.0 to v2.6.0 breaks `gatsby-remark-prismjs` line-numbering when specified in a markdown file using the syntax:
```javascript{numberlines: true}
i repeatedly get an error in development after making changes
i haven't found a pattern, but it happens every 5 or so saves
it then works fine after i run `gatsby clean && gatsby develop` again.
if `oncreatepage` api "modifies" pages created by `gatsby-plugin-page-creator` (default src/pages) where it alters the page path, then gatsby crashes if the corresponding page file is deleted from the filesystem
i've created a glitch project which is available [here]( ~gatsby-page-deletion-issue) to make it a little bit easier to reproduce the issue.
when i go to something like #reporter and click the link to get the permalink, it jumps under the navbar.
while following the guide at i hit failing tests at step 6
master at time of writing is ea117e3d8 two issues:
- some tests fail
- testing framework doesn't exit
this branch resolves an issue where `gatsby-transformer-remark` is no longer supplying the configured `pathprefix` to gatsby remark plugins
this is happening because in [this commit]( #diff-488d99b036db541ee4a25a6991027b5dl262), the `pathprefix` variable was replaced with `basepath`, but `pathprefix` was left in the destructured function argument
since the destructured `pathprefix` variable isn't being used within the function, i removed it
this causes the property to remain in the `...rest` object, which in turn gets spread into the options provided to gatsby remark plugins [here]( #l233)
## related issues fixes #15787
if i try to import content to a programmatically processed mdx page, i must first reboot the server otherwise i get undefined.
when navigating to a non-existent path the 404 page flashes and disappears, and i see an empty page
this only happens when i use a pathprefix
my website is hosted on github pages and normally during the gatsby build step, i need to prepend a prefix path in order for links to work
after running `npm update` and `npm upgrade` it seems as if my prefix path still worked on normal links, but didn't work on images
i am using gatsby-remark-images for prefix paths.
when there are 0 images in drupal site, `gatsby-source-drupal` crashes with:
![d_ilntnx4ag4c-0]( this happens in this part of code - #l139-l154 plugin should determine array of file nodes first:
const filenodes = [...nodes.values()].filter(isfilenode)
``` and only use `asyncpool` (and reporter for logging) when there are any images.
within process-file.js, there's a `require` statement that's pointing to maybe an old path to where cpu-core-count.js should be
it should be changed to `gatsby/dist/utils/worker/cpu-core-count`
by default, sharp uses the number of cpus it detects, but this logic could be different than what gatsby defines as the number of cpus in cpu-core-count.js.
when using `gatsby develop` with a theme, the following error is printed in the terminal after a page is loaded in the browser: ```
error loading a result for the page query in "/404.html"
query was not run and
page not found /404.html
when errors occur within files **within directories**, the errors are reported on the command line and in the browser (this is good!)
however, when the error has been resolved by removing the offending files, the errors do not go away.
remove empty parentheses from graphql schema directives, because they lead to the error: ```
syntax error: expected name, found )
puppeteer itself cannot recognize utf-8 character (chinese, thai etc.) and fallback to square character instead ![screenshot]( ![screenshot]( i think there's a way to resolve this by set system locale to utf-8 in `dockerfile` before gatsby site was built, i will launch pr there.
<img width="1440" alt=" 2019-07-14 21 53 19" src=" ">
#15477 fixed the cause of broken links in all the package changelogs
this fixes those existing links to work correctly
used a regex to capture the ("/tree/master/packages/[a-z,-]+?/") and replaced with "/"
## related issues
#15477 #12755
i have an svg that i'm referencing directly in my css
i can see it render in the `gatsby develop` view of my site, but not when i build and serve.
the slug for post in `gatsby-theme-blog` are invalid url when using windows
this is due to the code that use `path.join` to create slug at #l171, which is fine in unix but problematic in windows because `path.join` returns backslash in windows.
the prism-powered codeblocks in `gatsby-theme-blog` currently seem to have a couple of issues: - any blank lines in the original code are completely ignored - the code is displayed as if it simply didn't have any blank lines
- they have a bottom margin of 0, which just looks weird.
running `gatsby develop` outputs the total pages created as the final output, this text is supposed to span the entire width of the command line however it is pushing onto another line ![image](
on @christopherbiscardi stream today, he set up a local copy of `gatsby-theme-blog` and the babel transpilation didn't work
it looks like something happened that is excluding local workspaces from the babel transpilation
for the next two weeks, you can watch the issue happen on in the videos section.
when doing a nested shadow in a site `site/src/theme-a/theme-b/index.js`, it doesn't use it and fallsback to `theme-a/src/theme-b/index.js`
that said, this issue doesn't appear when the shadowed file is not an `index.js` file cc: @christopherbiscardi
created a site with `gatsby-starter-blog-theme`, and there is a `unique key` error message in the gatsby develop terminal.
following jason's egghead course until step 5
the 404 develop page should show up showing the available pages, instead the pages stays blank and displays nothing.
with the latest stable gatsby-plugin-typescript / gatsby i'm experiencing this error in development mode: ```
element type is invalid: expected a string (for built-in components) or a class/function (for composite components) but got: object
you likely forgot to export your component from the file it's defined in, or you might have mixed up default and named imports.
``` if i build and serve, this error does not occur.
client-only routes broken in gatsby@2.13.2
i'm seeing the following errors and warnings for pages that are only rendered on the client
they are not using any queries, just plain ole react components fetching data from a rest api
warning in the terminal: ```
error loading a result for the page query in "/app/overview"
query was not run and no cached result was found.
page not found /app/overview
``` in the browser after build: ```
prefetch.js:33 get net::err_aborted 404 (not found)
``` @lekoarts is also seeing this issue, which you can see here:
not sure if this is the right place for this issue, but anyways~ i was trying to find out more about gatsby days
this post showed up in the blog search results, but doesn't load:
there's a lot of errors in the console for this page.
`slash` is being required by the `gatsby-node` script of `gatsby-plugin-offline`, however, it is not declared as a dependency in `package.json`.
wpcom's rest api differs slightly from the typical wp rest api, so using the header to determine number of items and number of pages does not work properly
for instance, if you have over 100 tags, the endpoint will not pull more than 100, and then posts that link to those tags will result in: ```
typeerror: cannot read property 'id' of undefined
``` if you're in a bind, you can remove some tags, and the build will proceed normally
i'm talking to a wp support admin to determine what the proper path forward is
i'll update this post as i learn more
when i get a chance, i'll make a pr to fix this issue, but i wanted to put up this issue in case others are using wordpress.com instead of the self-hosted version.
updated to the latest version of gatsby 2.13.1 and started getting the following error after running gatsby develop
error #85901 graphql there was an error in your graphql query: error: relayparser: encountered duplicate defintitions for one or more documents: each document must have a unique name
duplicated documents:
- sitetitlequery
i was able to fix this issue after removing gatsby-plugin-mailchimp apparently the mailchimp examples are creating a problem
just wanted to let everyone else know.
{ markdownremark(fields: {slug: {eq: "slug-here"}}) { id excerpt(prunelength: 120) }
} ``` returns entire post; not trimmed to 120 characters.
i'm getting error when running `gatsby build` for a second time (with cache present).
it happens only when i query image in 404 page.
i am receiving 404 errors when rendering images from mdx files after running `gatsby build`
initially i thought it happens to certain images but it happens randomly enough that i am not sure if it's an issue with the images or a config issue
i am importing `png` and `jpg`
this issue does not occur on local development environment `gatsby develop -h 0.0.0.0`, only when you build
i have tried to clear the `.cache` and `public` folders using `gatsby clean` before each build, and i do not know if it's an issue with the images, plugin, or mdx files.
when i use the `fluid` function and specify a `maxheight` value, it doesn't stick to that size
however, when i use the `fixed` version of the following, everything renders just fine
i have tried `gatsby clean`, `gatsby build`, and `gatsby serve` as well as re-installing all my node_modules
i'm not sure if this issue is related to #14988 but i didn't want to comment on it if they are separate issues..
but i apologize for duplicating if they are not
`@t2ca#1075` has also been kind enough to help me on discord but we haven't had any luck in the troubleshooting we did
i've done a search through the issues as best i can but i didn't find much in the short time i spent.
* in production: client-side routing works perfectly well until we refresh the page
if the current path is not root, say "/foo", the rendered page is a mixture of the the route component for root "/" and the route component for "/foo".
* in development: this issue does not exist.
as described in further detail in
the query logic for repeaters as described in the documentation like [repeater_field_name]_[post_type] does not work when the repeater is wrapped inside a acf group
i have not tried if this also applies if the wrapping element is something other than a group as well
at this point i am not sure if this is a bug that can or should be fixed but this should definitely be mentioned in the documentation if not so.
custom components in markdown, created following [this guide]( are nested in a paragraph element when rendered to the dom.
`gatsby develop --https` is failed to serve proper ssl certificate, resulting in binary termination
![term](
i am seeing a value for the menu link content in the graphiql browser as null when i would expect it to be an id
client-side routing does not seem to be supported any longer when serving the app in "production" (either through `gatsby serve` or some other static file serving)
an unrecognized route redirects back to the route where the client-side router has been mounted.
i'm having a hard time sorting out what package version where causes the issue, but when upgrading from gatsby 2.9.8 to 2.9.9 i now get this error when starting gatsby with a self-signed certificate: ```
error unhandled rejection fetcherror: request to failed, reason: self signed certificate - index.js:1455 clientrequest.<anonymous> [hello-epics]/[node-fetch]/lib/index.js:1455:11 - destroy.js:82 emiterrornt internal/streams/destroy.js:82:8 - destroy.js:50 emiterrorandclosent internal/streams/destroy.js:50:3 - next_tick.js:63 process._tickcallback internal/process/next_tick.js:63:19
``` my guess is it has to do with the upgrade of `node-fetch` in `gatsby-cli`
i'm trying to enable eager loading on images using gatsby-image.
gatsby pointing to 404 page when google web cache tried to open.
i've tried running `gatsby build` on my shared hosting, but the build failed
more specifically, it seems to fail due to the fact that one of the parent directories (in this case `/home`) does not permit listing of files
the `true-case-path` library, used by gatsby, throws an error because it is unable to `scandir` a component path's parent folder (in this case the component path is `/home/myusername/gatsby-site/src/pages/404.js`)
i think the build should proceed in this case, and handle this error silently.
an exported fragment containing a union throws errors on develop, however only in a component, not in a page component.
something changed between 2.9.8 and 2.9.9 that breaks gatsby sites with typescript
problem doesn seem to have to do with `gatsby-plugin-typescript`, but more to do with gatsby looking for an `index.js`
but please take that observation with a grain of salt.
code written as a local plugin behaves differently then if it were written directly in `gatsby-ssr.js`/`gatsby-browser.js`
i started with [this example]( from the material-ui repo, after seeing that their `<cssbaseline />` ([docs]( [code]( behaves differently in our app then in that example
i reduced the issue down to [a minimal reproduction]( based on the above repo
there are 3 commits there, the last (`77251e6`) of which causes a fouc, while the previous commit (`5022cb6`) works fine.
the only difference between them is that the local plugin was removed in favor of having it as part of the app's `gatsby-ssr.js` and `gatsby-browser.js`.
`gatsby-cli`'s `package.json` has `react` in `dependencies`
it makes all kind of unwanted behavior in monorepo setups
for example: if you have `react` installed in the parent directory (`./`) and gatsby site installed by `gatsby new` command on a child directory (`./site`) directory, it creates a nasty bug
if you use hooks in your application, this error pops up: ```
invalid hook call
hooks can only be called inside of the body of a function component
this could happen for one of the following reasons:
you might have mismatching versions of react and the renderer (such as react dom)
you might be breaking the rules of hooks
you might have more than one copy of react in the same app
``` and it is specifically caused by the point number 1 described in the error message
if you remove the parent directory's `node_modules` (i.e
`./node_modules`) everything works fine.
i have a repo that has a json file with author data for a blog i am making inside a folder `/src/data`: ```json
[ { "id": "crutchcorn", "name": "corbin crutchley", "description": "is a person who exists", "profileimg": "./crutchcorn.png" }
``` inside that same folder exists the file `crutchcorn.png` i am mapping this author data to the frontmatter by adding this into the `gatsby-config.js`: ```
mapping: { "markdownremark.frontmatter.author": `authorsjson`,
``` i noticed that when i was using `filter` query on `allmarkdownremark`, i am not able to query the author profile picture `childimagesharp`, but i am when using `sort`
eg, when running: ```graphql
{ allmarkdownremark(sort: { fields: [frontmatter___date], order: desc }) { edges { node { frontmatter { author { name profileimg { childimagesharp { fixed(width: 60, height: 60) { base64 } } } } } } } }
``` i get the base64 value i expect
however if i change the query to read: ```graphql allmarkdownremark(filter: {frontmatter:{author: {id: {eq: "crutchcorn"}}}}) {
``` i am only returned `null`s for the `profileimg`
this is true both in the ui and in the graphiql i have made a repo to reproduce the issue in question (though have not included a ui to reproduce, so graphiql will be able to verify the problem):
#### 2019-06-15: original problem statement passing state through @reach/router's `navigate` function works in gatsby v2.8.8 but not in v2.9.0 (nor v2.9.4, the latest version at this time)
this broke in #14359
declarative links pass state correctly (e.g
`<link to="/page-2" state={{ success: true }}>`)
#### 2019-08-23: update 1 the problem appears partially fixed as of gatsby v2.13.2 ([b8e2adc6]( specifically) for development mode (`gatsby develop`) but is still broken in production (`gatsby build` output)
also, instead of `null`, `location.state` is now `undefined`.
with the latest `gatsby-plugin-netlify-cms` package ( `yarn start` will throw error `typeerror: cannot read property "minimizer" of undefined`
this is caused by
because in dev mode `optimization` is indeed undefined.
in a project i am working on, i am using gatsby's `link` component within storybook stories
to get this working, i followed the instructions found [here in the gatsby docs](
this has been working fine for over 2 months now
however, when updating gatsby from `2.8.8` to `2.9.0`, storybook fails to build because of a gatsby `cache-dir` error
this is what is logged to the console: ```
error in ./node_modules/gatsby/cache-dir/loader.js
module not found: error: can't resolve './match-paths.json' in '/x/x/node_modules/gatsby/cache-dir' @ ./node_modules/gatsby/cache-dir/loader.js 15:0-44 97:32-42 @ ./node_modules/gatsby/cache-dir/public-page-renderer-dev.js @ ./node_modules/gatsby/cache-dir/public-page-renderer.js @ ./node_modules/gatsby/cache-dir/gatsby-browser-entry.js @ ./src/utils/universallink.tsx @ ./stories/misc/universallink.stories.tsx @ ./stories sync \\.stories\\.tsx$ @ ./.storybook/config.js @ multi ./node_modules/@storybook/core/dist/server/common/polyfills.js ./node_modules/@storybook/core/dist/server/preview/globals.js ./.storybook/config.js (webpack)-hot-middleware/client.js?reload=true
``` the important part of this error is the following: ```
error in ./node_modules/gatsby/cache-dir/loader.js
module not found: error: can't resolve './match-paths.json' in '/x/x/node_modules/gatsby/cache-dir'
``` from this, i could tell that the problem was originating from a change made in 2.9.0 to `cache-dir/loader.js`, so i went and looked through the update diff
i found the following lines added: #diff-06ce5193de7c2c01dd947a5001c147c3r6 on l7 of the file, `./match-paths.json` is being imported
on l6, there is a helpful comment noting that this file is "generated during bootstrap" (which i\'m guessing means that it is generated only when `gatsby dev` or `gatsby build` is ran)
as using gatsby components like `link` in storybook doesn't require you to run `gatsby dev` or `gatsby build`, this file isn't being generated, so when `loader.js` tries to import it, it results in the above error
from looking at the git blame, this change was introduce by so i'm tagging @moocar and @kyleamathews as they were the pr author and pr reviewer respectively.
the google tag manager (gtm) plugin for gatsby does not seem to guarantee that the gtm snippet is inserted immediately after the `body` tag, which is a requirement for google search console verification.
since today after i serve my static files, i got this notorious error: `uncaught error: missing resources for /`
after researching and trying to find out what happened, i was able to pinpoint it to component shadowing with themes
my setup is, that i have a theme that exports utility components and section components, basically behaving like a ui-kit
it's exported by an `export.js` file
now when i shadow a component, that i use, to let the user inject custom components in a certain spot and at the same time import something from the theme, this occurs in the browser
this happens whenever that component is rendered on the page.
gatsby-remark-images do not converts image path string node to file node when it is under the node with a dash('-') in the name
instead, it changes the path of the image to some weird invalid path with lot of `../`
my markdown file looks like this
logo-branding: other_projects: thumbnail: /assets/hp_project_letenky.png
so name of the `logo-branding` node is automatically renamed to `logo_branding`.
![screen]( but then string node is not converted to file node but instead path is changed from `/assets/hp_project_letenky.png` (output when gatsby-remark-images plugin is disabled) to `../../../../assets/hp_project_letenky.png`.
i just created a new project using the gatsby-cli
i ran gatsby-develop in the terminal and opened the project in vscode and deleted a file from there
upon deleting the file the output of the gastby develop command ran earlier is shown in the below screenshot
![image]( as we can see above, gatsby outputs that a file was deleted saying `file deleted at` but does not output the path of the file, which it should as why else the `at` would be there at the end of that sentence.
on the gatsby-starter (and others) when i set a duotone on an image query..
<staticquery query={graphql` query { placeholderimage: file(relativepath: { eq: "gatsby-astronaut.png" }) { childimagesharp { fluid( maxwidth: 200 duotone: { shadow: "#10c5f8", highlight: "#32cd32" } ) { ...gatsbyimagesharpfluid } } } } `} ```` all works well
however when i change the highlight and shadow colours it still renders the old colour choices
i have emptied all caches etc to no avail
i'm getting a series of warnings related to the `browserslist` package.
i can't override the settings following the warning instructions because i can't find
where the wrong properties are written.
while going through [part 6 of the gatsby tutorial]( i noticed that generated excerpt output is displayed without spaces between paragraphs
so instead of receiving "pandas are really sweet
here\'s a video of a panda eating sweets." the excerpt is "pandas are really sweet.here\'s a video of a panda eating sweets."
when i navigate to another page, new dom nodes are created, but old one aren't disposed or even cached.
transparent png image transform to webp does not create correct image
i have tested with the following script ```js
const sharp = require("sharp"); sharp("docker.png").webp().tofile("output.webp");
``` this produce a correct webp image which make me believe this is a gatsby problem.
```markdown
!["text"](./foo.png)
when people install gatsby with `--no-optional` gatsby breaks because ink is not being installed
we made ink optional because of node 6 #14233 we should fix our check here
#l4-l8 ```js
let inkexists;
try { require.resolve('ink') inkexists = true
} catch(err) {} if (inkexists && !isci) {
gatsby is giving me this false positive warning: > we were unable to find the declaration of variable "homepagequery", which you passed as the "query" prop into the usestaticquery declaration in
"~/gatsby-project/src/pages/index.tsx"
![image]( gatsby code that i assume is reporting this warning: #l213-l259 current workaround is changing this: ```jsx const data = usestaticquery<homepagequery>(query)
```jsx const data: homepagequery = usestaticquery(query)
i was previously experiencing #14186
after upgrading to gatsby-remark-images 3.x the situation has improved, but is still not working correctly
the blurred image only appears for a very short amount of time, and then is covered with a blank white rectangle.
not sure if this is working as expected or if it is even an issue with emotion: when adding styled components into a non-styled node, the compiler produces duplicate css class declarations.
images and icons are displayed really large on the screen before the page actually loads and renders everything correctly
lasts half a second or so.
the icons in the sections header for ecosystem and blog seem to be collapsing out of alignment when resizing the browser under 1000px
gatsby shopify source plugin throws unhandled timeout exception while building cache
when modifying the graphql query to use `first: 150` rather than `first: 250`, the cache is built and gatsby starts.
we heavily use markdown and, in particular, markdown code fencing for our code snippets
for example: ````markdown
hello, a code snippet is below ```js
var a = 'waddup'
var b = 'its dat boi'
```` we _also_ use some custom features, e.g
when building out gatsbyjs.org some of these code languages and features (titles) are not correct, and are therefore throwing a bunch of warnings
let's fix 'em.
since when using `showcaptions:true` `gatsby-remark-images` inserts the file name, when using the standard img snippet: ```
![](./img.jpg)
when calling `createremotefilenode` in `gatsby-node`'s `sourcenodes`, if a remote url fails to download (e.g
if it's a 404), the whole process crashes with an `unhandled rejection` error, even if we `.catch`
i'm seeing layout.css referenced after starting a new site with gatsby when using `gatsby develop` but i'm not referencing this stylesheet in my project.
when using node type mapping, queries for fields that are affected by it don't return items in the order that they were originally defined in.
![ezgif com-video-to-gif (1)]( on plugins page, the webpage has two scrollable containers one for list of plugins and another for plugin details
when the plugin details container is scrolled and then if you try to scroll the plugin list container it won't scroll unless you select a plugin
browser with this issue
google chrome - version 74.0.3729.157 browsers where it's working as expected
mozilla firefox
if node data has field name that can't be used in graphql (i.e
containing `?`, `(`, `)` characters etc), there is no quick way to define type without explicitly adding resolver that will pick from source using unsanitized field name
this is regression / behaviour change from gatsby@<2.5.0
`gatsby-image` has a run-time cache that is separate from the browsers own image cache
this cache tracks what images are loaded by assigning their `src` value in the fluid/fixed metadata as their cache key for lookup
this key is always the same despite multiple `src` values an image can represent(sizes and formats, and in future - [variants](
this is a non-issue provided the viewport is not resized (browser window, or on mobile when splitting the display area to accomodate another app, or an orientation change)
presently, at least with chrome, resizing the viewport only changes the image source when the viewport grows and a better source is available for a given size(`w` in srcset in combination with the `sizes` attribute)
this updates the `src`, if you were to copy the image address, but retains the current image loaded in until the new one is ready to replace
however, if you have since navigated to a different page which unmounted the image, resize the viewport and visit that page again, the image is freshly mounted but it's cache key now returns `true`, thus lazy loading and any transition effect is disabled
when `gatsby-image` supports image variants via the art direction pr, this bug will be further impacted when a viewport shrinks if it triggers a media condition for a source variant.
discovered this one the hard way tonight - it looks like pathprefix is not honored for links to files in the static directory as of v2.0.6
note (this is a clone of which was closed as "could not reproduce" some time ago, but can be reproduced now)
importing css with print media query doesn't work in development mode
styles described in css ignore the media query and apply by default, not only print mode.
however, this works correctly as expected in production mode.
circleci [builds]( failed with the following error: ```js error: spawn enomem - child_process.js:372 childprocess.spawn internal/child_process.js:372:11 - worker.js:80 exports.default._initialize [src]/[jest-worker]/build/worker.js:80:69 - worker.js:206 exports.default._exit [src]/[jest-worker]/build/worker.js:206:12 - child_process.js:254 process.childprocess._handle.onexit internal/child_process.js:254:12
if you use paths with no trailing slashes, the first page you navigate to on your site will be replaced when you click the first navigation link
as a result, using the back button from the second page will take you back to e.g
the blank-tab page in chrome
this occurs because `production-app.js` triggers a `navigate` call in reach/router to fix the trailing slash
normally, reach handles `navigate` as following (irrelevant details omitted): when you click a link, a `transitioning` variable is set to true in the reach history state (see #l59)
that variable is then set to false when `componentdidupdate` is called on the `locationprovider` (see #l86)
as long as `transitioning` is true, reach will use `replacestate` instead of `pushstate` (see #l49)
in this instance, because the router component has not rendered yet, `componentdidupdate` never gets called on the locationprovider, and so the `navigate` call (again, triggered by lack of trailing slash) causes `transitioning` to be set to true for the entire time you are viewing the first page loaded
so when you click any link from that page, the state is replaced, and the back button will not work
this could be fixed by having reach simply complete the transition in componentdidmount (maybe this issue should be posted there as well), or by making some change to gatsby to use the `navigate` api at a different time or in a different way
i don't understand gatsby well enough to make the pr for that particular change
for now, i've fixed my application simply by adding trailing slashes to every path.
google analytics captures incorrect page title when using google tag manager via gatsby-plugin-google-tagmanager
see solution below.
the issue related to this pr is in the "download all files" logic
the code is written in **parallel** which causes buffer and memory exhaustion issues when `createremotefilenode` is called
this is caused by unresolved promises in the call-stack especially when you have substantial pages and media entities
the use of `for` and `lodash` loops that do not respect resolving promises before continuing on to the next item in the loop is to blame
they currently overwhelm the call-stack with unresolved promises
i have simply refactored the code to be **serialised** using the appropriate for-loop functionality and voila! ## related issues #12848 [gatsby-source-drupal] "failed to process remote content" error on drupal images
also described in #10254
queries for `allmarkdownremark` and `allmdx` contain all entries that i can otherwise find from `allcontentfulblogpost`
these redundant entries are missing several fields that are found on the `contentful` queries that make them unusable `title`, `slug`, `node_locale`, to name 3
as #10254 concludes, i'm working around this by filtering them out, which is easy enough as they have no `absolutefilepath`
this isn't mentioned in the [`gatsby-source-contentful`]( plugin page, and the data returned is unhelpful enough that i'm not sure it's intentional
i can put together a repro, but as it relies on a contentful account it's a little awkward to set up
[i made a gist]( of the markdown + contentful query results.
installing a gatsby version older than 2.4.0 will install a newer version of gatsby link that's incompatible with the older gatsby.
when doing a query on markdownremark, fields added using createnodefields are not present
this occurs only after running `npm audit fix`, updating the gatsby package from 2.0.91 to 2.3.36 - gatsby-transformer-remark was unchanged from 2.2.0
with the previous version of gatsby, it worked fine
code is adding the fields in the setfieldsongraphqlnodetype method with createnodefield
console.log the nodes after calling createnodefield shows the fields correctly placed
i checked if the fields are present on the allmarkdownremark query in createpages and they were not
they were also not present in /src/templates/post.jsx, in the following query:
export const pagequery = graphql` query blogpostbyslug($slug: string!) { markdownremark(fields: { slug: { eq: $slug } }) { html timetoread excerpt frontmatter { title cover date category tags } fields { nexttitle nextslug prevtitle prevslug slug date } } }
as shown [here]( #diff-60a650c8008bf341b6e36303e102c9b1r106), a commit was made that made it into v2.3.35 that changed the `gatsbynode` type's name to just `node`
although this was a breaking change for those depending on the types, i thought it would be a simple thing to update and get our codebase compiling again
however, i was getting a strange error message when i updated the type (`gatsbynode`) to the new name (`node`): > type \'{ createpages: ((args: createpagesargs & { traceid: "initial-createpages"; }, options?: pluginoptions | undefined, callback?: plugincallback | undefined) => void) | undefined; }\' is missing the following properties from type \'node\': id, parent, children, internal
ts(2739) after looking further into the issue, i realised that gatsby already exports a separate type called `node` (that is related to [this]( kind of node), which can be seen [here]( #l1102-l1140)
this is what was causing the above error message, as this `node` type requires the `id`, `parent`, `children` and `internal` properties to be defined
the likely reason this mistake was allowed to slip through is because of [declaration merging]( in typescript
to fix this issue, please revert this name change made to this type (`node` -> `gatsbynode`).
several of our plugins require sharp@^0.21.3 which does _not_ resolve to the latest version of sharp
sharp@0.21.3 seems to have severe issues with node 12, therefore our plugins should be upgraded to account for this
however--we want to do so in a way that is transparent to the end user, and doesn't introduce breaking changes if e.g
only one plugin is updated but others aren't (or at least warn in this scenario in gatsby core!).
when i use `createremotefilenode`, i have an `error graphql error unknown type "imagesharpfixed"` node is created (available on `allfile`), but not in `allimagesharp`
including gatsby-plugin-emotion in the gatsby-config.js file makes the onrenderbody api unusable.
i'm working with the new gatsby-themes api and gatsby won't build my child theme if the parent theme is in a symlinked directory in the child's node_modules
this is the standard repo setup for a [rush monorepo]( and allows you to test against local changes very easily
could symlinked node_modules be supported? other js projects i've worked on which rely on the default node_modules resolution algorithms support this functionality.
newest version of node 12 has some api changes that require a newer version of sharp
see:
i've seen this issue before, and thought we fixed it months ago
the plugin library doesn't seem to render some kinds of images from readme files.
caching video with gatsby-plugin-offline works almost everywhere, except on safari after digging a bit, it seems that safari do some pretty weird stuff when loading video, i found [this blog post interesting]( a quick fix would probably be to exclude video files from the `gatsby-plugin-offline` cache, but i can't find a way to do so.
#13510 from @fk: > i noticed we don't currently catch (which is a stub, too) i don't have the time to figure out why this happens, and i'm not sure if there are others we are missing i believe this is due to some mishap in the findstubs method in the [stub-list.js]( file.
if a filesystem source contains a dangling symbolic link it will hang the source and transform nodes step.
after installing the gatsby dependencies `npm install` i noticed the following two packages are depreciated: ```
npm warn deprecated eslint-plugin-flow-vars@0.5.0: eslint-plugin-flow-vars has been deprecated in favor of eslint-plugin-flowtype@2.4.0 or higher npm warn deprecated coffee-script@1.12.7: coffeescript on npm has moved to "coffeescript" (no hyphen)
does `eslint-plugin-flow-vars` need to be updated to `eslint-plugin-flowtype`? it appears `coffee-script` is a dependency of a package.
a security vulnerability has [been uncovered in js-yaml](
we should update our packages wherever possible to ensure we are on the correct version.
while making a site using gatsby-source-wordpress i noticed that builds failed occasionally, with the error message `error cannot query field "localfile" on type "wordpress__pageacfhero_image" graphql/template-strings` i\'ve checked the sections in the docs with regard to issues querying images and null files, and have taken steps to address them ([this]( #graphql-error---unknown-field-localfile-on-type-image-field) one seems particularly relevant)
but here's the kicker: this issue happens seemingly randomly
in other words, the image is certainly not null, and is available, since it is being queried some of the time, but not at other times.
solved an issue with netlifycms not running on `localhost`, but unfortunately it only lets you use `/admin` url to access the admin-page
hard-coded stuff here:
#diff-4d1c9d2c489d6b95920275f753551be8 [the plugin itself has `publicpath` variable]( #publicpath) that lets you set the url to be different than `/admin`
the fix mentioned above doesn't play nice with this feature.
when using nested lists in markdown frontmatter (corresponding to arrays in arrays), path strings resolving to images are not transformed to file nodes
instead their types remain "string"
it seems like [this]( issue is related.
i wrote the issue about infinite loop in ie9 before
#12985 i found the code caused infinite loop in **.cache/production-app.js**
if ( // make sure the window.page object is defined page && // the canonical path doesn't match the actual path (i.e
the address bar) __path_prefix__ + page.path !== browserloc.pathname && // ...and if matchpage is specified, it also doesn't match the actual path (!page.matchpath || !match(__path_prefix__ + page.matchpath, browserloc.pathname)) && // ignore 404 pages, since we want to keep the same url page.path !== `/404.html` && !page.path.match(/^\\/404\\/?$/) && // also ignore the offline shell (since when using the offline plugin, all // pages have this canonical path) !page.path.match(/^\\/offline-plugin-app-shell-fallback\\/?$/) ) { navigate( __path_prefix__ + page.path + browserloc.search + browserloc.hash, { replace: true } ) }
``` when `location.pathname` doesn't match with `page.path` and not 404 page, replace the location
however, ie9 browser add trailing slash on url automatically.
and it makes that `location.pathname` is always different from `page.path`
for example, `/hello-world` url in ie9, always compare `/hello-world` to `/hello-world/` in code and then get infinite loop in ie9
i think that code need to be modified for trailing slash in ie9..
please fix it..
and if i override that code, please let me know..
thank you!!
in a minimal installation, export `wrappageelement` from `gatsby-browser` like: ```
export const wrappageelement = ({ element, props }) => { return <layout>{element}</layout>;
``` then in `layout` (shown here in typescript) put: ```
export const layout:react.fc<{}> = props => { return ( <> <div style={{ border: `1px solid red` }}>test</div> <div style={{ border: `1px solid blue` }}>{props.children}</div> </> );
gatsby-transformer-toml 2.1.8 uses `createdigestcontent` which is not a function
note that if i edit the plugin in place to use `createcontentdigest` (which is mentioned here the result is a successful compilation.
i'm using: gatsby, wordpress, and gatsby-source-wordpress, and acf on wordpress for my custom data
the issue i'm encountering is this: when a post is *unpublished* (from being published to a draft), and then re-published, the images (or almost all of them) become `null`
example graphql being used: ```graphql main_images { product_code image { title localfile { childimagesharp { fluid(maxwidth: 1200) { ...gatsbyimagesharpfluid_withwebp } fixed(width: 100) { ...gatsbyimagesharpfixed } } } } }
``` in the instance of this graphql field, the issue i'm having is that `localfile` will be `null`
the `title` in that query comes back fine, however
furthermore, it also seems that the wordpress api response is correct
it seems highly possible its a bug in `gatsby-source-wordpress`, caching related? help or advice would be much appreciated
other notes:
- unpublishing it and republishing it again (or several times) doesn't fix it
- the only way i know to fix this issue is to delete all the images on the post and re-add them.
- the images have return type of `image url` (changing it has no effect on the issue)
this is addressing an issue already reported in #2352
the issue has reappeared, probably a regression, in even a worse fashion, because files cannot be accessed altogether, as opposed to having to specify the file name as reported in the original issue
storing static html files in the static folder causes gatsby to not serve them properly in development mode.
1) gatsby-plugin-manifest fails to create images when paths are different.
2) gatsby-plugin-manifest does not delete the `include_favicon` option when creating the manifest file.
according to [the docs]( creating a page whose path matches the regex `/404*` should be recognized as the 404 page
however, the development 404 page says no custom 404 page was detected even though a page with such a path exists
<img width="1422" alt="custom-404-not-detected" src=" ">
in circleci, my build hangs in machine and docker builds
in either case, it's a linux os: ```
+ debug='gats*,cow*'
+ yarn build --verbose
yarn run v1.13.0
$ gatsby build --verbose
verbose 0.401 set gatsby_log_level: "verbose"
verbose 0.403 set gatsby_executing_command: "build"
verbose 0.404 loading local command from: /home/circleci/project/node_modules/gatsby/dist/commands/build.js
verbose 1.73 running command: build
success open and validate gatsby-configs 0.005 s
success load plugins 0.086 s
success onpreinit 0.022 s
success delete html and css files from previous builds 0.005 s
success initialize cache 0.008 s
success copy gatsby files 0.017 s
success onprebootstrap 0.009 s
success source and transform nodes 0.023 s
success building schema 0.089 s
success createpages 0.000 s
success createpagesstatefully 0.017 s
success onpreextractqueries 0.000 s
success update schema 0.008 s
success extract queries from components 0.008 s # and nothing else
scss sourcemaps in any of the downloadable starter kits or in a fresh build of gatsby, do not correctly show scss sourcemap references in the web inspector
in firefox on windows you see a blob reference (screenshot attached), in chrome, you see an absolute path that repeats several times (screenshot attached), which while better as i can work out what file the code references, does not look great
i feel like a lot of people must have this issue as all the starter kits i've downloaded have this problem
this issue is present in gatsby v1 and v2, it is not present in similar static generators such as next.js, so i feel it's not an issue with webpack
the same build, when run on linux, shows source map references correctly which leads me to believe this issue seems to be limited to windows.
on subsequent runs of `gatsby develop` in a project of mine, the schema is running into some caching issues.
i have been unable to complete the build process using the 'gatsby-source-shopify' plugin
the progress varies each time, but it always stalls on "source and transform nodes" after a successful "fetched and processed collections"
- maxwidth and maxheight will control aspect ratio/cropping if both are provided but this isn't documented - sizes is an option for `fluid` but not documented
- not clear that by default maxwidth or maxheight is used to determine the source break points - leads to poorly optimized breakpoints if maxwidth or maxheight is close to or over original size
- when cropped, placeholders remain at original aspect ratio #12008
on the gatsby cloud team, we've noticed that we sometimes see error log output come out of `stdout` and regular log output come out of `stderr`
this results in the wrong colors being displayed to the end user in the gatsby cloud product
this includes, but not limited to, promises resolving with non-errors and doesn't seem to be coming exclusively from plugin code.
here are those bug fixes, and cleanup for the new `icon_options`
i also added tests
## related issues #12794
when adding new packages in the new terminal, the `gatsby develop` window throw errors and don't recover back even after the package finished getting installed
have to restart again everytime
the new schema api always returns null on fields that reference multiple union types in contentful when at least one of the types is not present
i'm not sure if this is only affecting arrays of unions or single unions too
in this instance the ```subsections``` field is not referencing any of the ```contentfulsubsectionsibling``` union type
webpack's dead code elimination cuts off global css imports in production builds
create react app has a solution of setting field `sideeffects: true` to css loader like this: ``` test: cssregex, exclude: cssmoduleregex, use: getstyleloaders({ importloaders: 1, sourcemap: isenvproduction && shouldusesourcemap, }), // don't consider css imports dead code even if the // containing package claims to have no side effects
// remove this when webpack adds a warning or an error for this
// see sideeffects: true,
header title has several text-shadows after adding to [gatsby-starter-default]( according to [tutorial-3]( #using-plugins)
although there is not any `text-shadow` in _[layout.css]( and `textshadow` in other [components]( and [pages]( header acquires `text-shadow` according to web inspection tool (image 2)
seems to appear with the `elk glen` theme too (did not test with other themes).
gatsby started warning in development mode about a missing but assumed corejs config that was subject to change
the issue linked below tracks down the source of the problem and this fix quiets it down
thanks! ## related issues fixes #12744
the latest gatsby-plugin-netlify-cms doesn't seem to work with the latest netlify-cms.
when performing a graphql filter for image not null in markdown frontmatter, an unexpected error `the "path" argument must be of type string
received type object` is thrown
this is using a modified query from gatsby\'s `/examples/graphql-reference/src/pages/index.js`: ``` query { site { sitemetadata { title description } } allmarkdownremark( sort: { fields: [frontmatter___date], order: desc } filter: { frontmatter: { title: { ne: "" } image: { ne: null } # <-------- part that i added } } ) { edges { node { excerpt fields { slug } frontmatter { date(formatstring: "mmmm dd, yyyy") title image { # <--- also part that i added childimagesharp { fluid(maxwidth: 500) { src } } } } } } } }
when i refresh a page with a scroll bar, after i have scrolled down, the page reloads but i am back at the top of the page, not at the same scroll position.
i have a shopify store with approximately 100 products and associated images
when running `npm run build` i am not seeing any errors, though the request is taking a while
however, when i explore my data in graphiql, some of the `localfile` nodes are `null`
these images do exist however, and have valid `originalsrc` urls.
after upgrading from `v1` to `v2` following the official guide i am witnessing the following issue: ```
error unhandled rejection typeerror: cannot read property 'key' of null - render-page.js:1997 /users/danielkov/projects/project/public/render-page.js:1997:11 - array.sort - render-page.js:1996 object../node_modules/gatsby-plugin-typography/gatsby-ssr.js.exports.onprerenderhtml /users/danielkov/projects/project/public/render-page.js:1996:18 - render-page.js:196 /users/danielkov/projects/project/public/render-page.js:196:36 - array.map - render-page.js:191 ./.cache/api-runner-ssr.js.module.exports /users/danielkov/projects/project/public/render-page.js:191:25 - render-page.js:597 module.default /users/danielkov/projects/project/public/render-page.js:597:57 - worker.js:35 promise [project]/[gatsby]/dist/utils/worker.js:35:36 - debuggability.js:303 promise._execute [project]/[gatsby]/[bluebird]/js/release/debuggability.js:303:9 - promise.js:483 promise._resolvefromexecutor [project]/[gatsby]/[bluebird]/js/release/promise.js:483:18 - promise.js:79 new promise [project]/[gatsby]/[bluebird]/js/release/promise.js:79:10 - worker.js:31 promise.map.path [project]/[gatsby]/dist/utils/worker.js:31:37 - util.js:16 trycatcher [project]/[gatsby]/[bluebird]/js/release/util.js:16:23 - map.js:61 mappingpromisearray._promisefulfilled [project]/[gatsby]/[bluebird]/js/release/map.js:61:38 - promise_array.js:114 mappingpromisearray.promisearray._iterate [project]/[gatsby]/[bluebird]/js/release/promise_array.js:114:31 - promise_array.js:78 mappingpromisearray.init [project]/[gatsby]/[bluebird]/js/release/promise_array.js:78:10 ``` i realise this is because in the following method: ```js
exports.onprerenderhtml = function (_ref2) { var getheadcomponents = _ref2.getheadcomponents, replaceheadcomponents = _ref2.replaceheadcomponents; var headcomponents = getheadcomponents(); headcomponents.sort(function (x, y) { if (x.key === "typographystyle") { return -1; } else if (y.key === "typographystyle") { return 1; } return 0; }); replaceheadcomponents(headcomponents);
``` the value of `headcomponents` is `react.reactnode[]`, which can include `null` as valid values
in my project one of the other plugins injects a `null` into this array, which shouldn't cause an issue to this plugin in my opinion.
if app is loaded from serviceworker, only my layout gets rendered.
after a few seconds of waiting, the page appears
this happens consistently throughout reloads on all pages
this experience is far less superior than the 'normal' non-sw workflow, which immediately shows a page
see [screen recording here]( i would like to make a minimal reproduction repo, but i have no idea what part of my setup is causing this
a live example is available, however.
if more details are required, i'm on the discord as jari#1337
the "minor refactor" rewriting `gastby-node.js` from cjs to esm syntax in #12482 was [published untranspiled]( thus breaking the build for any consuming project.
after modifing placeholder file in /src/data/ index page is removed and server returns 404
when a markdown file includes a link that would be shown in the plaintext excerpt, an extra space is added after the link.
when using the `excerpt(format: html)` graphql value, it seems to be just showing the end of the article/blog-post instead of from the beginning
this is regardless of the `prunelength` i set
it seems to be just showing the last node that contains text.
when going to in brave browser, the page fails to load and opens a blank browser page with "data:text/plain," in the url bar
the only information i could find referencing this issue seems to be an ie issue with data uris
this shouldn't be an issue in the brave browser as it is running chromium
the other weird thing is that seems to be the only page that fails to load, for me anyways.
at the moment `gatsby-remark-code-repls` plugin do not support scoped npm packages (started by @ character)
it expects only one @ character for name - version separation.
gatsby-plugin-page-creator's package.json file does not include a repository field which is used to notify it is an official plugin
as seen below, it is an official plugin but it does not get a icon in the sidebar because the repository field is undefined ![screenshot_2019-03-05 gatsby-plugin-page-creator]( looking at the hit object that we get from algolia, there is no way to note it is an official plugin otherwise so the solution to this likely would just add the repo url in the package.json
plugin search on www.gatsbyjs.org break page with some search phrases
i have an issue while using styled-components with gatsby
i already use the styled-components plugin
it works, but if i reload the page the style stops working
when in develop it works normal, when built this happens, maybe it is some problem with path.
when running `gatsby develop` everything works perfectly and fast for the first 5 pages i open (in multiple tabs)
subsequent pages opened in new tabs hang indefinitely
when i close one of the previously opened tabs the last pages load immediately
i've tried to see if this is related to similar issues including ( and but it seems different
![gatsby-closing-tabs](
basic auth headers seem not to be set correctly anymore in the latest version
instead in the request header only a `"auth":"some_user:some_pass"` are set without proper encoding
the broken change seems to be introduced here:
fixes infinite loop when clicking reset filter on [showcase page](
## related issues
#issuecomment-467986879
<!-- link to the issue that is fixed by this pr (if there is one) e.g
fixes #1234, addresses #1234, related to #1234, etc.
the post detail page on is missing the avatar image
this should be updated to fix the image, or if that's not possible, remove the image completely
### getting started the [gatsbygram code can be found in the example directory of this repo](
the avatar is rendered in [post-detail.js]( #l30-l41) and the browser tests are in [home-page-spec.js](
run the browser tests (built with cypress.io) with `yarn run cy:run`
for reference there's [a recent pr that fixes this for the gatsbygram homepage](
css class is missing in some components when including `gatsby-plugin-offline` during deployment
during development it works as expected
the missing css corresponds to the `tab` styled component in `src/components/header.jsx`
the `div` tag renders but without the corresponding class
on the first load it may render fine, but on refresh the header css styles are missing
navigating to another section of the page makes the header css reappear
see for an example.
hot reload fails when updating pages deleted and created by `deletepage` and `createpage` inside `oncreatepage`
it renders correctly after `npm start` but it fails to hot reload
updating any other type of file works correctly
it actually updates correctly but it attempts to refresh the page after 1 second and then it fails
the idea is to replace pages inside `src/pages` by their i18n version
so `/` is deleted and replaced by a component which redirects to `/es/` and `/en/`
the relevant code is: ```
exports.oncreatepage = async ({ page, actions }) => { const { createpage, deletepage } = actions; if (page.path.includes('404') || page.context.locale) { return; } const redirect = path.resolve('src/i18n/redirect.js'); const redirectpage = { ...page, component: redirect, context: { languages, locale: '', routed: false, redirectpage: page.path, } }; deletepage(page); createpage(redirectpage); languages.foreach(({ value }) => { const localepage = { ...page, originalpath: page.path, path: `/${value}${page.path}`, context: { languages, locale: value, routed: true, originalpath: page.path, } }; createpage(localepage); });
i see nothing, the page is blank.
it's working when `gatsby develop`
but failed to build when you use react.createcontext with empty default value
you can solve it by assigned default value in react.createcontext method
but i cannot modify other npm packages which are using react.createcontext with empty default value
so i cannot build the website.
usually i set the default value by <context.provider value={defaultvalue} children={children} />,
not in the createcontext method
enables `anonymize: true` on
## related issues <!-- link to the issue that is fixed by this pr (if there is one) e.g
fixes #1234, addresses #1234, related to #1234, etc.
changed the shape of favicons exported to a square when even providing rectangular images ## related issues fixes #12051
when using `createremotefilenode` from `gatsby-source-filesystem`, remote files get downloaded each time `yarn develop` is restarted (or each build) even though the remote files are unchanged and the cache is present
there are multiple issues in `createremotefilenode`
the `headers` option is not being set properly on the `got` http request and, thus, the `if-none-match` header is not getting sent.
when (1) is fixed, you'll find that the cached response header gets overwritten by the 304 response headers and you lose the etag
we should only encache response headers from a 200 response
i'm uncertain how to wrap this up in tests but both patches are trivial and i can submit pr.
when you provide an svg with rectangular canvas (not square), gatsby-plugin-manifest produces malformed favicons, e.g
144x130, which then results in an error in the browser.
loads beautifully, but cloning this repo and running it locally produces glitchy loading/rerendering of components/images.
i have a page on which i want to disable scroll update
in order to achieve that i defined `shouldupdatescroll` function in `gatsby-browser.js` file in the root of the project which returns false when location matches my page's url
but when `gatsby-remark-autolink-headers` is used result of my `shouldupdatescroll` is ignored
as far as i understand, when gatsby decides whether it should update scroll or not, it runs `shouldupdatescroll` functions defined by plugins first and then it runs the function defined in the project
but only the first result is used (in my case the result returned from `gatsby-remark-autolink-headers` ): #l90-l101 `gatsby-remark-autolink-headers` defines its own `shouldupdatescroll` function which returns `true` if url does not contain a hash:
#l27-l30 probably `shouldupdatescroll` function defined in `gatsby-remark-autolink-headers` should return `undefined` instead of `true` if url does not contain a hash
in this case its result will be ignored and it will be possible to disable scroll update for certain pages.
#l36-l37
tracedsvg image placeholders are not aligned to the original image when cropped
it looks like this was reported already [here]( 4 months ago, but the original poster didn't provide a reproducible demo and the issue was closed
he/she explains the issue very well
i'm providing a demo.
click on links load content from file with longer name on server
on macos or windows parialy work, on some builds links work as expected, in some cases links load content of longer named file.
in a theme scenario where there are multiple ancestors, component shadowing appears to only respect the first component (or it stops looking after a certain point)
example (site uses theme3, theme3 uses theme2, theme2 uses theme1):
=> theme1/src/components/foo.js
=> theme2/src/theme1/components/foo.js (actually shows up)
=> theme3/src/theme1/components/foo.js (should show up)
=> site (where develop is run from)
gatsby-plugin-emotion throws an error if it encounters a component that only contains fragment syntax and no other jsx
this is due to [an upstream issue in `babel-preset-css-prop` that has since been fixed](
would you accept a pr to bump the dependency version? not sure if the dependency is pinned to 10.0.5 for a specific reason or if it's just that nobody's had good reason to update yet :)
when using gatsby's `navigate` helper or the `<link>` component, the `withprefix` function will always be called, adding a prefix to navigations to hash-link or query parameters
while this can be circumvented with an anchor tag, you may want to navigate programmatically and the only fix there is to use `@reach/router`'s `navigate` function directly or `window.___navigate`, which is unintuitive to developers starting out
i think gatsby should support all use cases of the `navigate` function without having to load any other package and this would require some change in the `withprefix` function to not add a slash if detecting a hash-link or a query param
the contributor in the above pr which fixed the issue in a very ugly way suggested i instead add this limitation to the docs and open an issue to discuss this problem and possible solutions.
gatsby with package - [ react-scrollable-anchor]( to navigate between sections on same page
i am facing a weird bug where page keeps scrolling to top if you try to scroll down the page past section 1
this use to work with previous version of gatsby.
it's related to #5436
opening a new issue per @kyleamathews' [comment]( #issuecomment-419614254)
when headings are in backticks (e.g
<code># \\`foo\\`</code>), the `headings` array from `markdownremark` have `null` value.
when running 'gatsby build' command and then viewing the website with 'gatsby serve', the website html is different to the actual markup written
at surface level, i first thought there was an issue with the sass/css as i've noticed there have been quite a few issues, but having observed dom elements closer - i noticed they were muddled up
however, when refreshing the page, for a split second everything looks normal but then goes back to the incorrect structure
correct (gatsby develop):
<img width="490" alt="screen shot 2019-02-18 at 10 03 49 pm" src=" "> incorrect (gatsby build and serve):
<img width="486" alt="screen shot 2019-02-18 at 10 02 49 pm" src=" ">
when using a `mapping` in `gatsby-config.js`, reverse relationships work as described in the docs but only for a 1:1 relationship
a 1:n relationship doesn't return an array, it just returns a single value
this was discussed also in #11151
we use `fs-exists-cached` (memoized `fs.lstat(sync)`) in `gatsby-plugin-sharp` to check if processed file already exists to skip processing
this works in production, but in development cause problem: if file doesn't exist on initial check, it will cache this -> sharp plugin will generate image
on next query run that would cause sharp plugin processing we use cached check and regenerate same image
ideally we would invalidate that cached value for the file, but `fs-exists-cached` doesn't support that currently
we could fork it (it's pretty low weight - ) and add invalidation mechanism and use that once images are generated.
for my application i have to serve bit-identical versions of images - preferable from static paths
shows that an images path changes on configuration changes, even if the (bitstream) content of an image stays the same
([cool uris don't change]( is a little unclear to me but would be solved with access to an `originalimg`
but currently the `originalimg` does not provide access to the unmodified (bitstream) of the source image but to an processed version.
whenever a `delete_page` action is called from a `oncreatepage` api hook, we turn on a flag that stops the rest of the queued `oncreatepage` calls for the partiular page we are working with given we can't try deleting a page that was already deleted
## related issues fixes #11173
i have a multi language website build with gatsby, redux, redux-persist and storyblok (cms)
when sharing our website in slack i've noticed that no preview is available
i did some research and it looks that all the meta tags set via helmet are present but they are not server rendered
you see the tags appearing when you inspect the website via the browser
**as a result, when sharing the website, no preview text or picture is available (og meta tags, title & description) and i guess this also has a negative impact on general seo as well.** the official gatsby website is working fine though
after investigating the gatsby repo i saw they are not using redux and custom html.js file
i'm wondering if the combination of redux and a custom html.js file can break the gatsby-plugin-react-helmet plugin? i saw a lot of other people struggling with helmet-related issues
**since seo is an absolute key-stone of every website these days i think we have to improve both the plugin as well as documentation on how this plugin works and the current limitations.** we've spent a lot of time creating this website and it's basically useless because of this problem, which is very hard to debug and information of how this plugin works in combination with gatsby just doesn't exist.
in this umbrella issue, i'd like to provide a means for others to share any issues encountered regarding caching, **specifically in instances when the solution to a problem you were facing was remediated by removing the cache (e.g
`rm -rf .cache`)**
issues that we have seen before (but generally have not been able to reproduce) can usually be classified as one of the following: 1
remote content sourced by a plugin is available (e.g
in the database, cms, etc.) but is _not_ available after a local re-build
a local plugin source code changed, but the change(s) do not seem to have taken effect
local content (e.g
images, markdown, etc.) were changed, but the changes do not seem to show up after a build if any of these scenarios, or more broadly speaking, if you've ran into a problem where content wasn't appearing appropriately and deleting the cache solved this problem--then please chime in! ## intent if we can reliably reproduce these types of issues and scenarios, we can harden our cache and improve the experience for _all_ gatsby users
specifically, if we can reliably reproduce we can fix the underlying issue _and_ then author end-to-end tests to ensure that the caching issue remains fixed
## template please use the following template to report an issue so that we can most effectively debug the underlying issue
note: it is *extremely important* that you provide as much information as possible for the reproduction step
the more info and clearer the reproduction, the better we will be able to debug and ship fixes to these issues! ```markdown
## description ## reproduction <!-- please, please provide detailed steps to reproduce
ideally a github repository where we can reproduce the issue(s) ourselves, as well
--> ## environment info
i'm using gatsby-plugin-offline and gatsby-plugin-layout on my site
prop activestyle on link component rendered in gatsby-plugin-layout layouts/index.js component (footer) isn't properly applied on subsequent access to the site after service worker is installed
link rendered in the gatsby v2 layout component (header) works as expected.
shopify restricts node edges to 250 per query, this project seems to have missed this feature so only the first 250 products are returned
issue is brought up here: #issuecomment-426396621
## steps to reproduce - hook gatsby-source-shopify into a store with over 250 products, attempt to find the data.
- alternatively, create a collection, attach products 251+ to that collection, gatsby will fail to build as it is unable to link (find) the products in that collection ## expected result all products should be indexed ## actual result ```error: invariant violation: encountered an error trying to infer a graphql type for: "products___node"
there is no corresponding node with the id field matching:``` ## environment ``` system: os: macos high sierra 10.13.6 cpu: (4) x64 intel(r) core(tm) i5-5250u cpu @ 1.60ghz shell: 5.3 - /bin/zsh binaries: node: 11.6.0 - /usr/local/bin/node yarn: 1.13.0 - /usr/local/bin/yarn npm: 6.5.0 - /usr/local/bin/npm languages: python: 2.7.15 - /usr/local/bin/python browsers: chrome: 71.0.3578.98 firefox: 62.0 safari: 12.0.3 npmpackages: gatsby: ^2.0.115 => 2.0.115 gatsby-image: ^2.0.29 => 2.0.29 gatsby-link: ^2.0.10 => 2.0.10 gatsby-plugin-google-analytics: ^2.0.6 => 2.0.13 gatsby-plugin-layout: ^1.0.12 => 1.0.12 gatsby-plugin-react-helmet: ^3.0.6 => 3.0.6 gatsby-plugin-sass: ^2.0.10 => 2.0.10 gatsby-plugin-sharp: ^2.0.20 => 2.0.20 gatsby-source-filesystem: ^2.0.20 => 2.0.20 gatsby-source-shopify: ^2.0.13 => 2.0.13 gatsby-transformer-sharp: ^2.1.13 => 2.1.13 npmglobalpackages: gatsby-cli: 2.4.9```
building a blog / portfolio with gatsbyjs and i'm struggling with this issue
i had the website working for the most part but all of a sudden it's stopped working
really not sure why
the error doesn't make much sense to me
hoping someone cold help me work out why.
i have a relationship in my model
this relationship is stored in a `objectid`
this doesn't end up in the graphql schema (probably because it doesn't understand `objectid`'s)
i also cannot use the `map` option, because it is not a string ( #l5) is there a way for gatsby-source-mongodb to support `objectid`'s? or even better, to support relationships and represent them in the graphql?
since updating gatsby to latest version i've been getting the following error in development
unhandled rejection (syntaxerror): unexpected token < in json at position 0
when having literal enums that have non-string values (eg imagecropfocus), relay fails to print the query.
i get a console error: webpack-hot-middleware's client requires eventsource to work
you should include a polyfill if you want to support this browser: #tools
when a component with a `staticquery` exports its query, e.g
import react from 'react'
import { staticquery, graphql } from 'gatsby' export default function header() { return ( <staticquery query={titlequery} render={data => ( <header><h1>{data.site.sitemetadata.title}</h1></header> )} /> )
} export const titlequery = graphql` { site { sitemetadata { title } } }
` ``` building this code will lead to the query data _not_ being injected into the component and will lead to a display of `loading (staticquery)`
when building for production with `gatsby-plugin-react-css-modules` styles are't correctly applied
guessing the hash that react-css-modules defaults to and the hash that gatsby's internal css module setup use don't match
the extended hash used in dev works fine.
while creating pages programatically using the `createpage` action, one of my `path`s has the following characters...
after adding `gatsby-plugin-netlify-cms` to gatsby project generated html files doesn't include scripts and are running without javascript
`chunk-map.json` file is overridden with chunks generated by plugin\'s webpack build and looks like this: `{"cms":["/cms.js"]}`.
i am looking to replicate the blur up effect of `gatsby-image`, but in the body of my markdown blog post images using `gatsby-remark-images`
here are two examples, the top image is what i expect to happen, but the bottom image is what i am seeing (no blur up)
**example image with blur up using `gatsby-image`**
![blur up working in gatsby-image]( # **example image with no blur up using `gatsby-remark-images`**
![blur up not working in gatsby-remark-images]( #
i tried `gatsby-source-mongodb` with a database name with 2 dashes (something like `one-two-three`) and it seems the name is not properly sanitized
i get the following error when trying to build: ```
error: names must match /^[_a-za-z][_a-za-z0-9]*$/ but "mongodbonetwo-threedocumentsconnectionsortbyfieldsenum" does not.
``` i think the culprit is a missing `g` in the regular expression of the [`sanitizename`]( #l135) function in that plug in: ```
function sanitizename(s) { return s.replace(/[^_a-za-z0-9]/, ``).replace(/\\b\\w/g, l => l.touppercase())
``` the first replace stops after the first dash
`s.replace(/[^_a-za-z0-9]/, ``)` should be `s.replace(/[^_a-za-z0-9]/g, ``)`.
when using the cache in plugins, calling cache.set always resolves to `undefined` when it appears the intention was to have it resolve with what was stored (pretty standard practice).
since `v2.2.3` of `gatsby-plugin-typography` the `omitgooglefont` option no longer works on the development server
when running a build it does the right thing and the font is not fetched from google fonts, but on the development server fetching the font is still injected into the `<head>` even with `omitgooglefont: true`
there is only one change between `v2.2.2..v2.2.3` and it is #10545
this pull request also happens to relate to google font loading so presumably this is where the bug was introduced from.
when running gatsby in development mode and exposing it to the local network with `-h 0.0.0.0` and opening a site that has svgs, the image doesn't appear and if it has alt-text, the alt text appears
that said, when built and served, the svg does render on ios.
gatsby build fails when deploying to netlify
i get an `unknown kernel` error: ![image]( works fine locally when using `gatsby develop` or `gatsby build && gatsby serve` i'm using the gatsby default starter.
i've tried update gatsby and netlify, but still seeing the same issue.
the issue seems to be that calling `deletepage` in two different `oncreatepage` hooks is unexpectedly asynchronous, causing the [delete_node reducer]( #l16) to receive ```js
{ type: 'delete_node', plugin: undefined, payload: undefined }
``` this causes ![image](
the gtag plugin crashes if `pluginconfig` is not defined, even though its fields are in turn documented as optional
the code carefully treats all of the fields as optional too ([exclude]( #l23), [head]( #l30))
and there is definitely a use case for the plugin without any of them, so to avoid unnecessary config bloat, it should be optional
probably just an oversight.
trying to fetch the date from `api` provided by `wordpress.com`
`app` is created and set up
i think the auth is working, i am manage to verify it, and getting: ```
{"client_id":"64395","user_id":"16355831","blog_id":"15570813","scope":""}
``` providing the related stuff in the `gatsby-config.js` file, such as: ```
baseurl: "fmehu.wordpress.com", // the protocol
this can be http or https
protocol: "https",
``` and ```
hostingwpcom: true,
useacf: false,
wpcom_app_clientsecret: process.env.gatsby_wordpress_client_secret,
wpcom_app_clientid: process.env.gatsby_wordpress_clientid,
wpcom_user: process.env.gatsby_wordpress_username,
wpcom_pass: process.env.gatsby_wordpress_password, includedroutes: [ "**/*/*/categories", "**/*/*/posts", "**/*/*/pages", "**/*/*/media", "**/*/*/tags", "**/*/*/taxonomies", "**/*/*/users", ],
in a project using the gatsby-offline-plugin, in production (gatsby build), when you access or refresh a page, you'll get a quick blank page instead of the styled html from the react's render
disabling the serviceworker from chrome's devtools (bypass for network) fixes this.
i have built a [small site]( with gatsby and recently upgraded to v2
now i am facing two issues that i cannot figure out and i have been reading plenty of github issues already
for your information the site is deployed on netlify and the **code** can be found [here](
**problem 1: scroll position flashes when page is reloaded** this is a very obvious issue and when ever the page is reloaded, it scrolls to the top for a short period of time and then jumps back to its original scoll position
**problem 2: font and content flashes** i am using the `gatsby-plugin-google-font` to load a font
even though this adds a link tag to the head, which means the font should be loaded before the content is being rendered, i can see my text flashing
for a short period of time i can see the font changing
the same goes for the content sometimes
for a short period of time i can see the styles not being loaded but the content is already rendered
i am using bootstrap grid for example
i found a very similar [issue]( but it's still open and no solution was successful for me.
when enabling mozjpeg in my gatsby-config.js, jpg images do see better compression, but any png source images if using `toformat: jpg` in their graphql query, will not actually format the image into jpeg, but instead output a png image data with a jpg file extension.
when pages are created from nodes, and you use the `createpagedependency()` action to declare a dependency on the node, when the node is deleted (after the first build), no page rebuilding is triggered
the change is visible once something else triggers a page rebuild, but the page is not removed
a similar thing happens when you update a node which causes a new page to be built: the node is updated, but the page building fails with this error: ```
error loading a result for the page query in "/updated-title-of-post-3"
query was not run and no cached result was found.
page not found /updated-title-of-post-3 ```
some blog posts on gatsbyjs.org have a `canonicallink`, but no `publishedat` key in their frontmatter
this leads to the blog post header saying _(originally published at )_, instead of _(originally published at example.com)_
a quick fix would be to update the blog posts that have a `canonicallink` but no `publishedat` text to also include `publishedat`
a better fix would be to update [`template-blog-post.js`]( #l210-l220) to automatically display a `publishedat` value if one isn't supplied
as an example, a `canonicallink` like ` ` should be displayed as `contentful.com`.
the last several times i\'ve clicked on "visit a site" from a site detail page and then, after browsing the site, use the back arrow to try and go back to the site showcase, there is just a blank white page staring at me!
when following the gatsby docs for storybook support ( on any version >= 2.0.24 you get the following fatal error:
error in ./node_modules/gatsby/cache-dir/commonjs/public-page-renderer-dev.js
module not found: error: can't resolve './pages.json' in '.....project..../node_modules/gatsby/cache-dir/commonjs' @ ./node_modules/gatsby/cache-dir/commonjs/public-page-renderer-dev.js 12:36-59 @ ./node_modules/gatsby/cache-dir/commonjs/public-page-renderer.js @ ./node_modules/gatsby/cache-dir/commonjs/gatsby-browser-entry.js @ ./src/components/header/index.js @ ./src/components/header/header.stories.js @ ./src sync .stories.js$ @ ./.storybook/config.js @ multi ./node_modules/@storybook/core/dist/server/common/polyfills.js ./node_modules/@storybook/core/dist/server/preview/globals.js ./.storybook/config.js (webpack)-hot-middleware/client.js?reload=true
after this pr #10545 `gatsby-plugin-typography` no longer works with default config.
i've been working on using the rich text fields in gatsby and it seems that embedded entries are supposed to be resolved since this plugin uses the contentful sdk, but all i see is the id of the entry its supposed to resolve to.
[environment variables]( (captured in `.env.environment`, e.g
`.env.staging`) do not get exposed correctly to the code that gets bundled with webpack, e.g
the client-side, non-node code
we can see this by walking through the build process: 1
add a script, `build:staging` ```json { "scripts": { "build:staging": "cross-env node_env=staging npm run build" } } ``` 1
`gatsby build` is kicked off via the cli [here]( #l177) - this _explicitly_ sets node_env=production, therefore ignoring any overrides from the user
environment variables are sourced via webpack [here]( #l40) - this will _always_ be production; it's not possible to override this since it's set and overwritten early in the build via the cli
when running `gatsby develop` with gatsby@2.0.66, navigating to a url that doesn\'t exist (as suggested in [part seven of the tutorial]( results in a nice 404 page like this: <kbd><img width="855" alt="screen shot 2018-12-17 at 11 29 01 pm" src=" ">
</kbd> starting with gatsby@2.0.67, it results in an uncaught error: <kbd><img width="578" alt="screen shot 2018-12-17 at 11 34 14 pm" src=" "></kbd> looking through the [comparison between the two versions]( it looks like #10224 might be the culprit.
when excerpts are queried from `gatsby-transformer-remark` using the `format: html` option, the resulting html is not parsed correctly
the system is returning something like this: ```
<p>we have an elasticsearch backed search interface ..
<code class="language-text">joe</code>..
that the user cares about.</p>
``` the problem is that the `code` tag is being processed as a text node rather than parsed as part of the html syntax tree
this is related to work i did adding the `format: html` option in the first place
i'll try to figure it out.
when the following conditions are true, gatsby is unable to build the site, reporting graphql validation failures: 1
use the latest version of `gatsby-remark-images` (`v3.0.1`).
use the `gatsby-paginate` plugin with the suggested template.
include the field `htmlast` in the `createpages` query.
have a markdown file containing specific content.
suddenly there where images missing on the page
after some search i realized that one of the images uploaded in the wp backend was a gif
after removing it all images showed up again
the problem seems to be that during the thumbnail generation the gif throws an error and the rest of the images after the gif are not generated
but there is no hint or error message.
i have a several custom post types which have either an repeater for images or a featured image
until a random lower amount of posts ~20 everything seems fine but than if i add new images to the page like for example in my projects post, the localfile for another post not related to the one becomes null
i could not detect any pattern for that
it seems random and looks like there is just certain space / limit available and if that space is full new localfile items override the old ones
i tried deleting .cache and public and reuploading the images but no effect
when i check the api response from wordpress everything is fine and the image sources are all in the api response i first thought that the problem was when i upload a image which is smaller in its natural dimensions than defined in the graphql query like this
project_images { image { localfile { childimagesharp { fixed(width: 940) { src width height originalname } } } }
g i upload an image with 900px width
if i do so localfile will be null
i will get this in the terminal during build generating image thumbnails [============================ ] 14/16 0.5 secs 100%
the requested width "940px" for a resolutions field for
the file /users/arturnagenrauft/dev/si-page/.cache/gatsby-source-filesystem/0a7d60e9c09b0ab319d3d49daa855b4f.jpg
was larger than the actual image width of 900px!
if possible, replace the current image with a larger one
but i reduced the fixed width so the images are not to big for the required width but i still get this issue
after upgrading to the latest version of gatsby-plugin-emotion i noticed that some headers were missing from the ssr version of my pages
i added a log inside `onrenderbody` in my project's `gatsby-ssr.js` file and noticed it wasn't getting called at all
i was able to track it down to the usage of `babel-plugin-jsx-pragmatic` and `@babel/plugin-transform-react-jsx` ( #l4-l19)
if i remove these lines then the rendering hooks get called again, but emotion is no longer working without adding the `@jsx jsx` pragma and importing `jsx` from `@emotion/core`.
access to `window.localstorage` is not a given (some browsers have it, some don't) and the following line completely stops the js for kicking in
#l96 some cases where `localstorage` might be disabled: - weird/semi-old browsers (not sexy to work with, i know, but sometimes necessary)
- recent ones with "cookies and site data" disabled (see
- some browser extension messing with properties
there seems to be a broken link in the [get to know gatsby building blocks]( tutorial
the link in "see a list of the existing official and community starters" takes me to a 404 page however it does successfully redirect to the new location if i refresh the page.
`gatsby-plugin-create-client-paths` is remounting the root component on every single page transition for the client-only path
this means that if you have auth check in your top-level root, your authentication check will run on each new page instead of just once like it would with a normal react spa (e.g
one built with create-react-app)
revisiting: as stated in the previous issue (closed), single reference fields that accept multiple content types cause graphql to error out: "expected value of type \\"contentfulpage\\" but got: [object object]." the workaround is to create a multiple reference field, but this shouldn\'t be a permanent fix.
here is a gif: ![nov-21-2018 20-42-26](
i tried rebuilding my project but couldn't
`gatsby develop` and `gatsby build` give the same error
if i add `uglifyjs-webpack-plugin` the project builds without errors
i didn't change any code since my last successful build, nor could i find any recent commits referring to this module.
i created a website with gatsby and found an issue, the `<link>` component does not support unicode path like: ` <link to=" "> </link>` i also tried the `link` component directly from` @reach/router` package and found the same issue, so i submitted an issue over there
to help other people with the same issue, i am adding the issue here.
while inspecting production bundles of a gatsby site, i saw that all environment variables used during the build process are included in a bundle js file
this can also include sensitive data (e.g wordpress htaccess passwords) when used via a .env file.
we run gatsby inside a docker container to build our web site
recently we had added a fair number of images and noticed a strange issue where our automed e2e test was failing due to images not being found (404 error)
investigation of the build confirmed that the relevant folders has been generated in `public/static` but were empty
this was strange because it worked when being built locally on a developer and all images were produced
however, when running on our ci server, this was failing to produce all the images
given that the build was happening in a docker container we assumed this must be some sort of race condition that occurs depending on the physical hardware used
investigation confirmed that the ci server was taking longer to process each images and hence the overall build was completed before all images had been created
this was strange as i was aware that the bootstrap process was meant to wait until all outstanding jobs were completed
after some debugging, i found the root of the problem
`gatsby-plugin-sharp` acquires the bound action creators via this line: ```
const { boundactioncreators } = require(`gatsby/dist/redux/actions`)
``` we run gatsby iniside a monorepo
the plugin is correctly sending the `create_job` and `end_job` actions but these were going to a totally different redux store due to the way yarn had hoisted the dependencies! the require will find the "closest" `gatsby` which might not be the `gatsby` module executing
hence the correct store was never receiving the actions and the code in the bootstrap process to check for active jobs would pass even though the plugin was still working
## corrective action `gatsby-plugin-sharp` should use the `actions` that are passed to the `gatsby-node` api file
this will ensure the plugin is always referring to the correct store
i will submit a pull request with this change
i've mainly created this issue for reference purposes in case it helps anyone else
## other considerations i've not had time to check but any other plugins that pull out the `boundactioncreators` from ` require('gatsby/dist/redux/actions')` would also suffer from this bug of referencing the wrong redux store which could lead to all sorts of weird behaviour.
in styled components, we can create global styles with the method `createglobalstyle()`
this method results a component and the stylesheet is only used when the component is mounted
with gatsby, if you use it, the global styles does not apply only for the page where the globalstylecomponent is mounted
in fact, the behavior is correct in development mode but not in the static build.
gatsby styled components plugin is not overriding styled properties when server-side rendering is disabled
for example, i am using carbon components react, and carbon components react applies the following styles to a button
this only happens when i am not using server-side rendering.
during the build process if there is no .cache directory then the build is totally fine without error
but if i have .cache directory it throws error.
in css nested calc() functions must be treated as simple parentheses.<sup>[mdn]( #notes)</sup> in gatsby, however all the parentheses are currently being dropped in the build process (`gatsby build`)
the issue persists even when the `--no-uglify` flag is used on `gatsby build`
issue doesn't occur on development (`gatsby develop`).
with gatsby 2.x and latest drupal module json api 2.x version, it's not indexing correctly the file entities
and it's not possible anymore to take advantage of `gatsby-transformer-sharp` images query
``` json api 1.x on drupal <8.5.x
data.attributes.url
json api 1.x on drupal 8.5.x
data.attributes.url
data.attributes.uri.url
json api 2.x on drupal >=8.5.x
data.attributes.uri.url
from
i'm using the `gatsby-image`, `gatsby-plugin-sharp`, and `gatsby-transformer-sharp` plugins to work with images imported from a drupal backend
up until a couple of days ago this was working fine
at some point i stopped and restarted `gatsby develop` and things just stopped working
the issue is related to images imported from drupal, and specifically, an error where `props.image.localfile` is undefined in my component and causes the page to not display at all
(i can add a conditional to fix that, but it doesn't resolve the fact that the image should be there.) i'm using this query in a template component, and it always returns null for `image.localfile` ```gql
export const query = graphql` query recipetemplate($uuid: string!) { noderecipe(uuid: {eq: $uuid}) { uuid, title, cooking_time: field_cooking_time, difficulty: field_difficulty, ingredients: field_ingredients, preparation_time: field_preparation_time, number_of_servings: field_number_of_servings, instructions: field_recipe_instruction { processed, }, summary: field_summary { processed, }, relationships { category: field_recipe_category { name, } tags: field_tags { name, } image: field_image { localfile { childimagesharp { fluid(maxwidth: 1100) { ...gatsbyimagesharpfluid } } } } } } }
``` in graphiql i can run the following query, and i see the data i would expect: ```gql
{ allnoderecipe { edges { node { relationships { image:field_image { localfile { childimagesharp { fluid(maxwidth: 1100) { base64, aspectratio, src, srcset, sizes, } } } } } } } }
``` i've tried things like removing node_modules/ and re-installing
and removing the .cache/ directory
so far that's not made any difference
i can see that the files exist in public/static/*, and map to the paths i see when running the query in graphiql
permissions on the image files seem fine.
if i specify a wildcard matchpath for the root path on my index page `matchpath: \'/*\'`, the index page is always served, ignoring any "static" paths.
i noticed a little css padding problem on placeholder text at search bar
the authors image in a blogpost is a link
it inherits link tag stylings which draws a border in the background.
the share button on top of every starter should be algned with the rest of the buttons, and the drop-down should go away on clicking outside the drop-down area.
say i want to have multiple components in a single file, that both use `staticquery` in one form or another
example code:
// src/components/things.js import react from "react";
import {staticquery} from "gatsby"; export const myfirstquery = (props) => ( <staticquery query={some_query} render={() => <div>hello world</div>} />
); export const mysecondquery = (props) => ( <staticquery query={some_query} render={() => <div>hello world</div>} />
// src/pages/testpage.js import react from "react";
import { myfirstquery } from "../components/things"; export const () => ( <div> here is my first static query: <myfirstquery /> </div>
``` the page will render as expected when using `gatsby develop`, but `gatsby build` will cause the following error to occur: ```
error generating javascript bundles failed error: ./src/components/things.js 6:7 module parse failed: identifier 'staticquerydata' has already been declared (6:7) you may need an appropriate loader to handle this file type
| import _objectwithoutpropertiesloose from "@babel/runtime/helpers/objectwithoutpropertiesloose"; | import staticquerydata from "../../public/static/d/2162154064.json"; > import staticquerydata from "../../public/static/d/2162154064.json"; | import { staticquery } from "gatsby"; @ ./src/pages/testpage.js 2:0-47 105:31-39 @ ./.cache/async-requires.js @ ./.cache/production-app.js
on a fresh install of the using remark example in the gatsby repo, the actual blog posts of the using remark website lead to blank pages instead of blog posts
the website is working as intended.
gatsby v2 can't handle the generation of very big sites
we build around 2000 pages (however, the data is those pages is pretty big, e-commerce...), and the build step ends up failing.
we narrowed it down to this line of code: #l82
stringify seems to crash with error:
const datastr = json.stringify(data, null, 2) ^
rangeerror: invalid string length at json.stringify (<anonymous>) at object.<anonymous> (/users/xxx/code/stringy-tests/index.js:17:22) at module._compile (module.js:652:30) at object.module._extensions..js (module.js:663:10) at module.load (module.js:565:32) at trymoduleload (module.js:505:12) at function.module._load (module.js:497:3) at function.module.runmain (module.js:693:10) at startup (bootstrap_node.js:188:16) at bootstrap_node.js:609:3
error command failed with exit code 1.
note that this error comes from the reproducible snippet here:
i've tried to use `gatsby-plugin-subfont` on several gatsby v2 sites, but it always errors out for one of the following reasons: 1
it can't find `sw.js` (which it says is included by `public/app-1b277d8308c390a95f4b.js` even if i haven't yet enabled `gatsby-plugin-manfest` and `gatsby-plugin-offline` during development)
it can't find `public/workbox-v3.6.2/packages/workbox-sw/browser.mjs` (which it says is included by `public/workbox-v3.6.2/workbox-sw.js.map` after i have enabled the service worker) i'd love to use the plugin! hoping someone can help.
i recently deployed a gatsby website and i get reports of users seeing white screen
i see it myself on my device and i don't know why?
getting `typeerror: t.props.page is null` when attempting to thumbs up or down a remote plugin.
the slug for each starter is the github repo stub (the part after the username)
there are currently 2 starters in the list called `gatsby-starter`
those two starters have the same url on the starter showcase.
command line filepath name does not accept special characters for command "gatsby develop"
when the page path matches in the initial `if` statement, we `resolve()` the promise, but do not `return`, so the rest of the code is still processed.
when using gatsby-image and gatsby-plugin-sharp to produce traced svg images for image loading, and specifying both `maxwidth` and `maxheight` for the resulting image, the traced svg image is from the full (uncropped) source image, where as the actual generated image is cropped to aspect ratio with the crop location defined by `cropfocus`
the end result is very jarring where the traces do not match at all with the actual image when loaded
instead the traced svg should match the cropped actual resulting image, meaning that the image should be cropped to correct aspect ratio first, and then traced.
images don't appear the first time a site is loaded on gatsbyjs.org
seems like an offline-plugin issue -- perhaps @davidbailey00 could take a look?
when i search the v1 docs site, i get results for pages that only exist on v2
if i click them i get taken to an error page.
some paragraphs are rendered just as `<p>text</p>` instead of the p with the class from emotion-js.
prismnjs: line numbers in the gutter are not aligned with the code (on the x axis)
adding a field in `setfieldsongraphqlnodetype` with `graphqljson` only crashes the query compiler.
i'm not sure when this issue started appearing, but i can remember this to not be an issue not long ago
it seems that on the generated table of contents, any headings with any additional html elements attached to it (e.g
code) is not sanitised properly.
the **submit a starter** button is a bit broken on mobile version.
flexible content in flexible content returns an array with only the first unique row times the amount of rows
so all the rows after row 1 are duplicates of row 1 (even if every row are different field types)
only one level flexible content works just fine.
if pathprefix exists, *gatsby-plugin-catch-links* works incorrectly for links in markdown files
as a result, the prefix has been added twice, once by *gatsby-transformer-remark*, and once by `navigate`.
when a `pagequery` only searches by `id` then changes to the source for those pages do not appear in the browser (tested with firefox and chrome)
i've taken a look at this myself and it seems to be because the pages aren't getting added to the `component-data-dependencies`
pr to follow!
i've read through several recent discussions about supporting `mjs` files and i see gatsbyjs/gatsby#8327 was merged to include the extension, however i continue to see the original `require is not defined` runtime error after adding the change to include the extension
from what i've seen in my app and in several repos (e.g
aws-amplify/amplify-js#686, facebook/create-react-app#5151), the test for `mjs` still needs to be added to the webpack js loader rules.
when writing a page template component the following pattern works
const component = ({ data }) => { ..
} export default component export const componentquery = graphql` ...
``` however, the following results in the `data` prop being `undefined`
const component = ({ data }) => { ..
} const componentquery = graphql` ...
` export { component as default, componentquery }
because the placeholder image remains visible in the dom, screen readers will encounter both images and read the image tag, as well as the `alt` text
this means that each image is duplicated for screen reader users
i am using gatsby v2 with `gatsby-image` v2.0.9
i tested this behaviour with nvda in firefox and ios voiceover in safari
both setups read duplicate images.
when a 404 page is returned the page breaks
this appears to be a regression, or at least difference in the handling of "dot" files within the `pages` folder during the `gatsby build` command
this was working in 1.x, but now in 2.0 it fails
i believe the intended behavior should be that dot files are ignored during the `gatsby build` command.
when gatsby-plugin-remove-trailing-slashes is installed, the development 404 page breaks.
using gatsby-transformer-remark and gatsby-remark-images, i am seeing new fields added to the graphql schema if i run `gatsby develop` with a warm `.cache`.
when a users first page on the site is a page which has been created with no trailing slash.
then that page will be skipped if the user uses the back button on the next page they view
netlify cms doesn't handle redirect after re-logging in
i'm opening this issue to pair with a pr i'm about to submit
there is a minor issue with running the local server with `--host` switch
the local server literally takes the host ip for constructing urls rather than taking from the base url
for example, if the local ip is 10.0.10.0 and with the host switch enabled, the page at ` ` should have all the urls relative to this path
rather, gatsby local server constructs url some thing like which is wrong
right now, we can workaround this problem by giving the **exact ip address** in the host switch like `gatsby develop --host=10.0.10.0`, but this should not be the behaviour for `--host=0.0.0.0` switch by default.
project using contentful plugin and gatsby v2 was working fine then all of a sudden started throwing this error
i have googled around and see it could be related to the contentful content model having issues
we are not sure what changed how can i dig into this further to find out exactly what field is having issues from contentful? seems like the error message should be a little better at pointing to what exactly is null
tried deleting cache, removing node modules and reinstalling with all fresh v2 plugins and newest gatsby no luck same problem exists
fetch contentful data: 2165.227ms
success source and transform nodes 2.421 s
error cannot read property 'internal' of null typeerror: cannot read property 'internal' of null - infer-graphql-input-fields.js:343 _.each [myproject]/[gatsby]/dist/schema/infer-graphql-input-fields.js:343:38 - lodash.js:4911 [myproject]/[lodash]/lodash.js:4911:15 - lodash.js:2996 baseforown [myproject]/[lodash]/lodash.js:2996:24 - lodash.js:4880 [myproject]/[lodash]/lodash.js:4880:18 - lodash.js:9344 function.foreach [myproject]/[lodash]/lodash.js:9344:14 - infer-graphql-input-fields.js:331 inferinputobjectstructurefromnodes [myproject]/[gatsby]/dist/schema/infer-graphql-input-fields.js:331:5 - build-node-types.js:186 [myproject]/[gatsby]/dist/schema/build-node-types.js:186:36 - generator.next - util.js:16 trycatcher [myproject]/[bluebird]/js/release/util.js:16:23 - promise.js:512 promise._settlepromisefromhandler [myproject]/[bluebird]/js/release/promise.js:512:31 - promise.js:569 promise._settlepromise [myproject]/[bluebird]/js/release/promise.js:569:18 - promise.js:614 promise._settlepromise0 [myproject]/[bluebird]/js/release/promise.js:614:10 - promise.js:694 promise._settlepromises [myproject]/[bluebird]/js/release/promise.js:694:18 - async.js:138 _drainqueuestep [myproject]/[bluebird]/js/release/async.js:138:12 error unhandled rejection typeerror: cannot read property 'internal' of null - infer-graphql-input-fields.js:343 _.each [myproject]/[gatsby]/dist/schema/infer-graphql-input-fields.js:343:38 - lodash.js:4911 [myproject]/[lodash]/lodash.js:4911:15 - lodash.js:2996 baseforown [myproject]/[lodash]/lodash.js:2996:24 - lodash.js:4880 [myproject]/[lodash]/lodash.js:4880:18 - lodash.js:9344 function.foreach [myproject]/[lodash]/lodash.js:9344:14 - infer-graphql-input-fields.js:331 inferinputobjectstructurefromnodes [myproject]/[gatsby]/dist/schema/infer-graphql-input-fields.js:331:5 - build-node-types.js:186 [myproject]/[gatsby]/dist/schema/build-node-types.js:186:36 - generator.next - util.js:16 trycatcher [myproject]/[bluebird]/js/release/util.js:16:23 - promise.js:512 promise._settlepromisefromhandler [myproject]/[bluebird]/js/release/promise.js:512:31 - promise.js:569 promise._settlepromise [myproject]/[bluebird]/js/release/promise.js:569:18 - promise.js:614 promise._settlepromise0 [myproject]/[bluebird]/js/release/promise.js:614:10 - promise.js:694 promise._settlepromises [myproject]/[bluebird]/js/release/promise.js:694:18 - async.js:138 _drainqueuestep [myproject]/[bluebird]/js/release/async.js:138:12 ```
the low-res placeholder image that gatsby-image generates is not fading out on safari, both on desktop and mobile
you can see it happening at the gatsby-image [example site](
it becomes an issue when using images with transparency, as you can still see parts of the placeholder.
i think that both `example1` and `example2` should produce the same output: ![image]( there is something funny going on with the `id` field, for example, when i try `ne` instead of `eq`, i get an error: ![image](
upon upgrading to v2, i am getting an error originating from the `gatsby-plugin-react-css-modules` package
this package allows me to use the `stylename` attribute for nicer css modules usage.
using tracedsvg on a file ending in .jpeg causes gatsby-plugin-sharp to report the following vague error: ```
error unhandled exception typeerror: cannot read property 'bitmap' of undefined - potrace.js:1000 potrace._processloadedimage [www]/[potrace]/lib/potrace.js:1000:35 - potrace.js:1046 jimp.<anonymous> [www]/[potrace]/lib/potrace.js:1046:14 - index.js:85 jimp.throwerror [www]/[jimp]/index.js:85:44 - index.js:201 readfilecontext.callback [www]/[jimp]/index.js:201:44
``` of note, twitter always uses .jpeg for its image suffix, so any images saved from twitter will crash tracedsvg.
i'm using gatsby v2
i have a strange problem with 404 error because it redirects automatically to ?no-cache=1 my url is:
if page's matchpath property is altered in gatsby-node.js, loader.js is not able to find the page in development mode.
i use wrappageelement api hook as described in the docs to have persistent page elements.
at the descriptions show unrendered markdown code, for example <hr /> ![screenshot_673]( <hr />
the [using-page-transitions]( example seems to be broken after today's gatsby 2.0 release
it was correctly fading as a page transition before today but after updating the deps to go from the gatsby rcs to 2.0 releases it no longer fades.
clicking a featured site on next.gatsbyjs.org causes an error and a white page
when using the `redirect` component or the `navigate` function of reach router, the paths are not prefixed.
compile error not specific enough
gatsby build (and develop) dies with oom with ~800 somewhat heavy markdown content, only used plugins are fs-source and remark.
hot reloading not working on hello world starter
no title if gatsby app is opened in the background.
when querying for transformed nodes by id, the content initially loads correctly but doesn't receive any updates made to the file, even after refreshing the page
if the node is queried for by any other field, it works correctly
this was originally reported in
when serving gatsby from static build, typography gets injected into the head as `<style id="typography.js">[object object]</style>`
but when using gatsby develop, the css is injected properly within the style tag.
in the extend node tests #l88 `result.data.listnode.excerpt` is undefined since listnode is in fact a list
to the very least we should use `listnode[0].excerpt`
but the issue is deeper than this
the test seems to pass without running the assertion and the excerpt even if it is a string it is an empty one
we've got an issue with the graphql schema generation where some linked types (`xxx___node`) are missing from schema.
this happens only when a linked type is part of an array
[ { children: [ { linked___node: `child_2`}, { linked___node: `child_3`} ] }
``` after some debugging, i found the issue comes from here:
#l274-l279 `recursiveomitby` is not creating a brand new object and therefore updates the cached examplevalues
when the schema is built the first time, everything looks good.
however, once the schema is updated, the second generation omits `linked___node` as it was removed from the example values
new site pages do not update router's routes and displays 404 (while `develop` is running).
creating new pages by plugins and refreshed via sourcenodes() is not working as expected
it only refreshes contents but cannot load the newly created pages
the newly created page entry can be found in the gatsby redux state, but the updated pages dictionary object is not transferred to the client side.
during css compilation, hsl color values with negative hue values are clipped to 0 instead of wrapped
not using postcss, as far as i can tell
just built on top of the blog starter kit.
when `pathprefix` is set to `/foo` and the site is built and served statically, the browser renders the page and then immediately redirects to `/`
i think it was probably caused by:
#issuecomment-414425126 similar issues that might be related are:
i didn't see this happening until i upgraded gatsby and babel
this lock file entry _seems_ to be the problem: ```
gatsby-react-router-scroll@^2.0.0-rc.2: version "2.0.0-rc.2" resolved " #292f013af77b8a75d3289945c5103a578884dfb3"
``` downgrading to `2.0.0-rc.0` appears to fix the issue.
the plugin no longer appears to support pathprefix.
doing a production build with path prefix will reuse the graphql query responses from development
these are without pathprefix so images will all 404.
when using the offline plugin with remove trailing slashes plugin, refreshing a cached internal page redirects you to `/offline-plugin-app-shell-fallback` which is blank
this has started occurring since changing over to workbox in `gatsby-plugin-offline 2.0.0-rc.2`.
gatsby does not verify that plugins are gatsby plugins before attempting to load them
this can cause silent failures for configs that want to pass a `plugins` key through to another library
refs:
after upgrading to v2 `pathprefix` is not working properly
it is added for links and assets in html, but ignored in other places which results in redirection like this:
opening: `githubusername.github.io/reponame`
changes url in address bar to: `githubusername.github.io/` and screen goes blank
i see that `pathprefix` is not included in generated html files (
<script id="gatsby-script-loader">/*<![cdata[*/window.page={"componentchunkname":"component---src-pages-index-js","jsonname":"index","path":"/"};window.datapath="173/path---index-6a9-nzuapzhg3x9tan1iiixfv1w23e";/*]]>*/</script>
``` and in one of the chunks (
(window.webpackjsonp = window.webpackjsonp || []).push([ [4], { 155: function(a) { a.exports = { pages: [ { componentchunkname: 'component---src-pages-404-js', jsonname: '404-22d', path: '/404/', }, { componentchunkname: 'component---src-pages-index-js', jsonname: 'index', path: '/', }, { componentchunkname: 'component---src-pages-404-js', jsonname: '404-html-516', path: '/404.html', }, ], datapaths: { index: '173/path---index-6a9-nzuapzhg3x9tan1iiixfv1w23e', 'sq--src-components-layout-js': 755544856, '404-22d': '44/path---404-22-d-bce-nzuapzhg3x9tan1iiixfv1w23e', '404-html-516': '164/path---404-html-516-62a-nzuapzhg3x9tan1iiixfv1w23e', }, } }, },
//# sourcemappingurl=4-0d5ca849d8ef3a6a86ed.js.map
running `gatsby build` throws the error ```
error plugin gatsby-plugin-offline returned an error error: enametoolong: name too long, stat 'publ icdata:image/png;base64,ivborw0kggoaaaansuheug...
[v2] in the new `staticquery` component the `graphql` gatsby export fails if there is whitespace in the graphql document.
using a `staticquery` in a a component inside `wraprootelement` or `wrappageelement` results in _loading (staticquery)_ both for `gatsby-node.js` and `gatsby-ssr.js`.
visiting `www.my.domain/fakepath` does not render my custom `404.js` in production
however `www.my.domain/404.html` works as expected.
i use the `activeclassname` prop on the `link` component to style the sidebar on my site and highlight the page the user is currently using
if i visit a link that ends in a hash (such as `/page#heading-within-page`), the `activeclassname` is not applied to the link
i would expect for it to be applied because the user is still on the same page and the link is still "active".
adding `gatsby-plugin-postcss` to a gatsby v2 site seems to cause css to no longer be minified in production.
gatsby does not handle @reach/router's `<redirect>` component when server rendering, [resulting in a build error on sites that use `<redirect>`]( #issuecomment-413354477)
the current workaround is to use the [`nothrow` prop]( on the redirect
the fix is to use @reach/router's `isredirect` method to check errors in `static-entry.js`
importing `isredirect` and replacing [this block]( #l187-l190) with something like: ```js // if no one stepped up, we'll handle it
if (!bodyhtml) { try { bodyhtml = rendertostring(bodycomponent) } catch (error) { // ignore @reach/router redirect errors if (!isredirect(error)) throw error } }
``` should fix the issue.
with certain combinations of styles, the sheetsregistry should be cleared between rendered pages.
when using <redirect /> from @reach/router the url in the nav bar is changing as expected however i am getting a blank white screen until i manually refresh
it isn't re-rendering the page that is being routed too.
hello, when i build my website with `yarn build` i have this error: `module parse failed: identifier 'staticquerydata' has already been declared`.
when running `gatsby develop` the processes finish successfully and open the dev server at localhost
but if i visit localhost i only see a blank page with the following error: ```
uncaught error: it appears like gatsby is misconfigured
jsonstore is gatsby internal development-only component and should never be used in production
unless your site has a complex or custom webpack/gatsby configuration this is likely a bug in gatsby
please report this at with steps to reproduce this error.
``` for some reason this evals to true in the dev server (that's `.cache/json-store.js`): ```
if (process.env.node_env === `production`) { throw new error( `it appears like gatsby is misconfigured
jsonstore is gatsby internal ` + `development-only component and should never be used in production.\ \ ` + `unless your site has a complex or custom webpack/gatsby ` + `configuration this is likely a bug in gatsby
` + `please report this at ` + `with steps to reproduce this error.` )
the `location` prop of the layout component while using `gatsby-plugin-layout` seems to have a delay at the first load
only when navigating the site and revisiting the index page the right component gets displayed **instantly**
on the first load for a short time the location is not available (or something else, i can't figure it out) and therefore the check gets falsy
this only happens on `build`, not on `dev`
this bug is breaking my navigation/navigation style as i check for the location.pathname and display different elements!
so i wanted to try the release candidate in my own website but it looks like something dies during the process for some reason and i don't really understand what happens.
the example "using-page-transitions" stopped working correctly
specifically, it does not seem to perform a "transition-out"
when navigating, the current page should fade out before the next page fades in
i was relying on this example for my website, and i noticed this problem today, when upgrading from `2.0.0-beta.67` to `2.0.0-rc.0`.
i setup my site-wide layout and imported jquery, and bootstrap js
when building for develop everything works fine
when building for production i get the error `webpackerror: typeerror: cannot set property 'emulatetransitionend' of undefined` note: when i moved the jquery and bootstrap imports into gatsby-browser.js it built fine but i'm not sure if that's a good idea and i would like it to be put in the components that actually use them so it's not always loaded.
seems that `gatsby-plugin-react-css-modules` had a regression from v1 -> v2, since it no longer passes user config to react-css-modules.
createpages is called on an infinite loop after edit when developing
clicking on a `<link>` in v2 (111) appears to scroll you to a previous scroll position (if it exists) rather than scroll you to the top.
using `"gatsby-plugin-typography": "next"` with a config file in `utils/typography.js`, after saving changes these changes are not reflected in browser
the user must stop the `gatsby develop` process and restart to see the changes reflected
interestingly, using `gatsby next` but using the older `"gatsby-plugin-typography": "^1.7.19",` plugin in package.json, things work as expected and no incompatibility issues seem to exist from using a 1.x module with 2.x
i'm trying to recreate the modal version of gatsbygram in my own site and i need the pagerenderer component to render the background on the modal and when i upgraded gatsby to 2.0.0-beta.106 pagerenderer stopped working
during build gatsby logs a warning that my dynamic page component is a non-page component, however it's not
warning the graphql query in the non-page component "/src/templates/case.js" will not be run.
exported queries are only executed for page components
instead of an exported
query, either co-locate a graphql fragment and compose that fragment into the
query (or other fragment) of the top-level page that renders this component, or
use a <staticquery> in this component
for more info on fragments and
composition, see #fragments and for more
information on <staticquery>, see
running `gatsby develop` and editing markdown file second time is causing page component to not get any data and cause runtime errors:
gatsby compiler is working fine but then browser throws an error because the graphql query data is null
i'm using `gatsby-mdx` and originally thought it was an [issue there](
this error happens 90% of the time when i edit a markdown/mdx file
a simple page refresh doesn't fix it
the only way to fix the page again is to *change* the `gatsby-config.js` and restart `gatsby develop`
this is making switching to gatsby very painful.
i have a local project that is using the v2 of gatsby
eevrything works great except for the fact that a page refresh and a back button on the browser always leads to a 404
on that 404 page gatsby displays a list of routes and the actual route (the one that responded with 404) is in that list
gatsby.js development 404 page
there's not a page yet at /categories/release/ create a react.js component in your site directory at src/pages/categories/release.js and this page will automatically refresh to show the new page component you created
if you were trying to reach another page, perhaps you can find it below
/tags/cards/
/tags/example/
/tags/release/
/categories/release/
(i am using gatsby v2) when trying to load a page that doesn't exist, the 404 page flashes and then the page becomes blank
#2223 is similar, but i think this is a different problem because `render` isn't being called for my `layout` component
i did some poking around and i believe that this happens because `getresourcesforpathname` is always called with `location.pathname`, so when `pagerenderer` is rendered none of the resources for the pages are loaded and it render's null
(i could be reading things wrong though)
create-a-gatsby-site is not navigate to right location
#create-a-gatsby-site it should navigate to #create-a-site
but its pointing to different location
as i comment in #issuecomment-411317374 , after upgrade to `2.0.0-beta.86`, my gatsby-site's link have significant delay before redirection
note this only occur in develop mode.
running `gatsby build` when using the fairly minimal postcss setup suggested in the [v1 to v2 upgrade guide]( #restore-v1-postcss-plugin-setup) an unspecified error occurs: ```
error building static html for pages failed see our docs page on debugging html builds for help 31 | if (!plugin.plugin[api]) { 32 | return undefined
> 33 | } | ^ 34 | const result = plugin.plugin[api](args, plugin.options) 35 | return result 36 | }) webpackerror: ./src/components/header.module.css - api-runner-ssr.js:33 childcompiler.runaschild lib/.cache/api-runner-ssr.js:33:6
whenever i add redux to gatsby, gatsby-plugin-offline stops working
the service worker is registered, but the offline functionality doesn't work
after updating to the latest v2 (2.0.0-beta.69) the location props from the `router` component do not get updated on `jsonstore` if just the `location.search` is updated but not `location.pathname` (figured this out with react dev tools)
this worked lately with gatsby@2.0.0-beta.34 and gatsby-link@2.0.0-beta.4
i would guess this is related to this commit as i cannot really see where the update happens, maybe @pieh could have a look at this.
`gatsby-transformer-react-docgen` throws "there are conflicting field types in your data" warning depending on the proptypes
here are two components that conflict: ```
button.proptypes = { type: proptypes.oneof(['button', 'submit']),
datepicker.proptypes = { lastmonth: proptypes.instanceof(date),
currently gatsby handles clicking on hash links as in we do correctly scroll to the link
however, we don't handle scrolling back to the previous scroll position when you click back.
> gatsby build building production javascript and css bundles step **never completes**.
> gatsby develop works.
when the `duotone` parameter is used with the `sizes` method, `quality` gets ignored.
redirects doesn't work and throws an error
when using `gatsby-remark-images`, if the `linkimagestooriginal` is set to `true` (which is the default), all images will be linked to their original, even if they're already wrapped in a link.
the `allpageheaders` option for gatsby-plugin-netlify is not writing headers to the `./public/_headers` file on build
it looks like the problem is here:
#l183-l190 the pages collection is an instance of map, and lodash reduce doesn't iterate over its keys
i'm happy to submit a pull request if you'd like
i've reproduced the issue here:
in gatsby-config.js, in the plugin options, when anonymize option is explicitly set to `false`, ie:
// setting this parameter is optional anonymize: false,
the following code is added to the bundled analytics snippet: `ga('set', 'anonymizeip', 1);` i guess, in this case, there should not be any code setting the anonymizeip feature at all in the bundled snippet
moreover, as far as i know, the `1` value can be potentially interpreted as `true`, which would enable the ip anonymization (instead of disabling it).
after i renamed my project folder from she-says to she-says-sg, i keep getting errors on `gatsby develop` enoent: no such file or directory, open '/users/isabellachen/developer/projects/she-says/src/templates/page.js'
hi, i am making a simple variation of the site introduced in the tutorial for v2.
`gatsby develop` works as expected but `gatsby build` fails
info bootstrap finished - 2.926 s success building production javascript and css bundles 4.258 s error building static html for pages failed see our docs page on debugging html builds for help 8 | <table> 9 | <tbody>
> 10 | {data.allmyitemsjson.edges.map( | ^ 11 | ({node}, index) => 12 | <tr key={index}> 13 | <td><a href={node.home_page_url}>{node.title}</a></td> webpackerror: typeerror: cannot read property 'edges' of null - feed.js:10 ./src/templates/feed.js.__webpack_exports__.default lib/src/templates/feed.js:10:34 - react-dom-server.node.production.min.js:26 d [lib]/[react-dom]/cjs/react-dom-server.node.production.min.js:26:482 - react-dom-server.node.production.min.js:28 wa [lib]/[react-dom]/cjs/react-dom-server.node.production.min.js:28:493 - react-dom-server.node.production.min.js:33 a.render [lib]/[react-dom]/cjs/react-dom-server.node.production.min.js:33:46 - react-dom-server.node.production.min.js:32 a.read [lib]/[react-dom]/cjs/react-dom-server.node.production.min.js:32:246 - react-dom-server.node.production.min.js:43 rendertostring [lib]/[react-dom]/cjs/react-dom-server.node.production.min.js:43:1 - static-entry.js:148 module../.cache/static-entry.js.__webpack_exports__.default lib/.cache/static-entry.js:148:16 - default-html.js:5 promise._execute lib/.cache/default-html.js:5:3 - static-entry.js:43 promise._resolvefromexecutor lib/.cache/static-entry.js:43:18 - bootstrap:68 new promise lib/webpack/bootstrap:68:1 - bootstrap:16 promise.map.path lib/webpack/bootstrap:16:1 - bootstrap:5 trycatcher lib/webpack/bootstrap:5:1 - bootstrap:50 mappingpromisearray._promisefulfilled lib/webpack/bootstrap:50:1 - api-runner-ssr.js:6 mappingpromisearray.promisearray._iterate lib/.cache/api-runner-ssr.js:6:16 - bootstrap:67 mappingpromisearray.init lib/webpack/bootstrap:67:1
i was following tutorial at #gatsby-plugins but `gatsby develop` is not working as expected after the below `npm install` command
npm install --save gatsby-plugin-typography react-typography typography
`gatsby develop` command work as expected before the above command
i am getting the below error when i run `gatsby develop` command
error there was a problem loading the local develop command
gatsby may not be installed
perhaps you need to run "npm install"?
``` **output** of the `npm install --save gatsby-plugin-typography react-typography typography` ```bash
npm warn rm not removing /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/.bin/gatsby as it wasn't installed by /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/gatsby
npm warn rm not removing /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/.bin/browserslist as it wasn't installed by /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/browserslist
npm warn rm not removing /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/.bin/regjsparser as it wasn't installed by /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/regjsparser
npm warn rm not removing /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/.bin/jsesc as it wasn't installed by /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/jsesc
npm warn rm not removing /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/fsevents/node_modules/.bin/node-pre-gyp as it wasn't installed by /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/fsevents/node_modules/node-pre-gyp
npm warn rm not removing /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/@babel/preset-env/node_modules/.bin/browserslist as it wasn't installed by /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/@babel/preset-env/node_modules/browserslist
npm warn rm not removing /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/.bin/babylon as it wasn't installed by /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/babylon
npm warn rm not removing /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/babel-template/node_modules/.bin/babylon as it wasn't installed by /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/babel-template/node_modules/babylon
npm warn rm not removing /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/@babel/generator/node_modules/.bin/jsesc as it wasn't installed by /users/mammar/documents/gatsby/site/tutorial-part-two/node_modules/@babel/generator/node_modules/jsesc
npm warn react-typography@0.16.13 requires a peer of react@^0.14.0 || ^15.0.0 || ^16.0.0 but none is installed
you must install peer dependencies yourself.
npm warn gatsby-plugin-typography@1.7.19 requires a peer of gatsby@^1.0.0 but none is installed
you must install peer dependencies yourself.
npm warn gatsby-starter-hello-world@ no repository field
+ react-typography@0.16.13
+ typography@0.16.17
+ gatsby-plugin-typography@1.7.19
added 11 packages from 6 contributors, removed 1454 packages, updated 6 packages and audited 34 packages in 22.085s
found 0 vulnerabilities
when `gatsby build` is used against a configuration consisting of stylus modules, the resultant site doesn't render the css
this issue is on gatsby v2 but seems to exist back in gatsby v1
this can be best viewed on the [stylus example site](
this issue doesn't occur on the example that demonstrates [plain example](
`promise.map` is not a function when build.
running `gatsby serve` on a system running node.js v6 will result in an error: ```
gatsby serve serve previously built gatsby site
options: --verbose turn on verbose output [boolean] [default: false] --no-color turn off the color in output [boolean] [default: false] -h, --host set host
defaults to localhost [string] [default: "localhost"] -p, --port set port
defaults to 9000 [string] [default: "9000"] -o, --open open the site in your browser for you
[boolean] -h, --help show help [boolean] -v, --version show version number [boolean] error there was a problem loading the local serve command
gatsby may not be installed
perhaps you need to run "npm install"? error: /users/mike/dev/temp/tutorial-part-one/node_modules/serve-handler/src/index.js:177 const getheaders = async (customheaders = [], current, absolutepath, stats) => { ^ syntaxerror: unexpected token ( - module.js:20 require internal/module.js:20:19 - serve.js:4 object.<anonymous> [tutorial-part-one]/[gatsby]/dist/commands/serve.js:4:15
``` this is because the underlying package `serve` doesn't support node versions that are in _maintenance lts_, only _active lts_
#release-schedule i think there's two options for fixing this: 1
stop supporting older lts releases
replace `serve` with something else i don't think the first option is practical for gatsby, so we're left with option 2
this fix should add tests to prevent future regresssions.
when using develop mode (`gatesby develop`), plugin gatsby-plugin-typography will not embed google font `<link>` at all, both in v1 and v2, even if `googlefonts` field exists in the typography config file
however it is working after build.
gatsby-source-drupal doesn't create local files when using node v6
gatsby-source-drupal/src/gatsby-node.js, line 145:
``` // resolve w/ baseurl if node.uri isn't absolute
const url = new url(node.url, baseurl)
``` urls can't be created using new url() using node v6 so 'typeerror: url is not a constructor' exception is thrown.
there's a [security vulnerability in `serve`]( that github just started flagging
the fix is to upgrade `serve` to `serve@^7.0.0`
currently we're still on version 6
#l117 ## steps to solve - [ ] run `yarn install serve@latest` in the `gatsby` package
- [ ] ensure `gatsby serve` continues to work as expected
- [ ] spread the word that everyone should upgrade to remove the vulnerability we should apply this upgrade to both v1 and v2, assuming there are no breaking changes for v1.
if i try to assign my graphql to a variable as a const, and then pass it to my `query` prop of my `<saticquery/>` component, i only get __"loading (staticquery)"__ rendered on my page.
after update to the latest beta, builds start failing, image-sharp is not able to store files as directories do not exist yet
error failed to process image /home/porfirio/agroop/website/src/images/hero/homepage.jpg error: vips__file_open_write: unable to open file "/home/porfirio/agroop/website/public/static/homepage-e9a46789054c3337a506ffa991521c93-8a184.jpg" for writing unix error: no such file or directory
the button that opens the sliding menu is overlapping with the "showcase button" <img width="377" alt="screen shot 2018-07-17 at 3 23 54 pm" src=" "> i\'m wondering if this was an intended design
when using v2 with contentful, setting `enable_gatsby_refresh_endpoint=true` in order to run a webhook for targeting `__refresh` results in the following error and doesn't compile successfully:
typeerror: cannot destructure property `parentspan` of 'undefined' or 'null'.
when i set `gatsby_refresh_token=true`, the error disappears and the app compiles with no problem
however hot reloading still does not work and it is not refreshing source data like it did in v1.
if you are using a custom html.js and it is invalid, `build` and `develop` will both fail silently and hang forever.
with `gatsby` 2.0.0-beta.20 to 2.0.0-beta.38, updating markdown files does not trigger a re-render
even refreshing doesn't show the updated content
ref: #issuecomment-405158853
ref: #issuecomment-405280637
writing a local plugin i started to get the following `validationerror` when trying to add a new node source
> the new node didn't pass validation
validationerror: child "internal" fails because [child "owner" fails because ["owner" is required]] being new to gatsby i thought that perhaps i needed to set this value
doing so produced: > the node internal.owner field is set automatically by gatsby and not by plugin i finally tracked this down to my `package.json` file not having a name
[according to the docs:]( #what-files-does-gatsby-look-for-in-a-plugin) > this can be an empty object ({}) for local plugins
> if `name` isn set, the folder name for the plugin is used this appears to not be working
i followed the `{}` advice to get going quickly.
following the directions in the [babel.js]( docs breaks the build.
for some reason i can only get hot reloading effects with my style sheets and not react components
not sure if this a problem with v2 or my computer.
in the process of moving from gatsby v1 to v2, i converted `/src/layouts/index.js` to a regular component at `/src/components/layout.js`
i now get the error ```
uncaught (in promise) referenceerror: graphql is not defined at module.eval (/src/components/layout.js:53)
running `gatsby build` on all fresh installs using v2 results in the creation of the directory public/static/d with 998 empty subdirectories numbered 1-998.
i'm using the following config: ```js { resolve: 'gatsby-plugin-stylus', options: { use: [ ..
], import: [ ..
``` the plugins in `use` are not taking effect
in fact, i did a config dump in the stylus plugin, and seems that the second `config.merge` for `import` overrides the first config merge for `use`: ```js config.merge(function (current) { current.stylus = { import: options.import }; return current; });
``` the merge result is that fields in `stylus` got replaced, instead of merged.
when a gatsby website loads, the user can happily start scrolling
however, after some time has elapsed the page scrolls back up to the top.
after this merge
the way as pages are stored in redux changed, so this line
#l58 gives error
when you create a custom block the class name added is just `custom-block` instead of the class name defined in the config.
when using the new `<staticquery />` api i am continually receiving the `loading (static query)` message.
hi all, i was struggling with `graphql fragments and roots must have unique names` error even with the simplest setup: - one `layout` component with `staticquery`
- one page importing `layout`
- no plugins while running either `gatsby develop` or `gatsby build` it shows error message: > **graphql error** there was an error while compiling your site's graphql queries
invariant violation: graphqlcompilercontext: duplicate document named `titlequery`
graphql fragments and roots must have unique names
eventually i tried to use default export instead of named export and suddenly everything worked: - `export const layout`, `import { layout } from "..."` - causes error
- `export default layout`, `import layout from "..."` - works ok don\'t know, is this intended or not? thanks for the hard work on this project!
having parenthesis in the path when using the createpage api isn't creating the pages even though they appear in the dev 404 page
no error is shown
using `typography.js` and `gatsby-plugin-sass` (and associated libraries of each), the css is "blobbed" after `typography` in develop and inlined before `typography` in build
this means the look of the website changes from develop to build
images below (obviously more drastic with more css being moved around)
![develop]( build:
![build](
when opening a gatsby site in google translate, it shows a flash of translated content and then shows a 404 page
or
i'm processing around 1500 images with gatsby-plugin-sharp/gatsby-transformer-sharp and graphql, to display with gatsby-image as per [this page in the docs](
for smaller numbers of images i have had no issues, but now that i'm processing 1500 images the build randomly fails with the following error: ```
(sharp:104): glib-gobject-warning **: 09:35:11.293: gtype.c:4265: type id '0' is invalid (sharp:104): glib-gobject-warning **: 09:35:11.293: can't peek value table for type '<invalid>' which is not currently referenced (sharp:104): glib-gobject-warning **: 09:35:11.293: gvalue.c:188: cannot initialize gvalue with type '(null)', this type has no gtypevaluetable implementation (sharp:104): glib-gobject-critical **: 09:35:11.293: g_value_transform: assertion 'g_is_value (src_value)' failed
received 'segmentation fault' signal
``` this happens during the "generating image thumbnails" step in the build process and it occurs apparently randomly (sometimes 10% of the way through the images, sometimes at 80%, sometimes not at all)
therefore i do not believe it is caused by a "faulty image".
when images are included in a css module, the build fails
development mode works.
i'm importing a script in `gatsby-browser.js` that, when imported, runs some code that uses `document.location.hostname`: ```js
import { cid, analytics } from '@freeletics/tracking'; // this calls `document.location.hostname` when imported export const oncliententry = () => { ...
this causes an error when running `gatsby build`:
success building production javascript and css bundles 16.087 s
error unhandled exception referenceerror: document is not defined - render-page.js:44102 /users/.../blog/public/render-page.js:44102:21
``` i'm using 2.0.0-beta.13
it worked fine in v1.
query allcareersquery { allsourcepluginapicareers { edges { node { tags { region { slug title { en } } } } } group(field: tags___region___slug) { field fieldvalue totalcount, edges { node { tags { region { slug title { en } } } } } } }
and here is the result: ```
{ "data": { "allsourcepluginapicareers": { "edges": [ { "node": { "tags": { "region": { "slug": "americas", "title": { "en": "americas" } } } } }, { "node": { "tags": { "region": { "slug": "europe", "title": { "en": "europe" } } } } }, { "node": { "tags": { "region": { "slug": "americas", "title": { "en": "americas" } } } } } ], "group": [ { "field": "tags.region___slug", "fieldvalue": "undefined", "pageinfo": { "hasnextpage": false }, "totalcount": 3, "edges": [ { "node": { "tags": { "region": { "slug": "americas", "title": { "en": "americas" } } } } }, { "node": { "tags": { "region": { "slug": "europe", "title": { "en": "europe" } } } } }, { "node": { "tags": { "region": { "slug": "americas", "title": { "en": "americas" } } } } } ] } ] } }
when viewing the v2 docs site at while using the the search field, the pop-up window appears to be cutoff on smaller screens (a 13" macbook pro for example), or in smaller browser windows, when there is a large amount of search result content
![screen shot 2018-06-28 at 6 01 23 pm](
since #6008 and #6009, css styles are no longer inlined in development (they are still inlined in production)
in development, this causes a flash of unstyled content followed by a layout jump when the styles are applied.
as mentioned on #5789, any component that has both a `staticquery` and a ts `interface` (or `type`) declaration will flat out fail to compile the graphql fragments/queries
inserting semicolons inside the `interface`/`type` declaration seems to be the "solution" at the moment..
but it's a hacky workaround at best, and i'm not sure that breaking a linting rule is a true solution to this problem
other than that, this error log appears: ```
error there was a problem parsing "/users/resir014/etc/repos/resir014/gatsby-starter-typescript-plus/src/layouts/index.tsx"; any graphql fragments or queries in this file were not processed.
``` i've also discovered this while testing out my `typescript-plus` starter with v2 of gatsby
i'm in the early stages of converting it, and honestly it's not a big deal of an issue, but still a weirdness that threw me off regardless...
when one of the functions in a class (like a react component) is `public`, gatsby is not able to parse the file:
there was a problem parsing "/examples/using-typescript/src/pages/index.tsx"; any graphql fragments or queries in this file were not processed.
this may indicate a syntax error in the code, or it may be a file type that gatsby does not know how to parse.
``` it does work with react components that are included on those pages.
when deployed to netlify, gatsby links are broken.
when i use `<staticquery></staticquery>`
`gatsby build` fails.
when i use `<staticquery />`, everything works
failure message:
error: ./src/components/layout.js module build failed (from ./node_modules/babel-loader/lib/index.js): typeerror: cannot read property 'push' of undefined
``` this happens at the following location:
#l139 the value of path2.parent is:
node { type: 'jsxclosingelement', start: 1095, end: 1109, loc: sourcelocation { start: position { line: 38, column: 8 }, end: position { line: 38, column: 22 } }, name: node { type: 'jsxidentifier', start: 1097, end: 1108, loc: sourcelocation { start: [position], end: [position] }, name: 'staticquery' } }
ie 11 throws "unhandled promise rejection referenceerror: \'promise\' is undefined" error in v2 sites
this can be observed at next.gatsbyjs.org and can replicate it locally on my site
including promise polyfill fixes the issue, but from looking at documentation `babel-polyfill` is meant to handle that based on defined browsers list.
hmr is only updating one page.
i made a video:
the shell says: ```
info changed file at e:\\lennart\\documents\\github\\portfolio\\content\\blog\\2018-06-21\\index.md
the "deletenodes" action is now deprecated and will be removed in gatsby v3
please use "deletenode" instead.
(node:28256) maxlistenersexceededwarning: possible eventemitter memory leak detected
11 drain listeners added
use emitter.setmaxliste
ners() to increase limit
``` what the video isn't showing:
a split second after switching the page the correct text is shown, but then it goes away
**note:** after some time the hmr doesn't work at all anymore
the changes on the same page won't be applied.
ints > 32 bit are incorrectly inferred to graphqlint instead of graphqlfloat (graphqlint is only 32 bit long).
i am using gatsby@next and i am trying to get the netlify-cms plugin to work.
using the 1.0 plugin doesn't get inserted into webpack and the index.html in admin doesn't get build.
using the 2.x plugin causes a error when executing the oncreatewebpackconfig
the code looks like this
exports.oncreatewebpackconfig = ({ config, stage }, { modulepath }) => { config.merge({ entry: { cms: [`${__dirname}/cms.js`, modulepath].filter(p => p), }, plugins: plugins(stage), }) module(config, stage) return config
and this seems to be an older pre final 2 api
the new api uses actions and not config, state and modulepath
the error is:
error unhandled exception typeerror: cannot read property 'merge' of undefined - gatsby-node.js:91 object.exports.oncreatewebpackconfig [gatsby-starter-netlify-cms]/[gatsby-plugin-netlify-cms]/gatsby-node.js:91:10 - api-runner-node.js:104 runapi [gatsby-starter-netlify-cms]/[gatsby]/dist/utils/api-runner-node.js:104:37 - api-runner-node.js:173 mapseries [gatsby-starter-netlify-cms]/[gatsby]/dist/utils/api-runner-node.js:173:25
seeing a chrome and lighthouse warning related to css assets not being preloaded (correctly?) when using `gatsby serve` after upgrading to latest v2 beta releases.
i tried to upgrade my portfolio to v2
since i already upgraded multiple sites i know what i had to do and in the past i never had a problem with `gatsby-node.js`
the creating of the pages worked without problems in **v1**, the `projects` query also works in graphiql but now i'm getting the error: >typeerror: cannot read property 'edges' of null
>gatsby-node.js:107 graphql.then.result
>e:/lennart/documents/github/portfolio/gatsby-node.js:107:50
on firefox 60 (ubuntu) the `gatsby-plugin-offline` seems broken
when its installed and a new version of a website is served, the browser window is reloaded indefinitely without ending on the new version
i've experienced this bug on my website, but also on
the only way to olve the issue on the user side, is to close the tab, and re-open it.
inline codes add unnecessary `code-classlanguage-text` `code` to its link
for example: #move-source-directories-pages-components-utils-etc-under-code-classlanguage-textsrccode should ideally be: #move-source-directories-pages-components-utils-etc-under-src
when changing gatsby's graphql fragments and testing these changes using `gatsby-dev-cli`, the changed fragments need to be manually copied from gatsby's `src` directories
this should be done automatically
note that this is a fairly rare bug that can be worked around
it'd be nice to fix but it's not essential as it only affects people editing gatsby's built in graphql fragments
refs:
refs: #issuecomment-393877212
i have added `gatsby-plugin-remark` and `gatsby-transformer-remark` to optimize some images through frontmatter
the setup is really simple
say i have a `md` file
```markdown
title: beautiful ui
featured_image: ../../images/project-vscbui.png
subtitle: a set of color themes for vscode
link:
templatekey: projects
``` in `gatsby-config.js` i have ```js
'gatsby-plugin-sharp',
'gatsby-transformer-sharp',
``` and i am querying the image like this ```js
export const projectquery = graphql` query projectquery { projects: allmarkdownremark( sort: { order: desc, fields: [frontmatter___order] } filter: { frontmatter: { templatekey: { eq: "projects" } } } limit: 1000 ) { edges { node { id frontmatter { title subtitle featured_image { childimagesharp { sizes(maxwidth: 960) { ...gatsbyimagesharpsizes } } } link } html } } } site { sitemetadata { shorttitle } } }
``` when doing so, `gatsby develop` runs fine and even shows the images
but when i run `gatsby build` it seems to work but in the end, it throws error ```
success building static html for pages 3.818 s
error input file is missing or of an unsupported image format error: input file is missing or of an unsupported image format error unhandled rejection error: input file is missing or of an unsupported image format
``` the funny thing is, if i just ignore the error and serve with `gatsby serve` it seems to work perfectly fine
i don't know why the errors are happening
i have tried all approach for solving this 1
add `featured_image` to every frontmatter.
remove the `featured_image` query from graphql.
remove the `gatsby-remark-images` plugin
but nothing seems to work, except for actually removing the images and the sharp plugin.
i just upgraded gatsby from version 1.9.250 to 1.9.264
before that upgrade my site was working fine in development mode
after the upgrade all pages yield blank output with a 404 as status code.
as per #issuecomment-390571773 - if something triggers a warning in the console during the initial build process of `gatsby develop`, subsequent messages in the console appear to get lost
specifically, the useful links to the development site and graphiql editor.
right now, using assistive tech to navigate between pages works, but doesn't announce that the user has reached the next page
this is confusing, so we should find a way to mimic standard navigation behavior when using `gatsby-link` for navigation
thanks to @nickcolley for pointing this out! here were a few suggestions he came up with: - focus the page after routing
- use aria live regions
- use a service worker to simulate server routing, but with less lag - this seems like the least desirable options, since it would require a full page re-render for all navigation; if someone wants this behavior, they could omit `gatsby-link` to get it
nick has done some research and mentioned he'll follow up on this issue with his findings
this _may_ be an upstream fix for react router, but let's make sure it's at least working with a11y in mind in gatsby.
components being used on 404 page don't have access to passed props.
i have this issue with styled components (accessing theme prop inside them), so example will be based on that.
as per i was having isssues with graphql when the results were mixed int and float.
adding a page named `search.js` with a site that leverages client only routing causes gatsby to always serve `index.js`
as stated in the title, some of my graphql queries enclosed in a `staticquery` component refuse to run in development mode until i change the content of its container page and save it.
when visiting a link that doesn't exist on a gatsby site, the page flashes a couple of times as it's rendering the 404 page.
gatsby-plugin-sass@2.0.0-alpha.11 emits the following error message if gatsby-plugin-react-helmet@2.0.12-3 is installed: ```
$ gatsby develop
success delete html files from previous builds 0.012 s
success open and validate gatsby-config.js 0.010 s
success copy gatsby files 0.126 s
success onprebootstrap 0.055 s
success source and transform nodes 0.034 s
success building schema 0.184 s
success createpages 0.000 s
success createpagesstatefully 0.060 s
success onpreextractqueries 0.001 s
success update schema 0.066 s
success extract queries from components 0.030 s
success run graphql queries 0.014 s
success write out page data 0.012 s
success write out redirect data 0.003 s
success onpostbootstrap 0.001 s info bootstrap finished - 11.503 s error inst.render is not a function typeerror: inst.render is not a function - render-page.js:22633 processchild c:/development/projects/gatsby-v2-test/public/render-page.js:22633:18 - render-page.js:22490 resolve c:/development/projects/gatsby-v2-test/public/render-page.js:22490:5 - render-page.js:22775 reactdomserverrenderer.render c:/development/projects/gatsby-v2-test/public/render-page.js:22775:22 - render-page.js:22749 reactdomserverrenderer.read c:/development/projects/gatsby-v2-test/public/render-page.js:22749:19 - render-page.js:23132 rendertostaticmarkup c:/development/projects/gatsby-v2-test/public/render-page.js:23132:25 - render-page.js:417 object../.cache/develop-static-entry.js.__webpack_exports__.default c:/development/projects/gatsby-v2-test/public/render-page.js:417:90 - html-renderer.js:23 worker.queue [as fn] [gatsby-v2-test]/[gatsby]/dist/utils/html-renderer.js:23:36 - worker.js:69 worker.start [gatsby-v2-test]/[better-queue]/lib/worker.js:69:29 - queue.js:701 queue._startbatch [gatsby-v2-test]/[better-queue]/lib/queue.js:701:12 - queue.js:572 [gatsby-v2-test]/[better-queue]/lib/queue.js:572:12 - index.js:87 memorystore.getlock [gatsby-v2-test]/[better-queue-memory]/index.js:87:3 - queue.js:533 [gatsby-v2-test]/[better-queue]/lib/queue.js:533:17 - index.js:69 memorystore.takefirstn [gatsby-v2-test]/[better-queue-memory]/index.js:69:3 - queue.js:473 queue._getnextbatch [gatsby-v2-test]/[better-queue]/lib/queue.js:473:54 - queue.js:530 queue._processnext [gatsby-v2-test]/[better-queue]/lib/queue.js:530:8 - queue.js:520 [gatsby-v2-test]/[better-queue]/lib/queue.js:520:12 error unhandled rejection typeerror: inst.render is not a function - render-page.js:22633 processchild c:/development/projects/gatsby-v2-test/public/render-page.js:22633:18 - render-page.js:22490 resolve c:/development/projects/gatsby-v2-test/public/render-page.js:22490:5 - render-page.js:22775 reactdomserverrenderer.render c:/development/projects/gatsby-v2-test/public/render-page.js:22775:22 - render-page.js:22749 reactdomserverrenderer.read c:/development/projects/gatsby-v2-test/public/render-page.js:22749:19 - render-page.js:23132 rendertostaticmarkup c:/development/projects/gatsby-v2-test/public/render-page.js:23132:25 - render-page.js:417 object../.cache/develop-static-entry.js.__webpack_exports__.default c:/development/projects/gatsby-v2-test/public/render-page.js:417:90 - html-renderer.js:23 worker.queue [as fn] [gatsby-v2-test]/[gatsby]/dist/utils/html-renderer.js:23:36 - worker.js:69 worker.start [gatsby-v2-test]/[better-queue]/lib/worker.js:69:29 - queue.js:701 queue._startbatch [gatsby-v2-test]/[better-queue]/lib/queue.js:701:12 - queue.js:572 [gatsby-v2-test]/[better-queue]/lib/queue.js:572:12 - index.js:87 memorystore.getlock [gatsby-v2-test]/[better-queue-memory]/index.js:87:3 - queue.js:533 [gatsby-v2-test]/[better-queue]/lib/queue.js:533:17 - index.js:69 memorystore.takefirstn [gatsby-v2-test]/[better-queue-memory]/index.js:69:3 - queue.js:473 queue._getnextbatch [gatsby-v2-test]/[better-queue]/lib/queue.js:473:54 - queue.js:530 queue._processnext [gatsby-v2-test]/[better-queue]/lib/queue.js:530:8 - queue.js:520 [gatsby-v2-test]/[better-queue]/lib/queue.js:520:12 error command failed with exit code 1.
info visit for documentation about this command.
v2 gatsbygram doesn't build, failing with a `window is not defined` error
disabling the `gatsby-plugin-manifest` plugin avoids the error for `gatsby develop`, but not `gatsby build`
gatsbygram's [`gatsby-browser.js`]( #l1) references `window` which triggers the error
this seems to be caused by `import { apirunner } from "./api-runner-browser"` in `cache-dir/loader.js` in addition to importing from `gatsby` in the manifest plugin\'s [`gatsby-ssr.js`]( #l2).
`gatsby-remark-autolink-headers` adds a [script]( #l39-l53) to scroll to the anchor
the issue is since the native browser event is also fired, it takes to target to complete top and then the above script adds the offset which leads to a jumping effect
![jumpy](
html inside code-block is rendered when no language is defined on the codeblock.
when using `gatsby-source-filesystem` and `gatsby-transformer-json`, if your json objects have an `id` key, with a number instead of a string, you l get the following error for each node: ```sh
validationerror: child "id" fails because ["id" must be a string]
table alignments using colons should work properly when using gatsby-transformer-remark.
in v1 using css modules, the css custom properties get compiled away
i'm inclined to blame this on an optimization step (cssnext/cssnano?), or maybe autoprefixer, but i haven't had the chance to look into it.
this is for an issue originally reported by @sonicah on
the issue involves potentially the js not getting properly cleared from the cache in safari if the website is updated while the user is in the middle of a browser session.
error thrown when running `gatsby serve`
gatsby fails out of the box following the instructions here:
css styles are loading when running 'gatsby develop' however, when deploying to netlify or surge, the styles do not load
here are some of the solutions i tried: - setting `gatsby-plugin-sass` to `1.0.19`
- re-deploying to netlify with build cache cleared
- removing the yarn.lock file to force netlify to use npm
- removing the netlify site altogether and creating a new one
these solutions don't seem to correct the issue of the styles not loading
also i tried deploying to surge.sh and i'm still getting no-styles deployment
i'm pretty befuddled at this point even after looking at similar issues
graphql function`resize(width: 125, height: 125, rotate: 180)` is not work.
`gatsby-plugin-remove-trailing-slashes` causes infinite recompilation and cases blog posts' content to go blank after a few saves/edits.
when running `gatsby develop` and making a change to a markdown file the page fails to render again until gatsby is restarted, failing with `this.props.data is undefined`
when holding a gatsby workshop last week, several people on old, slow windows computers didn't get new page hot reloading to work
they had to restart the dev server to see new page components (in src/pages) added as routes.
based on investigation from @shannonbux and @tsriram
it seems that clicking to select a search result does not remove focus from the search input, which can prevent the search result panel from re-opening when re-focussing the search input.
i have tags arrays in my content, and i want to be able to fetch by those tags.
graphql fields with whitespace in their names are normalized to contain underscores instead, which is great -- but the values for these fields are all null
this probably happens with any other not-completely-alphanumeric field name (not just whitespace)
i've minimally reproduced this at (i'm open to making a pr, but i'm having a hard time figuring out where the schema-field normalization happens[1] and where would be appropriate to update the actual nodes.) [1] `packages/gatsby/src/schema/create-key.js`?
when querying with `resolutions` or `resize` (and probably `sizes`; didn't try), if the requested dimensions are larger than the source image's natural dimensions and upscaling is disabled (as is default), the url returned for the image points to an image with dimensions smaller than the requested dimensions
however, the `width` and `height` fields in the response say what the dimensions *would* be, had the image been upscaled
this means the details given in the srcset are incorrect, and also that the `img` tag has the larger dimensions, meaning the image will be upscaled in the browser.
i'm experimenting with gatsby & wordpress (really cool stuff), when running `gatsby build` i hit this error: ```
error generating javascript bundles failed error: enametoolong: name too long, open '/home/user/applications/wpgatsby/public/path---crazy-insane-long-slug-why-on-earth-did-anyone-ever-choose-to-create-a-header-this-long-its-completely-ridiculous-please-make-it-stop-48ae67005d81988049b2.js'
``` what drives the file naming here?
when parsing an array of dates from a yaml file, gatsby fails to add it to the graphql schema when doing a build without a cache
this triggers warnings about invalid queries, because the property being requested doesn't exist
after killing the process and starting gatsby again, leaving the cache in place, the problem is resolved
i've only observed this for data coming from yaml files, not json files
this may be related to the work done in #3688 that resolved #3556.
since i started using gatsby a couple of months ago, i regularly get issues when visiting the published site
no issue in local development
the issue gets fixed when hitting ctrl-shift-r, but i can hardly expect all my visitors to do this every time..
i just see this error in the console: <img width="629" alt="screen shot 2018-01-18 at 17 59 12" src=" "> the `bootstrap%2003bd3a01b7024eecaa93:52` file shows this:
// execute the module function
modules[moduleid].call(module.exports, module, module.exports, __webpack_require__);
``` this is in a file whose description is `// install a jsonp callback for chunk loading`
is this something to do with chunk loading which breaks because of gatsby-plugin-offline? my setup is very similar to the gatsbyjs.org codebase, so i think that the gatsby site has the same issue, as i reported previously in #3142
do you have any idea of the underlying cause and the proper way to fix this? if there's no proper fix, is there a workaround such as disabling service worker entirely? unfortunately chunking and caching are still way above my skillset, but this is directly impacting our visitors.
a reference field in contentful limited to a single entry but which accepts many types results in an incorrect graphql type being generated
this "full slot field" is a reference to a single entry, and accepts multiple entry types: ![screen shot 2018-01-15 at 10 39 08 am]( ![screen shot 2018-01-15 at 10 40 00 am]( however, the `fullslot` graphql field incorrectly has its type set to `contentfulplaintextmoduletest` instead of a `union(contentfulplaintextmoduletest|contentfulmediamodule`) or something similar
this results in an error running queries when multiple types appear for this reference field
e.g ```graphql
query allfullslices { allcontentfulslicefull { edges { node { fullslot { __typename } } } }
``` ```json
{ "errors": [ { "message": "expected value of type \\"contentfulplaintextmoduletest\\" but got: [object object].", "locations": [ { "line": 30, "column": 9 } ], "path": [ "allcontentfulslicefull", "edges", 0, "node", "fullslot" ] } ], "data": { "allcontentfulslicefull": { "edges": [ { "node": { "fullslot": null } }, { "node": { "fullslot": { "__typename": "contentfulplaintextmoduletest" } } } ] } }
``` you can see the inferred type for `fullslot` is set incorrectly in graphiql: ![screen shot 2018-01-15 at 10 45 15 am]( having done a lot of `console.log`-ing, it seems like the issue comes from the logic that extracts an "example value" for a given node: #l52 maybe a fix is to wrap any contentful reference fields in an array? our current work around is just going to be to convert contentful references into "many" references so that way the union types are built correctly and our project can build again.
i have a graphql query in my layout, which is passing down data to all pages
the 404 page receives this data in development, but not in production.
each time i load new page, the scroll position stays same as it was on the previous page.
i want to reset the scroll position each time page is reloaded.
the csv item exporter does not flush on close.
some [ides recognize type annotations]( within docstring to make suggestions or raise warnings related to your code
in the scrapy source, there are some annotations in the docstring that are wrong
this is a minor issue
the `scrapy.crawler.crawlerprocess.crawl` method expects one mandatory positional argument, `crawler_or_spidercls`, and optional positional and keyword arguments through arbitrary argument lists
the type annotations for the arbitrary argument lists are wrong:
#l183-l185 when using `list` for `args` and `dict` for `kwargs`, the docstring suggests that the types of arguments passed through these lists should be `list` and `dict` respectively
according to [pep 484]( #arbitrary-argument-lists-and-default-argument-values), the types of `args` and `kwargs` will be automatically deduced as `tuple[list, ...]` and `dict[dict, int]`, so the specified types correspond to the values they contain
these annotations don't match the intention you have with this method, do they? btw, `list` and `dict` weren't generic types for annotations until [python 3.9]( #pep-585-builtin-generic-types).
thank you for maintaining this awesome software :) i am working on a project using scrapy that implements a custom downloader class ([link](
i want to resolve ipv6 addresses, and i found the section in the documentation about the ``dns_resolver`` setting that was added in #4227
i tried enabling the new ``dns_resolver = "scrapy.resolver.cachinghostnameresolver"`` and was immediately greeted with this exception
unhandled error
traceback (most recent call last): file "/usr/local/lib/python3.8/site-packages/scrapy/commands/crawl.py", line 27, in run self.crawler_process.start() file "/usr/local/lib/python3.8/site-packages/scrapy/crawler.py", line 327, in start reactor.run(installsignalhandlers=false) # blocking call file "/usr/local/lib/python3.8/site-packages/twisted/internet/base.py", line 1283, in run self.mainloop() file "/usr/local/lib/python3.8/site-packages/twisted/internet/base.py", line 1292, in mainloop self.rununtilcurrent()
--- <exception caught here> --- file "/usr/local/lib/python3.8/site-packages/twisted/internet/base.py", line 913, in rununtilcurrent call.func(*call.args, **call.kw) file "/usr/local/lib/python3.8/site-packages/twisted/internet/tcp.py", line 449, in resolveaddress d = self.reactor.resolve(self.addr[0]) file "/usr/local/lib/python3.8/site-packages/twisted/internet/base.py", line 638, in resolve return self.resolver.gethostbyname(name, timeout) file "/usr/local/lib/python3.8/site-packages/twisted/internet/_resolver.py", line 277, in gethostbyname self._nameresolver.resolvehostname(firstonewins(result), name, 0, file "/usr/local/lib/python3.8/site-packages/scrapy/resolver.py", line 80, in resolvehostname class cachingresolutionreceiver(resolutionreceiver):
builtins.typeerror: __init__() takes 2 positional arguments but 4 were given
when scraping certain sites and passing cookies to scrapy, i\'ve had an issue pop up where the page wasn\'t able to scrape due to an error message `"invalid cookie found in request {}: {} (\'{}\' is missing)"`
this is because some websites and pages form cookies with an empty value instead of not including the key altogether (hacky fix on their side), causing the newly added check in scrapy/downloadermiddlewares/cookies.py ln
78 to pass and stop the request
perhaps a setup variable that would let us toggle this cookie check would solve the issue, or perhaps removing this specific check/making it a warning, and not causing the function to return
the only other solution temporarily right now if for scrapy users to have to re-format the cookies themselves, and some sites do want the empty value cookie object
since 2.3.0 just got released, i've only seen one other thread (on stackoverflow) mentioning this issue
i'm building a scraper that follows some urls with a pattern with the response.follow function
i'm currently stuck on a webpage which has the <base> element in the header commented out
the href in the <base> element is invalid
when i try to follow a relative url on the webpage it incorrectly tries to send me to the invalid url
it ignores the fact that it actually is a comment.
i have some error when trying to install scrapy
don't know if it should be considered as a bug but at least it should be the same behaviour if spider callback only raised an exception or raised an exception with yielding
when raising an exception from spider callback with also yielding item or request if neither one middleware catch this exception by `return iterable` the sequence of process_spider_exception methods are executed multiple times
actual behaviuor in case of n enabled middlewares and all of them returns none for thi exception:
exec mw_n.process_spider_exception -> (mw_n-1).process_spider_exception -> (mw_n-2).process_spider_exception -> ..
-> mw_1.process_spider_exception -> (mw_n-1).process_spider_exception -> (mw_n-2).process_spider_exception -> ..
-> mw_1.process_spider_exception -> ...
if i make a `dataclass` item and want to export to csv, i get this error: ```
file "/home/tadej/miniconda3/envs/main/lib/python3.7/site-packages/scrapy/exporters.py", line 251, in _write_headers_and_set_fields_to_export self.fields_to_export = list(item.fields.keys())
attributeerror: 'companyitem' object has no attribute 'fields'
the problem stems from here #l243-l253 there should be an additional if case checking if the item is of type dataclass, and then accessing the fields differently, perhaps as
[field.name for field in fields(item)]
when running `scrapy startproject` after creating a virtualenv in .venv in the project directory, the executable files have their permissions changed.
the test `tests/test_scheduler.py::testintegrationwithdownloaderawareinmemory::test_integration_downloader_aware_priority_queue` raises the following exception: ```
error scrapy.core.engine:engine.py:308 stats close failure
traceback (most recent call last): file "/home/lukas/projects/3rd/scrapy/.tox/py/lib/python3.8/site-packages/twisted/internet/defer.py", line 654, in _runcallbacks current.result = callback(current.result, *args, **kw) file "/home/lukas/projects/3rd/scrapy/scrapy/core/engine.py", line 328, in <lambda> dfd.addboth(lambda _: self.crawler.stats.close_spider(spider, reason=reason)) file "/home/lukas/projects/3rd/scrapy/scrapy/statscollectors.py", line 48, in close_spider self._persist_stats(self._stats, spider) file "/home/lukas/projects/3rd/scrapy/scrapy/statscollectors.py", line 61, in _persist_stats self.spider_stats[spider.name] = stats
typeerror: unhashable type: 'list'
``` the exception is only logged by scrapy.core.engine and hence swallowed by py.test
i discovered it accidentally when using the `log_cli = true` pytest setting.
when having `feed_store_empty=false` and multiple feeds, and the output is empty, `storage.store` is called until first empty feed slot is encountered.
when i have multiple feeds and a blocking feed storage, i get duplicated feed logs.
the value of the `twisted_reactor` setting is not taken into account if the setting is specified in a spider's `custom_settings` attribute.
it works well if the setting is specified in a project's settings file, as a parameter when creating a `crawlerprocess` object (as the tests show) or as a cli argument with the `-s` option.
a spider inherits sitemapspider parcing sites sitemaps, starting from `robots.txt`, has `jobdir` set
i run it as a `centos 8.x` service with a unit file defined and it runs just fine
but after i stop the service (memory leaks or something) and run it again it starts spider and closes it immidiately
it does not resume the job
the only way to start it is to remove the directory set in `jobdir` setting, but then it starts parsing the target site all over again.
code that is accepted by the python interpreter raises when fed through `textwrap.dedent`
can not get certificate information when http body is empty.
`follow_all` with an empty list of urls fails with `valueerror('please supply exactly one of the following arguments: urls, css, xpath')` what i would expect instead is just an empty generator of requests.
i try to use `scrapy parse` command in cmd naconda env ut when it logs scraped items and requests, there are full of garbled code which i show you below dditional context
i have no idea of it, but it seems to have nothing to do with character encoding,
i'm having the same issue reported in [issue 4075]( but i'd like to provide some more information.
`process_spider_exception` method of a spider middleware is ignored when spider middleware is first and callback is a generator.
binary (file) responses are identified as `textresponse` instead of a plain `response` in `spider.parse`.
in our case, we execute command `scrapy crawl` in airflow task and the exit code would be used to judge this task success or failure
i agree that `scrapy crawl` ignores spider exceptions because it's unpredictable in the crawling process
back to our case, we export data to file or database in the pipeline and we create the directory or database connection in `open_spider(self, spider)`
i think if there is an exception happens during this function, it's reasonable to propagate a non-zero exit code
it because we normally do some initialization in this function.
when i scrapyied the url " " with scrapy , it is ok in version 1.7 , but it is forbidden by robots.txt in version 1.8
the robots.txt `user-agent: *
disallow:
disallow:
disallow:
disallow:
disallow: user-agent: twitterbot
closespider_timeout settings 36000 run for five days...
closespider_timeout settings 60 closespider_timeout(is ok)
when the 302 response return a headers's location startswith 3 slash, the scrapy redirect to a url different from what the browser do.
using the dummystatscollector results in an exception: ```
2019-09-09 13:51:23 [scrapy.utils.signal] error: error caught on signal handler: <bound method corestats.spider_closed of <scrapy.extensions.corestats.corestats object at >>
traceback (most recent call last): file ".../lib/python3.6/site-packages/twisted/internet/defer.py", line 150, in maybedeferred result = f(*args, **kw) file ".../lib/python3.6/site-packages/pydispatch/robustapply.py", line 55, in robustapply return receiver(*arguments, **named) file ".../lib/python3.6/site-packages/scrapy/extensions/corestats.py", line 28, in spider_closed elapsed_time = finish_time - self.stats.get_value(\'start_time\')
typeerror: unsupported operand type(s) for -: 'datetime.datetime' and 'nonetype'
``` this problem has been introduced in aa46e1995cd5cb1099aba17535372b538bd656b3.
this issue was already reported #2397 but the reporter closed the issue after posting a temporary fix
i reckon there should be an elegant way to hande this as this is a common use case i guess
maybe a configurable setting that allows image to be downloaded even when the url is redirected.
contracts can't be written for callbacks that receive `cb_kwargs`
#3804 introduced a bug where `itemloader` fields are reprocessed.
related #3897.
bug report from @fritzx6 (thanks!) that the `comman_name` column appears empty, looks like [this commit]( may be partially responsible
i've yet to dig into this, filing for awareness and will triage/report back soon, unless someone beats me to it!
there appears to be a parsing issue with xpath filter syntax, that causes an osquery crash
see the below query to reproduce.
the "security" channel for the `windows_eventlog` table shows inconsistent numbers of events when constraints are added to the query
there have been a handful of reports about duplicate events
this is meant as a rollup of these:
*
*
* # debugging steps it would be great if someone in this state could run `select * from osquery_events;` # speculation about causes * when nick removed the windows events from core, the static initialization might have started doing soemthing twice.
* in the config change, we _stop_ all the publishers, then _start_ them
so there might be a bug there.
* if osquery has stopped things, but the os thinks there are still callbacks, when it's restarted the old things may come back.
while in the step building libaudit there is a circular definition
it is caused because osquery libaudit submodule [is snapshotted at `20204cc`]( which appears out of date
[in that version's libaudit.h]( #l263), it says: #define audit_filter_exclude audit_filter_type but the definition of `audit_filter_type` on kubuntu 20 in `<linux/audit.h>` is: #define audit_filter_type audit_filter_exclude /* obsolete misleading naming */ clearly a problem
if the libaudit were brought up to [the version at time of writing]( #l320), it would say: #ifndef audit_filter_exclude #define audit_filter_exclude audit_filter_type they seemed to [do this on purpose](
the users table will always generate a row for every user using netenumuser: #l124 this can be expensive if the machine has a large number of local accounts or is a domain controller
the table should be improved to optimize any queries joining to the user table
if a sid constraint is used the user information could be looked up individually (e.g
using lookupaccountsid)
the sid column could also be marked as indexed to ensure the planner calls the table with this constraint whenever possible.
i was looking at the table cache code in `osquery/core/tables.cpp` and noticed that it does not check whether the query has all the columns requested
in reality, the query cache is only useful for full table scans with all the columns requested
virtual table implementations can optimize and only fetch and return the columns requested
consider the following two queries, where the first one executes, and the second one uses the cache
the second query ends up acting on cmdline fields that are empty, since the processes table (on windows) checks `if (context.iscolumnused("cmdline")) ` before fetching that information: - `select pid, name, path from processes`
- `select * from processes where cmdline like '%baddie%'` relevant code: ![image](
osquery consumes remaining space on my hard drive when it finds a symlink loop
this happens with games installed from lutris and themes downloaded for gnome
it seems osqueryd is eating all of my hard drive space with logs
it first started with games i installed with lutris, files in the games folder would be "flagged" as symlink loops
osqueryd's /var/log/osquery would continue to eat up the entire disk
i would check the folder and it would be 144gb+
if i deleted the entire game, osdquery would then move to the next game and find something
so i just deleted the games folder because it was late, and i was fed up with the issue
then osqueryd started pointing out symlink loops in the themes that i grabbed from github and dropped into my themes folder
i'm not sure if it matters, but i installed my system with btrfs
/dev/nvme0n1p6 on / type btrfs (rw,relatime,seclabel,ssd,space_cache,subvolid=256,subvol=/root)
/dev/nvme0n1p6 on /home type btrfs (rw,relatime,seclabel,ssd,space_cache,subvolid=258,subvol=/home)
/dev/nvme0n1p4 on /boot type ext4 (rw,relatime,seclabel)
/dev/nvme0n1p1 on /boot/efi type vfat (rw,relatime,fmask=0077,dmask=0077,codepage=437,iocharset=ascii,shortname=winnt,errors=remount-ro) ``` ``` text
3.1m ./anaconda
12m ./audit
0 ./blivet-gui
0 ./glusterfs
4.0g ./journal
0 ./libvirt
0 ./private
0 ./speech-dispatcher
19m ./opswatclient
144g ./osquery
0 ./expressvpn
0 ./lightdm
0 ./mariadb
4.0k ./deepin
``` ``` text
1 root root 0 may 24 11:50 osqueryd.results.log
1 root root 591 may 24 11:50 osqueryd.warning.20200524-115029.45614
1 root root 591 may 24 11:50 osqueryd.info.20200524-115029.45614
1 root root 591 may 24 11:51 osqueryd.warning.20200524-115133.45689
1 root root 591 may 24 11:51 osqueryd.info.20200524-115133.45689
1 root root 591 may 24 11:51 osqueryd.warning.20200524-115142.45718
1 root root 591 may 24 11:51 osqueryd.info.20200524-115142.45718
1 root root 591 may 24 11:51 osqueryd.warning.20200524-115152.45763
1 root root 591 may 24 11:51 osqueryd.info.20200524-115152.45763
1 root root 591 may 24 11:52 osqueryd.warning.20200524-115202.45786
1 root root 591 may 24 11:52 osqueryd.info.20200524-115202.45786
1 root root 591 may 24 11:52 osqueryd.warning.20200524-115212.45809
1 root root 591 may 24 11:52 osqueryd.info.20200524-115212.45809
1 root root 591 may 24 11:52 osqueryd.warning.20200524-115221.45831
1 root root 591 may 24 11:52 osqueryd.info.20200524-115221.45831
1 root root 591 may 24 11:52 osqueryd.warning.20200524-115231.45869
1 root root 591 may 24 11:52 osqueryd.info.20200524-115231.45869
1 root root 591 may 24 11:52 osqueryd.warning.20200524-115240.45895
1 root root 591 may 24 11:52 osqueryd.info.20200524-115240.45895
1 root root 591 may 24 11:52 osqueryd.warning.20200524-115250.45934
1 root root 591 may 24 11:52 osqueryd.info.20200524-115250.45934
1 root root 591 may 24 11:53 osqueryd.warning.20200524-115300.45958
1 root root 591 may 24 11:53 osqueryd.info.20200524-115300.45958
1 root root 591 may 24 11:53 osqueryd.warning.20200524-115309.45980
1 root root 591 may 24 11:53 osqueryd.info.20200524-115309.45980
1 root root 591 may 24 11:53 osqueryd.warning.20200524-115319.46005
1 root root 591 may 24 11:53 osqueryd.info.20200524-115319.46005
1 root root 591 may 24 11:53 osqueryd.warning.20200524-115328.46041
1 root root 591 may 24 11:53 osqueryd.info.20200524-115328.46041
1 root root 591 may 24 11:53 osqueryd.warning.20200524-115338.46066
1 root root 591 may 24 11:53 osqueryd.info.20200524-115338.46066
1 root root 591 may 24 11:53 osqueryd.warning.20200524-115348.46100
1 root root 591 may 24 11:53 osqueryd.info.20200524-115348.46100
1 root root 591 may 24 11:53 osqueryd.warning.20200524-115357.46126
1 root root 591 may 24 11:53 osqueryd.info.20200524-115357.46126
1 root root 38 may 24 11:54 osqueryd.warning -> osqueryd.warning.20200524-115407.46149
1 root root 35 may 24 11:54 osqueryd.info -> osqueryd.info.20200524-115407.46149
1 root root 591 may 24 11:54 osqueryd.warning.20200524-115407.46149
1 root root 591 may 24 11:54 osqueryd.info.20200524-115407.46149
log file created at: 2020/05/24 11:51:42
running on machine: tinolinuxdesktop
log line format: [iwef]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
w0524 11:51:42.910405 45718 filesystem.cpp:292] symlink loop detected possibly involving: /home/martinojones/themes/macos/gtk-3.0/gtk-3.20/assets
w0524 11:51:42.934082 45718 inotify.cpp:94] failed to do stat on: /opt/bin/
w0524 11:51:42.934128 45718 inotify.cpp:94] failed to do stat on: /opt/sbin/
w0524 11:51:42.939642 45718 filesystem.cpp:292] symlink loop detected possibly involving: /home/martinojones/themes/macos/gtk-3.0/gtk-3.20/assets
minor bug but annoying for automated validation/testing.
if hashing of a file fails for md5/sha1/sha256, no messages are sent to stderr and the value returned for them is an empty string
however for ssdeep type hashing, if it fails it will print a message to stderr and also return a "-1"
the behavior is inconsistent
relevant code:
#l194-l201
because osquery does not correctly verify the tls sni hostname, it may be possible to present a valid certificate for a different tls endpoint and, in the absence of a configured root chain of trust in osquery, mitm osquery traffic.
playing with the windows [patches]( #patches) table, i noticed the `install_date` column is blank
i see that this is defined by #l32 which, by the name `getstring`, expects string data
however, the [upstream docs]( describe it as a `datetime` field
though, that strategy seems to work for the `video_info` table
this [internet thread]( has some discussion about inherited properties.
we noticed a couple of issues with the windows version table
windows seems to have a major, minor, build, and build revision
notably the is no `patch` level
this means that when we select against the `os_version` table, we get cast errors: ```
osquery> select patch from os_version; i1125 20:47:07.555104 3564 dynamic_table_row.cpp:114] error casting patch () to integer patch = ``` also, it could be interesting to add a build revision
i know this is in the registry, not sure it's in wmi
osquery> select data from registry where key = "hkey_local_machine\\software\\microsoft\\windows nt\\currentversion\\" and name = "ubr" ; data = 864 ```
debugging something on slack, it seems like using `decorators` can cause the options block to be ignored
$ cat /tmp/osq.conf { "decorators":{"load":["select uuid as host_uuid from system_info;" ]}, "options": { "disable_tables": "kernel_info" }
} $ osqueryd -s -config_path /tmp/osq.conf 'select version from kernel_info;'
+---------+
| version |
+---------+
+---------+ $ cat /tmp/osq.conf { //"decorators":{"load":["select uuid as host_uuid from system_info;" ]}, "options": { "disable_tables": "kernel_info" }
} $ osqueryd -s -config_path /tmp/osq.conf 'select version from kernel_info;'
error: no such table: kernel_info
the nice-to-have, "you did not include a correct where clause" warnings are missing from the shell
i should investigate why they are gone and if this is intentional
iirc these were a feature request from several people and they were helpful in debugging unexpected behavior.
`power_sensors` table returns `-1.00` value for all power related smc keys, instead of actual values
osquery> .all power_sensors;
+------+----------+-------------------+-------+
| key | category | name | value |
+------+----------+-------------------+-------+
| pblc | power | battery rail | -1.00 |
| pc0r | power | mainboard s0 rail | -1.00 |
| pcpc | power | cpu cores | -1.00 |
| pcpg | power | cpu gfx | -1.00 |
| pdtr | power | dc in total | -1.00 |
| pg0r | power | gpu rail | -1.00 |
| pstr | power | system total | -1.00 |
| ic0r | current | cpu rail | -1.00 |
| id0r | current | mainboard s0 rail | -1.00 |
| ig0c | current | gpu rail | -1.00 |
| im0c | current | memory controller | -1.00 |
| ipbr | current | charger bmon | -1.00 |
| vd0r | voltage | mainboard s0 rail | -1.00 |
| vg0c | voltage | gpu core | -1.00 |
| vp0r | voltage | 12v rail | -1.00 |
+------+----------+-------------------+-------+
``` joining with `smc_keys` table, we can see that the raw smc data is still there: ```
osquery> select power_sensors.key, ...> category, ...> name, ...> power_sensors.value as power_value, ...> smc_keys.value as raw_smc_value, ...> smc_keys.type as smc_type, ...> smc_keys.size as smc_size ...> from power_sensors ...> join smc_keys where power_sensors.key = smc_keys.key;
+------+----------+-------------------+-------------+---------------+----------+----------+
| key | category | name | power_value | raw_smc_value | smc_type | smc_size |
+------+----------+-------------------+-------------+---------------+----------+----------+
| pblc | power | battery rail | -1.00 | 00000000 | flt | 4 |
| pc0r | power | mainboard s0 rail | -1.00 | 1f3ea240 | flt | 4 |
| pcpc | power | cpu cores | -1.00 | 0107 | sp87 | 2 |
| pcpg | power | cpu gfx | -1.00 | 0000 | sp87 | 2 |
| pdtr | power | dc in total | -1.00 | 00000000 | flt | 4 |
| pg0r | power | gpu rail | -1.00 | 94fb7040 | flt | 4 |
| pstr | power | system total | -1.00 | 06f9 | sp87 | 2 |
| ic0r | current | cpu rail | -1.00 | 91adc13e | flt | 4 |
| id0r | current | mainboard s0 rail | -1.00 | ff9fb939 | flt | 4 |
| ig0c | current | gpu rail | -1.00 | 00000000 | flt | 4 |
| im0c | current | memory controller | -1.00 | 00000000 | flt | 4 |
| ipbr | current | charger bmon | -1.00 | 4d75983f | flt | 4 |
| vd0r | voltage | mainboard s0 rail | -1.00 | 00000000 | flt | 4 |
| vg0c | voltage | gpu core | -1.00 | a5d54d3f | flt | 4 |
| vp0r | voltage | 12v rail | -1.00 | 164c4641 | flt | 4 |
+------+----------+-------------------+-------------+---------------+----------+----------+
``` this suggests that we may not be converting the various smc data types correctly
i will dig deeper on this later
making a registry call from example_extension gives error "no registry item name specified".
auto status = osquery::registry::call("config", {{"action", "genconfig"}}, response); even though config_plugin is set properly to local filesystem and osquery core
can fetch the same config correctly.
i e noticed an odd behavior when running osquery as a shell process and having extensions loaded
running ```
osqueryd.exe --s --verbose "select * from os_version"
``` with anything in the `extensions.load` file (i used the open source trail_of_bits extensions for example), it will execute the query and exit the shell (as expected) the majority of the time
but, if an extension happens to register before the query results come back, the shell process just hangs and you have to ctrl+c (usually twice) to get out of it
i running a build from source on windows 10 with the latest master branch, but i not sure how long the issue has actually been in the codebase
while trying to build `master` (buck) on darwin
in file included from osquery/remote/http_client.h:27:
in file included from "buck-out/release"/gen/third-party/boost/boost_1.66.0_macos-x86_64_header_dir/include/boost/asio/ip/tcp.hpp:25:
in file included from "buck-out/release"/gen/third-party/boost/boost_1.66.0_macos-x86_64_header_dir/include/boost/asio/ip/basic_resolver.hpp:27:
in file included from "buck-out/release"/gen/third-party/boost/boost_1.66.0_macos-x86_64_header_dir/include/boost/asio/ip/basic_resolver_iterator.hpp:27:
"buck-out/release"/gen/third-party/boost/boost_1.66.0_macos-x86_64_header_dir/include/boost/asio/ip/basic_resolver_entry.hpp:54:42: error: no type named \'string_view\' in namespace \'boost::asio\'; did you mean \'std::string_view\'? boost_asio_string_view_param host, boost_asio_string_view_param service) ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
"buck-out/release"/gen/third-party/boost/boost_1.66.0_macos-x86_64_header_dir/include/boost/asio/detail/string_view.hpp:42:39: note: expanded from macro \'boost_asio_string_view_param\'
# define boost_asio_string_view_param boost::asio::string_view ^~~~~~~~~~~~~
/applications/xcode.app/contents/developer/toolchains/xcodedefault.xctoolchain/usr/include/c++/v1/string_view:770:37: note: 'std::string_view' declared here
typedef basic_string_view<char> string_view; ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
20 errors generated.
``` it seems related to (1) my version of macos, (2) i suggest adding a temporary work-around until the project updated the boost version in third-party.
when running osqueryd with a "view" and a scheduled query on the view, the query works on first run when there is no database, and all subsequent runs fail with `no such table` on the view.
the build fails when libc++ in installed
might be related to #1660
according to the documentation, "if all of the discovery queries return more than zero rows, then the queries are added to the query schedule"
however, the code in distributed.cpp acceptwork() will add queries regardless of the discovery scan results.
error message should point faulty query name else it's make harder to locate issue..
valid for #l568 and l582 found this related bug but more about planner and query format.
we are seeing issues on mac machines with the new t2 chip reporting that the disk is encrypted when filevault hasn't been enabled
<img width="1284" alt="security___privacy_and_1__osqueryd" src=" ">
the certificates table shows the serial number reversed (wrong endianess)
this is because the serial number is actually a big int and it is encoded in little endian form
the code simply hex encodes the encoded form: ``` std::string serial; boost::algorithm::hex( std::string(certcontext->pcertinfo->serialnumber.pbdata, certcontext->pcertinfo->serialnumber.pbdata + certcontext->pcertinfo->serialnumber.cbdata), back_inserter(serial)); r["serial"] = serial;
``` which is incorrect since it needs to also deal with byte endianess
the overall result is that the serial number it shows is backwards from the one, say, windows certmgr shows
![image](
under windows the query: select key_strength from certificate produces nonsense results like 1437, 677 etc
this is because the code just emits the length of the der encoded raw certificate which has nothing to do with the key strength
#l189
``` r["key_strength"] = integer(certcontext->cbcertencoded);
``` key strengths are typically something like 4096, 1024, etc.
ripgrep exits with the following error..
error: the argument '--pretty' was provided more than once, but cannot be used multiple times ...if `-p` or `--pretty` is in the configuration file and condensed short option syntax is used on the command line.
.z compress test fails with both uncompress provided by gzip and ncompress package.
gentoo bug and full buld log available here
i have a pattern (with look-around) which with `--count` reports `2` but with `--count-matches` reports `0`
this doesn't appear to make sense
i would expect ``--count-matches` to report a number at least as high as `--count`.
the cmakelists.txt contains #l756-l761 which basically says that pytorch requires glog and gflags
however i just downloaded the "official pytorch" via `pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f ` and checked that glog is not used there
`torch/include/c10/macros/cmake_macros.h` contains `/* #undef c10_use_glog */` and the cmake config string in torch/include/caffe2/core/macros.h confirms that too this matches what @lw reported
see discussion in #issuecomment-693344746 is the warning message from cmake outdated? if so since when? is that a mistake? in particular i'd like to ask if using glog is recommend, required and/or tested
background of my question is that i'm compiling pytorch on power and seeing failures when using glog due to floating point exceptions getting enabled without being able to tell why
cc @malfet @seemethere @walterddr
to reproduce: ```
$cat dockerfile
from centos/python-36-centos7
workdir /root
run yum update -y
run pip install --upgrade pip
run pip install opencv-python
run pip install -u matplotlib
run pip install torch==1.6.0+cpu -f
copy a.py /root/a.py
run python -x faulthandler a.py $cat a.py
import torch
try: import cv2
except: pass
import matplotlib.pyplot as plt $docker build -t test:v0
..................
step 10/10 : run python -x faulthandler a.py ---> running in 1b7bc36c9727
fatal python error: segmentation fault thread (most recent call first): file "/opt/rh/rh-python36/root/usr/lib64/python3.6/json/encoder.py", line 356 in _iterencode_dict
the command '/bin/sh -c python -x faulthandler a.py' returned a non-zero code: 139
``` a lower-level repro (to replace a.py above):
from ctypes import cdll def load(x): print("loading", x) try: cdll.loadlibrary(x) except exception as e: print("\\tfailed", e) pass else: print("\\tsucc") load("/opt/app-root/lib/python3.6/site-packages/torch/_c.cpython-36m-x86_64-linux-gnu.so")
#load("/opt/app-root/lib/python3.6/site-packages/cv2/../opencv_python.libs/libz-d8a329de.so.1.2.7")
load("/opt/app-root/lib/python3.6/site-packages/cv2/../opencv_python.libs/libcrypto-354cbd1a.so.1.1")
load("libgcc_s.so.1")
logs for this one:
loading /opt/app-root/lib/python3.6/site-packages/torch/_c.cpython-36m-x86_64-linux-gnu.so succ loading /opt/app-root/lib/python3.6/site-packages/cv2/../opencv_python.libs/libcrypto-354cbd1a.so.1.1 failed libz-d8a329de.so.1.2.7: cannot open shared object file: no such file or directory loading libgcc_s.so.1 program received signal sigsegv, segmentation fault
in elf_machine_rela (reloc= , reloc= , skip_ifunc=0, reloc_addr_arg= , version= , sym= , map= ) at ../sysdeps/x86_64/dl-machine.h:299 299 struct link_map *sym_map = resolve_map (&sym, version, r_type); (gdb) bt #0 in elf_machine_rela (reloc= , reloc= , skip_ifunc=0, reloc_addr_arg= , version= , sym= , map= ) at ../sysdeps/x86_64/dl-machine.h:299 #1 elf_dynamic_do_rela (skip_ifunc=0, lazy=<optimized out>, nrelative=<optimized out>, relsize=<optimized out>, reladdr=<optimized out>, map= ) at do-rel.h:137 #2 _dl_relocate_object (scope=<optimized out>, reloc_mode=reloc_mode@entry=0, consider_profiling=<optimized out>, consider_profiling@entry=0) at dl-reloc.c:259 #3 in dl_open_worker (a=a@entry= ) at dl-open.c:423 #4 in _dl_catch_error (objname=objname@entry= , errstring=errstring@entry= , mallocedp=mallocedp@entry= , operate=operate@entry= <dl_open_worker>, args=args@entry= ) at dl-error.c:177 #5 in _dl_open (file= "libgcc_s.so.1", mode=-2147483646, caller_dlopen=<optimized out>, nsid=-2, argc=2, argv= , env= ) at dl-open.c:649 #6 in dlopen_doit (a=a@entry= ) at dlopen.c:66 #7 in _dl_catch_error (objname= , errstring= , mallocedp= , operate= <dlopen_doit>, args= ) at dl-error.c:177 #8 in _dlerror_run (operate=operate@entry= <dlopen_doit>, args=args@entry= ) at dlerror.c:163 #9 in __dlopen (file=<optimized out>, mode=<optimized out>) at dlopen.c:87 #10 in py_dl_open (self=<optimized out>, args=<optimized out>) at /usr/src/debug/python-3.6.9/modules/_ctypes/callproc.c:1377 ``` cc @ezyang @gchanan @zou3519 @malfet @seemethere @walterddr
reported in the [forum]( by `eliaz` (thanks again for reporting this issue :) )
> i using the lowrankmultivariatenormal distribution in order to have a distribution of logits for every pixel of an image.
i have an issue when using this distribution for squared images with a shape that is even and large (>= 512x512).
the following code does not work on a colab notebook when the size is set to 512x512 but does for size 513x513.
i also tried it on different gpus, with the same results.
it works fine when using cpus.
i am using cusolverdn in c++ and import it to python with pybind11.
segment fault after use cusolverdncreate() and cusolverdndestroy() with torch
note: ###**1: when the demo run with torch1.2,it run success, the segfault disappear, does it mean torch 1.5 has some bug?**
###**2: this segfault only appear with "thread_local", does it provide some information for this bug?**
###**3: please see test.py below, if we "import torch" after "import example", segfault disappear.**
###**4: torch have not link libcusolver.so, so we just link it once.** @ezyang say that upgarde cuda may fix this, but after i upgrade cuda to 10.2, segfault as usual
cc please @ezyang @gchanan @zou3519 @yf225 @glaringlee @ngimel @mcarilli <!-- a clear and concise description of what the bug is
the conv3d output inconsistent results between float mode and half mode, if the gpu is v100 and the conv kernel size is (3,1,1) and the input/output channel number are multiple of 8.
i could repro this in pytorch 1.2.0~pytorch 1.5.1 with gpu v100-sxm2/pcie 16gb/32gb
torch.nn.functional.conv2d produces a segmentation fault when using float32 data type and large enough padding <!-- a clear and concise description of what the bug is
our use of `pybind11::gil_scoped_release` can cause crashes when used with daemon threads (from the `threading` package) and with c++ created threads that acquire/release the gil
note that we previously used autonogil, but that has the same problem
this manifests as a crash on exit with a message like: ```
terminate called without an active exception
``` the problem occurs when a thread tries to acquire the gil during python interpreter finalization
the interpreter [calls]( #l275) `pthread_exit(0)` to terminate the thread
note that the call is from the **destructor** of [`gil_scoped_release`]( #l2000-l2007)
the glibc `pthread_exit` implementation uses unwind; calling unwind from a destructor has similar problems to throwing c++ exceptions from destructors
this triggers the call to `std::terminate` and the abort
here is some code that reproduces the issue
i think #22924 is essentially the same issue
i've also seen this happen in research code that mixes c++ threads with python
import torch
import threading def thread_loop(): a = torch.randn(100) while true: a + a t = threading.thread(target=thread_loop, daemon=true)
``` cc @ezyang @gchanan @zou3519
i am using fairseq to run some multi-gpu training of nlp models
after upgrading pytorch from 1.4.0 to 1.5.0 through conda (on the pytorch channel), i consistently get this error:
error: mkl-service + intel(r) mkl: mkl_threading_layer=intel is incompatible with libgomp.so.1 library
try to import numpy first or set the threading layer accordingly
set mkl_service_force_intel to force it.
error: mkl-service + intel(r) mkl: mkl_threading_layer=intel is incompatible with libgomp.so.1 library
try to import numpy first or set the threading layer accordingly
set mkl_service_force_intel to force it.
error: mkl-service + intel(r) mkl: mkl_threading_layer=intel is incompatible with libgomp.so.1 library
try to import numpy first or set the threading layer accordingly
set mkl_service_force_intel to force it.
traceback (most recent call last): file "/data/mwright/anaconda3/envs/gpu/bin/fairseq-train", line 11, in <module> load_entry_point(\'fairseq\', \'console_scripts\', \'fairseq-train\')() file "/data/mwright/fairseq/fairseq_cli/train.py", line 355, in cli_main nprocs=args.distributed_world_size, file "/data/mwright/anaconda3/envs/gpu/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn return start_processes(fn, args, nprocs, join, daemon, start_method=\'spawn\') file "/data/mwright/anaconda3/envs/gpu/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes while not context.join(): file "/data/mwright/anaconda3/envs/gpu/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 113, in join (error_index, exitcode)
exception: process 0 terminated with exit code 1
``` the above error message was generated when trying to train on 3 gpus, so i assume that the three repetitions of the incompatibliity error means each process is generating one
this error does not occur if i downgrade to pytorch 1.4.0.
while helping @vfdev-5 integrate `torch.cuda.amp` with [ignite]( he asked me to debug a cyclegan+amp example
i saw weird nondeterministic errors
eventually i narrowed down a repro with convtranspose2d, fp16 inputs, and shapes taken from cyclegan
it fails with illegal memory accesses in `slowconvtranspose2dbackward`
(the repro does not involve `torch.cuda.amp` or @vfdev-5 \'s script at all, so i think these are innocent.) i don\'t know the cause yet, the failure may or may not occur based on input addresses, and i\'m not sure what distinguishes "bad" input addresses
posting for visibility
i will check for similar issues and keep digging
- which discusses how nonzero `output_padding` can force convtranspose2d to use the "slow conv" backend (im2col+col2im+cublas gemm) instead of cudnn.
- same failing call (convtranspose2d with fp16 inputs, even the same shapes as my repro!) but fails with different symptoms
the "fix" ( is a one-line change that replaced a macro with a hardcoded character, so any deep memory movement problems likely weren\'t affected.
- also cyclegan backward() failure, but failure came from cudnn
not resolved.
lu_solve throws an error if it is provided with large batched data that is on the gpu
it works for unbachted data, data on the cpu, or tiny matrices (at least 3 x 3).
when kernel has many zeros (e.g
in a masked conv), conv2d output is wrong on gpu.
traceback (most recent call last): file "create_dummy_weight.py", line 1, in <module> import torch file "{some-path}/env/lib/python3.6/site-packages/torch/__init__.py", line 81, in <module> from torch._c import *
importerror: numpy.core.multiarray failed to import
<!-- a clear and concise description of what the bug is
--> error text:
======================================================================
error: test_serialization_filelike_api_requirements (__main__.testtorch)
----------------------------------------------------------------------
traceback (most recent call last): file "test_torch.py", line 4446, in test_serialization_filelike_api_requirements _ = torch.load(filemock) file "c:\\users\\circleci\\project\\build\\win_tmp\\build\\torch\\serialization.py", line 590, in load return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args) file "c:\\users\\circleci\\project\\build\\win_tmp\\build\\torch\\serialization.py", line 754, in _legacy_load magic_number = pickle_module.load(f, **pickle_load_args)
typeerror: file must have 'read', 'readinto' and 'readline' attributes ======================================================================
error: test_serialization_filelike_missing_attrs (__main__.testtorch)
----------------------------------------------------------------------
traceback (most recent call last): file "test_torch.py", line 4473, in test_serialization_filelike_missing_attrs self._test_serialization_filelike(to_serialize, mock, desc) file "test_torch.py", line 4458, in _test_serialization_filelike b = torch.load(data) file "c:\\users\\circleci\\project\\build\\win_tmp\\build\\torch\\serialization.py", line 590, in load return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args) file "c:\\users\\circleci\\project\\build\\win_tmp\\build\\torch\\serialization.py", line 754, in _legacy_load magic_number = pickle_module.load(f, **pickle_load_args)
typeerror: file must have 'read', 'readinto' and 'readline' attributes ======================================================================
error: test_serialization_filelike_stress (__main__.testtorch)
----------------------------------------------------------------------
traceback (most recent call last): file "test_torch.py", line 4479, in test_serialization_filelike_stress self._test_serialization_filelike(a, lambda x: filelikemock(x, has_readinto=false), file "test_torch.py", line 4458, in _test_serialization_filelike b = torch.load(data) file "c:\\users\\circleci\\project\\build\\win_tmp\\build\\torch\\serialization.py", line 590, in load return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args) file "c:\\users\\circleci\\project\\build\\win_tmp\\build\\torch\\serialization.py", line 754, in _legacy_load magic_number = pickle_module.load(f, **pickle_load_args)
typeerror: file must have 'read', 'readinto' and 'readline' attributes ----------------------------------------------------------------------
ran 3620 tests in 103.071s
if you compute the dot product of a column sliced from a larger cuda matrix with itself using `th.mm()`, it will produce an illegal memory access
if you instead compute `(v**2).sum()` (doesn't use cublas), it will not produce the illegal memory access
additionally, if `v` is allocated separately rather than being sliced, it will not produce the error
this may be a duplicate of #17897 or just a similar underlying cublas issue
this script can succeed if n*k > 2^31 - 1 (the commented `n = ...` line is bigger but still works) so i'm not sure.
this may be a marginal use case
i expect the result of multiplying n by 0 matrices be `zeros(n, m)` as a particular case of matrix multiplication definition
however, `bmm` and `matmul` neither fail nor return zero tensor
most likely, memory initialisation is skipped in that case.
let discuss whether we consider it a legitimate input, and either fix the result, or raise an exception.
we observe a weird assertion happening after 4-12 hours of training an image classifier with pytorch nightly and intel omp 2019.4, one of data loader workers fails with this error: ```
omp: error #13: assertion failure at z_linux_util.cpp(2338).
omp: hint please submit a bug report with this message, compile and run commands used, and machine configuration info including native compiler and operating system versions
faster response will be obtained by including all program sources
for information on submitting this issue, please see
in update v = v.item() file "/private/home/szagoruyko/miniconda3/envs/pytorch-nightly/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler _error_if_any_worker_fails()
runtimeerror: dataloader worker (pid 42786) is killed by signal: aborted.
``` downgrading to intel-omp 2019.1 seemingly fixes the issue
also found this issue but it looks like it's not present in 2019.4 (cc: discussed offline with @fmassa and @pietern )
since i can't use conda gcc 7.3 ( i tried to build master with system gcc `7.4` and met ```
cmake error at third_party/fbgemm/third_party/asmjit/cmakelists.txt:100 (target_compile_features): target_compile_features no known features for cxx compiler "gnu" version 7.4.0.
call stack (most recent call first): third_party/fbgemm/third_party/asmjit/cmakelists.txt:332 (asmjit_add_target)
``` i was able to fix it by explicitly adding stdlib11, i.e., adding ```
cmake_cxx_flags="-std=gnu++11",
to #l289 maybe i should submit this issue to `asmjit` repo?
my backward passes are roughly 300 times slower than my forward passes when using `nn.conv2d` layers
for example, a forward pass using just a convolutional layer takes 0.003 seconds, while the backward pass takes more than one second.
have a warning message when i used amp to train a model with fp16.
(some?) batched magma calls illegally read cuda memory
these illegal reads are often "silent" and harmless
if, however, they access unallocated device memory they will cause the program's future cuda calls to fail.
some specific situations, such as batch_size = 32, in/out_channels = 128, h = 1, w = 128 and kernel_size = 7, memory usage is too large.
if kernel_size = 5, memory usage is a few mb;
but if kernel_size = 7, memory usage can reach 10gb!
during training the process dies with the following error: ```
global_step=101292, batch=73, batch_group=0: 30%| | 74/250 [05:01<10:25, 3.56s/it]
python: /opt/conda/conda-bld/magma-cuda100_1564975479425/work/interface_cuda/interface.cpp:897: void magma_queue_create_from_cuda_internal(magma_device_t, cudastream_t, cublashandle_t, cusparsehandle_t, magma_queue**, const char*, const char*, int): assertion `queue->daarray__ != __null' failed.
[1] 71261 abort python train_reconstruct.py --resume ```
cudnn implementation of ctcloss does not handle gradients from subsequent operations.
it seems like there's an undeclared dependency on in the caffe2 library that causes import errors.
when a minimal pytorch extension is run in cuda-gdb, it crashes with this error: ```
cuda-gdb/7.12/gdb/block.c:456: internal-error: set_block_compunit_symtab: assertion `gb->compunit_symtab == null' failed.
i'm just testing the new release and observe the increased time consumption for the basic `conv2d/conv3d` layers
i'm more interested in `float16` performance
here is the simple script: ``` import time
import torch
import torch.nn as nn dtype = torch.float32
device = torch.device("cuda:0") mod = nn.conv3d(64, 64, 3).to(device, dtype=dtype)
input_ = torch.randn((8, 64, 64, 64, 64), device=device, dtype=dtype) curr = time.time()
torch.cuda.synchronize() for i in range(100): mod(input_) torch.cuda.synchronize()
print(time.time() - curr)
``` it takes `4.002` for `float32` and `6.214` for `float16`
upd: testing now with the newest `cuda toolkit`, will include the results here.
upd2: tested on `py3.6_cuda10.0.130_cudnn7.6.2_0`, the results are same
- pytorch version (e.g., 1.2.0): - os (e.g., linux): - how you installed pytorch (`conda`): - cuda/cudnn version: 7.6.0 - gpu models and configuration: rtx 2080 ti cc @ezyang @gchanan @zou3519
running pytorch with multiple p40 gpus freeze and is not killable (even kill -9 by root)
only a reboot removes this process
inside docker container (with nvidia-docker2) it freezes docker
sorry if a duplicate of existing bug-report (can't easily find it)
multiplying a very large cuda tensor with another tensor yields unexpected result.
after initialising a multivariatenormal model with `scale_tril` input, the first `.log_prob()` is extremely slow
by running the below repro code (note that it must be run each time in a fresh python instance), i get the following results:
[0.32401383699834696, 0.0002588090028439183, 0.00021725300030084327, 0.0002125649989466183, 0.00021101400125189684]
``` note that the time for the first call to `.log_prob()` is around 1000x slower than the successive calls
<summary>repro code</summary>
import time
import torch
from torch.distributions.multivariate_normal import multivariatenormal mu = torch.ones(2, device='cuda')
sigma = torch.eye(2, device='cuda')
dist = multivariatenormal(loc=mu, scale_tril=sigma) runs = 5
x = torch.rand(1, 2, device='cuda')
for _ in range(runs): torch.cuda.synchronize() st = time.perf_counter() prob = dist.log_prob(x) torch.cuda.synchronize() times.append(time.perf_counter() - st)
print(times)
</details> when the model is initialised using `covariance_matrix` as the input, this difference between first and successive call times isn't so pronounced
the only difference between supplying `scale_tril` and `covariance_matrix` is that in the latter case, `torch.cholesky()` is performed
somehow performing `torch.cholesky()` on a cuda torch object first seems to reduce the calculation time of the first `.log_pdf()`
in my particular use case, i'm re-initialising models quite frequently, and making only few calls to `.log_prob()` before discarding the model, and so this first call time being so long is very punishing.
hi, i'm trying to compute the jacobian vector product using a trick from
this involves computing the gradient twice
it seems like using conv2d with padding =1 slows down the computation by almost 3 times, compared to padding =0: padding= 0: 2.962866 s
padding=1: 9.922703s in case only one backward pass is computed both give the same times: padding =0: 1.056120s
padding = 1: 1.180639s
source build fails because of mkl-dnn's use of `-werror` and there being a warning thrown in the code
<!-- a clear and concise description of what the bug is
`torch.solve` in gpu tensor fails when the batch size of the tensors > 65535, and throws a `runtimeerror: cuda error: invalid configuration argument `
interestingly, if you run the `torch.solve` multiple times, it will occasionally pass (but with wrong results)
see the reproducing code.
test_array_adaptor and test_from_cuda_array_interface_active_device fails with numba version 0.44.0
when running the example of using libtorch with cmake, it errors about missing `libc10_cuda` during `find_library(torch required)`: ```
cmake error at /usr/lib64/cmake/caffe2/caffe2targets.cmake:107 (message): the imported target "c10_cuda" references the file "/usr/lib/libc10_cuda.so" but this file does not exist
possible reasons include: * the file was deleted, renamed, or moved to another location
* an install or uninstall procedure did not complete successfully
* the installation package was faulty and contained "/usr/lib64/cmake/caffe2/caffe2targets.cmake" but not all the files it references
call stack (most recent call first): /usr/lib64/cmake/caffe2/caffe2config.cmake:116 (include) /usr/lib64/cmake/torch/torchconfig.cmake:39 (find_package) cmakelists.txt:4 (find_package) -- configuring incomplete, errors occurred!
``` it tries to find it under `/usr/lib`, but arch's package manager installs it to `/usr/lib/pytorch`
so it's either the packager didn't install it to the correct place, or the `caffe2targets.cmake` file not rigorous enough about elf location
what's your thought on this? is it proper to modify `caffe2targets.cmake` so it can find the lib correctly under this circumstance, or at least provides a variable or something to workaround this please.
hi, i found a bug while feeding big batch size to my model
the code works fine if i remove `bn.eval()`.
i have checked similar issues, none seems to solve the problem `runtimeerror: cudnn_status_not_supported
this error may appear if you passed in a non-contiguous input.`
<!-- a clear and concise description of what the bug is
i got non-deterministic results when i run my model with nn.lstm with its dropout > 0 on gpu, even when i seeded everything and torch.backends.cudnn.deterministic = true
also, if i set torch.backends.cudnn.enabled = false, the results are deterministic.
the following simple script: crashes with the following traceback:
traceback (most recent call last): file "models/unet/test.py", line 126, in <module> loss.backward() file "/opt/conda/lib/python3.6/site-packages/torch/tensor.py", line 102, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph) file "/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py", line 90, in backward allow_unreachable=true) # allow_unreachable flag
runtimeerror: cudnn error: cudnn_status_execution_failed
`torch.mv` causes an "illegal memory access" when multiplying a matrix with more than 2^31-1 elements
note that each dim of the first matrix can fit in an `int`
this is likely a bug in cublas
either cublas should be fixed or pytorch should issue multiple calls to `cublassgemv`.
building from source fails with nvidia driver 418.43, cuda 10.1, on ubuntu 18.04.
when trying to perform batch cholesky decomposition of a singular matrix on the gpu, a tensor with nans is returned instead of raising a `runtimeerror` as on the cpu.
together with @fmassa, we observed a potential instability when i run the following snippet with cudnn
without cudnn, it works as expected.
it's also worth noticing that this used to work on pytorch 0.4.1, and that it works as expected on cpu as well.
i am running an image classification model with serverless and aws lambda
receiving following error upon calling the serverless function; **"error in cpuinfo: failed to parse the list of present procesors in /sys/devices/system/cpu/present"** - i did not misspell this, the spelling is copied from the error message i received and appear with the same spelling here; suspected it might be something with pytorch 1.0.0 so i switched back to pytorch 0.4.1 which made it work.
there seems to be a limit of n=256x256 for the number of batches one can invert on the gpu
i don't think this limit corresponds properly to available memory
because i can run a n=256x256 -1 batched inverse on a gpu with less availiable memory
i have tested tensorflow on google collab and it allows batched inverse of size n=6144x6144.
when importing pytorch and reading a parquet file with pandas the script randomly fails with a segmentation fault
this problem only occurs when importing pytorch and seems to be related to #11326 as #12739 seems to resolve it (at least i am not able to produce the error anymore)
steps to reproduce the behavior: install pytorch not effected by #12739
a minimal example for producing the error is: import torch import pandas as pd if __name__ == '__main__': df = pd.read_parquet('summary.par') print('done') the data can be found here: unluckily i was never able to fetch a stacktrace for this bug
i ran a script to run the code thousands of times in gdb, but it never fails when using gdb, even though it fails around 50% of the times when normally executing it...
<!-- a clear and concise description of what the bug is
`conv1d` with nan weights outputs non-nan values during traing
but after saving and reloading the weights, it outputs nan values
it should output nan value not only after reloading but also during training if the weights are nan
and i don't know why the weights become nan
these lines in my repo are example
it prints only `weight has nan` after hundreds iterations
#l58-l70
when providing examples via `examples` or `example` keyword for responses it will not be rendered according to media-type.
facing issue with boolean fields reported @ (#4621)[ again.
when i create endpoint documentation i try to use 2 requestbody method using 'application/json' and 'multipart/form-data'
it run correctly when i use application/json with same schema but it caused error when i use multipart/form-data with same configuration of schma, i don't know why because i've set same configuration for those 2 requestbody method
i was working on trying to fix a performance issue in swagger when i noticed a console error unrelated to my changes
you can reproduce the error simply by clicking on the 'model' of a request
![image](
i encountered a strange situation with swagger-ui where the `execute` button stopped working without any apparent reason why (nothing in the console or network tab)
after investigating i noticed that the issue was caused by a trailing comma in my json body.
in brief the problem is that the ui shows the schema of webhook requests as though they were requests made *to* the api when in fact they contain responses *from* the api.
when the query parameter filter=true is used, then the filter field should be shown with all of the endpoints.
but in `src/core/components/operations.jsx` the result of the code:
```javascript
let filter = layoutselectors.currentfilter()
is that the `filter` field will contain a string with value "true".
since this value is a string and not a boolean, the following condition:
```javascript
if (filter !== true)
is true (it should be false), and the filtering is applied.
when multipart/form-data is selected as the content-type and a file is selected to be uploaded, nothing happens after clicking on `execute`
the `execute` button does not work at all.
when opening a path that is in a tag roup , it disappears and then reappears underneath the `default` tag
this is a regression in 3.30.1; i temporarily set my unpkg url to `3.30.0` ( and the behavior no longer happens
i set it back to `3` to get the latest version and it started happening again.
if an oas3 operation uses form data with some _required_ fields, and the field values are left empty, these fields are not included in the request
this is a regression in v
3.26.0, most likely introduced by pr
3.25.5, required fields were sent, even with empty values
this issue is not the same as #5181 which is about preventing "try it out" from being executed if the required fields aren\'t filled.
in the definition above, the post operation uses two media types with different schemas
if you switch the media type to `multipart` then back to `application/x-www-form-urlencoded`, the generated curl command will also include the required fields from the `multipart` schema
this issue is somewhat similar to #5872, not sure if it's the same issue.
consider response headers that contain comma-separated values:
x-header1: value1,value2
x-header2: value1, value2 # note the space after comma
in "try it out" results, the first header is displayed correctly, but the second header is displayed as `x-header2: value1value2`, that is without the `, ` characters
### steps to reproduce 1
open and paste the definition provided above.
open the browser dev tools > network tab.
run the request with the default parameter values.
compare the response header values displayed in swagger ui with the values on the network tab in dev tools
### actual result
the values of the `access-control-expose-headers`, `x-header2` and `x-header3` headers are missing inner `, ` characters.
access-control-expose-headers: x-header1x-header2x-header3access-control-expose-headers
content-length: 289
content-type: application/json
x-header1: value1,value1
x-header2: value1value1
x-header3: value1value2
``` ### expected result
the values of the `access-control-expose-headers`, `x-header2` and `x-header3` headers include commas (and match the values in dev tools > network):
access-control-expose-headers: x-header1, x-header2, x-header3, access-control-expose-headers
content-length: 289
content-type: application/json
x-header1: value1,value1
x-header2: value1, value1
x-header3: value1, value2
- the "available authorizations" popup is empty.
- no errors in the console
the read-only property is not hidden in `post/put`
when the `content-type` response header is not set, swagger-ui does not show the response body
i am seeing this issue when using openapi 3.0 with swagger-ui 3.26.2
![screen shot 2020-06-15 at 5 41 59 pm]( when using swagger 2.0 with swagger-ui 2.2.10, we do see response body even when the `content-type` response header is not set.
![screen shot 2020-06-15 at 5 44 32 pm]( as you can see in the above picture, the `content-type` is set to null so i am wondering if there is any way for swagger-ui(3.26.2) to show the response body even when the `content-type` response header is not set
during the logout from authorize button, i see that "curl" doesn\'t contain the header with authorize, but it seems credentials still exist in session.
(includes steps to re-produce) 1
users clicks on 'authorize' button
oauth pop-up shows and user clicks on authorize.
login succeeds, pop-up now shows the 'logout' button.
user logs out
*without closing the oauth pop-up* user tries to authorize again
an error is returned, something like "error: invalid_grant, description: authorization code is invalid or expired."
i have a micro service system with various swagger-specified apis
my goal was to create a dedicated application, that integrates all the swagger documentation
ron in irc suggested to use the `urls` option to configure multuple spec urls to be selected
so i pulled the `swaggerapi/swagger-ui:v3.25.3` image, copied my files in specified the `urls` environment variable
as expected: the swagger ui shows the first url in the list by default and allows to switch between the urls using a selection in the header
because we have many apis, i then tried to use a custom swagger-config.yaml by copying it into the container and specifying `config_url=swagger-config.yaml` with the contents from above
the ui seems to load the correct swagger-config.yaml (or .json) file, but it still shows the default petstore spec, apparently ignoring the provided `urls` option.
when you choose a file to upload, the ui mistakenly thinks that there is a validation error and will prevent execution of the request.
warning.js:33 warning: unknown prop `initialvalue` on <input> tag
remove this prop from the element
for details, see **however, it works with swagger-ui-dist **
in the preview for the users get request, not all fields are displayed.
i had a typo
`scheme` field on the http auth was `basic` instead of `basic`
but even with this typo all ui features seemed to work okay
i was able to click authorize and enter my credentials
only for them to not being send on request
and actually on `available authorizations` modal, authorization method is depicted as `basicauth (http, basic)` with capital **b**
as how it would be depicted in many other places
this causes confusion as everything seems fine but authorization headers are not send on *try it out* requests
since many issues about authorization headers seem to point at cors issues, whole situation causes a witch hunt over a simple typo.
when changing between request body content types, non form based bodies get stuck on the last one to be selected.
an invalid json body doesn't display an error message or state
if you enter invalid json and click execute, nothing seems to happen
this can be reproduced on this endpoint that accepts json.
depending on the default value for basepath above, the ui will not honor the computed path (which is computed correctly in the ui)
if the default is the current value, when you select the empty string enum for the base path, the executed path just uses the default base path even though the computed url is correct
no matter how you switch it, it does not work
however, if you change the spec to use the empty string as the default, then switching the base path is honored by the ui when executing.
i have one `openapi.yaml` from which i'm referencing paths from other files
when remote path has global parameter (see `petidpathparam` definition in `petstore.yaml`) this parameter is not visible through referenced url (e.g
when looking at openapi.yaml from swagger-ui -> in this case options does not have param
when i switch to `petstore.yaml` parameters are visible in both methods (get and options) even when options doesn't define `petidpathparam`.
swagger ui doesn\'t know hot to render when urls parameter is an empty array ("[]")
it reports an error
when a request body is a type that causes the ui to use an `input type=file` box, then the description is not shown, and instead a message about examples is shown (even if no examples are specified in the openapi json)
the message is: > example values are not available for application/octet-stream media types
changing the type to something like `text/plain` results in the description being shown.
swagger ui resolves the `$ref` inside `examples.<name>.value`, which is incorrect
`$ref` should only be resolved if used directly under `examples.<name>`, but not inside `value`
### expected result
the `incorrect` example should be rendered as
[ { "$ref": "#/components/examples/myexample" }
``` ### actual result
the `incorrect` example is rendered as
[ { "value": { "foo": "bar" }, "$$ref": "#/components/examples/myexample" }
when running the docker container with `-e validator_url=null`, the validator badge is not disabled and instead shows up as a broken link
the documentation at #network says to use `null` to disable the validator badge
it appears that an empty string does disable the validator (i.e
`-e validator_url=`)
i'm not sure which behavior was intended, but if an empty string was the intended way to disable the validator, the documentation should probably be more explicit.
when the page loads up for locations api, it just stays at the top of the page and does not scroll down to #/location like i would expect it to.
fails to render new lines for parameter description as expected.
both parameter descriptions should be two lines
only the first one is rendered with a <br> the second without the dash does not get split into a new line
adding a character like a comma or dash does result in correct render.
in certain cases, switching between media types does not update the displayed "example value"
### steps to reproduce
go to and paste the spec above.
expand the operation.
from the "examples" list, select "bar_json".
from the media types list, select "application/xml".
=> the "examples" list is updated to contain "foo_xml" and "bar_xml" but the displayed "example value" is not updated.
from the media types list, select "text/plain".
=> "example value" still contains the json example
should display "hello, world!".
with an older swagger 2.0 spec, i had a [`parametermacro`]( #macros) that would provide a default value for various request parameters
after a switch to using an openapi 3.0 spec, that `parametermacro` function no longer seems to work and these default values aren't set
it does seem to fire, but that seems to do nothing.
if a request body has `example` but no `schema`, the example value is not displayed
responses do not have this issue.
when i first open dist/index.html, it shows the petstore api
if i point ui at my http (not https) server then it successfully loads but any attempt to "try it out" does the request over https
through trial and error, i have found that this is caused by the `schemes` value in the petstore api
if i modify index.html to point directly to my http url, it works fine
if i add a `schemes` entry to my swagger.json, it works fine
if i remove the ui `url` field so that nothing is loaded initially, it works fine
if i load the petstore api over http instead, it doesn't work, which indicates that the `schemes` value takes precedence, as you would expect.
there was recently a [pull request]( to make automatic example if it is not present
that works fine, but when i have my own example, then the rendered date for some reason includes timestamp as well:
"startdate": "2018-12-25t00:00:00.000z",
when `components` comes before `paths` in yaml/json specification schemas are not rendered correctly.
cannot expand the operation
the following is logged on the chrome dev console:
rangeerror: maximum call stack size exceeded at ue.get (immutable.js:1245) at jt (immutable.js:2753) at pt.set (immutable.js:2686) at immutable.js:2651 at te.__iterate (immutable.js:418) at te.foreach (immutable.js:4381) at immutable.js:2651 at pt.ue.withmutations (immutable.js:1353) at object.pt [as orderedmap] (immutable.js:2648) at e (utils.js:64)
with a `$ref` placed under a summary tag in an oas3 definition, swagger-ui crashes rendering
resolving the issue by removing the tag and filling out the summary correctly does not allow validation to continue working.
it seems that log out functionality does not flushes authorization **code** received after successful oauth2 log in
when you log out and logging in again token request sent again with the same code, not with the new one.
operations with very long paths and summaries render strangely
the long path takes maybe 90% of the space, resulting in the operation summary rendering very strangely.
`swagger-config.yaml` is being overriden by default configuration: #l136 `constructorconfig` is filled with the defaults.
some of the schemas defined in the anyof clause are not rendering all info and their name, as shown in the image below
there's no difference between the definition of the events in the yml file though
![image]( (unfortunately i can't share the definition as it's an internal model)
here is the developer console stacktrace.
index.js:1 typeerror: cannot read property '0' of undefined at object.replace (core.js:27) at c (core.js:231) at object.p [as applypatch] (core.js:268) at object.applypatch (index.js:1) at e.value (index.js:1) at index.js:1 at array.foreach (<anonymous>) at e.value (index.js:1) at e (index.js:1) at index.js:1
(anonymous) @ index.js:1
value @ index.js:1
e @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
t.default @ index.js:1
t @ index.js:1
t.default @ index.js:1
(anonymous) @ index.js:1
x @ runtime.js:62
(anonymous) @ runtime.js:296
e.(anonymous function) @ runtime.js:114
r @ asynctogenerator.js:17
(anonymous) @ asynctogenerator.js:35
t @ _export.js:36
(anonymous) @ asynctogenerator.js:14
(anonymous) @ index.js:1
(anonymous) @ actions.js:175
x @ runtime.js:62
(anonymous) @ runtime.js:296
e.(anonymous function) @ runtime.js:114
r @ asynctogenerator.js:17
(anonymous) @ asynctogenerator.js:28
promise.then (async)
r @ asynctogenerator.js:27
(anonymous) @ asynctogenerator.js:35
t @ _export.js:36
(anonymous) @ asynctogenerator.js:14
(anonymous) @ actions.js:173
(anonymous) @ actions.js:173
x @ runtime.js:62
(anonymous) @ runtime.js:296
e.(anonymous function) @ runtime.js:114
r @ asynctogenerator.js:17
(anonymous) @ asynctogenerator.js:35
t @ _export.js:36
(anonymous) @ asynctogenerator.js:14
_ @ debounce.js:95
k @ debounce.js:144
x @ debounce.js:132
settimeout (async)
(anonymous) @ debounce.js:103
e @ debounce.js:172
(anonymous) @ actions.js:227
(anonymous) @ utils.js:121
(anonymous) @ bindactioncreators.js:3
o.requestresolvedsubtree @ operationcontainer.jsx:155
value @ operationcontainer.jsx:89
e.notifyall @ callbackqueue.js:74
close @ reactreconciletransaction.js:78
closeall @ transaction.js:207
perform @ transaction.js:154
perform @ transaction.js:141
perform @ reactupdates.js:87
x @ reactupdates.js:170
closeall @ transaction.js:207
perform @ transaction.js:154
batchedupdates @ reactdefaultbatchingstrategy.js:60
e @ reactupdates.js:198
a @ reactupdatequeue.js:22
enqueuesetstate @ reactupdatequeue.js:216
s.setstate @ reactbaseclasses.js:62
o.handlechange @ connect.js:302
g @ createstore.js:173
(anonymous) @ utils.js:124
(anonymous) @ bindactioncreators.js:3
(anonymous) @ wrap-actions.js:9
r @ system.js:173
(anonymous) @ system.js:458
(anonymous) @ index.js:22
r @ system.js:173
(anonymous) @ system.js:458
(anonymous) @ actions.js:76
(anonymous) @ utils.js:121
(anonymous) @ bindactioncreators.js:3
(anonymous) @ wrap-actions.js:5
r @ system.js:173
(anonymous) @ system.js:458
(anonymous) @ index.js:11
r @ system.js:173
(anonymous) @ system.js:458
p @ download-url.js:37
promise.then (async)
(anonymous) @ download-url.js:26
(anonymous) @ utils.js:121
(anonymous) @ bindactioncreators.js:3
k @ index.js:152
e.exports @ index.js:179
window.onload @ (index):43
load (async)
(anonymous) @ (index):40
3index.js:1 typeerror: cannot read property '0' of undefined at object._get (core.js:53) at c (core.js:231) at object.l [as getvaluebypointer] (core.js:96) at y (index.js:1) at object.applypatch (index.js:1) at e.value (index.js:1) at index.js:1 at array.foreach (<anonymous>) at e.value (index.js:1) at e (index.js:1)
y @ index.js:1
applypatch @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
e @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
t.default @ index.js:1
t @ index.js:1
t.default @ index.js:1
(anonymous) @ index.js:1
x @ runtime.js:62
(anonymous) @ runtime.js:296
e.(anonymous function) @ runtime.js:114
r @ asynctogenerator.js:17
(anonymous) @ asynctogenerator.js:35
t @ _export.js:36
(anonymous) @ asynctogenerator.js:14
(anonymous) @ index.js:1
(anonymous) @ actions.js:175
x @ runtime.js:62
(anonymous) @ runtime.js:296
e.(anonymous function) @ runtime.js:114
r @ asynctogenerator.js:17
(anonymous) @ asynctogenerator.js:28
promise.then (async)
r @ asynctogenerator.js:27
(anonymous) @ asynctogenerator.js:35
t @ _export.js:36
(anonymous) @ asynctogenerator.js:14
(anonymous) @ actions.js:173
(anonymous) @ actions.js:173
x @ runtime.js:62
(anonymous) @ runtime.js:296
e.(anonymous function) @ runtime.js:114
r @ asynctogenerator.js:17
(anonymous) @ asynctogenerator.js:35
t @ _export.js:36
(anonymous) @ asynctogenerator.js:14
_ @ debounce.js:95
k @ debounce.js:144
x @ debounce.js:132
settimeout (async)
(anonymous) @ debounce.js:103
e @ debounce.js:172
(anonymous) @ actions.js:227
(anonymous) @ utils.js:121
(anonymous) @ bindactioncreators.js:3
o.requestresolvedsubtree @ operationcontainer.jsx:155
value @ operationcontainer.jsx:89
e.notifyall @ callbackqueue.js:74
close @ reactreconciletransaction.js:78
closeall @ transaction.js:207
perform @ transaction.js:154
perform @ transaction.js:141
perform @ reactupdates.js:87
x @ reactupdates.js:170
closeall @ transaction.js:207
perform @ transaction.js:154
batchedupdates @ reactdefaultbatchingstrategy.js:60
e @ reactupdates.js:198
a @ reactupdatequeue.js:22
enqueuesetstate @ reactupdatequeue.js:216
s.setstate @ reactbaseclasses.js:62
o.handlechange @ connect.js:302
g @ createstore.js:173
(anonymous) @ utils.js:124
(anonymous) @ bindactioncreators.js:3
(anonymous) @ wrap-actions.js:9
r @ system.js:173
(anonymous) @ system.js:458
(anonymous) @ index.js:22
r @ system.js:173
(anonymous) @ system.js:458
(anonymous) @ actions.js:76
(anonymous) @ utils.js:121
(anonymous) @ bindactioncreators.js:3
(anonymous) @ wrap-actions.js:5
r @ system.js:173
(anonymous) @ system.js:458
(anonymous) @ index.js:11
r @ system.js:173
(anonymous) @ system.js:458
p @ download-url.js:37
promise.then (async)
(anonymous) @ download-url.js:26
(anonymous) @ utils.js:121
(anonymous) @ bindactioncreators.js:3
k @ index.js:152
e.exports @ index.js:179
window.onload @ (index):43
load (async)
(anonymous) @ (index):40
index.js:1 typeerror: cannot read property '0' of undefined at c (core.js:238) at object.p [as applypatch] (core.js:268) at object.applypatch (index.js:1) at e.value (index.js:1) at index.js:1 at array.foreach (<anonymous>) at e.value (index.js:1) at e (index.js:1) at index.js:1 at e.value (index.js:1)
(anonymous) @ index.js:1
value @ index.js:1
e @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
(anonymous) @ index.js:1
value @ index.js:1
t.default @ index.js:1
t @ index.js:1
t.default @ index.js:1
(anonymous) @ index.js:1
x @ runtime.js:62
(anonymous) @ runtime.js:296
e.(anonymous function) @ runtime.js:114
r @ asynctogenerator.js:17
(anonymous) @ asynctogenerator.js:35
t @ _export.js:36
(anonymous) @ asynctogenerator.js:14
(anonymous) @ index.js:1
(anonymous) @ actions.js:175
x @ runtime.js:62
(anonymous) @ runtime.js:296
e.(anonymous function) @ runtime.js:114
r @ asynctogenerator.js:17
(anonymous) @ asynctogenerator.js:28
promise.then (async)
r @ asynctogenerator.js:27
(anonymous) @ asynctogenerator.js:35
t @ _export.js:36
(anonymous) @ asynctogenerator.js:14
(anonymous) @ actions.js:173
(anonymous) @ actions.js:173
x @ runtime.js:62
(anonymous) @ runtime.js:296
e.(anonymous function) @ runtime.js:114
r @ asynctogenerator.js:17
(anonymous) @ asynctogenerator.js:35
t @ _export.js:36
(anonymous) @ asynctogenerator.js:14
_ @ debounce.js:95
k @ debounce.js:144
x @ debounce.js:132
settimeout (async)
(anonymous) @ debounce.js:103
e @ debounce.js:172
(anonymous) @ actions.js:227
(anonymous) @ utils.js:121
(anonymous) @ bindactioncreators.js:3
o.requestresolvedsubtree @ operationcontainer.jsx:155
value @ operationcontainer.jsx:89
e.notifyall @ callbackqueue.js:74
close @ reactreconciletransaction.js:78
closeall @ transaction.js:207
perform @ transaction.js:154
perform @ transaction.js:141
perform @ reactupdates.js:87
x @ reactupdates.js:170
closeall @ transaction.js:207
perform @ transaction.js:154
batchedupdates @ reactdefaultbatchingstrategy.js:60
e @ reactupdates.js:198
a @ reactupdatequeue.js:22
enqueuesetstate @ reactupdatequeue.js:216
s.setstate @ reactbaseclasses.js:62
o.handlechange @ connect.js:302
g @ createstore.js:173
(anonymous) @ utils.js:124
(anonymous) @ bindactioncreators.js:3
(anonymous) @ wrap-actions.js:9
r @ system.js:173
(anonymous) @ system.js:458
(anonymous) @ index.js:22
r @ system.js:173
(anonymous) @ system.js:458
(anonymous) @ actions.js:76
(anonymous) @ utils.js:121
(anonymous) @ bindactioncreators.js:3
(anonymous) @ wrap-actions.js:5
r @ system.js:173
(anonymous) @ system.js:458
(anonymous) @ index.js:11
r @ system.js:173
(anonymous) @ system.js:458
p @ download-url.js:37
promise.then (async)
(anonymous) @ download-url.js:26
(anonymous) @ utils.js:121
(anonymous) @ bindactioncreators.js:3
k @ index.js:152
e.exports @ index.js:179
window.onload @ (index):43
load (async)
(anonymous) @ (index):40
actions.js:144 debresolvesubtrees: don't have a system to operate on, aborting.
``` ![image](
topbar display correctly with `urls.primaryname` matched spec in the dropdown list, url include `?urls.primaryname=v1` in the address bar of browser, but only the first spec of urls list will be loaded, not v1.
when a swagger spec contains tags that have spaces, and doc expansion is disabled, the deep links to operations don't work.
`/pet` it's response content type contains 3 entries as expected
- application/json - application/xml - text/csv `/pet/findbystatus` only contains `application/json` while it also should contain the above items.
when using swagger-ui for a rest endpoint which sends mutlipart form data the generated curl command is invalid if using a file with an extension that is not recognized by the os/browser.
error in browser console:
system.js:461 rangeerror: maximum call stack size exceeded at e (swagger-ui-bundle.js:1) at immutable.js:3016 at immutable.js:2699 at pt.__iterate (immutable.js:2206) at pt.__iterate (immutable.js:2698) at r.__iterateuncached (immutable.js:3015) at le (immutable.js:604) at r.j.__iterate (immutable.js:274) at r.foreach (immutable.js:4381) at immutable.js:2651
the documentation states that the `url` parameter will be ignored if `urls` or `spec` is used
the ui has a race condition which causes it to load the pet store example even though the `urls` configuration parameter is provided.
when i launch swagger ui with the api_urls environment set, i get the expected behavior with 2 api docs returned
when i launch swagger ui with the config_url environment set, i get the expected behavior with regards to the doc expansion, etc
if i have both api_urls and config_url set, then the config is used, but no api doc is loaded.
i have request body which is being described by external file
one of the property is required, unfortunately it's not indicated in swagger ui.
an operation without an `operationid` will not work with deep linking.
refer to the image below, the curl example seems to be gaining extra backslashes and the `n` characters are removed.
swagger-ui fails to parse callback operation parameters.
when initially loading below example, the spec is detected as 3.0, but after calling `swaggeruibundle` a second time, the spec is detected as 2.0 as seen by the oas3 badge disappearing and the authorization functionality not working
i observe this bug in a react application where it shows on every component mount after the first one
i tried with both `swagger-ui` and `swagger-ui-dist`, both seem affected.
when i try to open endpoint description with empty requestbody parameter, ui just show me ajax loader and nothing else.
the generated curl looks like this:
curl -x post " " -h "accept: application/json" -h "content-type: multipart/form-data" -f "options={ "some_array": [ "string" ], "max_bar": 0 }" -f "myfile=@bla;type=application/zip"
available authorizations dialog is empty.
i expect the description for the server to be there as defined in openapi 3, but instead i don't see anything.
same is happening when i add the `customerkey` and the `projectkey` fields
for a requestbody of type application/octet-stream, as expected, no example is shown, and instead a message similar to "no example values are available for content type application/octet-stream"
this is good since we shouldn't try to convert this content type into json to try to show an example value
for the response however, instead of showing this message in the place of an example value, the example value "string" is shown, which can be misleading to the user.
when using a `requestinterceptor` that returns a promise (that resolves to the request), instead of the pure request, the curl statement generated with curlify results in `curl -x "undefined"`
although the modified request is being used to send the http request.
the first time you instance the swagger ui, it works correctly
after this, if you do it using swaggeruibundle variable again, it doesn't show the same information
for example the requestbody of each request and oas3 badge are missing
this always happens until you reload the page
it is a big problem for spa pages.
if there is an enum query parameter, the user can select the parameter value from a drop down list
in swagger-ui
but the actual request made does not use the selected value, but uses the first element in this drop down list instead.
from what i understand, oas 2.0 response examples (`responses.<code>.examples.<media-type>`) are inline examples and do not support `$ref`
but swagger ui tries to resolve properties named `$ref` in these examples
### swagger/openapi definition
swagger: '2.0'
info: title: test version: 0.0.0
paths: /: get: responses: 200: description: ok examples: application/json: status: ok $ref: '#/definitions/foo'
``` ### actual behavior
response example is displayed as
{ "status": "ok"
the red errors message field is not rendering
the browser console (when using inspect) however still shows the correct error about not being able to get the the referenced resource (404 not found)
interestingly enough, when commenting out the path reference for testb, the error caused by testa is rendered as expected
judging from the intial rendering, it seems like the error is temporarily shown, then vanishing
however im not completely sure about that.
some of the example value" and "model" boxes are empty when viewing the pet store demo site in internet explorer 11.
impossible to specify the required parameter for routes like `/get/{petid}`
the ui just remove it when i'm clicking on try it out -> execute button.
the operation deep link is incorrect
for post pet it is: #/**operations/**pet/addpet, but should be #/pet/addpet
authorize form does not replace url variables:
![image]( it instead makes a call to:
` ` ![image]( _copied from original issue: swagger-api/swagger-editor#1837_
who needs description when you got screenshots...
a definition with only one model, when incorrectly indented, will crash the models component.
i create two swagger-uis in a html page, the same spec, all the configurations are the same
it seems some parameters missed in the second swagger-ui.
we have oauth2 authorization code flow implemented
our api documentation is build using openapi v3
using does not work for us, because there is a bug with the callback url
swagger editor should either provide means to change the callback url required or should at least get it right
expected:
actual:
schema displayed in swagger is not correct
please see the screenshots
newlines in the description fields are being converted to `<br>`
since these fields should be treated as markdown, single newlines should be converted to an empty space
double newlines would be converted to `<p>`
for example: `system for storing beneficiaries' health insurance information for the\ third-party liability group.` is being converted to `system for storing beneficiaries' health insurance information for the <br> third-party liability group.`
in swagger ui, when you have a get that has a response that is a list, and you selected content type of xml, the example value has an error "xml example cannot be generated".
the authorize popup is not clearing the apikey when logout button is clicked.
if server url changes in editor, the url use to obtain an oauth2 token upon attempting to authorize uses the previously used server url.
the browser console shows the following warning when opening a model: ``` bash
vm5274 10:33 warning: failed prop type: invalid prop `schema` of type `immutable.map` supplied to `model`, expected `orderedmap`
in model (created by modelwrapper) in modelwrapper (created by models) in span (created by modelcollapse) in modelcollapse (created by models) in div (created by models) in div (created by nomargin) in nomargin (created by collapse) in collapse (created by models) in section (created by models) in models (created by _class) in _class (created by connect(_class)) in connect(_class) (created by baselayout) in section (created by col) in col (created by baselayout) in div (created by row) in row (created by baselayout) in div (created by baselayout) in div (created by baselayout) in baselayout (created by _class) in _class (created by connect(_class)) in connect(_class) in section (created by container) in container in standalonelayout (created by _class) in _class (created by connect(_class)) in connect(_class) (created by app) in app (created by _class) in _class (created by connect(_class)) in connect(_class) (created by _class2) in provider (created by _class2) in _class2 ```
have a request with optional header `/sql/` where once the header is set it works fine, but once it is reset to empty then an emtpy header is being sent every time.
when submitting a request ("try it out"), the request form clears on submission
this is obnoxious because the user will have to manually refill the form every time they want to retry a request
> note: this only occurs when swagger-ui is installed via npm
when the swagger-ui-bundle.js script is used instead, then everything works as expected.
when a route has a "-" (dash) in the name the ui flinches
the first click causes the route pane to open and immediately close; must be clicked on a second time to stay open
browser consoles report no errors.
i have 2 specs that contains same api, but different enum values
first i tried with one, and then i tried with the second one, and the value of form data is still the old value from the first one, even the dropdown display correctly
consider a model provided by reference, with a `title` that is different from the model's key name in the `definitions` / `components/schemas` collection.
by default (when the models are collapsed), the displayed model name is the model's key name.
but after we expand a model, its displayed name changes to the `title`.
this can be confusing to the end-users of api docs.
consider a model with a `title` that is different from the model's key name in the `definitions` / `components/schemas` collection.
by default (when the models are collapsed), the displayed model name is the model's key name.
but after we expand a model, its displayed name changes to the `title`.
this can be confusing to the end-users of api docs
### steps to reproduce
paste the spec above into the editor.
note the model name in the "models" section.
expand the model.
note the model name in the "models" section.
when i provide json examples in the x-examples section data will get rendered outside the table in swagger ui.
